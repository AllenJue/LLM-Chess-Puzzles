{
  "result": "gpt-3.5-turbo-instruct wins by disqualification (deepseek-ai/deepseek-v3 failed to produce a legal move)",
  "white_player": "gpt-3.5-turbo-instruct",
  "black_player": "deepseek-ai/deepseek-v3",
  "white_score": 1.0,
  "black_score": 0.0,
  "total_moves": 33,
  "moves": [
    "e2e4",
    "e7e5",
    "g1f3",
    "b8c6",
    "f1b5",
    "a7a6",
    "b5c6",
    "d7c6",
    "f3e5",
    "d8d4",
    "e5f3",
    "d4e4",
    "e1f1",
    "e4f3",
    "d1f3",
    "c8g4",
    "f3g4",
    "g8f6",
    "g4e2",
    "f8e7",
    "d2d3",
    "e8g8",
    "e2e7",
    "f6d5",
    "e7e2",
    "d5f4",
    "c1f4",
    "f8e8",
    "e2g4",
    "h7h5",
    "g4h5",
    "g7g6",
    "h5h6"
  ],
  "game_history": [
    {
      "move_number": 1,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e4",
      "move_san": "e4",
      "fen_after": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "move_number": 2,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "e7e5",
      "move_san": "e5",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "move_number": 3,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1f3",
      "move_san": "Nf3",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "move_number": 4,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "b8c6",
      "move_san": "Nc6",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "move_number": 5,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1b5",
      "move_san": "Bb5",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "move_number": 6,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "a7a6",
      "move_san": "a6",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "move_number": 7,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b5c6",
      "move_san": "Bxc6",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1B5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 0 4"
    },
    {
      "move_number": 8,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "d7c6",
      "move_san": "dxc6",
      "fen_after": "r1bqkbnr/1pp2ppp/p1p5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 5"
    },
    {
      "move_number": 9,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f3e5",
      "move_san": "Nxe5",
      "fen_after": "r1bqkbnr/1pp2ppp/p1p5/4N3/4P3/8/PPPP1PPP/RNBQK2R b KQkq - 0 5"
    },
    {
      "move_number": 10,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "d8d4",
      "move_san": "Qd4",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/4N3/3qP3/8/PPPP1PPP/RNBQK2R w KQkq - 1 6"
    },
    {
      "move_number": 11,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e5f3",
      "move_san": "Nf3",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/3qP3/5N2/PPPP1PPP/RNBQK2R b KQkq - 2 6"
    },
    {
      "move_number": 12,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "d4e4",
      "move_san": "Qxe4+",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 7"
    },
    {
      "move_number": 13,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1f1",
      "move_san": "Kf1",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQ1K1R b kq - 1 7"
    },
    {
      "move_number": 14,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "e4f3",
      "move_san": "Qxf3",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/8/5q2/PPPP1PPP/RNBQ1K1R w kq - 0 8"
    },
    {
      "move_number": 15,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1f3",
      "move_san": "Qxf3",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/8/5Q2/PPPP1PPP/RNB2K1R b kq - 0 8"
    },
    {
      "move_number": 16,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "c8g4",
      "move_san": "Bg4",
      "fen_after": "r3kbnr/1pp2ppp/p1p5/8/6b1/5Q2/PPPP1PPP/RNB2K1R w kq - 1 9"
    },
    {
      "move_number": 17,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f3g4",
      "move_san": "Qxg4",
      "fen_after": "r3kbnr/1pp2ppp/p1p5/8/6Q1/8/PPPP1PPP/RNB2K1R b kq - 0 9"
    },
    {
      "move_number": 18,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "g8f6",
      "move_san": "Nf6",
      "fen_after": "r3kb1r/1pp2ppp/p1p2n2/8/6Q1/8/PPPP1PPP/RNB2K1R w kq - 1 10"
    },
    {
      "move_number": 19,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g4e2",
      "move_san": "Qe2+",
      "fen_after": "r3kb1r/1pp2ppp/p1p2n2/8/8/8/PPPPQPPP/RNB2K1R b kq - 2 10"
    },
    {
      "move_number": 20,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "f8e7",
      "move_san": "Be7",
      "fen_after": "r3k2r/1pp1bppp/p1p2n2/8/8/8/PPPPQPPP/RNB2K1R w kq - 3 11"
    },
    {
      "move_number": 21,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2d3",
      "move_san": "d3",
      "fen_after": "r3k2r/1pp1bppp/p1p2n2/8/8/3P4/PPP1QPPP/RNB2K1R b kq - 0 11"
    },
    {
      "move_number": 22,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "e8g8",
      "move_san": "O-O",
      "fen_after": "r4rk1/1pp1bppp/p1p2n2/8/8/3P4/PPP1QPPP/RNB2K1R w - - 1 12"
    },
    {
      "move_number": 23,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e7",
      "move_san": "Qxe7",
      "fen_after": "r4rk1/1pp1Qppp/p1p2n2/8/8/3P4/PPP2PPP/RNB2K1R b - - 0 12"
    },
    {
      "move_number": 24,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "f6d5",
      "move_san": "Nd5",
      "fen_after": "r4rk1/1pp1Qppp/p1p5/3n4/8/3P4/PPP2PPP/RNB2K1R w - - 1 13"
    },
    {
      "move_number": 25,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e7e2",
      "move_san": "Qe2",
      "fen_after": "r4rk1/1pp2ppp/p1p5/3n4/8/3P4/PPP1QPPP/RNB2K1R b - - 2 13"
    },
    {
      "move_number": 26,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "d5f4",
      "move_san": "Nf4",
      "fen_after": "r4rk1/1pp2ppp/p1p5/8/5n2/3P4/PPP1QPPP/RNB2K1R w - - 3 14"
    },
    {
      "move_number": 27,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c1f4",
      "move_san": "Bxf4",
      "fen_after": "r4rk1/1pp2ppp/p1p5/8/5B2/3P4/PPP1QPPP/RN3K1R b - - 0 14"
    },
    {
      "move_number": 28,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "f8e8",
      "move_san": "Rfe8",
      "fen_after": "r3r1k1/1pp2ppp/p1p5/8/5B2/3P4/PPP1QPPP/RN3K1R w - - 1 15"
    },
    {
      "move_number": 29,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2g4",
      "move_san": "Qg4",
      "fen_after": "r3r1k1/1pp2ppp/p1p5/8/5BQ1/3P4/PPP2PPP/RN3K1R b - - 2 15"
    },
    {
      "move_number": 30,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "h7h5",
      "move_san": "h5",
      "fen_after": "r3r1k1/1pp2pp1/p1p5/7p/5BQ1/3P4/PPP2PPP/RN3K1R w - - 0 16"
    },
    {
      "move_number": 31,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g4h5",
      "move_san": "Qxh5",
      "fen_after": "r3r1k1/1pp2pp1/p1p5/7Q/5B2/3P4/PPP2PPP/RN3K1R b - - 0 16"
    },
    {
      "move_number": 32,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "g7g6",
      "move_san": "g6",
      "fen_after": "r3r1k1/1pp2p2/p1p3p1/7Q/5B2/3P4/PPP2PPP/RN3K1R w - - 0 17"
    },
    {
      "move_number": 33,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h5h6",
      "move_san": "Qh6",
      "fen_after": "r3r1k1/1pp2p2/p1p3pQ/8/5B2/3P4/PPP2PPP/RN3K1R b - - 1 17"
    }
  ],
  "final_fen": "r3r1k1/1pp2p2/p1p3pQ/8/5B2/3P4/PPP2PPP/RN3K1R b - - 1 17",
  "white_tokens": {
    "prompt_tokens": 18160,
    "completion_tokens": 48037,
    "total_tokens": 66197
  },
  "black_tokens": {
    "prompt_tokens": 17418,
    "completion_tokens": 11964,
    "total_tokens": 29382
  },
  "white_token_log": [
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 470,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 616,
          "total_tokens": 726,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1726,
        "total_tokens": 2055
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 470,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 616,
          "total_tokens": 726,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 603,
          "total_tokens": 719,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1883,
        "total_tokens": 2230
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 603,
          "total_tokens": 719,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 545,
          "total_tokens": 670,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 457,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 460,
          "total_tokens": 584,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1462,
        "total_tokens": 1836
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 545,
          "total_tokens": 670,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 457,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 460,
          "total_tokens": 584,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 251,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1531,
        "total_tokens": 1929
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 251,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 394,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 500,
          "total_tokens": 640,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 419,
        "total_completion_tokens": 1534,
        "total_tokens": 1953
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 394,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 500,
          "total_tokens": 640,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 254,
          "total_tokens": 401,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 321,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 1215,
        "total_tokens": 1655
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 254,
          "total_tokens": 401,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 321,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 388,
          "total_tokens": 541,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 1668,
        "total_tokens": 2129
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 388,
          "total_tokens": 541,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 1920,
        "total_tokens": 2402
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 170,
          "completion_tokens": 264,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 509,
        "total_completion_tokens": 1544,
        "total_tokens": 2053
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 170,
          "completion_tokens": 264,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 536,
        "total_completion_tokens": 1920,
        "total_tokens": 2456
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 640,
          "total_tokens": 825,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 557,
        "total_completion_tokens": 1920,
        "total_tokens": 2477
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 640,
          "total_tokens": 825,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 195,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 206,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 584,
        "total_completion_tokens": 1041,
        "total_tokens": 1625
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 195,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 206,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 236,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 287,
          "total_tokens": 489,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 1163,
        "total_tokens": 1771
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 236,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 287,
          "total_tokens": 489,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 522,
          "total_tokens": 733,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 1802,
        "total_tokens": 2437
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 522,
          "total_tokens": 733,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 640,
          "total_tokens": 859,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 1920,
        "total_tokens": 2579
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 640,
          "total_tokens": 859,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 28,
          "total_tokens": 257,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 36,
          "total_tokens": 265,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 304,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 686,
        "total_completion_tokens": 368,
        "total_tokens": 1054
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 28,
          "total_tokens": 257,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 36,
          "total_tokens": 265,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 304,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 640,
          "total_tokens": 878,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 236,
          "total_tokens": 474,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 640,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 713,
        "total_completion_tokens": 1516,
        "total_tokens": 2229
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 640,
          "total_tokens": 878,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 236,
          "total_tokens": 474,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 640,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 465,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 318,
          "total_tokens": 431,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1423,
        "total_tokens": 1764
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 465,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 318,
          "total_tokens": 431,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 377,
          "total_tokens": 487,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 334,
          "total_tokens": 444,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1351,
        "total_tokens": 1680
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 377,
          "total_tokens": 487,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 334,
          "total_tokens": 444,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1920,
        "total_tokens": 2267
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 455,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 266,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1361,
        "total_tokens": 1735
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 455,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 266,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 176,
          "total_tokens": 309,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1456,
        "total_tokens": 1854
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 176,
          "total_tokens": 309,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 138,
          "total_tokens": 280,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 425,
        "total_completion_tokens": 1418,
        "total_tokens": 1843
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 138,
          "total_tokens": 280,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 379,
          "total_tokens": 530,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 402,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 452,
        "total_completion_tokens": 1421,
        "total_tokens": 1873
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 379,
          "total_tokens": 530,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 402,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 363,
          "total_tokens": 524,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 625,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 592,
          "total_tokens": 752,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 1580,
        "total_tokens": 2062
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 363,
          "total_tokens": 524,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 625,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 592,
          "total_tokens": 752,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 422,
          "total_tokens": 592,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1702,
        "total_tokens": 2214
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 422,
          "total_tokens": 592,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 207,
          "total_tokens": 386,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 349,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 536,
        "total_completion_tokens": 1196,
        "total_tokens": 1732
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 207,
          "total_tokens": 386,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 349,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 189,
          "completion_tokens": 207,
          "total_tokens": 396,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 189,
          "completion_tokens": 226,
          "total_tokens": 415,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 188,
          "completion_tokens": 640,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 566,
        "total_completion_tokens": 1073,
        "total_tokens": 1639
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 189,
          "completion_tokens": 207,
          "total_tokens": 396,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 189,
          "completion_tokens": 226,
          "total_tokens": 415,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 188,
          "completion_tokens": 640,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 198,
          "completion_tokens": 317,
          "total_tokens": 515,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 198,
          "completion_tokens": 256,
          "total_tokens": 454,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 197,
          "completion_tokens": 196,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 593,
        "total_completion_tokens": 769,
        "total_tokens": 1362
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 198,
          "completion_tokens": 317,
          "total_tokens": 515,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 198,
          "completion_tokens": 256,
          "total_tokens": 454,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 197,
          "completion_tokens": 196,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 205,
          "completion_tokens": 640,
          "total_tokens": 845,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 205,
          "completion_tokens": 183,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 204,
          "completion_tokens": 640,
          "total_tokens": 844,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 614,
        "total_completion_tokens": 1463,
        "total_tokens": 2077
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 205,
          "completion_tokens": 640,
          "total_tokens": 845,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 205,
          "completion_tokens": 183,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 204,
          "completion_tokens": 640,
          "total_tokens": 844,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 213,
          "completion_tokens": 120,
          "total_tokens": 333,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 213,
          "completion_tokens": 344,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 212,
          "completion_tokens": 308,
          "total_tokens": 520,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 638,
        "total_completion_tokens": 772,
        "total_tokens": 1410
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 213,
          "completion_tokens": 120,
          "total_tokens": 333,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 213,
          "completion_tokens": 344,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 212,
          "completion_tokens": 308,
          "total_tokens": 520,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 194,
          "total_tokens": 416,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 89,
          "total_tokens": 311,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 665,
        "total_completion_tokens": 923,
        "total_tokens": 1588
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 194,
          "total_tokens": 416,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 89,
          "total_tokens": 311,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 89,
          "total_tokens": 320,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 107,
          "total_tokens": 338,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 107,
          "total_tokens": 337,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 692,
        "total_completion_tokens": 303,
        "total_tokens": 995
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 89,
          "total_tokens": 320,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 107,
          "total_tokens": 338,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 107,
          "total_tokens": 337,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 239,
          "completion_tokens": 640,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 239,
          "completion_tokens": 372,
          "total_tokens": 611,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 238,
          "completion_tokens": 7,
          "total_tokens": 245,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 716,
        "total_completion_tokens": 1019,
        "total_tokens": 1735
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 239,
          "completion_tokens": 640,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 239,
          "completion_tokens": 372,
          "total_tokens": 611,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 238,
          "completion_tokens": 7,
          "total_tokens": 245,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 248,
          "completion_tokens": 103,
          "total_tokens": 351,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 248,
          "completion_tokens": 11,
          "total_tokens": 259,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 247,
          "completion_tokens": 640,
          "total_tokens": 887,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 743,
        "total_completion_tokens": 754,
        "total_tokens": 1497
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 248,
          "completion_tokens": 103,
          "total_tokens": 351,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 248,
          "completion_tokens": 11,
          "total_tokens": 259,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 247,
          "completion_tokens": 640,
          "total_tokens": 887,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    }
  ],
  "black_token_log": [
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 14,
          "total_tokens": 130,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 10,
          "total_tokens": 126,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 32,
        "total_tokens": 379
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 14,
          "total_tokens": 130,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 10,
          "total_tokens": 126,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 33,
          "total_tokens": 157,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 32,
          "total_tokens": 156,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 371,
        "total_completion_tokens": 705,
        "total_tokens": 1076
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 33,
          "total_tokens": 157,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 32,
          "total_tokens": 156,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 30,
          "total_tokens": 163,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 34,
          "total_tokens": 167,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 47,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 111,
        "total_tokens": 509
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 30,
          "total_tokens": 163,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 34,
          "total_tokens": 167,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 47,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 38,
          "total_tokens": 178,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 43,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 419,
        "total_completion_tokens": 721,
        "total_tokens": 1140
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 38,
          "total_tokens": 178,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 43,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 45,
          "total_tokens": 192,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 50,
          "total_tokens": 197,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 44,
          "total_tokens": 190,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 139,
        "total_tokens": 579
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 45,
          "total_tokens": 192,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 50,
          "total_tokens": 197,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 44,
          "total_tokens": 190,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 58,
          "total_tokens": 211,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 174,
        "total_tokens": 635
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 58,
          "total_tokens": 211,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 76,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 74,
          "total_tokens": 235,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 66,
          "total_tokens": 226,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 216,
        "total_tokens": 698
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 76,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 74,
          "total_tokens": 235,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 66,
          "total_tokens": 226,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 84,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 75,
          "total_tokens": 242,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 503,
        "total_completion_tokens": 234,
        "total_tokens": 737
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 84,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 75,
          "total_tokens": 242,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 83,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 86,
          "total_tokens": 263,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 86,
          "total_tokens": 262,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 530,
        "total_completion_tokens": 255,
        "total_tokens": 785
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 83,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 86,
          "total_tokens": 263,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 86,
          "total_tokens": 262,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 91,
          "total_tokens": 277,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 95,
          "total_tokens": 280,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 557,
        "total_completion_tokens": 272,
        "total_tokens": 829
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 91,
          "total_tokens": 277,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 95,
          "total_tokens": 280,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 194,
          "completion_tokens": 101,
          "total_tokens": 295,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 194,
          "completion_tokens": 112,
          "total_tokens": 306,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 193,
          "completion_tokens": 115,
          "total_tokens": 308,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 581,
        "total_completion_tokens": 328,
        "total_tokens": 909
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 194,
          "completion_tokens": 101,
          "total_tokens": 295,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 194,
          "completion_tokens": 112,
          "total_tokens": 306,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 193,
          "completion_tokens": 115,
          "total_tokens": 308,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 110,
          "total_tokens": 313,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 111,
          "total_tokens": 314,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 125,
          "total_tokens": 327,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 346,
        "total_tokens": 954
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 110,
          "total_tokens": 313,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 111,
          "total_tokens": 314,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 125,
          "total_tokens": 327,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 122,
          "total_tokens": 334,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 132,
          "total_tokens": 344,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 126,
          "total_tokens": 337,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 380,
        "total_tokens": 1015
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 122,
          "total_tokens": 334,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 132,
          "total_tokens": 344,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 126,
          "total_tokens": 337,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 125,
          "total_tokens": 345,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 135,
          "total_tokens": 355,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 141,
          "total_tokens": 360,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 401,
        "total_tokens": 1060
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 125,
          "total_tokens": 345,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 135,
          "total_tokens": 355,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 141,
          "total_tokens": 360,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 128,
          "total_tokens": 357,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 145,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 686,
        "total_completion_tokens": 419,
        "total_tokens": 1105
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 128,
          "total_tokens": 357,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 145,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 154,
          "total_tokens": 392,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 145,
          "total_tokens": 383,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 151,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 713,
        "total_completion_tokens": 450,
        "total_tokens": 1163
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 154,
          "total_tokens": 392,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 145,
          "total_tokens": 383,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 151,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 335,
        "total_completion_tokens": 1920,
        "total_tokens": 2255
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 13,
          "total_tokens": 129,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 23,
          "total_tokens": 139,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 676,
        "total_tokens": 1023
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 13,
          "total_tokens": 129,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 23,
          "total_tokens": 139,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 22,
          "total_tokens": 145,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 371,
        "total_completion_tokens": 82,
        "total_tokens": 453
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 22,
          "total_tokens": 145,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 26,
          "total_tokens": 159,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 49,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 43,
          "total_tokens": 175,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 118,
        "total_tokens": 516
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 26,
          "total_tokens": 159,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 49,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 43,
          "total_tokens": 175,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 46,
          "total_tokens": 187,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 48,
          "total_tokens": 189,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 45,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 139,
        "total_tokens": 561
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 46,
          "total_tokens": 187,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 48,
          "total_tokens": 189,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 45,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 57,
          "total_tokens": 207,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 58,
          "total_tokens": 208,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 57,
          "total_tokens": 206,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 449,
        "total_completion_tokens": 172,
        "total_tokens": 621
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 57,
          "total_tokens": 207,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 58,
          "total_tokens": 208,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 57,
          "total_tokens": 206,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 159,
          "completion_tokens": 65,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 159,
          "completion_tokens": 65,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 158,
          "completion_tokens": 79,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 476,
        "total_completion_tokens": 209,
        "total_tokens": 685
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 159,
          "completion_tokens": 65,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 159,
          "completion_tokens": 65,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 158,
          "completion_tokens": 79,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 169,
          "completion_tokens": 80,
          "total_tokens": 249,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 169,
          "completion_tokens": 83,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 168,
          "completion_tokens": 68,
          "total_tokens": 236,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 506,
        "total_completion_tokens": 231,
        "total_tokens": 737
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 169,
          "completion_tokens": 80,
          "total_tokens": 249,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 169,
          "completion_tokens": 83,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 168,
          "completion_tokens": 68,
          "total_tokens": 236,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 80,
          "total_tokens": 258,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 93,
          "total_tokens": 271,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 75,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 533,
        "total_completion_tokens": 248,
        "total_tokens": 781
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 80,
          "total_tokens": 258,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 93,
          "total_tokens": 271,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 75,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 92,
          "total_tokens": 279,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 105,
          "total_tokens": 292,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 560,
        "total_completion_tokens": 283,
        "total_tokens": 843
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 92,
          "total_tokens": 279,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 105,
          "total_tokens": 292,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 104,
          "total_tokens": 301,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 104,
          "total_tokens": 301,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 111,
          "total_tokens": 307,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 590,
        "total_completion_tokens": 319,
        "total_tokens": 909
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 104,
          "total_tokens": 301,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 104,
          "total_tokens": 301,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 111,
          "total_tokens": 307,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 204,
          "completion_tokens": 103,
          "total_tokens": 307,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 204,
          "completion_tokens": 116,
          "total_tokens": 320,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 203,
          "completion_tokens": 101,
          "total_tokens": 304,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 611,
        "total_completion_tokens": 320,
        "total_tokens": 931
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 204,
          "completion_tokens": 103,
          "total_tokens": 307,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 204,
          "completion_tokens": 116,
          "total_tokens": 320,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 203,
          "completion_tokens": 101,
          "total_tokens": 304,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 120,
          "total_tokens": 332,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 117,
          "total_tokens": 329,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 130,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 367,
        "total_tokens": 1002
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 120,
          "total_tokens": 332,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 117,
          "total_tokens": 329,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 130,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 121,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 149,
          "total_tokens": 369,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 123,
          "total_tokens": 342,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 393,
        "total_tokens": 1052
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 121,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 149,
          "total_tokens": 369,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 123,
          "total_tokens": 342,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 134,
          "total_tokens": 363,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 144,
          "total_tokens": 373,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 686,
        "total_completion_tokens": 424,
        "total_tokens": 1110
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 134,
          "total_tokens": 363,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 144,
          "total_tokens": 373,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 143,
          "total_tokens": 381,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 150,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 143,
          "total_tokens": 380,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 713,
        "total_completion_tokens": 436,
        "total_tokens": 1149
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 143,
          "total_tokens": 381,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 150,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 143,
          "total_tokens": 380,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 246,
          "completion_tokens": 151,
          "total_tokens": 397,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 246,
          "completion_tokens": 151,
          "total_tokens": 397,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 245,
          "completion_tokens": 142,
          "total_tokens": 387,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 737,
        "total_completion_tokens": 444,
        "total_tokens": 1181
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 246,
          "completion_tokens": 151,
          "total_tokens": 397,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 246,
          "completion_tokens": 151,
          "total_tokens": 397,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 245,
          "completion_tokens": 142,
          "total_tokens": 387,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    }
  ],
  "white_responses": [
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 Nf6\nd4 Nf6 Nc3 d5 Bg5 Nbd7 e3 e6 Bd3 Be7 Nf3 O-O O-O c5 dxc5 Nxc5 Ne5 Nxd3 cxd3 Nd7 Bxe7 Qxe7 Nxd7 Bxd7 d4 Rac8 Rc1 Rc7 Qd2 Rfc8 Rc2 Qb4 Rfc1 Ba4 b3 Bb5 Nxb5 Qxd2 Rxc7 Qxc1+ Rxc1 Rxc1#\nd4 Nf6 Nc3 d5 Bg5 Nbd7 e3 e6 Bd3 Be7 Nf3 O-O O-O c5 dxc5 Nxc5 Ne5 Nxd3 cxd3 Nd7 Bxe7 Qxe7 Nxd7 Bxd7 d4 Rac8 Rc1 Rc7 Qd2 Rfc8 Rfc1 Qb4 Rxc7 Qxd2 Rxc8+ Bxc8 Nxd2 Kf8 Kf1 Ke7 Ke2 Kd6 Kd3 b6 Kc3 a5 b4 Ba6 bxa5 bxa5 Nb3 a4 Nc5 Bb5 Kb4 Bc6 Nxa4 e5 Nc3 f6 a4 e5 a5 exd4 exd4 Kc7 Kc5 Kb7 Kxd4 Ka6 Kc5 Kxa5 Nxd5 Kb7 Kd6 Bb5+ Ke7 Kc5 Bf1 g3 Ke6 Kd4 Kf5 Ke3 Kg4 Kf2 Kh3 Kg1 Bc4 Nf5 g6 Ne3 Bd3 Nd5 f5 Nf6 h6 Ne5 Be4 Nxg6 h5 Ne5 Be4 Nf7 Bd5 Ng5 Bf3 Nxf3+ Kf2 Kxh2 Kxf3 Kh3 Kf2 Kg4 Kg2 h4 gxh4 Kxh4 Kf3 Kh3 Kf2 Kg4 Ke3 Kg3 Ke2 Kxf4 Kf2 Ke4 Ke2 f4 Kf2 f3 Kf1 Ke3 Ke1 f2+ Kf1 Kf3#",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 470,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rac8",
            "Rc1",
            "Rc7",
            "Qd2",
            "Rfc8",
            "Rfc1",
            "Qb4",
            "Rxc7",
            "Qxd2",
            "Rxc8+",
            "Bxc8",
            "Nxd2",
            "Kf8",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd6",
            "Kd3",
            "b6",
            "Kc3",
            "a5",
            "b4",
            "Ba6",
            "bxa5",
            "bxa5",
            "Nb3",
            "a4",
            "Nc5",
            "Bb5",
            "Kb4",
            "Bc6",
            "Nxa4",
            "e5",
            "Nc3",
            "f6",
            "a4",
            "e5",
            "a5",
            "exd4",
            "exd4",
            "Kc7",
            "Kc5",
            "Kb7",
            "Kxd4",
            "Ka6",
            "Kc5",
            "Kxa5",
            "Nxd5",
            "Kb7",
            "Kd6",
            "Bb5+",
            "Ke7",
            "Kc5",
            "Bf1",
            "g3",
            "Ke6",
            "Kd4",
            "Kf5",
            "Ke3",
            "Kg4",
            "Kf2",
            "Kh3",
            "Kg1",
            "Bc4",
            "Nf5",
            "g6",
            "Ne3",
            "Bd3",
            "Nd5",
            "f5",
            "Nf6",
            "h6",
            "Ne5",
            "Be4",
            "Nxg6",
            "h5",
            "Ne5",
            "Be4",
            "Nf7",
            "Bd5",
            "Ng5",
            "Bf3",
            "Nxf3+",
            "Kf2",
            "Kxh2",
            "Kxf3",
            "Kh3",
            "Kf2",
            "Kg4",
            "Kg2",
            "h4",
            "gxh4",
            "Kxh4",
            "Kf3",
            "Kh3",
            "Kf2",
            "Kg4",
            "Ke3",
            "Kg3",
            "Ke2",
            "Kxf4",
            "Kf2",
            "Ke4",
            "Ke2",
            "f4",
            "Kf2",
            "f3",
            "Kf1",
            "Ke3",
            "Ke1",
            "f2+",
            "Kf1",
            "Kf3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5\n4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4\n7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8\n10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5\n13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8\n16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6\n19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8\n22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8\n25. Qe7+ Kg8 26. Qg7# 1-0\n*1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5\n4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4\n7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8\n10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5\n13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8\n16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6\n19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8\n22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8\n25. Qe7+ Kg8 26. Qg7# 1-0 1-0 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Bg7 Qe6 Nf6+ Qxf6 Bxf6 Be6 Qxb7 Rc8 Rad1 Bd7 Rxd6 Nb8 Rfd1 Rxc2 Rxd7 Nxd7 Qxd7+ Kf8 Qe7+ Kg8 Qg7#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 616,
            "total_tokens": 726,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Be6",
            "Qxb7",
            "Rc8",
            "Rad1",
            "Bd7",
            "Rxd6",
            "Nb8",
            "Rfd1",
            "Rxc2",
            "Rxd7",
            "Nxd7",
            "Qxd7+",
            "Kf8",
            "Qe7+",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 d5 2. Nf3 Nf6 3. Bg5 Bf5 4. e3 e6 5. Bd3 Bxd3 6. Qxd3 Be7 7. O-O O-O 8. Nbd2 Nbd7 9. c4 c6 10. Rac1 Re8 11. Rfe1 Nf8 12. Ne5 N6d7 13. Bxe7 Qxe7 14. Nxd7 Nxd7 15. cxd5 exd5 16. e4 dxe4 17. Rxe4 Qd6 18. Rce1 Rxe4 19. Nxe4 Qd5 20. Nc3 Qd6 21. Qe4 Nf6 22. Qe5 Qxe5 23. dxe5 Nd7 24. f4 Re8 25. Kf2 Kf8 26. Kf3 f6 27. e6 Nc5 28. f5 g6 29. g4 Ke7 30. Rd1 Rd8 31. Rxd8 Kxd8 32. Ne4 Nxe4 33. Kxe4 Ke7 34. Kd4 b6 35. b4 a6 36. a4 Kd6 37. a5 bxa5 38. bxa5 g5 39. Kc4 c5 40. e7 Kxe7 41. Kxc5 Kd7 42. Kb6 Kd6 43. Kxa6 Kc6 44. Ka7 Kc7 45. a6 Kc8 46. Kb6 Kb8 47. Kc6 Ka7 48. Kd6 Kxa6 49. Ke6 Kb6 50. Kxf6 Kc6 51. Kxg5 Kd6 52. Kh6 Ke7 53. Kxh7 Kf6 54. h4 Kf7 55. g5 Kf8 56. g6 Ke7 57. g7 Kf6 58. g8=Q Kxf5 59. Qg5+ Ke6 60. Kg6 Kd6 61. h5 Ke6 62. h6 Kd6 63. h7 Ke6 64. h8=Q Kd6 65. Qhf6+ Kd7 66. Qd5+ Kc7 67. Qdf7+ Kc8 68. Qh8# d4 d5 Nf3 Nf6 Bg5 Bf5 e3 e6 Bd3 Bxd3 Qxd3 Be7 O-O O-O Nbd2 c6 Rac1 Re8 Rfe1 Nf8 Ne5 N6d7 Bxe7 Qxe7 cxd5 exd5 Rxe4 Qd6 Qe4 Nf6 Qe",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "Bf5",
            "e3",
            "e6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "Be7",
            "O-O",
            "O-O",
            "Nbd2",
            "c6",
            "Rac1",
            "Re8",
            "Rfe1",
            "Nf8",
            "Ne5",
            "N6d7",
            "Bxe7",
            "Qxe7",
            "cxd5",
            "exd5",
            "Rxe4",
            "Qd6",
            "Qe4",
            "Nf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rac8",
              "Rc1",
              "Rc7",
              "Qd2",
              "Rfc8",
              "Rfc1",
              "Qb4",
              "Rxc7",
              "Qxd2",
              "Rxc8+",
              "Bxc8",
              "Nxd2",
              "Kf8",
              "Kf1",
              "Ke7",
              "Ke2",
              "Kd6",
              "Kd3",
              "b6",
              "Kc3",
              "a5",
              "b4",
              "Ba6",
              "bxa5",
              "bxa5",
              "Nb3",
              "a4",
              "Nc5",
              "Bb5",
              "Kb4",
              "Bc6",
              "Nxa4",
              "e5",
              "Nc3",
              "f6",
              "a4",
              "e5",
              "a5",
              "exd4",
              "exd4",
              "Kc7",
              "Kc5",
              "Kb7",
              "Kxd4",
              "Ka6",
              "Kc5",
              "Kxa5",
              "Nxd5",
              "Kb7",
              "Kd6",
              "Bb5+",
              "Ke7",
              "Kc5",
              "Bf1",
              "g3",
              "Ke6",
              "Kd4",
              "Kf5",
              "Ke3",
              "Kg4",
              "Kf2",
              "Kh3",
              "Kg1",
              "Bc4",
              "Nf5",
              "g6",
              "Ne3",
              "Bd3",
              "Nd5",
              "f5",
              "Nf6",
              "h6",
              "Ne5",
              "Be4",
              "Nxg6",
              "h5",
              "Ne5",
              "Be4",
              "Nf7",
              "Bd5",
              "Ng5",
              "Bf3",
              "Nxf3+",
              "Kf2",
              "Kxh2",
              "Kxf3",
              "Kh3",
              "Kf2",
              "Kg4",
              "Kg2",
              "h4",
              "gxh4",
              "Kxh4",
              "Kf3",
              "Kh3",
              "Kf2",
              "Kg4",
              "Ke3",
              "Kg3",
              "Ke2",
              "Kxf4",
              "Kf2",
              "Ke4",
              "Ke2",
              "f4",
              "Kf2",
              "f3",
              "Kf1",
              "Ke3",
              "Ke1",
              "f2+",
              "Kf1",
              "Kf3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Bg7",
              "Qe6",
              "Nf6+",
              "Qxf6",
              "Bxf6",
              "Be6",
              "Qxb7",
              "Rc8",
              "Rad1",
              "Bd7",
              "Rxd6",
              "Nb8",
              "Rfd1",
              "Rxc2",
              "Rxd7",
              "Nxd7",
              "Qxd7+",
              "Kf8",
              "Qe7+",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "Bf5",
              "e3",
              "e6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "Be7",
              "O-O",
              "O-O",
              "Nbd2",
              "c6",
              "Rac1",
              "Re8",
              "Rfe1",
              "Nf8",
              "Ne5",
              "N6d7",
              "Bxe7",
              "Qxe7",
              "cxd5",
              "exd5",
              "Rxe4",
              "Qd6",
              "Qe4",
              "Nf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 470,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 616,
            "total_tokens": 726,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1726,
          "total_tokens": 2055
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 470,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 616,
            "total_tokens": 726,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nf6 *\n3. c4 c6 *\n4. Nc3 dxc4 *\n5. a4 Bf5 *\n6. e3 e6 *\n7. Bxc4 Bb4 *\n8. O-O O-O *\n9. Qe2 Nbd7 *\n10. e4 Bg6 *\n11. Bd3 Bh5 *\n12. e5 Nd5 *\n13. Nxd5 cxd5 *\n14. Qe3 Bg6 *\n15. Bxg6 hxg6 *\n16. Ng5 Re8 *\n17. Qh3 Nf8 *\n18. Rd1 Rc8 *\n19. Rd3 f6 *\n20. Nf3 Qc7 *\n21. Bf4 Qc2 *\n22. Rad1 Qxb2 *\n23. exf6 gxf6 *\n24. Qh6 Rc2 *\n25. Ne5 Rxf2 *\n26. Rh3 Rxg2+ *\n27. Kh1 fxe5 *\n28. Bxe5 Re7 *\n29. Qh8+ Kf7 *\n30. Rf1+ Rf2 *\n31. Rf3+ Rxf3 *\n32. Rxf3+ Ke8 *\n33. Qxf8+ Kd7 *\n34. Qb8 Qb6 *\n35. Rf8 Kc6 *\n36. Qd6# Qxd6 *\n37. Rc8+ Kd7 *\n38. Rc7+ Qxc7 *\n39. Bxc7 Kxc7 *\n40. Kg2 Kd6 *\n41. Kf3 e5 *\n42. dxe5+ Rxe5 *\n43. Kf4 d4 *\n44. h4 d3 *\n45. h5 gxh5 *\n46. a5 d2 *\n47. a6 bxa6 *\n48. Kf3 d1=Q+ *\n49. Kf4 Qd4+ *\n50. Kf3 Re3+ *\n51. Kf2 Qd2+ *\n52. Kf1 Re1# *\nd4 d5 Nf3 Nf6 c4 c6 Nc3 dxc4 a4 Bf5 e3 e6 Bxc4 Bb4 O-O O-O Qe2 Nbd7 e4 Bg6 Bd3 Bh5 e5 Nd5 Nxd5 cxd5 Qe3 Bg6 Bxg6 hxg6 Ng5 Re8 Qh3 Nf8 Rd1 Rc8 Rd3 f6 Nf3 Qc7 Bf4 Qc2 Rd2 Qc1+ Ke2 Qc4+ Rd3 Qxb2+ exf6 gxf6 Qh6 Rc2 Ne5 Rxf2 Rh3 Rxg2 Rh8+ K",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qc7",
            "Bf4",
            "Qc2",
            "Rd2",
            "Qc1+",
            "Ke2",
            "Qc4+",
            "Rd3",
            "Qxb2+",
            "exf6",
            "gxf6",
            "Qh6",
            "Rc2",
            "Ne5",
            "Rxf2",
            "Rh3",
            "Rxg2",
            "Rh8+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nf6 3. c4 c6 4. Nc3 dxc4 5. a4 Bf5 6. e3 e6 7. Bxc4 Bb4 8. O-O O-O 9. Qe2 Nbd7 10. e4 Bg6 11. Bd3 Bh5 12. e5 Nd5 13. Nxd5 cxd5 14. Qe3 Bg6 15. Bxg6 hxg6 16. Ng5 Re8 17. Qh3 Nf8 18. Rd1 Rc8 19. Qb3 Qe7 20. Rd3 Rc4 21. Be3 Rec8 22. h4 f6 23. Nf3 Qc7 24. Bf4 Qb6 25. Qd1 Be7 26. Rb3 Qc6 27. a5 Rb4 28. Rxb4 Bxb4 29. Rc1 Qd7 30. Rxc8 Qxc8 31. Qa4 Be7 32. Qb5 Qc6 33. Qxc6 bxc6 34. Bd2 Nd7 35. exf6 gxf6 36. Kf1 e5 37. dxe5 fxe5 38. Bg5 Kf7 39. Bxe7 Kxe7 40. g4 e4 41. Nd4 c5 42. Nc6+ Kd6 43. Nxa7 Ne5 44. h5 gxh5 45. gxh5 Nf7 46. Nb5+ Kc6 47. Nc3 c4 48. Ke2 Kc5 49. a6 Kb6 50. Nxd5+ Kxa6 51. Ke3 Kb5 52. Kxe4 Kc5 53. Nc3 Kb4 54. Kd5 Kb3 55. f4 Kxb2 56. Kxc4 Kc2 57. Kd4 Kd2 58. Ne4+ Ke2 59. Ng5 Nh6 60. Ke5 Ke3 61. f5 Ng4+ 62. Ke6 Kf4 63. f6 Nh6 64. Nf7 Ng4 65. h6 Nxh6 66. Nxh6 Kg5 67. f7 Kxh6 68. f8=Q+ Kg5 69. Qf5+ Kh4 70. Qg6 Kh3 71. Kf5 Kh2 72. Kf4 Kh1 73. Kf3 Kh2 74. Qg2# e4 d5",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 603,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc7",
            "Bf4",
            "Qb6",
            "Qd1",
            "Be7",
            "Rb3",
            "Qc6",
            "a5",
            "Rb4",
            "Rxb4",
            "Bxb4",
            "Rc1",
            "Qd7",
            "Rxc8",
            "Qxc8",
            "Qa4",
            "Be7",
            "Qb5",
            "Qc6",
            "Qxc6",
            "bxc6",
            "Bd2",
            "Nd7",
            "exf6",
            "gxf6",
            "Kf1",
            "e5",
            "dxe5",
            "fxe5",
            "Bg5",
            "Kf7",
            "Bxe7",
            "Kxe7",
            "g4",
            "e4",
            "Nd4",
            "c5",
            "Nc6+",
            "Kd6",
            "Nxa7",
            "Ne5",
            "h5",
            "gxh5",
            "gxh5",
            "Nf7",
            "Nb5+",
            "Kc6",
            "Nc3",
            "c4",
            "Ke2",
            "Kc5",
            "a6",
            "Kb6",
            "Nxd5+",
            "Kxa6",
            "Ke3",
            "Kb5",
            "Kxe4",
            "Kc5",
            "Nc3",
            "Kb4",
            "Kd5",
            "Kb3",
            "f4",
            "Kxb2",
            "Kxc4",
            "Kc2",
            "Kd4",
            "Kd2",
            "Ne4+",
            "Ke2",
            "Ng5",
            "Nh6",
            "Ke5",
            "Ke3",
            "f5",
            "Ng4+",
            "Ke6",
            "Kf4",
            "f6",
            "Nh6",
            "Nf7",
            "Ng4",
            "h6",
            "Nxh6",
            "Nxh6",
            "Kg5",
            "f7",
            "Kxh6",
            "f8=Q+",
            "Kg5",
            "Qf5+",
            "Kh4",
            "Qg6",
            "Kh3",
            "Kf5",
            "Kh2",
            "Kf4",
            "Kh1",
            "Kf3",
            "Kh2",
            "Qg2#",
            "e4",
            "d5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nf6 3. c4 c6 4. Nc3 dxc4 5. a4 Bf5 6. e3 e6 7. Bxc4 Bb4 8. O-O O-O 9. Qe2 Nbd7 10. e4 Bg6 11. Bd3 Bh5 12. e5 Nd5 13. Nxd5 cxd5 14. Qe3 Bg6 15. Bxg6 hxg6 16. Ng5 Re8 17. Qh3 Nf8 18. Rd1 Rc8 19. Qb3 Qb6 20. Rd3 Be7 21. Qxb6 axb6 22. Nf3 Rc4 23. Bd2 Ra8 24. b3 Rc2 25. Rc1 Rxc1+ 26. Bxc1 Rc8 27. Bd2 Nd7 28. Rc3 Rxc3 29. Bxc3 Nb8 30. Kf1 Nc6 31. Ke2 Kf8 32. Kd3 Ke8 33. Ne1 Kd7 34. Nc2 f6 35. f4 g5 36. g3 gxf4 37. gxf4 f5 38. Ne1 g5 39. fxg5 Bxg5 40. Nf3 Be7 41. h4 Ke8 42. Bd2 Kf7 43. Bg5 Bf8 44. Bd2 Kg6 45. Ng5 Nd8 46. Nf3 Kh5 47. Bg5 Nc6 48. Bd2 Kg4 49. Ng5 Nd8 50. Nh7 Be7 51. Bg5 Bxg5 52. hxg5 Kh5 53. Nf8 Kxg5 54. Nd7 f4 55. Nxb6 Kg4 56. Ke2 Kg3 57. Kf1 Nc6 58. Nd7 Nxd4 59. b4 Nc2 60. b5 f3 61. Nc5 Ne3+ 62. Ke1 f2+ 63. Ke2 f1=Q+ 64. Kxe3 Qf2+ 65. Kd3 Qxc5 66. Kd2 Qa3 67. Kc2 Kf3 68. Kd2 Qb3 69. Kc1 Ke3 70. a5 Kd3 71. a6 Qc2# d4 d5 Nf3 Nf6 c4 c6 Nc3 dxc4 a4 Bf5 e3 e6 Bxc4 Bb4 O-O O-O Qe2 Nbd7 e5 Bg6 Bd3 Bh5 e5 Nd5 Nxd5 cxd5 Qe3 Bg6",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "c4",
            "c6",
            "Nc3",
            "dxc4",
            "a4",
            "Bf5",
            "e3",
            "e6",
            "Bxc4",
            "Bb4",
            "O-O",
            "O-O",
            "Qe2",
            "Nbd7",
            "e5",
            "Bg6",
            "Bd3",
            "Bh5",
            "e5",
            "Nd5",
            "Nxd5",
            "cxd5",
            "Qe3",
            "Bg6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qc7",
              "Bf4",
              "Qc2",
              "Rd2",
              "Qc1+",
              "Ke2",
              "Qc4+",
              "Rd3",
              "Qxb2+",
              "exf6",
              "gxf6",
              "Qh6",
              "Rc2",
              "Ne5",
              "Rxf2",
              "Rh3",
              "Rxg2",
              "Rh8+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qc7",
              "Bf4",
              "Qb6",
              "Qd1",
              "Be7",
              "Rb3",
              "Qc6",
              "a5",
              "Rb4",
              "Rxb4",
              "Bxb4",
              "Rc1",
              "Qd7",
              "Rxc8",
              "Qxc8",
              "Qa4",
              "Be7",
              "Qb5",
              "Qc6",
              "Qxc6",
              "bxc6",
              "Bd2",
              "Nd7",
              "exf6",
              "gxf6",
              "Kf1",
              "e5",
              "dxe5",
              "fxe5",
              "Bg5",
              "Kf7",
              "Bxe7",
              "Kxe7",
              "g4",
              "e4",
              "Nd4",
              "c5",
              "Nc6+",
              "Kd6",
              "Nxa7",
              "Ne5",
              "h5",
              "gxh5",
              "gxh5",
              "Nf7",
              "Nb5+",
              "Kc6",
              "Nc3",
              "c4",
              "Ke2",
              "Kc5",
              "a6",
              "Kb6",
              "Nxd5+",
              "Kxa6",
              "Ke3",
              "Kb5",
              "Kxe4",
              "Kc5",
              "Nc3",
              "Kb4",
              "Kd5",
              "Kb3",
              "f4",
              "Kxb2",
              "Kxc4",
              "Kc2",
              "Kd4",
              "Kd2",
              "Ne4+",
              "Ke2",
              "Ng5",
              "Nh6",
              "Ke5",
              "Ke3",
              "f5",
              "Ng4+",
              "Ke6",
              "Kf4",
              "f6",
              "Nh6",
              "Nf7",
              "Ng4",
              "h6",
              "Nxh6",
              "Nxh6",
              "Kg5",
              "f7",
              "Kxh6",
              "f8=Q+",
              "Kg5",
              "Qf5+",
              "Kh4",
              "Qg6",
              "Kh3",
              "Kf5",
              "Kh2",
              "Kf4",
              "Kh1",
              "Kf3",
              "Kh2",
              "Qg2#",
              "e4",
              "d5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "c4",
              "c6",
              "Nc3",
              "dxc4",
              "a4",
              "Bf5",
              "e3",
              "e6",
              "Bxc4",
              "Bb4",
              "O-O",
              "O-O",
              "Qe2",
              "Nbd7",
              "e5",
              "Bg6",
              "Bd3",
              "Bh5",
              "e5",
              "Nd5",
              "Nxd5",
              "cxd5",
              "Qe3",
              "Bg6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 603,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1883,
          "total_tokens": 2230
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 603,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": "c1g5",
          "aggressive_response": "3. Bg5 Bf5 4. e3 e6 5. Bd3 Bxd3 6. Qxd3 Nbd7 7. Nbd2 Be7 8. O-O O-O 9. c4 c6 10. Rac1 Rc8 11. Rc2 h6 12. Bh4 Nh7 13. Bxe7 Qxe7 14. Rfc1 f5 15. cxd5 exd5 16. Nb3 Ng5 17. Nxg5 Qxg5 18. Nc5 Nxc5 19. Rxc5 f4 20. e4 f3 21. g3 Qg4 22. exd5 cxd5 23. Rxc8 Rxc8 24. Rxc8+ Qxc8 25. Qxf3 Qc1+ 26. Kg2 Qxb2 27. Qxd5+ Kh7 28. Qe4+ Kg8 29. d5 Qxa2 30. d6 Qf7 31. Qe7 Qd5+ 32. Kh3 Qf5+ 33. Kg2 Qd5+ 34. f3 Qd2+ 35. Kh3 Qd5 36. d7 Qf5+ 37. Kg2 Qc2+ 38. Kf1 Qd1+ 39. Kf2 Qd2+ 40. Kg1 Qd1+ 41. Kg2 Qd2+ 42. Kh3 Qd5 43. d8=Q+ Qxd8 44. Qxd8+ Kh7 45. Qc7 b5 46. Qxa7 b4 47. Qb6 b3 48. Qxb3 Kg6 49. Qd3+ Kf6 50. Qe4 g5 51. f4 gxf4 52. gxf4 h5 53. Qe5+ Kg6 54. Qg5+ Kf7 55. Qxh5+ Kf6 56. Qg5+ Ke6 57. Kg4 Kd6 58. h4 Ke6 59. h5 Kd6 60. h6 Ke6 61. h7 Kd6 62. h8=Q Ke6 63. Qhh6+ Kf7 64. Qgg7+ Ke8 65. Qhh8# d4 d5 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 545,
            "total_tokens": 670,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bf5",
            "e3",
            "e6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "Nbd7",
            "Nbd2",
            "Be7",
            "O-O",
            "O-O",
            "c4",
            "c6",
            "Rac1",
            "Rc8",
            "Rc2",
            "h6",
            "Bh4",
            "Nh7",
            "Bxe7",
            "Qxe7",
            "Rfc1",
            "f5",
            "cxd5",
            "exd5",
            "Nb3",
            "Ng5",
            "Nxg5",
            "Qxg5",
            "Nc5",
            "Nxc5",
            "Rxc5",
            "f4",
            "e4",
            "f3",
            "g3",
            "Qg4",
            "exd5",
            "cxd5",
            "Rxc8",
            "Rxc8",
            "Rxc8+",
            "Qxc8",
            "Qxf3",
            "Qc1+",
            "Kg2",
            "Qxb2",
            "Qxd5+",
            "Kh7",
            "Qe4+",
            "Kg8",
            "d5",
            "Qxa2",
            "d6",
            "Qf7",
            "Qe7",
            "Qd5+",
            "Kh3",
            "Qf5+",
            "Kg2",
            "Qd5+",
            "f3",
            "Qd2+",
            "Kh3",
            "Qd5",
            "d7",
            "Qf5+",
            "Kg2",
            "Qc2+",
            "Kf1",
            "Qd1+",
            "Kf2",
            "Qd2+",
            "Kg1",
            "Qd1+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qd5",
            "d8=Q+",
            "Qxd8",
            "Qxd8+",
            "Kh7",
            "Qc7",
            "b5",
            "Qxa7",
            "b4",
            "Qb6",
            "b3",
            "Qxb3",
            "Kg6",
            "Qd3+",
            "Kf6",
            "Qe4",
            "g5",
            "f4",
            "gxf4",
            "gxf4",
            "h5",
            "Qe5+",
            "Kg6",
            "Qg5+",
            "Kf7",
            "Qxh5+",
            "Kf6",
            "Qg5+",
            "Ke6",
            "Kg4",
            "Kd6",
            "h4",
            "Ke6",
            "h5",
            "Kd6",
            "h6",
            "Ke6",
            "h7",
            "Kd6",
            "h8=Q",
            "Ke6",
            "Qhh6+",
            "Kf7",
            "Qgg7+",
            "Ke8",
            "Qhh8#",
            "d4",
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 c4 18. Bc2 Nc5 19. Nf3 Rxf4 20. Nd4 Raf8 21. Rxf4 Rxf4 22. Qe3 Rf8 23. Nb5 Bc6 24. Nd6 Nb7 25. Nxb7 Bxb7 26. Rf1 Rxf1+ 27. Kxf1 Qf7+ 28. Ke2 Kg7 29. Qg5 Bc6 30. h4 Be8 31. h5 h6 32. hxg6 hxg5 33. gxf7 Bxf7 34. Ke3 Bg6 35. Ba4 Bb1 36. a3 Kg6 37. Bd7 Kf5 38. Kd4 Be4 39. g3 Kg4 40. Bxe6+ Kxg3 41. Bxd5 Bxd5 42. Kxd5 Kf4 43. e6 g4 44. e7 g3 45. e8=Q g2 46. Qe1 Kf3 47. Qg1 b5 48. Kc5 a6 49. Kb6 Ke2 50. Kxa6 Kd2 51. Kxb5 Kc2 52. Kxc4 Kxb2 53. Qxg2+ Kxa3 54. Qb7 Ka2 55. Kd3 Ka1 56. Kc2 Ka2 57. Qb2# e4 e5 g5",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 457,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "c4",
            "Bc2",
            "Nc5",
            "Nf3",
            "Rxf4",
            "Nd4",
            "Raf8",
            "Rxf4",
            "Rxf4",
            "Qe3",
            "Rf8",
            "Nb5",
            "Bc6",
            "Nd6",
            "Nb7",
            "Nxb7",
            "Bxb7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qf7+",
            "Ke2",
            "Kg7",
            "Qg5",
            "Bc6",
            "h4",
            "Be8",
            "h5",
            "h6",
            "hxg6",
            "hxg5",
            "gxf7",
            "Bxf7",
            "Ke3",
            "Bg6",
            "Ba4",
            "Bb1",
            "a3",
            "Kg6",
            "Bd7",
            "Kf5",
            "Kd4",
            "Be4",
            "g3",
            "Kg4",
            "Bxe6+",
            "Kxg3",
            "Bxd5",
            "Bxd5",
            "Kxd5",
            "Kf4",
            "e6",
            "g4",
            "e7",
            "g3",
            "e8=Q",
            "g2",
            "Qe1",
            "Kf3",
            "Qg1",
            "b5",
            "Kc5",
            "a6",
            "Kb6",
            "Ke2",
            "Kxa6",
            "Kd2",
            "Kxb5",
            "Kc2",
            "Kxc4",
            "Kxb2",
            "Qxg2+",
            "Kxa3",
            "Qb7",
            "Ka2",
            "Kd3",
            "Ka1",
            "Kc2",
            "Ka2",
            "Qb2#",
            "e4",
            "e5",
            "g5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": null,
          "neutral_response": "3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 c4 18. Bc2 Nc5 19. Nf3 Rxf4 20. Nd4 Raf8 21. Rxf4 Rxf4 22. Qg3 Qf7 23. h4 Ne4 24. Bxe4 dxe4 25. h5 Bd5 26. hxg6 hxg6 27. Re1 Kg7 28. Qg5 Rf2 29. Re3 Rxb2 30. Rh3 Qf2+ 31. Kh2 Qxg2+ 32. Qxg2 Rxg2+ 33. Kxg2 e3+ 34. Kf1 g5 35. Rxe3 Kg6 36. Kf2 g4 37. Kg3 Kg5 38. Re1 a6 39. Rf1 b5 40. Rf6 b4 41. Nxe6+ Bxe6 42. Rxe6 bxc3 43. Rc6 Kf5 44. Rxc4 Kxe5 45. Rxc3 Kd4 46. Ra3 Kc4 47. Rxa6 Kb4 48. Kxg4 Kb5 49. Ra8 Kb6 50. Kf5 Kb7 51. Ra3 Kb6 52. Ke5 Kb5 53. Kd5 Kb4 54. Rb3+ Ka4 55. Kc5 Ka5 56. Ra3# 1-0 3. Bxf6 gxf6 4. Qxf6#",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 460,
            "total_tokens": 584,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf6",
            "Qxf6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1g5",
          "positional_uci": "c1g5",
          "neutral_uci": null,
          "consensus_move": "c1g5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bf5",
              "e3",
              "e6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "Nbd7",
              "Nbd2",
              "Be7",
              "O-O",
              "O-O",
              "c4",
              "c6",
              "Rac1",
              "Rc8",
              "Rc2",
              "h6",
              "Bh4",
              "Nh7",
              "Bxe7",
              "Qxe7",
              "Rfc1",
              "f5",
              "cxd5",
              "exd5",
              "Nb3",
              "Ng5",
              "Nxg5",
              "Qxg5",
              "Nc5",
              "Nxc5",
              "Rxc5",
              "f4",
              "e4",
              "f3",
              "g3",
              "Qg4",
              "exd5",
              "cxd5",
              "Rxc8",
              "Rxc8",
              "Rxc8+",
              "Qxc8",
              "Qxf3",
              "Qc1+",
              "Kg2",
              "Qxb2",
              "Qxd5+",
              "Kh7",
              "Qe4+",
              "Kg8",
              "d5",
              "Qxa2",
              "d6",
              "Qf7",
              "Qe7",
              "Qd5+",
              "Kh3",
              "Qf5+",
              "Kg2",
              "Qd5+",
              "f3",
              "Qd2+",
              "Kh3",
              "Qd5",
              "d7",
              "Qf5+",
              "Kg2",
              "Qc2+",
              "Kf1",
              "Qd1+",
              "Kf2",
              "Qd2+",
              "Kg1",
              "Qd1+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qd5",
              "d8=Q+",
              "Qxd8",
              "Qxd8+",
              "Kh7",
              "Qc7",
              "b5",
              "Qxa7",
              "b4",
              "Qb6",
              "b3",
              "Qxb3",
              "Kg6",
              "Qd3+",
              "Kf6",
              "Qe4",
              "g5",
              "f4",
              "gxf4",
              "gxf4",
              "h5",
              "Qe5+",
              "Kg6",
              "Qg5+",
              "Kf7",
              "Qxh5+",
              "Kf6",
              "Qg5+",
              "Ke6",
              "Kg4",
              "Kd6",
              "h4",
              "Ke6",
              "h5",
              "Kd6",
              "h6",
              "Ke6",
              "h7",
              "Kd6",
              "h8=Q",
              "Ke6",
              "Qhh6+",
              "Kf7",
              "Qgg7+",
              "Ke8",
              "Qhh8#",
              "d4",
              "d5",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "c4",
              "Bc2",
              "Nc5",
              "Nf3",
              "Rxf4",
              "Nd4",
              "Raf8",
              "Rxf4",
              "Rxf4",
              "Qe3",
              "Rf8",
              "Nb5",
              "Bc6",
              "Nd6",
              "Nb7",
              "Nxb7",
              "Bxb7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qf7+",
              "Ke2",
              "Kg7",
              "Qg5",
              "Bc6",
              "h4",
              "Be8",
              "h5",
              "h6",
              "hxg6",
              "hxg5",
              "gxf7",
              "Bxf7",
              "Ke3",
              "Bg6",
              "Ba4",
              "Bb1",
              "a3",
              "Kg6",
              "Bd7",
              "Kf5",
              "Kd4",
              "Be4",
              "g3",
              "Kg4",
              "Bxe6+",
              "Kxg3",
              "Bxd5",
              "Bxd5",
              "Kxd5",
              "Kf4",
              "e6",
              "g4",
              "e7",
              "g3",
              "e8=Q",
              "g2",
              "Qe1",
              "Kf3",
              "Qg1",
              "b5",
              "Kc5",
              "a6",
              "Kb6",
              "Ke2",
              "Kxa6",
              "Kd2",
              "Kxb5",
              "Kc2",
              "Kxc4",
              "Kxb2",
              "Qxg2+",
              "Kxa3",
              "Qb7",
              "Ka2",
              "Kd3",
              "Ka1",
              "Kc2",
              "Ka2",
              "Qb2#",
              "e4",
              "e5",
              "g5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf6",
              "Qxf6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 545,
            "total_tokens": 670,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 457,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 460,
            "total_tokens": 584,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1462,
          "total_tokens": 1836
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 545,
            "total_tokens": 670,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 457,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 460,
            "total_tokens": 584,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e3",
          "aggressive_uci": "e2e3",
          "aggressive_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 Nf6 17. Qh4 Rae8 18. Rf3 Ne4 19. Qh5 Rf5 20. Qg4 Nf6 21. Qh4 Rh5 22. Qf2 Nd7 23. g4 Nxe5 24. fxe5 Rxe5 25. Rf1 d4 26. Rf7 dxe3 27. Qf4 Qd6 28. Rxg7+ Kxg7 29. Qf7+ Kh6 30. Qxh7+ Kg5 31. Qh5# e4 dxe3 Qxe3+ Kh8 Qe5 Qg7#",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 251,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rae8",
            "Rf3",
            "Ne4",
            "Qh5",
            "Rf5",
            "Qg4",
            "Nf6",
            "Qh4",
            "Rh5",
            "Qf2",
            "Nd7",
            "g4",
            "Nxe5",
            "fxe5",
            "Rxe5",
            "Rf1",
            "d4",
            "Rf7",
            "dxe3",
            "Qf4",
            "Qd6",
            "Rxg7+",
            "Kxg7",
            "Qf7+",
            "Kh6",
            "Qxh7+",
            "Kg5",
            "Qh5#",
            "e4",
            "dxe3",
            "Qxe3+",
            "Kh8",
            "Qe5",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e3",
          "positional_uci": "e2e3",
          "positional_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh6 Qg7 18. Qh3 Rae8 19. Rae1 c4 20. Bc2 Nc5 21. Re3 Rf7 22. Rg3 Ref8 23. Rg4 Bc8 24. Qg3 Kh8 25. h4 Qh6 26. Rg5 Rg7 27. Nf3 Bd7 28. Nd4 Rgf7 29. Rg4 Rg7 30. Rg5 Rgf7 31. Rg4 Rg7 32. Rg5 Rgf7 33. Rg4 Rg7 34. Rg5 Rgf7 35. Rg4 Rg7 36. Rg5 Rgf7 37. Rg4 Rg7 38. Rg5 Rgf7 39. Rg4 Rg7 40. Rg5 Rgf7 41. Rg4 Rg7 42. Rg5 Rgf7 43. Rg4 Rg7 44. Rg5 Rgf7 45. Rg4 Rg7 46. Rg5 Rgf7 47. Rg4 Rg7 48. Rg5 Rgf7 49. Rg4 Rg7 50. Rg5 Rgf7 51. Rg4 Rg7 52. Rg5 Rgf7 53. Rg4 Rg7 54. Rg5 Rgf7 55. Rg4 Rg7 56. Rg5 Rgf7 57. Rg4 Rg7 58. Rg5 Rgf7 59. Rg4 Rg7 60. Rg5 Rgf7 61. Rg4 Rg7 62. Rg5 Rgf7 63. Rg4 Rg7 64. Rg5 Rgf7 65. Rg4 Rg7 66. Rg5 Rgf7 67. Rg4 Rg7 68. Rg5 Rgf7 69. Rg4 Rg7 70. Rg5 Rgf7 71. Rg4 Rg7 72. Rg5 Rgf7 73. Rg4 Rg7 74. Rg5 Rgf7 75. Rg4 Rg7 76. Rg5 Rgf7 77. Rg4 Rg",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh3",
            "Rae8",
            "Rae1",
            "c4",
            "Bc2",
            "Nc5",
            "Re3",
            "Rf7",
            "Rg3",
            "Ref8",
            "Rg4",
            "Bc8",
            "Qg3",
            "Kh8",
            "h4",
            "Qh6",
            "Rg5",
            "Rg7",
            "Nf3",
            "Bd7",
            "Nd4",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e3",
          "neutral_uci": "e2e3",
          "neutral_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh6 Qg7 24. Qh4 Qf6 25. Qh6 Qg7 26. Qh4 Qf6 27. Qh6 Qg7 28. Qh4 Qf6 29. Qh6 Qg7 30. Qh4 Qf6 31. Qh6 Qg7 32. Qh4 Qf6 33. Qh6 Qg7 34. Qh4 Qf6 35. Qh6 Qg7 36. Qh4 Qf6 37. Qh6 Qg7 38. Qh4 Qf6 39. Qh6 Qg7 40. Qh4 Qf6 41. Qh6 Qg7 42. Qh4 Qf6 43. Qh6 Qg7 44. Qh4 Qf6 45. Qh6 Qg7 46. Qh4 Qf6 47. Qh6 Qg7 48. Qh4 Qf6 49. Qh6 Qg7 50. Qh4 Qf6 51. Qh6 Qg7 52. Qh4 Qf6 53. Qh6 Qg7 54. Qh4 Qf6 55. Qh6 Qg7 56. Qh4 Qf6 57. Qh6 Qg7 58. Qh4 Qf6 59. Qh6 Qg7 60. Qh4 Qf6 61. Qh6 Qg7 62. Qh4 Qf6 63. Qh6 Qg7 64. Qh4 Qf6 65. Qh6 Qg7 66. Qh4 Qf6 67. Qh6 Qg7 68. Qh4 Qf6 69. Qh6 Qg7 70. Qh4 Qf6 71. Qh6 Qg7 72. Qh4 Qf6 73. Qh6 Qg7 74. Qh4 Qf6 75. Qh6 Qg7 76. Qh4 Qf6",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e3",
          "positional_uci": "e2e3",
          "neutral_uci": "e2e3",
          "consensus_move": "e2e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rae8",
              "Rf3",
              "Ne4",
              "Qh5",
              "Rf5",
              "Qg4",
              "Nf6",
              "Qh4",
              "Rh5",
              "Qf2",
              "Nd7",
              "g4",
              "Nxe5",
              "fxe5",
              "Rxe5",
              "Rf1",
              "d4",
              "Rf7",
              "dxe3",
              "Qf4",
              "Qd6",
              "Rxg7+",
              "Kxg7",
              "Qf7+",
              "Kh6",
              "Qxh7+",
              "Kg5",
              "Qh5#",
              "e4",
              "dxe3",
              "Qxe3+",
              "Kh8",
              "Qe5",
              "Qg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh3",
              "Rae8",
              "Rae1",
              "c4",
              "Bc2",
              "Nc5",
              "Re3",
              "Rf7",
              "Rg3",
              "Ref8",
              "Rg4",
              "Bc8",
              "Qg3",
              "Kh8",
              "h4",
              "Qh6",
              "Rg5",
              "Rg7",
              "Nf3",
              "Bd7",
              "Nd4",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 251,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1531,
          "total_tokens": 1929
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 251,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p2B1/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bd3",
          "aggressive_uci": "f1d3",
          "aggressive_response": "5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Bb7 10. f4 Ne4 11. Bxe7 Qxe7 12. Nxd7 Qxd7 13. Nf3 f6 14. Qe2 Rac8 15. Rad1 Qe7 16. Nd2 Nxd2 17. Rxd2 e5 18. fxe5 fxe5 19. Rxf8+ Rxf8 20. dxc5 bxc5 21. e4 d4 22. Bc4+ Kh8 23. Bd5 Bxd5 24. exd5 Qd6 25. c4 Re8 26. Qe4 Qh6 27. Rd1 Qh5 28. Rf1 Kg8 29. d6 Qg6 30. Qd5+ Qe6 31. Qxc5 Rd8 32. Qxa7 Qxd6 33. Qf7+ Kh8 34. c5 Qxc5 35. b4 Qd6 36. b5 d3 37. b6 d2 38. Rd1 Qxb6+ 39. Kh1 Qe3 40. Qf1 h6 41. h3 Qd3 42. Qf2 e4 43. Qh4 e3 44. Kh2 e2 45. Rxd2 Qxd2 46. a4 e1=Q 47. Qxe1 Qxe1 48. a5 Qxa5 49. h4 Qe5+ 50. Kh3 Rd3+ 51. Kg4 Rg3# e4 d5 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 394,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Bb7",
            "f4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxd7",
            "Qxd7",
            "Nf3",
            "f6",
            "Qe2",
            "Rac8",
            "Rad1",
            "Qe7",
            "Nd2",
            "Nxd2",
            "Rxd2",
            "e5",
            "fxe5",
            "fxe5",
            "Rxf8+",
            "Rxf8",
            "dxc5",
            "bxc5",
            "e4",
            "d4",
            "Bc4+",
            "Kh8",
            "Bd5",
            "Bxd5",
            "exd5",
            "Qd6",
            "c4",
            "Re8",
            "Qe4",
            "Qh6",
            "Rd1",
            "Qh5",
            "Rf1",
            "Kg8",
            "d6",
            "Qg6",
            "Qd5+",
            "Qe6",
            "Qxc5",
            "Rd8",
            "Qxa7",
            "Qxd6",
            "Qf7+",
            "Kh8",
            "c5",
            "Qxc5",
            "b4",
            "Qd6",
            "b5",
            "d3",
            "b6",
            "d2",
            "Rd1",
            "Qxb6+",
            "Kh1",
            "Qe3",
            "Qf1",
            "h6",
            "h3",
            "Qd3",
            "Qf2",
            "e4",
            "Qh4",
            "e3",
            "Kh2",
            "e2",
            "Rxd2",
            "Qxd2",
            "a4",
            "e1=Q",
            "Qxe1",
            "Qxe1",
            "a5",
            "Qxa5",
            "h4",
            "Qe5+",
            "Kh3",
            "Rd3+",
            "Kg4",
            "Rg3#",
            "e4",
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bd3",
          "positional_uci": "f1d3",
          "positional_response": "5. Bd3 O-O 6. Nbd2 c5 7. c3 Nc6 8. O-O b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh3 Qf5 24. g4 Qf6 25. g5 Qf5 26. Qh6 Re7 27. Rh3 Rg7 28. Be2 d4 29. Bg4 Qf8 30. Bxe6+ Kh8 31. Nxg6+ Rxg6 32. Qxg6 Qg7 33. Qxg7+ Kxg7 34. Bf5 dxc3 35. Rxh7+ Kg8 36. Rxb7 cxb2 37. Rb1 Nc3 38. Rxb2 Nd1 39. Re2 Nc3 40. Re1 Nxa2 41. Be6+ Kh8 42. Bxa2 Rd2 43. Bb1 c4 44. Rxa7 c3 45. Rc7 b5 46. Rxc3 b4 47. Rb3 Kg7 48. Rxb4 Kf7 49. Rb6 Kg7 50. Rc1 Rd7 51. h4 Re7 52. Kf2 Rd7 53. h5 Re7 54. h6+ Kf7 55. g6+ Ke8 56. h7 Kd7 57. Rb7+ Ke6 58. Rxe7+ Kxe7 59. h8=Q Ke6 60. Qe5+ Kd7 61. Rc7+ Kd8 62. Qe7# e4 d3 Qd4+ Kf8 Qf7#",
          "positional_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 500,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "c5",
            "c3",
            "Nc6",
            "O-O",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh3",
            "Qf5",
            "g4",
            "Qf6",
            "g5",
            "Qf5",
            "Qh6",
            "Re7",
            "Rh3",
            "Rg7",
            "Be2",
            "d4",
            "Bg4",
            "Qf8",
            "Bxe6+",
            "Kh8",
            "Nxg6+",
            "Rxg6",
            "Qxg6",
            "Qg7",
            "Qxg7+",
            "Kxg7",
            "Bf5",
            "dxc3",
            "Rxh7+",
            "Kg8",
            "Rxb7",
            "cxb2",
            "Rb1",
            "Nc3",
            "Rxb2",
            "Nd1",
            "Re2",
            "Nc3",
            "Re1",
            "Nxa2",
            "Be6+",
            "Kh8",
            "Bxa2",
            "Rd2",
            "Bb1",
            "c4",
            "Rxa7",
            "c3",
            "Rc7",
            "b5",
            "Rxc3",
            "b4",
            "Rb3",
            "Kg7",
            "Rxb4",
            "Kf7",
            "Rb6",
            "Kg7",
            "Rc1",
            "Rd7",
            "h4",
            "Re7",
            "Kf2",
            "Rd7",
            "h5",
            "Re7",
            "h6+",
            "Kf7",
            "g6+",
            "Ke8",
            "h7",
            "Kd7",
            "Rb7+",
            "Ke6",
            "Rxe7+",
            "Kxe7",
            "h8=Q",
            "Ke6",
            "Qe5+",
            "Kd7",
            "Rc7+",
            "Kd8",
            "Qe7#",
            "e4",
            "d3",
            "Qd4+",
            "Kf8",
            "Qf7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bd3",
          "neutral_uci": "f1d3",
          "neutral_response": "5. Bd3 O-O 6. Nbd2 c5 7. c3 Nc6 8. O-O b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 Nf6 17. Qh4 Rae8 18. Rf3 Ne4 19. Qh5 Rf5 20. Qh3 Rf6 21. g4 Rh6 22. Qg2 Qh4 23. g5 Rh5 24. Be2 d4 25. Rg3 Nxg3 26. Qxg3 Qxg3+ 27. hxg3 Rh1+ 28. Kf2 Rxa1 29. exd4 cxd4 30. cxd4 Rxa2 31. Ke3 Rxb2 32. Bc4 Bd5 33. Bd3 Rb3 34. Kd2 Rc8 35. g4 Rcc3 36. f5 exf5 37. gxf5 a5 38. f6 gxf6 39. gxf6 a4 40. Bc2 Rb2 41. Kxc3 a3 42. Nd3 Rxc2+ 43. Kxc2 a2 44. Kb2 Kf7 45. Nb4 Bc4 46. Nxa2 Bxa2 47. Kxa2 Kxf6 48. Kb3 Ke6 49. Kc4 h5 50. d5+ Kd6 51. Kd4 h4 52. Ke4 h3 53. Kf3 Kxd5 54. Kg3 b5 55. Kxh3 b4 56. Kg3 b3 57. Kf3 b2 58. Ke3 b1=Q 59. Kd2 Qb3 60. Ke2 Ke4 61. Kd2 Qd3+ 62. Kc1 Qe2 63. Kb1 Kd3 64. Ka1 Kc3 65. Kb1 Qb2# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O Nbd2 c5 c3 Nc6 O-O b6 Ne5 Nxe5 dxe5 Nd7 f4 f6 exf6 Nxf6 Ne5 Bb7 Ne5 Nd7 Qh5 Nf6 Qh3 Rae8 Rf3 Ne4 Qh5 Rf6 g4 Rh6 Qg2 Qh4 g5 Rh5 Be2 d4 Rg3 Nxg3 Qxg3 Qxg3+ hxg3 Rh1+ Kf2 Rxa1 exd4 cxd4",
          "neutral_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "c5",
            "c3",
            "Nc6",
            "O-O",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Ne5",
            "Bb7",
            "Ne5",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh3",
            "Rae8",
            "Rf3",
            "Ne4",
            "Qh5",
            "Rf6",
            "g4",
            "Rh6",
            "Qg2",
            "Qh4",
            "g5",
            "Rh5",
            "Be2",
            "d4",
            "Rg3",
            "Nxg3",
            "Qxg3",
            "Qxg3+",
            "hxg3",
            "Rh1+",
            "Kf2",
            "Rxa1",
            "exd4",
            "cxd4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1d3",
          "positional_uci": "f1d3",
          "neutral_uci": "f1d3",
          "consensus_move": "f1d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Bb7",
              "f4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxd7",
              "Qxd7",
              "Nf3",
              "f6",
              "Qe2",
              "Rac8",
              "Rad1",
              "Qe7",
              "Nd2",
              "Nxd2",
              "Rxd2",
              "e5",
              "fxe5",
              "fxe5",
              "Rxf8+",
              "Rxf8",
              "dxc5",
              "bxc5",
              "e4",
              "d4",
              "Bc4+",
              "Kh8",
              "Bd5",
              "Bxd5",
              "exd5",
              "Qd6",
              "c4",
              "Re8",
              "Qe4",
              "Qh6",
              "Rd1",
              "Qh5",
              "Rf1",
              "Kg8",
              "d6",
              "Qg6",
              "Qd5+",
              "Qe6",
              "Qxc5",
              "Rd8",
              "Qxa7",
              "Qxd6",
              "Qf7+",
              "Kh8",
              "c5",
              "Qxc5",
              "b4",
              "Qd6",
              "b5",
              "d3",
              "b6",
              "d2",
              "Rd1",
              "Qxb6+",
              "Kh1",
              "Qe3",
              "Qf1",
              "h6",
              "h3",
              "Qd3",
              "Qf2",
              "e4",
              "Qh4",
              "e3",
              "Kh2",
              "e2",
              "Rxd2",
              "Qxd2",
              "a4",
              "e1=Q",
              "Qxe1",
              "Qxe1",
              "a5",
              "Qxa5",
              "h4",
              "Qe5+",
              "Kh3",
              "Rd3+",
              "Kg4",
              "Rg3#",
              "e4",
              "d5",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Nbd2",
              "c5",
              "c3",
              "Nc6",
              "O-O",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh3",
              "Qf5",
              "g4",
              "Qf6",
              "g5",
              "Qf5",
              "Qh6",
              "Re7",
              "Rh3",
              "Rg7",
              "Be2",
              "d4",
              "Bg4",
              "Qf8",
              "Bxe6+",
              "Kh8",
              "Nxg6+",
              "Rxg6",
              "Qxg6",
              "Qg7",
              "Qxg7+",
              "Kxg7",
              "Bf5",
              "dxc3",
              "Rxh7+",
              "Kg8",
              "Rxb7",
              "cxb2",
              "Rb1",
              "Nc3",
              "Rxb2",
              "Nd1",
              "Re2",
              "Nc3",
              "Re1",
              "Nxa2",
              "Be6+",
              "Kh8",
              "Bxa2",
              "Rd2",
              "Bb1",
              "c4",
              "Rxa7",
              "c3",
              "Rc7",
              "b5",
              "Rxc3",
              "b4",
              "Rb3",
              "Kg7",
              "Rxb4",
              "Kf7",
              "Rb6",
              "Kg7",
              "Rc1",
              "Rd7",
              "h4",
              "Re7",
              "Kf2",
              "Rd7",
              "h5",
              "Re7",
              "h6+",
              "Kf7",
              "g6+",
              "Ke8",
              "h7",
              "Kd7",
              "Rb7+",
              "Ke6",
              "Rxe7+",
              "Kxe7",
              "h8=Q",
              "Ke6",
              "Qe5+",
              "Kd7",
              "Rc7+",
              "Kd8",
              "Qe7#",
              "e4",
              "d3",
              "Qd4+",
              "Kf8",
              "Qf7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Nbd2",
              "c5",
              "c3",
              "Nc6",
              "O-O",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Ne5",
              "Bb7",
              "Ne5",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh3",
              "Rae8",
              "Rf3",
              "Ne4",
              "Qh5",
              "Rf6",
              "g4",
              "Rh6",
              "Qg2",
              "Qh4",
              "g5",
              "Rh5",
              "Be2",
              "d4",
              "Rg3",
              "Nxg3",
              "Qxg3",
              "Qxg3+",
              "hxg3",
              "Rh1+",
              "Kf2",
              "Rxa1",
              "exd4",
              "cxd4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 140,
            "completion_tokens": 394,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 140,
            "completion_tokens": 500,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 419,
          "total_completion_tokens": 1534,
          "total_tokens": 1953
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 140,
            "completion_tokens": 394,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 140,
            "completion_tokens": 500,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp1bppp/4pn2/3p2B1/3P4/4PN2/PPP2PPP/RN1QKB1R w KQkq - 1 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh6 Qg7 18. Qxg7+ Kxg7 19. g3 Rf7 20. Nf3 h6 21. Nh4 Nf8 22. Rad1 Rd8 23. Bc2 Rfd7 24. Ba4 Re7 25. Bc2 Red7 26. Ba4 Re7 27. Bc2 Red7 28. Ba4 Re7 29. Bc2 Red7 30. Ba4 Re7 31. Bc2 Red7 32. Ba4 Re7 33. Bc2 Red7 34. Ba4 Re7 35. Bc2 Red7 36. Ba4 Re7 37. Bc2 Red7 38. Ba4 Re7 39. Bc2 Red7 40. Ba4 Re7 41. Bc2 Red7 42. Ba4 Re7 43. Bc2 Red7 44. Ba4 Re7 45. Bc2 Red7 46. Ba4 Re7 47. Bc2 Red7 48. Ba4 Re7 49. Bc2 Red7 50. Ba4 Re7 51. Bc2 Red7 52. Ba4 Re7 53. Bc2 Red7 54. Ba4 Re7 55. Bc2 Red7 56. Ba4 Re7 57. Bc2 Red7 58. Ba4 Re7 59. Bc2 Red7 60. Ba4 Re7 61. Bc2 Red7 62. Ba4 Re7 63. Bc2 Red7 64. Ba4 Re7 65. Bc2 Red7 66. Ba4 Re7 67. Bc2 Red7 68. Ba4 Re7 69. Bc2 Red7 70. Ba4 Re7 71. Bc2 Red7 72. Ba4 Re7 73. Bc2 Rd7 74. Ba4 Re7 75. Bc2 Rd7 76. Ba4 Re7 77. Bc2 Rd7 78. Ba4 Re7 79. Bc2 Rd7 80. Ba4 Re7 81. Bc2 Rd7 82. Ba4 Re7 83. Bc2 Rd7 84. Ba4 Re7 85. Bc2 Rd7 86. Ba4 Re7 87. Bc2 Rd7 88. Ba4 Re7 89. Bc",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qxg7+",
            "Kxg7",
            "g3",
            "Rf7",
            "Nf3",
            "h6",
            "Nh4",
            "Nf8",
            "Rad1",
            "Rd8",
            "Bc2",
            "Rfd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh3 Qf5 24. g4 Qf6 25. g5 Qf5 26. Qh6 Re7 27. Rh3 Rg7 28. Be2 d4 29. Bg4 Qf8 30. Bxe6+ Kh8 31. Nxg6+ Rxg6 32. Qxh7# d4 33. Qxg6 dxe3 34. Rxh7# d3 35. Qh5# d2",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 254,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh3",
            "Qf5",
            "g4",
            "Qf6",
            "g5",
            "Qf5",
            "Qh6",
            "Re7",
            "Rh3",
            "Rg7",
            "Be2",
            "d4",
            "Bg4",
            "Qf8",
            "Bxe6+",
            "Kh8",
            "Nxg6+",
            "Rxg6",
            "Qxh7#",
            "d4",
            "Qxg6",
            "dxe3",
            "Rxh7#",
            "d3",
            "Qh5#",
            "d2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 Rf7 18. Rae1 Raf8 19. Qg4 c4 20. Bc2 Nc5 21. g3 b5 22. Nf3 a5 23. Nd4 b4 24. h4 bxc3 25. bxc3 Bc8 26. h5 Rg7 27. hxg6 hxg6 28. Kg2 g5 29. f5 exf5 30. Bxf5 Bxf5 31. Nxf5 Qe6 32. Nh6+ Qxh6 33. Rxf8+ Kxf8 34. Qc8+ Kf7 35. Rf1+ Ke7 36. Qxc5+ Kd7 37. Qxd5+ Kc7 38. Qxc4+ Kb7 39. Rb1+ Ka7 40. Qc5+ Ka8 41. Qxa5+ Ra7 42. Qd8# Nf6+ Kh2 Qh7#",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 321,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "Rf7",
            "Rae1",
            "Raf8",
            "Qg4",
            "c4",
            "Bc2",
            "Nc5",
            "g3",
            "b5",
            "Nf3",
            "a5",
            "Nd4",
            "b4",
            "h4",
            "bxc3",
            "bxc3",
            "Bc8",
            "h5",
            "Rg7",
            "hxg6",
            "hxg6",
            "Kg2",
            "g5",
            "f5",
            "exf5",
            "Bxf5",
            "Bxf5",
            "Nxf5",
            "Qe6",
            "Nh6+",
            "Qxh6",
            "Rxf8+",
            "Kxf8",
            "Qc8+",
            "Kf7",
            "Rf1+",
            "Ke7",
            "Qxc5+",
            "Kd7",
            "Qxd5+",
            "Kc7",
            "Qxc4+",
            "Kb7",
            "Rb1+",
            "Ka7",
            "Qc5+",
            "Ka8",
            "Qxa5+",
            "Ra7",
            "Qd8#",
            "Nf6+",
            "Kh2",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qxg7+",
              "Kxg7",
              "g3",
              "Rf7",
              "Nf3",
              "h6",
              "Nh4",
              "Nf8",
              "Rad1",
              "Rd8",
              "Bc2",
              "Rfd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh3",
              "Qf5",
              "g4",
              "Qf6",
              "g5",
              "Qf5",
              "Qh6",
              "Re7",
              "Rh3",
              "Rg7",
              "Be2",
              "d4",
              "Bg4",
              "Qf8",
              "Bxe6+",
              "Kh8",
              "Nxg6+",
              "Rxg6",
              "Qxh7#",
              "d4",
              "Qxg6",
              "dxe3",
              "Rxh7#",
              "d3",
              "Qh5#",
              "d2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "Rf7",
              "Rae1",
              "Raf8",
              "Qg4",
              "c4",
              "Bc2",
              "Nc5",
              "g3",
              "b5",
              "Nf3",
              "a5",
              "Nd4",
              "b4",
              "h4",
              "bxc3",
              "bxc3",
              "Bc8",
              "h5",
              "Rg7",
              "hxg6",
              "hxg6",
              "Kg2",
              "g5",
              "f5",
              "exf5",
              "Bxf5",
              "Bxf5",
              "Nxf5",
              "Qe6",
              "Nh6+",
              "Qxh6",
              "Rxf8+",
              "Kxf8",
              "Qc8+",
              "Kf7",
              "Rf1+",
              "Ke7",
              "Qxc5+",
              "Kd7",
              "Qxd5+",
              "Kc7",
              "Qxc4+",
              "Kb7",
              "Rb1+",
              "Ka7",
              "Qc5+",
              "Ka8",
              "Qxa5+",
              "Ra7",
              "Qd8#",
              "Nf6+",
              "Kh2",
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 254,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 321,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 1215,
          "total_tokens": 1655
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 254,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 321,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1QK2R w KQ - 3 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bh4",
          "aggressive_uci": "g5h4",
          "aggressive_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 f6 14. exf6 Nxf6 15. Nf3 Bb7 16. Ne5 Qc7 17. Qe2 Nd7 18. Ng6 Rf6 19. Qh5 Nf8 20. Ne5 Nd7 21. Ng4 Rf7 22. Qg6 Kf8 23. Qxe6 Re8 24. Qg6 Nf6 25. Ne5 Rfe7 26. Rae1 Kg8 27. g4 Re6 28. g5 hxg5 29. Qxg5 Ne4 30. Bxe4 dxe4 31. Rd1 Qe7 32. Qxe7 R8xe7 33. Rd8+ Kh7 34. Rfd1 g5 35. R1d7 gxf4 36. exf4 Kg7 37. Kf2 Kf6 38. Rf8+ Kg7 39. Rf7+ Rxf7 40. Rxf7+ Kh6 41. Rxb7 Rd6 42. Ke3 Rd1 43. Kxe4 Re1+ 44. Kf5 Re2 45. Ng4+ Kh5 46. Rh7# 1-0\n\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 f6 14. exf6 Nxf6 15. Nf3 Bb7 16. Ne5 Qc7 17. Qe2 Nd7 18. Ng6 Rf6 19. Qh5 Nf8 20. Ne5 Nd7 21. Ng4 Rf7 22. Qg6 Kf8 23. Qxe6 Re8 24. Qg6 Nf6 25. Ne5 Rfe7 26. Rae1 Kg8 27. g4 Re6 28. g5 hxg5 29. Qxg5 Ne4 30. Bxe4 dxe4 31. Rd1 Qe7 32. Qxe7 R8xe7 33. Rd8+ Kh7 34. Rfd1 g5 35. R1d7 gxf4 36. exf4 Kg7 37. Kf2 Kf6 38. Rf",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Qc7",
            "Qe2",
            "Nd7",
            "Ng6",
            "Rf6",
            "Qh5",
            "Nf8",
            "Ne5",
            "Nd7",
            "Ng4",
            "Rf7",
            "Qg6",
            "Kf8",
            "Qxe6",
            "Re8",
            "Qg6",
            "Nf6",
            "Ne5",
            "Rfe7",
            "Rae1",
            "Kg8",
            "g4",
            "Re6",
            "g5",
            "hxg5",
            "Qxg5",
            "Ne4",
            "Bxe4",
            "dxe4",
            "Rd1",
            "Qe7",
            "Qxe7",
            "R8xe7",
            "Rd8+",
            "Kh7",
            "Rfd1",
            "g5",
            "R1d7",
            "gxf4",
            "exf4",
            "Kg7",
            "Kf2",
            "Kf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bh4",
          "positional_uci": "g5h4",
          "positional_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 f5 14. exf6 Nxf6 15. Nf3 Bb7 16. Ne5 Rfd8 17. Qe2 Nd7 18. Ng6 Qf6 19. Qh5 Nf8 20. Ne5 Nd7 21. Ng4 Qf7 22. Bg6 Qe7 23. Rf3 Nf6 24. Nxf6+ Qxf6 25. Rg3 d4 26. cxd4 cxd4 27. Rf1 dxe3 28. Rxe3 Rd2 29. Rg3 Qxb2 30. Bf7+ Kf8 31. Bxe6 Rxg2+ 32. Kh1 Rxg3+ 33. Bd5 Qg2+ 34. Bxg2 Bxg2+ 35. Kg1 Bf3+ 36. hxg3 Bxh5 37. Rc1 Re8 38. Rc7 Re7 39. Rc8+ Kf7 40. Rc2 Bg4 41. Kf2 Re2+ 42. Rxe2 Bxe2 43. Kxe2 Ke6 44. Ke3 Kd5 45. Kd3 b5 46. a3 a5 47. g4 b4 48. axb4 axb4 49. f5 Ke5 50. Kc4 Kf4 51. Kxb4 Kxg4 52. Kc4 Kxf5 53. Kd3 Kf4 54. Ke2 Kg3 55. Kf1 Kh2 56. Kf2 g5 57. Kf3 h5 58. Kf2 g4 59. Kf1 g3 60. Ke2 g2 61. Kf3 g1=Q 62. Kf4 Qg4+ 63. Ke5 Kg3 64. Kd5 Kf3 65. Ke5 Qe4+ 66. Kd6 Qf5 67. Kc6 Ke4 68. Kd6 Qd5+ 69. Ke7 Qc6 70. Kf7 Kf5 71. Ke7 Qe6+ 72. Kd8 Qf7 73. Kc8 Ke6 74. Kb8 Kd6 75. Ka8 Kc6 76. Kb8 Qb7# d4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O Bh4 Nbd7 c5 Ne5 Nxe5 dxe5 f4 exf6 Nxf6 Ne5 B",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "c5",
            "Ne5",
            "Nxe5",
            "dxe5",
            "f4",
            "exf6",
            "Nxf6",
            "Ne5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bh4",
          "neutral_uci": "g5h4",
          "neutral_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Rc1 Bb7 11. Bb1 Rc8 12. Qc2 Re8 13. Ne5 Nf8 14. f4 cxd4 15. exd4 Ne4 16. Bxe7 Qxe7 17. Nxe4 dxe4 18. Qe2 f5 19. g4 Qh4 20. gxf5 exf5 21. Qe3 Re6 22. Rf2 Ng6 23. Rg2 Nxe5 24. fxe5 f4 25. Qe1 Qxe1+ 26. Rxe1 e3 27. Rg4 Rf8 28. a3 g5 29. Ba2 Kf7 30. h4 Ke7 31. Bxe6 Kxe6 32. hxg5 hxg5 33. Rxg5 Rh8 34. Kf1 Rh2 35. c4 Be4 36. d5+ Kf7 37. e6+ Kf6 38. Rg8 Bd3+ 39. Kg1 Rxb2 40. Rf8+ Ke7 41. Rf7+ Ke8 42. Rxf4 e2 43. d6 Rd2 44. d7+ Ke7 45. Rf7+ Kd8 46. Rf8+ Ke7 47. d8=Q+ Kxe6 48. Rf6+ Ke5 49. Qd6+ Ke4 50. Rf4+ Ke3 51. Qd4# Nf6+ gxf6+ Kxf6",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 388,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Rc1",
            "Bb7",
            "Bb1",
            "Rc8",
            "Qc2",
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxe4",
            "dxe4",
            "Qe2",
            "f5",
            "g4",
            "Qh4",
            "gxf5",
            "exf5",
            "Qe3",
            "Re6",
            "Rf2",
            "Ng6",
            "Rg2",
            "Nxe5",
            "fxe5",
            "f4",
            "Qe1",
            "Qxe1+",
            "Rxe1",
            "e3",
            "Rg4",
            "Rf8",
            "a3",
            "g5",
            "Ba2",
            "Kf7",
            "h4",
            "Ke7",
            "Bxe6",
            "Kxe6",
            "hxg5",
            "hxg5",
            "Rxg5",
            "Rh8",
            "Kf1",
            "Rh2",
            "c4",
            "Be4",
            "d5+",
            "Kf7",
            "e6+",
            "Kf6",
            "Rg8",
            "Bd3+",
            "Kg1",
            "Rxb2",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rxf4",
            "e2",
            "d6",
            "Rd2",
            "d7+",
            "Ke7",
            "Rf7+",
            "Kd8",
            "Rf8+",
            "Ke7",
            "d8=Q+",
            "Kxe6",
            "Rf6+",
            "Ke5",
            "Qd6+",
            "Ke4",
            "Rf4+",
            "Ke3",
            "Qd4#",
            "Nf6+",
            "gxf6+",
            "Kxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5h4",
          "positional_uci": "g5h4",
          "neutral_uci": "g5h4",
          "consensus_move": "g5h4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Qc7",
              "Qe2",
              "Nd7",
              "Ng6",
              "Rf6",
              "Qh5",
              "Nf8",
              "Ne5",
              "Nd7",
              "Ng4",
              "Rf7",
              "Qg6",
              "Kf8",
              "Qxe6",
              "Re8",
              "Qg6",
              "Nf6",
              "Ne5",
              "Rfe7",
              "Rae1",
              "Kg8",
              "g4",
              "Re6",
              "g5",
              "hxg5",
              "Qxg5",
              "Ne4",
              "Bxe4",
              "dxe4",
              "Rd1",
              "Qe7",
              "Qxe7",
              "R8xe7",
              "Rd8+",
              "Kh7",
              "Rfd1",
              "g5",
              "R1d7",
              "gxf4",
              "exf4",
              "Kg7",
              "Kf2",
              "Kf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "c5",
              "Ne5",
              "Nxe5",
              "dxe5",
              "f4",
              "exf6",
              "Nxf6",
              "Ne5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Rc1",
              "Bb7",
              "Bb1",
              "Rc8",
              "Qc2",
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxe4",
              "dxe4",
              "Qe2",
              "f5",
              "g4",
              "Qh4",
              "gxf5",
              "exf5",
              "Qe3",
              "Re6",
              "Rf2",
              "Ng6",
              "Rg2",
              "Nxe5",
              "fxe5",
              "f4",
              "Qe1",
              "Qxe1+",
              "Rxe1",
              "e3",
              "Rg4",
              "Rf8",
              "a3",
              "g5",
              "Ba2",
              "Kf7",
              "h4",
              "Ke7",
              "Bxe6",
              "Kxe6",
              "hxg5",
              "hxg5",
              "Rxg5",
              "Rh8",
              "Kf1",
              "Rh2",
              "c4",
              "Be4",
              "d5+",
              "Kf7",
              "e6+",
              "Kf6",
              "Rg8",
              "Bd3+",
              "Kg1",
              "Rxb2",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rxf4",
              "e2",
              "d6",
              "Rd2",
              "d7+",
              "Ke7",
              "Rf7+",
              "Kd8",
              "Rf8+",
              "Ke7",
              "d8=Q+",
              "Kxe6",
              "Rf6+",
              "Ke5",
              "Qd6+",
              "Ke4",
              "Rf4+",
              "Ke3",
              "Qd4#",
              "Nf6+",
              "gxf6+",
              "Kxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 388,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 1668,
          "total_tokens": 2129
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 388,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bpp1/4pn1p/3p2B1/3P4/3BPN2/PPP2PPP/RN1Q1RK1 w - - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c4",
          "aggressive_uci": "c2c4",
          "aggressive_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qe6+ Kh7 30. Qf5+ Kg8 31. Qe6+ Kh7 32. Qf5+ Kg8 33. Qe6+ Kh7 34. Qf5+ Kg8 35. Qe6+ Kh7 36. Qf5+ Kg8 37. Qe6+ Kh7 38. Qf5+ Kg8 39. Qe6+ Kh7 40. Qf5+ Kg8 41. Qe6+ Kh7 42. Qf5+ Kg8 43. Qe6+ Kh7 44. Qf5+ Kg8 45. Qe6+ Kh7 46. Qf5+ Kg8 47. Qe6+ Kh7 48. Qf5+ Kg8 49. Qe6+ Kh7 50. Qf5+ Kg8 51. Qe6+ Kh7 52. Qf5+ Kg8 53. Qe6+ Kh7 54. Qf5+ Kg8 55. Qe6+ Kh7 56. Qf5+ Kg8 57. Qe6+ Kh7 58. Qf5+ Kg8 59. Qe6+ Kh7 60. Qf5+ Kg8 61. Qe6+ Kh7 62. Qf5+ Kg8 63. Qe6+ Kh7 64. Qf5+ Kg8 65. Qe6+ Kh7 66. Qf5+ Kg8 67. Qe6+ Kh7 68. Qf5+ Kg8 69. Qe6+ Kh7 70. Qf5+ Kg8 71. Qe6+ Kh7 72. Qf5+ Kg8 73. Qe6+ Kh7 74. Qf5+ Kg8 75. Qe6+ Kh7 76. Qf5+ Kg8 77. Qe6+ Kh7 78. Qf5+ Kg8 79. Qe6+ Kh7 80.",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c4",
          "positional_uci": "c2c4",
          "positional_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qc3+ 39. Ke2 Qc2+ 40. Kf3 Qc3+ 41. Ke2 Qc2+ 42. Kf3 Qc3+ 43. Ke2 Qc2+ 44. Kf3 Qc3+ 45. Ke2 Qc2+ 46. Kf3 Qc3+ 47. Ke2 Qc2+ 48. Kf3 Qc3+ 49. Ke2 Qc2+ 50. Kf3 Qc3+ 51. Ke2 Qc2+ 52. Kf3 Qc3+ 53. Ke2 Qc2+ 54. Kf3 Qc3+ 55. Ke2 Qc2+ 56. Kf3 Qc3+ 57. Ke2 Qc2+ 58. Kf3 Qc3+ 59. Ke2 Qc2+ 60. Kf3 Qc3+ 61. Ke2 Qc2+ 62. Kf3 Qc3+ 63. Ke2 Qc2+ 64. Kf3 Qc3+ 65. Ke2 Qc2+ 66. Kf3 Qc3+ 67. Ke2 Qc2+ 68. Kf3 Qc3+ 69. Ke2 Qc2+ 70. Kf3 Qc3+ 71. Ke2 Qc2+ 72. Kf3 Qc3+ 73. Ke2 Qc2+ 74. Kf3 Qc3+ 75. Ke2 Qc2+ 76. Kf3 Qc3+ 77. Ke2",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c4",
          "neutral_uci": "c2c4",
          "neutral_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80.",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c2c4",
          "positional_uci": "c2c4",
          "neutral_uci": "c2c4",
          "consensus_move": "c2c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 1920,
          "total_tokens": 2402
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbq1rk1/p1p1bpp1/1p2pn1p/3p4/3P3B/3BPN2/PPP2PPP/RN1Q1RK1 w - - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc3",
          "aggressive_uci": "b1c3",
          "aggressive_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 e5 19. bxc5 Rxd4 20. Qb3 bxc5 21. Rxc5 Qxc5 22. Qxb7 Rad8 23. Qb3 Rd2 24. Rf1 Re2 25. Bd3 Rd2 26. Bc4 R8d7 27. Bd5 Kh7 28. Qf3 f6 29. Qf5+ Kh8 30. Qxd7 Kh7 31. Qf5+ Kh8 32. Qe6 Kh7 33. Qg8+ Kg6 34. Bf7+ Kg5 35. Qxg7+ Kf4 36. Qg3+ Kxe4 37. Qf3+ Kd4 38. Qe3# d4 e5 Qd6",
          "aggressive_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 264,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "e5",
            "bxc5",
            "Rxd4",
            "Qb3",
            "bxc5",
            "Rxc5",
            "Qxc5",
            "Qxb7",
            "Rad8",
            "Qb3",
            "Rd2",
            "Rf1",
            "Re2",
            "Bd3",
            "Rd2",
            "Bc4",
            "R8d7",
            "Bd5",
            "Kh7",
            "Qf3",
            "f6",
            "Qf5+",
            "Kh8",
            "Qxd7",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qe6",
            "Kh7",
            "Qg8+",
            "Kg6",
            "Bf7+",
            "Kg5",
            "Qxg7+",
            "Kf4",
            "Qg3+",
            "Kxe4",
            "Qf3+",
            "Kd4",
            "Qe3#",
            "d4",
            "e5",
            "Qd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc3",
          "positional_uci": "b1c3",
          "positional_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qc3+ 39. Ke2 Qc2+ 40. Kf3 Qc3+ 41. Ke2 Qc2+ 42. Kf3 Qc3+ 43. Ke2 Qc2+ 44. Kf3 Qc3+ 45. Ke2 Qc2+ 46. Kf3 Qc3+ 47. Ke2 Qc2+ 48. Kf3 Qc3+ 49. Ke2 Qc2+ 50. Kf3 Qc3+ 51. Ke2 Qc2+ 52. Kf3 Qc3+ 53. Ke2 Qc2+ 54. Kf3 Qc3+ 55. Ke2 Qc2+ 56. Kf3 Qc3+ 57. Ke2 Qc2+ 58. Kf3 Qc3+ 59. Ke2 Qc2+ 60. Kf3 Qc3+ 61. Ke2 Qc2+ 62. Kf3 Qc3+ 63. Ke2 Qc2+ 64. Kf3 Qc3+ 65. Ke2 Qc2+ 66. Kf3 Qc3+ 67. Ke2 Qc2+ 68. Kf3 Qc3+ 69. Ke2 Qc2+ 70. Kf3 Qc3+ 71. Ke2 Qc2+ 72. Kf3 Qc3+ 73. Ke2 Qc2+ 74. Kf3 Qc3+ 75. Ke2 Qc2+ 76. Kf3 Qc3+ 77. Ke2 Qc2+ 78. K",
          "positional_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc3",
          "neutral_uci": "b1c3",
          "neutral_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81",
          "neutral_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b1c3",
          "positional_uci": "b1c3",
          "neutral_uci": "b1c3",
          "consensus_move": "b1c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "e5",
              "bxc5",
              "Rxd4",
              "Qb3",
              "bxc5",
              "Rxc5",
              "Qxc5",
              "Qxb7",
              "Rad8",
              "Qb3",
              "Rd2",
              "Rf1",
              "Re2",
              "Bd3",
              "Rd2",
              "Bc4",
              "R8d7",
              "Bd5",
              "Kh7",
              "Qf3",
              "f6",
              "Qf5+",
              "Kh8",
              "Qxd7",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qe6",
              "Kh7",
              "Qg8+",
              "Kg6",
              "Bf7+",
              "Kg5",
              "Qxg7+",
              "Kf4",
              "Qg3+",
              "Kxe4",
              "Qf3+",
              "Kd4",
              "Qe3#",
              "d4",
              "e5",
              "Qd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 170,
            "completion_tokens": 264,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 509,
          "total_completion_tokens": 1544,
          "total_tokens": 2053
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 170,
            "completion_tokens": 264,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rn1q1rk1/pbp1bpp1/1p2pn1p/3p4/2PP3B/3BPN2/PP3PPP/RN1Q1RK1 w - - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rc1",
          "aggressive_uci": "a1c1",
          "aggressive_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. h4 Qf6 24. Rd1 Rd8 25. Rxd8+ Qxd8 26. Qg4 Qf6 27. Ba2 Kh7 28. h5 Nc7 29. Qd1 Bxe4 30. Nd6 Qd8 31. Bxf7 Nb5 32. Bg6+ Bxg6 33. hxg6+ Kxg6 34. Qd3+ Kf6 35. Ne4+ Ke7 36. Qxb5 Qd1+ 37. Qf1 Qd4 38. Qe1 Ke6 39. Qe3 Qa1+ 40. Kh2 Qd1 41. Qh3+ Kd5 42. Nc3+ 1-0\nd4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 c5 cxd5 Nxd5 Bxe7 Qxe7 Nxd5 Bxd5 e4 Bb7 Re1 cxd4 Nxd4 Nc5 Bb1 Rfd8 b4 Na6 a3 e5 Nf5 Qg5 Qf3 Rac8 Rxc8 Rxc8 h4 Qf6 Qg4 Kh7 h5 Nc7 Qd1 Nb5 Qd7 Bc6 Qxc8 Nd4 Nxd4 exd4 e5+ 1-0 d4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 c5 cxd5 Nxd5 Bxe7 Qxe7 Nxd5 Bxd5 e4 Bb7 Re1 cxd4 Nxd4 Nc5 Bb1 Rfd8 b4 Na6 a3 e5 Nf5 Qg5 Qf3 Rac8 Rxc8 Rxc8 h4 Qf6 Qg4 Kh7 h5 Nc7 Qd1 Nb5 Qd7 Bc6 Qxc8 Nd4 Nxd4 exd4 e5+ 1-0 d4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd",
          "aggressive_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "h4",
            "Qf6",
            "Qg4",
            "Kh7",
            "h5",
            "Nc7",
            "Qd1",
            "Nb5",
            "Qd7",
            "Bc6",
            "Qxc8",
            "Nd4",
            "Nxd4",
            "exd4",
            "e5+",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4",
            "b6",
            "c4",
            "Bb7",
            "Nc3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rc1",
          "positional_uci": "a1c1",
          "positional_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82",
          "positional_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rc1",
          "neutral_uci": "a1c1",
          "neutral_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82",
          "neutral_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a1c1",
          "positional_uci": "a1c1",
          "neutral_uci": "a1c1",
          "consensus_move": "a1c1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "h4",
              "Qf6",
              "Qg4",
              "Kh7",
              "h5",
              "Nc7",
              "Qd1",
              "Nb5",
              "Qd7",
              "Bc6",
              "Qxc8",
              "Nd4",
              "Nxd4",
              "exd4",
              "e5+",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4",
              "b6",
              "c4",
              "Bb7",
              "Nc3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 536,
          "total_completion_tokens": 1920,
          "total_tokens": 2456
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2q1rk1/pbpnbpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/R2Q1RK1 w - - 3 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd5",
          "aggressive_uci": "c4d5",
          "aggressive_response": "11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Qe2 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. Rfd1 Rac8 19. b4 Na4 20. Rxc8 Rxc8 21. Qd2 Nc3 22. Rc1 Nxb1 23. Rxb1 Bxe4 24. Re1 Bd5 25. a3 Qf6 26. Nb5 Qg6 27. g3 Rc2 28. Qe3 Qh5 29. Nd4 Qh3 30. Nf3 Qg4 31. Nd4 Qh3 32. Nf3 Qf5 33. Nd4 Qh3 34. Nf3 Qf5 35. Nd4 Qh3 36. Nf3 Qf5 37. Nd4 Qh3 38. Nf3 Qf5 39. Nd4 Qh3 40. Nf3 Qf5 41. Nd4 Qh3 42. Nf3 Qf5 43. Nd4 Qh3 44. Nf3 Qf5 45. Nd4 Qh3 46. Nf3 Qf5 47. Nd4 Qh3 48. Nf3 Qf5 49. Nd4 Qh3 50. Nf3 Qf5 51. Nd4 Qh3 52. Nf3 Qf5 53. Nd4 Qh3 54. Nf3 Qf5 55. Nd4 Qh3 56. Nf3 Qf5 57. Nd4 Qh3 58. Nf3 Qf5 59. Nd4 Qh3 60. Nf3 Qf5 61. Nd4 Qh3 62. Nf3 Qf5 63. Nd4 Qh3 64. Nf3 Qf5 65. Nd4 Qh3 66. Nf3 Qf5 67. Nd4 Qh3 68. Nf3 Qf5 69. Nd4 Qh3 70. Nf3 Qf5 71. Nd4 Qh3 72. Nf3 Qf5 73. Nd4 Qh3 74. Nf3 Qf5 75. Nd4 Qh3 76. Nf3 Qf5 77. Nd4 Qh3 78. Nf3 Qf5 79. Nd4 Qh3 80. Nf3 Qf5 81. Nd4 Qh3 82. Nf3 Qf5 83. Nd4 Qh3 84. Nf3 Qf5 85. Nd4 Qh3 86. Nf",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Qe2",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "Rfd1",
            "Rac8",
            "b4",
            "Na4",
            "Rxc8",
            "Rxc8",
            "Qd2",
            "Nc3",
            "Rc1",
            "Nxb1",
            "Rxb1",
            "Bxe4",
            "Re1",
            "Bd5",
            "a3",
            "Qf6",
            "Nb5",
            "Qg6",
            "g3",
            "Rc2",
            "Qe3",
            "Qh5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qg4",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "cxd5",
          "positional_uci": "c4d5",
          "positional_response": "11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qc3+ 39. Ke2 Qc2+ 40. Kf3 Qf5+ 41. Ke2 Qe4+ 42. Kf1 Qb1+ 43. Ke2 Qc2+ 44. Kf3 Qc3+ 45. Ke2 Qc2+ 46. Kf3 Qf5+ 47. Ke2 Qe4+ 48. Kf1 Qb1+ 49. Ke2 Qc2+ 50. Kf3 Qc3+ 51. Ke2 Qc2+ 52. Kf3 Qf5+ 53. Ke2 Qe4+ 54. Kf1 Qb1+ 55. Ke2 Qc2+ 56. Kf3 Qc3+ 57. Ke2 Qc2+ 58. Kf3 Qf5+ 59. Ke2 Qe4+ 60. Kf1 Qb1+ 61. Ke2 Qc2+ 62. Kf3 Qc3+ 63. Ke2 Qc2+ 64. Kf3 Qf5+ 65. Ke2 Qe4+ 66. Kf1 Qb1+ 67. Ke2 Qc2+ 68. Kf3 Qc3+ 69. Ke2 Qc2+ 70. Kf3 Qf5+ 71. Ke2 Qe4+ 72. Kf1 Qb1+ 73. Ke2 Qc2+ 74. Kf3 Qc3+ 75. Ke2 Qc2+ 76. Kf3 Qf5+ 77. Ke2 Qe4+ 78. Kf1 Qb1+ 79. Ke2 Qc2+",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "cxd5",
          "neutral_uci": "c4d5",
          "neutral_response": "11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82. Qf5+ Kg8",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c4d5",
          "positional_uci": "c4d5",
          "neutral_uci": "c4d5",
          "consensus_move": "c4d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Qe2",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "Rfd1",
              "Rac8",
              "b4",
              "Na4",
              "Rxc8",
              "Rxc8",
              "Qd2",
              "Nc3",
              "Rc1",
              "Nxb1",
              "Rxb1",
              "Bxe4",
              "Re1",
              "Bd5",
              "a3",
              "Qf6",
              "Nb5",
              "Qg6",
              "g3",
              "Rc2",
              "Qe3",
              "Qh5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qg4",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 1920,
          "total_tokens": 2477
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p2pn1p/2pp4/2PP3B/2NBPN2/PP3PPP/2RQ1RK1 w - - 0 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb1",
          "aggressive_uci": "d3b1",
          "aggressive_response": "12. Bb1 Rc8 13. Qc2 Re8 14. Ne5 Nf8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18.\nQd3 f6 19. Ng4 Qd7 20. Ne3 f5 21. a3 Kh8 22. Ba2 Nxc3 23. Rxc3 Rxc3 24. bxc3\ng6 25. c4 dxc4 26. Bxc4 Re4 27. d5 Qd6 28. g3 Nd7 29. Rd1 Nf6 30. Qc3 Kh7 31.\nRd4 Re7 32. Qd3 Qc5 33. Kf1 b5 34. Bxb5 Rxe3 35. Qxe3 Qxb5+ 36. Kg1 Qb1+ 37.\nKg2 Qc2+ 38. Kh3 Qc5 39. Qe5 Kg7 40. d6 Qc6 41. Qe7+ Kg8 42. Qe6+ Kg7 43. Qe7+\nKg8 44. Qe6+ Kg7 45. Qe7+ Kg8 46. Qe6+ Kg7 47. Qe7+ Kg8 48. Qe6+ Kg7 49. Qe7+\nKg8 50. Qe6+ Kg7 51. Qe7+ Kg8 52. Qe6+ Kg7 53. Qe7+ Kg8 54. Qe6+ Kg7 55. Qe7+\nKg8 56. Qe6+ Kg7 57. Qe7+ Kg8 58. Qe6+ Kg7 59. Qe7+ Kg8 60. Qe6+ Kg7 61. Qe7+\nKg8 62. Qe6+ Kg7 63. Qe7+ Kg8 64. Qe6+ Kg7 65. Qe7+ Kg8 66. Qe6+ Kg7 67. Qe7+\nKg8 68. Qe6+ Kg7 69. Qe7+ Kg8 70. Qe6+ Kg7 71. Qe7+ Kg8 72. Qe6+ Kg7 73. Qe7+\nKg8 74. Qe6+ Kg7 75. Qe7+ Kg8 76. Qe6+ Kg7 77. Qe7+ Kg8 78. Qe6+ Kg7 79. Qe7+\nKg8 80. Qe6+ Kg7 81. Qe7+ Kg8 82. Qe6+ Kg7 83. Qe7+ Kg8 84. Qe6+",
          "aggressive_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rc8",
            "Qc2",
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Qd3",
            "f6",
            "Ng4",
            "Qd7",
            "Ne3",
            "f5",
            "a3",
            "Kh8",
            "Ba2",
            "Nxc3",
            "Rxc3",
            "Rxc3",
            "bxc3",
            "g6",
            "c4",
            "dxc4",
            "Bxc4",
            "Re4",
            "d5",
            "Qd6",
            "g3",
            "Nd7",
            "Rd1",
            "Nf6",
            "Qc3",
            "Kh7",
            "Rd4",
            "Re7",
            "Qd3",
            "Qc5",
            "Kf1",
            "b5",
            "Bxb5",
            "Rxe3",
            "Qxe3",
            "Qxb5+",
            "Kg1",
            "Qb1+",
            "Kg2",
            "Qc2+",
            "Kh3",
            "Qc5",
            "Qe5",
            "Kg7",
            "d6",
            "Qc6",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb1",
          "positional_uci": "d3b1",
          "positional_response": "12. Bb1 Re8 13. Qc2 Nf8 14. Ne5 Rc8 15. Qf5 cxd4 16. exd4 Rc7 17. Nb5 Rxc1 18.\nRxc1 Bc8 19. Qf3 a6 20. Nc7 Ne6 21. Nxe8 Qxe8 22. Qd3 g6 23. Qf3 Kg7 24. Bxf6+\nBxf6 25. Qxd5 Nf4 26. Qe4 Bg5 27. Rc7 Be6 28. g3 Bd5 29. Qc2 Nh3+ 30. Kf1 Qb5+\n31. Qd3 Qxb2 32. Qxg6+ Kf8 33. Rxf7+ Ke8 34. Qg8#",
          "positional_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 195,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Qc2",
            "Nf8",
            "Ne5",
            "Rc8",
            "Qf5",
            "cxd4",
            "exd4",
            "Rc7",
            "Nb5",
            "Rxc1",
            "Rxc1",
            "Bc8",
            "Qf3",
            "a6",
            "Nc7",
            "Ne6",
            "Nxe8",
            "Qxe8",
            "Qd3",
            "g6",
            "Qf3",
            "Kg7",
            "Bxf6+",
            "Bxf6",
            "Qxd5",
            "Nf4",
            "Qe4",
            "Bg5",
            "Rc7",
            "Be6",
            "g3",
            "Bd5",
            "Qc2",
            "Nh3+",
            "Kf1",
            "Qb5+",
            "Qd3",
            "Qxb2",
            "Qxg6+",
            "Kf8",
            "Rxf7+",
            "Ke8",
            "Qg8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb1",
          "neutral_uci": "d3b1",
          "neutral_response": "12. Bb1 Re8 13. Qc2 Nf8 14. Ne5 Rc8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18. Qd3 f6 19. Ng4 Qd7 20. Ne3 f5 21. a3 Kh8 22. Ba2 Nxc3 23. Rxc3 Rxc3 24. Qxc3 Ne6 25. Nxf5 Rf8 26. Bb1 Ba6 27. Rf2 Qa4 28. b3 Qxa3 29. Ra2 Rc8 30. Qxc8+ Bxc8 31. Rxa3 Nxf4 32. Rxa7 Bxf5 33. Bxf5 Ne2+ 34. Kf2 Nxd4 35. Ra8# Nf3 Nf6 Nxf6",
          "neutral_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 206,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba6",
            "Rf2",
            "Qa4",
            "b3",
            "Qxa3",
            "Ra2",
            "Rc8",
            "Qxc8+",
            "Bxc8",
            "Rxa3",
            "Nxf4",
            "Rxa7",
            "Bxf5",
            "Bxf5",
            "Ne2+",
            "Kf2",
            "Nxd4",
            "Ra8#",
            "Nf3",
            "Nf6",
            "Nxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3b1",
          "positional_uci": "d3b1",
          "neutral_uci": "d3b1",
          "consensus_move": "d3b1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rc8",
              "Qc2",
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Qd3",
              "f6",
              "Ng4",
              "Qd7",
              "Ne3",
              "f5",
              "a3",
              "Kh8",
              "Ba2",
              "Nxc3",
              "Rxc3",
              "Rxc3",
              "bxc3",
              "g6",
              "c4",
              "dxc4",
              "Bxc4",
              "Re4",
              "d5",
              "Qd6",
              "g3",
              "Nd7",
              "Rd1",
              "Nf6",
              "Qc3",
              "Kh7",
              "Rd4",
              "Re7",
              "Qd3",
              "Qc5",
              "Kf1",
              "b5",
              "Bxb5",
              "Rxe3",
              "Qxe3",
              "Qxb5+",
              "Kg1",
              "Qb1+",
              "Kg2",
              "Qc2+",
              "Kh3",
              "Qc5",
              "Qe5",
              "Kg7",
              "d6",
              "Qc6",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Qc2",
              "Nf8",
              "Ne5",
              "Rc8",
              "Qf5",
              "cxd4",
              "exd4",
              "Rc7",
              "Nb5",
              "Rxc1",
              "Rxc1",
              "Bc8",
              "Qf3",
              "a6",
              "Nc7",
              "Ne6",
              "Nxe8",
              "Qxe8",
              "Qd3",
              "g6",
              "Qf3",
              "Kg7",
              "Bxf6+",
              "Bxf6",
              "Qxd5",
              "Nf4",
              "Qe4",
              "Bg5",
              "Rc7",
              "Be6",
              "g3",
              "Bd5",
              "Qc2",
              "Nh3+",
              "Kf1",
              "Qb5+",
              "Qd3",
              "Qxb2",
              "Qxg6+",
              "Kf8",
              "Rxf7+",
              "Ke8",
              "Qg8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ba6",
              "Rf2",
              "Qa4",
              "b3",
              "Qxa3",
              "Ra2",
              "Rc8",
              "Qxc8+",
              "Bxc8",
              "Rxa3",
              "Nxf4",
              "Rxa7",
              "Bxf5",
              "Bxf5",
              "Ne2+",
              "Kf2",
              "Nxd4",
              "Ra8#",
              "Nf3",
              "Nf6",
              "Nxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 195,
            "completion_tokens": 195,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 194,
            "completion_tokens": 206,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 584,
          "total_completion_tokens": 1041,
          "total_tokens": 1625
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 195,
            "completion_tokens": 195,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 194,
            "completion_tokens": 206,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2NBPN2/PP3PPP/2RQ1RK1 w - - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qd3",
          "aggressive_uci": "d1d3",
          "aggressive_response": "13. Qd3 Re8 14. Ne5 Nf8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18. f5 f6 19. Ng4 Qb4 20. Rc2 Rc4 21. Rd1 Rec8 22. a3 Qb3 23. Ba2 Rxc3 24. Bxb3 Rxd3 25. Rxd3 Rxc2 26. Bxc2 Nd6 27. Ne3 Nd7 28. Rc3 Nb5 29. Rd3 Nd6 30. Bb3 Kf8 31. Bxd5 Ba6 32. Rc3 Nb5 33. Rc4 Nd6 34. Ra4 Nb8 35. Be6 Nc6 36. d5 Bb5 37. Rh4 Ne5 38. a4 Bd3 39. Rd4 Be4 40. b4 Ke7 41. a5 bxa5 42. bxa5 a6 43. Rb4 Bd3 44. Rb8 Bb5 45. Rg8 Ne8 46. Nc2 Nc4 47. Nd4 Nxa5 48. Nxb5 axb5 49. d6+ Nxd6 50. Rxg7+ Kf8 51. Rd7 Nac4 52. Bxc4 Nxc4 53. Rb7 Nd6 54. Rb6 Ke7 55. g4 Kd7 56. Kf2 Kc7 57. Ra6 b4 58. Ke3 b3 59. Kd3 b2 60. Kc2 Nc4 61. Rxf6 Ne3+ 62. Kxb2 Nxg4 63. Rg6 Ne3 64. f6 Kd7 65. Rxh6 Ke6 66. Kc3 Ng4 67. Rh4 Nxf6 68. Kd4 Kf5 69. Rh8 Kg6 70. Ke5 Ng4+ 71. Kf4 Nf6 72. Ra8 Nh5+ 73. Kg4 Nf6+ 74. Kh4 Kh6 75. Ra6 Kg6 76. h3 Kf5 77. Ra5+ Kg6 78. Rg5+ Kh6 79. Rg1 Nh7 80. Kg4 Nf6+ 81. Kf5 Nh5 82. Rg6+ Kh7 83. Kg5 Ng7 84. Ra6 Kg8 85. Kg6 Ne8 86. Ra8 Kf8 87. h4 Ke7 88. Rxe8+ Kxe8 89. Kg7 Ke7 90. h5 Ke6 91. h6 Kf5 92. h7 Kg5 93",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "f5",
            "f6",
            "Ng4",
            "Qb4",
            "Rc2",
            "Rc4",
            "Rd1",
            "Rec8",
            "a3",
            "Qb3",
            "Ba2",
            "Rxc3",
            "Bxb3",
            "Rxd3",
            "Rxd3",
            "Rxc2",
            "Bxc2",
            "Nd6",
            "Ne3",
            "Nd7",
            "Rc3",
            "Nb5",
            "Rd3",
            "Nd6",
            "Bb3",
            "Kf8",
            "Bxd5",
            "Ba6",
            "Rc3",
            "Nb5",
            "Rc4",
            "Nd6",
            "Ra4",
            "Nb8",
            "Be6",
            "Nc6",
            "d5",
            "Bb5",
            "Rh4",
            "Ne5",
            "a4",
            "Bd3",
            "Rd4",
            "Be4",
            "b4",
            "Ke7",
            "a5",
            "bxa5",
            "bxa5",
            "a6",
            "Rb4",
            "Bd3",
            "Rb8",
            "Bb5",
            "Rg8",
            "Ne8",
            "Nc2",
            "Nc4",
            "Nd4",
            "Nxa5",
            "Nxb5",
            "axb5",
            "d6+",
            "Nxd6",
            "Rxg7+",
            "Kf8",
            "Rd7",
            "Nac4",
            "Bxc4",
            "Nxc4",
            "Rb7",
            "Nd6",
            "Rb6",
            "Ke7",
            "g4",
            "Kd7",
            "Kf2",
            "Kc7",
            "Ra6",
            "b4",
            "Ke3",
            "b3",
            "Kd3",
            "b2",
            "Kc2",
            "Nc4",
            "Rxf6",
            "Ne3+",
            "Kxb2",
            "Nxg4",
            "Rg6",
            "Ne3",
            "f6",
            "Kd7",
            "Rxh6",
            "Ke6",
            "Kc3",
            "Ng4",
            "Rh4",
            "Nxf6",
            "Kd4",
            "Kf5",
            "Rh8",
            "Kg6",
            "Ke5",
            "Ng4+",
            "Kf4",
            "Nf6",
            "Ra8",
            "Nh5+",
            "Kg4",
            "Nf6+",
            "Kh4",
            "Kh6",
            "Ra6",
            "Kg6",
            "h3",
            "Kf5",
            "Ra5+",
            "Kg6",
            "Rg5+",
            "Kh6",
            "Rg1",
            "Nh7",
            "Kg4",
            "Nf6+",
            "Kf5",
            "Nh5",
            "Rg6+",
            "Kh7",
            "Kg5",
            "Ng7",
            "Ra6",
            "Kg8",
            "Kg6",
            "Ne8",
            "Ra8",
            "Kf8",
            "h4",
            "Ke7",
            "Rxe8+",
            "Kxe8",
            "Kg7",
            "Ke7",
            "h5",
            "Ke6",
            "h6",
            "Kf5",
            "h7",
            "Kg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd3",
          "positional_uci": "d1d3",
          "positional_response": "13. Qd3 Re8 14. Ne5 Nf8 15. f4 c4 16. Qc2 a6 17. Rf3 b5 18. Rg3 b4 19. Ne2 Ne4 20. Bxe7 Qxe7 21. Rh3 f6 22. Ng4 Qe6 23. Nf2 Nxf2 24. Kxf2 Rc7 25. Rg1 Rce7 26. g4 Bc8 27. Rhg3 Qf7 28. h4 Re4 29. Qd2 R4e7 30. g5 fxg5 31. hxg5 hxg5 32. Rxg5 Qe6 33. R1g3 Qh6 34. Ng1 Qh2+ 35. Rg2 Qh4+ 36. R5g3 Rxe3 37. Nf3 Qxf4 38. Rxg7+ Kh8 39. Rg8# d4 d3 Qd8#",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 236,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "c4",
            "Qc2",
            "a6",
            "Rf3",
            "b5",
            "Rg3",
            "b4",
            "Ne2",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Rh3",
            "f6",
            "Ng4",
            "Qe6",
            "Nf2",
            "Nxf2",
            "Kxf2",
            "Rc7",
            "Rg1",
            "Rce7",
            "g4",
            "Bc8",
            "Rhg3",
            "Qf7",
            "h4",
            "Re4",
            "Qd2",
            "R4e7",
            "g5",
            "fxg5",
            "hxg5",
            "hxg5",
            "Rxg5",
            "Qe6",
            "R1g3",
            "Qh6",
            "Ng1",
            "Qh2+",
            "Rg2",
            "Qh4+",
            "R5g3",
            "Rxe3",
            "Nf3",
            "Qxf4",
            "Rxg7+",
            "Kh8",
            "Rg8#",
            "d4",
            "d3",
            "Qd8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qc2",
          "neutral_uci": "d1c2",
          "neutral_response": "13. Qc2 Re8 14. Ne5 Nf8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18. Qd3 f6 19. Ng4 Qd7 20. Ne3 f5 21. a3 Ne6 22. Ba2 Nxc3 23. Rxc3 Rxc3 24. bxc3 g6 25. g4 fxg4 26. Nxg4 Kg7 27. Ne5 Qe7 28. Qxg6+ Kf8 29. Qxh6+ Qg7+ 30. Qxg7+ Kxg7 31. f5 Ng5 32. f6+ Kf8 33. f7 Re6 34. Nd7+ Ke7 35. f8=Q+ Kxd7 36. Qg7+ Kc6 37. Qxg5 Kb5 38. Bxd5 Bxd5 39. Qxd5+ Ka4 40. Qxe6 Kxa3 41. Rb1 a5 42. Qb3# Bb7 cxb7 43. Qxb7 a4 44. Qxb6 Ka2 45. Qb2#",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 287,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Qd3",
            "f6",
            "Ng4",
            "Qd7",
            "Ne3",
            "f5",
            "a3",
            "Ne6",
            "Ba2",
            "Nxc3",
            "Rxc3",
            "Rxc3",
            "bxc3",
            "g6",
            "g4",
            "fxg4",
            "Nxg4",
            "Kg7",
            "Ne5",
            "Qe7",
            "Qxg6+",
            "Kf8",
            "Qxh6+",
            "Qg7+",
            "Qxg7+",
            "Kxg7",
            "f5",
            "Ng5",
            "f6+",
            "Kf8",
            "f7",
            "Re6",
            "Nd7+",
            "Ke7",
            "f8=Q+",
            "Kxd7",
            "Qg7+",
            "Kc6",
            "Qxg5",
            "Kb5",
            "Bxd5",
            "Bxd5",
            "Qxd5+",
            "Ka4",
            "Qxe6",
            "Kxa3",
            "Rb1",
            "a5",
            "Qb3#",
            "Bb7",
            "cxb7",
            "Qxb7",
            "a4",
            "Qxb6",
            "Ka2",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1d3",
          "positional_uci": "d1d3",
          "neutral_uci": "d1c2",
          "consensus_move": "d1d3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "f5",
              "f6",
              "Ng4",
              "Qb4",
              "Rc2",
              "Rc4",
              "Rd1",
              "Rec8",
              "a3",
              "Qb3",
              "Ba2",
              "Rxc3",
              "Bxb3",
              "Rxd3",
              "Rxd3",
              "Rxc2",
              "Bxc2",
              "Nd6",
              "Ne3",
              "Nd7",
              "Rc3",
              "Nb5",
              "Rd3",
              "Nd6",
              "Bb3",
              "Kf8",
              "Bxd5",
              "Ba6",
              "Rc3",
              "Nb5",
              "Rc4",
              "Nd6",
              "Ra4",
              "Nb8",
              "Be6",
              "Nc6",
              "d5",
              "Bb5",
              "Rh4",
              "Ne5",
              "a4",
              "Bd3",
              "Rd4",
              "Be4",
              "b4",
              "Ke7",
              "a5",
              "bxa5",
              "bxa5",
              "a6",
              "Rb4",
              "Bd3",
              "Rb8",
              "Bb5",
              "Rg8",
              "Ne8",
              "Nc2",
              "Nc4",
              "Nd4",
              "Nxa5",
              "Nxb5",
              "axb5",
              "d6+",
              "Nxd6",
              "Rxg7+",
              "Kf8",
              "Rd7",
              "Nac4",
              "Bxc4",
              "Nxc4",
              "Rb7",
              "Nd6",
              "Rb6",
              "Ke7",
              "g4",
              "Kd7",
              "Kf2",
              "Kc7",
              "Ra6",
              "b4",
              "Ke3",
              "b3",
              "Kd3",
              "b2",
              "Kc2",
              "Nc4",
              "Rxf6",
              "Ne3+",
              "Kxb2",
              "Nxg4",
              "Rg6",
              "Ne3",
              "f6",
              "Kd7",
              "Rxh6",
              "Ke6",
              "Kc3",
              "Ng4",
              "Rh4",
              "Nxf6",
              "Kd4",
              "Kf5",
              "Rh8",
              "Kg6",
              "Ke5",
              "Ng4+",
              "Kf4",
              "Nf6",
              "Ra8",
              "Nh5+",
              "Kg4",
              "Nf6+",
              "Kh4",
              "Kh6",
              "Ra6",
              "Kg6",
              "h3",
              "Kf5",
              "Ra5+",
              "Kg6",
              "Rg5+",
              "Kh6",
              "Rg1",
              "Nh7",
              "Kg4",
              "Nf6+",
              "Kf5",
              "Nh5",
              "Rg6+",
              "Kh7",
              "Kg5",
              "Ng7",
              "Ra6",
              "Kg8",
              "Kg6",
              "Ne8",
              "Ra8",
              "Kf8",
              "h4",
              "Ke7",
              "Rxe8+",
              "Kxe8",
              "Kg7",
              "Ke7",
              "h5",
              "Ke6",
              "h6",
              "Kf5",
              "h7",
              "Kg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "c4",
              "Qc2",
              "a6",
              "Rf3",
              "b5",
              "Rg3",
              "b4",
              "Ne2",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Rh3",
              "f6",
              "Ng4",
              "Qe6",
              "Nf2",
              "Nxf2",
              "Kxf2",
              "Rc7",
              "Rg1",
              "Rce7",
              "g4",
              "Bc8",
              "Rhg3",
              "Qf7",
              "h4",
              "Re4",
              "Qd2",
              "R4e7",
              "g5",
              "fxg5",
              "hxg5",
              "hxg5",
              "Rxg5",
              "Qe6",
              "R1g3",
              "Qh6",
              "Ng1",
              "Qh2+",
              "Rg2",
              "Qh4+",
              "R5g3",
              "Rxe3",
              "Nf3",
              "Qxf4",
              "Rxg7+",
              "Kh8",
              "Rg8#",
              "d4",
              "d3",
              "Qd8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Qd3",
              "f6",
              "Ng4",
              "Qd7",
              "Ne3",
              "f5",
              "a3",
              "Ne6",
              "Ba2",
              "Nxc3",
              "Rxc3",
              "Rxc3",
              "bxc3",
              "g6",
              "g4",
              "fxg4",
              "Nxg4",
              "Kg7",
              "Ne5",
              "Qe7",
              "Qxg6+",
              "Kf8",
              "Qxh6+",
              "Qg7+",
              "Qxg7+",
              "Kxg7",
              "f5",
              "Ng5",
              "f6+",
              "Kf8",
              "f7",
              "Re6",
              "Nd7+",
              "Ke7",
              "f8=Q+",
              "Kxd7",
              "Qg7+",
              "Kc6",
              "Qxg5",
              "Kb5",
              "Bxd5",
              "Bxd5",
              "Qxd5+",
              "Ka4",
              "Qxe6",
              "Kxa3",
              "Rb1",
              "a5",
              "Qb3#",
              "Bb7",
              "cxb7",
              "Qxb7",
              "a4",
              "Qxb6",
              "Ka2",
              "Qb2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 236,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 287,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 1163,
          "total_tokens": 1771
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 236,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 287,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2rq1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2N1PN2/PP3PPP/1BRQ1RK1 w - - 2 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne5",
          "aggressive_uci": "f3e5",
          "aggressive_response": "14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3\nBe7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5\nexd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3\nBe7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5\nexd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6.",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe5",
            "dxe5",
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne5",
          "positional_uci": "f3e5",
          "positional_response": "14. Ne5 Nxe5 15. dxe5 Ne4 16. Bxe7 Qxe7 17. Nxd5 Bxd5 18. Qxd5 Ng5 19. f4 Rfd8 20. Qc4 Ne6 21. Qe4 g6 22. f5 Ng5 23. Qf4 Rd2 24. fxg6 fxg6 25. Bxg6 Rf8 26. Qc4+ Kg7 27. Rxf8 Qxf8 28. Rf1 Qe7 29. Qc3 Rd8 30. Bc2 Ne6 31. Rf6 Nf8 32. e4 Nh7 33. Qg3+ Kh8 34. Rxh6 Rg8 35. Qh3 Rg7 36. e6 Kg8 37. e5 Qg5 38. Bxh7+ Kf8 39. Rf6+ Ke7 40. Rf7+ Rxf7 41. exf7 Qc1+ 42. Kf2 Qxb2+ 43. Kg3 Qxe5+ 44. Kh4 Qf6+ 45. Kg3 Qe5+ 46. Kf2 Qf6+ 47. Qf3 Qd4+ 48. Kg3 Qg7+ 49. Kh3 Qxh7+ 50. Kg3 Qg7+ 51. Kh3 Qh6+ 52. Kg3 Qg5+ 53. Kh3 Qh6+ 54. Kg3 Qg5+ 55. Kh3 Qh6+ 56. Kg3 Qg5+ 57. Kh3 Qh6+ 58. Kg3 Qg5+ 59. Kh3 Qh6+ 60. Kg3 Qg5+ 61. Kh3 Qh6+ 62. Kg3 Qg5+ 63. Kh3 Qh6+ 64. Kg3 Qg5+ 65. Kh3 Qh6+ 66. Kg3 Qg5+ 67. Kh3 Qh6+ 68. Kg3 Qg5+ 69. Kh3 Qh6+ 70. Kg3 Qg5+ 71. Kh3 Qh6+ 72. Kg3 Qg5+ 73. Kh3 Qh6+ 74. Kg3 Qg5+ 75. Kh3 Qh6+ 76. Kg3 Qg5+ 77. Kh3 Qh6+ 78. Kg3 Qg5+ 79. Kh3 Qh6+ 80. Kg3 Qg5+ 81. Kh3 Qh6+ 82. Kg3 Qg5+ 83. Kh3 Qh6+ 84. Kg3 Qg5+ 85. Kh3 Qh6",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe5",
            "dxe5",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "Qxd5",
            "Ng5",
            "f4",
            "Rfd8",
            "Qc4",
            "Ne6",
            "Qe4",
            "g6",
            "f5",
            "Ng5",
            "Qf4",
            "Rd2",
            "fxg6",
            "fxg6",
            "Bxg6",
            "Rf8",
            "Qc4+",
            "Kg7",
            "Rxf8",
            "Qxf8",
            "Rf1",
            "Qe7",
            "Qc3",
            "Rd8",
            "Bc2",
            "Ne6",
            "Rf6",
            "Nf8",
            "e4",
            "Nh7",
            "Qg3+",
            "Kh8",
            "Rxh6",
            "Rg8",
            "Qh3",
            "Rg7",
            "e6",
            "Kg8",
            "e5",
            "Qg5",
            "Bxh7+",
            "Kf8",
            "Rf6+",
            "Ke7",
            "Rf7+",
            "Rxf7",
            "exf7",
            "Qc1+",
            "Kf2",
            "Qxb2+",
            "Kg3",
            "Qxe5+",
            "Kh4",
            "Qf6+",
            "Kg3",
            "Qe5+",
            "Kf2",
            "Qf6+",
            "Qf3",
            "Qd4+",
            "Kg3",
            "Qg7+",
            "Kh3",
            "Qxh7+",
            "Kg3",
            "Qg7+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne5",
          "neutral_uci": "f3e5",
          "neutral_response": "14. Ne5 Nxe5 15. dxe5 Ne4 16. Bxe7 Qxe7 17. Nxd5 Bxd5 18. Qxd5 Ng5 19. f4 Ne6 20. Qe4 g6 21. f5 Ng5 22. Qf4 Rce8 23. h4 Nh7 24. Qxh6 Qxe5 25. fxg6 fxg6 26. Qxg6+ Qg7 27. Rxf8+ Rxf8 28. Qxg7+ Kxg7 29. Bxh7 Kxh7 30. Rf1 Re8 31. Rf7+ Kg6 32. Rxa7 Rxe3 33. Rb7 Re6 34. g4 Re4 35. Rxb6+ Kg7 36. Kf2 Rxg4 37. h5 Rh4 38. h6+ Kh7 39. Ke3 Rh2 40. Kd3 Rh4 41. Kc3 Rg4 42. b3 Rh4 43. a4 Rg4 44. a5 Rg1 45. a6 Ra1 46. Kc4 Ra5 47. Rc6 Kh8 48. Rxc5 Rxa6 49. Rh5 Kh7 50. b4 Ra1 51. b5 Rc1+ 52. Kd5 Rd1+ 53. Kc6 Rc1+ 54. Kb7 Rb1 55. b6 Rb2 56. Kc7 Rc2+ 57. Kb8 Rb2 58. b7 Rb1 59. Rc5 Kxh6 60. Kc7 1-0 61. b8=Q Rxb8 62. Kxb8 Kg6 63. Kc7 Kf6 64. Kd6 Kf7 65. Re5 Kf6 66. Kd5 Kf7 67. Re6 Kg7 68. Ke5 Kf7 69. Kf5 Kg7 70. Rf6 Kh7 71. Rg6 Kh8 72. Kf6 Kh7 73. Kf7 Kh8 74. Rh6# 1-0 Qc7 Qc7 Qc7",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 522,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe5",
            "dxe5",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "Qxd5",
            "Ng5",
            "f4",
            "Ne6",
            "Qe4",
            "g6",
            "f5",
            "Ng5",
            "Qf4",
            "Rce8",
            "h4",
            "Nh7",
            "Qxh6",
            "Qxe5",
            "fxg6",
            "fxg6",
            "Qxg6+",
            "Qg7",
            "Rxf8+",
            "Rxf8",
            "Qxg7+",
            "Kxg7",
            "Bxh7",
            "Kxh7",
            "Rf1",
            "Re8",
            "Rf7+",
            "Kg6",
            "Rxa7",
            "Rxe3",
            "Rb7",
            "Re6",
            "g4",
            "Re4",
            "Rxb6+",
            "Kg7",
            "Kf2",
            "Rxg4",
            "h5",
            "Rh4",
            "h6+",
            "Kh7",
            "Ke3",
            "Rh2",
            "Kd3",
            "Rh4",
            "Kc3",
            "Rg4",
            "b3",
            "Rh4",
            "a4",
            "Rg4",
            "a5",
            "Rg1",
            "a6",
            "Ra1",
            "Kc4",
            "Ra5",
            "Rc6",
            "Kh8",
            "Rxc5",
            "Rxa6",
            "Rh5",
            "Kh7",
            "b4",
            "Ra1",
            "b5",
            "Rc1+",
            "Kd5",
            "Rd1+",
            "Kc6",
            "Rc1+",
            "Kb7",
            "Rb1",
            "b6",
            "Rb2",
            "Kc7",
            "Rc2+",
            "Kb8",
            "Rb2",
            "b7",
            "Rb1",
            "Rc5",
            "Kxh6",
            "Kc7",
            "b8=Q",
            "Rxb8",
            "Kxb8",
            "Kg6",
            "Kc7",
            "Kf6",
            "Kd6",
            "Kf7",
            "Re5",
            "Kf6",
            "Kd5",
            "Kf7",
            "Re6",
            "Kg7",
            "Ke5",
            "Kf7",
            "Kf5",
            "Kg7",
            "Rf6",
            "Kh7",
            "Rg6",
            "Kh8",
            "Kf6",
            "Kh7",
            "Kf7",
            "Kh8",
            "Rh6#",
            "Qc7",
            "Qc7",
            "Qc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3e5",
          "positional_uci": "f3e5",
          "neutral_uci": "f3e5",
          "consensus_move": "f3e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxe5",
              "dxe5",
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxe5",
              "dxe5",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "Qxd5",
              "Ng5",
              "f4",
              "Rfd8",
              "Qc4",
              "Ne6",
              "Qe4",
              "g6",
              "f5",
              "Ng5",
              "Qf4",
              "Rd2",
              "fxg6",
              "fxg6",
              "Bxg6",
              "Rf8",
              "Qc4+",
              "Kg7",
              "Rxf8",
              "Qxf8",
              "Rf1",
              "Qe7",
              "Qc3",
              "Rd8",
              "Bc2",
              "Ne6",
              "Rf6",
              "Nf8",
              "e4",
              "Nh7",
              "Qg3+",
              "Kh8",
              "Rxh6",
              "Rg8",
              "Qh3",
              "Rg7",
              "e6",
              "Kg8",
              "e5",
              "Qg5",
              "Bxh7+",
              "Kf8",
              "Rf6+",
              "Ke7",
              "Rf7+",
              "Rxf7",
              "exf7",
              "Qc1+",
              "Kf2",
              "Qxb2+",
              "Kg3",
              "Qxe5+",
              "Kh4",
              "Qf6+",
              "Kg3",
              "Qe5+",
              "Kf2",
              "Qf6+",
              "Qf3",
              "Qd4+",
              "Kg3",
              "Qg7+",
              "Kh3",
              "Qxh7+",
              "Kg3",
              "Qg7+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxe5",
              "dxe5",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "Qxd5",
              "Ng5",
              "f4",
              "Ne6",
              "Qe4",
              "g6",
              "f5",
              "Ng5",
              "Qf4",
              "Rce8",
              "h4",
              "Nh7",
              "Qxh6",
              "Qxe5",
              "fxg6",
              "fxg6",
              "Qxg6+",
              "Qg7",
              "Rxf8+",
              "Rxf8",
              "Qxg7+",
              "Kxg7",
              "Bxh7",
              "Kxh7",
              "Rf1",
              "Re8",
              "Rf7+",
              "Kg6",
              "Rxa7",
              "Rxe3",
              "Rb7",
              "Re6",
              "g4",
              "Re4",
              "Rxb6+",
              "Kg7",
              "Kf2",
              "Rxg4",
              "h5",
              "Rh4",
              "h6+",
              "Kh7",
              "Ke3",
              "Rh2",
              "Kd3",
              "Rh4",
              "Kc3",
              "Rg4",
              "b3",
              "Rh4",
              "a4",
              "Rg4",
              "a5",
              "Rg1",
              "a6",
              "Ra1",
              "Kc4",
              "Ra5",
              "Rc6",
              "Kh8",
              "Rxc5",
              "Rxa6",
              "Rh5",
              "Kh7",
              "b4",
              "Ra1",
              "b5",
              "Rc1+",
              "Kd5",
              "Rd1+",
              "Kc6",
              "Rc1+",
              "Kb7",
              "Rb1",
              "b6",
              "Rb2",
              "Kc7",
              "Rc2+",
              "Kb8",
              "Rb2",
              "b7",
              "Rb1",
              "Rc5",
              "Kxh6",
              "Kc7",
              "b8=Q",
              "Rxb8",
              "Kxb8",
              "Kg6",
              "Kc7",
              "Kf6",
              "Kd6",
              "Kf7",
              "Re5",
              "Kf6",
              "Kd5",
              "Kf7",
              "Re6",
              "Kg7",
              "Ke5",
              "Kf7",
              "Kf5",
              "Kg7",
              "Rf6",
              "Kh7",
              "Rg6",
              "Kh8",
              "Kf6",
              "Kh7",
              "Kf7",
              "Kh8",
              "Rh6#",
              "Qc7",
              "Qc7",
              "Qc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 522,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 1802,
          "total_tokens": 2437
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 522,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pbqnbpp1/1p3n1p/2pp4/3P3B/2NQPN2/PP3PPP/1BR2RK1 w - - 4 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxe5",
          "aggressive_uci": "d4e5",
          "aggressive_response": "15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 17. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7#",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxe5",
          "positional_uci": "d4e5",
          "positional_response": "15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxe5",
          "neutral_uci": "d4e5",
          "neutral_response": "15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 640,
            "total_tokens": 859,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4e5",
          "positional_uci": "d4e5",
          "neutral_uci": "d4e5",
          "consensus_move": "d4e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 640,
            "total_tokens": 859,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 1920,
          "total_tokens": 2579
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 640,
            "total_tokens": 859,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "2r2rk1/pbq1bpp1/1p3n1p/2ppn3/3P3B/2NQP3/PP3PPP/1BR2RK1 w - - 0 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": "h4f6",
          "aggressive_response": "16. Bxf6 Bxf6 17. Qh7# cxd5 e4 Bxe4 Qh8#",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 28,
            "total_tokens": 257,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh7#",
            "cxd5",
            "e4",
            "Bxe4",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf6",
          "positional_uci": "h4f6",
          "positional_response": "16. Bxf6 Bxf6 17. Qh7# d5 18. Qh8# d4 19. Qh7# d3",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 36,
            "total_tokens": 265,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh7#",
            "d5",
            "Qh8#",
            "d4",
            "Qh7#",
            "d3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "h4f6",
          "neutral_response": "16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1-0",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 304,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4f6",
          "positional_uci": "h4f6",
          "neutral_uci": "h4f6",
          "consensus_move": "h4f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh7#",
              "cxd5",
              "e4",
              "Bxe4",
              "Qh8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qh7#",
              "d5",
              "Qh8#",
              "d4",
              "Qh7#",
              "d3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 28,
            "total_tokens": 257,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 36,
            "total_tokens": 265,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 304,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 368,
          "total_tokens": 1054
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 28,
            "total_tokens": 257,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 36,
            "total_tokens": 265,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 304,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pb2bpp1/1p3n1p/2ppq3/7B/2NQP3/PP3PPP/1BR2RK1 w - - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh7#",
          "aggressive_uci": "d3h7",
          "aggressive_response": "17. Qh7# gxf6 18. Qh7# Kh8 19. Qxh6+ Kg8 20. Qh7# Kh8 21. Qxh6+ Kg8 22. Qh7# Kh8 23. Qxh6+ Kg8 24. Qh7# Kh8 25. Qxh6+ Kg8 26. Qh7# Kh8 27. Qxh6+ Kg8 28. Qh7# Kh8 29. Qxh6+ Kg8 30. Qh7# Kh8 31. Qxh6+ Kg8 32. Qh7# Kh8 33. Qxh6+ Kg8 34. Qh7# Kh8 35. Qxh6+ Kg8 36. Qh7# Kh8 37. Qxh6+ Kg8 38. Qh7# Kh8 39. Qxh6+ Kg8 40. Qh7# Kh8 41. Qxh6+ Kg8 42. Qh7# Kh8 43. Qxh6+ Kg8 44. Qh7# Kh8 45. Qxh6+ Kg8 46. Qh7# Kh8 47. Qxh6+ Kg8 48. Qh7# Kh8 49. Qxh6+ Kg8 50. Qh7# Kh8 51. Qxh6+ Kg8 52. Qh7# Kh8 53. Qxh6+ Kg8 54. Qh7# Kh8 55. Qxh6+ Kg8 56. Qh7# Kh8 57. Qxh6+ Kg8 58. Qh7# Kh8 59. Qxh6+ Kg8 60. Qh7# Kh8 61. Qxh6+ Kg8 62. Qh7# Kh8 63. Qxh6+ Kg8 64. Qh7# Kh8 65. Qxh6+ Kg8 66. Qh7# Kh8 67. Qxh6+ Kg8 68. Qh7# Kh8 69. Qxh6+ Kg8 70. Qh7# Kh8 71. Qxh6+ Kg8 72. Qh7# Kh8 73. Qxh6+ Kg8 74. Qh7# Kh8 75. Qxh6+ Kg8 76. Qh7# Kh8 77. Qxh6+ Kg8 78. Qh7# Kh8 79. Qxh6+ Kg8 80. Qh7# Kh8 81. Qxh6+ Kg8 82. Qh7# Kh8 83. Qxh6+ Kg8 84.",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 640,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh8",
            "Qxh6+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qh7#",
          "positional_uci": "d3h7",
          "positional_response": "17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 gxf6 17. Qh7# 1-0\nd4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 c5 cxd5 exd5 Bb1 Rc8 Qd3 Qc7 Ne5 Nxe5 dxe5 Qxe5 Bxf6 gxf6 Qh7#",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 236,
            "total_tokens": 474,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh7#",
          "neutral_uci": "d3h7",
          "neutral_response": "17. Qh7# gxf6 18. Qh7# Kh8 19. Qxh6+ Kg8 20. Qh7# Kh8 21. Qxh6+ Kg8 22. Qh7# Kh8 23. Qxh6+ Kg8 24. Qh7# Kh8 25. Qxh6+ Kg8 26. Qh7# Kh8 27. Qxh6+ Kg8 28. Qh7# Kh8 29. Qxh6+ Kg8 30. Qh7# Kh8 31. Qxh6+ Kg8 32. Qh7# Kh8 33. Qxh6+ Kg8 34. Qh7# Kh8 35. Qxh6+ Kg8 36. Qh7# Kh8 37. Qxh6+ Kg8 38. Qh7# Kh8 39. Qxh6+ Kg8 40. Qh7# Kh8 41. Qxh6+ Kg8 42. Qh7# Kh8 43. Qxh6+ Kg8 44. Qh7# Kh8 45. Qxh6+ Kg8 46. Qh7# Kh8 47. Qxh6+ Kg8 48. Qh7# Kh8 49. Qxh6+ Kg8 50. Qh7# Kh8 51. Qxh6+ Kg8 52. Qh7# Kh8 53. Qxh6+ Kg8 54. Qh7# Kh8 55. Qxh6+ Kg8 56. Qh7# Kh8 57. Qxh6+ Kg8 58. Qh7# Kh8 59. Qxh6+ Kg8 60. Qh7# Kh8 61. Qxh6+ Kg8 62. Qh7# Kh8 63. Qxh6+ Kg8 64. Qh7# Kh8 65. Qxh6+ Kg8 66. Qh7# Kh8 67. Qxh6+ Kg8 68. Qh7# Kh8 69. Qxh6+ Kg8 70. Qh7# Kh8 71. Qxh6+ Kg8 72. Qh7# Kh8 73. Qxh6+ Kg8 74. Qh7# Kh8 75. Qxh6+ Kg8 76. Qh7# Kh8 77. Qxh6+ Kg8 78. Qh7# Kh8 79. Qxh6+ Kg8 80. Qh7# Kh8 81. Qxh6+ Kg8 82. Qh7# Kh8 83. Qxh6+ Kg8 84.",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh8",
            "Qxh6+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3h7",
          "positional_uci": "d3h7",
          "neutral_uci": "d3h7",
          "consensus_move": "d3h7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kh8",
              "Qxh6+",
              "Kg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kh8",
              "Qxh6+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 640,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 236,
            "total_tokens": 474,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 1516,
          "total_tokens": 2229
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 640,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 236,
            "total_tokens": 474,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "2r2rk1/pb2bp2/1p3p1p/2ppq3/8/2NQP3/PP3PPP/1BR2RK1 w - - 0 17"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5\n11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Qf3 Bg4\n16. Qg2 Qh5 17. Be3 Rae8 18. Nd2 Re6 19. a4 b4 20. c4 Nxe3\n21. Rxe3 Rxe3 22. fxe3 c5 23. Re1 Re8 24. Qc6 Rd8 25. Ne4 Bf3\n26. Bd1 Bxd1 27. Nxd6 Bf3 28. Qc7 Rf8 29. Qxc5 Qh3 30. Re2 Bxe2\n31. Qf5 Bg4 32. Qf4 Be6 33. d5 Bd7 34. c5 Bxa4 35. c6 Bb3\n36. e4 Qh5 37. c7 Qd1+ 38. Kg2 Qc2+ 39. Kh3 Qxc7 40. Nf5 Qxf4\n41. gxf4 Re8 42. d6 Be6 43. Kg3 Bxf5 44. exf5 Rd8 45. Kf3 Rxd6\n46. Ke4 a5 47. Ke5 Rd2 48. b3 a4 49. bxa4 b3 50. a5 b2\n51. a6 b1=Q 52. a7 Qb5+ 53. Ke4 Qd5+ 54. Ke3 Qd3# 1-0\n55. f6 gxf6 56. a8=Q+ Kg7 57. Qf3 Qd4#",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 465,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Qh5",
            "Be3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "b4",
            "c4",
            "Nxe3",
            "Rxe3",
            "Rxe3",
            "fxe3",
            "c5",
            "Re1",
            "Re8",
            "Qc6",
            "Rd8",
            "Ne4",
            "Bf3",
            "Bd1",
            "Bxd1",
            "Nxd6",
            "Bf3",
            "Qc7",
            "Rf8",
            "Qxc5",
            "Qh3",
            "Re2",
            "Bxe2",
            "Qf5",
            "Bg4",
            "Qf4",
            "Be6",
            "d5",
            "Bd7",
            "c5",
            "Bxa4",
            "c6",
            "Bb3",
            "e4",
            "Qh5",
            "c7",
            "Qd1+",
            "Kg2",
            "Qc2+",
            "Kh3",
            "Qxc7",
            "Nf5",
            "Qxf4",
            "gxf4",
            "Re8",
            "d6",
            "Be6",
            "Kg3",
            "Bxf5",
            "exf5",
            "Rd8",
            "Kf3",
            "Rxd6",
            "Ke4",
            "a5",
            "Ke5",
            "Rd2",
            "b3",
            "a4",
            "bxa4",
            "b3",
            "a5",
            "b2",
            "a6",
            "b1=Q",
            "a7",
            "Qb5+",
            "Ke4",
            "Qd5+",
            "Ke3",
            "Qd3#",
            "f6",
            "gxf6",
            "a8=Q+",
            "Kg7",
            "Qf3",
            "Qd4#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Kf7\n39. Bxb5 Bxb5 40. Rxb5 Rc8 41. Rb4 Rc1+ 42. Kh2 Rc2\n43. Kg3 Nc6 44. Rxa4 Rxb2 45. Ra6 Nb4 46. Ra7+ Kg6\n47. Nh4+ Kh6 48. Nf5+ Kg6 49. Rg7+ Kh5 50. Rxh7+ Kg6\n51. Rg7+ Kh5 52. Kf3 Nd3 53. g4# Nxf2 54. Rh7+ Kg6\n55. Rh6+ Kf7 56. Rh7+ Kg6 57. Rg7# Nxe4 58. Kxe4 Rxa2\n59. h4 Ra4+ 60. Kf3 Rf4+ 61. Kg3 Rxf5 62. gxf5+ Kxg7\n63. Kg4 Kh6 64. h5 Kg7 65. Kh4 Kh6 66. Kg4 Kg7\n67. Kh4 Kh6 68. Kg4 Kg7 69. Kh4 Kh6 70. Kg4 Kg7\n71. Kh4 Kh6 72. Kg4 Kg7 73. Kh4 Kh6 74. Kg4 Kg7\n75. Kh4 Kh6 76. Kg4 Kg7 77. Kh4 Kh6 78. Kg4 Kg7\n79. Kh4 Kh6 80. Kg4 Kg7",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Kf7",
            "Bxb5",
            "Bxb5",
            "Rxb5",
            "Rc8",
            "Rb4",
            "Rc1+",
            "Kh2",
            "Rc2",
            "Kg3",
            "Nc6",
            "Rxa4",
            "Rxb2",
            "Ra6",
            "Nb4",
            "Ra7+",
            "Kg6",
            "Nh4+",
            "Kh6",
            "Nf5+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Rxh7+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Kf3",
            "Nd3",
            "g4#",
            "Nxf2",
            "Rh7+",
            "Kg6",
            "Rh6+",
            "Kf7",
            "Rh7+",
            "Kg6",
            "Rg7#",
            "Nxe4",
            "Kxe4",
            "Rxa2",
            "h4",
            "Ra4+",
            "Kf3",
            "Rf4+",
            "Kg3",
            "Rxf5",
            "gxf5+",
            "Kxg7",
            "Kg4",
            "Kh6",
            "h5",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Bb7\n10. d4 Re8 11. Nbd2 Bf8 12. a4 h6\n13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5\n16. d5 Nd7 17. Ra3 f5 18. Rae3 fxe4\n19. Nxe4 Nxd5 20. Ba2 c4 21. Nxd6 Rxe3\n22. Nxb7 Rxe1+ 23. Nxe1 Qe7 24. Qxd5+ Kh8\n25. Nf3 Nf6 26. Qc6 Rb8 27. Na5 Qd8\n28. Bd2 Bb4 29. Bxb4 Qd1+ 30. Kh2 Qxa4\n31. Qd6 Re8 32. Bb1 Qa1 33. Bg6 Rc8\n34. Bc3 Qc1 35. Bxf6 gxf6 36. Qxf6+ Kg8\n37. Qf7+ Kh8 38. Qh7# e5 Nf6 Qf4",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 318,
            "total_tokens": 431,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Qf4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Qh5",
              "Be3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "b4",
              "c4",
              "Nxe3",
              "Rxe3",
              "Rxe3",
              "fxe3",
              "c5",
              "Re1",
              "Re8",
              "Qc6",
              "Rd8",
              "Ne4",
              "Bf3",
              "Bd1",
              "Bxd1",
              "Nxd6",
              "Bf3",
              "Qc7",
              "Rf8",
              "Qxc5",
              "Qh3",
              "Re2",
              "Bxe2",
              "Qf5",
              "Bg4",
              "Qf4",
              "Be6",
              "d5",
              "Bd7",
              "c5",
              "Bxa4",
              "c6",
              "Bb3",
              "e4",
              "Qh5",
              "c7",
              "Qd1+",
              "Kg2",
              "Qc2+",
              "Kh3",
              "Qxc7",
              "Nf5",
              "Qxf4",
              "gxf4",
              "Re8",
              "d6",
              "Be6",
              "Kg3",
              "Bxf5",
              "exf5",
              "Rd8",
              "Kf3",
              "Rxd6",
              "Ke4",
              "a5",
              "Ke5",
              "Rd2",
              "b3",
              "a4",
              "bxa4",
              "b3",
              "a5",
              "b2",
              "a6",
              "b1=Q",
              "a7",
              "Qb5+",
              "Ke4",
              "Qd5+",
              "Ke3",
              "Qd3#",
              "f6",
              "gxf6",
              "a8=Q+",
              "Kg7",
              "Qf3",
              "Qd4#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Kf7",
              "Bxb5",
              "Bxb5",
              "Rxb5",
              "Rc8",
              "Rb4",
              "Rc1+",
              "Kh2",
              "Rc2",
              "Kg3",
              "Nc6",
              "Rxa4",
              "Rxb2",
              "Ra6",
              "Nb4",
              "Ra7+",
              "Kg6",
              "Nh4+",
              "Kh6",
              "Nf5+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Rxh7+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Kf3",
              "Nd3",
              "g4#",
              "Nxf2",
              "Rh7+",
              "Kg6",
              "Rh6+",
              "Kf7",
              "Rh7+",
              "Kg6",
              "Rg7#",
              "Nxe4",
              "Kxe4",
              "Rxa2",
              "h4",
              "Ra4+",
              "Kf3",
              "Rf4+",
              "Kg3",
              "Rxf5",
              "gxf5+",
              "Kxg7",
              "Kg4",
              "Kh6",
              "h5",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Qf4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 465,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 318,
            "total_tokens": 431,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1423,
          "total_tokens": 1764
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 465,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 318,
            "total_tokens": 431,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Bd7 19. Qxd6 Rc8 20. Rad1 Kf7 21. Qxd7+ Kxf6 22. Qxc8 Ne5 23. Qf5+ Ke7 24. Qxe5+ Kf7 25. Rd7+ Kg6 26. Rg7+ Kh6 27. Qg5# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Bg7 Qe6 Nf6+ Qxf6 Bxf6 Bd7 Qxd6 Rc8 Rad1 Kf7 Qxd7+ Kg6 Qf5+ Kg7 Rd7+ Kg8 Qxh7#",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 377,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Bd7",
            "Qxd6",
            "Rc8",
            "Rad1",
            "Kf7",
            "Qxd7+",
            "Kg6",
            "Qf5+",
            "Kg7",
            "Rd7+",
            "Kg8",
            "Qxh7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "Game 1\n1. e4 e5\n2. Nc3 Nc6\n3. Bc4 Bc5\n4. d3 d6\n5. Nge2 Nf6\n6. O-O O-O\n7. Bg5 Bg4\n8. Nd5 Nd4\n9. Re1 Nxe2+\n10. Rxe2 Bxe2\n11. Qxe2 c6\n12. Nxf6+ gxf6\n13. Bh6 Re8\n14. Qg4+ Kh8\n\n15. Qg7# 1-0\n1. e4 e5\n2. Nc3 Nc6\n3. Bc4 Bc5\n4. d3 d6\n5. Nge2 Nf6\n6. O-O O-O\n7. Bg5 Bg4\n8. Nd5 Nd4\n9. Re1 Nxe2+\n10. Rxe2 Bxe2\n11. Qxe2 c6\n12. Nxf6+ gxf6\n13. Bh6 Re8\n14. Qg4+ Kh8\n15. Qg7# 1-0 e4 e5 Nc3 Nc6 Bc4 Bc5 d3 d6 Nge2 Nf6 O-O O-O Bg5 Bg4 Nd5 Nd4 Re1 Nxe2+ Rxe2 Bxe2 Qxe2 c6 Nxf6+ gxf6 Bh6 Re8 Qg4+ Kh8 Qg7#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 334,
            "total_tokens": 444,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nc3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6",
            "Nge2",
            "Nf6",
            "O-O",
            "O-O",
            "Bg5",
            "Bg4",
            "Nd5",
            "Nd4",
            "Re1",
            "Nxe2+",
            "Rxe2",
            "Bxe2",
            "Qxe2",
            "c6",
            "Nxf6+",
            "gxf6",
            "Bh6",
            "Re8",
            "Qg4+",
            "Kh8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 d5 2. Nf3 Nf6 3. Bg5 Bf5 4. e3 e6 5. Bd3 Bxd3 6. Qxd3 Be7\n7. O-O O-O 8. Nbd2 Nbd7 9. c4 c6 10. Rac1 Rc8 11. cxd5 cxd5\n12. Rxc8 Qxc8 13. Nb3 Qc4 14. Qxc4 dxc4 15. Nbd2 b5 16. Rc1 Rc8\n17. Ne5 Nxe5 18. dxe5 Nd5 19. Bxe7 Nxe7 20. Ne4 Nc6 21. Nd6 Rb8\n22. f4 Nb4 23. a3 Nd3 24. Rc2 Kf8 25. Kf1 Ke7 26. Ke2 f6\n27. Ne4 fxe5 28. fxe5 Nxe5 29. Nc5 Rc8 30. Na6 Nd3 31. Nb4 Nxb4\n32. axb4 Kd6 33. Rd2+ Ke5 34. Rd7 a6 35. Rxg7 c3 36. bxc3 Rxc3\n37. Rxh7 Rb3 38. Rh4 Kd5 39. Rd4+ Ke5 40. h4 Kf5 41. g4+ Kg6\n42. Kf3 e5 43. Re4 Kf6 44. g5+ Kf5 45. Rg4 Rb1 46. Rg2 Rxb4\n47. g6 e4+ 48. Kg3 Kxg6 49. Kf4+ Kh5 50. Rg5+ Kxh4 51. Rg6 Kh5\n52. Rxa6 Ra4 53. Rb6 b4 54. Kxe4 b3+ 55. Kd3 Ra3 56. Kc3 b2+\n57. Kxb2 Rxe3 58. Rb5+ Kg4 59. Rb4+ Kf3 60. Rb3 Rxb3+ 61. Kxb3\nRg8 62. Kc4 Ke4 63. Kc5 Rg6 64. Kc4 Rc6+ 65. Kb5 Kd5 66. Kb4\nRc5 67. Kb3 Kd4 68. Kb4 Kd5 69. Kb3 Rc4 70. Kb2 Kd4 71. Kb3 Kd3\n72. Kb2 Rc3 73. Kb1 Rc2 74. Ka1 Kc3 75. Kb1 Kb3 76. Ka1 Rc1#\nd4 d5 2. Nf3 Nf6 3. Bg",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Bg7",
              "Qe6",
              "Nf6+",
              "Qxf6",
              "Bxf6",
              "Bd7",
              "Qxd6",
              "Rc8",
              "Rad1",
              "Kf7",
              "Qxd7+",
              "Kg6",
              "Qf5+",
              "Kg7",
              "Rd7+",
              "Kg8",
              "Qxh7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nc3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6",
              "Nge2",
              "Nf6",
              "O-O",
              "O-O",
              "Bg5",
              "Bg4",
              "Nd5",
              "Nd4",
              "Re1",
              "Nxe2+",
              "Rxe2",
              "Bxe2",
              "Qxe2",
              "c6",
              "Nxf6+",
              "gxf6",
              "Bh6",
              "Re8",
              "Qg4+",
              "Kh8",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf3",
              "Nf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 377,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 334,
            "total_tokens": 444,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1351,
          "total_tokens": 1680
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 377,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 334,
            "total_tokens": 444,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nc6 *\n3. Bb5 a6 *\n4. Ba4 Nf6 *\n5. O-O Be7 *\n6. Re1 b5 *\n7. Bb3 d6 *\n8. c3 O-O *\n9. h3 Na5 *\n10. Bc2 c5 *\n11. d4 Qc7 *\n12. Nbd2 cxd4 *\n13. cxd4 Nc6 *\n14. Nb3 a5 *\n15. Be3 a4 *\n16. Nbd2 Bd7 *\n17. Rc1 Qb7 *\n18. Bb1 Rfc8 *\n19. Nf1 Bd8 *\n20. Ng3 Bb6 *\n21. Qd2 Ba5 *\n22. Qe2 Bxe1 *\n23. Rxe1 exd4 *\n24. Nxd4 Nxd4 *\n25. Bxd4 Ne8 *\n26. Qh5 g6 *\n27. Qh6 Be6 *\n28. Nh5 f6 *\n29. Nxf6+ Nxf6 *\n30. Bxf6 Qf7 *\n31. Bd4 Bxa2 *\n32. Bd3 Bc4 *\n33. Bb1 Re8 *\n34. Re3 Re7 *\n35. Rf3 Qe6 *\n36. Rf6 Qd7 *\n37. e5 dxe5 *\n38. Bc5 Rg7 *\n39. Be4 Re8 *\n40. Bc6 Qd1+ *\n41. Kh2 Rc8 *\n42. Rd6 Qh5 *\n43. Qd2 Rgc7 *\n44. Rd8+ Kg7 *\n45. Bf8+ Kf7 *\n46. Be8+ Kf6 *\n47. Rd6+ Be6 *\n48. Bd7 Rxd7 *\n49. Rxd7 Bxd7 *\n50. Qxd7 Rxf8 *\n51. Qd6+ Kg7 *\n52. Qe7+ Rf7 *\n53. Qe6 Qf5 *\n54. Qd5 Qf4+ *\n55. Kh1 Qxf2 *\n56. Qxe5+ Qf6 *\n57. Qxb5 Qf1+ *\n58. Qxf1 Rxf1+ *\n59. Kh2 Rb1 *\n60. Kg3 Rxb2 *\n61. Kf3 a3 *\n62. Ke3 a2 *\n63. Kd3 a1=Q *\n64. Kc3 Qc1+ *\n65. Kd3 Rd2+ *\n66. Ke3 Qe1+ *\n67. Kf3 Rf2+ *\n68. Kg3 Qe3+ *\n69. Kh2 Q",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "exd4",
            "Nxd4",
            "Nxd4",
            "Bxd4",
            "Ne8",
            "Qh5",
            "g6",
            "Qh6",
            "Be6",
            "Nh5",
            "f6",
            "Nxf6+",
            "Nxf6",
            "Bxf6",
            "Qf7",
            "Bd4",
            "Bxa2",
            "Bd3",
            "Bc4",
            "Bb1",
            "Re8",
            "Re3",
            "Re7",
            "Rf3",
            "Qe6",
            "Rf6",
            "Qd7",
            "e5",
            "dxe5",
            "Bc5",
            "Rg7",
            "Be4",
            "Re8",
            "Bc6",
            "Qd1+",
            "Kh2",
            "Rc8",
            "Rd6",
            "Qh5",
            "Qd2",
            "Rgc7",
            "Rd8+",
            "Kg7",
            "Bf8+",
            "Kf7",
            "Be8+",
            "Kf6",
            "Rd6+",
            "Be6",
            "Bd7",
            "Rxd7",
            "Rxd7",
            "Bxd7",
            "Qxd7",
            "Rxf8",
            "Qd6+",
            "Kg7",
            "Qe7+",
            "Rf7",
            "Qe6",
            "Qf5",
            "Qd5",
            "Qf4+",
            "Kh1",
            "Qxf2",
            "Qxe5+",
            "Qf6",
            "Qxb5",
            "Qf1+",
            "Qxf1",
            "Rxf1+",
            "Kh2",
            "Rb1",
            "Kg3",
            "Rxb2",
            "Kf3",
            "a3",
            "Ke3",
            "a2",
            "Kd3",
            "a1=Q",
            "Kc3",
            "Qc1+",
            "Kd3",
            "Rd2+",
            "Ke3",
            "Qe1+",
            "Kf3",
            "Rf2+",
            "Kg3",
            "Qe3+",
            "Kh2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nc6 *\n3. Bb5 a6 *\n4. Ba4 Nf6 *\n5. O-O Be7 *\n6. Re1 b5 *\n7. Bb3 d6 *\n8. c3 O-O *\n9. h3 Na5 *\n10. Bc2 c5 *\n11. d4 Qc7 *\n12. Nbd2 cxd4 *\n13. cxd4 Nc6 *\n14. Nb3 a5 *\n15. Be3 a4 *\n16. Nbd2 Bd7 *\n17. Rc1 Qb7 *\n18. Bb1 Rfc8 *\n19. Nf1 Bd8 *\n20. Ng3 Bb6 *\n21. Qd2 Ba5 *\n22. Qe2 Bxe1 *\n23. Rxe1 Re8 *\n24. d5 Ne7 *\n25. Nh4 Rac8 *\n26. Bg5 Kh8 *\n27. Bxf6 gxf6 *\n28. Qh5 Rf8 *\n29. Qh6 Ng8 *\n30. Qh5 Ne7 *\n31. Qh6 Ng8 *\n32. Qh5 Ne7 *\n33. Qh6 Ng8 *\n34. Qh5 Ne7 *\n35. Qh6 Ng8 *\n36. Qh5 Ne7 *\n37. Qh6 Ng8 *\n38. Qh5 Ne7 *\n39. Qh6 Ng8 *\n40. Qh5 Ne7 *\n41. Qh6 Ng8 *\n42. Qh5 Ne7 *\n43. Qh6 Ng8 *\n44. Qh5 Ne7 *\n45. Qh6 Ng8 *\n46. Qh5 Ne7 *\n47. Qh6 Ng8 *\n48. Qh5 Ne7 *\n49. Qh6 Ng8 *\n50. Qh5 Ne7 *\n51. Qh6 Ng8 *\n52. Qh5 Ne7 *\n53. Qh6 Ng8 *\n54. Qh5 Ne7 *\n55. Qh6 Ng8 *\n56. Qh5 Ne7 *\n57. Qh6 Ng8 *\n58. Qh5 Ne7 *\n59. Qh6 Ng8 *\n60. Qh5 Ne7 *\n61. Qh6 Ng8 *\n62. Qh5 Ne7 *\n63. Qh6 Ng8 *\n64. Qh5 Ne7 *\n65. Qh6 Ng8 *\n66. Qh5 Ne7 *\n67. Qh6 Ng8 *\n68. Qh5 Ne7 *\n69. Qh6 Ng8 *\n70. Qh5 Ne7 *\n71. Qh6 Ng8 *\n72. Qh5 Ne7 *\n73",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh5",
            "Rf8",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nc6 *\n3. Bb5 a6 *\n4. Ba4 Nf6 *\n5. O-O Be7 *\n6. Re1 b5 *\n7. Bb3 d6 *\n8. c3 O-O *\n9. h3 Na5 *\n10. Bc2 c5 *\n11. d4 Qc7 *\n12. Nbd2 cxd4 *\n13. cxd4 Nc6 *\n14. Nb3 a5 *\n15. Be3 a4 *\n16. Nbd2 Bd7 *\n17. Rc1 Qb7 *\n18. Bb1 Rfc8 *\n19. Nf1 Bd8 *\n20. Ng3 Bb6 *\n21. Qd2 Ba5 *\n22. Qe2 Bxe1 *\n23. Rxe1 Re8 *\n24. Qd2 Rac8 *\n25. Bg5 Kh8 *\n26. Bxf6 gxf6 *\n27. Qh6 Rg8 *\n28. Qxf6+ Rg7 *\n29. Nh5 Rg8 *\n30. Ng5 Be8 *\n31. Nxg7 Rxg7 *\n32. dxe5 dxe5 *\n33. Rd1 Qe7 *\n34. Qxe7 Nxe7 *\n35. Rd8 Rxg5 *\n36. Rxe8+ Ng8 *\n37. Bd3 Kg7 *\n38. Bxb5 Nf6 *\n39. Ra8 Nxe4 *\n40. Rxa4 Nd6 *\n41. Be2 e4 *\n42. Rd4 Rg6 *\n43. a4 f5 *\n44. a5 Nc8 *\n45. a6 Rc6 *\n46. Rc4 Rxc4 *\n47. Bxc4 Kf6 *\n48. b4 Ke7 *\n49. b5 Kd6 *\n50. Bxf7 Kc5 *\n51. Be6 Nb6 *\n52. Bxf5 Kxb5 *\n53. a7 Ka6 *\n54. Bxe4 Kxa7 *\n55. Bxh7 Kb7 *\n56. h4 Kc7 *\n57. h5 Kd7 *\n58. h6 Ke7 *\n59. Bg6 Kf6 *\n60. h7 Kg7 *\n61. f4 Nd5 *\n62. f5 Nf6 *\n63. Kf2 Ng4+ *\n64. Kf3 Nf6 *\n65. Kf4 Nd5+ *\n66. Ke5 Nf6 *\n67. h8=Q+ Kxh8 *\n68. Kxf6 Kg8 *\n69. Ke7 Kg7 *\n70. f6+ Kxg6 *\n71. f7 Kg5 *",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rxg5",
            "Rxe8+",
            "Ng8",
            "Bd3",
            "Kg7",
            "Bxb5",
            "Nf6",
            "Ra8",
            "Nxe4",
            "Rxa4",
            "Nd6",
            "Be2",
            "e4",
            "Rd4",
            "Rg6",
            "a4",
            "f5",
            "a5",
            "Nc8",
            "a6",
            "Rc6",
            "Rc4",
            "Rxc4",
            "Bxc4",
            "Kf6",
            "b4",
            "Ke7",
            "b5",
            "Kd6",
            "Bxf7",
            "Kc5",
            "Be6",
            "Nb6",
            "Bxf5",
            "Kxb5",
            "a7",
            "Ka6",
            "Bxe4",
            "Kxa7",
            "Bxh7",
            "Kb7",
            "h4",
            "Kc7",
            "h5",
            "Kd7",
            "h6",
            "Ke7",
            "Bg6",
            "Kf6",
            "h7",
            "Kg7",
            "f4",
            "Nd5",
            "f5",
            "Nf6",
            "Kf2",
            "Ng4+",
            "Kf3",
            "Nf6",
            "Kf4",
            "Nd5+",
            "Ke5",
            "Nf6",
            "h8=Q+",
            "Kxh8",
            "Kxf6",
            "Kg8",
            "Ke7",
            "Kg7",
            "f6+",
            "Kxg6",
            "f7",
            "Kg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "exd4",
              "Nxd4",
              "Nxd4",
              "Bxd4",
              "Ne8",
              "Qh5",
              "g6",
              "Qh6",
              "Be6",
              "Nh5",
              "f6",
              "Nxf6+",
              "Nxf6",
              "Bxf6",
              "Qf7",
              "Bd4",
              "Bxa2",
              "Bd3",
              "Bc4",
              "Bb1",
              "Re8",
              "Re3",
              "Re7",
              "Rf3",
              "Qe6",
              "Rf6",
              "Qd7",
              "e5",
              "dxe5",
              "Bc5",
              "Rg7",
              "Be4",
              "Re8",
              "Bc6",
              "Qd1+",
              "Kh2",
              "Rc8",
              "Rd6",
              "Qh5",
              "Qd2",
              "Rgc7",
              "Rd8+",
              "Kg7",
              "Bf8+",
              "Kf7",
              "Be8+",
              "Kf6",
              "Rd6+",
              "Be6",
              "Bd7",
              "Rxd7",
              "Rxd7",
              "Bxd7",
              "Qxd7",
              "Rxf8",
              "Qd6+",
              "Kg7",
              "Qe7+",
              "Rf7",
              "Qe6",
              "Qf5",
              "Qd5",
              "Qf4+",
              "Kh1",
              "Qxf2",
              "Qxe5+",
              "Qf6",
              "Qxb5",
              "Qf1+",
              "Qxf1",
              "Rxf1+",
              "Kh2",
              "Rb1",
              "Kg3",
              "Rxb2",
              "Kf3",
              "a3",
              "Ke3",
              "a2",
              "Kd3",
              "a1=Q",
              "Kc3",
              "Qc1+",
              "Kd3",
              "Rd2+",
              "Ke3",
              "Qe1+",
              "Kf3",
              "Rf2+",
              "Kg3",
              "Qe3+",
              "Kh2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "d5",
              "Ne7",
              "Nh4",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh5",
              "Rf8",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rxg5",
              "Rxe8+",
              "Ng8",
              "Bd3",
              "Kg7",
              "Bxb5",
              "Nf6",
              "Ra8",
              "Nxe4",
              "Rxa4",
              "Nd6",
              "Be2",
              "e4",
              "Rd4",
              "Rg6",
              "a4",
              "f5",
              "a5",
              "Nc8",
              "a6",
              "Rc6",
              "Rc4",
              "Rxc4",
              "Bxc4",
              "Kf6",
              "b4",
              "Ke7",
              "b5",
              "Kd6",
              "Bxf7",
              "Kc5",
              "Be6",
              "Nb6",
              "Bxf5",
              "Kxb5",
              "a7",
              "Ka6",
              "Bxe4",
              "Kxa7",
              "Bxh7",
              "Kb7",
              "h4",
              "Kc7",
              "h5",
              "Kd7",
              "h6",
              "Ke7",
              "Bg6",
              "Kf6",
              "h7",
              "Kg7",
              "f4",
              "Nd5",
              "f5",
              "Nf6",
              "Kf2",
              "Ng4+",
              "Kf3",
              "Nf6",
              "Kf4",
              "Nd5+",
              "Ke5",
              "Nf6",
              "h8=Q+",
              "Kxh8",
              "Kxf6",
              "Kg8",
              "Ke7",
              "Kg7",
              "f6+",
              "Kxg6",
              "f7",
              "Kg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1920,
          "total_tokens": 2267
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb5",
          "aggressive_uci": "f1b5",
          "aggressive_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bb8 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qf3 Bg4 26. Qg2 Bh3 27. Qf3 Bg4 28. Qg2 Bh3 29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3 33. Qf3 Bg4 34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3 37. Qf3 Bg4 38. Qg2 Bh3 39. Qf3 Bg4 40. Qg2 Bh3 41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4 44. Qg2 Bh3 45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3 49. Qf3 Bg4 50. Qg2 Bh3 51. Qf3 Bg4 52. Qg2 Bh3 53. Qf3 Bg4 54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3 57. Qf3 Bg4 58. Qg2 Bh3 59. Qf3 Bg4 60. Qg2 Bh3 61. Qf3 Bg4 62. Qg2 Bh3 63. Qf3 Bg4 64. Qg2 Bh3 65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3 69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3 73. Qf3 Bg4 74. Qg2 Bh3 75. Qf3 Bg4 76. Qg2 Bh3 77. Qf3 Bg4 78. Qg2 Bh3 79. Q",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb5",
          "positional_uci": "f1b5",
          "positional_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Ra6 Bf8 24. Rxc6 Bh3 25. Qh1 Rxc6 26. Qxc6 Re6 27. Qf3 Bg4 28. Qa8 g5 29. Ra1 Rh6 30. Qg2 Bh3 31. Qd5 Be6 32. Qxg5+ Qxg5 33. Bxg5 Rg6 34. Be3 b4 35. c4 Bf5 36. Ra8 Kg7 37. d5 Bd6 38. Bd4+ Kh6 39. Ra6 Bf4 40. Rxg6+ hxg6 41. gxf4 Kh5 42. Kg2 Kg4 43. Be3 Bd3 44. c5 Kf5 45. c6 Ba6 46. d6 Ke6 47. d7 Ke7 48. Bc5+ Kd8 49. Bb6+ Ke7 50. d8=Q+ Ke6 51. Qd7+ Kf6 52. Bd4# Bb7 53. cxb7# Kf5 54. Qxf7+ Kg4 55. Qxg6+ Kh4 56. Nf3# Kg4 57. Qg5#",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 455,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Ra6",
            "Bf8",
            "Rxc6",
            "Bh3",
            "Qh1",
            "Rxc6",
            "Qxc6",
            "Re6",
            "Qf3",
            "Bg4",
            "Qa8",
            "g5",
            "Ra1",
            "Rh6",
            "Qg2",
            "Bh3",
            "Qd5",
            "Be6",
            "Qxg5+",
            "Qxg5",
            "Bxg5",
            "Rg6",
            "Be3",
            "b4",
            "c4",
            "Bf5",
            "Ra8",
            "Kg7",
            "d5",
            "Bd6",
            "Bd4+",
            "Kh6",
            "Ra6",
            "Bf4",
            "Rxg6+",
            "hxg6",
            "gxf4",
            "Kh5",
            "Kg2",
            "Kg4",
            "Be3",
            "Bd3",
            "c5",
            "Kf5",
            "c6",
            "Ba6",
            "d6",
            "Ke6",
            "d7",
            "Ke7",
            "Bc5+",
            "Kd8",
            "Bb6+",
            "Ke7",
            "d8=Q+",
            "Ke6",
            "Qd7+",
            "Kf6",
            "Bd4#",
            "Bb7",
            "cxb7#",
            "Kf5",
            "Qxf7+",
            "Kg4",
            "Qxg6+",
            "Kh4",
            "Nf3#",
            "Kg4",
            "Qg5#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb5",
          "neutral_uci": "f1b5",
          "neutral_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 266,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1b5",
          "positional_uci": "f1b5",
          "neutral_uci": "f1b5",
          "consensus_move": "f1b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Ra6",
              "Bf8",
              "Rxc6",
              "Bh3",
              "Qh1",
              "Rxc6",
              "Qxc6",
              "Re6",
              "Qf3",
              "Bg4",
              "Qa8",
              "g5",
              "Ra1",
              "Rh6",
              "Qg2",
              "Bh3",
              "Qd5",
              "Be6",
              "Qxg5+",
              "Qxg5",
              "Bxg5",
              "Rg6",
              "Be3",
              "b4",
              "c4",
              "Bf5",
              "Ra8",
              "Kg7",
              "d5",
              "Bd6",
              "Bd4+",
              "Kh6",
              "Ra6",
              "Bf4",
              "Rxg6+",
              "hxg6",
              "gxf4",
              "Kh5",
              "Kg2",
              "Kg4",
              "Be3",
              "Bd3",
              "c5",
              "Kf5",
              "c6",
              "Ba6",
              "d6",
              "Ke6",
              "d7",
              "Ke7",
              "Bc5+",
              "Kd8",
              "Bb6+",
              "Ke7",
              "d8=Q+",
              "Ke6",
              "Qd7+",
              "Kf6",
              "Bd4#",
              "Bb7",
              "cxb7#",
              "Kf5",
              "Qxf7+",
              "Kg4",
              "Qxg6+",
              "Kh4",
              "Nf3#",
              "Kg4",
              "Qg5#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 455,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 266,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1361,
          "total_tokens": 1735
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 455,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 266,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxc6",
          "aggressive_uci": "b5c6",
          "aggressive_response": "4. Bxc6 dxc6 5. O-O Bg4 6. h3 h5 7. d3 Qf6 8. Nbd2 Ne7 9. Re1 Ng6 10. hxg4 hxg4 11. Nh2 Rxh2 12. Kxh2 Qh4+ 13. Kg1 Bc5 14. d4 Bxd4 15. Re3 O-O-O 16. Qe1 Rh8 17. Kf1 Nf4 18. Rh3 gxh3 19. g3 h2 20. gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re3 O-O-O Qe1 Rh8 Kf1 Nf4 Rh3 gxh3 g3 h2 gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re3 O-O-O Qe1 Rh8 Kf1 Nf4 Rh3 gxh3 g3 h2 gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re3 O-O-O Qe1 Rh8 Kf1 Nf4 Rh3 gxh3 g3 h2 gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re3 O-O-O Qe1 Rh8 Kf1 Nf4 Rh3 gxh3 g3 h2 gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc6",
            "O-O",
            "Bg4",
            "h3",
            "h5",
            "d3",
            "Qf6",
            "Nbd2",
            "Ne7",
            "Re1",
            "Ng6",
            "hxg4",
            "hxg4",
            "Nh2",
            "Rxh2",
            "Kxh2",
            "Qh4+",
            "Kg1",
            "Bc5",
            "d4",
            "Bxd4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxc6",
          "positional_uci": "b5c6",
          "positional_response": "4. Bxc6 dxc6 5. O-O Bg4 6. h3 h5 7. d3 Qf6 8. Nbd2 Ne7 9. Re1 Ng6 10. d4 O-O-O 11. hxg4 hxg4 12. Nh2 Rxh2 13. Qxg4+ Kb8 14. Kxh2 Qxf2 15. Nf3 Bd6 16. Kh1 Rh8+ 17. Qh3 Rxh3+ 18. gxh3 Qxf3+ 19. Kg1 Nh4 20. Re2 Qxe2 21. Bg5 Qg2# 0-1\n22. Kh1 Qxh3+ 23. Kg1 Qg2#",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 176,
            "total_tokens": 309,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc6",
            "O-O",
            "Bg4",
            "h3",
            "h5",
            "d3",
            "Qf6",
            "Nbd2",
            "Ne7",
            "Re1",
            "Ng6",
            "d4",
            "O-O-O",
            "hxg4",
            "hxg4",
            "Nh2",
            "Rxh2",
            "Qxg4+",
            "Kb8",
            "Kxh2",
            "Qxf2",
            "Nf3",
            "Bd6",
            "Kh1",
            "Rh8+",
            "Qh3",
            "Rxh3+",
            "gxh3",
            "Qxf3+",
            "Kg1",
            "Nh4",
            "Re2",
            "Qxe2",
            "Bg5",
            "Qg2#",
            "Kh1",
            "Qxh3+",
            "Kg1",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxc6",
          "neutral_uci": "b5c6",
          "neutral_response": "4. Bxc6 dxc6 5. O-O Bg4 6. h3 h5 7. d3 Qf6 8. Nbd2 Ne7 9. Re1 Ng6 10. d4 O-O-O 11. hxg4 hxg4 12. Nh2 Rxh2 13. Qxg4+ Kb8 14. Kxh2 Qxf2 15. Nf3 Bd6 16. Kh1 Rh8+ 17. Nh2 Qxe1+ 18. Nf1 Qxf1# 19. Kh2 exd4+ 20. g3 Qf2+ 21. Kh1 Qf1+ 22. Kh2 Ne5 23. Qf5 Nf3+ 24. Qxf3 Qxf3 25. Bf4 Bxf4 26. gxf4 Rxh3+ 27. Kg1 Rh1# 28. Kxh1 Qh3+ 29. Kg1 Qg3+ 30. Kh1 Qxf4 31. Kg1 Qxe4 32. Kh2 Qxc2+ 33. Kh3 Qxb2 34. Kh4 Qxa1 35. Kh5 Qxa2 36. Kg5 Qe6 37. Kh5 Qg6+ 38. Kh4 d3 39. Kh3 d2 40. Kh2 d1=Q 41. Kh3 Qdh5# 42. Kh2 Qhg5 43. Kh3 Qg4+ 44. Kh2 Qg3+ 45. Kh1 Qg2# 46. Kh2 Q6g3# 47. Kh1 Qg4 48. Kh2 Qg5 49. Kh1 Qg6 50. Kh2 Q6g5 51. Kh1 Q5g4 52. Kh2 Qg1# 53. Kh3 Q1g3# 54. Kh1 Qg2# 55. Kh2 Q2g3# 56. Kh1 Qg1# 57. Kh2 Q1g2# 58. Kh1 Qg1# 59. Kh2 Q1g2# 60. Kh1 Qg1# 61. Kh2 Q1g2# 62. Kh1 Qg1# 63. Kh2 Q1g2# 64. Kh1 Qg1# 65. Kh2 Q1g2# 66. Kh1 Qg1# 67. Kh2 Q1g2# 68. Kh1 Qg1# 69. Kh2 Q1g2# 70. Kh1 Qg1# 71. Kh2 Q1g2# 72. Kh1 Qg1# 73. Kh2 Q1g2# 74. Kh1 Qg1# 75. Kh2 Q1g2#",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc6",
            "O-O",
            "Bg4",
            "h3",
            "h5",
            "d3",
            "Qf6",
            "Nbd2",
            "Ne7",
            "Re1",
            "Ng6",
            "d4",
            "O-O-O",
            "hxg4",
            "hxg4",
            "Nh2",
            "Rxh2",
            "Qxg4+",
            "Kb8",
            "Kxh2",
            "Qxf2",
            "Nf3",
            "Bd6",
            "Kh1",
            "Rh8+",
            "Nh2",
            "Qxe1+",
            "Nf1",
            "Qxf1#",
            "Kh2",
            "exd4+",
            "g3",
            "Qf2+",
            "Kh1",
            "Qf1+",
            "Kh2",
            "Ne5",
            "Qf5",
            "Nf3+",
            "Qxf3",
            "Qxf3",
            "Bf4",
            "Bxf4",
            "gxf4",
            "Rxh3+",
            "Kg1",
            "Rh1#",
            "Kxh1",
            "Qh3+",
            "Kg1",
            "Qg3+",
            "Kh1",
            "Qxf4",
            "Kg1",
            "Qxe4",
            "Kh2",
            "Qxc2+",
            "Kh3",
            "Qxb2",
            "Kh4",
            "Qxa1",
            "Kh5",
            "Qxa2",
            "Kg5",
            "Qe6",
            "Kh5",
            "Qg6+",
            "Kh4",
            "d3",
            "Kh3",
            "d2",
            "Kh2",
            "d1=Q",
            "Kh3",
            "Qdh5#",
            "Kh2",
            "Qhg5",
            "Kh3",
            "Qg4+",
            "Kh2",
            "Qg3+",
            "Kh1",
            "Qg2#",
            "Kh2",
            "Q6g3#",
            "Kh1",
            "Qg4",
            "Kh2",
            "Qg5",
            "Kh1",
            "Qg6",
            "Kh2",
            "Q6g5",
            "Kh1",
            "Q5g4",
            "Kh2",
            "Qg1#",
            "Kh3",
            "Q1g3#",
            "Kh1",
            "Qg2#",
            "Kh2",
            "Q2g3#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b5c6",
          "positional_uci": "b5c6",
          "neutral_uci": "b5c6",
          "consensus_move": "b5c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc6",
              "O-O",
              "Bg4",
              "h3",
              "h5",
              "d3",
              "Qf6",
              "Nbd2",
              "Ne7",
              "Re1",
              "Ng6",
              "hxg4",
              "hxg4",
              "Nh2",
              "Rxh2",
              "Kxh2",
              "Qh4+",
              "Kg1",
              "Bc5",
              "d4",
              "Bxd4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc6",
              "O-O",
              "Bg4",
              "h3",
              "h5",
              "d3",
              "Qf6",
              "Nbd2",
              "Ne7",
              "Re1",
              "Ng6",
              "d4",
              "O-O-O",
              "hxg4",
              "hxg4",
              "Nh2",
              "Rxh2",
              "Qxg4+",
              "Kb8",
              "Kxh2",
              "Qxf2",
              "Nf3",
              "Bd6",
              "Kh1",
              "Rh8+",
              "Qh3",
              "Rxh3+",
              "gxh3",
              "Qxf3+",
              "Kg1",
              "Nh4",
              "Re2",
              "Qxe2",
              "Bg5",
              "Qg2#",
              "Kh1",
              "Qxh3+",
              "Kg1",
              "Qg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc6",
              "O-O",
              "Bg4",
              "h3",
              "h5",
              "d3",
              "Qf6",
              "Nbd2",
              "Ne7",
              "Re1",
              "Ng6",
              "d4",
              "O-O-O",
              "hxg4",
              "hxg4",
              "Nh2",
              "Rxh2",
              "Qxg4+",
              "Kb8",
              "Kxh2",
              "Qxf2",
              "Nf3",
              "Bd6",
              "Kh1",
              "Rh8+",
              "Nh2",
              "Qxe1+",
              "Nf1",
              "Qxf1#",
              "Kh2",
              "exd4+",
              "g3",
              "Qf2+",
              "Kh1",
              "Qf1+",
              "Kh2",
              "Ne5",
              "Qf5",
              "Nf3+",
              "Qxf3",
              "Qxf3",
              "Bf4",
              "Bxf4",
              "gxf4",
              "Rxh3+",
              "Kg1",
              "Rh1#",
              "Kxh1",
              "Qh3+",
              "Kg1",
              "Qg3+",
              "Kh1",
              "Qxf4",
              "Kg1",
              "Qxe4",
              "Kh2",
              "Qxc2+",
              "Kh3",
              "Qxb2",
              "Kh4",
              "Qxa1",
              "Kh5",
              "Qxa2",
              "Kg5",
              "Qe6",
              "Kh5",
              "Qg6+",
              "Kh4",
              "d3",
              "Kh3",
              "d2",
              "Kh2",
              "d1=Q",
              "Kh3",
              "Qdh5#",
              "Kh2",
              "Qhg5",
              "Kh3",
              "Qg4+",
              "Kh2",
              "Qg3+",
              "Kh1",
              "Qg2#",
              "Kh2",
              "Q6g3#",
              "Kh1",
              "Qg4",
              "Kh2",
              "Qg5",
              "Kh1",
              "Qg6",
              "Kh2",
              "Q6g5",
              "Kh1",
              "Q5g4",
              "Kh2",
              "Qg1#",
              "Kh3",
              "Q1g3#",
              "Kh1",
              "Qg2#",
              "Kh2",
              "Q2g3#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 176,
            "total_tokens": 309,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1456,
          "total_tokens": 1854
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 176,
            "total_tokens": 309,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": "f3e5",
          "aggressive_response": "5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Be3 Nd5 16. Bd4 Re1 17. b3 Nf4+ 18. Kg3 Rg1+ 19. Kh4 g5# g4 Qg5# Qxg5#",
          "aggressive_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 138,
            "total_tokens": 280,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd4",
            "Nf3",
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Be3",
            "Nd5",
            "Bd4",
            "Re1",
            "b3",
            "Nf4+",
            "Kg3",
            "Rg1+",
            "Kh4",
            "g5#",
            "g4",
            "Qg5#",
            "Qxg5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe5",
          "positional_uci": "f3e5",
          "positional_response": "5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. d3 Re8+ 11. Kf1 Rxe1+ 12. Nxe1 Nf6 13. Nc3 Bb4 14. Bd2 Re8 15. f3 Be6 16. a3 Bd6 17. g3 Bh3+ 18. Ng2 Nd5 19. Ne4 Be5 20. c3 f5 21. Ng5 Bxg2+ 22. Kxg2 Bf6 23. Kf2 h6 24. Nh3 g5 25. Re1 Rxe1 26. Kxe1 Kd7 27. Ke2 Ke6 28. Nf2 b5 29. Nd1 c5 30. Ne3 Nxe3 31. Bxe3 Kd5 32. Kd2 c4 33. d4 Be7 34. h3 c5 35. dxc5 Bxc5 36. Bxc5 Kxc5 37. Ke3 Kd5 38. f4 g4 39. hxg4 fxg4 40. f5 Ke5 41. f6 Kxf6 42. Kf4 h5 43. Ke4 Kg5 44. Ke3 h4 45. gxh4+ Kxh4 46. Kf2 Kh3 47. Kg1 Kg3 48. Kh1 Kf2 49. Kh2 g3+ 50. Kh1 g2+ 51. Kh2 g1=Q+ 52. Kh3 Qg3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Qxe4 Qxe4 Qxe4 Kxe2 Bg4 Re1+ Kf1 Rxe1+ Nxe1 Nf6 Bb4 Bd6 a3 Bd7 g3 Bc6 Ng2 Bxg2+ Kxg2 Nd5 Ne4 Be7 Kf3 Kf7 c4 Nb6 b3 Ke6 a4 Nd7 g4 Nc5 Nxc5+ Bxc5 Ke4 Bb4 f5+ Kf6 Kf4 Bd2+ Ke4 Kg5 Kf3 Bc3 Kg3 Be5+ Kf3 Kh4 Ke4 Kxh3 Kd5 Kxg4 Ke6 h5 Kd5 h4 Kc6 h3 Kb6 h2 Kxa6 h1=Q Kb5 Qb7+ Kc5 Qb5+ Kd6 Qd5+ Ke7 Qe6+ Kf8 Qf7# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc",
          "positional_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qd4",
            "Qxe4",
            "Qxe4",
            "Qxe4",
            "Kxe2",
            "Bg4",
            "Re1+",
            "Kf1",
            "Rxe1+",
            "Nxe1",
            "Nf6",
            "Bb4",
            "Bd6",
            "a3",
            "Bd7",
            "g3",
            "Bc6",
            "Ng2",
            "Bxg2+",
            "Kxg2",
            "Nd5",
            "Ne4",
            "Be7",
            "Kf3",
            "Kf7",
            "c4",
            "Nb6",
            "b3",
            "Ke6",
            "a4",
            "Nd7",
            "g4",
            "Nc5",
            "Nxc5+",
            "Bxc5",
            "Ke4",
            "Bb4",
            "f5+",
            "Kf6",
            "Kf4",
            "Bd2+",
            "Ke4",
            "Kg5",
            "Kf3",
            "Bc3",
            "Kg3",
            "Be5+",
            "Kf3",
            "Kh4",
            "Ke4",
            "Kxh3",
            "Kd5",
            "Kxg4",
            "Ke6",
            "h5",
            "Kd5",
            "h4",
            "Kc6",
            "h3",
            "Kb6",
            "h2",
            "Kxa6",
            "h1=Q",
            "Kb5",
            "Qb7+",
            "Kc5",
            "Qb5+",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qe6+",
            "Kf8",
            "Qf7#",
            "e4",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Bxc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe5",
          "neutral_uci": "f3e5",
          "neutral_response": "5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Bd6 27. Kg4 Bc5 28. Kh5 Bxe3 29. fxe3 Kf5 30. Kh6 Kg4 31. e4 Kf4 32. Kh5 c5 33. a3 b5 34. c3 c6 35. b4 cxb4 36. axb4 Ke3 37. Kh6 Kxd3 38. Kxh7 Kxe4 39. Kg7 Kf5 40. Kxf7 Kxg5 41. Ke6 Kf4 42. Kd6 Ke4 43. Kxc6 Kd3 44. Kb6 Kxc3 45. Kxa6 Kxb4 46. Kb6 Kc4 47. Ka5 b4 48. Ka4 Kc3 49. Kb5 b3 50. Ka4 b2 51. Ka3 b1=Q 52. Ka4 Qb4# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf6 Qxe4 Qd6 Qxe6 Qxe6 Qe2 Qd4 Qe3 Qxe3 fxe3 Nf6 Kf2 Kd7 Ke2 Ke6 Kd2 Ke5 Kc2 Ke4 Kb2 Kd3 Ka2 Kxc3 Ka3 Kc4 Ka4 Kc3 Kb5 Kb3 Kxc5 Kc3 Kd5 Kd3 Ke5 Ke3 Kf5 Kf3 Kg5 Kg3 Kh5 Kh3 g5 Kg3 g4 Kg2 Kh4 Kh2 g3+ Kg2 Kg4 Kg1 Kf3 Kf1 g2+ Kg1 Kg3 * e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4 Qd3 Qxe3 fxe3 Nf6 Kf2 Kd7 Ke2 Ke6 Kd2 Ke5 Kc2 Ke4 Kb2 Kd3 Ka2 Kxc3 Ka3",
          "neutral_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qd4",
            "Nf3",
            "Qxe4",
            "Qd3",
            "Qxe3",
            "fxe3",
            "Nf6",
            "Kf2",
            "Kd7",
            "Ke2",
            "Ke6",
            "Kd2",
            "Ke5",
            "Kc2",
            "Ke4",
            "Kb2",
            "Kd3",
            "Ka2",
            "Kxc3",
            "Ka3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3e5",
          "positional_uci": "f3e5",
          "neutral_uci": "f3e5",
          "consensus_move": "f3e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd4",
              "Nf3",
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Be3",
              "Nd5",
              "Bd4",
              "Re1",
              "b3",
              "Nf4+",
              "Kg3",
              "Rg1+",
              "Kh4",
              "g5#",
              "g4",
              "Qg5#",
              "Qxg5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd4",
              "Qxe4",
              "Qxe4",
              "Qxe4",
              "Kxe2",
              "Bg4",
              "Re1+",
              "Kf1",
              "Rxe1+",
              "Nxe1",
              "Nf6",
              "Bb4",
              "Bd6",
              "a3",
              "Bd7",
              "g3",
              "Bc6",
              "Ng2",
              "Bxg2+",
              "Kxg2",
              "Nd5",
              "Ne4",
              "Be7",
              "Kf3",
              "Kf7",
              "c4",
              "Nb6",
              "b3",
              "Ke6",
              "a4",
              "Nd7",
              "g4",
              "Nc5",
              "Nxc5+",
              "Bxc5",
              "Ke4",
              "Bb4",
              "f5+",
              "Kf6",
              "Kf4",
              "Bd2+",
              "Ke4",
              "Kg5",
              "Kf3",
              "Bc3",
              "Kg3",
              "Be5+",
              "Kf3",
              "Kh4",
              "Ke4",
              "Kxh3",
              "Kd5",
              "Kxg4",
              "Ke6",
              "h5",
              "Kd5",
              "h4",
              "Kc6",
              "h3",
              "Kb6",
              "h2",
              "Kxa6",
              "h1=Q",
              "Kb5",
              "Qb7+",
              "Kc5",
              "Qb5+",
              "Kd6",
              "Qd5+",
              "Ke7",
              "Qe6+",
              "Kf8",
              "Qf7#",
              "e4",
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Bxc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd4",
              "Nf3",
              "Qxe4",
              "Qd3",
              "Qxe3",
              "fxe3",
              "Nf6",
              "Kf2",
              "Kd7",
              "Ke2",
              "Ke6",
              "Kd2",
              "Ke5",
              "Kc2",
              "Ke4",
              "Kb2",
              "Kd3",
              "Ka2",
              "Kxc3",
              "Ka3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 142,
            "completion_tokens": 138,
            "total_tokens": 280,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 425,
          "total_completion_tokens": 1418,
          "total_tokens": 1843
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 142,
            "completion_tokens": 138,
            "total_tokens": 280,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1pp2ppp/p1p5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "e5f3",
          "aggressive_response": "6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Bd6 27. Kg4 Bc5 28. Kf4 Bxe3+ 29. fxe3 f6 30. gxf6 Kxf6 31. e4 h5 32. d4 h4 33. Kg4 h3 34. Kxh3 Kg5 35. Kg3 b6 36. Kf3 c5 37. d5 Kf6 38. Kf4 b5 39. e5+ Ke7 40. Kf5 a5 41. c4 bxc4 42. bxc4 a4 43. a3 Kd7 44. Kf6 Ke8 45. Ke6 Kd8 46. Kf7 Kd7 47. e6+ Kd8 48. e7+ Kd7 49. e8=Q+ Kd6 50. Qe6# e4 d5 Qd6",
          "aggressive_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 379,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "Kg3",
            "Ke6",
            "Kf4",
            "Be5+",
            "Ke4",
            "Bxh2",
            "f4",
            "g6",
            "Kf3",
            "g5",
            "fxg5",
            "Bd6",
            "Kg4",
            "Bc5",
            "Kf4",
            "Bxe3+",
            "fxe3",
            "f6",
            "gxf6",
            "Kxf6",
            "e4",
            "h5",
            "d4",
            "h4",
            "Kg4",
            "h3",
            "Kxh3",
            "Kg5",
            "Kg3",
            "b6",
            "Kf3",
            "c5",
            "d5",
            "Kf6",
            "Kf4",
            "b5",
            "e5+",
            "Ke7",
            "Kf5",
            "a5",
            "c4",
            "bxc4",
            "bxc4",
            "a4",
            "a3",
            "Kd7",
            "Kf6",
            "Ke8",
            "Ke6",
            "Kd8",
            "Kf7",
            "Kd7",
            "e6+",
            "Kd8",
            "e7+",
            "Kd7",
            "e8=Q+",
            "Kd6",
            "Qe6#",
            "e4",
            "d5",
            "Qd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "e5f3",
          "positional_response": "6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Bd6 27. Kg4 Bc5 28. Kf4 Bxe3+ 29. fxe3 f6 30. gxf6 Kxf6 31. e4 h5 32. d4 b6 33. c4 c5 34. d5 h4 35. e5+ Ke7 36. Kg4 b5 37. Kxh4 bxc4 38. bxc4 a5 39. Kg5 a4 40. Kf5 a3 41. e6 Kd6 42. Kf6 c6 43. e7 cxd5 44. e8=Q dxc4 45. Qe6+ Kc7 46. Qxc4 Kc6 47. Ke5 Kb6 48. Kd5 Ka5 49. Qxc5+ Ka4 50. Qc4+ Ka5 51. Qb3 Ka6 52. Kc6 Ka5 53. Qb5# e4 d5 dxe4",
          "positional_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 402,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "Kg3",
            "Ke6",
            "Kf4",
            "Be5+",
            "Ke4",
            "Bxh2",
            "f4",
            "g6",
            "Kf3",
            "g5",
            "fxg5",
            "Bd6",
            "Kg4",
            "Bc5",
            "Kf4",
            "Bxe3+",
            "fxe3",
            "f6",
            "gxf6",
            "Kxf6",
            "e4",
            "h5",
            "d4",
            "b6",
            "c4",
            "c5",
            "d5",
            "h4",
            "e5+",
            "Ke7",
            "Kg4",
            "b5",
            "Kxh4",
            "bxc4",
            "bxc4",
            "a5",
            "Kg5",
            "a4",
            "Kf5",
            "a3",
            "e6",
            "Kd6",
            "Kf6",
            "c6",
            "e7",
            "cxd5",
            "e8=Q",
            "dxc4",
            "Qe6+",
            "Kc7",
            "Qxc4",
            "Kc6",
            "Ke5",
            "Kb6",
            "Kd5",
            "Ka5",
            "Qxc5+",
            "Ka4",
            "Qc4+",
            "Ka5",
            "Qb3",
            "Ka6",
            "Kc6",
            "Ka5",
            "Qb5#",
            "e4",
            "d5",
            "dxe4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "e5f3",
          "neutral_response": "6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. f4 Ke6 22. Kf3 f5 23. h4 g6 24. Nc4 Bf6 25. Kg3 Kd5 26. Na5 b6 27. Nc4 Kd4 28. Ne3 Kc3 29. h5 Kb2 30. a4 Kc3 31. hxg6 hxg6 32. Kf3 Bd4 33. Ke2 Bxe3 34. Kxe3 Kxc2 35. Kd4 Kxb3 36. Ke5 Kxa4 37. Kf6 b5 38. Kxg6 b4 39. Kxf5 b3 40. Ke6 b2 41. f5 b1=Q 42. f6 Qxd3 43. f7 Qd5+ 44. Ke7 Qxf7+ 45. Kxf7 c5 46. f4 c4 47. f5 c3 48. f6 c2 49. Kg7 c1=Q 50. f7 Qg5+ 51. Kf8 Kb5 52. Ke8 Qe5+ 53. Kf8 Kc6 54. Kg8 Qg5+ 55. Kf8 Kd6 56. Ke8 Qe7# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf6 Qxe4+ Qxe4 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke1 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Rxe8 Rxe8 Nc3 Re1 b3 Be5 Bb2 Bxc3 Bxc3 Rc1 Bb2 Rxa1 Bxa1 Ne3 Kd7 f4 Ke6 f5+ Ke5 Kf3 Bd4 Ng4+ Kxf5 h4 g6 Nf2 Bxf2 Kxf2 Kf4 Kg2 Kg4 h5 gxh5 Kh2 Kf3 Kh3 Ke3 Kh4 Kxd3 Kg3 Kc3 Kf3 Kxb3 Ke4 Kxa4 Kd4 Kb4 Kd3 a5 Kc2 a4 Kb2 a3+ Ka2 c5 Kb1 c4 K",
          "neutral_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Bxc6",
            "dxc6",
            "Nxe5",
            "Qd4",
            "Nf6",
            "Qxe4+",
            "Qxe4",
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Ke1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Bxc3",
            "Bxc3",
            "Rc1",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Ne3",
            "Kd7",
            "f4",
            "Ke6",
            "f5+",
            "Ke5",
            "Kf3",
            "Bd4",
            "Ng4+",
            "Kxf5",
            "h4",
            "g6",
            "Nf2",
            "Bxf2",
            "Kxf2",
            "Kf4",
            "Kg2",
            "Kg4",
            "h5",
            "gxh5",
            "Kh2",
            "Kf3",
            "Kh3",
            "Ke3",
            "Kh4",
            "Kxd3",
            "Kg3",
            "Kc3",
            "Kf3",
            "Kxb3",
            "Ke4",
            "Kxa4",
            "Kd4",
            "Kb4",
            "Kd3",
            "a5",
            "Kc2",
            "a4",
            "Kb2",
            "a3+",
            "Ka2",
            "c5",
            "Kb1",
            "c4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5f3",
          "positional_uci": "e5f3",
          "neutral_uci": "e5f3",
          "consensus_move": "e5f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "Kg3",
              "Ke6",
              "Kf4",
              "Be5+",
              "Ke4",
              "Bxh2",
              "f4",
              "g6",
              "Kf3",
              "g5",
              "fxg5",
              "Bd6",
              "Kg4",
              "Bc5",
              "Kf4",
              "Bxe3+",
              "fxe3",
              "f6",
              "gxf6",
              "Kxf6",
              "e4",
              "h5",
              "d4",
              "h4",
              "Kg4",
              "h3",
              "Kxh3",
              "Kg5",
              "Kg3",
              "b6",
              "Kf3",
              "c5",
              "d5",
              "Kf6",
              "Kf4",
              "b5",
              "e5+",
              "Ke7",
              "Kf5",
              "a5",
              "c4",
              "bxc4",
              "bxc4",
              "a4",
              "a3",
              "Kd7",
              "Kf6",
              "Ke8",
              "Ke6",
              "Kd8",
              "Kf7",
              "Kd7",
              "e6+",
              "Kd8",
              "e7+",
              "Kd7",
              "e8=Q+",
              "Kd6",
              "Qe6#",
              "e4",
              "d5",
              "Qd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "Kg3",
              "Ke6",
              "Kf4",
              "Be5+",
              "Ke4",
              "Bxh2",
              "f4",
              "g6",
              "Kf3",
              "g5",
              "fxg5",
              "Bd6",
              "Kg4",
              "Bc5",
              "Kf4",
              "Bxe3+",
              "fxe3",
              "f6",
              "gxf6",
              "Kxf6",
              "e4",
              "h5",
              "d4",
              "b6",
              "c4",
              "c5",
              "d5",
              "h4",
              "e5+",
              "Ke7",
              "Kg4",
              "b5",
              "Kxh4",
              "bxc4",
              "bxc4",
              "a5",
              "Kg5",
              "a4",
              "Kf5",
              "a3",
              "e6",
              "Kd6",
              "Kf6",
              "c6",
              "e7",
              "cxd5",
              "e8=Q",
              "dxc4",
              "Qe6+",
              "Kc7",
              "Qxc4",
              "Kc6",
              "Ke5",
              "Kb6",
              "Kd5",
              "Ka5",
              "Qxc5+",
              "Ka4",
              "Qc4+",
              "Ka5",
              "Qb3",
              "Ka6",
              "Kc6",
              "Ka5",
              "Qb5#",
              "e4",
              "d5",
              "dxe4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Bxc6",
              "dxc6",
              "Nxe5",
              "Qd4",
              "Nf6",
              "Qxe4+",
              "Qxe4",
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Ke1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Bxc3",
              "Bxc3",
              "Rc1",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Ne3",
              "Kd7",
              "f4",
              "Ke6",
              "f5+",
              "Ke5",
              "Kf3",
              "Bd4",
              "Ng4+",
              "Kxf5",
              "h4",
              "g6",
              "Nf2",
              "Bxf2",
              "Kxf2",
              "Kf4",
              "Kg2",
              "Kg4",
              "h5",
              "gxh5",
              "Kh2",
              "Kf3",
              "Kh3",
              "Ke3",
              "Kh4",
              "Kxd3",
              "Kg3",
              "Kc3",
              "Kf3",
              "Kxb3",
              "Ke4",
              "Kxa4",
              "Kd4",
              "Kb4",
              "Kd3",
              "a5",
              "Kc2",
              "a4",
              "Kb2",
              "a3+",
              "Ka2",
              "c5",
              "Kb1",
              "c4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 151,
            "completion_tokens": 379,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 151,
            "completion_tokens": 402,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 452,
          "total_completion_tokens": 1421,
          "total_tokens": 1873
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 151,
            "completion_tokens": 379,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 151,
            "completion_tokens": 402,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/4N3/3qP3/8/PPPP1PPP/RNBQK2R w KQkq - 1 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf1",
          "aggressive_uci": "e1f1",
          "aggressive_response": "7. Kf1 Bg4 8. d3 Bxf3 9. Qxf3 Qxf3 10. gxf3 O-O-O 11. Nc3 Nf6 12. Bg5 Be7 13. Re1 Rhe8 14. Kg2 h6 15. Bh4 g5 16. Bg3 Nd5 17. Nxd5 cxd5 18. Re2 Bf6 19. Rxe8 Rxe8 20. c3 Re2 21. Rb1 Rd2 22. d4 Kd7 23. f4 g4 24. h3 h5 25. hxg4 hxg4 26. Kf1 Be7 27. Ke1 Rc2 28. Kd1 Rxf2 29. Bxf2 f5 30. Ke2 Bd6 31. Bg3 c5 32. dxc5 Bxc5 33. Rd1 Kc6 34. b4 Bb6 35. a4 a5 36. b5+ Kc5 37. Bf2+ Kc4 38. Bxb6 Kxc3 39. Rxd5 Kb4 40. Rxf5 Kxa4 41. Rg5 Kb4 42. Rxg4 Kxb5 43. Bxa5 Kxa5 44. f5 b5 45. f6 b4 46. f7 b3 47. f8=Q b2 48. Qb8 b1=Q 49. Qxb1 Ka6 50. Ra4# e5 e6 e7",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 363,
            "total_tokens": 524,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "Ke1",
            "Rc2",
            "Kd1",
            "Rxf2",
            "Bxf2",
            "f5",
            "Ke2",
            "Bd6",
            "Bg3",
            "c5",
            "dxc5",
            "Bxc5",
            "Rd1",
            "Kc6",
            "b4",
            "Bb6",
            "a4",
            "a5",
            "b5+",
            "Kc5",
            "Bf2+",
            "Kc4",
            "Bxb6",
            "Kxc3",
            "Rxd5",
            "Kb4",
            "Rxf5",
            "Kxa4",
            "Rg5",
            "Kb4",
            "Rxg4",
            "Kxb5",
            "Bxa5",
            "Kxa5",
            "f5",
            "b5",
            "f6",
            "b4",
            "f7",
            "b3",
            "f8=Q",
            "b2",
            "Qb8",
            "b1=Q",
            "Qxb1",
            "Ka6",
            "Ra4#",
            "e5",
            "e6",
            "e7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe2",
          "positional_uci": "d1e2",
          "positional_response": "7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Be3 Nd5 16. Bd4 Re1 17. b3 Nf4+ 18. Kg3 Rg1+ 19. Kh4 g5# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke3 O-O-O Kf4 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Be3 Nd5 Bd4 Re2 c4 Nf4+ Kf1 Rxc2 Bxg7 Nxd3 Nc3 Rxf2+ Kg1 Rg8 Ne4 Rxg7+ Ng3 Bxg3 hxg3 Rxg3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke3 O-O-O Kf4 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Be3 Nd5 Bd4 Re2 c4 Nf4 Kf1 Rxc2 Bxg7 Nxd3 Nc3 Rxf2+ Kg1 Rg8 Ne4 Rxg7+ Ng3 Bxg3 hxg3 Rxg3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke3 O-O-O Kf4 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Be3 Nd5 Bd4 Re2 c4 Nf4 Kf1 Rxc2 Bxg7 Nxd3 Nc3 Rxf2+ Kg1 Rg8 Ne4 Rxg7+ Ng3 Bxg3 hxg3 Rxg3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke3 O-O-O Kf4 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Be3 Nd5 Bd4 Re2 c4 Nf4 Kf1 Rxc2 Bxg7 Nxd3 Nc3 Rxf2+ Kg1 Rg8 Ne4 Rxg7+ Ng3 Bxg3 hxg3 Rxg3#",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 625,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Ke3",
            "O-O-O",
            "Kf4",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Be3",
            "Nd5",
            "Bd4",
            "Re2",
            "c4",
            "Nf4",
            "Kf1",
            "Rxc2",
            "Bxg7",
            "Nxd3",
            "Nc3",
            "Rxf2+",
            "Kg1",
            "Rg8",
            "Ne4",
            "Rxg7+",
            "Ng3",
            "Bxg3",
            "hxg3",
            "Rxg3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kf1",
          "neutral_uci": "e1f1",
          "neutral_response": "7. Kf1 Bg4 8. d3 Bxf3 9. Qxf3 Qxf3 10. gxf3 O-O-O 11. Nc3 Nf6 12. Bg5 Be7 13. Re1 Rhe8 14. Kg2 h6 15. Bh4 g5 16. Bg3 Nh5 17. Re2 Bb4 18. Rhe1 Rxe2 19. Rxe2 Bxc3 20. bxc3 f5 21. h3 f4 22. Bh2 Kd7 23. Re4 Re8 24. Kf1 Nf6 25. Rxe8 Nxe8 26. Ke2 Nd6 27. Kd2 Nf5 28. Ke2 Kd6 29. Kd2 Kd5 30. Ke2 c5 31. Kd2 b5 32. Ke2 c4 33. Kd2 c5 34. Ke2 b4 35. Kd2 a5 36. cxb4 cxb4 37. c3 b3 38. axb3 cxb3 39. Kc1 a4 40. Kb2 Kc5 41. Ka3 Kb5 42. Kb2 Nd6 43. Ka3 Nc4+ 44. dxc4+ Kxc4 45. Kb2 a3+ 46. Kxa3 Kxc3 47. Bxf4 gxf4 48. h4 b2 49. Ka2 Kc2 50. h5 b1=Q+ 51. Ka3 Qb3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nxf3 Kf1 Bg4 d3 Bxf3 Qxf3 Qxf3 gxf3 O-O-O Nc3 Nf6 Bg5 Be7 Re1 Rhe8 Kg2 h6 Bh4 g5 Bg3 Nh5 Re2 Bb4 Re4 Rxe4 fxe4 Bxc3 bxc3 f5 exf5 Nf6 Kf3 Kd7 Be5 Ke7 Bxf6+ Kxf6 Ke4 h5 f3 a5 c4 a4 d4 a3 d5 cxd5+ Kxd5 a2 Kc3 a1=Q Kd3 Qd4+ Ke2 Qc3 Kf2 Qd3 Kg2 Qe3 Kg3 Qf4+ Kg2 Kd3 Kf2 Kd2 Kg2 Ke2 Kh3 Qxf3+ Kg1 Qf2+ Kh1 Kf3 h4 Qg2#",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 592,
            "total_tokens": 752,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "d3",
            "Bxf3",
            "Qxf3",
            "Qxf3",
            "gxf3",
            "O-O-O",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "Re1",
            "Rhe8",
            "Kg2",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Nh5",
            "Re2",
            "Bb4",
            "Re4",
            "Rxe4",
            "fxe4",
            "Bxc3",
            "bxc3",
            "f5",
            "exf5",
            "Nf6",
            "Kf3",
            "Kd7",
            "Be5",
            "Ke7",
            "Bxf6+",
            "Kxf6",
            "Ke4",
            "h5",
            "f3",
            "a5",
            "c4",
            "a4",
            "d4",
            "a3",
            "d5",
            "cxd5+",
            "Kxd5",
            "a2",
            "Kc3",
            "a1=Q",
            "Kd3",
            "Qd4+",
            "Ke2",
            "Qc3",
            "Kf2",
            "Qd3",
            "Kg2",
            "Qe3",
            "Kg3",
            "Qf4+",
            "Kg2",
            "Kd3",
            "Kf2",
            "Kd2",
            "Kg2",
            "Ke2",
            "Kh3",
            "Qxf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Kf3",
            "h4",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1f1",
          "positional_uci": "d1e2",
          "neutral_uci": "e1f1",
          "consensus_move": "e1f1",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "Ke1",
              "Rc2",
              "Kd1",
              "Rxf2",
              "Bxf2",
              "f5",
              "Ke2",
              "Bd6",
              "Bg3",
              "c5",
              "dxc5",
              "Bxc5",
              "Rd1",
              "Kc6",
              "b4",
              "Bb6",
              "a4",
              "a5",
              "b5+",
              "Kc5",
              "Bf2+",
              "Kc4",
              "Bxb6",
              "Kxc3",
              "Rxd5",
              "Kb4",
              "Rxf5",
              "Kxa4",
              "Rg5",
              "Kb4",
              "Rxg4",
              "Kxb5",
              "Bxa5",
              "Kxa5",
              "f5",
              "b5",
              "f6",
              "b4",
              "f7",
              "b3",
              "f8=Q",
              "b2",
              "Qb8",
              "b1=Q",
              "Qxb1",
              "Ka6",
              "Ra4#",
              "e5",
              "e6",
              "e7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Ke3",
              "O-O-O",
              "Kf4",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Be3",
              "Nd5",
              "Bd4",
              "Re2",
              "c4",
              "Nf4",
              "Kf1",
              "Rxc2",
              "Bxg7",
              "Nxd3",
              "Nc3",
              "Rxf2+",
              "Kg1",
              "Rg8",
              "Ne4",
              "Rxg7+",
              "Ng3",
              "Bxg3",
              "hxg3",
              "Rxg3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bg4",
              "d3",
              "Bxf3",
              "Qxf3",
              "Qxf3",
              "gxf3",
              "O-O-O",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "Re1",
              "Rhe8",
              "Kg2",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Nh5",
              "Re2",
              "Bb4",
              "Re4",
              "Rxe4",
              "fxe4",
              "Bxc3",
              "bxc3",
              "f5",
              "exf5",
              "Nf6",
              "Kf3",
              "Kd7",
              "Be5",
              "Ke7",
              "Bxf6+",
              "Kxf6",
              "Ke4",
              "h5",
              "f3",
              "a5",
              "c4",
              "a4",
              "d4",
              "a3",
              "d5",
              "cxd5+",
              "Kxd5",
              "a2",
              "Kc3",
              "a1=Q",
              "Kd3",
              "Qd4+",
              "Ke2",
              "Qc3",
              "Kf2",
              "Qd3",
              "Kg2",
              "Qe3",
              "Kg3",
              "Qf4+",
              "Kg2",
              "Kd3",
              "Kf2",
              "Kd2",
              "Kg2",
              "Ke2",
              "Kh3",
              "Qxf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Kf3",
              "h4",
              "Qg2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 363,
            "total_tokens": 524,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 625,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 592,
            "total_tokens": 752,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 1580,
          "total_tokens": 2062
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 363,
            "total_tokens": 524,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 625,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 592,
            "total_tokens": 752,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxf3",
          "aggressive_uci": "d1f3",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bxf6 Bxf6 15. g4 Bxc3 16. bxc3 Bd5 17. Qf5+ Be6 18. Qf4 Bd5 19. Rg1 Rxe1+ 20. Kxe1 Re8+ 21. Kd2 g5 22. Qf5+ Be6 23. Qf6 Bxa2 24. c4 b5 25. Qxc6 Re6 26. Qa8+ Kd7 27. cxb5 axb5 28. Qxa2 1-0\n*1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bxf6 Bxf6 15. g4 Bxc3 16. bxc3 Bd5 17. Qf5+ Be6 18. Qf4 Bd5 19. Rg1 Rxe1+ 20. Kxe1 Re8+ 21. Kd2 g5 22. Qf5+ Be6 23. Qf6 Bxa2 24. c4 b5 25. Qxc6 Re6 26. Qa8+ Kd7 27. cxb5 axb5 28. Qxa2 1-0 29. Re1 Rxe1 30. Kxe1 Be6 31. Qa5 c6 32. Qa7+ Kd6 33. Qd4+ Ke7 34. Qc5+ Kd7 35. Qf8 Kc7 36. Qxh6 Kb6 37. Qxg5 c5 38. Qd8+ Kc6 39. Qa8+ Kb6 40. Qb8+ Kc6 41. Qa7 Kd5 42. Qxa6 b4 43. Qb7+ Kd4 44. Qe4+ Kc3 45. Kd1 b3 46. Qe5+ Kb",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be6",
            "d3",
            "O-O-O",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "Re1",
            "Rhe8",
            "h3",
            "h6",
            "Bxf6",
            "Bxf6",
            "g4",
            "Bxc3",
            "bxc3",
            "Bd5",
            "Qf5+",
            "Be6",
            "Qf4",
            "Bd5",
            "Rg1",
            "Rxe1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "g5",
            "Qf5+",
            "Be6",
            "Qf6",
            "Bxa2",
            "c4",
            "b5",
            "Qxc6",
            "Re6",
            "Qa8+",
            "Kd7",
            "cxb5",
            "axb5",
            "Qxa2",
            "Re1",
            "Rxe1",
            "Kxe1",
            "Be6",
            "Qa5",
            "c6",
            "Qa7+",
            "Kd6",
            "Qd4+",
            "Ke7",
            "Qc5+",
            "Kd7",
            "Qf8",
            "Kc7",
            "Qxh6",
            "Kb6",
            "Qxg5",
            "c5",
            "Qd8+",
            "Kc6",
            "Qa8+",
            "Kb6",
            "Qb8+",
            "Kc6",
            "Qa7",
            "Kd5",
            "Qxa6",
            "b4",
            "Qb7+",
            "Kd4",
            "Qe4+",
            "Kc3",
            "Kd1",
            "b3",
            "Qe5+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxf3",
          "positional_uci": "d1f3",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bxf6 Bxf6 15. g4 Bxc3 16. bxc3 Bd5 17. Qf5+ Kb8 18. Rxe8 Rxe8 19. Rg1 Bxa2 20. c4 Bb1 21. Qxf7 Rc8 22. Qxg7 Bxc2 23. Qc3 Ba4 24. Kg2 c5 25. Rb1 Bc6+ 26. Kg3 Rf8 27. f4 Re8 28. Re1 Rd8 29. Re6 h5 30. Rxc6 bxc6 31. gxh5 Rg8+ 32. Kf3 Rg1 33. h6 Rf1+ 34. Kg4 Rg1+ 35. Kf5 Rg8 36. h7 Rf8+ 37. Kg6 Rxf4 38. h8=Q+ Kb7 39. Qb3+ Ka7 40. Qhb8#\n*1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bxf6 Bxf6 15. g4 Bxc3 16. bxc3 Bd5 17. Qf5+ Kb8 18. Rxe8 Rxe8 19. Rg1 Bxa2 20. c4 Bb1 21. Qxf7 Rc8 22. Qxg7 Bxc2 23. Qc3 Ba4 24. Kg2 c5 25. Rb1 Bc6+ 26. Kg3 Rf8 27. f4 Re8 28. Re1 Rd8 29. Re6 h5 30. Rxc6 bxc6 31. gxh5 Rg8+ 32. Kf3 Rg1 33. h6 Rf1+ 34. Kg4 Rg1+ 35. Kf5 Rg8 36. h7 Rf",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be6",
            "d3",
            "O-O-O",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "Re1",
            "Rhe8",
            "h3",
            "h6",
            "Bxf6",
            "Bxf6",
            "g4",
            "Bxc3",
            "bxc3",
            "Bd5",
            "Qf5+",
            "Kb8",
            "Rxe8",
            "Rxe8",
            "Rg1",
            "Bxa2",
            "c4",
            "Bb1",
            "Qxf7",
            "Rc8",
            "Qxg7",
            "Bxc2",
            "Qc3",
            "Ba4",
            "Kg2",
            "c5",
            "Rb1",
            "Bc6+",
            "Kg3",
            "Rf8",
            "f4",
            "Re8",
            "Re1",
            "Rd8",
            "Re6",
            "h5",
            "Rxc6",
            "bxc6",
            "gxh5",
            "Rg8+",
            "Kf3",
            "Rg1",
            "h6",
            "Rf1+",
            "Kg4",
            "Rg1+",
            "Kf5",
            "Rg8",
            "h7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxf3",
          "neutral_uci": "d1f3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bf4 Nd5 15. Nxd5 Bxd5 16. Qg3 Bf6 17. Bxc7 Rxe1+ 18. Kxe1 Re8+ 19. Kd2 Bxb2 20. Bb8 Re7 21. Re1 Rd7 22. Re8+ Rd8 23. Qc7#\n*8... Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bf4 Nd5 15. Nxd5 Bxd5 16. Qg3 Bf6 17. Bxc7 Rxe1+ 18. Kxe1 Re8+ 19. Kd2 Bxb2 20. Bb8 Re7 21. Re1 Rd7 22. Re8+ Rd8 23. Qc7# e5 Nc6 Bb5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Be6 d3 O-O-O Nc3 Nf6 Bg5 Be7 Re1 Rhe8 h3 h6 Bf4 Nd5 Nxd5 Bxd5 Qg3 Bf6 Bxc7 Rxe1+ Kxe1 Re8+ Kd2 Bxb2 Bb8 Re7 Re1 Rd7 Qc7#",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 422,
            "total_tokens": 592,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be6",
            "d3",
            "O-O-O",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "Re1",
            "Rhe8",
            "h3",
            "h6",
            "Bf4",
            "Nd5",
            "Nxd5",
            "Bxd5",
            "Qg3",
            "Bf6",
            "Bxc7",
            "Rxe1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Bxb2",
            "Bb8",
            "Re7",
            "Re1",
            "Rd7",
            "Qc7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1f3",
          "positional_uci": "d1f3",
          "neutral_uci": "d1f3",
          "consensus_move": "d1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be6",
              "d3",
              "O-O-O",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "Re1",
              "Rhe8",
              "h3",
              "h6",
              "Bxf6",
              "Bxf6",
              "g4",
              "Bxc3",
              "bxc3",
              "Bd5",
              "Qf5+",
              "Be6",
              "Qf4",
              "Bd5",
              "Rg1",
              "Rxe1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "g5",
              "Qf5+",
              "Be6",
              "Qf6",
              "Bxa2",
              "c4",
              "b5",
              "Qxc6",
              "Re6",
              "Qa8+",
              "Kd7",
              "cxb5",
              "axb5",
              "Qxa2",
              "Re1",
              "Rxe1",
              "Kxe1",
              "Be6",
              "Qa5",
              "c6",
              "Qa7+",
              "Kd6",
              "Qd4+",
              "Ke7",
              "Qc5+",
              "Kd7",
              "Qf8",
              "Kc7",
              "Qxh6",
              "Kb6",
              "Qxg5",
              "c5",
              "Qd8+",
              "Kc6",
              "Qa8+",
              "Kb6",
              "Qb8+",
              "Kc6",
              "Qa7",
              "Kd5",
              "Qxa6",
              "b4",
              "Qb7+",
              "Kd4",
              "Qe4+",
              "Kc3",
              "Kd1",
              "b3",
              "Qe5+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be6",
              "d3",
              "O-O-O",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "Re1",
              "Rhe8",
              "h3",
              "h6",
              "Bxf6",
              "Bxf6",
              "g4",
              "Bxc3",
              "bxc3",
              "Bd5",
              "Qf5+",
              "Kb8",
              "Rxe8",
              "Rxe8",
              "Rg1",
              "Bxa2",
              "c4",
              "Bb1",
              "Qxf7",
              "Rc8",
              "Qxg7",
              "Bxc2",
              "Qc3",
              "Ba4",
              "Kg2",
              "c5",
              "Rb1",
              "Bc6+",
              "Kg3",
              "Rf8",
              "f4",
              "Re8",
              "Re1",
              "Rd8",
              "Re6",
              "h5",
              "Rxc6",
              "bxc6",
              "gxh5",
              "Rg8+",
              "Kf3",
              "Rg1",
              "h6",
              "Rf1+",
              "Kg4",
              "Rg1+",
              "Kf5",
              "Rg8",
              "h7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be6",
              "d3",
              "O-O-O",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "Re1",
              "Rhe8",
              "h3",
              "h6",
              "Bf4",
              "Nd5",
              "Nxd5",
              "Bxd5",
              "Qg3",
              "Bf6",
              "Bxc7",
              "Rxe1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Bxb2",
              "Bb8",
              "Re7",
              "Re1",
              "Rd7",
              "Qc7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 422,
            "total_tokens": 592,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1702,
          "total_tokens": 2214
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 422,
            "total_tokens": 592,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/8/5q2/PPPP1PPP/RNBQ1K1R w kq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxg4",
          "aggressive_uci": "f3g4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O-O 12. Qxe7 Rhe8 13. Qxf7 Rd7\n14. Qb3 Rde7 15. Bd2 Re2 16. Qf7 R8e7 17. Qf8+ Kd7 18. Qb8 Ng4 19. Qxb7 Rxf2+\n20. Kg1 Ree2 21. Qxc6+ Kxc6 22. h3 Rxg2+ 23. Kf1 Ref2+ 24. Ke1 Re2+ 25. Kd1 Nf2+\n26. Kxe2 Nxh1+ 27. Kf3 Rf2+ 28. Ke3 Rf1 29. Ke2 Ng3+ 30. Ke3 Kd5 31. c4+ Ke5\n32. Bc3+ Kf5 33. b3 c5 34. Bxg7 Re1+ 35. Kf2 Re7 36. Kxg3 Rxg7+ 37. Kf3 Rd7\n38. Ke3 Re7+ 39. Kd2 Kf4 40. Nc3 Kg3 41. Ne4+ Kxh3 42. Nxc5 h5 43. Nxa6 h4\n44. Nc5 Kg2 45. Ne4 h3 46. Re1 h2 47. Re2+ Kh3 48. Nf2+ Kg2 49. Rxe7 Kxf2\n50. Rh7 Kg2 51. Rxh2+ Kxh2 52. a4 Kg3 53. a5 Kf4 54. a6 Ke5 55. a7 Kd6\n56. a8=Q Kc5 57. Qd5+ Kb4 58. Qb5+ Ka3 59. Kc3 Ka2 60. Qa4+ Kb1 61. b4 c5\n62. Qc2+ Ka1 63. Qb2# 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O-O",
          "aggressive_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Qe2+",
            "Be7",
            "d3",
            "O-O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxg4",
          "positional_uci": "f3g4",
          "positional_response": "9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O-O 12. Bg5 Rhe8 13. Bxf6 Bxf6 14. Qg4+ Kb8 15. Nc3 Rd4 16. Qf3 Rb4 17. Re1 Rd8 18. Ne4 Bxb2 19. Rb1 Ba3 20. Rxb4 Bxb4 21. Qxf7 Rf8 22. Qxg7 h5 23. Ke2 Re8 24. Rb1 Ba5 25. Qf7 Re5 26. Qf8+ Ka7 27. Qc8 Bb6 28. f4 Ra5 29. Rb2 h4 30. f5 Re5 31. f6 Bd4 32. Qxb7# Qxb7 Rxb7 Rxb7#",
          "positional_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 207,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Qe2+",
            "Be7",
            "d3",
            "O-O-O",
            "Bg5",
            "Rhe8",
            "Bxf6",
            "Bxf6",
            "Qg4+",
            "Kb8",
            "Nc3",
            "Rd4",
            "Qf3",
            "Rb4",
            "Re1",
            "Rd8",
            "Ne4",
            "Bxb2",
            "Rb1",
            "Ba3",
            "Rxb4",
            "Bxb4",
            "Qxf7",
            "Rf8",
            "Qxg7",
            "h5",
            "Ke2",
            "Re8",
            "Rb1",
            "Ba5",
            "Qf7",
            "Re5",
            "Qf8+",
            "Ka7",
            "Qc8",
            "Bb6",
            "f4",
            "Ra5",
            "Rb2",
            "h4",
            "f5",
            "Re5",
            "f6",
            "Bd4",
            "Qxb7#",
            "Qxb7",
            "Rxb7",
            "Rxb7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxg4",
          "neutral_uci": "f3g4",
          "neutral_response": "9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O-O 12. Bg5 Rhe8 13. Bxf6 Bxf6 14. Qg4+ Kb8\n15. Nc3 Rd4 16. Qf3 Rb4 17. Re1 Rd8 18. Ne4 Bxb2 19. Rb1 a5 20. c3 Rb6 21. Qe2 Ba3\n22. Rxb6 cxb6 23. g3 f5 24. Ng5 h6 25. Ne6 Re8 26. Qe5+ Ka7 27. Qxf5 Bb2 28. c4 Bf6\n29. Kg2 Re7 30. Re1 Rd7 31. Re3 Rd6 32. c5 Rd5 33. cxb6+ Kxb6 34. Qe4 Ka6 35. Nc7+ Ka7\n36. Nxd5 cxd5 37. Qxd5 b6 38. Qd7+ Ka6 39. Re8 b5 40. Ra8+ Kb6 41. Qd6+ Kb7 42. Qa6+ Kc7\n43. Ra7+ Kd8 44. Qd6+ Ke8 45. Qb8+ Bd8 46. Qxb5+ Kf8 47. Qf5+ Kg8 48. Qf7+ Kh8 49. Qxg7# Qe4 Qg4",
          "neutral_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 349,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Qe2+",
            "Be7",
            "d3",
            "O-O-O",
            "Bg5",
            "Rhe8",
            "Bxf6",
            "Bxf6",
            "Qg4+",
            "Kb8",
            "Nc3",
            "Rd4",
            "Qf3",
            "Rb4",
            "Re1",
            "Rd8",
            "Ne4",
            "Bxb2",
            "Rb1",
            "a5",
            "c3",
            "Rb6",
            "Qe2",
            "Ba3",
            "Rxb6",
            "cxb6",
            "g3",
            "f5",
            "Ng5",
            "h6",
            "Ne6",
            "Re8",
            "Qe5+",
            "Ka7",
            "Qxf5",
            "Bb2",
            "c4",
            "Bf6",
            "Kg2",
            "Re7",
            "Re1",
            "Rd7",
            "Re3",
            "Rd6",
            "c5",
            "Rd5",
            "cxb6+",
            "Kxb6",
            "Qe4",
            "Ka6",
            "Nc7+",
            "Ka7",
            "Nxd5",
            "cxd5",
            "Qxd5",
            "b6",
            "Qd7+",
            "Ka6",
            "Re8",
            "b5",
            "Ra8+",
            "Kb6",
            "Qd6+",
            "Kb7",
            "Qa6+",
            "Kc7",
            "Ra7+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Bd8",
            "Qxb5+",
            "Kf8",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qxg7#",
            "Qe4",
            "Qg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3g4",
          "positional_uci": "f3g4",
          "neutral_uci": "f3g4",
          "consensus_move": "f3g4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Qe2+",
              "Be7",
              "d3",
              "O-O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Qe2+",
              "Be7",
              "d3",
              "O-O-O",
              "Bg5",
              "Rhe8",
              "Bxf6",
              "Bxf6",
              "Qg4+",
              "Kb8",
              "Nc3",
              "Rd4",
              "Qf3",
              "Rb4",
              "Re1",
              "Rd8",
              "Ne4",
              "Bxb2",
              "Rb1",
              "Ba3",
              "Rxb4",
              "Bxb4",
              "Qxf7",
              "Rf8",
              "Qxg7",
              "h5",
              "Ke2",
              "Re8",
              "Rb1",
              "Ba5",
              "Qf7",
              "Re5",
              "Qf8+",
              "Ka7",
              "Qc8",
              "Bb6",
              "f4",
              "Ra5",
              "Rb2",
              "h4",
              "f5",
              "Re5",
              "f6",
              "Bd4",
              "Qxb7#",
              "Qxb7",
              "Rxb7",
              "Rxb7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Qe2+",
              "Be7",
              "d3",
              "O-O-O",
              "Bg5",
              "Rhe8",
              "Bxf6",
              "Bxf6",
              "Qg4+",
              "Kb8",
              "Nc3",
              "Rd4",
              "Qf3",
              "Rb4",
              "Re1",
              "Rd8",
              "Ne4",
              "Bxb2",
              "Rb1",
              "a5",
              "c3",
              "Rb6",
              "Qe2",
              "Ba3",
              "Rxb6",
              "cxb6",
              "g3",
              "f5",
              "Ng5",
              "h6",
              "Ne6",
              "Re8",
              "Qe5+",
              "Ka7",
              "Qxf5",
              "Bb2",
              "c4",
              "Bf6",
              "Kg2",
              "Re7",
              "Re1",
              "Rd7",
              "Re3",
              "Rd6",
              "c5",
              "Rd5",
              "cxb6+",
              "Kxb6",
              "Qe4",
              "Ka6",
              "Nc7+",
              "Ka7",
              "Nxd5",
              "cxd5",
              "Qxd5",
              "b6",
              "Qd7+",
              "Ka6",
              "Re8",
              "b5",
              "Ra8+",
              "Kb6",
              "Qd6+",
              "Kb7",
              "Qa6+",
              "Kc7",
              "Ra7+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Bd8",
              "Qxb5+",
              "Kf8",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qxg7#",
              "Qe4",
              "Qg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 179,
            "completion_tokens": 207,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 178,
            "completion_tokens": 349,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 536,
          "total_completion_tokens": 1196,
          "total_tokens": 1732
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 179,
            "completion_tokens": 207,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 178,
            "completion_tokens": 349,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3kbnr/1pp2ppp/p1p5/8/6b1/5Q2/PPPP1PPP/RNB2K1R w kq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe2+",
          "aggressive_uci": "g4e2",
          "aggressive_response": "10. Qe2+ Be7 11. d3 O-O-O 12. Qxe7 Rhe8 13. Qxf7 Rd7 14. Qb3 Rde7 15. Be3 Ng4 16. Nd2 Nxe3+ 17. fxe3 Rxe3 18. Ne4 Rf8+ 19. Kg1 Re2 20. Qe6+ Kb8 21. Qe7 Rf4 22. Qxg7 Rxc2 23. Qxh7 Rxb2 24. Qh8+ Ka7 25. Qxb2 Rf5 26. Rb1 Rb5 27. Qd4+ b6 28. Rxb5 axb5 29. Qd7 Kb7 30. Nd6+ Ka6 31. Qxc6 Ka5 32. Qxb5# Qd4+ Nxd4 Nf3",
          "aggressive_tokens": {
            "prompt_tokens": 189,
            "completion_tokens": 207,
            "total_tokens": 396,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "d3",
            "O-O-O",
            "Qxe7",
            "Rhe8",
            "Qxf7",
            "Rd7",
            "Qb3",
            "Rde7",
            "Be3",
            "Ng4",
            "Nd2",
            "Nxe3+",
            "fxe3",
            "Rxe3",
            "Ne4",
            "Rf8+",
            "Kg1",
            "Re2",
            "Qe6+",
            "Kb8",
            "Qe7",
            "Rf4",
            "Qxg7",
            "Rxc2",
            "Qxh7",
            "Rxb2",
            "Qh8+",
            "Ka7",
            "Qxb2",
            "Rf5",
            "Rb1",
            "Rb5",
            "Qd4+",
            "b6",
            "Rxb5",
            "axb5",
            "Qd7",
            "Kb7",
            "Nd6+",
            "Ka6",
            "Qxc6",
            "Ka5",
            "Qxb5#",
            "Qd4+",
            "Nxd4",
            "Nf3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe2+",
          "positional_uci": "g4e2",
          "positional_response": "10. Qe2+ Be7 11. d3 O-O-O 12. Bg5 Rhe8 13. Bxf6 Bxf6 14. Qg4+ Kb8 15. Nc3 Rd4 16. Qf3 Rb4 17. Re1 Rd8 18. Ne4 Bxb2 19. Rb1 Ba3 20. Rxb4 Bxb4 21. Qxf7 Rf8 22. Qxg7 Re8 23. Qxh7 Re7 24. Qg8+ Ka7 25. Qc4 Ba5 26. Qc5+ Bb6 27. Qxe7 c5 28. Nxc5 a5 29. Nd7 a4 30. Nxb6 cxb6 31. Ke2 Ka6 32. Rb1 b5 33. Qd6+ b6 34. Qb8 Ka5 35. Qa7# Qd4 Qe2 Qe3",
          "positional_tokens": {
            "prompt_tokens": 189,
            "completion_tokens": 226,
            "total_tokens": 415,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe2+",
          "neutral_uci": "g4e2",
          "neutral_response": "10. Qe2+ Be7 11. d3 O-O-O 12. Bg5 Rhe8 13. Bxf6 Bxf6 14. Qg4+ Kb8 15. Nc3 Rd4 16. Qf3 Rb4 17. Re1 Rd8 18. Ne4 Bxb2 19. Rb1 Ba3 20. Rxb4 Bxb4 21. Qxf7 Rd5 22. Qxg7 Ra5 23. Qg8+ Ka7 24. Qb3 c5 25. c3 Ra3 26. Qxa3 Bxa3 27. Ke2 b5 28. Rb1 b4 29. cxb4 cxb4 30. Nc5 Kb6 31. Nb3 a5 32. f4 a4 33. Nd4 Kc5 34. Nc2 b3 35. axb3 axb3 36. Nxa3 Kb4 37. Nc4 Kc3 38. f5 Kc2 39. Rb2+ Kc3 40. f6 c5 41. f7 h5 42. f8=Q h4 43. Qf6+ Kb4 44. Qb6+ Kc3 45. Qxb3+ Kd4 46. Qb6 h3 47. Qd6+ Kc3 48. Qe5# Qxe5+ 49. Nxe5 Kxb2 50. gxh3 Kc3 51. h4 Kd4 52. Nf3+ Kd5 53. h5 Ke6 54. h6 Kf7 55. Ng5+ Kg6 56. h7 Kg7 57. Ke3 Kh8 58. Ke4 Kg7 59. Kd5 Kh8 60. Kxc5 Kg7 61. d4 Kh8 62. d5 Kg7 63. d6 Kh8 64. d7 Kg7 65. d8=Q Kh6 66. h8=Q+ Kg6 67. Qdf6# Qxf6 68. Qxf6+ Kxf6 69. Ne4+ Ke5 70. h4 Kf4 71. h5 Kf5 72. Kd5 Kg4 73. h6 Kh5 74. h7 Kg6 75. h8=Q Kf7 76. Qf6+ Kg8 77. Qe7 Kh8 78. Ke6 Kg8 79. Nf6+ Kh8 80. Qh7# Qxf6+ 81. Kxf6 c5 82. Qg7# Qxf6+ 83. Kxf6 c4 84. Kg6 cxd3 85. Qf8# Qxf6+ 86",
          "neutral_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "d3",
            "O-O-O",
            "Bg5",
            "Rhe8",
            "Bxf6",
            "Bxf6",
            "Qg4+",
            "Kb8",
            "Nc3",
            "Rd4",
            "Qf3",
            "Rb4",
            "Re1",
            "Rd8",
            "Ne4",
            "Bxb2",
            "Rb1",
            "Ba3",
            "Rxb4",
            "Bxb4",
            "Qxf7",
            "Rd5",
            "Qxg7",
            "Ra5",
            "Qg8+",
            "Ka7",
            "Qb3",
            "c5",
            "c3",
            "Ra3",
            "Qxa3",
            "Bxa3",
            "Ke2",
            "b5",
            "Rb1",
            "b4",
            "cxb4",
            "cxb4",
            "Nc5",
            "Kb6",
            "Nb3",
            "a5",
            "f4",
            "a4",
            "Nd4",
            "Kc5",
            "Nc2",
            "b3",
            "axb3",
            "axb3",
            "Nxa3",
            "Kb4",
            "Nc4",
            "Kc3",
            "f5",
            "Kc2",
            "Rb2+",
            "Kc3",
            "f6",
            "c5",
            "f7",
            "h5",
            "f8=Q",
            "h4",
            "Qf6+",
            "Kb4",
            "Qb6+",
            "Kc3",
            "Qxb3+",
            "Kd4",
            "Qb6",
            "h3",
            "Qd6+",
            "Kc3",
            "Qe5#",
            "Qxe5+",
            "Nxe5",
            "Kxb2",
            "gxh3",
            "Kc3",
            "h4",
            "Kd4",
            "Nf3+",
            "Kd5",
            "h5",
            "Ke6",
            "h6",
            "Kf7",
            "Ng5+",
            "Kg6",
            "h7",
            "Kg7",
            "Ke3",
            "Kh8",
            "Ke4",
            "Kg7",
            "Kd5",
            "Kh8",
            "Kxc5",
            "Kg7",
            "d4",
            "Kh8",
            "d5",
            "Kg7",
            "d6",
            "Kh8",
            "d7",
            "Kg7",
            "d8=Q",
            "Kh6",
            "h8=Q+",
            "Kg6",
            "Qdf6#",
            "Qxf6",
            "Qxf6+",
            "Kxf6",
            "Ne4+",
            "Ke5",
            "h4",
            "Kf4",
            "h5",
            "Kf5",
            "Kd5",
            "Kg4",
            "h6",
            "Kh5",
            "h7",
            "Kg6",
            "h8=Q",
            "Kf7",
            "Qf6+",
            "Kg8",
            "Qe7",
            "Kh8",
            "Ke6",
            "Kg8",
            "Nf6+",
            "Kh8",
            "Qh7#",
            "Qxf6+",
            "Kxf6",
            "c5",
            "Qg7#",
            "Qxf6+",
            "Kxf6",
            "c4",
            "Kg6",
            "cxd3",
            "Qf8#",
            "Qxf6+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4e2",
          "positional_uci": "g4e2",
          "neutral_uci": "g4e2",
          "consensus_move": "g4e2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "d3",
              "O-O-O",
              "Qxe7",
              "Rhe8",
              "Qxf7",
              "Rd7",
              "Qb3",
              "Rde7",
              "Be3",
              "Ng4",
              "Nd2",
              "Nxe3+",
              "fxe3",
              "Rxe3",
              "Ne4",
              "Rf8+",
              "Kg1",
              "Re2",
              "Qe6+",
              "Kb8",
              "Qe7",
              "Rf4",
              "Qxg7",
              "Rxc2",
              "Qxh7",
              "Rxb2",
              "Qh8+",
              "Ka7",
              "Qxb2",
              "Rf5",
              "Rb1",
              "Rb5",
              "Qd4+",
              "b6",
              "Rxb5",
              "axb5",
              "Qd7",
              "Kb7",
              "Nd6+",
              "Ka6",
              "Qxc6",
              "Ka5",
              "Qxb5#",
              "Qd4+",
              "Nxd4",
              "Nf3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "d3",
              "O-O-O",
              "Bg5",
              "Rhe8",
              "Bxf6",
              "Bxf6",
              "Qg4+",
              "Kb8",
              "Nc3",
              "Rd4",
              "Qf3",
              "Rb4",
              "Re1",
              "Rd8",
              "Ne4",
              "Bxb2",
              "Rb1",
              "Ba3",
              "Rxb4",
              "Bxb4",
              "Qxf7",
              "Rd5",
              "Qxg7",
              "Ra5",
              "Qg8+",
              "Ka7",
              "Qb3",
              "c5",
              "c3",
              "Ra3",
              "Qxa3",
              "Bxa3",
              "Ke2",
              "b5",
              "Rb1",
              "b4",
              "cxb4",
              "cxb4",
              "Nc5",
              "Kb6",
              "Nb3",
              "a5",
              "f4",
              "a4",
              "Nd4",
              "Kc5",
              "Nc2",
              "b3",
              "axb3",
              "axb3",
              "Nxa3",
              "Kb4",
              "Nc4",
              "Kc3",
              "f5",
              "Kc2",
              "Rb2+",
              "Kc3",
              "f6",
              "c5",
              "f7",
              "h5",
              "f8=Q",
              "h4",
              "Qf6+",
              "Kb4",
              "Qb6+",
              "Kc3",
              "Qxb3+",
              "Kd4",
              "Qb6",
              "h3",
              "Qd6+",
              "Kc3",
              "Qe5#",
              "Qxe5+",
              "Nxe5",
              "Kxb2",
              "gxh3",
              "Kc3",
              "h4",
              "Kd4",
              "Nf3+",
              "Kd5",
              "h5",
              "Ke6",
              "h6",
              "Kf7",
              "Ng5+",
              "Kg6",
              "h7",
              "Kg7",
              "Ke3",
              "Kh8",
              "Ke4",
              "Kg7",
              "Kd5",
              "Kh8",
              "Kxc5",
              "Kg7",
              "d4",
              "Kh8",
              "d5",
              "Kg7",
              "d6",
              "Kh8",
              "d7",
              "Kg7",
              "d8=Q",
              "Kh6",
              "h8=Q+",
              "Kg6",
              "Qdf6#",
              "Qxf6",
              "Qxf6+",
              "Kxf6",
              "Ne4+",
              "Ke5",
              "h4",
              "Kf4",
              "h5",
              "Kf5",
              "Kd5",
              "Kg4",
              "h6",
              "Kh5",
              "h7",
              "Kg6",
              "h8=Q",
              "Kf7",
              "Qf6+",
              "Kg8",
              "Qe7",
              "Kh8",
              "Ke6",
              "Kg8",
              "Nf6+",
              "Kh8",
              "Qh7#",
              "Qxf6+",
              "Kxf6",
              "c5",
              "Qg7#",
              "Qxf6+",
              "Kxf6",
              "c4",
              "Kg6",
              "cxd3",
              "Qf8#",
              "Qxf6+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 189,
            "completion_tokens": 207,
            "total_tokens": 396,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 189,
            "completion_tokens": 226,
            "total_tokens": 415,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 566,
          "total_completion_tokens": 1073,
          "total_tokens": 1639
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 189,
            "completion_tokens": 207,
            "total_tokens": 396,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 189,
            "completion_tokens": 226,
            "total_tokens": 415,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r3kb1r/1pp2ppp/p1p2n2/8/6Q1/8/PPPP1PPP/RNB2K1R w kq - 1 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d3",
          "aggressive_uci": "d2d3",
          "aggressive_response": "11. d3 O-O-O 12. Qxe7 Rhe8 13. Qxf7 Rd7 14. Qc4 Rde7 15. Be3 Nd5 16. Nc3 Nxe3+ 17. fxe3 Rxe3 18. Qg4+ Kb8 19. Qxg7 R3e7 20. Qg4 Rf8+ 21. Kg1 Ref7 22. h3 Rf4 23. Qg3 R4f7 24. Kh2 Rf6 25. Rhe1 Rg6 26. Qe3 Rfg8 27. Re2 Rg3 28. Qxg3 Rxg3 29. Kxg3 Ka7 30. Re7 Kb6 31. Rxh7 Kc5 32. Rxc7 Kd4 33. Rxb7 Ke3 34. Rb6 Kd2 35. Rxc6 Kxc2 36. Rxa6 Kxb2 37. Rb1+ Kxc3 38. Rc6+ Kxd3 39. Rd1+ Ke4 40. Re6+ Kf5 41. Re8 Kf6 42. Rf1+ Kg7 43. Re4 Kg6 44. Rg4+ Kh5 45. Rf8 Kh6 46. Rh8# e4 Nf6+ Kg5",
          "aggressive_tokens": {
            "prompt_tokens": 198,
            "completion_tokens": 317,
            "total_tokens": 515,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O-O",
            "Qxe7",
            "Rhe8",
            "Qxf7",
            "Rd7",
            "Qc4",
            "Rde7",
            "Be3",
            "Nd5",
            "Nc3",
            "Nxe3+",
            "fxe3",
            "Rxe3",
            "Qg4+",
            "Kb8",
            "Qxg7",
            "R3e7",
            "Qg4",
            "Rf8+",
            "Kg1",
            "Ref7",
            "h3",
            "Rf4",
            "Qg3",
            "R4f7",
            "Kh2",
            "Rf6",
            "Rhe1",
            "Rg6",
            "Qe3",
            "Rfg8",
            "Re2",
            "Rg3",
            "Qxg3",
            "Rxg3",
            "Kxg3",
            "Ka7",
            "Re7",
            "Kb6",
            "Rxh7",
            "Kc5",
            "Rxc7",
            "Kd4",
            "Rxb7",
            "Ke3",
            "Rb6",
            "Kd2",
            "Rxc6",
            "Kxc2",
            "Rxa6",
            "Kxb2",
            "Rb1+",
            "Kxc3",
            "Rc6+",
            "Kxd3",
            "Rd1+",
            "Ke4",
            "Re6+",
            "Kf5",
            "Re8",
            "Kf6",
            "Rf1+",
            "Kg7",
            "Re4",
            "Kg6",
            "Rg4+",
            "Kh5",
            "Rf8",
            "Kh6",
            "Rh8#",
            "e4",
            "Nf6+",
            "Kg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d3",
          "positional_uci": "d2d3",
          "positional_response": "11. d3 O-O 12. Qxe7 Rfe8 13. Qxc7 Rac8 14. Qxb7 Rb8 15. Qxa6 Ra8 16. Qxc6 Rac8 17. Qa4 Ra8 18. Qb3 Rab8 19. Qc3 Rbc8 20. Qd2 Rcd8 21. Nc3 Rc8 22. Qf4 Rcd8 23. Be3 Rc8 24. Re1 Rcd8 25. Bd4 Rc8 26. Rxe8+ Rxe8 27. Bxf6 gxf6 28. Qxf6 Re6 29. Qxe6 fxe6 30. Ke2 Kf7 31. Ke3 Ke7 32. Ke4 Kd6 33. d4 Ke7 34. Ke5 Kd7 35. d5 Ke7 36. dxe6 Ke8 37. Kf6 Kf8 38. e7+ Ke8 39. Ke6 h5 40. Nd5 h4 41. Nc7# e5 e4 dxe4",
          "positional_tokens": {
            "prompt_tokens": 198,
            "completion_tokens": 256,
            "total_tokens": 454,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Qxe7",
            "Rfe8",
            "Qxc7",
            "Rac8",
            "Qxb7",
            "Rb8",
            "Qxa6",
            "Ra8",
            "Qxc6",
            "Rac8",
            "Qa4",
            "Ra8",
            "Qb3",
            "Rab8",
            "Qc3",
            "Rbc8",
            "Qd2",
            "Rcd8",
            "Nc3",
            "Rc8",
            "Qf4",
            "Rcd8",
            "Be3",
            "Rc8",
            "Re1",
            "Rcd8",
            "Bd4",
            "Rc8",
            "Rxe8+",
            "Rxe8",
            "Bxf6",
            "gxf6",
            "Qxf6",
            "Re6",
            "Qxe6",
            "fxe6",
            "Ke2",
            "Kf7",
            "Ke3",
            "Ke7",
            "Ke4",
            "Kd6",
            "d4",
            "Ke7",
            "Ke5",
            "Kd7",
            "d5",
            "Ke7",
            "dxe6",
            "Ke8",
            "Kf6",
            "Kf8",
            "e7+",
            "Ke8",
            "Ke6",
            "h5",
            "Nd5",
            "h4",
            "Nc7#",
            "e5",
            "e4",
            "dxe4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d3",
          "neutral_uci": "d2d3",
          "neutral_response": "11. d3 O-O 12. Qxe7 Rfe8 13. Qxc7 Rac8 14. Qxb7 Rb8 15. Qxc6 Rbc8 16. Qxa6 Ra8\n17. Qc4 Rac8 18. Qb3 Rb8 19. Qa3 Ra8 20. Qc5 Rac8 21. Qf5 Rxc2 22. Nc3 Rc8\n23. Qxc8+ Ne8 24. Qxe8# Qxe8 25. Be3 Rxb2 26. Re1 Qc8 27. Bd4 Qd8 28. Nd5 Rxa2\n29. Ne7+ Kh8 30. Nf5 Kg8 31. Nxg7 Qxd4 32. Nf5 Qxf2# Qxf2+ 34. Nxf2",
          "neutral_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 196,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Qxe7",
            "Rfe8",
            "Qxc7",
            "Rac8",
            "Qxb7",
            "Rb8",
            "Qxc6",
            "Rbc8",
            "Qxa6",
            "Ra8",
            "Qc4",
            "Rac8",
            "Qb3",
            "Rb8",
            "Qa3",
            "Ra8",
            "Qc5",
            "Rac8",
            "Qf5",
            "Rxc2",
            "Nc3",
            "Rc8",
            "Qxc8+",
            "Ne8",
            "Qxe8#",
            "Qxe8",
            "Be3",
            "Rxb2",
            "Re1",
            "Qc8",
            "Bd4",
            "Qd8",
            "Nd5",
            "Rxa2",
            "Ne7+",
            "Kh8",
            "Nf5",
            "Kg8",
            "Nxg7",
            "Qxd4",
            "Nf5",
            "Qxf2#",
            "Qxf2+",
            "Nxf2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d3",
          "positional_uci": "d2d3",
          "neutral_uci": "d2d3",
          "consensus_move": "d2d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O-O",
              "Qxe7",
              "Rhe8",
              "Qxf7",
              "Rd7",
              "Qc4",
              "Rde7",
              "Be3",
              "Nd5",
              "Nc3",
              "Nxe3+",
              "fxe3",
              "Rxe3",
              "Qg4+",
              "Kb8",
              "Qxg7",
              "R3e7",
              "Qg4",
              "Rf8+",
              "Kg1",
              "Ref7",
              "h3",
              "Rf4",
              "Qg3",
              "R4f7",
              "Kh2",
              "Rf6",
              "Rhe1",
              "Rg6",
              "Qe3",
              "Rfg8",
              "Re2",
              "Rg3",
              "Qxg3",
              "Rxg3",
              "Kxg3",
              "Ka7",
              "Re7",
              "Kb6",
              "Rxh7",
              "Kc5",
              "Rxc7",
              "Kd4",
              "Rxb7",
              "Ke3",
              "Rb6",
              "Kd2",
              "Rxc6",
              "Kxc2",
              "Rxa6",
              "Kxb2",
              "Rb1+",
              "Kxc3",
              "Rc6+",
              "Kxd3",
              "Rd1+",
              "Ke4",
              "Re6+",
              "Kf5",
              "Re8",
              "Kf6",
              "Rf1+",
              "Kg7",
              "Re4",
              "Kg6",
              "Rg4+",
              "Kh5",
              "Rf8",
              "Kh6",
              "Rh8#",
              "e4",
              "Nf6+",
              "Kg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Qxe7",
              "Rfe8",
              "Qxc7",
              "Rac8",
              "Qxb7",
              "Rb8",
              "Qxa6",
              "Ra8",
              "Qxc6",
              "Rac8",
              "Qa4",
              "Ra8",
              "Qb3",
              "Rab8",
              "Qc3",
              "Rbc8",
              "Qd2",
              "Rcd8",
              "Nc3",
              "Rc8",
              "Qf4",
              "Rcd8",
              "Be3",
              "Rc8",
              "Re1",
              "Rcd8",
              "Bd4",
              "Rc8",
              "Rxe8+",
              "Rxe8",
              "Bxf6",
              "gxf6",
              "Qxf6",
              "Re6",
              "Qxe6",
              "fxe6",
              "Ke2",
              "Kf7",
              "Ke3",
              "Ke7",
              "Ke4",
              "Kd6",
              "d4",
              "Ke7",
              "Ke5",
              "Kd7",
              "d5",
              "Ke7",
              "dxe6",
              "Ke8",
              "Kf6",
              "Kf8",
              "e7+",
              "Ke8",
              "Ke6",
              "h5",
              "Nd5",
              "h4",
              "Nc7#",
              "e5",
              "e4",
              "dxe4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Qxe7",
              "Rfe8",
              "Qxc7",
              "Rac8",
              "Qxb7",
              "Rb8",
              "Qxc6",
              "Rbc8",
              "Qxa6",
              "Ra8",
              "Qc4",
              "Rac8",
              "Qb3",
              "Rb8",
              "Qa3",
              "Ra8",
              "Qc5",
              "Rac8",
              "Qf5",
              "Rxc2",
              "Nc3",
              "Rc8",
              "Qxc8+",
              "Ne8",
              "Qxe8#",
              "Qxe8",
              "Be3",
              "Rxb2",
              "Re1",
              "Qc8",
              "Bd4",
              "Qd8",
              "Nd5",
              "Rxa2",
              "Ne7+",
              "Kh8",
              "Nf5",
              "Kg8",
              "Nxg7",
              "Qxd4",
              "Nf5",
              "Qxf2#",
              "Qxf2+",
              "Nxf2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 198,
            "completion_tokens": 317,
            "total_tokens": 515,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 198,
            "completion_tokens": 256,
            "total_tokens": 454,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 197,
            "completion_tokens": 196,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 593,
          "total_completion_tokens": 769,
          "total_tokens": 1362
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 198,
            "completion_tokens": 317,
            "total_tokens": 515,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 198,
            "completion_tokens": 256,
            "total_tokens": 454,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 197,
            "completion_tokens": 196,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3k2r/1pp1bppp/p1p2n2/8/8/8/PPPPQPPP/RNB2K1R w kq - 3 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe7",
          "aggressive_uci": "e2e7",
          "aggressive_response": "12. Qxe7 Rfe8 13. Qxc7 Rac8 14. Qxb7 Rb8 15. Qxc6 Rbc8 16. Qxa6 Ra8 17. Qc4 Rac8\n18. Qb3 Rb8 19. Qa3 Ra8 20. Qc3 Rac8 21. Qd2 Rcd8 22. Nc3 Rc8 23. Qg5 h6 24. Qg3\nNh5 25. Qg4 Nf6 26. Qg3 Nh5 27. Qh4 Nf6 28. Bxh6 gxh6 29. Qxf6 Re6 30. Qf5 Rce8\n31. Ne4 Re5 32. Nf6+ Kf8 33. Qh7 Ke7 34. Nxe8 Kxe8 35. Qh8+ Ke7 36. Qxe5+ Kf8\n37. Qh8+ Ke7 38. Qxh6 f6 39. Re1+ Kf7 40. Qh7+ Kf8 41. Qe7+ Kg8 42. Qxf6 Kh7\n43. Re7+ Kg8 44. Qg7# Qxe7 45. Qxe7 Kh8 46. Qf8+ Kh7 47. Qf7+ Kh8 48. Qf6+ Kh7\n49. Qf5+ Kh8 50. Qh5+ Kg7 51. Qg5+ Kh8 52. Qh6+ Kg8 53. Qg6+ Kh8 54. Qh6+ Kg8\n55. Qg6+ Kh8 56. Qh6+ Kg8 57. Qg6+ Kh8 58. Qh6+ Kg8 59. Qg6+ Kh8 60. Qh6+ Kg8\n61. Qg6+ Kh8 62. Qh6+ Kg8 63. Qg6+ Kh8 64. Qh6+ Kg8 65. Qg6+ Kh8 66. Qh6+ Kg8\n67. Qg6+ Kh8 68. Qh6+ Kg8 69. Qg6+ Kh8 70. Qh6+ Kg8 71. Qg6+ Kh8 72. Qh6+ Kg8\n73. Qg6+ Kh8 74. Qh6+ Kg8 75. Qg6+ Kh8 76. Qh6+ Kg8 77. Qg6+ Kh8 78. Qh6+ Kg8\n79. Qg6+ Kh8 80. Qh6+ Kg8 81. Qg6+ Kh8 82. Qh6+ Kg8 83. Qg6+ Kh8 84",
          "aggressive_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 640,
            "total_tokens": 845,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf7+",
            "Kh8",
            "Qf6+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qh5+",
            "Kg7",
            "Qg5+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe7",
          "positional_uci": "e2e7",
          "positional_response": "12. Qxe7 Rae8 13. Qxc7 Nd5 14. Qxb7 Re7 15. Qxc6 Rfe8 16. Bd2 Nb4 17. Bxb4 Re6\n18. Qc4 a5 19. Bxa5 Ra8 20. Qd5 Rae8 21. Nc3 Re5 22. Qd7 R5e7 23. Qd4 Re5\n24. Bb4 R5e6 25. Ne4 f5 26. Ng5 Re5 27. Qc4+ Kh8 28. Nf7+ Kg8 29. Nxe5+ Kh8\n30. Nf7+ Kg8 31. Nh6+ Kh8 32. Qg8+ Rxg8 33. Nf7#",
          "positional_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 183,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qxc7",
            "Nd5",
            "Qxb7",
            "Re7",
            "Qxc6",
            "Rfe8",
            "Bd2",
            "Nb4",
            "Bxb4",
            "Re6",
            "Qc4",
            "a5",
            "Bxa5",
            "Ra8",
            "Qd5",
            "Rae8",
            "Nc3",
            "Re5",
            "Qd7",
            "R5e7",
            "Qd4",
            "Re5",
            "Bb4",
            "R5e6",
            "Ne4",
            "f5",
            "Ng5",
            "Re5",
            "Qc4+",
            "Kh8",
            "Nf7+",
            "Kg8",
            "Nxe5+",
            "Kh8",
            "Nf7+",
            "Kg8",
            "Nh6+",
            "Kh8",
            "Qg8+",
            "Rxg8",
            "Nf7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe7",
          "neutral_uci": "e2e7",
          "neutral_response": "12. Qxe7 Rfe8 13. Qxc7 Rac8 14. Qxb7 Rb8 15. Qxc6 Rbc8 16. Qxa6 Ra8 17. Qc4 Rac8\n18. Qb3 Rb8 19. Qa3 Ra8 20. Qc3 Rac8 21. Qd2 Rcd8 22. Nc3 Rc8 23. Qf4 Rcd8 24. Be3 Rc8\n25. Re1 Rcd8 26. Bd4 Rc8 27. Rxe8+ Rxe8 28. Bxf6 gxf6 29. Qxf6 Rf8 30. Nd5 Re8 31. Ne7+ Kf8\n32. Nf5 Re6 33. Qh8# Rxe7 34. Qh8# Rxe7 35. Qxh7# Rxe7 36. Qh8# Rxe7 37. Qxh7# Rxe7 38. Qh8# Rxe7 39. Qxh7# Rxe7 40. Qh8# Rxe7 41. Qxh7# Rxe7 42. Qh8# Rxe7 43. Qxh7# Rxe7 44. Qh8# Rxe7 45. Qxh7# Rxe7 46. Qh8# Rxe7 47. Qxh7# Rxe7 48. Qh8# Rxe7 49. Qxh7# Rxe7 50. Qh8# Rxe7 51. Qxh7# Rxe7 52. Qh8# Rxe7 53. Qxh7# Rxe7 54. Qh8# Rxe7 55. Qxh7# Rxe7 56. Qh8# Rxe7 57. Qxh7# Rxe7 58. Qh8# Rxe7 59. Qxh7# Rxe7 60. Qh8# Rxe7 61. Qxh7# Rxe7 62. Qh8# Rxe7 63. Qxh7# Rxe7 64. Qh8# Rxe7 65. Qxh7# Rxe7 66. Qh8# Rxe7 67. Qxh7# Rxe7 68. Qh8# Rxe7 69. Qxh7# Rxe7 70. Qh8# Rxe7 71. Qxh7# Rxe7 72. Qh8# Rxe7 73. Qxh7# Rxe7 74. Qh8# Rxe7 75. Qxh7# Rxe7 76. Qh8# Rxe7 77.",
          "neutral_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 640,
            "total_tokens": 844,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rfe8",
            "Qxc7",
            "Rac8",
            "Qxb7",
            "Rb8",
            "Qxc6",
            "Rbc8",
            "Qxa6",
            "Ra8",
            "Qc4",
            "Rac8",
            "Qb3",
            "Rb8",
            "Qa3",
            "Ra8",
            "Qc3",
            "Rac8",
            "Qd2",
            "Rcd8",
            "Nc3",
            "Rc8",
            "Qf4",
            "Rcd8",
            "Be3",
            "Rc8",
            "Re1",
            "Rcd8",
            "Bd4",
            "Rc8",
            "Rxe8+",
            "Rxe8",
            "Bxf6",
            "gxf6",
            "Qxf6",
            "Rf8",
            "Nd5",
            "Re8",
            "Ne7+",
            "Kf8",
            "Nf5",
            "Re6",
            "Qh8#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e7",
          "positional_uci": "e2e7",
          "neutral_uci": "e2e7",
          "consensus_move": "e2e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf7+",
              "Kh8",
              "Qf6+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qh5+",
              "Kg7",
              "Qg5+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rae8",
              "Qxc7",
              "Nd5",
              "Qxb7",
              "Re7",
              "Qxc6",
              "Rfe8",
              "Bd2",
              "Nb4",
              "Bxb4",
              "Re6",
              "Qc4",
              "a5",
              "Bxa5",
              "Ra8",
              "Qd5",
              "Rae8",
              "Nc3",
              "Re5",
              "Qd7",
              "R5e7",
              "Qd4",
              "Re5",
              "Bb4",
              "R5e6",
              "Ne4",
              "f5",
              "Ng5",
              "Re5",
              "Qc4+",
              "Kh8",
              "Nf7+",
              "Kg8",
              "Nxe5+",
              "Kh8",
              "Nf7+",
              "Kg8",
              "Nh6+",
              "Kh8",
              "Qg8+",
              "Rxg8",
              "Nf7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rfe8",
              "Qxc7",
              "Rac8",
              "Qxb7",
              "Rb8",
              "Qxc6",
              "Rbc8",
              "Qxa6",
              "Ra8",
              "Qc4",
              "Rac8",
              "Qb3",
              "Rb8",
              "Qa3",
              "Ra8",
              "Qc3",
              "Rac8",
              "Qd2",
              "Rcd8",
              "Nc3",
              "Rc8",
              "Qf4",
              "Rcd8",
              "Be3",
              "Rc8",
              "Re1",
              "Rcd8",
              "Bd4",
              "Rc8",
              "Rxe8+",
              "Rxe8",
              "Bxf6",
              "gxf6",
              "Qxf6",
              "Rf8",
              "Nd5",
              "Re8",
              "Ne7+",
              "Kf8",
              "Nf5",
              "Re6",
              "Qh8#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 205,
            "completion_tokens": 640,
            "total_tokens": 845,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 205,
            "completion_tokens": 183,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 204,
            "completion_tokens": 640,
            "total_tokens": 844,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 614,
          "total_completion_tokens": 1463,
          "total_tokens": 2077
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 205,
            "completion_tokens": 640,
            "total_tokens": 845,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 205,
            "completion_tokens": 183,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 204,
            "completion_tokens": 640,
            "total_tokens": 844,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r4rk1/1pp1bppp/p1p2n2/8/8/3P4/PPP1QPPP/RNB2K1R w - - 1 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe2",
          "aggressive_uci": "e7e2",
          "aggressive_response": "13. Qe2 Rae8 14. Qd1 Re6 15. Nc3 Rfe8 16. Nxd5 cxd5 17. Be3 c5 18. Bxc5 b6 19. Be3 d4 20. Bxd4 b5 21. Qg4 g6 22. Qh4 h5 23. Qg5 Kh7 24. g4 hxg4 25. Qh4+ Kg8 26. Qh8# e4 Nxe4 dxe4",
          "aggressive_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 120,
            "total_tokens": 333,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qd1",
            "Re6",
            "Nc3",
            "Rfe8",
            "Nxd5",
            "cxd5",
            "Be3",
            "c5",
            "Bxc5",
            "b6",
            "Be3",
            "d4",
            "Bxd4",
            "b5",
            "Qg4",
            "g6",
            "Qh4",
            "h5",
            "Qg5",
            "Kh7",
            "g4",
            "hxg4",
            "Qh4+",
            "Kg8",
            "Qh8#",
            "e4",
            "Nxe4",
            "dxe4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe2",
          "positional_uci": "e7e2",
          "positional_response": "13. Qe2 Rae8 14. Qd1 Re6 15. Nc3 Rfe8 16. Nxd5 cxd5 17. Be3 c5 18. Bxc5 b6 19. Be3 d4 20. Bxd4 Rd6 21. Be3 Rde6 22. Qd2 f5 23. Re1 f4 24. Bxf4 Rxe1+ 25. Qxe1 Rxe1+ 26. Kxe1 Kf7 27. Kd2 Ke6 28. Re1+ Kf5 29. Be3 g5 30. Bxb6 h5 31. Re4 g4 32. Ra4 h4 33. Rxa6 g3 34. fxg3 hxg3 35. hxg3 Kg4 36. Bc7 Kf5 37. Ra4 Ke6 38. Rf4 Kd7 39. Ba5 Kc6 40. Bc3 Kd5 41. g4 Ke6 42. g5 Kd5 43. g6 Ke6 44. g7 Kd5 45. g8=Q+ Kc6 46. Qg5 Kd7 47. Rf6 Ke8 48. Qg7 Kd8 49. Rf8# e4 50. dxe4 Ke8 51. e5 Kd8 52. e6 Ke8 53. Qf7# e3+ 54. Kxe3",
          "positional_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 344,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qd1",
            "Re6",
            "Nc3",
            "Rfe8",
            "Nxd5",
            "cxd5",
            "Be3",
            "c5",
            "Bxc5",
            "b6",
            "Be3",
            "d4",
            "Bxd4",
            "Rd6",
            "Be3",
            "Rde6",
            "Qd2",
            "f5",
            "Re1",
            "f4",
            "Bxf4",
            "Rxe1+",
            "Qxe1",
            "Rxe1+",
            "Kxe1",
            "Kf7",
            "Kd2",
            "Ke6",
            "Re1+",
            "Kf5",
            "Be3",
            "g5",
            "Bxb6",
            "h5",
            "Re4",
            "g4",
            "Ra4",
            "h4",
            "Rxa6",
            "g3",
            "fxg3",
            "hxg3",
            "hxg3",
            "Kg4",
            "Bc7",
            "Kf5",
            "Ra4",
            "Ke6",
            "Rf4",
            "Kd7",
            "Ba5",
            "Kc6",
            "Bc3",
            "Kd5",
            "g4",
            "Ke6",
            "g5",
            "Kd5",
            "g6",
            "Ke6",
            "g7",
            "Kd5",
            "g8=Q+",
            "Kc6",
            "Qg5",
            "Kd7",
            "Rf6",
            "Ke8",
            "Qg7",
            "Kd8",
            "Rf8#",
            "e4",
            "dxe4",
            "Ke8",
            "e5",
            "Kd8",
            "e6",
            "Ke8",
            "Qf7#",
            "e3+",
            "Kxe3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe2",
          "neutral_uci": "e7e2",
          "neutral_response": "13. Qe2 Rae8 14. Qd1 Re6 15. Nc3 Rfe8 16. Nxd5 cxd5 17. Be3 c5 18. Bxc5 b6 19. Be3 d4 20. Bxd4 Rd6 21. Be3 Rde6 22. Qd2 f5 23. Re1 f4 24. Bxf4 Rxe1+ 25. Qxe1 Rxe1+ 26. Kxe1 Kf7 27. Kd2 Ke6 28. Re1+ Kd5 29. Re5+ Kd6 30. Rg5+ Ke6 31. Rxg7 Kf6 32. Rxh7 Kg6 33. Rh6+ Kf5 34. Rxb6 Kxf4 35. Rxa6 Ke5 36. Ra4 Kd5 37. Re4 Kc5 38. f4 Kd5 39. f5 Kd6 40. f6 Kd5 41. f7 Kd6 42. f8=Q+ Kd5 43. Qf5+ Kd6 44. Re6+ Kd7 45. Qf7+ Kd8 46. Re8# e4 47. Qe7# e5 48. Qxe5# e6",
          "neutral_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 308,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qd1",
            "Re6",
            "Nc3",
            "Rfe8",
            "Nxd5",
            "cxd5",
            "Be3",
            "c5",
            "Bxc5",
            "b6",
            "Be3",
            "d4",
            "Bxd4",
            "Rd6",
            "Be3",
            "Rde6",
            "Qd2",
            "f5",
            "Re1",
            "f4",
            "Bxf4",
            "Rxe1+",
            "Qxe1",
            "Rxe1+",
            "Kxe1",
            "Kf7",
            "Kd2",
            "Ke6",
            "Re1+",
            "Kd5",
            "Re5+",
            "Kd6",
            "Rg5+",
            "Ke6",
            "Rxg7",
            "Kf6",
            "Rxh7",
            "Kg6",
            "Rh6+",
            "Kf5",
            "Rxb6",
            "Kxf4",
            "Rxa6",
            "Ke5",
            "Ra4",
            "Kd5",
            "Re4",
            "Kc5",
            "f4",
            "Kd5",
            "f5",
            "Kd6",
            "f6",
            "Kd5",
            "f7",
            "Kd6",
            "f8=Q+",
            "Kd5",
            "Qf5+",
            "Kd6",
            "Re6+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Re8#",
            "e4",
            "Qe7#",
            "e5",
            "Qxe5#",
            "e6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e2",
          "positional_uci": "e7e2",
          "neutral_uci": "e7e2",
          "consensus_move": "e7e2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rae8",
              "Qd1",
              "Re6",
              "Nc3",
              "Rfe8",
              "Nxd5",
              "cxd5",
              "Be3",
              "c5",
              "Bxc5",
              "b6",
              "Be3",
              "d4",
              "Bxd4",
              "b5",
              "Qg4",
              "g6",
              "Qh4",
              "h5",
              "Qg5",
              "Kh7",
              "g4",
              "hxg4",
              "Qh4+",
              "Kg8",
              "Qh8#",
              "e4",
              "Nxe4",
              "dxe4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rae8",
              "Qd1",
              "Re6",
              "Nc3",
              "Rfe8",
              "Nxd5",
              "cxd5",
              "Be3",
              "c5",
              "Bxc5",
              "b6",
              "Be3",
              "d4",
              "Bxd4",
              "Rd6",
              "Be3",
              "Rde6",
              "Qd2",
              "f5",
              "Re1",
              "f4",
              "Bxf4",
              "Rxe1+",
              "Qxe1",
              "Rxe1+",
              "Kxe1",
              "Kf7",
              "Kd2",
              "Ke6",
              "Re1+",
              "Kf5",
              "Be3",
              "g5",
              "Bxb6",
              "h5",
              "Re4",
              "g4",
              "Ra4",
              "h4",
              "Rxa6",
              "g3",
              "fxg3",
              "hxg3",
              "hxg3",
              "Kg4",
              "Bc7",
              "Kf5",
              "Ra4",
              "Ke6",
              "Rf4",
              "Kd7",
              "Ba5",
              "Kc6",
              "Bc3",
              "Kd5",
              "g4",
              "Ke6",
              "g5",
              "Kd5",
              "g6",
              "Ke6",
              "g7",
              "Kd5",
              "g8=Q+",
              "Kc6",
              "Qg5",
              "Kd7",
              "Rf6",
              "Ke8",
              "Qg7",
              "Kd8",
              "Rf8#",
              "e4",
              "dxe4",
              "Ke8",
              "e5",
              "Kd8",
              "e6",
              "Ke8",
              "Qf7#",
              "e3+",
              "Kxe3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rae8",
              "Qd1",
              "Re6",
              "Nc3",
              "Rfe8",
              "Nxd5",
              "cxd5",
              "Be3",
              "c5",
              "Bxc5",
              "b6",
              "Be3",
              "d4",
              "Bxd4",
              "Rd6",
              "Be3",
              "Rde6",
              "Qd2",
              "f5",
              "Re1",
              "f4",
              "Bxf4",
              "Rxe1+",
              "Qxe1",
              "Rxe1+",
              "Kxe1",
              "Kf7",
              "Kd2",
              "Ke6",
              "Re1+",
              "Kd5",
              "Re5+",
              "Kd6",
              "Rg5+",
              "Ke6",
              "Rxg7",
              "Kf6",
              "Rxh7",
              "Kg6",
              "Rh6+",
              "Kf5",
              "Rxb6",
              "Kxf4",
              "Rxa6",
              "Ke5",
              "Ra4",
              "Kd5",
              "Re4",
              "Kc5",
              "f4",
              "Kd5",
              "f5",
              "Kd6",
              "f6",
              "Kd5",
              "f7",
              "Kd6",
              "f8=Q+",
              "Kd5",
              "Qf5+",
              "Kd6",
              "Re6+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Re8#",
              "e4",
              "Qe7#",
              "e5",
              "Qxe5#",
              "e6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 213,
            "completion_tokens": 120,
            "total_tokens": 333,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 213,
            "completion_tokens": 344,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 212,
            "completion_tokens": 308,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 638,
          "total_completion_tokens": 772,
          "total_tokens": 1410
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 213,
            "completion_tokens": 120,
            "total_tokens": 333,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 213,
            "completion_tokens": 344,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 212,
            "completion_tokens": 308,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp1Qppp/p1p5/3n4/8/3P4/PPP2PPP/RNB2K1R w - - 1 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf4",
          "aggressive_uci": "c1f4",
          "aggressive_response": "14. Bxf4 Rfe8 15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 h5 19. Qxh5 g6 20. Qh6 f5 21. Be5 Kf7 22. Qg7+ Ke6 23. Qf6+ Kd5 24. c4+ Kc5 25. Bd4+ Kb4 26. a3+ Kb3 27. Nd2+ Kc2 28. Rhc1# Qd8 29. Qxd8 b5 30. Qxc7 c5 31. Qxc5 b4 32. Qxb4 a5 33. Qc3# Qd8 34. Qxc2# Qd8 35. Qc3# Qd8",
          "aggressive_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 194,
            "total_tokens": 416,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rfe8",
            "Qg4",
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "h5",
            "Qxh5",
            "g6",
            "Qh6",
            "f5",
            "Be5",
            "Kf7",
            "Qg7+",
            "Ke6",
            "Qf6+",
            "Kd5",
            "c4+",
            "Kc5",
            "Bd4+",
            "Kb4",
            "a3+",
            "Kb3",
            "Nd2+",
            "Kc2",
            "Rhc1#",
            "Qd8",
            "Qxd8",
            "b5",
            "Qxc7",
            "c5",
            "Qxc5",
            "b4",
            "Qxb4",
            "a5",
            "Qc3#",
            "Qd8",
            "Qxc2#",
            "Qd8",
            "Qc3#",
            "Qd8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf4",
          "positional_uci": "c1f4",
          "positional_response": "14. Bxf4 Rae8 15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 f5 19. Qxf5 g6 20. Qe6+ Kg7 21. Be5+ Kh6 22. Qh3+ Kg5 23. f4# e5 d5 d4",
          "positional_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 89,
            "total_tokens": 311,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qg4",
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "f5",
            "Qxf5",
            "g6",
            "Qe6+",
            "Kg7",
            "Be5+",
            "Kh6",
            "Qh3+",
            "Kg5",
            "f4#",
            "e5",
            "d5",
            "d4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf4",
          "neutral_uci": "c1f4",
          "neutral_response": "14. Bxf4 Rfe8 15. Qd2 Re1+ 16. Qxe1 Re8 17. Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1",
          "neutral_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rfe8",
            "Qd2",
            "Re1+",
            "Qxe1",
            "Re8",
            "Qxe8#",
            "e4",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Bxc6",
            "dxc6",
            "Nxe5",
            "Qd4",
            "Nf3",
            "Qxe4+",
            "Kf1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1f4",
          "positional_uci": "c1f4",
          "neutral_uci": "c1f4",
          "consensus_move": "c1f4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rfe8",
              "Qg4",
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "h5",
              "Qxh5",
              "g6",
              "Qh6",
              "f5",
              "Be5",
              "Kf7",
              "Qg7+",
              "Ke6",
              "Qf6+",
              "Kd5",
              "c4+",
              "Kc5",
              "Bd4+",
              "Kb4",
              "a3+",
              "Kb3",
              "Nd2+",
              "Kc2",
              "Rhc1#",
              "Qd8",
              "Qxd8",
              "b5",
              "Qxc7",
              "c5",
              "Qxc5",
              "b4",
              "Qxb4",
              "a5",
              "Qc3#",
              "Qd8",
              "Qxc2#",
              "Qd8",
              "Qc3#",
              "Qd8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rae8",
              "Qg4",
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "f5",
              "Qxf5",
              "g6",
              "Qe6+",
              "Kg7",
              "Be5+",
              "Kh6",
              "Qh3+",
              "Kg5",
              "f4#",
              "e5",
              "d5",
              "d4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rfe8",
              "Qd2",
              "Re1+",
              "Qxe1",
              "Re8",
              "Qxe8#",
              "e4",
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Bxc6",
              "dxc6",
              "Nxe5",
              "Qd4",
              "Nf3",
              "Qxe4+",
              "Kf1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 222,
            "completion_tokens": 194,
            "total_tokens": 416,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 222,
            "completion_tokens": 89,
            "total_tokens": 311,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 665,
          "total_completion_tokens": 923,
          "total_tokens": 1588
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 222,
            "completion_tokens": 194,
            "total_tokens": 416,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 222,
            "completion_tokens": 89,
            "total_tokens": 311,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r4rk1/1pp2ppp/p1p5/8/5n2/3P4/PPP1QPPP/RNB2K1R w - - 3 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qg4",
          "aggressive_uci": "e2g4",
          "aggressive_response": "15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 g5 19. Qxg5+ Kf8 20. Be5\nf6 21. Qxf6+ Ke8 22. Qe6+ Kd8 23. Bf6# e4 Nf6 Qe7#",
          "aggressive_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 89,
            "total_tokens": 320,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Qxg5+",
            "Kf8",
            "Be5",
            "f6",
            "Qxf6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Bf6#",
            "e4",
            "Nf6",
            "Qe7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qg4",
          "positional_uci": "e2g4",
          "positional_response": "15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 g5 19. Qxg5+ Kf8 20. Qd8+ Kg7 21. Be5+ Kg6 22. Qf6+ Kh5 23. g4+ Kxg4 24. Rg1+ Kh3 25. Qh6# e5 Nxe5 Qg7#",
          "positional_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 107,
            "total_tokens": 338,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Qxg5+",
            "Kf8",
            "Qd8+",
            "Kg7",
            "Be5+",
            "Kg6",
            "Qf6+",
            "Kh5",
            "g4+",
            "Kxg4",
            "Rg1+",
            "Kh3",
            "Qh6#",
            "e5",
            "Nxe5",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qg4",
          "neutral_uci": "e2g4",
          "neutral_response": "15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 g5 19. Qxg5+ Kf8 20. Qd8+ Kg7\n21. Be5+ Kg6 22. Qf6+ Kh5 23. g4+ Kxg4 24. Rg1+ Kh3 25. Qh6# e5 Nxe5 Qg7#",
          "neutral_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 107,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Qxg5+",
            "Kf8",
            "Qd8+",
            "Kg7",
            "Be5+",
            "Kg6",
            "Qf6+",
            "Kh5",
            "g4+",
            "Kxg4",
            "Rg1+",
            "Kh3",
            "Qh6#",
            "e5",
            "Nxe5",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2g4",
          "positional_uci": "e2g4",
          "neutral_uci": "e2g4",
          "consensus_move": "e2g4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Qxg5+",
              "Kf8",
              "Be5",
              "f6",
              "Qxf6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Bf6#",
              "e4",
              "Nf6",
              "Qe7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Qxg5+",
              "Kf8",
              "Qd8+",
              "Kg7",
              "Be5+",
              "Kg6",
              "Qf6+",
              "Kh5",
              "g4+",
              "Kxg4",
              "Rg1+",
              "Kh3",
              "Qh6#",
              "e5",
              "Nxe5",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Qxg5+",
              "Kf8",
              "Qd8+",
              "Kg7",
              "Be5+",
              "Kg6",
              "Qf6+",
              "Kh5",
              "g4+",
              "Kxg4",
              "Rg1+",
              "Kh3",
              "Qh6#",
              "e5",
              "Nxe5",
              "Qg7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 231,
            "completion_tokens": 89,
            "total_tokens": 320,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 231,
            "completion_tokens": 107,
            "total_tokens": 338,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 230,
            "completion_tokens": 107,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 692,
          "total_completion_tokens": 303,
          "total_tokens": 995
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 231,
            "completion_tokens": 89,
            "total_tokens": 320,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 231,
            "completion_tokens": 107,
            "total_tokens": 338,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 230,
            "completion_tokens": 107,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2ppp/p1p5/8/5B2/3P4/PPP1QPPP/RN3K1R w - - 1 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxh5",
          "aggressive_uci": "g4h5",
          "aggressive_response": "16. Qxh5 g6 17. Qh6 Re6 18. Nc3 Rae8 19. Ne4 f5 20. Ng5 R6e7 21. Qxg6+ Rg7 22.\nQxe8# g5 23. Be5 Rxe8 24. Bxg7 Kxg7 25. Re1 Rf8 26. Ne6+ Kf7 27. Nxf8 Kxf8 28.\nRe5 Kf7 29. Rxf5+ Kg6 30. g4 b5 31. Kg2 a5 32. Re1 a4 33. Re6+ Kg7 34. Rxc6 b4\n35. Rxc7+ Kg6 36. Rc6+ Kg7 37. Rb5 b3 38. Rb7+ Kf8 39. Rc8# Kd8 40. Rh7 bxa2\n41. Ra8# Kxc8 42. Rh8+ Kb7 43. Rh7+ Kb6 44. Rh6+ Kb5 45. c4+ Kb4 46. Rb6+ Ka5\n47. Rb5+ Ka6 48. Rxg5 a1=Q 49. Rg6+ Kb7 50. Rg7+ Kc6 51. Rg6+ Kd7 52. Rg7+ Ke6\n53. Rg6+ Kf7 54. Rb6 Qd1 55. Rb7+ Ke6 56. Rb6+ Kd7 57. Rb7+ Kc6 58. Rg7 Qxd3\n59. Rg6+ Kc5 60. Rg5+ Kxc4 61. h4 Qe4+ 62. Kg3 Qd3+ 63. f3 Qd6+ 64. Kh3 Qd3\n65. Kg3 Qd6+ 66. Kh3 Qd3 67. Kg3 Qd6+ 68. Kh3 Qd3 69. Kg3 Qd6+ 70. Kh3 Qd3\n71. Kg3 Qd6+ 72. Kh3 Qd3 73. Kg3 Qd6+ 74. Kh3 Qd3 75. Kg3 Qd6+ 76. Kh3 Qd3\n77. Kg3 Qd6+ 78. Kh3 Qd3 79. Kg3 Qd6+ 80. Kh3 Qd3 81. Kg3 Qd6+ 82. Kh3 Qd3\n83. Kg3 Qd6+ 84. Kh3 Qd3 85. Kg3 Qd6+ 86. Kh3 Qd3 87. Kg3 Qd6+ 88. Kh3 Qd3\n89. Kg3",
          "aggressive_tokens": {
            "prompt_tokens": 239,
            "completion_tokens": 640,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "g6",
            "Qh6",
            "Re6",
            "Nc3",
            "Rae8",
            "Ne4",
            "f5",
            "Ng5",
            "R6e7",
            "Qxg6+",
            "Rg7",
            "Qxe8#",
            "g5",
            "Be5",
            "Rxe8",
            "Bxg7",
            "Kxg7",
            "Re1",
            "Rf8",
            "Ne6+",
            "Kf7",
            "Nxf8",
            "Kxf8",
            "Re5",
            "Kf7",
            "Rxf5+",
            "Kg6",
            "g4",
            "b5",
            "Kg2",
            "a5",
            "Re1",
            "a4",
            "Re6+",
            "Kg7",
            "Rxc6",
            "b4",
            "Rxc7+",
            "Kg6",
            "Rc6+",
            "Kg7",
            "Rb5",
            "b3",
            "Rb7+",
            "Kf8",
            "Rc8#",
            "Kd8",
            "Rh7",
            "bxa2",
            "Ra8#",
            "Kxc8",
            "Rh8+",
            "Kb7",
            "Rh7+",
            "Kb6",
            "Rh6+",
            "Kb5",
            "c4+",
            "Kb4",
            "Rb6+",
            "Ka5",
            "Rb5+",
            "Ka6",
            "Rxg5",
            "a1=Q",
            "Rg6+",
            "Kb7",
            "Rg7+",
            "Kc6",
            "Rg6+",
            "Kd7",
            "Rg7+",
            "Ke6",
            "Rg6+",
            "Kf7",
            "Rb6",
            "Qd1",
            "Rb7+",
            "Ke6",
            "Rb6+",
            "Kd7",
            "Rb7+",
            "Kc6",
            "Rg7",
            "Qxd3",
            "Rg6+",
            "Kc5",
            "Rg5+",
            "Kxc4",
            "h4",
            "Qe4+",
            "Kg3",
            "Qd3+",
            "f3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxh5",
          "positional_uci": "g4h5",
          "positional_response": "16. Qxh5 g6 17. Qh6 Re6 18. Nc3 Rae8 19. Ne4 f5 20. Ng5 R6e7 21. Qxg6+ Rg7 22.\nQxe8# Qxe8 23. Re1 Qg6 24. h4 Qh5 25. Rh3 Rd7 26. Rhe3 Qxh4 27. Re8+ Kg7 28. Be5+\nKg6 29. Rg8+ Kh5 30. Rh8+ Kxg5 31. Rxh4 Kxh4 32. Bf6+ Kh5 33. Re7 Rxe7 34.\nBxe7 Kg6 35. Bd8 Kf7 36. Bxc7 Ke6 37. Ke2 Kd5 38. Ke3 c5 39. c4+ Kc6 40. Be5 b5\n41. Kf4 bxc4 42. dxc4 Kb6 43. Kxf5 Ka5 44. g4 Kb4 45. g5 Kxc4 46. g6 Kd3 47.\ng7 c4 48. g8=Q c3 49. Qd5+ Kc2 50. Qb3+ Kd3 51. Qxc3+ Ke2 52. Qe3+ Kf1 53. f4\nKg2 54. Kg4 Kh2 55. Qg3+ Kh1 56. Kh3 a5 57. Qg2# Qxg2# 58. Bxg2# e5 Nf3",
          "positional_tokens": {
            "prompt_tokens": 239,
            "completion_tokens": 372,
            "total_tokens": 611,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g6",
            "Qh6",
            "Re6",
            "Nc3",
            "Rae8",
            "Ne4",
            "f5",
            "Ng5",
            "R6e7",
            "Qxg6+",
            "Rg7",
            "Qxe8#",
            "Qxe8",
            "Re1",
            "Qg6",
            "h4",
            "Qh5",
            "Rh3",
            "Rd7",
            "Rhe3",
            "Qxh4",
            "Re8+",
            "Kg7",
            "Be5+",
            "Kg6",
            "Rg8+",
            "Kh5",
            "Rh8+",
            "Kxg5",
            "Rxh4",
            "Kxh4",
            "Bf6+",
            "Kh5",
            "Re7",
            "Rxe7",
            "Bxe7",
            "Kg6",
            "Bd8",
            "Kf7",
            "Bxc7",
            "Ke6",
            "Ke2",
            "Kd5",
            "Ke3",
            "c5",
            "c4+",
            "Kc6",
            "Be5",
            "b5",
            "Kf4",
            "bxc4",
            "dxc4",
            "Kb6",
            "Kxf5",
            "Ka5",
            "g4",
            "Kb4",
            "g5",
            "Kxc4",
            "g6",
            "Kd3",
            "g7",
            "c4",
            "g8=Q",
            "c3",
            "Qd5+",
            "Kc2",
            "Qb3+",
            "Kd3",
            "Qxc3+",
            "Ke2",
            "Qe3+",
            "Kf1",
            "f4",
            "Kg2",
            "Kg4",
            "Kh2",
            "Qg3+",
            "Kh1",
            "Kh3",
            "a5",
            "Qg2#",
            "Qxg2#",
            "Bxg2#",
            "e5",
            "Nf3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re1+",
          "neutral_uci": null,
          "neutral_response": "Re1+ Rxe1#",
          "neutral_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 7,
            "total_tokens": 245,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4h5",
          "positional_uci": "g4h5",
          "neutral_uci": null,
          "consensus_move": "g4h5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "g6",
              "Qh6",
              "Re6",
              "Nc3",
              "Rae8",
              "Ne4",
              "f5",
              "Ng5",
              "R6e7",
              "Qxg6+",
              "Rg7",
              "Qxe8#",
              "g5",
              "Be5",
              "Rxe8",
              "Bxg7",
              "Kxg7",
              "Re1",
              "Rf8",
              "Ne6+",
              "Kf7",
              "Nxf8",
              "Kxf8",
              "Re5",
              "Kf7",
              "Rxf5+",
              "Kg6",
              "g4",
              "b5",
              "Kg2",
              "a5",
              "Re1",
              "a4",
              "Re6+",
              "Kg7",
              "Rxc6",
              "b4",
              "Rxc7+",
              "Kg6",
              "Rc6+",
              "Kg7",
              "Rb5",
              "b3",
              "Rb7+",
              "Kf8",
              "Rc8#",
              "Kd8",
              "Rh7",
              "bxa2",
              "Ra8#",
              "Kxc8",
              "Rh8+",
              "Kb7",
              "Rh7+",
              "Kb6",
              "Rh6+",
              "Kb5",
              "c4+",
              "Kb4",
              "Rb6+",
              "Ka5",
              "Rb5+",
              "Ka6",
              "Rxg5",
              "a1=Q",
              "Rg6+",
              "Kb7",
              "Rg7+",
              "Kc6",
              "Rg6+",
              "Kd7",
              "Rg7+",
              "Ke6",
              "Rg6+",
              "Kf7",
              "Rb6",
              "Qd1",
              "Rb7+",
              "Ke6",
              "Rb6+",
              "Kd7",
              "Rb7+",
              "Kc6",
              "Rg7",
              "Qxd3",
              "Rg6+",
              "Kc5",
              "Rg5+",
              "Kxc4",
              "h4",
              "Qe4+",
              "Kg3",
              "Qd3+",
              "f3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "g6",
              "Qh6",
              "Re6",
              "Nc3",
              "Rae8",
              "Ne4",
              "f5",
              "Ng5",
              "R6e7",
              "Qxg6+",
              "Rg7",
              "Qxe8#",
              "Qxe8",
              "Re1",
              "Qg6",
              "h4",
              "Qh5",
              "Rh3",
              "Rd7",
              "Rhe3",
              "Qxh4",
              "Re8+",
              "Kg7",
              "Be5+",
              "Kg6",
              "Rg8+",
              "Kh5",
              "Rh8+",
              "Kxg5",
              "Rxh4",
              "Kxh4",
              "Bf6+",
              "Kh5",
              "Re7",
              "Rxe7",
              "Bxe7",
              "Kg6",
              "Bd8",
              "Kf7",
              "Bxc7",
              "Ke6",
              "Ke2",
              "Kd5",
              "Ke3",
              "c5",
              "c4+",
              "Kc6",
              "Be5",
              "b5",
              "Kf4",
              "bxc4",
              "dxc4",
              "Kb6",
              "Kxf5",
              "Ka5",
              "g4",
              "Kb4",
              "g5",
              "Kxc4",
              "g6",
              "Kd3",
              "g7",
              "c4",
              "g8=Q",
              "c3",
              "Qd5+",
              "Kc2",
              "Qb3+",
              "Kd3",
              "Qxc3+",
              "Ke2",
              "Qe3+",
              "Kf1",
              "f4",
              "Kg2",
              "Kg4",
              "Kh2",
              "Qg3+",
              "Kh1",
              "Kh3",
              "a5",
              "Qg2#",
              "Qxg2#",
              "Bxg2#",
              "e5",
              "Nf3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxe1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 239,
            "completion_tokens": 640,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 239,
            "completion_tokens": 372,
            "total_tokens": 611,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 238,
            "completion_tokens": 7,
            "total_tokens": 245,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 716,
          "total_completion_tokens": 1019,
          "total_tokens": 1735
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 239,
            "completion_tokens": 640,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 239,
            "completion_tokens": 372,
            "total_tokens": 611,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 238,
            "completion_tokens": 7,
            "total_tokens": 245,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2pp1/p1p5/7p/5BQ1/3P4/PPP2PPP/RN3K1R w - - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh6",
          "aggressive_uci": "h5h6",
          "aggressive_response": "17. Qh6 Re1+ 18. Kxe1 Re8+ 19. Kd2 Re2+ 20. Kxe2 g5 21. Bxg5 f6 22. Bxf6 Kf7 23. Qg7+ Ke6 24. Qe7+ Kd5 25. Qe5# e4 Nxe5 dxe5 Bxe5+ Kxe5 f5+ Kd4 c5#",
          "aggressive_tokens": {
            "prompt_tokens": 248,
            "completion_tokens": 103,
            "total_tokens": 351,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Bxg5",
            "f6",
            "Bxf6",
            "Kf7",
            "Qg7+",
            "Ke6",
            "Qe7+",
            "Kd5",
            "Qe5#",
            "e4",
            "Nxe5",
            "dxe5",
            "Bxe5+",
            "Kxe5",
            "f5+",
            "Kd4",
            "c5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re1+",
          "positional_uci": null,
          "positional_response": "Re1+ Rxe1+ Qxe1#",
          "positional_tokens": {
            "prompt_tokens": 248,
            "completion_tokens": 11,
            "total_tokens": 259,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe1+",
            "Qxe1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": "h5h6",
          "neutral_response": "17. Qh6 Re1+ 18. Kxe1 Re8+ 19. Kd2 Re2+ 20. Kxe2 g5 21. Bxg5 f6 22. Bxf6 Kf7\n23. Qg7+ Ke6 24. Qe7+ Kd5 25. Qe5# e5 Nc5+ Kc6 Qc5# e6 Nc6+ Kc6 Qc5# e7 Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ K",
          "neutral_tokens": {
            "prompt_tokens": 247,
            "completion_tokens": 640,
            "total_tokens": 887,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Bxg5",
            "f6",
            "Bxf6",
            "Kf7",
            "Qg7+",
            "Ke6",
            "Qe7+",
            "Kd5",
            "Qe5#",
            "e5",
            "Nc5+",
            "Kc6",
            "Qc5#",
            "e6",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e7",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h5h6",
          "positional_uci": null,
          "neutral_uci": "h5h6",
          "consensus_move": "h5h6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Bxg5",
              "f6",
              "Bxf6",
              "Kf7",
              "Qg7+",
              "Ke6",
              "Qe7+",
              "Kd5",
              "Qe5#",
              "e4",
              "Nxe5",
              "dxe5",
              "Bxe5+",
              "Kxe5",
              "f5+",
              "Kd4",
              "c5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxe1+",
              "Qxe1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Bxg5",
              "f6",
              "Bxf6",
              "Kf7",
              "Qg7+",
              "Ke6",
              "Qe7+",
              "Kd5",
              "Qe5#",
              "e5",
              "Nc5+",
              "Kc6",
              "Qc5#",
              "e6",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e7",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 248,
            "completion_tokens": 103,
            "total_tokens": 351,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 248,
            "completion_tokens": 11,
            "total_tokens": 259,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 247,
            "completion_tokens": 640,
            "total_tokens": 887,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 743,
          "total_completion_tokens": 754,
          "total_tokens": 1497
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 248,
            "completion_tokens": 103,
            "total_tokens": 351,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 248,
            "completion_tokens": 11,
            "total_tokens": 259,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 247,
            "completion_tokens": 640,
            "total_tokens": 887,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2p2/p1p3p1/7Q/5B2/3P4/PPP2PPP/RN3K1R w - - 0 17"
    }
  ],
  "black_responses": [
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "1. d4 * d5 Nf3 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 14,
            "total_tokens": 130,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": null,
          "positional_response": "1. d4\nd4 e5",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 10,
            "total_tokens": 126,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": null,
          "neutral_response": "1. d4 *\nd4",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 14,
            "total_tokens": 130,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 10,
            "total_tokens": 126,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 32,
          "total_tokens": 379
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 14,
            "total_tokens": 130,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 10,
            "total_tokens": 126,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6\nBlack Nf6 c4 e6",
          "aggressive_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c4",
            "e6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6\nNf6 e6 c4",
          "positional_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e6",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6 4. Nc3 Be7 5. Bf4 O-O 6. e3 c5 7. dxc5 Bxc5 8. Qc2 Nc6 9. Rd1 Qe7 10. Be2 Rd8 11. O-O Ne5 12. Nxe5 dxe5 13. Bg3 Bf5 14. Qb3 b6 15. cxb6 axb6 16. Rc1 Rac8 17. Rxc8 Rxc8 18. Bxb6 Bxb6 19. Qxb6 Qxb6 20. Rxd8+ Nf8 21. Rd7 Qb1+ 22. Kf2 Qxb2 23. Rxg7+ Kh8 24. Rh7+ Kg8 25. Rxh6 Qxc3 26. Rh8+ Kf7 27. Rh7+ Ke8 28. Rh8+ Kd7 29. Rh7+ Kc6 30. Rh6+ Kb5 31. Rh5+ Ka4 32. Rh4+ Ka3 33. Rh3+ Ka2 34. Rh2+ Ka1 35. Rh1+ Ka2 36. Rh2+ Ka3 37. Rh3+ Ka4 38. Rh4+ Ka5 39. Rh5+ Ka6 40. Rh6+ Ka7 41. Rh7+ Ka8 42. Rh8+ Ka7 43. Rh7+ Ka6 44. Rh6+ Ka5 45. Rh5+ Ka4 46. Rh4+ Ka3 47. Rh3+ Ka2 48. Rh2+ Ka1 49. Rh1+ Ka2 50. Rh2+ Ka3 51. Rh3+ Ka4 52. Rh4+ Ka5 53. Rh5+ Ka6 54. Rh6+ Ka7 55. Rh7+ Ka8 56. Rh8+ Ka7 57. Rh7+ Ka6 58. Rh6+ Ka5 59. Rh5+ Ka4 60. Rh4+ Ka3 61. Rh3+ Ka2 62. Rh2+ Ka1 63. Rh1+ Ka2 64. Rh2+ Ka3 65. Rh3+ Ka4 66. Rh4+ Ka5 67. Rh5+ Ka6 68. Rh6+ Ka7 69. Rh7+ Ka8 70. Rh8+ Ka7 71. Rh7+ Ka6 72. Rh6+ Ka5 73. Rh5+ Ka4 74. Rh4+ Ka3 75. Rh3+ Ka2 76. Rh2+ Ka1 77. Rh1+ Ka2 78. Rh2+ Ka3 79",
          "neutral_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "c4",
            "e6",
            "Nc3",
            "Be7",
            "Bf4",
            "O-O",
            "e3",
            "c5",
            "dxc5",
            "Bxc5",
            "Qc2",
            "Nc6",
            "Rd1",
            "Qe7",
            "Be2",
            "Rd8",
            "O-O",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Bg3",
            "Bf5",
            "Qb3",
            "b6",
            "cxb6",
            "axb6",
            "Rc1",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Bxb6",
            "Bxb6",
            "Qxb6",
            "Qxb6",
            "Rxd8+",
            "Nf8",
            "Rd7",
            "Qb1+",
            "Kf2",
            "Qxb2",
            "Rxg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rxh6",
            "Qxc3",
            "Rh8+",
            "Kf7",
            "Rh7+",
            "Ke8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kc6",
            "Rh6+",
            "Kb5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3",
            "Rh3+",
            "Ka4",
            "Rh4+",
            "Ka5",
            "Rh5+",
            "Ka6",
            "Rh6+",
            "Ka7",
            "Rh7+",
            "Ka8",
            "Rh8+",
            "Ka7",
            "Rh7+",
            "Ka6",
            "Rh6+",
            "Ka5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3",
            "Rh3+",
            "Ka4",
            "Rh4+",
            "Ka5",
            "Rh5+",
            "Ka6",
            "Rh6+",
            "Ka7",
            "Rh7+",
            "Ka8",
            "Rh8+",
            "Ka7",
            "Rh7+",
            "Ka6",
            "Rh6+",
            "Ka5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3",
            "Rh3+",
            "Ka4",
            "Rh4+",
            "Ka5",
            "Rh5+",
            "Ka6",
            "Rh6+",
            "Ka7",
            "Rh7+",
            "Ka8",
            "Rh8+",
            "Ka7",
            "Rh7+",
            "Ka6",
            "Rh6+",
            "Ka5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c4",
              "e6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c4",
              "e6",
              "Nc3",
              "Be7",
              "Bf4",
              "O-O",
              "e3",
              "c5",
              "dxc5",
              "Bxc5",
              "Qc2",
              "Nc6",
              "Rd1",
              "Qe7",
              "Be2",
              "Rd8",
              "O-O",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Bg3",
              "Bf5",
              "Qb3",
              "b6",
              "cxb6",
              "axb6",
              "Rc1",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Bxb6",
              "Bxb6",
              "Qxb6",
              "Qxb6",
              "Rxd8+",
              "Nf8",
              "Rd7",
              "Qb1+",
              "Kf2",
              "Qxb2",
              "Rxg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rxh6",
              "Qxc3",
              "Rh8+",
              "Kf7",
              "Rh7+",
              "Ke8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kc6",
              "Rh6+",
              "Kb5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3",
              "Rh3+",
              "Ka4",
              "Rh4+",
              "Ka5",
              "Rh5+",
              "Ka6",
              "Rh6+",
              "Ka7",
              "Rh7+",
              "Ka8",
              "Rh8+",
              "Ka7",
              "Rh7+",
              "Ka6",
              "Rh6+",
              "Ka5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3",
              "Rh3+",
              "Ka4",
              "Rh4+",
              "Ka5",
              "Rh5+",
              "Ka6",
              "Rh6+",
              "Ka7",
              "Rh7+",
              "Ka8",
              "Rh8+",
              "Ka7",
              "Rh7+",
              "Ka6",
              "Rh6+",
              "Ka5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3",
              "Rh3+",
              "Ka4",
              "Rh4+",
              "Ka5",
              "Rh5+",
              "Ka6",
              "Rh6+",
              "Ka7",
              "Rh7+",
              "Ka8",
              "Rh8+",
              "Ka7",
              "Rh7+",
              "Ka6",
              "Rh6+",
              "Ka5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 371,
          "total_completion_tokens": 705,
          "total_tokens": 1076
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e6",
          "aggressive_uci": "e7e6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 *\nBlack e6 Bb4+",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 30,
            "total_tokens": 163,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb4+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e3",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 * e3 Bg4 4. Bxf6",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 34,
            "total_tokens": 167,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e6",
          "neutral_uci": "e7e6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Nbd2 O-O\nBlack e6 Be7 O-O",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e6",
          "positional_uci": null,
          "neutral_uci": "e7e6",
          "consensus_move": "e7e6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb4+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bg4",
              "Bxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 30,
            "total_tokens": 163,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 34,
            "total_tokens": 167,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 111,
          "total_tokens": 509
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 30,
            "total_tokens": 163,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 34,
            "total_tokens": 167,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p2B1/3P4/5N2/PPP1PPPP/RN1QKB1R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. c4 c5 10. Qc2 Nc6 11. Rac1 Rc8 12. Rfd1 Qd7 13. dxc5 bxc5 14. Nb3 Qe7 15. Nxc5 Nxc5 16. Qxc5 Rfd8 17. Qc2 d4 18. exd4 Bxd4 19. Ne5 Bxe5 20. Bxe5 Qxe5 21. Bxf6 gxf6 22. Qxf6 Qxf6 23. Rxd8+ Rxd8 24. Rxd8+ Kg7 25. Rd7+ Kg6 26. Rxh7 Kxh7 27. h3 Kg7 28. g4 Kf6 29. Kg2 Ke5 30. Kg3 Kd5 31. f4 Kc4 32. Kf3 Kb3 33. Ke3 Kxa2 34. Kd3 Kb3 35. Kd4 a5 36. Kc5 a4 37. Kb4 a3 38. Kxa3 Kc4 39. Ka4 Kc5 40. Ka5 Kc6 41. Ka6 Kc7 42. Ka7 Kc8 43. Ka8 Kc7 44. Ka7 Kc8 45. Ka8 Kc7 46. Ka7 Kc8 47. Ka8 Kc7 48. Ka7 Kc8 49. Ka8 Kc7 50. Ka7 Kc8 51. Ka8 Kc7 52. Ka7 Kc8 53. Ka8 Kc7 54. Ka7 Kc8 55. Ka8 Kc7 56. Ka7 Kc8 57. Ka8 Kc7 58. Ka7 Kc8 59. Ka8 Kc7 60. Ka7 Kc8 61. Ka8 Kc7 62. Ka7 Kc8 63. Ka8 Kc7 64. Ka7 Kc8 65. Ka8 Kc7 66. Ka7 Kc8 67. Ka8 Kc7 68. Ka7 Kc8 69. Ka8 Kc7 70. Ka7 Kc8 71. Ka8 Kc7 72. Ka7 Kc8 73. Ka8 Kc7 74. Ka7 Kc8 75. Ka8 Kc7 76. Ka7 Kc8 77. Ka8 Kc7 78. Ka7 Kc8 79. Ka8 Kc",
          "aggressive_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4",
            "b6",
            "Nbd2",
            "Bb7",
            "c4",
            "c5",
            "Qc2",
            "Nc6",
            "Rac1",
            "Rc8",
            "Rfd1",
            "Qd7",
            "dxc5",
            "bxc5",
            "Nb3",
            "Qe7",
            "Nxc5",
            "Nxc5",
            "Qxc5",
            "Rfd8",
            "Qc2",
            "d4",
            "exd4",
            "Bxd4",
            "Ne5",
            "Bxe5",
            "Bxe5",
            "Qxe5",
            "Bxf6",
            "gxf6",
            "Qxf6",
            "Qxf6",
            "Rxd8+",
            "Rxd8",
            "Rxd8+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rxh7",
            "Kxh7",
            "h3",
            "Kg7",
            "g4",
            "Kf6",
            "Kg2",
            "Ke5",
            "Kg3",
            "Kd5",
            "f4",
            "Kc4",
            "Kf3",
            "Kb3",
            "Ke3",
            "Kxa2",
            "Kd3",
            "Kb3",
            "Kd4",
            "a5",
            "Kc5",
            "a4",
            "Kb4",
            "a3",
            "Kxa3",
            "Kc4",
            "Ka4",
            "Kc5",
            "Ka5",
            "Kc6",
            "Ka6",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 * Be7 h3 Bd6",
          "positional_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Bd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O",
          "neutral_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 43,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3",
            "O-O",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4",
              "b6",
              "Nbd2",
              "Bb7",
              "c4",
              "c5",
              "Qc2",
              "Nc6",
              "Rac1",
              "Rc8",
              "Rfd1",
              "Qd7",
              "dxc5",
              "bxc5",
              "Nb3",
              "Qe7",
              "Nxc5",
              "Nxc5",
              "Qxc5",
              "Rfd8",
              "Qc2",
              "d4",
              "exd4",
              "Bxd4",
              "Ne5",
              "Bxe5",
              "Bxe5",
              "Qxe5",
              "Bxf6",
              "gxf6",
              "Qxf6",
              "Qxf6",
              "Rxd8+",
              "Rxd8",
              "Rxd8+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rxh7",
              "Kxh7",
              "h3",
              "Kg7",
              "g4",
              "Kf6",
              "Kg2",
              "Ke5",
              "Kg3",
              "Kd5",
              "f4",
              "Kc4",
              "Kf3",
              "Kb3",
              "Ke3",
              "Kxa2",
              "Kd3",
              "Kb3",
              "Kd4",
              "a5",
              "Kc5",
              "a4",
              "Kb4",
              "a3",
              "Kxa3",
              "Kc4",
              "Ka4",
              "Kc5",
              "Ka5",
              "Kc6",
              "Ka6",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h3",
              "Bd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bd3",
              "O-O",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 139,
            "completion_tokens": 43,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 419,
          "total_completion_tokens": 721,
          "total_tokens": 1140
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 139,
            "completion_tokens": 43,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p2B1/3P4/4PN2/PPP2PPP/RN1QKB1R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd7",
          "aggressive_uci": "b8d7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 *\nBlack Nbd7 O-O c6",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "c6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e8g8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 * O-O Nbd7 h6",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 44,
            "total_tokens": 190,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "h6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8d7",
          "positional_uci": "e8g8",
          "neutral_uci": "e8g8",
          "consensus_move": "e8g8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "c6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h6",
              "Bh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "h6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 44,
            "total_tokens": 190,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 139,
          "total_tokens": 579
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 44,
            "total_tokens": 190,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1QK2R b KQkq - 2 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "h6",
          "aggressive_uci": "h7h6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h6",
          "positional_uci": "h7h6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "h6",
          "neutral_uci": "h7h6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 58,
            "total_tokens": 211,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h7h6",
          "positional_uci": "h7h6",
          "neutral_uci": "h7h6",
          "consensus_move": "h7h6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 58,
            "total_tokens": 211,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 174,
          "total_tokens": 635
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 58,
            "total_tokens": 211,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1Q1RK1 b - - 4 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b6",
          "aggressive_uci": "b7b6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. Ne5\nBlack Ne4 Bxe4 Qc8",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Bb7",
            "Ne5",
            "Ne4",
            "Bxe4",
            "Qc8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b6",
          "positional_uci": "b7b6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. c4\nb6 Bb7 c4",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 74,
            "total_tokens": 235,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb7",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "b6",
          "neutral_uci": "b7b6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. c4",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 66,
            "total_tokens": 226,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Bb7",
            "c4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b7b6",
          "positional_uci": "b7b6",
          "neutral_uci": "b7b6",
          "consensus_move": "b7b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd2",
              "Bb7",
              "Ne5",
              "Ne4",
              "Bxe4",
              "Qc8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd2",
              "Bb7",
              "c4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 74,
            "total_tokens": 235,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 66,
            "total_tokens": 226,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 216,
          "total_tokens": 698
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 74,
            "total_tokens": 235,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 66,
            "total_tokens": 226,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bpp1/4pn1p/3p4/3P3B/3BPN2/PPP2PPP/RN1Q1RK1 b - - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb7",
          "aggressive_uci": "c8b7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2",
          "aggressive_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Qc2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb7",
          "positional_uci": "c8b7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1\nBb7 Nc3 Rc1",
          "positional_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 84,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Rc1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb7",
          "neutral_uci": "c8b7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2",
          "neutral_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Qc2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8b7",
          "positional_uci": "c8b7",
          "neutral_uci": "c8b7",
          "consensus_move": "c8b7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Nbd7",
              "Qc2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Rc1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc3",
              "Nbd7",
              "Qc2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 168,
            "completion_tokens": 84,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 503,
          "total_completion_tokens": 234,
          "total_tokens": 737
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 168,
            "completion_tokens": 84,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/p1p1bpp1/1p2pn1p/3p4/2PP3B/3BPN2/PP3PPP/RN1Q1RK1 b - - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd7",
          "aggressive_uci": "b8d7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2 c5 11. Rfd1",
          "aggressive_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc2",
            "c5",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nbd7",
          "positional_uci": "b8d7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. dxc5 bxc5",
          "positional_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 86,
            "total_tokens": 263,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rc1",
            "c5",
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nbd7",
          "neutral_uci": "b8d7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. dxc5 bxc5",
          "neutral_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 86,
            "total_tokens": 262,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rc1",
            "c5",
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8d7",
          "positional_uci": "b8d7",
          "neutral_uci": "b8d7",
          "consensus_move": "b8d7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qc2",
              "c5",
              "Rfd1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rc1",
              "c5",
              "dxc5",
              "bxc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rc1",
              "c5",
              "dxc5",
              "bxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 177,
            "completion_tokens": 86,
            "total_tokens": 263,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 176,
            "completion_tokens": 86,
            "total_tokens": 262,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 530,
          "total_completion_tokens": 255,
          "total_tokens": 785
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 177,
            "completion_tokens": 86,
            "total_tokens": 263,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 176,
            "completion_tokens": 86,
            "total_tokens": 262,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rn1q1rk1/pbp1bpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/R2Q1RK1 b - - 2 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd5",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 * cxd5 Nxd5 11. Bxe7 Qxe7",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c5",
          "positional_uci": "c7c5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. dxc5 bxc5",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c5",
          "neutral_uci": "c7c5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 95,
            "total_tokens": 280,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "cxd5",
            "exd5",
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "c7c5",
          "neutral_uci": "c7c5",
          "consensus_move": "c7c5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "cxd5",
              "exd5",
              "dxc5",
              "bxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 95,
            "total_tokens": 280,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 272,
          "total_tokens": 829
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 95,
            "total_tokens": 280,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pbpnbpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/2RQ1RK1 b - - 4 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "exd5",
          "aggressive_uci": "e6d5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5 13. Qa4",
          "aggressive_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qa4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "exd5",
          "positional_uci": "e6d5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5 13. Qe2\nBlack Qe2 Rfc8 Bf5",
          "positional_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 112,
            "total_tokens": 306,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qe2",
            "Qe2",
            "Rfc8",
            "Bf5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "exd5",
          "neutral_uci": "e6d5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5 13. Bxf6 Nxf6\nBlack exd5 dxc5 bxc5",
          "neutral_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 115,
            "total_tokens": 308,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e6d5",
          "positional_uci": "e6d5",
          "neutral_uci": "e6d5",
          "consensus_move": "e6d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc5",
              "bxc5",
              "Qa4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5",
              "Qe2",
              "Qe2",
              "Rfc8",
              "Bf5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc5",
              "bxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 194,
            "completion_tokens": 112,
            "total_tokens": 306,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 193,
            "completion_tokens": 115,
            "total_tokens": 308,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 581,
          "total_completion_tokens": 328,
          "total_tokens": 909
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 194,
            "completion_tokens": 112,
            "total_tokens": 306,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 193,
            "completion_tokens": 115,
            "total_tokens": 308,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p2pn1p/2pP4/3P3B/2NBPN2/PP3PPP/2RQ1RK1 b - - 0 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rc8",
          "aggressive_uci": "a8c8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. dxc5 bxc5 14. Qd2",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 110,
            "total_tokens": 313,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rc8",
          "positional_uci": "a8c8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. dxc5 bxc5 14. Qd2 *",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 111,
            "total_tokens": 314,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rc8",
          "neutral_uci": "a8c8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. dxc5 bxc5 14. Qd2\nBb7 Rc8 dxc5 bxc5 Qd2",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 125,
            "total_tokens": 327,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qd2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a8c8",
          "positional_uci": "a8c8",
          "neutral_uci": "a8c8",
          "consensus_move": "a8c8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc5",
              "bxc5",
              "Qd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5",
              "Qd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc5",
              "bxc5",
              "Qd2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 110,
            "total_tokens": 313,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 111,
            "total_tokens": 314,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 125,
            "total_tokens": 327,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 346,
          "total_tokens": 954
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 110,
            "total_tokens": 313,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 111,
            "total_tokens": 314,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 125,
            "total_tokens": 327,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2N1PN2/PP3PPP/1BRQ1RK1 b - - 1 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qc7",
          "aggressive_uci": "d8c7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. dxc5 bxc5 15. Bxf6 Nxf6",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 122,
            "total_tokens": 334,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Bxf6",
            "Nxf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe8",
          "positional_uci": "d8e8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qe8 14. dxc5 bxc5 15. Bxf6\nQe8 dxc5 bxc5 Bxf6",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 132,
            "total_tokens": 344,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qa5",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qa5 14. Ne2 Rfd8 15. Ng3\nQa5 Rfd8 Ng3",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 126,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rfd8",
            "Ng3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8c7",
          "positional_uci": "d8e8",
          "neutral_uci": null,
          "consensus_move": "d8c7",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc5",
              "bxc5",
              "Bxf6",
              "Nxf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5",
              "Bxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rfd8",
              "Ng3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 122,
            "total_tokens": 334,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 132,
            "total_tokens": 344,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 126,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 380,
          "total_tokens": 1015
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 122,
            "total_tokens": 334,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 132,
            "total_tokens": 344,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 126,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2rq1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2NQPN2/PP3PPP/1BR2RK1 b - - 3 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": "d7e5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Nd7 16. f4",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 125,
            "total_tokens": 345,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Nd7",
            "f4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe5",
          "positional_uci": "d7e5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Ng4 16. Bg3\nNg4 Bg3 Qe7",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 135,
            "total_tokens": 355,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Ng4",
            "Bg3",
            "Ng4",
            "Bg3",
            "Qe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe5",
          "neutral_uci": "d7e5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6\nBlack Nxe5 dxe5 Qxe5 Bxf6",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 141,
            "total_tokens": 360,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Qxe5",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7e5",
          "positional_uci": "d7e5",
          "neutral_uci": "d7e5",
          "consensus_move": "d7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxe5",
              "Nd7",
              "f4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxe5",
              "Ng4",
              "Bg3",
              "Ng4",
              "Bg3",
              "Qe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxe5",
              "Qxe5",
              "Bxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 125,
            "total_tokens": 345,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 135,
            "total_tokens": 355,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 141,
            "total_tokens": 360,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 401,
          "total_tokens": 1060
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 125,
            "total_tokens": 345,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 135,
            "total_tokens": 355,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 141,
            "total_tokens": 360,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pbqnbpp1/1p3n1p/2ppN3/3P3B/2NQP3/PP3PPP/1BR2RK1 b - - 5 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe5",
          "aggressive_uci": "c7e5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 * Qxe5 Qxe5 Bxe5",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne4",
          "positional_uci": "f6e4",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Ne4 16. Bxe7 Qxe7 17. f3\nNe4 f3 Bxe7 Qxe7",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 145,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "f3",
            "Bxe7",
            "Qxe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe5",
          "neutral_uci": "c7e5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qxd5\nQxe5 Qxd5 Bxf6",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd5",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c7e5",
          "positional_uci": "f6e4",
          "neutral_uci": "c7e5",
          "consensus_move": "c7e5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxe5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "f3",
              "Bxe7",
              "Qxe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxd5",
              "Bxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 145,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 419,
          "total_tokens": 1105
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 145,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pbq1bpp1/1p3n1p/2ppP3/7B/2NQP3/PP3PPP/1BR2RK1 b - - 0 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "gxf6",
          "aggressive_uci": "g7f6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 gxf6 17. Qg3+ Kh8 18. Qh4\nQg3+ Kh8 Qh4",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 154,
            "total_tokens": 392,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg3+",
            "Kh8",
            "Qh4",
            "Qg3+",
            "Kh8",
            "Qh4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "gxf6",
          "positional_uci": "g7f6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 gxf6 17. Qg3+ Kh8 18. Qh4",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 145,
            "total_tokens": 383,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg3+",
            "Kh8",
            "Qh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "e7f6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qxh6 Qg5 18. Qxg5\nBg5 Qxg5",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 151,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh6",
            "Qg5",
            "Qxg5",
            "Bg5",
            "Qxg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g7f6",
          "positional_uci": "g7f6",
          "neutral_uci": "e7f6",
          "consensus_move": "g7f6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qg3+",
              "Kh8",
              "Qh4",
              "Qg3+",
              "Kh8",
              "Qh4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qg3+",
              "Kh8",
              "Qh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxh6",
              "Qg5",
              "Qxg5",
              "Bg5",
              "Qxg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 154,
            "total_tokens": 392,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 145,
            "total_tokens": 383,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 151,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 450,
          "total_tokens": 1163
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 154,
            "total_tokens": 392,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 145,
            "total_tokens": 383,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 151,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pb2bpp1/1p3B1p/2ppq3/8/2NQP3/PP3PPP/1BR2RK1 b - - 0 16"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d6 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Nb4 15. Bb1 Bb7 16. Nbd2 Rac8 17. Nb1 Rfd8 18. Nbd2 Qb8 19. Nb1 Qb7 20. Nbd2 Qb8 21. Nb1 Qb7 22. Nbd2 Qb8 23. Nb1 Qb7 24. Nbd2 Qb8 25. Nb1 Qb7 26. Nbd2 Qb8 27. Nb1 Qb7 28. Nbd2 Qb8 29. Nb1 Qb7 30. Nbd2 Qb8 31. Nb1 Qb7 32. Nbd2 Qb8 33. Nb1 Qb7 34. Nbd2 Qb8 35. Nb1 Qb7 36. Nbd2 Qb8 37. Nb1 Qb7 38. Nbd2 Qb8 39. Nb1 Qb7 40. Nbd2 Qb8 41. Nb1 Qb7 42. Nbd2 Qb8 43. Nb1 Qb7 44. Nbd2 Qb8 45. Nb1 Qb7 46. Nbd2 Qb8 47. Nb1 Qb7 48. Nbd2 Qb8 49. Nb1 Qb7 50. Nbd2 Qb8 51. Nb1 Qb7 52. Nbd2 Qb8 53. Nb1 Qb7 54. Nbd2 Qb8 55. Nb1 Qb7 56. Nbd2 Qb8 57. Nb1 Qb7 58. Nbd2 Qb8 59. Nb1 Qb7 60. Nbd2 Qb8 61. Nb1 Qb7 62. Nbd2 Qb8 63. Nb1 Qb7 64. Nbd2 Qb8 65. Nb1 Qb7 66. Nbd2 Qb8 67. Nb1 Qb7 68. Nbd2 Qb8 69. Nb1 Qb7 70. Nbd2 Qb8 71. Nb1 Qb7 72. Nbd2 Qb8 73. Nb1 Qb7 74. Nbd2 Qb8 75. Nb1 Qb7 76. Nbd2 Qb8 77. Nb1",
          "aggressive_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Nb4",
            "Bb1",
            "Bb7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Rfd8",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Bb7 15. Be3 Rac8 16. Rc1 Qb8 17. dxe5 dxe5 18. Qxd8 Rfxd8 19. Nxe5 Nxe5 20. Bxe5 Rxc1 21. Rxc1 Bxe4 22. Bxf6 Bxf6 23. Rc7 Bxb2 24. Rb7 Bc3 25. Rxb5 Bxa1 26. Rxa5 Bc3 27. Ra7 Bb4 28. Rb7 Bc5 29. Rb5 Bb6 30. Rb7 Bc5 31. Rb5 Bb6 32. Rb7 Bc5 33. Rb5 Bb6 34. Rb7 Bc5 35. Rb5 Bb6 36. Rb7 Bc5 37. Rb5 Bb6 38. Rb7 Bc5 39. Rb5 Bb6 40. Rb7 Bc5 41. Rb5 Bb6 42. Rb7 Bc5 43. Rb5 Bb6 44. Rb7 Bc5 45. Rb5 Bb6 46. Rb7 Bc5 47. Rb5 Bb6 48. Rb7 Bc5 49. Rb5 Bb6 50. Rb7 Bc5 51. Rb5 Bb6 52. Rb7 Bc5 53. Rb5 Bb6 54. Rb7 Bc5 55. Rb5 Bb6 56. Rb7 Bc5 57. Rb5 Bb6 58. Rb7 Bc5 59. Rb5 Bb6 60. Rb7 Bc5 61. Rb5 Bb6 62. Rb7 Bc5 63. Rb5 Bb6 64. Rb7 Bc5 65. Rb5 Bb6 66. Rb7 Bc5 67. Rb5 Bb6 68. Rb7 Bc5 69. Rb5 Bb6 70. Rb7 Bc5 71. Rb5 Bb6 72. Rb7 Bc5 73. Rb5 Bb6 74. Rb7 Bc5 75. Rb5 Bb6 76. Rb7 Bc5 77. Rb5 Bb6 78. Rb7 Bc5 79. Rb5 Bb6",
          "positional_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Be3",
            "Rac8",
            "Rc1",
            "Qb8",
            "dxe5",
            "dxe5",
            "Qxd8",
            "Rfxd8",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "Rxc1",
            "Rxc1",
            "Bxe4",
            "Bxf6",
            "Bxf6",
            "Rc7",
            "Bxb2",
            "Rb7",
            "Bc3",
            "Rxb5",
            "Bxa1",
            "Rxa5",
            "Bc3",
            "Ra7",
            "Bb4",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Nb4 15. Bb1 Bb7 16. a3 Nc6 17. d5 Nb8 18. Be3 Qd7 19. Qd2 Rc8 20. Rac1 Rxc1 21. Rxc1 Rc8 22. Rxc8+ Qxc8 23. Qc3 Qxc3 24. bxc3 Na6 25. c4 bxc4 26. Nxc4 Nb4 27. Nd2 Bc8 28. Nb3 Bd7 29. Nc5 Bc8 30. Nb7 Bxb7 31. Bxb7 Nc2 32. Bxa6 Nxa3 33. Bb5 Nb1 34. Bc6 Nc3 35. Bxd6 Nxd5 36. exd5 exd5 37. Bxf8 Kxf8 38. Nc5 Ke7 39. Nxd7 Kxd7 40. Kf1 Ke6 41. Ke2 Kd5 42. Kd3 f5 43. f3 g5 44. g3 h5 45. h4 g4 46. fxg4 fxg4 47. Kc3 Kc5 48. Kb3 Kb5 49. Ka3 Ka5 50. Kb3 Kb5 51. Ka3 Ka5 52. Kb3 Kb5 53. Ka3 Ka5 54. Kb3 Kb5 55. Ka3 Ka5 56. Kb3 Kb5 57. Ka3 Ka5 58. Kb3 Kb5 59. Ka3 Ka5 60. Kb3 Kb5 61. Ka3 Ka5 62. Kb3 Kb5 63. Ka3 Ka5 64. Kb3 Kb5 65. Ka3 Ka5 66. Kb3 Kb5 67. Ka3 Ka5 68. Kb3 Kb5 69. Ka3 Ka5 70. Kb3 Kb5 71. Ka3 Ka5 72. Kb3 Kb5 73. Ka3 Ka5 74. Kb3 Kb5 75. Ka3 Ka5 76. Kb3 Kb5 77. Ka3 Ka5 78. Kb3 Kb5 79. Ka3 Ka5",
          "neutral_tokens": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Nb4",
            "Bb1",
            "Bb7",
            "a3",
            "Nc6",
            "d5",
            "Nb8",
            "Be3",
            "Qd7",
            "Qd2",
            "Rc8",
            "Rac1",
            "Rxc1",
            "Rxc1",
            "Rc8",
            "Rxc8+",
            "Qxc8",
            "Qc3",
            "Qxc3",
            "bxc3",
            "Na6",
            "c4",
            "bxc4",
            "Nxc4",
            "Nb4",
            "Nd2",
            "Bc8",
            "Nb3",
            "Bd7",
            "Nc5",
            "Bc8",
            "Nb7",
            "Bxb7",
            "Bxb7",
            "Nc2",
            "Bxa6",
            "Nxa3",
            "Bb5",
            "Nb1",
            "Bc6",
            "Nc3",
            "Bxd6",
            "Nxd5",
            "exd5",
            "exd5",
            "Bxf8",
            "Kxf8",
            "Nc5",
            "Ke7",
            "Nxd7",
            "Kxd7",
            "Kf1",
            "Ke6",
            "Ke2",
            "Kd5",
            "Kd3",
            "f5",
            "f3",
            "g5",
            "g3",
            "h5",
            "h4",
            "g4",
            "fxg4",
            "fxg4",
            "Kc3",
            "Kc5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Nb4",
              "Bb1",
              "Bb7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Rfd8",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Be3",
              "Rac8",
              "Rc1",
              "Qb8",
              "dxe5",
              "dxe5",
              "Qxd8",
              "Rfxd8",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "Rxc1",
              "Rxc1",
              "Bxe4",
              "Bxf6",
              "Bxf6",
              "Rc7",
              "Bxb2",
              "Rb7",
              "Bc3",
              "Rxb5",
              "Bxa1",
              "Rxa5",
              "Bc3",
              "Ra7",
              "Bb4",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Nb4",
              "Bb1",
              "Bb7",
              "a3",
              "Nc6",
              "d5",
              "Nb8",
              "Be3",
              "Qd7",
              "Qd2",
              "Rc8",
              "Rac1",
              "Rxc1",
              "Rxc1",
              "Rc8",
              "Rxc8+",
              "Qxc8",
              "Qc3",
              "Qxc3",
              "bxc3",
              "Na6",
              "c4",
              "bxc4",
              "Nxc4",
              "Nb4",
              "Nd2",
              "Bc8",
              "Nb3",
              "Bd7",
              "Nc5",
              "Bc8",
              "Nb7",
              "Bxb7",
              "Bxb7",
              "Nc2",
              "Bxa6",
              "Nxa3",
              "Bb5",
              "Nb1",
              "Bc6",
              "Nc3",
              "Bxd6",
              "Nxd5",
              "exd5",
              "exd5",
              "Bxf8",
              "Kxf8",
              "Nc5",
              "Ke7",
              "Nxd7",
              "Kxd7",
              "Kf1",
              "Ke6",
              "Ke2",
              "Kd5",
              "Kd3",
              "f5",
              "f3",
              "g5",
              "g3",
              "h5",
              "h4",
              "g4",
              "fxg4",
              "fxg4",
              "Kc3",
              "Kc5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 335,
          "total_completion_tokens": 1920,
          "total_tokens": 2255
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Ng5 cxd4 cxd4 Nc6 Nxc6 Qxc6 Qf3 Be6 Rad1 Rfd8 Qg3 Rac8 Bb3 h6 Nf3 Qb6 Be3 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Ng5",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nxc6",
            "Qxc6",
            "Qf3",
            "Be6",
            "Rad1",
            "Rfd8",
            "Qg3",
            "Rac8",
            "Bb3",
            "h6",
            "Nf3",
            "Qb6",
            "Be3",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nb6 Nb3 Bg4 Be3 Rfc8 Rc1 Qb7 Qd3 Rac8 Rg1 Qa8 Qf1 Bxf3 Qxf3 Qb7 Qg3 Qxg3 fxg3 Nd7 Rcf1 Nf8 Bb1 Ne6 Bxe6 fxe6 Rxf8+ Kxf8 Rf1+ Ke8 Kg2 Kd7 Kf3 Kc6 Ke4 Kb6 Kd3 Kc6 Kc3 Kb6 Kb3 Kc6 a3 Kb6 a4 Kc6 a5 Kb5 axb6 Kxb6 b4 Kc6 Kc4 Kb6 c5+ dxc5 bxc5+ Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 K",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nb6",
            "Nb3",
            "Bg4",
            "Be3",
            "Rfc8",
            "Rc1",
            "Qb7",
            "Qd3",
            "Rac8",
            "Rg1",
            "Qa8",
            "Qf1",
            "Bxf3",
            "Qxf3",
            "Qb7",
            "Qg3",
            "Qxg3",
            "fxg3",
            "Nd7",
            "Rcf1",
            "Nf8",
            "Bb1",
            "Ne6",
            "Bxe6",
            "fxe6",
            "Rxf8+",
            "Kxf8",
            "Rf1+",
            "Ke8",
            "Kg2",
            "Kd7",
            "Kf3",
            "Kc6",
            "Ke4",
            "Kb6",
            "Kd3",
            "Kc6",
            "Kc3",
            "Kb6",
            "Kb3",
            "Kc6",
            "a3",
            "Kb6",
            "a4",
            "Kc6",
            "a5",
            "Kb5",
            "axb6",
            "Kxb6",
            "b4",
            "Kc6",
            "Kc4",
            "Kb6",
            "c5+",
            "dxc5",
            "bxc5+",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Ng5",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nxc6",
              "Qxc6",
              "Qf3",
              "Be6",
              "Rad1",
              "Rfd8",
              "Qg3",
              "Rac8",
              "Bb3",
              "h6",
              "Nf3",
              "Qb6",
              "Be3",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nb6",
              "Nb3",
              "Bg4",
              "Be3",
              "Rfc8",
              "Rc1",
              "Qb7",
              "Qd3",
              "Rac8",
              "Rg1",
              "Qa8",
              "Qf1",
              "Bxf3",
              "Qxf3",
              "Qb7",
              "Qg3",
              "Qxg3",
              "fxg3",
              "Nd7",
              "Rcf1",
              "Nf8",
              "Bb1",
              "Ne6",
              "Bxe6",
              "fxe6",
              "Rxf8+",
              "Kxf8",
              "Rf1+",
              "Ke8",
              "Kg2",
              "Kd7",
              "Kf3",
              "Kc6",
              "Ke4",
              "Kb6",
              "Kd3",
              "Kc6",
              "Kc3",
              "Kb6",
              "Kb3",
              "Kc6",
              "a3",
              "Kb6",
              "a4",
              "Kc6",
              "a5",
              "Kb5",
              "axb6",
              "Kxb6",
              "b4",
              "Kc6",
              "Kc4",
              "Kb6",
              "c5+",
              "dxc5",
              "bxc5+",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 1920,
          "total_tokens": 2273
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 *\ne4 e5 Nf3 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Nbd2 Rac8 Nb1 Rfe8 Nc3 Bf8 Nb5 Qb8 Be3 Nb4 Bxb4 Qxb4 a3 Qb6 Qd3 g6 Rac1 Qd8 Rxc8 Qxc8 Qc2 Qxc2 Bxc2 Rc8 Bb3 Rc3 Bd1 Kf8 f3 Ke8 Kf2 Kd7 Ke2 Kc7 Kd2 Kb6 Kc2 Ka5 Kb2 Kb4 a4 Kc4 Bc2 Kd4 Bb3 Ke3 Bc2 Kf4 Bb3 Kg3 Bc2 Kh4 Bb3 Kh5 Bc2 Kh6 Bb3 Kg7 Bc2 Kf8 Bb3 Ke8 Bc2 Kd7 Bb3 Kc7 Bc2 Kb6 Bb3 Ka5 Bc2 Kb4 a5 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 a6 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 a7 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 a8=Q Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 Qa7 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Rfe8",
            "Nc3",
            "Bf8",
            "Nb5",
            "Qb8",
            "Be3",
            "Nb4",
            "Bxb4",
            "Qxb4",
            "a3",
            "Qb6",
            "Qd3",
            "g6",
            "Rac1",
            "Qd8",
            "Rxc8",
            "Qxc8",
            "Qc2",
            "Qxc2",
            "Bxc2",
            "Rc8",
            "Bb3",
            "Rc3",
            "Bd1",
            "Kf8",
            "f3",
            "Ke8",
            "Kf2",
            "Kd7",
            "Ke2",
            "Kc7",
            "Kd2",
            "Kb6",
            "Kc2",
            "Ka5",
            "Kb2",
            "Kb4",
            "a4",
            "Kc4",
            "Bc2",
            "Kd4",
            "Bb3",
            "Ke3",
            "Bc2",
            "Kf4",
            "Bb3",
            "Kg3",
            "Bc2",
            "Kh4",
            "Bb3",
            "Kh5",
            "Bc2",
            "Kh6",
            "Bb3",
            "Kg7",
            "Bc2",
            "Kf8",
            "Bb3",
            "Ke8",
            "Bc2",
            "Kd7",
            "Bb3",
            "Kc7",
            "Bc2",
            "Kb6",
            "Bb3",
            "Ka5",
            "Bc2",
            "Kb4",
            "a5",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "a6",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "a7",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "a8=Q",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "Qa7",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 exd4 Nb3 Nxb3 axb3 Bb7 Nxd4 Rfe8 Nf5 Bf8 Bd3 g6 Nh6+ Kg7 Qf3 Bg7 Qg3 Qf4 Qxf4 Bxf4 Bxf4 Nxe4 Bxe4 Rxe4 Rxe4 Bxe4 Re1 Bf5 Re7+ Kg8 Rxh7 Be6 Rh8+ Kxh8 Bg5 Kg7 Bf6+ Kg8 Be7 Kf7 Bxd6 Ke6 Bc5 Kd5 Bxb7 Kc4 Bxa6 Kb3 Bxb5 Ka3 Bc4 Kb2 Bd3 Kc3 Be4 Kd2 Bf5 Ke3 Bg6 Kf4 Bh5 Kg5 Bg6 Kh6 Bf7+ Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "exd4",
            "Nb3",
            "Nxb3",
            "axb3",
            "Bb7",
            "Nxd4",
            "Rfe8",
            "Nf5",
            "Bf8",
            "Bd3",
            "g6",
            "Nh6+",
            "Kg7",
            "Qf3",
            "Bg7",
            "Qg3",
            "Qf4",
            "Qxf4",
            "Bxf4",
            "Bxf4",
            "Nxe4",
            "Bxe4",
            "Rxe4",
            "Rxe4",
            "Bxe4",
            "Re1",
            "Bf5",
            "Re7+",
            "Kg8",
            "Rxh7",
            "Be6",
            "Rh8+",
            "Kxh8",
            "Bg5",
            "Kg7",
            "Bf6+",
            "Kg8",
            "Be7",
            "Kf7",
            "Bxd6",
            "Ke6",
            "Bc5",
            "Kd5",
            "Bxb7",
            "Kc4",
            "Bxa6",
            "Kb3",
            "Bxb5",
            "Ka3",
            "Bc4",
            "Kb2",
            "Bd3",
            "Kc3",
            "Be4",
            "Kd2",
            "Bf5",
            "Ke3",
            "Bg6",
            "Kf4",
            "Bh5",
            "Kg5",
            "Bg6",
            "Kh6",
            "Bf7+",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Rfe8",
              "Nc3",
              "Bf8",
              "Nb5",
              "Qb8",
              "Be3",
              "Nb4",
              "Bxb4",
              "Qxb4",
              "a3",
              "Qb6",
              "Qd3",
              "g6",
              "Rac1",
              "Qd8",
              "Rxc8",
              "Qxc8",
              "Qc2",
              "Qxc2",
              "Bxc2",
              "Rc8",
              "Bb3",
              "Rc3",
              "Bd1",
              "Kf8",
              "f3",
              "Ke8",
              "Kf2",
              "Kd7",
              "Ke2",
              "Kc7",
              "Kd2",
              "Kb6",
              "Kc2",
              "Ka5",
              "Kb2",
              "Kb4",
              "a4",
              "Kc4",
              "Bc2",
              "Kd4",
              "Bb3",
              "Ke3",
              "Bc2",
              "Kf4",
              "Bb3",
              "Kg3",
              "Bc2",
              "Kh4",
              "Bb3",
              "Kh5",
              "Bc2",
              "Kh6",
              "Bb3",
              "Kg7",
              "Bc2",
              "Kf8",
              "Bb3",
              "Ke8",
              "Bc2",
              "Kd7",
              "Bb3",
              "Kc7",
              "Bc2",
              "Kb6",
              "Bb3",
              "Ka5",
              "Bc2",
              "Kb4",
              "a5",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "a6",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "a7",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "a8=Q",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "Qa7",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "exd4",
              "Nb3",
              "Nxb3",
              "axb3",
              "Bb7",
              "Nxd4",
              "Rfe8",
              "Nf5",
              "Bf8",
              "Bd3",
              "g6",
              "Nh6+",
              "Kg7",
              "Qf3",
              "Bg7",
              "Qg3",
              "Qf4",
              "Qxf4",
              "Bxf4",
              "Bxf4",
              "Nxe4",
              "Bxe4",
              "Rxe4",
              "Rxe4",
              "Bxe4",
              "Re1",
              "Bf5",
              "Re7+",
              "Kg8",
              "Rxh7",
              "Be6",
              "Rh8+",
              "Kxh8",
              "Bg5",
              "Kg7",
              "Bf6+",
              "Kg8",
              "Be7",
              "Kf7",
              "Bxd6",
              "Ke6",
              "Bc5",
              "Kd5",
              "Bxb7",
              "Kc4",
              "Bxa6",
              "Kb3",
              "Bxb5",
              "Ka3",
              "Bc4",
              "Kb2",
              "Bd3",
              "Kc3",
              "Be4",
              "Kd2",
              "Bf5",
              "Ke3",
              "Bg6",
              "Kf4",
              "Bh5",
              "Kg5",
              "Bg6",
              "Kh6",
              "Bf7+",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 1298,
          "total_tokens": 1651
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Nbd2 Rac8 Nb1 Nb4 Bb1 Rfe8 Nbd2 Bf8 Nb1 g6 Nbd2 Bg7 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Nb4",
            "Bb1",
            "Rfe8",
            "Nbd2",
            "Bf8",
            "Nb1",
            "g6",
            "Nbd2",
            "Bg7",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 d6 c3 O-O h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Bd3 exd4 Nfxd4 Nxd4 Nxd4 Qb6 Be3 Rfe8 Qf3 Bf8 Rac1 Rac8 Rxc8 Rxc8 Rc1 Rxc1 Qxc1 Qc7 Qxc7 Bxc7 Kf1 Kf8 Ke2 Ke7 Kd3 Kd7 Kc4 Bb6 f3 f6 g4 g5 Kb5 Bc7 Ka6 Kc6 Ka7 Bb6+ Ka6 Bc7\nKa6 Bc7 Ka7 Bb6+ Ka6 Bc7",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 202,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Bd3",
            "exd4",
            "Nfxd4",
            "Nxd4",
            "Nxd4",
            "Qb6",
            "Be3",
            "Rfe8",
            "Qf3",
            "Bf8",
            "Rac1",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Rc1",
            "Rxc1",
            "Qxc1",
            "Qc7",
            "Qxc7",
            "Bxc7",
            "Kf1",
            "Kf8",
            "Ke2",
            "Ke7",
            "Kd3",
            "Kd7",
            "Kc4",
            "Bb6",
            "f3",
            "f6",
            "g4",
            "g5",
            "Kb5",
            "Bc7",
            "Ka6",
            "Kc6",
            "Ka7",
            "Bb6+",
            "Ka6",
            "Bc7",
            "Ka6",
            "Bc7",
            "Ka7",
            "Bb6+",
            "Ka6",
            "Bc7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Nb4",
              "Bb1",
              "Rfe8",
              "Nbd2",
              "Bf8",
              "Nb1",
              "g6",
              "Nbd2",
              "Bg7",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Bd3",
              "exd4",
              "Nfxd4",
              "Nxd4",
              "Nxd4",
              "Qb6",
              "Be3",
              "Rfe8",
              "Qf3",
              "Bf8",
              "Rac1",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Rc1",
              "Rxc1",
              "Qxc1",
              "Qc7",
              "Qxc7",
              "Bxc7",
              "Kf1",
              "Kf8",
              "Ke2",
              "Ke7",
              "Kd3",
              "Kd7",
              "Kc4",
              "Bb6",
              "f3",
              "f6",
              "g4",
              "g5",
              "Kb5",
              "Bc7",
              "Ka6",
              "Kc6",
              "Ka7",
              "Bb6+",
              "Ka6",
              "Bc7",
              "Ka6",
              "Bc7",
              "Ka7",
              "Bb6+",
              "Ka6",
              "Bc7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 202,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 860,
          "total_tokens": 1213
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 202,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 *\ne4 e5 Nf3",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 13,
            "total_tokens": 129,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 * e5 Nf3 Nc6\ne5 Nf3 Nc6",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 23,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1. e4 * e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Bd3 Rac8 Qe2 exd4 Nfxd4 Nxd4 Nxd4 Bxd4 Qxe7 Qxe7 Rxe7 Bxc3 bxc3 Rxc3 Bb2 Rfc8 Rac1 Rxc1 Rxc1 Rxc1+ Bxc1 Kf8 f3 Ke7 Kf2 Kd7 Ke3 Kc6 Kd4 Kb5 Kc3 Ka4 Kb2 Kb4 Ka2 Kc3 Ka3 Kb1 Kb3 Kc1 Kc3 Kd1 Kd3 Ke1 Ke3 Kf1 Kf3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Bd3",
            "Rac8",
            "Qe2",
            "exd4",
            "Nfxd4",
            "Nxd4",
            "Nxd4",
            "Bxd4",
            "Qxe7",
            "Qxe7",
            "Rxe7",
            "Bxc3",
            "bxc3",
            "Rxc3",
            "Bb2",
            "Rfc8",
            "Rac1",
            "Rxc1",
            "Rxc1",
            "Rxc1+",
            "Bxc1",
            "Kf8",
            "f3",
            "Ke7",
            "Kf2",
            "Kd7",
            "Ke3",
            "Kc6",
            "Kd4",
            "Kb5",
            "Kc3",
            "Ka4",
            "Kb2",
            "Kb4",
            "Ka2",
            "Kc3",
            "Ka3",
            "Kb1",
            "Kb3",
            "Kc1",
            "Kc3",
            "Kd1",
            "Kd3",
            "Ke1",
            "Ke3",
            "Kf1",
            "Kf3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Bd3",
              "Rac8",
              "Qe2",
              "exd4",
              "Nfxd4",
              "Nxd4",
              "Nxd4",
              "Bxd4",
              "Qxe7",
              "Qxe7",
              "Rxe7",
              "Bxc3",
              "bxc3",
              "Rxc3",
              "Bb2",
              "Rfc8",
              "Rac1",
              "Rxc1",
              "Rxc1",
              "Rxc1+",
              "Bxc1",
              "Kf8",
              "f3",
              "Ke7",
              "Kf2",
              "Kd7",
              "Ke3",
              "Kc6",
              "Kd4",
              "Kb5",
              "Kc3",
              "Ka4",
              "Kb2",
              "Kb4",
              "Ka2",
              "Kc3",
              "Ka3",
              "Kb1",
              "Kb3",
              "Kc1",
              "Kc3",
              "Kd1",
              "Kd3",
              "Ke1",
              "Ke3",
              "Kf1",
              "Kf3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 13,
            "total_tokens": 129,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 23,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 676,
          "total_tokens": 1023
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 13,
            "total_tokens": 129,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 23,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "1. e4 e5 2. Nf3 * Nc6 3. Bb5\nNc6 Bb5",
          "aggressive_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "1. e4 e5 2. Nf3 * Nc6 3. Bb5\nNc6 Bb5",
          "positional_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "1. e4 e5 2. Nf3 * Nc6 Nf6 d4",
          "neutral_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 22,
            "total_tokens": 145,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "d4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 123,
            "completion_tokens": 22,
            "total_tokens": 145,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 371,
          "total_completion_tokens": 82,
          "total_tokens": 453
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 123,
            "completion_tokens": 22,
            "total_tokens": 145,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5\nWhite a6",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 26,
            "total_tokens": 159,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\nBa4 Nf6 O-O Be7",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 49,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a7a6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O\nWhite Black White Black White",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 43,
            "total_tokens": 175,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "a7a6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 26,
            "total_tokens": 159,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 49,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 43,
            "total_tokens": 175,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 118,
          "total_tokens": 516
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 26,
            "total_tokens": 159,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 49,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 43,
            "total_tokens": 175,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxc6",
          "aggressive_uci": "d7c6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. O-O f6 6. d4 *",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 46,
            "total_tokens": 187,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "f6",
            "d4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxc6",
          "positional_uci": "d7c6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. O-O f6 6. d4 Bg4",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 48,
            "total_tokens": 189,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "f6",
            "d4",
            "Bg4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxc6",
          "neutral_uci": "d7c6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. O-O f6 6. d4",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "f6",
            "d4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7c6",
          "positional_uci": "d7c6",
          "neutral_uci": "d7c6",
          "consensus_move": "d7c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "f6",
              "d4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "f6",
              "d4",
              "Bg4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "f6",
              "d4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 46,
            "total_tokens": 187,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 48,
            "total_tokens": 189,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 139,
          "total_tokens": 561
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 46,
            "total_tokens": 187,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 48,
            "total_tokens": 189,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1B5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qd4",
          "aggressive_uci": "d8d4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be2",
          "aggressive_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qxe4+",
            "Be2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd4",
          "positional_uci": "d8d4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2",
          "positional_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 58,
            "total_tokens": 208,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qxe4+",
            "Qe2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qd4",
          "neutral_uci": "d8d4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be3",
          "neutral_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 57,
            "total_tokens": 206,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qxe4+",
            "Be3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8d4",
          "positional_uci": "d8d4",
          "neutral_uci": "d8d4",
          "consensus_move": "d8d4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Qxe4+",
              "Be2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Qxe4+",
              "Qe2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf3",
              "Qxe4+",
              "Be3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 150,
            "completion_tokens": 58,
            "total_tokens": 208,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 149,
            "completion_tokens": 57,
            "total_tokens": 206,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 449,
          "total_completion_tokens": 172,
          "total_tokens": 621
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 150,
            "completion_tokens": 58,
            "total_tokens": 208,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 149,
            "completion_tokens": 57,
            "total_tokens": 206,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1pp2ppp/p1p5/4N3/4P3/8/PPPP1PPP/RNBQK2R b KQkq - 0 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe4+",
          "aggressive_uci": "d4e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be2 Bg4 8. O-O",
          "aggressive_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Bg4",
            "O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe4+",
          "positional_uci": "d4e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be3 Bg4 8. O-O",
          "positional_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be3",
            "Bg4",
            "O-O"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe4+",
          "neutral_uci": "d4e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 * Qxe2+ Kxe2 Bg4",
          "neutral_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 79,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Qxe2+",
            "Kxe2",
            "Bg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4e4",
          "positional_uci": "d4e4",
          "neutral_uci": "d4e4",
          "consensus_move": "d4e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be2",
              "Bg4",
              "O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be3",
              "Bg4",
              "O-O"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Qxe2+",
              "Kxe2",
              "Bg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 158,
            "completion_tokens": 79,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 476,
          "total_completion_tokens": 209,
          "total_tokens": 685
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 158,
            "completion_tokens": 79,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/3qP3/5N2/PPPP1PPP/RNBQK2R b KQkq - 2 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be6",
          "aggressive_uci": "c8e6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Be6 8. d3 Qf5 9. Be3\nBe6 d3 Be3",
          "aggressive_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 80,
            "total_tokens": 249,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Be3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qf5",
          "positional_uci": "e4f5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Be6 9. Be3\nQf5 d3 Be6 Be3",
          "positional_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 83,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Be6",
            "Be3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxf3+",
          "neutral_uci": "e4f3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 * Qxf3+ gxf3 Be6",
          "neutral_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 68,
            "total_tokens": 236,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf3",
            "Be6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8e6",
          "positional_uci": "e4f5",
          "neutral_uci": "e4f3",
          "consensus_move": "e4f3",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d3",
              "Be3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d3",
              "Be6",
              "Be3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf3",
              "Be6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 169,
            "completion_tokens": 80,
            "total_tokens": 249,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 169,
            "completion_tokens": 83,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 168,
            "completion_tokens": 68,
            "total_tokens": 236,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 506,
          "total_completion_tokens": 231,
          "total_tokens": 737
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 169,
            "completion_tokens": 80,
            "total_tokens": 249,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 169,
            "completion_tokens": 83,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 168,
            "completion_tokens": 68,
            "total_tokens": 236,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQ1K1R b kq - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g3",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 * g3 Bg4 9. h3 Bh5",
          "aggressive_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 80,
            "total_tokens": 258,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "h3",
            "Bh5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg4",
          "positional_uci": "c8g4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qg3 Bh5 10. d3\nBg4 Qg3 Bh5 d3",
          "positional_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 93,
            "total_tokens": 271,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg3",
            "Bh5",
            "d3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g3",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 * g3 Bg4 Kg2",
          "neutral_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 75,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "Kg2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "c8g4",
          "neutral_uci": null,
          "consensus_move": "c8g4",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg4",
              "h3",
              "Bh5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qg3",
              "Bh5",
              "d3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bg4",
              "Kg2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 178,
            "completion_tokens": 80,
            "total_tokens": 258,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 178,
            "completion_tokens": 93,
            "total_tokens": 271,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 177,
            "completion_tokens": 75,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 533,
          "total_completion_tokens": 248,
          "total_tokens": 781
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 178,
            "completion_tokens": 80,
            "total_tokens": 258,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 178,
            "completion_tokens": 93,
            "total_tokens": 271,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 177,
            "completion_tokens": 75,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/8/5Q2/PPPP1PPP/RNB2K1R b kq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxg4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 * Qxg4 10. h3 h5 11. d3",
          "aggressive_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 92,
            "total_tokens": 279,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "h5",
            "d3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qf3 O-O 11. d3\n10. Qf3 O-O 11. d3",
          "positional_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 105,
            "total_tokens": 292,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "O-O",
            "d3",
            "Qf3",
            "O-O",
            "d3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 *\nBlack Nf6 h5 Qf6",
          "neutral_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h5",
            "Qf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h3",
              "h5",
              "d3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf3",
              "O-O",
              "d3",
              "Qf3",
              "O-O",
              "d3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h5",
              "Qf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 187,
            "completion_tokens": 92,
            "total_tokens": 279,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 187,
            "completion_tokens": 105,
            "total_tokens": 292,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 560,
          "total_completion_tokens": 283,
          "total_tokens": 843
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 187,
            "completion_tokens": 92,
            "total_tokens": 279,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 187,
            "completion_tokens": 105,
            "total_tokens": 292,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3kbnr/1pp2ppp/p1p5/8/6Q1/8/PPPP1PPP/RNB2K1R b kq - 0 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. Qxe7+ Kxe7 12. Re1+",
          "aggressive_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7+",
            "Kxe7",
            "Re1+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. Qxe7+ Kxe7 12. Re1+",
          "positional_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7+",
            "Kxe7",
            "Re1+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. Qxe7+ Kxe7 12. d3\nBe7 Kxe7 d3",
          "neutral_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 111,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxe7",
            "d3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe7+",
              "Kxe7",
              "Re1+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe7+",
              "Kxe7",
              "Re1+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxe7",
              "d3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 196,
            "completion_tokens": 111,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 590,
          "total_completion_tokens": 319,
          "total_tokens": 909
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 196,
            "completion_tokens": 111,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3kb1r/1pp2ppp/p1p2n2/8/8/8/PPPPQPPP/RNB2K1R b kq - 2 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 * \nBe7 Qe2+ Be7",
          "aggressive_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 103,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Be3 Rfe8 13. Nd2\nO-O Rfe8 Nd2",
          "positional_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 116,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rfe8",
            "Nd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 *\nBe7 O-O Bg5",
          "neutral_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 101,
            "total_tokens": 304,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e8g8",
          "neutral_uci": null,
          "consensus_move": "e8g8",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Rfe8",
              "Nd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Bg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 204,
            "completion_tokens": 103,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 204,
            "completion_tokens": 116,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 203,
            "completion_tokens": 101,
            "total_tokens": 304,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 611,
          "total_completion_tokens": 320,
          "total_tokens": 931
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 204,
            "completion_tokens": 103,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 204,
            "completion_tokens": 116,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 203,
            "completion_tokens": 101,
            "total_tokens": 304,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3k2r/1pp1bppp/p1p2n2/8/8/3P4/PPP1QPPP/RNB2K1R b kq - 0 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 *\n* Qe7 Qxe7 13. Bg5 Qd7 14. Nc3",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 124,
            "total_tokens": 336,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7",
            "Bg5",
            "Qd7",
            "Nc3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe7",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 *\nQxe7 Qd7 Qe8",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 111,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd7",
            "Qe8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qd8",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 *\nBlack Qd8 Qd7 Qxd3",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 112,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd7",
            "Qxd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe7",
              "Bg5",
              "Qd7",
              "Nc3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd7",
              "Qe8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd7",
              "Qxd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 124,
            "total_tokens": 336,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 111,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 112,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 347,
          "total_tokens": 982
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 124,
            "total_tokens": 336,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 111,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 112,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp1Qppp/p1p2n2/8/8/3P4/PPP2PPP/RNB2K1R b - - 0 12"
    },
    {
      "turn": 24,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 * Qxe7 13. Bg5 Rfe8 14. Bxf6",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 120,
            "total_tokens": 332,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg5",
            "Rfe8",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe7",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 * Qe7 Re8 Qxe7\nWhite Re8 Qxe7",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 117,
            "total_tokens": 329,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Qxe7",
            "Re8",
            "Qxe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nd5",
          "neutral_uci": "f6d5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qd7 Rfe8 14. Qxc7\nNd5 Qd7 Rfe8 Qxc7",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 130,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd7",
            "Rfe8",
            "Qxc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": "f6d5",
          "consensus_move": "f6d5",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg5",
              "Rfe8",
              "Bxf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Qxe7",
              "Re8",
              "Qxe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd7",
              "Rfe8",
              "Qxc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 120,
            "total_tokens": 332,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 117,
            "total_tokens": 329,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 130,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 367,
          "total_tokens": 1002
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 120,
            "total_tokens": 332,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 117,
            "total_tokens": 329,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 130,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp1Qppp/p1p2n2/8/8/3P4/PPP2PPP/RNB2K1R b - - 0 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe2",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 * \nWhite Qe2 Qd2 Qxd5",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 121,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd2",
            "Qxd5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf4",
          "positional_uci": "d5f4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Qf3 Rae8 15. Qxf4\n13. Qe2 Nf4 14. Qf3 Rae8 15. Qxf4",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 149,
            "total_tokens": 369,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rae8",
            "Qxf4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe2",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 *\nWhite: Qe2 Nd5 14. Qe4",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 123,
            "total_tokens": 342,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd5",
            "Qe4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "d5f4",
          "neutral_uci": null,
          "consensus_move": "d5f4",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd2",
              "Qxd5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf3",
              "Rae8",
              "Qxf4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nd5",
              "Qe4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 121,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 149,
            "total_tokens": 369,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 123,
            "total_tokens": 342,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 393,
          "total_tokens": 1052
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 121,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 149,
            "total_tokens": 369,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 123,
            "total_tokens": 342,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp2ppp/p1p5/3n4/8/3P4/PPP1QPPP/RNB2K1R b - - 2 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rfe8",
          "aggressive_uci": "f8e8",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Bg3 f5 16. h3",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 134,
            "total_tokens": 363,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg3",
            "f5",
            "h3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxf4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rxf4 15. Qe3 Rf5 16. g3\nRf5 g3 Qe3",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 144,
            "total_tokens": 373,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe3",
            "Rf5",
            "g3",
            "Rf5",
            "g3",
            "Qe3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxf4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rxf4 15. Qe3 Rf6 16. Qd2\nRf6 Qe3 Qd2",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe3",
            "Rf6",
            "Qd2",
            "Rf6",
            "Qe3",
            "Qd2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8e8",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "f8e8",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg3",
              "f5",
              "h3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe3",
              "Rf5",
              "g3",
              "Rf5",
              "g3",
              "Qe3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe3",
              "Rf6",
              "Qd2",
              "Rf6",
              "Qe3",
              "Qd2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 134,
            "total_tokens": 363,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 144,
            "total_tokens": 373,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 424,
          "total_tokens": 1110
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 134,
            "total_tokens": 363,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 144,
            "total_tokens": 373,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp2ppp/p1p5/8/5B2/3P4/PPP1QPPP/RN3K1R b - - 0 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rae8",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 Rae8 16. Qh5 g6 17. Qh6\nBlack Rae8 Qh5 g6 Qh6",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 155,
            "total_tokens": 393,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh5",
            "g6",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rae8",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 Rae8 16. Qf3 Rxe4 17. Qxf6\nQg4 Rae8 Qf3 Rxe4 Qxf6",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 158,
            "total_tokens": 396,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rxe4",
            "Qxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxg4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 Qxg4 16. h3 Qh5 17. g4",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Qh5",
            "g4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh5",
              "g6",
              "Qh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf3",
              "Rxe4",
              "Qxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h3",
              "Qh5",
              "g4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 155,
            "total_tokens": 393,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 158,
            "total_tokens": 396,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 456,
          "total_tokens": 1169
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 155,
            "total_tokens": 393,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 158,
            "total_tokens": 396,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2ppp/p1p5/8/5BQ1/3P4/PPP2PPP/RN3K1R b - - 2 15"
    },
    {
      "turn": 30,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rae8",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 Rae8 16. Qh5 g6 17. Qh6",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 143,
            "total_tokens": 381,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh5",
            "g6",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h5",
          "positional_uci": "h7h5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qh3 h4 17. g3\nh5 Qh3 g3",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 150,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh3",
            "g3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxg4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 Qxg4 16. h3 Qh5 17. g4",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Qh5",
            "g4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "h7h5",
          "neutral_uci": null,
          "consensus_move": "h7h5",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh5",
              "g6",
              "Qh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qh3",
              "g3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h3",
              "Qh5",
              "g4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 143,
            "total_tokens": 381,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 150,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 436,
          "total_tokens": 1149
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 143,
            "total_tokens": 381,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 150,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2ppp/p1p5/8/5BQ1/3P4/PPP2PPP/RN3K1R b - - 2 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g6",
          "aggressive_uci": "g7g6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qg5 f6 18. Qh6",
          "aggressive_tokens": {
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg5",
            "f6",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g6",
          "positional_uci": "g7g6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qg5 f6 18. Qh6",
          "positional_tokens": {
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg5",
            "f6",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g6",
          "neutral_uci": "g7g6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 Qg5 Rae8",
          "neutral_tokens": {
            "prompt_tokens": 245,
            "completion_tokens": 142,
            "total_tokens": 387,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg5",
            "Rae8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g7g6",
          "positional_uci": "g7g6",
          "neutral_uci": "g7g6",
          "consensus_move": "g7g6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qg5",
              "f6",
              "Qh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qg5",
              "f6",
              "Qh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qg5",
              "Rae8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 245,
            "completion_tokens": 142,
            "total_tokens": 387,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 737,
          "total_completion_tokens": 444,
          "total_tokens": 1181
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 245,
            "completion_tokens": 142,
            "total_tokens": 387,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2pp1/p1p5/7Q/5B2/3P4/PPP2PPP/RN3K1R b - - 0 16"
    },
    {
      "turn": 34,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh8",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh8 Qxh8 Rxh8",
          "aggressive_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh8",
            "Rxh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qh8",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh8 18. Qxh8 Rxh8 19. g3\nQh8 Rxh8 g3",
          "positional_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 169,
            "total_tokens": 423,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxh8",
            "g3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh6 Qg7 Qh7",
          "neutral_tokens": {
            "prompt_tokens": 253,
            "completion_tokens": 152,
            "total_tokens": 405,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg7",
            "Qh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxh8",
              "Rxh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxh8",
              "g3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qg7",
              "Qh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 254,
            "completion_tokens": 169,
            "total_tokens": 423,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 253,
            "completion_tokens": 152,
            "total_tokens": 405,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 761,
          "total_completion_tokens": 473,
          "total_tokens": 1234
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 254,
            "completion_tokens": 169,
            "total_tokens": 423,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 253,
            "completion_tokens": 152,
            "total_tokens": 405,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2p2/p1p3pQ/8/5B2/3P4/PPP2PPP/RN3K1R b - - 1 17"
    },
    {
      "turn": 34,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh6",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh6 18. Bg5 Qg7 19. Bh6",
          "aggressive_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg5",
            "Qg7",
            "Bh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qh6",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh6 18. Bg5 Qg7 19. h4",
          "positional_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg5",
            "Qg7",
            "h4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 * Qh6 Qxh6 gxh5",
          "neutral_tokens": {
            "prompt_tokens": 253,
            "completion_tokens": 153,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh6",
            "gxh5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg5",
              "Qg7",
              "Bh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bg5",
              "Qg7",
              "h4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxh6",
              "gxh5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 253,
            "completion_tokens": 153,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 761,
          "total_completion_tokens": 473,
          "total_tokens": 1234
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 253,
            "completion_tokens": 153,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2p2/p1p3pQ/8/5B2/3P4/PPP2PPP/RN3K1R b - - 1 17"
    },
    {
      "turn": 34,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qf6",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qf6 18. Qxf6 Bxf6 19. g3",
          "aggressive_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf6",
            "Bxf6",
            "g3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qh8",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh8 18. Qxh8+ Kxh8 19. g3\nQh8 Qxh8+ Kxh8 g3",
          "positional_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 174,
            "total_tokens": 428,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh8+",
            "Kxh8",
            "g3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh6 18. Bxh6 Re1+ 19. Kg2",
          "neutral_tokens": {
            "prompt_tokens": 253,
            "completion_tokens": 160,
            "total_tokens": 413,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxh6",
            "Re1+",
            "Kg2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxf6",
              "Bxf6",
              "g3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxh8+",
              "Kxh8",
              "g3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxh6",
              "Re1+",
              "Kg2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 254,
            "completion_tokens": 174,
            "total_tokens": 428,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 253,
            "completion_tokens": 160,
            "total_tokens": 413,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 761,
          "total_completion_tokens": 494,
          "total_tokens": 1255
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 254,
            "completion_tokens": 174,
            "total_tokens": 428,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 253,
            "completion_tokens": 160,
            "total_tokens": 413,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2p2/p1p3pQ/8/5B2/3P4/PPP2PPP/RN3K1R b - - 1 17"
    }
  ],
  "white_errors": [],
  "black_errors": [],
  "white_plan_log": [],
  "black_plan_log": [],
  "timestamp": "2025-11-29T23:07:00.125163",
  "game_id": "gpt-3.5-turbo-instruct_vs_deepseek-ai_deepseek-v3_SC_3",
  "configuration": "SC"
}