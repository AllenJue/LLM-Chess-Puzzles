{
  "result": "gpt-3.5-turbo-instruct wins by disqualification (deepseek-ai/deepseek-v3 failed to produce a legal move)",
  "white_player": "deepseek-ai/deepseek-v3",
  "black_player": "gpt-3.5-turbo-instruct",
  "white_score": 0.0,
  "black_score": 1.0,
  "total_moves": 2,
  "moves": [
    "e2e4",
    "e7e5"
  ],
  "game_history": [
    {
      "move_number": 1,
      "player": "deepseek-ai/deepseek-v3",
      "color": "white",
      "move_uci": "e2e4",
      "move_san": "e4",
      "fen_after": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "move_number": 2,
      "player": "gpt-3.5-turbo-instruct",
      "color": "black",
      "move_uci": "e7e5",
      "move_san": "e5",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    }
  ],
  "final_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2",
  "white_tokens": {
    "prompt_tokens": 8725,
    "completion_tokens": 7103,
    "total_tokens": 15828
  },
  "black_tokens": {
    "prompt_tokens": 9078,
    "completion_tokens": 27556,
    "total_tokens": 36634
  },
  "white_token_log": [
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 14,
          "total_tokens": 130,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 10,
          "total_tokens": 126,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 32,
        "total_tokens": 379
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 14,
          "total_tokens": 130,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 10,
          "total_tokens": 126,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 33,
          "total_tokens": 157,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 32,
          "total_tokens": 156,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 371,
        "total_completion_tokens": 705,
        "total_tokens": 1076
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 33,
          "total_tokens": 157,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 32,
          "total_tokens": 156,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 30,
          "total_tokens": 163,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 34,
          "total_tokens": 167,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 47,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 111,
        "total_tokens": 509
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 30,
          "total_tokens": 163,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 34,
          "total_tokens": 167,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 47,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 38,
          "total_tokens": 178,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 43,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 419,
        "total_completion_tokens": 721,
        "total_tokens": 1140
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 38,
          "total_tokens": 178,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 43,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 45,
          "total_tokens": 192,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 50,
          "total_tokens": 197,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 44,
          "total_tokens": 190,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 139,
        "total_tokens": 579
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 45,
          "total_tokens": 192,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 50,
          "total_tokens": 197,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 44,
          "total_tokens": 190,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 58,
          "total_tokens": 211,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 174,
        "total_tokens": 635
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 58,
          "total_tokens": 211,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 76,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 74,
          "total_tokens": 235,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 66,
          "total_tokens": 226,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 216,
        "total_tokens": 698
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 76,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 74,
          "total_tokens": 235,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 66,
          "total_tokens": 226,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 84,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 75,
          "total_tokens": 242,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 503,
        "total_completion_tokens": 234,
        "total_tokens": 737
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 84,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 75,
          "total_tokens": 242,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 83,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 86,
          "total_tokens": 263,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 86,
          "total_tokens": 262,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 530,
        "total_completion_tokens": 255,
        "total_tokens": 785
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 83,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 86,
          "total_tokens": 263,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 86,
          "total_tokens": 262,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 91,
          "total_tokens": 277,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 95,
          "total_tokens": 280,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 557,
        "total_completion_tokens": 272,
        "total_tokens": 829
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 91,
          "total_tokens": 277,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 95,
          "total_tokens": 280,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 194,
          "completion_tokens": 101,
          "total_tokens": 295,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 194,
          "completion_tokens": 112,
          "total_tokens": 306,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 193,
          "completion_tokens": 115,
          "total_tokens": 308,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 581,
        "total_completion_tokens": 328,
        "total_tokens": 909
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 194,
          "completion_tokens": 101,
          "total_tokens": 295,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 194,
          "completion_tokens": 112,
          "total_tokens": 306,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 193,
          "completion_tokens": 115,
          "total_tokens": 308,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 110,
          "total_tokens": 313,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 111,
          "total_tokens": 314,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 125,
          "total_tokens": 327,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 346,
        "total_tokens": 954
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 110,
          "total_tokens": 313,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 111,
          "total_tokens": 314,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 125,
          "total_tokens": 327,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 122,
          "total_tokens": 334,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 132,
          "total_tokens": 344,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 126,
          "total_tokens": 337,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 380,
        "total_tokens": 1015
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 122,
          "total_tokens": 334,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 132,
          "total_tokens": 344,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 126,
          "total_tokens": 337,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 125,
          "total_tokens": 345,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 135,
          "total_tokens": 355,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 141,
          "total_tokens": 360,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 401,
        "total_tokens": 1060
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 125,
          "total_tokens": 345,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 135,
          "total_tokens": 355,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 141,
          "total_tokens": 360,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 128,
          "total_tokens": 357,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 145,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 686,
        "total_completion_tokens": 419,
        "total_tokens": 1105
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 128,
          "total_tokens": 357,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 145,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 154,
          "total_tokens": 392,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 145,
          "total_tokens": 383,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 151,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 713,
        "total_completion_tokens": 450,
        "total_tokens": 1163
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 154,
          "total_tokens": 392,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 145,
          "total_tokens": 383,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 151,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 335,
        "total_completion_tokens": 1920,
        "total_tokens": 2255
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    }
  ],
  "black_token_log": [
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 470,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 616,
          "total_tokens": 726,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1726,
        "total_tokens": 2055
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 470,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 616,
          "total_tokens": 726,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 603,
          "total_tokens": 719,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1883,
        "total_tokens": 2230
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 603,
          "total_tokens": 719,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 545,
          "total_tokens": 670,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 457,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 460,
          "total_tokens": 584,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1462,
        "total_tokens": 1836
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 545,
          "total_tokens": 670,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 457,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 460,
          "total_tokens": 584,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 251,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1531,
        "total_tokens": 1929
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 251,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 394,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 500,
          "total_tokens": 640,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 419,
        "total_completion_tokens": 1534,
        "total_tokens": 1953
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 394,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 500,
          "total_tokens": 640,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 254,
          "total_tokens": 401,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 321,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 1215,
        "total_tokens": 1655
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 254,
          "total_tokens": 401,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 321,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 388,
          "total_tokens": 541,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 1668,
        "total_tokens": 2129
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 388,
          "total_tokens": 541,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 1920,
        "total_tokens": 2402
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 170,
          "completion_tokens": 264,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 509,
        "total_completion_tokens": 1544,
        "total_tokens": 2053
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 170,
          "completion_tokens": 264,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 536,
        "total_completion_tokens": 1920,
        "total_tokens": 2456
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 640,
          "total_tokens": 825,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 557,
        "total_completion_tokens": 1920,
        "total_tokens": 2477
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 640,
          "total_tokens": 825,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 195,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 206,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 584,
        "total_completion_tokens": 1041,
        "total_tokens": 1625
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 195,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 206,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 236,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 287,
          "total_tokens": 489,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 1163,
        "total_tokens": 1771
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 236,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 287,
          "total_tokens": 489,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 522,
          "total_tokens": 733,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 1802,
        "total_tokens": 2437
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 522,
          "total_tokens": 733,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 640,
          "total_tokens": 859,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 1920,
        "total_tokens": 2579
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 640,
          "total_tokens": 859,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 28,
          "total_tokens": 257,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 36,
          "total_tokens": 265,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 304,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 686,
        "total_completion_tokens": 368,
        "total_tokens": 1054
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 28,
          "total_tokens": 257,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 36,
          "total_tokens": 265,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 304,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 640,
          "total_tokens": 878,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 236,
          "total_tokens": 474,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 640,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 713,
        "total_completion_tokens": 1516,
        "total_tokens": 2229
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 640,
          "total_tokens": 878,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 236,
          "total_tokens": 474,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 640,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 465,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 318,
          "total_tokens": 431,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1423,
        "total_tokens": 1764
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 465,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 318,
          "total_tokens": 431,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    }
  ],
  "white_responses": [
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "1. d4 * d5 Nf3 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 14,
            "total_tokens": 130,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": null,
          "positional_response": "1. d4\nd4 e5",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 10,
            "total_tokens": 126,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": null,
          "neutral_response": "1. d4 *\nd4",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 14,
            "total_tokens": 130,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 10,
            "total_tokens": 126,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 32,
          "total_tokens": 379
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 14,
            "total_tokens": 130,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 10,
            "total_tokens": 126,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6\nBlack Nf6 c4 e6",
          "aggressive_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c4",
            "e6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6\nNf6 e6 c4",
          "positional_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e6",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6 4. Nc3 Be7 5. Bf4 O-O 6. e3 c5 7. dxc5 Bxc5 8. Qc2 Nc6 9. Rd1 Qe7 10. Be2 Rd8 11. O-O Ne5 12. Nxe5 dxe5 13. Bg3 Bf5 14. Qb3 b6 15. cxb6 axb6 16. Rc1 Rac8 17. Rxc8 Rxc8 18. Bxb6 Bxb6 19. Qxb6 Qxb6 20. Rxd8+ Nf8 21. Rd7 Qb1+ 22. Kf2 Qxb2 23. Rxg7+ Kh8 24. Rh7+ Kg8 25. Rxh6 Qxc3 26. Rh8+ Kf7 27. Rh7+ Ke8 28. Rh8+ Kd7 29. Rh7+ Kc6 30. Rh6+ Kb5 31. Rh5+ Ka4 32. Rh4+ Ka3 33. Rh3+ Ka2 34. Rh2+ Ka1 35. Rh1+ Ka2 36. Rh2+ Ka3 37. Rh3+ Ka4 38. Rh4+ Ka5 39. Rh5+ Ka6 40. Rh6+ Ka7 41. Rh7+ Ka8 42. Rh8+ Ka7 43. Rh7+ Ka6 44. Rh6+ Ka5 45. Rh5+ Ka4 46. Rh4+ Ka3 47. Rh3+ Ka2 48. Rh2+ Ka1 49. Rh1+ Ka2 50. Rh2+ Ka3 51. Rh3+ Ka4 52. Rh4+ Ka5 53. Rh5+ Ka6 54. Rh6+ Ka7 55. Rh7+ Ka8 56. Rh8+ Ka7 57. Rh7+ Ka6 58. Rh6+ Ka5 59. Rh5+ Ka4 60. Rh4+ Ka3 61. Rh3+ Ka2 62. Rh2+ Ka1 63. Rh1+ Ka2 64. Rh2+ Ka3 65. Rh3+ Ka4 66. Rh4+ Ka5 67. Rh5+ Ka6 68. Rh6+ Ka7 69. Rh7+ Ka8 70. Rh8+ Ka7 71. Rh7+ Ka6 72. Rh6+ Ka5 73. Rh5+ Ka4 74. Rh4+ Ka3 75. Rh3+ Ka2 76. Rh2+ Ka1 77. Rh1+ Ka2 78. Rh2+ Ka3 79",
          "neutral_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "c4",
            "e6",
            "Nc3",
            "Be7",
            "Bf4",
            "O-O",
            "e3",
            "c5",
            "dxc5",
            "Bxc5",
            "Qc2",
            "Nc6",
            "Rd1",
            "Qe7",
            "Be2",
            "Rd8",
            "O-O",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Bg3",
            "Bf5",
            "Qb3",
            "b6",
            "cxb6",
            "axb6",
            "Rc1",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Bxb6",
            "Bxb6",
            "Qxb6",
            "Qxb6",
            "Rxd8+",
            "Nf8",
            "Rd7",
            "Qb1+",
            "Kf2",
            "Qxb2",
            "Rxg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rxh6",
            "Qxc3",
            "Rh8+",
            "Kf7",
            "Rh7+",
            "Ke8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kc6",
            "Rh6+",
            "Kb5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3",
            "Rh3+",
            "Ka4",
            "Rh4+",
            "Ka5",
            "Rh5+",
            "Ka6",
            "Rh6+",
            "Ka7",
            "Rh7+",
            "Ka8",
            "Rh8+",
            "Ka7",
            "Rh7+",
            "Ka6",
            "Rh6+",
            "Ka5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3",
            "Rh3+",
            "Ka4",
            "Rh4+",
            "Ka5",
            "Rh5+",
            "Ka6",
            "Rh6+",
            "Ka7",
            "Rh7+",
            "Ka8",
            "Rh8+",
            "Ka7",
            "Rh7+",
            "Ka6",
            "Rh6+",
            "Ka5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3",
            "Rh3+",
            "Ka4",
            "Rh4+",
            "Ka5",
            "Rh5+",
            "Ka6",
            "Rh6+",
            "Ka7",
            "Rh7+",
            "Ka8",
            "Rh8+",
            "Ka7",
            "Rh7+",
            "Ka6",
            "Rh6+",
            "Ka5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c4",
              "e6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c4",
              "e6",
              "Nc3",
              "Be7",
              "Bf4",
              "O-O",
              "e3",
              "c5",
              "dxc5",
              "Bxc5",
              "Qc2",
              "Nc6",
              "Rd1",
              "Qe7",
              "Be2",
              "Rd8",
              "O-O",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Bg3",
              "Bf5",
              "Qb3",
              "b6",
              "cxb6",
              "axb6",
              "Rc1",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Bxb6",
              "Bxb6",
              "Qxb6",
              "Qxb6",
              "Rxd8+",
              "Nf8",
              "Rd7",
              "Qb1+",
              "Kf2",
              "Qxb2",
              "Rxg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rxh6",
              "Qxc3",
              "Rh8+",
              "Kf7",
              "Rh7+",
              "Ke8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kc6",
              "Rh6+",
              "Kb5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3",
              "Rh3+",
              "Ka4",
              "Rh4+",
              "Ka5",
              "Rh5+",
              "Ka6",
              "Rh6+",
              "Ka7",
              "Rh7+",
              "Ka8",
              "Rh8+",
              "Ka7",
              "Rh7+",
              "Ka6",
              "Rh6+",
              "Ka5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3",
              "Rh3+",
              "Ka4",
              "Rh4+",
              "Ka5",
              "Rh5+",
              "Ka6",
              "Rh6+",
              "Ka7",
              "Rh7+",
              "Ka8",
              "Rh8+",
              "Ka7",
              "Rh7+",
              "Ka6",
              "Rh6+",
              "Ka5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3",
              "Rh3+",
              "Ka4",
              "Rh4+",
              "Ka5",
              "Rh5+",
              "Ka6",
              "Rh6+",
              "Ka7",
              "Rh7+",
              "Ka8",
              "Rh8+",
              "Ka7",
              "Rh7+",
              "Ka6",
              "Rh6+",
              "Ka5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 371,
          "total_completion_tokens": 705,
          "total_tokens": 1076
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e6",
          "aggressive_uci": "e7e6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 *\nBlack e6 Bb4+",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 30,
            "total_tokens": 163,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb4+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e3",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 * e3 Bg4 4. Bxf6",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 34,
            "total_tokens": 167,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e6",
          "neutral_uci": "e7e6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Nbd2 O-O\nBlack e6 Be7 O-O",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e6",
          "positional_uci": null,
          "neutral_uci": "e7e6",
          "consensus_move": "e7e6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb4+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bg4",
              "Bxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 30,
            "total_tokens": 163,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 34,
            "total_tokens": 167,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 111,
          "total_tokens": 509
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 30,
            "total_tokens": 163,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 34,
            "total_tokens": 167,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p2B1/3P4/5N2/PPP1PPPP/RN1QKB1R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. c4 c5 10. Qc2 Nc6 11. Rac1 Rc8 12. Rfd1 Qd7 13. dxc5 bxc5 14. Nb3 Qe7 15. Nxc5 Nxc5 16. Qxc5 Rfd8 17. Qc2 d4 18. exd4 Bxd4 19. Ne5 Bxe5 20. Bxe5 Qxe5 21. Bxf6 gxf6 22. Qxf6 Qxf6 23. Rxd8+ Rxd8 24. Rxd8+ Kg7 25. Rd7+ Kg6 26. Rxh7 Kxh7 27. h3 Kg7 28. g4 Kf6 29. Kg2 Ke5 30. Kg3 Kd5 31. f4 Kc4 32. Kf3 Kb3 33. Ke3 Kxa2 34. Kd3 Kb3 35. Kd4 a5 36. Kc5 a4 37. Kb4 a3 38. Kxa3 Kc4 39. Ka4 Kc5 40. Ka5 Kc6 41. Ka6 Kc7 42. Ka7 Kc8 43. Ka8 Kc7 44. Ka7 Kc8 45. Ka8 Kc7 46. Ka7 Kc8 47. Ka8 Kc7 48. Ka7 Kc8 49. Ka8 Kc7 50. Ka7 Kc8 51. Ka8 Kc7 52. Ka7 Kc8 53. Ka8 Kc7 54. Ka7 Kc8 55. Ka8 Kc7 56. Ka7 Kc8 57. Ka8 Kc7 58. Ka7 Kc8 59. Ka8 Kc7 60. Ka7 Kc8 61. Ka8 Kc7 62. Ka7 Kc8 63. Ka8 Kc7 64. Ka7 Kc8 65. Ka8 Kc7 66. Ka7 Kc8 67. Ka8 Kc7 68. Ka7 Kc8 69. Ka8 Kc7 70. Ka7 Kc8 71. Ka8 Kc7 72. Ka7 Kc8 73. Ka8 Kc7 74. Ka7 Kc8 75. Ka8 Kc7 76. Ka7 Kc8 77. Ka8 Kc7 78. Ka7 Kc8 79. Ka8 Kc",
          "aggressive_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4",
            "b6",
            "Nbd2",
            "Bb7",
            "c4",
            "c5",
            "Qc2",
            "Nc6",
            "Rac1",
            "Rc8",
            "Rfd1",
            "Qd7",
            "dxc5",
            "bxc5",
            "Nb3",
            "Qe7",
            "Nxc5",
            "Nxc5",
            "Qxc5",
            "Rfd8",
            "Qc2",
            "d4",
            "exd4",
            "Bxd4",
            "Ne5",
            "Bxe5",
            "Bxe5",
            "Qxe5",
            "Bxf6",
            "gxf6",
            "Qxf6",
            "Qxf6",
            "Rxd8+",
            "Rxd8",
            "Rxd8+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rxh7",
            "Kxh7",
            "h3",
            "Kg7",
            "g4",
            "Kf6",
            "Kg2",
            "Ke5",
            "Kg3",
            "Kd5",
            "f4",
            "Kc4",
            "Kf3",
            "Kb3",
            "Ke3",
            "Kxa2",
            "Kd3",
            "Kb3",
            "Kd4",
            "a5",
            "Kc5",
            "a4",
            "Kb4",
            "a3",
            "Kxa3",
            "Kc4",
            "Ka4",
            "Kc5",
            "Ka5",
            "Kc6",
            "Ka6",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 * Be7 h3 Bd6",
          "positional_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Bd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O",
          "neutral_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 43,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3",
            "O-O",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4",
              "b6",
              "Nbd2",
              "Bb7",
              "c4",
              "c5",
              "Qc2",
              "Nc6",
              "Rac1",
              "Rc8",
              "Rfd1",
              "Qd7",
              "dxc5",
              "bxc5",
              "Nb3",
              "Qe7",
              "Nxc5",
              "Nxc5",
              "Qxc5",
              "Rfd8",
              "Qc2",
              "d4",
              "exd4",
              "Bxd4",
              "Ne5",
              "Bxe5",
              "Bxe5",
              "Qxe5",
              "Bxf6",
              "gxf6",
              "Qxf6",
              "Qxf6",
              "Rxd8+",
              "Rxd8",
              "Rxd8+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rxh7",
              "Kxh7",
              "h3",
              "Kg7",
              "g4",
              "Kf6",
              "Kg2",
              "Ke5",
              "Kg3",
              "Kd5",
              "f4",
              "Kc4",
              "Kf3",
              "Kb3",
              "Ke3",
              "Kxa2",
              "Kd3",
              "Kb3",
              "Kd4",
              "a5",
              "Kc5",
              "a4",
              "Kb4",
              "a3",
              "Kxa3",
              "Kc4",
              "Ka4",
              "Kc5",
              "Ka5",
              "Kc6",
              "Ka6",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h3",
              "Bd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bd3",
              "O-O",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 139,
            "completion_tokens": 43,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 419,
          "total_completion_tokens": 721,
          "total_tokens": 1140
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 139,
            "completion_tokens": 43,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p2B1/3P4/4PN2/PPP2PPP/RN1QKB1R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd7",
          "aggressive_uci": "b8d7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 *\nBlack Nbd7 O-O c6",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "c6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e8g8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 * O-O Nbd7 h6",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 44,
            "total_tokens": 190,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "h6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8d7",
          "positional_uci": "e8g8",
          "neutral_uci": "e8g8",
          "consensus_move": "e8g8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "c6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h6",
              "Bh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "h6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 44,
            "total_tokens": 190,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 139,
          "total_tokens": 579
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 44,
            "total_tokens": 190,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1QK2R b KQkq - 2 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "h6",
          "aggressive_uci": "h7h6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h6",
          "positional_uci": "h7h6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "h6",
          "neutral_uci": "h7h6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 58,
            "total_tokens": 211,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h7h6",
          "positional_uci": "h7h6",
          "neutral_uci": "h7h6",
          "consensus_move": "h7h6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 58,
            "total_tokens": 211,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 174,
          "total_tokens": 635
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 58,
            "total_tokens": 211,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1Q1RK1 b - - 4 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b6",
          "aggressive_uci": "b7b6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. Ne5\nBlack Ne4 Bxe4 Qc8",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Bb7",
            "Ne5",
            "Ne4",
            "Bxe4",
            "Qc8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b6",
          "positional_uci": "b7b6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. c4\nb6 Bb7 c4",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 74,
            "total_tokens": 235,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb7",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "b6",
          "neutral_uci": "b7b6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. c4",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 66,
            "total_tokens": 226,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Bb7",
            "c4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b7b6",
          "positional_uci": "b7b6",
          "neutral_uci": "b7b6",
          "consensus_move": "b7b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd2",
              "Bb7",
              "Ne5",
              "Ne4",
              "Bxe4",
              "Qc8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd2",
              "Bb7",
              "c4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 74,
            "total_tokens": 235,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 66,
            "total_tokens": 226,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 216,
          "total_tokens": 698
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 74,
            "total_tokens": 235,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 66,
            "total_tokens": 226,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bpp1/4pn1p/3p4/3P3B/3BPN2/PPP2PPP/RN1Q1RK1 b - - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb7",
          "aggressive_uci": "c8b7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2",
          "aggressive_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Qc2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb7",
          "positional_uci": "c8b7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1\nBb7 Nc3 Rc1",
          "positional_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 84,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Rc1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb7",
          "neutral_uci": "c8b7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2",
          "neutral_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Qc2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8b7",
          "positional_uci": "c8b7",
          "neutral_uci": "c8b7",
          "consensus_move": "c8b7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Nbd7",
              "Qc2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Rc1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc3",
              "Nbd7",
              "Qc2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 168,
            "completion_tokens": 84,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 503,
          "total_completion_tokens": 234,
          "total_tokens": 737
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 168,
            "completion_tokens": 84,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/p1p1bpp1/1p2pn1p/3p4/2PP3B/3BPN2/PP3PPP/RN1Q1RK1 b - - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd7",
          "aggressive_uci": "b8d7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2 c5 11. Rfd1",
          "aggressive_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc2",
            "c5",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nbd7",
          "positional_uci": "b8d7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. dxc5 bxc5",
          "positional_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 86,
            "total_tokens": 263,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rc1",
            "c5",
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nbd7",
          "neutral_uci": "b8d7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. dxc5 bxc5",
          "neutral_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 86,
            "total_tokens": 262,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rc1",
            "c5",
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8d7",
          "positional_uci": "b8d7",
          "neutral_uci": "b8d7",
          "consensus_move": "b8d7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qc2",
              "c5",
              "Rfd1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rc1",
              "c5",
              "dxc5",
              "bxc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rc1",
              "c5",
              "dxc5",
              "bxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 177,
            "completion_tokens": 86,
            "total_tokens": 263,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 176,
            "completion_tokens": 86,
            "total_tokens": 262,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 530,
          "total_completion_tokens": 255,
          "total_tokens": 785
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 177,
            "completion_tokens": 86,
            "total_tokens": 263,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 176,
            "completion_tokens": 86,
            "total_tokens": 262,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rn1q1rk1/pbp1bpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/R2Q1RK1 b - - 2 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd5",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 * cxd5 Nxd5 11. Bxe7 Qxe7",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c5",
          "positional_uci": "c7c5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. dxc5 bxc5",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c5",
          "neutral_uci": "c7c5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 95,
            "total_tokens": 280,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "cxd5",
            "exd5",
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "c7c5",
          "neutral_uci": "c7c5",
          "consensus_move": "c7c5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "cxd5",
              "exd5",
              "dxc5",
              "bxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 95,
            "total_tokens": 280,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 272,
          "total_tokens": 829
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 95,
            "total_tokens": 280,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pbpnbpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/2RQ1RK1 b - - 4 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "exd5",
          "aggressive_uci": "e6d5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5 13. Qa4",
          "aggressive_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qa4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "exd5",
          "positional_uci": "e6d5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5 13. Qe2\nBlack Qe2 Rfc8 Bf5",
          "positional_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 112,
            "total_tokens": 306,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qe2",
            "Qe2",
            "Rfc8",
            "Bf5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "exd5",
          "neutral_uci": "e6d5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5 13. Bxf6 Nxf6\nBlack exd5 dxc5 bxc5",
          "neutral_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 115,
            "total_tokens": 308,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e6d5",
          "positional_uci": "e6d5",
          "neutral_uci": "e6d5",
          "consensus_move": "e6d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc5",
              "bxc5",
              "Qa4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5",
              "Qe2",
              "Qe2",
              "Rfc8",
              "Bf5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc5",
              "bxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 194,
            "completion_tokens": 112,
            "total_tokens": 306,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 193,
            "completion_tokens": 115,
            "total_tokens": 308,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 581,
          "total_completion_tokens": 328,
          "total_tokens": 909
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 194,
            "completion_tokens": 112,
            "total_tokens": 306,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 193,
            "completion_tokens": 115,
            "total_tokens": 308,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p2pn1p/2pP4/3P3B/2NBPN2/PP3PPP/2RQ1RK1 b - - 0 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rc8",
          "aggressive_uci": "a8c8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. dxc5 bxc5 14. Qd2",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 110,
            "total_tokens": 313,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rc8",
          "positional_uci": "a8c8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. dxc5 bxc5 14. Qd2 *",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 111,
            "total_tokens": 314,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rc8",
          "neutral_uci": "a8c8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. dxc5 bxc5 14. Qd2\nBb7 Rc8 dxc5 bxc5 Qd2",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 125,
            "total_tokens": 327,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qd2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a8c8",
          "positional_uci": "a8c8",
          "neutral_uci": "a8c8",
          "consensus_move": "a8c8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc5",
              "bxc5",
              "Qd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5",
              "Qd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc5",
              "bxc5",
              "Qd2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 110,
            "total_tokens": 313,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 111,
            "total_tokens": 314,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 125,
            "total_tokens": 327,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 346,
          "total_tokens": 954
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 110,
            "total_tokens": 313,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 111,
            "total_tokens": 314,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 125,
            "total_tokens": 327,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2N1PN2/PP3PPP/1BRQ1RK1 b - - 1 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qc7",
          "aggressive_uci": "d8c7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. dxc5 bxc5 15. Bxf6 Nxf6",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 122,
            "total_tokens": 334,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Bxf6",
            "Nxf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe8",
          "positional_uci": "d8e8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qe8 14. dxc5 bxc5 15. Bxf6\nQe8 dxc5 bxc5 Bxf6",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 132,
            "total_tokens": 344,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qa5",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qa5 14. Ne2 Rfd8 15. Ng3\nQa5 Rfd8 Ng3",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 126,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rfd8",
            "Ng3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8c7",
          "positional_uci": "d8e8",
          "neutral_uci": null,
          "consensus_move": "d8c7",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc5",
              "bxc5",
              "Bxf6",
              "Nxf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5",
              "Bxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rfd8",
              "Ng3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 122,
            "total_tokens": 334,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 132,
            "total_tokens": 344,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 126,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 380,
          "total_tokens": 1015
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 122,
            "total_tokens": 334,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 132,
            "total_tokens": 344,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 126,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2rq1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2NQPN2/PP3PPP/1BR2RK1 b - - 3 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": "d7e5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Nd7 16. f4",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 125,
            "total_tokens": 345,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Nd7",
            "f4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe5",
          "positional_uci": "d7e5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Ng4 16. Bg3\nNg4 Bg3 Qe7",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 135,
            "total_tokens": 355,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Ng4",
            "Bg3",
            "Ng4",
            "Bg3",
            "Qe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe5",
          "neutral_uci": "d7e5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6\nBlack Nxe5 dxe5 Qxe5 Bxf6",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 141,
            "total_tokens": 360,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Qxe5",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7e5",
          "positional_uci": "d7e5",
          "neutral_uci": "d7e5",
          "consensus_move": "d7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxe5",
              "Nd7",
              "f4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxe5",
              "Ng4",
              "Bg3",
              "Ng4",
              "Bg3",
              "Qe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxe5",
              "Qxe5",
              "Bxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 125,
            "total_tokens": 345,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 135,
            "total_tokens": 355,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 141,
            "total_tokens": 360,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 401,
          "total_tokens": 1060
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 125,
            "total_tokens": 345,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 135,
            "total_tokens": 355,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 141,
            "total_tokens": 360,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pbqnbpp1/1p3n1p/2ppN3/3P3B/2NQP3/PP3PPP/1BR2RK1 b - - 5 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe5",
          "aggressive_uci": "c7e5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 * Qxe5 Qxe5 Bxe5",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne4",
          "positional_uci": "f6e4",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Ne4 16. Bxe7 Qxe7 17. f3\nNe4 f3 Bxe7 Qxe7",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 145,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "f3",
            "Bxe7",
            "Qxe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe5",
          "neutral_uci": "c7e5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qxd5\nQxe5 Qxd5 Bxf6",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd5",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c7e5",
          "positional_uci": "f6e4",
          "neutral_uci": "c7e5",
          "consensus_move": "c7e5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxe5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "f3",
              "Bxe7",
              "Qxe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxd5",
              "Bxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 145,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 419,
          "total_tokens": 1105
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 145,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pbq1bpp1/1p3n1p/2ppP3/7B/2NQP3/PP3PPP/1BR2RK1 b - - 0 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "gxf6",
          "aggressive_uci": "g7f6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 gxf6 17. Qg3+ Kh8 18. Qh4\nQg3+ Kh8 Qh4",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 154,
            "total_tokens": 392,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg3+",
            "Kh8",
            "Qh4",
            "Qg3+",
            "Kh8",
            "Qh4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "gxf6",
          "positional_uci": "g7f6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 gxf6 17. Qg3+ Kh8 18. Qh4",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 145,
            "total_tokens": 383,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg3+",
            "Kh8",
            "Qh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "e7f6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qxh6 Qg5 18. Qxg5\nBg5 Qxg5",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 151,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh6",
            "Qg5",
            "Qxg5",
            "Bg5",
            "Qxg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g7f6",
          "positional_uci": "g7f6",
          "neutral_uci": "e7f6",
          "consensus_move": "g7f6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qg3+",
              "Kh8",
              "Qh4",
              "Qg3+",
              "Kh8",
              "Qh4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qg3+",
              "Kh8",
              "Qh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxh6",
              "Qg5",
              "Qxg5",
              "Bg5",
              "Qxg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 154,
            "total_tokens": 392,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 145,
            "total_tokens": 383,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 151,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 450,
          "total_tokens": 1163
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 154,
            "total_tokens": 392,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 145,
            "total_tokens": 383,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 151,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pb2bpp1/1p3B1p/2ppq3/8/2NQP3/PP3PPP/1BR2RK1 b - - 0 16"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d6 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Nb4 15. Bb1 Bb7 16. Nbd2 Rac8 17. Nb1 Rfd8 18. Nbd2 Qb8 19. Nb1 Qb7 20. Nbd2 Qb8 21. Nb1 Qb7 22. Nbd2 Qb8 23. Nb1 Qb7 24. Nbd2 Qb8 25. Nb1 Qb7 26. Nbd2 Qb8 27. Nb1 Qb7 28. Nbd2 Qb8 29. Nb1 Qb7 30. Nbd2 Qb8 31. Nb1 Qb7 32. Nbd2 Qb8 33. Nb1 Qb7 34. Nbd2 Qb8 35. Nb1 Qb7 36. Nbd2 Qb8 37. Nb1 Qb7 38. Nbd2 Qb8 39. Nb1 Qb7 40. Nbd2 Qb8 41. Nb1 Qb7 42. Nbd2 Qb8 43. Nb1 Qb7 44. Nbd2 Qb8 45. Nb1 Qb7 46. Nbd2 Qb8 47. Nb1 Qb7 48. Nbd2 Qb8 49. Nb1 Qb7 50. Nbd2 Qb8 51. Nb1 Qb7 52. Nbd2 Qb8 53. Nb1 Qb7 54. Nbd2 Qb8 55. Nb1 Qb7 56. Nbd2 Qb8 57. Nb1 Qb7 58. Nbd2 Qb8 59. Nb1 Qb7 60. Nbd2 Qb8 61. Nb1 Qb7 62. Nbd2 Qb8 63. Nb1 Qb7 64. Nbd2 Qb8 65. Nb1 Qb7 66. Nbd2 Qb8 67. Nb1 Qb7 68. Nbd2 Qb8 69. Nb1 Qb7 70. Nbd2 Qb8 71. Nb1 Qb7 72. Nbd2 Qb8 73. Nb1 Qb7 74. Nbd2 Qb8 75. Nb1 Qb7 76. Nbd2 Qb8 77. Nb1",
          "aggressive_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Nb4",
            "Bb1",
            "Bb7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Rfd8",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Bb7 15. Be3 Rac8 16. Rc1 Qb8 17. dxe5 dxe5 18. Qxd8 Rfxd8 19. Nxe5 Nxe5 20. Bxe5 Rxc1 21. Rxc1 Bxe4 22. Bxf6 Bxf6 23. Rc7 Bxb2 24. Rb7 Bc3 25. Rxb5 Bxa1 26. Rxa5 Bc3 27. Ra7 Bb4 28. Rb7 Bc5 29. Rb5 Bb6 30. Rb7 Bc5 31. Rb5 Bb6 32. Rb7 Bc5 33. Rb5 Bb6 34. Rb7 Bc5 35. Rb5 Bb6 36. Rb7 Bc5 37. Rb5 Bb6 38. Rb7 Bc5 39. Rb5 Bb6 40. Rb7 Bc5 41. Rb5 Bb6 42. Rb7 Bc5 43. Rb5 Bb6 44. Rb7 Bc5 45. Rb5 Bb6 46. Rb7 Bc5 47. Rb5 Bb6 48. Rb7 Bc5 49. Rb5 Bb6 50. Rb7 Bc5 51. Rb5 Bb6 52. Rb7 Bc5 53. Rb5 Bb6 54. Rb7 Bc5 55. Rb5 Bb6 56. Rb7 Bc5 57. Rb5 Bb6 58. Rb7 Bc5 59. Rb5 Bb6 60. Rb7 Bc5 61. Rb5 Bb6 62. Rb7 Bc5 63. Rb5 Bb6 64. Rb7 Bc5 65. Rb5 Bb6 66. Rb7 Bc5 67. Rb5 Bb6 68. Rb7 Bc5 69. Rb5 Bb6 70. Rb7 Bc5 71. Rb5 Bb6 72. Rb7 Bc5 73. Rb5 Bb6 74. Rb7 Bc5 75. Rb5 Bb6 76. Rb7 Bc5 77. Rb5 Bb6 78. Rb7 Bc5 79. Rb5 Bb6",
          "positional_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Be3",
            "Rac8",
            "Rc1",
            "Qb8",
            "dxe5",
            "dxe5",
            "Qxd8",
            "Rfxd8",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "Rxc1",
            "Rxc1",
            "Bxe4",
            "Bxf6",
            "Bxf6",
            "Rc7",
            "Bxb2",
            "Rb7",
            "Bc3",
            "Rxb5",
            "Bxa1",
            "Rxa5",
            "Bc3",
            "Ra7",
            "Bb4",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Nb4 15. Bb1 Bb7 16. a3 Nc6 17. d5 Nb8 18. Be3 Qd7 19. Qd2 Rc8 20. Rac1 Rxc1 21. Rxc1 Rc8 22. Rxc8+ Qxc8 23. Qc3 Qxc3 24. bxc3 Na6 25. c4 bxc4 26. Nxc4 Nb4 27. Nd2 Bc8 28. Nb3 Bd7 29. Nc5 Bc8 30. Nb7 Bxb7 31. Bxb7 Nc2 32. Bxa6 Nxa3 33. Bb5 Nb1 34. Bc6 Nc3 35. Bxd6 Nxd5 36. exd5 exd5 37. Bxf8 Kxf8 38. Nc5 Ke7 39. Nxd7 Kxd7 40. Kf1 Ke6 41. Ke2 Kd5 42. Kd3 f5 43. f3 g5 44. g3 h5 45. h4 g4 46. fxg4 fxg4 47. Kc3 Kc5 48. Kb3 Kb5 49. Ka3 Ka5 50. Kb3 Kb5 51. Ka3 Ka5 52. Kb3 Kb5 53. Ka3 Ka5 54. Kb3 Kb5 55. Ka3 Ka5 56. Kb3 Kb5 57. Ka3 Ka5 58. Kb3 Kb5 59. Ka3 Ka5 60. Kb3 Kb5 61. Ka3 Ka5 62. Kb3 Kb5 63. Ka3 Ka5 64. Kb3 Kb5 65. Ka3 Ka5 66. Kb3 Kb5 67. Ka3 Ka5 68. Kb3 Kb5 69. Ka3 Ka5 70. Kb3 Kb5 71. Ka3 Ka5 72. Kb3 Kb5 73. Ka3 Ka5 74. Kb3 Kb5 75. Ka3 Ka5 76. Kb3 Kb5 77. Ka3 Ka5 78. Kb3 Kb5 79. Ka3 Ka5",
          "neutral_tokens": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Nb4",
            "Bb1",
            "Bb7",
            "a3",
            "Nc6",
            "d5",
            "Nb8",
            "Be3",
            "Qd7",
            "Qd2",
            "Rc8",
            "Rac1",
            "Rxc1",
            "Rxc1",
            "Rc8",
            "Rxc8+",
            "Qxc8",
            "Qc3",
            "Qxc3",
            "bxc3",
            "Na6",
            "c4",
            "bxc4",
            "Nxc4",
            "Nb4",
            "Nd2",
            "Bc8",
            "Nb3",
            "Bd7",
            "Nc5",
            "Bc8",
            "Nb7",
            "Bxb7",
            "Bxb7",
            "Nc2",
            "Bxa6",
            "Nxa3",
            "Bb5",
            "Nb1",
            "Bc6",
            "Nc3",
            "Bxd6",
            "Nxd5",
            "exd5",
            "exd5",
            "Bxf8",
            "Kxf8",
            "Nc5",
            "Ke7",
            "Nxd7",
            "Kxd7",
            "Kf1",
            "Ke6",
            "Ke2",
            "Kd5",
            "Kd3",
            "f5",
            "f3",
            "g5",
            "g3",
            "h5",
            "h4",
            "g4",
            "fxg4",
            "fxg4",
            "Kc3",
            "Kc5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Nb4",
              "Bb1",
              "Bb7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Rfd8",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Be3",
              "Rac8",
              "Rc1",
              "Qb8",
              "dxe5",
              "dxe5",
              "Qxd8",
              "Rfxd8",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "Rxc1",
              "Rxc1",
              "Bxe4",
              "Bxf6",
              "Bxf6",
              "Rc7",
              "Bxb2",
              "Rb7",
              "Bc3",
              "Rxb5",
              "Bxa1",
              "Rxa5",
              "Bc3",
              "Ra7",
              "Bb4",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Nb4",
              "Bb1",
              "Bb7",
              "a3",
              "Nc6",
              "d5",
              "Nb8",
              "Be3",
              "Qd7",
              "Qd2",
              "Rc8",
              "Rac1",
              "Rxc1",
              "Rxc1",
              "Rc8",
              "Rxc8+",
              "Qxc8",
              "Qc3",
              "Qxc3",
              "bxc3",
              "Na6",
              "c4",
              "bxc4",
              "Nxc4",
              "Nb4",
              "Nd2",
              "Bc8",
              "Nb3",
              "Bd7",
              "Nc5",
              "Bc8",
              "Nb7",
              "Bxb7",
              "Bxb7",
              "Nc2",
              "Bxa6",
              "Nxa3",
              "Bb5",
              "Nb1",
              "Bc6",
              "Nc3",
              "Bxd6",
              "Nxd5",
              "exd5",
              "exd5",
              "Bxf8",
              "Kxf8",
              "Nc5",
              "Ke7",
              "Nxd7",
              "Kxd7",
              "Kf1",
              "Ke6",
              "Ke2",
              "Kd5",
              "Kd3",
              "f5",
              "f3",
              "g5",
              "g3",
              "h5",
              "h4",
              "g4",
              "fxg4",
              "fxg4",
              "Kc3",
              "Kc5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 335,
          "total_completion_tokens": 1920,
          "total_tokens": 2255
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Ng5 cxd4 cxd4 Nc6 Nxc6 Qxc6 Qf3 Be6 Rad1 Rfd8 Qg3 Rac8 Bb3 h6 Nf3 Qb6 Be3 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Ng5",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nxc6",
            "Qxc6",
            "Qf3",
            "Be6",
            "Rad1",
            "Rfd8",
            "Qg3",
            "Rac8",
            "Bb3",
            "h6",
            "Nf3",
            "Qb6",
            "Be3",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nb6 Nb3 Bg4 Be3 Rfc8 Rc1 Qb7 Qd3 Rac8 Rg1 Qa8 Qf1 Bxf3 Qxf3 Qb7 Qg3 Qxg3 fxg3 Nd7 Rcf1 Nf8 Bb1 Ne6 Bxe6 fxe6 Rxf8+ Kxf8 Rf1+ Ke8 Kg2 Kd7 Kf3 Kc6 Ke4 Kb6 Kd3 Kc6 Kc3 Kb6 Kb3 Kc6 a3 Kb6 a4 Kc6 a5 Kb5 axb6 Kxb6 b4 Kc6 Kc4 Kb6 c5+ dxc5 bxc5+ Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 K",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nb6",
            "Nb3",
            "Bg4",
            "Be3",
            "Rfc8",
            "Rc1",
            "Qb7",
            "Qd3",
            "Rac8",
            "Rg1",
            "Qa8",
            "Qf1",
            "Bxf3",
            "Qxf3",
            "Qb7",
            "Qg3",
            "Qxg3",
            "fxg3",
            "Nd7",
            "Rcf1",
            "Nf8",
            "Bb1",
            "Ne6",
            "Bxe6",
            "fxe6",
            "Rxf8+",
            "Kxf8",
            "Rf1+",
            "Ke8",
            "Kg2",
            "Kd7",
            "Kf3",
            "Kc6",
            "Ke4",
            "Kb6",
            "Kd3",
            "Kc6",
            "Kc3",
            "Kb6",
            "Kb3",
            "Kc6",
            "a3",
            "Kb6",
            "a4",
            "Kc6",
            "a5",
            "Kb5",
            "axb6",
            "Kxb6",
            "b4",
            "Kc6",
            "Kc4",
            "Kb6",
            "c5+",
            "dxc5",
            "bxc5+",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Ng5",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nxc6",
              "Qxc6",
              "Qf3",
              "Be6",
              "Rad1",
              "Rfd8",
              "Qg3",
              "Rac8",
              "Bb3",
              "h6",
              "Nf3",
              "Qb6",
              "Be3",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nb6",
              "Nb3",
              "Bg4",
              "Be3",
              "Rfc8",
              "Rc1",
              "Qb7",
              "Qd3",
              "Rac8",
              "Rg1",
              "Qa8",
              "Qf1",
              "Bxf3",
              "Qxf3",
              "Qb7",
              "Qg3",
              "Qxg3",
              "fxg3",
              "Nd7",
              "Rcf1",
              "Nf8",
              "Bb1",
              "Ne6",
              "Bxe6",
              "fxe6",
              "Rxf8+",
              "Kxf8",
              "Rf1+",
              "Ke8",
              "Kg2",
              "Kd7",
              "Kf3",
              "Kc6",
              "Ke4",
              "Kb6",
              "Kd3",
              "Kc6",
              "Kc3",
              "Kb6",
              "Kb3",
              "Kc6",
              "a3",
              "Kb6",
              "a4",
              "Kc6",
              "a5",
              "Kb5",
              "axb6",
              "Kxb6",
              "b4",
              "Kc6",
              "Kc4",
              "Kb6",
              "c5+",
              "dxc5",
              "bxc5+",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 1920,
          "total_tokens": 2273
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 *\ne4 e5 Nf3 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Nbd2 Rac8 Nb1 Rfe8 Nc3 Bf8 Nb5 Qb8 Be3 Nb4 Bxb4 Qxb4 a3 Qb6 Qd3 g6 Rac1 Qd8 Rxc8 Qxc8 Qc2 Qxc2 Bxc2 Rc8 Bb3 Rc3 Bd1 Kf8 f3 Ke8 Kf2 Kd7 Ke2 Kc7 Kd2 Kb6 Kc2 Ka5 Kb2 Kb4 a4 Kc4 Bc2 Kd4 Bb3 Ke3 Bc2 Kf4 Bb3 Kg3 Bc2 Kh4 Bb3 Kh5 Bc2 Kh6 Bb3 Kg7 Bc2 Kf8 Bb3 Ke8 Bc2 Kd7 Bb3 Kc7 Bc2 Kb6 Bb3 Ka5 Bc2 Kb4 a5 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 a6 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 a7 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 a8=Q Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 Qa7 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Rfe8",
            "Nc3",
            "Bf8",
            "Nb5",
            "Qb8",
            "Be3",
            "Nb4",
            "Bxb4",
            "Qxb4",
            "a3",
            "Qb6",
            "Qd3",
            "g6",
            "Rac1",
            "Qd8",
            "Rxc8",
            "Qxc8",
            "Qc2",
            "Qxc2",
            "Bxc2",
            "Rc8",
            "Bb3",
            "Rc3",
            "Bd1",
            "Kf8",
            "f3",
            "Ke8",
            "Kf2",
            "Kd7",
            "Ke2",
            "Kc7",
            "Kd2",
            "Kb6",
            "Kc2",
            "Ka5",
            "Kb2",
            "Kb4",
            "a4",
            "Kc4",
            "Bc2",
            "Kd4",
            "Bb3",
            "Ke3",
            "Bc2",
            "Kf4",
            "Bb3",
            "Kg3",
            "Bc2",
            "Kh4",
            "Bb3",
            "Kh5",
            "Bc2",
            "Kh6",
            "Bb3",
            "Kg7",
            "Bc2",
            "Kf8",
            "Bb3",
            "Ke8",
            "Bc2",
            "Kd7",
            "Bb3",
            "Kc7",
            "Bc2",
            "Kb6",
            "Bb3",
            "Ka5",
            "Bc2",
            "Kb4",
            "a5",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "a6",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "a7",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "a8=Q",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "Qa7",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 exd4 Nb3 Nxb3 axb3 Bb7 Nxd4 Rfe8 Nf5 Bf8 Bd3 g6 Nh6+ Kg7 Qf3 Bg7 Qg3 Qf4 Qxf4 Bxf4 Bxf4 Nxe4 Bxe4 Rxe4 Rxe4 Bxe4 Re1 Bf5 Re7+ Kg8 Rxh7 Be6 Rh8+ Kxh8 Bg5 Kg7 Bf6+ Kg8 Be7 Kf7 Bxd6 Ke6 Bc5 Kd5 Bxb7 Kc4 Bxa6 Kb3 Bxb5 Ka3 Bc4 Kb2 Bd3 Kc3 Be4 Kd2 Bf5 Ke3 Bg6 Kf4 Bh5 Kg5 Bg6 Kh6 Bf7+ Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "exd4",
            "Nb3",
            "Nxb3",
            "axb3",
            "Bb7",
            "Nxd4",
            "Rfe8",
            "Nf5",
            "Bf8",
            "Bd3",
            "g6",
            "Nh6+",
            "Kg7",
            "Qf3",
            "Bg7",
            "Qg3",
            "Qf4",
            "Qxf4",
            "Bxf4",
            "Bxf4",
            "Nxe4",
            "Bxe4",
            "Rxe4",
            "Rxe4",
            "Bxe4",
            "Re1",
            "Bf5",
            "Re7+",
            "Kg8",
            "Rxh7",
            "Be6",
            "Rh8+",
            "Kxh8",
            "Bg5",
            "Kg7",
            "Bf6+",
            "Kg8",
            "Be7",
            "Kf7",
            "Bxd6",
            "Ke6",
            "Bc5",
            "Kd5",
            "Bxb7",
            "Kc4",
            "Bxa6",
            "Kb3",
            "Bxb5",
            "Ka3",
            "Bc4",
            "Kb2",
            "Bd3",
            "Kc3",
            "Be4",
            "Kd2",
            "Bf5",
            "Ke3",
            "Bg6",
            "Kf4",
            "Bh5",
            "Kg5",
            "Bg6",
            "Kh6",
            "Bf7+",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Rfe8",
              "Nc3",
              "Bf8",
              "Nb5",
              "Qb8",
              "Be3",
              "Nb4",
              "Bxb4",
              "Qxb4",
              "a3",
              "Qb6",
              "Qd3",
              "g6",
              "Rac1",
              "Qd8",
              "Rxc8",
              "Qxc8",
              "Qc2",
              "Qxc2",
              "Bxc2",
              "Rc8",
              "Bb3",
              "Rc3",
              "Bd1",
              "Kf8",
              "f3",
              "Ke8",
              "Kf2",
              "Kd7",
              "Ke2",
              "Kc7",
              "Kd2",
              "Kb6",
              "Kc2",
              "Ka5",
              "Kb2",
              "Kb4",
              "a4",
              "Kc4",
              "Bc2",
              "Kd4",
              "Bb3",
              "Ke3",
              "Bc2",
              "Kf4",
              "Bb3",
              "Kg3",
              "Bc2",
              "Kh4",
              "Bb3",
              "Kh5",
              "Bc2",
              "Kh6",
              "Bb3",
              "Kg7",
              "Bc2",
              "Kf8",
              "Bb3",
              "Ke8",
              "Bc2",
              "Kd7",
              "Bb3",
              "Kc7",
              "Bc2",
              "Kb6",
              "Bb3",
              "Ka5",
              "Bc2",
              "Kb4",
              "a5",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "a6",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "a7",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "a8=Q",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "Qa7",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "exd4",
              "Nb3",
              "Nxb3",
              "axb3",
              "Bb7",
              "Nxd4",
              "Rfe8",
              "Nf5",
              "Bf8",
              "Bd3",
              "g6",
              "Nh6+",
              "Kg7",
              "Qf3",
              "Bg7",
              "Qg3",
              "Qf4",
              "Qxf4",
              "Bxf4",
              "Bxf4",
              "Nxe4",
              "Bxe4",
              "Rxe4",
              "Rxe4",
              "Bxe4",
              "Re1",
              "Bf5",
              "Re7+",
              "Kg8",
              "Rxh7",
              "Be6",
              "Rh8+",
              "Kxh8",
              "Bg5",
              "Kg7",
              "Bf6+",
              "Kg8",
              "Be7",
              "Kf7",
              "Bxd6",
              "Ke6",
              "Bc5",
              "Kd5",
              "Bxb7",
              "Kc4",
              "Bxa6",
              "Kb3",
              "Bxb5",
              "Ka3",
              "Bc4",
              "Kb2",
              "Bd3",
              "Kc3",
              "Be4",
              "Kd2",
              "Bf5",
              "Ke3",
              "Bg6",
              "Kf4",
              "Bh5",
              "Kg5",
              "Bg6",
              "Kh6",
              "Bf7+",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 1298,
          "total_tokens": 1651
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Nbd2 Rac8 Nb1 Nb4 Bb1 Rfe8 Nbd2 Bf8 Nb1 g6 Nbd2 Bg7 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Nb4",
            "Bb1",
            "Rfe8",
            "Nbd2",
            "Bf8",
            "Nb1",
            "g6",
            "Nbd2",
            "Bg7",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 d6 c3 O-O h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Bd3 exd4 Nfxd4 Nxd4 Nxd4 Qb6 Be3 Rfe8 Qf3 Bf8 Rac1 Rac8 Rxc8 Rxc8 Rc1 Rxc1 Qxc1 Qc7 Qxc7 Bxc7 Kf1 Kf8 Ke2 Ke7 Kd3 Kd7 Kc4 Bb6 f3 f6 g4 g5 Kb5 Bc7 Ka6 Kc6 Ka7 Bb6+ Ka6 Bc7\nKa6 Bc7 Ka7 Bb6+ Ka6 Bc7",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 202,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Bd3",
            "exd4",
            "Nfxd4",
            "Nxd4",
            "Nxd4",
            "Qb6",
            "Be3",
            "Rfe8",
            "Qf3",
            "Bf8",
            "Rac1",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Rc1",
            "Rxc1",
            "Qxc1",
            "Qc7",
            "Qxc7",
            "Bxc7",
            "Kf1",
            "Kf8",
            "Ke2",
            "Ke7",
            "Kd3",
            "Kd7",
            "Kc4",
            "Bb6",
            "f3",
            "f6",
            "g4",
            "g5",
            "Kb5",
            "Bc7",
            "Ka6",
            "Kc6",
            "Ka7",
            "Bb6+",
            "Ka6",
            "Bc7",
            "Ka6",
            "Bc7",
            "Ka7",
            "Bb6+",
            "Ka6",
            "Bc7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Nb4",
              "Bb1",
              "Rfe8",
              "Nbd2",
              "Bf8",
              "Nb1",
              "g6",
              "Nbd2",
              "Bg7",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Bd3",
              "exd4",
              "Nfxd4",
              "Nxd4",
              "Nxd4",
              "Qb6",
              "Be3",
              "Rfe8",
              "Qf3",
              "Bf8",
              "Rac1",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Rc1",
              "Rxc1",
              "Qxc1",
              "Qc7",
              "Qxc7",
              "Bxc7",
              "Kf1",
              "Kf8",
              "Ke2",
              "Ke7",
              "Kd3",
              "Kd7",
              "Kc4",
              "Bb6",
              "f3",
              "f6",
              "g4",
              "g5",
              "Kb5",
              "Bc7",
              "Ka6",
              "Kc6",
              "Ka7",
              "Bb6+",
              "Ka6",
              "Bc7",
              "Ka6",
              "Bc7",
              "Ka7",
              "Bb6+",
              "Ka6",
              "Bc7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 202,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 860,
          "total_tokens": 1213
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 202,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    }
  ],
  "black_responses": [
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 Nf6\nd4 Nf6 Nc3 d5 Bg5 Nbd7 e3 e6 Bd3 Be7 Nf3 O-O O-O c5 dxc5 Nxc5 Ne5 Nxd3 cxd3 Nd7 Bxe7 Qxe7 Nxd7 Bxd7 d4 Rac8 Rc1 Rc7 Qd2 Rfc8 Rc2 Qb4 Rfc1 Ba4 b3 Bb5 Nxb5 Qxd2 Rxc7 Qxc1+ Rxc1 Rxc1#\nd4 Nf6 Nc3 d5 Bg5 Nbd7 e3 e6 Bd3 Be7 Nf3 O-O O-O c5 dxc5 Nxc5 Ne5 Nxd3 cxd3 Nd7 Bxe7 Qxe7 Nxd7 Bxd7 d4 Rac8 Rc1 Rc7 Qd2 Rfc8 Rfc1 Qb4 Rxc7 Qxd2 Rxc8+ Bxc8 Nxd2 Kf8 Kf1 Ke7 Ke2 Kd6 Kd3 b6 Kc3 a5 b4 Ba6 bxa5 bxa5 Nb3 a4 Nc5 Bb5 Kb4 Bc6 Nxa4 e5 Nc3 f6 a4 e5 a5 exd4 exd4 Kc7 Kc5 Kb7 Kxd4 Ka6 Kc5 Kxa5 Nxd5 Kb7 Kd6 Bb5+ Ke7 Kc5 Bf1 g3 Ke6 Kd4 Kf5 Ke3 Kg4 Kf2 Kh3 Kg1 Bc4 Nf5 g6 Ne3 Bd3 Nd5 f5 Nf6 h6 Ne5 Be4 Nxg6 h5 Ne5 Be4 Nf7 Bd5 Ng5 Bf3 Nxf3+ Kf2 Kxh2 Kxf3 Kh3 Kf2 Kg4 Kg2 h4 gxh4 Kxh4 Kf3 Kh3 Kf2 Kg4 Ke3 Kg3 Ke2 Kxf4 Kf2 Ke4 Ke2 f4 Kf2 f3 Kf1 Ke3 Ke1 f2+ Kf1 Kf3#",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 470,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rac8",
            "Rc1",
            "Rc7",
            "Qd2",
            "Rfc8",
            "Rfc1",
            "Qb4",
            "Rxc7",
            "Qxd2",
            "Rxc8+",
            "Bxc8",
            "Nxd2",
            "Kf8",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd6",
            "Kd3",
            "b6",
            "Kc3",
            "a5",
            "b4",
            "Ba6",
            "bxa5",
            "bxa5",
            "Nb3",
            "a4",
            "Nc5",
            "Bb5",
            "Kb4",
            "Bc6",
            "Nxa4",
            "e5",
            "Nc3",
            "f6",
            "a4",
            "e5",
            "a5",
            "exd4",
            "exd4",
            "Kc7",
            "Kc5",
            "Kb7",
            "Kxd4",
            "Ka6",
            "Kc5",
            "Kxa5",
            "Nxd5",
            "Kb7",
            "Kd6",
            "Bb5+",
            "Ke7",
            "Kc5",
            "Bf1",
            "g3",
            "Ke6",
            "Kd4",
            "Kf5",
            "Ke3",
            "Kg4",
            "Kf2",
            "Kh3",
            "Kg1",
            "Bc4",
            "Nf5",
            "g6",
            "Ne3",
            "Bd3",
            "Nd5",
            "f5",
            "Nf6",
            "h6",
            "Ne5",
            "Be4",
            "Nxg6",
            "h5",
            "Ne5",
            "Be4",
            "Nf7",
            "Bd5",
            "Ng5",
            "Bf3",
            "Nxf3+",
            "Kf2",
            "Kxh2",
            "Kxf3",
            "Kh3",
            "Kf2",
            "Kg4",
            "Kg2",
            "h4",
            "gxh4",
            "Kxh4",
            "Kf3",
            "Kh3",
            "Kf2",
            "Kg4",
            "Ke3",
            "Kg3",
            "Ke2",
            "Kxf4",
            "Kf2",
            "Ke4",
            "Ke2",
            "f4",
            "Kf2",
            "f3",
            "Kf1",
            "Ke3",
            "Ke1",
            "f2+",
            "Kf1",
            "Kf3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5\n4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4\n7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8\n10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5\n13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8\n16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6\n19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8\n22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8\n25. Qe7+ Kg8 26. Qg7# 1-0\n*1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5\n4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4\n7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8\n10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5\n13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8\n16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6\n19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8\n22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8\n25. Qe7+ Kg8 26. Qg7# 1-0 1-0 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Bg7 Qe6 Nf6+ Qxf6 Bxf6 Be6 Qxb7 Rc8 Rad1 Bd7 Rxd6 Nb8 Rfd1 Rxc2 Rxd7 Nxd7 Qxd7+ Kf8 Qe7+ Kg8 Qg7#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 616,
            "total_tokens": 726,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Be6",
            "Qxb7",
            "Rc8",
            "Rad1",
            "Bd7",
            "Rxd6",
            "Nb8",
            "Rfd1",
            "Rxc2",
            "Rxd7",
            "Nxd7",
            "Qxd7+",
            "Kf8",
            "Qe7+",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 d5 2. Nf3 Nf6 3. Bg5 Bf5 4. e3 e6 5. Bd3 Bxd3 6. Qxd3 Be7 7. O-O O-O 8. Nbd2 Nbd7 9. c4 c6 10. Rac1 Re8 11. Rfe1 Nf8 12. Ne5 N6d7 13. Bxe7 Qxe7 14. Nxd7 Nxd7 15. cxd5 exd5 16. e4 dxe4 17. Rxe4 Qd6 18. Rce1 Rxe4 19. Nxe4 Qd5 20. Nc3 Qd6 21. Qe4 Nf6 22. Qe5 Qxe5 23. dxe5 Nd7 24. f4 Re8 25. Kf2 Kf8 26. Kf3 f6 27. e6 Nc5 28. f5 g6 29. g4 Ke7 30. Rd1 Rd8 31. Rxd8 Kxd8 32. Ne4 Nxe4 33. Kxe4 Ke7 34. Kd4 b6 35. b4 a6 36. a4 Kd6 37. a5 bxa5 38. bxa5 g5 39. Kc4 c5 40. e7 Kxe7 41. Kxc5 Kd7 42. Kb6 Kd6 43. Kxa6 Kc6 44. Ka7 Kc7 45. a6 Kc8 46. Kb6 Kb8 47. Kc6 Ka7 48. Kd6 Kxa6 49. Ke6 Kb6 50. Kxf6 Kc6 51. Kxg5 Kd6 52. Kh6 Ke7 53. Kxh7 Kf6 54. h4 Kf7 55. g5 Kf8 56. g6 Ke7 57. g7 Kf6 58. g8=Q Kxf5 59. Qg5+ Ke6 60. Kg6 Kd6 61. h5 Ke6 62. h6 Kd6 63. h7 Ke6 64. h8=Q Kd6 65. Qhf6+ Kd7 66. Qd5+ Kc7 67. Qdf7+ Kc8 68. Qh8# d4 d5 Nf3 Nf6 Bg5 Bf5 e3 e6 Bd3 Bxd3 Qxd3 Be7 O-O O-O Nbd2 c6 Rac1 Re8 Rfe1 Nf8 Ne5 N6d7 Bxe7 Qxe7 cxd5 exd5 Rxe4 Qd6 Qe4 Nf6 Qe",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "Bf5",
            "e3",
            "e6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "Be7",
            "O-O",
            "O-O",
            "Nbd2",
            "c6",
            "Rac1",
            "Re8",
            "Rfe1",
            "Nf8",
            "Ne5",
            "N6d7",
            "Bxe7",
            "Qxe7",
            "cxd5",
            "exd5",
            "Rxe4",
            "Qd6",
            "Qe4",
            "Nf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rac8",
              "Rc1",
              "Rc7",
              "Qd2",
              "Rfc8",
              "Rfc1",
              "Qb4",
              "Rxc7",
              "Qxd2",
              "Rxc8+",
              "Bxc8",
              "Nxd2",
              "Kf8",
              "Kf1",
              "Ke7",
              "Ke2",
              "Kd6",
              "Kd3",
              "b6",
              "Kc3",
              "a5",
              "b4",
              "Ba6",
              "bxa5",
              "bxa5",
              "Nb3",
              "a4",
              "Nc5",
              "Bb5",
              "Kb4",
              "Bc6",
              "Nxa4",
              "e5",
              "Nc3",
              "f6",
              "a4",
              "e5",
              "a5",
              "exd4",
              "exd4",
              "Kc7",
              "Kc5",
              "Kb7",
              "Kxd4",
              "Ka6",
              "Kc5",
              "Kxa5",
              "Nxd5",
              "Kb7",
              "Kd6",
              "Bb5+",
              "Ke7",
              "Kc5",
              "Bf1",
              "g3",
              "Ke6",
              "Kd4",
              "Kf5",
              "Ke3",
              "Kg4",
              "Kf2",
              "Kh3",
              "Kg1",
              "Bc4",
              "Nf5",
              "g6",
              "Ne3",
              "Bd3",
              "Nd5",
              "f5",
              "Nf6",
              "h6",
              "Ne5",
              "Be4",
              "Nxg6",
              "h5",
              "Ne5",
              "Be4",
              "Nf7",
              "Bd5",
              "Ng5",
              "Bf3",
              "Nxf3+",
              "Kf2",
              "Kxh2",
              "Kxf3",
              "Kh3",
              "Kf2",
              "Kg4",
              "Kg2",
              "h4",
              "gxh4",
              "Kxh4",
              "Kf3",
              "Kh3",
              "Kf2",
              "Kg4",
              "Ke3",
              "Kg3",
              "Ke2",
              "Kxf4",
              "Kf2",
              "Ke4",
              "Ke2",
              "f4",
              "Kf2",
              "f3",
              "Kf1",
              "Ke3",
              "Ke1",
              "f2+",
              "Kf1",
              "Kf3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Bg7",
              "Qe6",
              "Nf6+",
              "Qxf6",
              "Bxf6",
              "Be6",
              "Qxb7",
              "Rc8",
              "Rad1",
              "Bd7",
              "Rxd6",
              "Nb8",
              "Rfd1",
              "Rxc2",
              "Rxd7",
              "Nxd7",
              "Qxd7+",
              "Kf8",
              "Qe7+",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "Bf5",
              "e3",
              "e6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "Be7",
              "O-O",
              "O-O",
              "Nbd2",
              "c6",
              "Rac1",
              "Re8",
              "Rfe1",
              "Nf8",
              "Ne5",
              "N6d7",
              "Bxe7",
              "Qxe7",
              "cxd5",
              "exd5",
              "Rxe4",
              "Qd6",
              "Qe4",
              "Nf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 470,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 616,
            "total_tokens": 726,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1726,
          "total_tokens": 2055
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 470,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 616,
            "total_tokens": 726,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nf6 *\n3. c4 c6 *\n4. Nc3 dxc4 *\n5. a4 Bf5 *\n6. e3 e6 *\n7. Bxc4 Bb4 *\n8. O-O O-O *\n9. Qe2 Nbd7 *\n10. e4 Bg6 *\n11. Bd3 Bh5 *\n12. e5 Nd5 *\n13. Nxd5 cxd5 *\n14. Qe3 Bg6 *\n15. Bxg6 hxg6 *\n16. Ng5 Re8 *\n17. Qh3 Nf8 *\n18. Rd1 Rc8 *\n19. Rd3 f6 *\n20. Nf3 Qc7 *\n21. Bf4 Qc2 *\n22. Rad1 Qxb2 *\n23. exf6 gxf6 *\n24. Qh6 Rc2 *\n25. Ne5 Rxf2 *\n26. Rh3 Rxg2+ *\n27. Kh1 fxe5 *\n28. Bxe5 Re7 *\n29. Qh8+ Kf7 *\n30. Rf1+ Rf2 *\n31. Rf3+ Rxf3 *\n32. Rxf3+ Ke8 *\n33. Qxf8+ Kd7 *\n34. Qb8 Qb6 *\n35. Rf8 Kc6 *\n36. Qd6# Qxd6 *\n37. Rc8+ Kd7 *\n38. Rc7+ Qxc7 *\n39. Bxc7 Kxc7 *\n40. Kg2 Kd6 *\n41. Kf3 e5 *\n42. dxe5+ Rxe5 *\n43. Kf4 d4 *\n44. h4 d3 *\n45. h5 gxh5 *\n46. a5 d2 *\n47. a6 bxa6 *\n48. Kf3 d1=Q+ *\n49. Kf4 Qd4+ *\n50. Kf3 Re3+ *\n51. Kf2 Qd2+ *\n52. Kf1 Re1# *\nd4 d5 Nf3 Nf6 c4 c6 Nc3 dxc4 a4 Bf5 e3 e6 Bxc4 Bb4 O-O O-O Qe2 Nbd7 e4 Bg6 Bd3 Bh5 e5 Nd5 Nxd5 cxd5 Qe3 Bg6 Bxg6 hxg6 Ng5 Re8 Qh3 Nf8 Rd1 Rc8 Rd3 f6 Nf3 Qc7 Bf4 Qc2 Rd2 Qc1+ Ke2 Qc4+ Rd3 Qxb2+ exf6 gxf6 Qh6 Rc2 Ne5 Rxf2 Rh3 Rxg2 Rh8+ K",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qc7",
            "Bf4",
            "Qc2",
            "Rd2",
            "Qc1+",
            "Ke2",
            "Qc4+",
            "Rd3",
            "Qxb2+",
            "exf6",
            "gxf6",
            "Qh6",
            "Rc2",
            "Ne5",
            "Rxf2",
            "Rh3",
            "Rxg2",
            "Rh8+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nf6 3. c4 c6 4. Nc3 dxc4 5. a4 Bf5 6. e3 e6 7. Bxc4 Bb4 8. O-O O-O 9. Qe2 Nbd7 10. e4 Bg6 11. Bd3 Bh5 12. e5 Nd5 13. Nxd5 cxd5 14. Qe3 Bg6 15. Bxg6 hxg6 16. Ng5 Re8 17. Qh3 Nf8 18. Rd1 Rc8 19. Qb3 Qe7 20. Rd3 Rc4 21. Be3 Rec8 22. h4 f6 23. Nf3 Qc7 24. Bf4 Qb6 25. Qd1 Be7 26. Rb3 Qc6 27. a5 Rb4 28. Rxb4 Bxb4 29. Rc1 Qd7 30. Rxc8 Qxc8 31. Qa4 Be7 32. Qb5 Qc6 33. Qxc6 bxc6 34. Bd2 Nd7 35. exf6 gxf6 36. Kf1 e5 37. dxe5 fxe5 38. Bg5 Kf7 39. Bxe7 Kxe7 40. g4 e4 41. Nd4 c5 42. Nc6+ Kd6 43. Nxa7 Ne5 44. h5 gxh5 45. gxh5 Nf7 46. Nb5+ Kc6 47. Nc3 c4 48. Ke2 Kc5 49. a6 Kb6 50. Nxd5+ Kxa6 51. Ke3 Kb5 52. Kxe4 Kc5 53. Nc3 Kb4 54. Kd5 Kb3 55. f4 Kxb2 56. Kxc4 Kc2 57. Kd4 Kd2 58. Ne4+ Ke2 59. Ng5 Nh6 60. Ke5 Ke3 61. f5 Ng4+ 62. Ke6 Kf4 63. f6 Nh6 64. Nf7 Ng4 65. h6 Nxh6 66. Nxh6 Kg5 67. f7 Kxh6 68. f8=Q+ Kg5 69. Qf5+ Kh4 70. Qg6 Kh3 71. Kf5 Kh2 72. Kf4 Kh1 73. Kf3 Kh2 74. Qg2# e4 d5",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 603,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc7",
            "Bf4",
            "Qb6",
            "Qd1",
            "Be7",
            "Rb3",
            "Qc6",
            "a5",
            "Rb4",
            "Rxb4",
            "Bxb4",
            "Rc1",
            "Qd7",
            "Rxc8",
            "Qxc8",
            "Qa4",
            "Be7",
            "Qb5",
            "Qc6",
            "Qxc6",
            "bxc6",
            "Bd2",
            "Nd7",
            "exf6",
            "gxf6",
            "Kf1",
            "e5",
            "dxe5",
            "fxe5",
            "Bg5",
            "Kf7",
            "Bxe7",
            "Kxe7",
            "g4",
            "e4",
            "Nd4",
            "c5",
            "Nc6+",
            "Kd6",
            "Nxa7",
            "Ne5",
            "h5",
            "gxh5",
            "gxh5",
            "Nf7",
            "Nb5+",
            "Kc6",
            "Nc3",
            "c4",
            "Ke2",
            "Kc5",
            "a6",
            "Kb6",
            "Nxd5+",
            "Kxa6",
            "Ke3",
            "Kb5",
            "Kxe4",
            "Kc5",
            "Nc3",
            "Kb4",
            "Kd5",
            "Kb3",
            "f4",
            "Kxb2",
            "Kxc4",
            "Kc2",
            "Kd4",
            "Kd2",
            "Ne4+",
            "Ke2",
            "Ng5",
            "Nh6",
            "Ke5",
            "Ke3",
            "f5",
            "Ng4+",
            "Ke6",
            "Kf4",
            "f6",
            "Nh6",
            "Nf7",
            "Ng4",
            "h6",
            "Nxh6",
            "Nxh6",
            "Kg5",
            "f7",
            "Kxh6",
            "f8=Q+",
            "Kg5",
            "Qf5+",
            "Kh4",
            "Qg6",
            "Kh3",
            "Kf5",
            "Kh2",
            "Kf4",
            "Kh1",
            "Kf3",
            "Kh2",
            "Qg2#",
            "e4",
            "d5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nf6 3. c4 c6 4. Nc3 dxc4 5. a4 Bf5 6. e3 e6 7. Bxc4 Bb4 8. O-O O-O 9. Qe2 Nbd7 10. e4 Bg6 11. Bd3 Bh5 12. e5 Nd5 13. Nxd5 cxd5 14. Qe3 Bg6 15. Bxg6 hxg6 16. Ng5 Re8 17. Qh3 Nf8 18. Rd1 Rc8 19. Qb3 Qb6 20. Rd3 Be7 21. Qxb6 axb6 22. Nf3 Rc4 23. Bd2 Ra8 24. b3 Rc2 25. Rc1 Rxc1+ 26. Bxc1 Rc8 27. Bd2 Nd7 28. Rc3 Rxc3 29. Bxc3 Nb8 30. Kf1 Nc6 31. Ke2 Kf8 32. Kd3 Ke8 33. Ne1 Kd7 34. Nc2 f6 35. f4 g5 36. g3 gxf4 37. gxf4 f5 38. Ne1 g5 39. fxg5 Bxg5 40. Nf3 Be7 41. h4 Ke8 42. Bd2 Kf7 43. Bg5 Bf8 44. Bd2 Kg6 45. Ng5 Nd8 46. Nf3 Kh5 47. Bg5 Nc6 48. Bd2 Kg4 49. Ng5 Nd8 50. Nh7 Be7 51. Bg5 Bxg5 52. hxg5 Kh5 53. Nf8 Kxg5 54. Nd7 f4 55. Nxb6 Kg4 56. Ke2 Kg3 57. Kf1 Nc6 58. Nd7 Nxd4 59. b4 Nc2 60. b5 f3 61. Nc5 Ne3+ 62. Ke1 f2+ 63. Ke2 f1=Q+ 64. Kxe3 Qf2+ 65. Kd3 Qxc5 66. Kd2 Qa3 67. Kc2 Kf3 68. Kd2 Qb3 69. Kc1 Ke3 70. a5 Kd3 71. a6 Qc2# d4 d5 Nf3 Nf6 c4 c6 Nc3 dxc4 a4 Bf5 e3 e6 Bxc4 Bb4 O-O O-O Qe2 Nbd7 e5 Bg6 Bd3 Bh5 e5 Nd5 Nxd5 cxd5 Qe3 Bg6",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "c4",
            "c6",
            "Nc3",
            "dxc4",
            "a4",
            "Bf5",
            "e3",
            "e6",
            "Bxc4",
            "Bb4",
            "O-O",
            "O-O",
            "Qe2",
            "Nbd7",
            "e5",
            "Bg6",
            "Bd3",
            "Bh5",
            "e5",
            "Nd5",
            "Nxd5",
            "cxd5",
            "Qe3",
            "Bg6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qc7",
              "Bf4",
              "Qc2",
              "Rd2",
              "Qc1+",
              "Ke2",
              "Qc4+",
              "Rd3",
              "Qxb2+",
              "exf6",
              "gxf6",
              "Qh6",
              "Rc2",
              "Ne5",
              "Rxf2",
              "Rh3",
              "Rxg2",
              "Rh8+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qc7",
              "Bf4",
              "Qb6",
              "Qd1",
              "Be7",
              "Rb3",
              "Qc6",
              "a5",
              "Rb4",
              "Rxb4",
              "Bxb4",
              "Rc1",
              "Qd7",
              "Rxc8",
              "Qxc8",
              "Qa4",
              "Be7",
              "Qb5",
              "Qc6",
              "Qxc6",
              "bxc6",
              "Bd2",
              "Nd7",
              "exf6",
              "gxf6",
              "Kf1",
              "e5",
              "dxe5",
              "fxe5",
              "Bg5",
              "Kf7",
              "Bxe7",
              "Kxe7",
              "g4",
              "e4",
              "Nd4",
              "c5",
              "Nc6+",
              "Kd6",
              "Nxa7",
              "Ne5",
              "h5",
              "gxh5",
              "gxh5",
              "Nf7",
              "Nb5+",
              "Kc6",
              "Nc3",
              "c4",
              "Ke2",
              "Kc5",
              "a6",
              "Kb6",
              "Nxd5+",
              "Kxa6",
              "Ke3",
              "Kb5",
              "Kxe4",
              "Kc5",
              "Nc3",
              "Kb4",
              "Kd5",
              "Kb3",
              "f4",
              "Kxb2",
              "Kxc4",
              "Kc2",
              "Kd4",
              "Kd2",
              "Ne4+",
              "Ke2",
              "Ng5",
              "Nh6",
              "Ke5",
              "Ke3",
              "f5",
              "Ng4+",
              "Ke6",
              "Kf4",
              "f6",
              "Nh6",
              "Nf7",
              "Ng4",
              "h6",
              "Nxh6",
              "Nxh6",
              "Kg5",
              "f7",
              "Kxh6",
              "f8=Q+",
              "Kg5",
              "Qf5+",
              "Kh4",
              "Qg6",
              "Kh3",
              "Kf5",
              "Kh2",
              "Kf4",
              "Kh1",
              "Kf3",
              "Kh2",
              "Qg2#",
              "e4",
              "d5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "c4",
              "c6",
              "Nc3",
              "dxc4",
              "a4",
              "Bf5",
              "e3",
              "e6",
              "Bxc4",
              "Bb4",
              "O-O",
              "O-O",
              "Qe2",
              "Nbd7",
              "e5",
              "Bg6",
              "Bd3",
              "Bh5",
              "e5",
              "Nd5",
              "Nxd5",
              "cxd5",
              "Qe3",
              "Bg6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 603,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1883,
          "total_tokens": 2230
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 603,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": "c1g5",
          "aggressive_response": "3. Bg5 Bf5 4. e3 e6 5. Bd3 Bxd3 6. Qxd3 Nbd7 7. Nbd2 Be7 8. O-O O-O 9. c4 c6 10. Rac1 Rc8 11. Rc2 h6 12. Bh4 Nh7 13. Bxe7 Qxe7 14. Rfc1 f5 15. cxd5 exd5 16. Nb3 Ng5 17. Nxg5 Qxg5 18. Nc5 Nxc5 19. Rxc5 f4 20. e4 f3 21. g3 Qg4 22. exd5 cxd5 23. Rxc8 Rxc8 24. Rxc8+ Qxc8 25. Qxf3 Qc1+ 26. Kg2 Qxb2 27. Qxd5+ Kh7 28. Qe4+ Kg8 29. d5 Qxa2 30. d6 Qf7 31. Qe7 Qd5+ 32. Kh3 Qf5+ 33. Kg2 Qd5+ 34. f3 Qd2+ 35. Kh3 Qd5 36. d7 Qf5+ 37. Kg2 Qc2+ 38. Kf1 Qd1+ 39. Kf2 Qd2+ 40. Kg1 Qd1+ 41. Kg2 Qd2+ 42. Kh3 Qd5 43. d8=Q+ Qxd8 44. Qxd8+ Kh7 45. Qc7 b5 46. Qxa7 b4 47. Qb6 b3 48. Qxb3 Kg6 49. Qd3+ Kf6 50. Qe4 g5 51. f4 gxf4 52. gxf4 h5 53. Qe5+ Kg6 54. Qg5+ Kf7 55. Qxh5+ Kf6 56. Qg5+ Ke6 57. Kg4 Kd6 58. h4 Ke6 59. h5 Kd6 60. h6 Ke6 61. h7 Kd6 62. h8=Q Ke6 63. Qhh6+ Kf7 64. Qgg7+ Ke8 65. Qhh8# d4 d5 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 545,
            "total_tokens": 670,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bf5",
            "e3",
            "e6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "Nbd7",
            "Nbd2",
            "Be7",
            "O-O",
            "O-O",
            "c4",
            "c6",
            "Rac1",
            "Rc8",
            "Rc2",
            "h6",
            "Bh4",
            "Nh7",
            "Bxe7",
            "Qxe7",
            "Rfc1",
            "f5",
            "cxd5",
            "exd5",
            "Nb3",
            "Ng5",
            "Nxg5",
            "Qxg5",
            "Nc5",
            "Nxc5",
            "Rxc5",
            "f4",
            "e4",
            "f3",
            "g3",
            "Qg4",
            "exd5",
            "cxd5",
            "Rxc8",
            "Rxc8",
            "Rxc8+",
            "Qxc8",
            "Qxf3",
            "Qc1+",
            "Kg2",
            "Qxb2",
            "Qxd5+",
            "Kh7",
            "Qe4+",
            "Kg8",
            "d5",
            "Qxa2",
            "d6",
            "Qf7",
            "Qe7",
            "Qd5+",
            "Kh3",
            "Qf5+",
            "Kg2",
            "Qd5+",
            "f3",
            "Qd2+",
            "Kh3",
            "Qd5",
            "d7",
            "Qf5+",
            "Kg2",
            "Qc2+",
            "Kf1",
            "Qd1+",
            "Kf2",
            "Qd2+",
            "Kg1",
            "Qd1+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qd5",
            "d8=Q+",
            "Qxd8",
            "Qxd8+",
            "Kh7",
            "Qc7",
            "b5",
            "Qxa7",
            "b4",
            "Qb6",
            "b3",
            "Qxb3",
            "Kg6",
            "Qd3+",
            "Kf6",
            "Qe4",
            "g5",
            "f4",
            "gxf4",
            "gxf4",
            "h5",
            "Qe5+",
            "Kg6",
            "Qg5+",
            "Kf7",
            "Qxh5+",
            "Kf6",
            "Qg5+",
            "Ke6",
            "Kg4",
            "Kd6",
            "h4",
            "Ke6",
            "h5",
            "Kd6",
            "h6",
            "Ke6",
            "h7",
            "Kd6",
            "h8=Q",
            "Ke6",
            "Qhh6+",
            "Kf7",
            "Qgg7+",
            "Ke8",
            "Qhh8#",
            "d4",
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 c4 18. Bc2 Nc5 19. Nf3 Rxf4 20. Nd4 Raf8 21. Rxf4 Rxf4 22. Qe3 Rf8 23. Nb5 Bc6 24. Nd6 Nb7 25. Nxb7 Bxb7 26. Rf1 Rxf1+ 27. Kxf1 Qf7+ 28. Ke2 Kg7 29. Qg5 Bc6 30. h4 Be8 31. h5 h6 32. hxg6 hxg5 33. gxf7 Bxf7 34. Ke3 Bg6 35. Ba4 Bb1 36. a3 Kg6 37. Bd7 Kf5 38. Kd4 Be4 39. g3 Kg4 40. Bxe6+ Kxg3 41. Bxd5 Bxd5 42. Kxd5 Kf4 43. e6 g4 44. e7 g3 45. e8=Q g2 46. Qe1 Kf3 47. Qg1 b5 48. Kc5 a6 49. Kb6 Ke2 50. Kxa6 Kd2 51. Kxb5 Kc2 52. Kxc4 Kxb2 53. Qxg2+ Kxa3 54. Qb7 Ka2 55. Kd3 Ka1 56. Kc2 Ka2 57. Qb2# e4 e5 g5",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 457,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "c4",
            "Bc2",
            "Nc5",
            "Nf3",
            "Rxf4",
            "Nd4",
            "Raf8",
            "Rxf4",
            "Rxf4",
            "Qe3",
            "Rf8",
            "Nb5",
            "Bc6",
            "Nd6",
            "Nb7",
            "Nxb7",
            "Bxb7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qf7+",
            "Ke2",
            "Kg7",
            "Qg5",
            "Bc6",
            "h4",
            "Be8",
            "h5",
            "h6",
            "hxg6",
            "hxg5",
            "gxf7",
            "Bxf7",
            "Ke3",
            "Bg6",
            "Ba4",
            "Bb1",
            "a3",
            "Kg6",
            "Bd7",
            "Kf5",
            "Kd4",
            "Be4",
            "g3",
            "Kg4",
            "Bxe6+",
            "Kxg3",
            "Bxd5",
            "Bxd5",
            "Kxd5",
            "Kf4",
            "e6",
            "g4",
            "e7",
            "g3",
            "e8=Q",
            "g2",
            "Qe1",
            "Kf3",
            "Qg1",
            "b5",
            "Kc5",
            "a6",
            "Kb6",
            "Ke2",
            "Kxa6",
            "Kd2",
            "Kxb5",
            "Kc2",
            "Kxc4",
            "Kxb2",
            "Qxg2+",
            "Kxa3",
            "Qb7",
            "Ka2",
            "Kd3",
            "Ka1",
            "Kc2",
            "Ka2",
            "Qb2#",
            "e4",
            "e5",
            "g5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": null,
          "neutral_response": "3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 c4 18. Bc2 Nc5 19. Nf3 Rxf4 20. Nd4 Raf8 21. Rxf4 Rxf4 22. Qg3 Qf7 23. h4 Ne4 24. Bxe4 dxe4 25. h5 Bd5 26. hxg6 hxg6 27. Re1 Kg7 28. Qg5 Rf2 29. Re3 Rxb2 30. Rh3 Qf2+ 31. Kh2 Qxg2+ 32. Qxg2 Rxg2+ 33. Kxg2 e3+ 34. Kf1 g5 35. Rxe3 Kg6 36. Kf2 g4 37. Kg3 Kg5 38. Re1 a6 39. Rf1 b5 40. Rf6 b4 41. Nxe6+ Bxe6 42. Rxe6 bxc3 43. Rc6 Kf5 44. Rxc4 Kxe5 45. Rxc3 Kd4 46. Ra3 Kc4 47. Rxa6 Kb4 48. Kxg4 Kb5 49. Ra8 Kb6 50. Kf5 Kb7 51. Ra3 Kb6 52. Ke5 Kb5 53. Kd5 Kb4 54. Rb3+ Ka4 55. Kc5 Ka5 56. Ra3# 1-0 3. Bxf6 gxf6 4. Qxf6#",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 460,
            "total_tokens": 584,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf6",
            "Qxf6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1g5",
          "positional_uci": "c1g5",
          "neutral_uci": null,
          "consensus_move": "c1g5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bf5",
              "e3",
              "e6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "Nbd7",
              "Nbd2",
              "Be7",
              "O-O",
              "O-O",
              "c4",
              "c6",
              "Rac1",
              "Rc8",
              "Rc2",
              "h6",
              "Bh4",
              "Nh7",
              "Bxe7",
              "Qxe7",
              "Rfc1",
              "f5",
              "cxd5",
              "exd5",
              "Nb3",
              "Ng5",
              "Nxg5",
              "Qxg5",
              "Nc5",
              "Nxc5",
              "Rxc5",
              "f4",
              "e4",
              "f3",
              "g3",
              "Qg4",
              "exd5",
              "cxd5",
              "Rxc8",
              "Rxc8",
              "Rxc8+",
              "Qxc8",
              "Qxf3",
              "Qc1+",
              "Kg2",
              "Qxb2",
              "Qxd5+",
              "Kh7",
              "Qe4+",
              "Kg8",
              "d5",
              "Qxa2",
              "d6",
              "Qf7",
              "Qe7",
              "Qd5+",
              "Kh3",
              "Qf5+",
              "Kg2",
              "Qd5+",
              "f3",
              "Qd2+",
              "Kh3",
              "Qd5",
              "d7",
              "Qf5+",
              "Kg2",
              "Qc2+",
              "Kf1",
              "Qd1+",
              "Kf2",
              "Qd2+",
              "Kg1",
              "Qd1+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qd5",
              "d8=Q+",
              "Qxd8",
              "Qxd8+",
              "Kh7",
              "Qc7",
              "b5",
              "Qxa7",
              "b4",
              "Qb6",
              "b3",
              "Qxb3",
              "Kg6",
              "Qd3+",
              "Kf6",
              "Qe4",
              "g5",
              "f4",
              "gxf4",
              "gxf4",
              "h5",
              "Qe5+",
              "Kg6",
              "Qg5+",
              "Kf7",
              "Qxh5+",
              "Kf6",
              "Qg5+",
              "Ke6",
              "Kg4",
              "Kd6",
              "h4",
              "Ke6",
              "h5",
              "Kd6",
              "h6",
              "Ke6",
              "h7",
              "Kd6",
              "h8=Q",
              "Ke6",
              "Qhh6+",
              "Kf7",
              "Qgg7+",
              "Ke8",
              "Qhh8#",
              "d4",
              "d5",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "c4",
              "Bc2",
              "Nc5",
              "Nf3",
              "Rxf4",
              "Nd4",
              "Raf8",
              "Rxf4",
              "Rxf4",
              "Qe3",
              "Rf8",
              "Nb5",
              "Bc6",
              "Nd6",
              "Nb7",
              "Nxb7",
              "Bxb7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qf7+",
              "Ke2",
              "Kg7",
              "Qg5",
              "Bc6",
              "h4",
              "Be8",
              "h5",
              "h6",
              "hxg6",
              "hxg5",
              "gxf7",
              "Bxf7",
              "Ke3",
              "Bg6",
              "Ba4",
              "Bb1",
              "a3",
              "Kg6",
              "Bd7",
              "Kf5",
              "Kd4",
              "Be4",
              "g3",
              "Kg4",
              "Bxe6+",
              "Kxg3",
              "Bxd5",
              "Bxd5",
              "Kxd5",
              "Kf4",
              "e6",
              "g4",
              "e7",
              "g3",
              "e8=Q",
              "g2",
              "Qe1",
              "Kf3",
              "Qg1",
              "b5",
              "Kc5",
              "a6",
              "Kb6",
              "Ke2",
              "Kxa6",
              "Kd2",
              "Kxb5",
              "Kc2",
              "Kxc4",
              "Kxb2",
              "Qxg2+",
              "Kxa3",
              "Qb7",
              "Ka2",
              "Kd3",
              "Ka1",
              "Kc2",
              "Ka2",
              "Qb2#",
              "e4",
              "e5",
              "g5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf6",
              "Qxf6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 545,
            "total_tokens": 670,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 457,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 460,
            "total_tokens": 584,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1462,
          "total_tokens": 1836
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 545,
            "total_tokens": 670,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 457,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 460,
            "total_tokens": 584,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e3",
          "aggressive_uci": "e2e3",
          "aggressive_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 Nf6 17. Qh4 Rae8 18. Rf3 Ne4 19. Qh5 Rf5 20. Qg4 Nf6 21. Qh4 Rh5 22. Qf2 Nd7 23. g4 Nxe5 24. fxe5 Rxe5 25. Rf1 d4 26. Rf7 dxe3 27. Qf4 Qd6 28. Rxg7+ Kxg7 29. Qf7+ Kh6 30. Qxh7+ Kg5 31. Qh5# e4 dxe3 Qxe3+ Kh8 Qe5 Qg7#",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 251,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rae8",
            "Rf3",
            "Ne4",
            "Qh5",
            "Rf5",
            "Qg4",
            "Nf6",
            "Qh4",
            "Rh5",
            "Qf2",
            "Nd7",
            "g4",
            "Nxe5",
            "fxe5",
            "Rxe5",
            "Rf1",
            "d4",
            "Rf7",
            "dxe3",
            "Qf4",
            "Qd6",
            "Rxg7+",
            "Kxg7",
            "Qf7+",
            "Kh6",
            "Qxh7+",
            "Kg5",
            "Qh5#",
            "e4",
            "dxe3",
            "Qxe3+",
            "Kh8",
            "Qe5",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e3",
          "positional_uci": "e2e3",
          "positional_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh6 Qg7 18. Qh3 Rae8 19. Rae1 c4 20. Bc2 Nc5 21. Re3 Rf7 22. Rg3 Ref8 23. Rg4 Bc8 24. Qg3 Kh8 25. h4 Qh6 26. Rg5 Rg7 27. Nf3 Bd7 28. Nd4 Rgf7 29. Rg4 Rg7 30. Rg5 Rgf7 31. Rg4 Rg7 32. Rg5 Rgf7 33. Rg4 Rg7 34. Rg5 Rgf7 35. Rg4 Rg7 36. Rg5 Rgf7 37. Rg4 Rg7 38. Rg5 Rgf7 39. Rg4 Rg7 40. Rg5 Rgf7 41. Rg4 Rg7 42. Rg5 Rgf7 43. Rg4 Rg7 44. Rg5 Rgf7 45. Rg4 Rg7 46. Rg5 Rgf7 47. Rg4 Rg7 48. Rg5 Rgf7 49. Rg4 Rg7 50. Rg5 Rgf7 51. Rg4 Rg7 52. Rg5 Rgf7 53. Rg4 Rg7 54. Rg5 Rgf7 55. Rg4 Rg7 56. Rg5 Rgf7 57. Rg4 Rg7 58. Rg5 Rgf7 59. Rg4 Rg7 60. Rg5 Rgf7 61. Rg4 Rg7 62. Rg5 Rgf7 63. Rg4 Rg7 64. Rg5 Rgf7 65. Rg4 Rg7 66. Rg5 Rgf7 67. Rg4 Rg7 68. Rg5 Rgf7 69. Rg4 Rg7 70. Rg5 Rgf7 71. Rg4 Rg7 72. Rg5 Rgf7 73. Rg4 Rg7 74. Rg5 Rgf7 75. Rg4 Rg7 76. Rg5 Rgf7 77. Rg4 Rg",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh3",
            "Rae8",
            "Rae1",
            "c4",
            "Bc2",
            "Nc5",
            "Re3",
            "Rf7",
            "Rg3",
            "Ref8",
            "Rg4",
            "Bc8",
            "Qg3",
            "Kh8",
            "h4",
            "Qh6",
            "Rg5",
            "Rg7",
            "Nf3",
            "Bd7",
            "Nd4",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e3",
          "neutral_uci": "e2e3",
          "neutral_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh6 Qg7 24. Qh4 Qf6 25. Qh6 Qg7 26. Qh4 Qf6 27. Qh6 Qg7 28. Qh4 Qf6 29. Qh6 Qg7 30. Qh4 Qf6 31. Qh6 Qg7 32. Qh4 Qf6 33. Qh6 Qg7 34. Qh4 Qf6 35. Qh6 Qg7 36. Qh4 Qf6 37. Qh6 Qg7 38. Qh4 Qf6 39. Qh6 Qg7 40. Qh4 Qf6 41. Qh6 Qg7 42. Qh4 Qf6 43. Qh6 Qg7 44. Qh4 Qf6 45. Qh6 Qg7 46. Qh4 Qf6 47. Qh6 Qg7 48. Qh4 Qf6 49. Qh6 Qg7 50. Qh4 Qf6 51. Qh6 Qg7 52. Qh4 Qf6 53. Qh6 Qg7 54. Qh4 Qf6 55. Qh6 Qg7 56. Qh4 Qf6 57. Qh6 Qg7 58. Qh4 Qf6 59. Qh6 Qg7 60. Qh4 Qf6 61. Qh6 Qg7 62. Qh4 Qf6 63. Qh6 Qg7 64. Qh4 Qf6 65. Qh6 Qg7 66. Qh4 Qf6 67. Qh6 Qg7 68. Qh4 Qf6 69. Qh6 Qg7 70. Qh4 Qf6 71. Qh6 Qg7 72. Qh4 Qf6 73. Qh6 Qg7 74. Qh4 Qf6 75. Qh6 Qg7 76. Qh4 Qf6",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e3",
          "positional_uci": "e2e3",
          "neutral_uci": "e2e3",
          "consensus_move": "e2e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rae8",
              "Rf3",
              "Ne4",
              "Qh5",
              "Rf5",
              "Qg4",
              "Nf6",
              "Qh4",
              "Rh5",
              "Qf2",
              "Nd7",
              "g4",
              "Nxe5",
              "fxe5",
              "Rxe5",
              "Rf1",
              "d4",
              "Rf7",
              "dxe3",
              "Qf4",
              "Qd6",
              "Rxg7+",
              "Kxg7",
              "Qf7+",
              "Kh6",
              "Qxh7+",
              "Kg5",
              "Qh5#",
              "e4",
              "dxe3",
              "Qxe3+",
              "Kh8",
              "Qe5",
              "Qg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh3",
              "Rae8",
              "Rae1",
              "c4",
              "Bc2",
              "Nc5",
              "Re3",
              "Rf7",
              "Rg3",
              "Ref8",
              "Rg4",
              "Bc8",
              "Qg3",
              "Kh8",
              "h4",
              "Qh6",
              "Rg5",
              "Rg7",
              "Nf3",
              "Bd7",
              "Nd4",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 251,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1531,
          "total_tokens": 1929
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 251,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p2B1/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bd3",
          "aggressive_uci": "f1d3",
          "aggressive_response": "5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Bb7 10. f4 Ne4 11. Bxe7 Qxe7 12. Nxd7 Qxd7 13. Nf3 f6 14. Qe2 Rac8 15. Rad1 Qe7 16. Nd2 Nxd2 17. Rxd2 e5 18. fxe5 fxe5 19. Rxf8+ Rxf8 20. dxc5 bxc5 21. e4 d4 22. Bc4+ Kh8 23. Bd5 Bxd5 24. exd5 Qd6 25. c4 Re8 26. Qe4 Qh6 27. Rd1 Qh5 28. Rf1 Kg8 29. d6 Qg6 30. Qd5+ Qe6 31. Qxc5 Rd8 32. Qxa7 Qxd6 33. Qf7+ Kh8 34. c5 Qxc5 35. b4 Qd6 36. b5 d3 37. b6 d2 38. Rd1 Qxb6+ 39. Kh1 Qe3 40. Qf1 h6 41. h3 Qd3 42. Qf2 e4 43. Qh4 e3 44. Kh2 e2 45. Rxd2 Qxd2 46. a4 e1=Q 47. Qxe1 Qxe1 48. a5 Qxa5 49. h4 Qe5+ 50. Kh3 Rd3+ 51. Kg4 Rg3# e4 d5 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 394,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Bb7",
            "f4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxd7",
            "Qxd7",
            "Nf3",
            "f6",
            "Qe2",
            "Rac8",
            "Rad1",
            "Qe7",
            "Nd2",
            "Nxd2",
            "Rxd2",
            "e5",
            "fxe5",
            "fxe5",
            "Rxf8+",
            "Rxf8",
            "dxc5",
            "bxc5",
            "e4",
            "d4",
            "Bc4+",
            "Kh8",
            "Bd5",
            "Bxd5",
            "exd5",
            "Qd6",
            "c4",
            "Re8",
            "Qe4",
            "Qh6",
            "Rd1",
            "Qh5",
            "Rf1",
            "Kg8",
            "d6",
            "Qg6",
            "Qd5+",
            "Qe6",
            "Qxc5",
            "Rd8",
            "Qxa7",
            "Qxd6",
            "Qf7+",
            "Kh8",
            "c5",
            "Qxc5",
            "b4",
            "Qd6",
            "b5",
            "d3",
            "b6",
            "d2",
            "Rd1",
            "Qxb6+",
            "Kh1",
            "Qe3",
            "Qf1",
            "h6",
            "h3",
            "Qd3",
            "Qf2",
            "e4",
            "Qh4",
            "e3",
            "Kh2",
            "e2",
            "Rxd2",
            "Qxd2",
            "a4",
            "e1=Q",
            "Qxe1",
            "Qxe1",
            "a5",
            "Qxa5",
            "h4",
            "Qe5+",
            "Kh3",
            "Rd3+",
            "Kg4",
            "Rg3#",
            "e4",
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bd3",
          "positional_uci": "f1d3",
          "positional_response": "5. Bd3 O-O 6. Nbd2 c5 7. c3 Nc6 8. O-O b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh3 Qf5 24. g4 Qf6 25. g5 Qf5 26. Qh6 Re7 27. Rh3 Rg7 28. Be2 d4 29. Bg4 Qf8 30. Bxe6+ Kh8 31. Nxg6+ Rxg6 32. Qxg6 Qg7 33. Qxg7+ Kxg7 34. Bf5 dxc3 35. Rxh7+ Kg8 36. Rxb7 cxb2 37. Rb1 Nc3 38. Rxb2 Nd1 39. Re2 Nc3 40. Re1 Nxa2 41. Be6+ Kh8 42. Bxa2 Rd2 43. Bb1 c4 44. Rxa7 c3 45. Rc7 b5 46. Rxc3 b4 47. Rb3 Kg7 48. Rxb4 Kf7 49. Rb6 Kg7 50. Rc1 Rd7 51. h4 Re7 52. Kf2 Rd7 53. h5 Re7 54. h6+ Kf7 55. g6+ Ke8 56. h7 Kd7 57. Rb7+ Ke6 58. Rxe7+ Kxe7 59. h8=Q Ke6 60. Qe5+ Kd7 61. Rc7+ Kd8 62. Qe7# e4 d3 Qd4+ Kf8 Qf7#",
          "positional_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 500,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "c5",
            "c3",
            "Nc6",
            "O-O",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh3",
            "Qf5",
            "g4",
            "Qf6",
            "g5",
            "Qf5",
            "Qh6",
            "Re7",
            "Rh3",
            "Rg7",
            "Be2",
            "d4",
            "Bg4",
            "Qf8",
            "Bxe6+",
            "Kh8",
            "Nxg6+",
            "Rxg6",
            "Qxg6",
            "Qg7",
            "Qxg7+",
            "Kxg7",
            "Bf5",
            "dxc3",
            "Rxh7+",
            "Kg8",
            "Rxb7",
            "cxb2",
            "Rb1",
            "Nc3",
            "Rxb2",
            "Nd1",
            "Re2",
            "Nc3",
            "Re1",
            "Nxa2",
            "Be6+",
            "Kh8",
            "Bxa2",
            "Rd2",
            "Bb1",
            "c4",
            "Rxa7",
            "c3",
            "Rc7",
            "b5",
            "Rxc3",
            "b4",
            "Rb3",
            "Kg7",
            "Rxb4",
            "Kf7",
            "Rb6",
            "Kg7",
            "Rc1",
            "Rd7",
            "h4",
            "Re7",
            "Kf2",
            "Rd7",
            "h5",
            "Re7",
            "h6+",
            "Kf7",
            "g6+",
            "Ke8",
            "h7",
            "Kd7",
            "Rb7+",
            "Ke6",
            "Rxe7+",
            "Kxe7",
            "h8=Q",
            "Ke6",
            "Qe5+",
            "Kd7",
            "Rc7+",
            "Kd8",
            "Qe7#",
            "e4",
            "d3",
            "Qd4+",
            "Kf8",
            "Qf7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bd3",
          "neutral_uci": "f1d3",
          "neutral_response": "5. Bd3 O-O 6. Nbd2 c5 7. c3 Nc6 8. O-O b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 Nf6 17. Qh4 Rae8 18. Rf3 Ne4 19. Qh5 Rf5 20. Qh3 Rf6 21. g4 Rh6 22. Qg2 Qh4 23. g5 Rh5 24. Be2 d4 25. Rg3 Nxg3 26. Qxg3 Qxg3+ 27. hxg3 Rh1+ 28. Kf2 Rxa1 29. exd4 cxd4 30. cxd4 Rxa2 31. Ke3 Rxb2 32. Bc4 Bd5 33. Bd3 Rb3 34. Kd2 Rc8 35. g4 Rcc3 36. f5 exf5 37. gxf5 a5 38. f6 gxf6 39. gxf6 a4 40. Bc2 Rb2 41. Kxc3 a3 42. Nd3 Rxc2+ 43. Kxc2 a2 44. Kb2 Kf7 45. Nb4 Bc4 46. Nxa2 Bxa2 47. Kxa2 Kxf6 48. Kb3 Ke6 49. Kc4 h5 50. d5+ Kd6 51. Kd4 h4 52. Ke4 h3 53. Kf3 Kxd5 54. Kg3 b5 55. Kxh3 b4 56. Kg3 b3 57. Kf3 b2 58. Ke3 b1=Q 59. Kd2 Qb3 60. Ke2 Ke4 61. Kd2 Qd3+ 62. Kc1 Qe2 63. Kb1 Kd3 64. Ka1 Kc3 65. Kb1 Qb2# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O Nbd2 c5 c3 Nc6 O-O b6 Ne5 Nxe5 dxe5 Nd7 f4 f6 exf6 Nxf6 Ne5 Bb7 Ne5 Nd7 Qh5 Nf6 Qh3 Rae8 Rf3 Ne4 Qh5 Rf6 g4 Rh6 Qg2 Qh4 g5 Rh5 Be2 d4 Rg3 Nxg3 Qxg3 Qxg3+ hxg3 Rh1+ Kf2 Rxa1 exd4 cxd4",
          "neutral_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "c5",
            "c3",
            "Nc6",
            "O-O",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Ne5",
            "Bb7",
            "Ne5",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh3",
            "Rae8",
            "Rf3",
            "Ne4",
            "Qh5",
            "Rf6",
            "g4",
            "Rh6",
            "Qg2",
            "Qh4",
            "g5",
            "Rh5",
            "Be2",
            "d4",
            "Rg3",
            "Nxg3",
            "Qxg3",
            "Qxg3+",
            "hxg3",
            "Rh1+",
            "Kf2",
            "Rxa1",
            "exd4",
            "cxd4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1d3",
          "positional_uci": "f1d3",
          "neutral_uci": "f1d3",
          "consensus_move": "f1d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Bb7",
              "f4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxd7",
              "Qxd7",
              "Nf3",
              "f6",
              "Qe2",
              "Rac8",
              "Rad1",
              "Qe7",
              "Nd2",
              "Nxd2",
              "Rxd2",
              "e5",
              "fxe5",
              "fxe5",
              "Rxf8+",
              "Rxf8",
              "dxc5",
              "bxc5",
              "e4",
              "d4",
              "Bc4+",
              "Kh8",
              "Bd5",
              "Bxd5",
              "exd5",
              "Qd6",
              "c4",
              "Re8",
              "Qe4",
              "Qh6",
              "Rd1",
              "Qh5",
              "Rf1",
              "Kg8",
              "d6",
              "Qg6",
              "Qd5+",
              "Qe6",
              "Qxc5",
              "Rd8",
              "Qxa7",
              "Qxd6",
              "Qf7+",
              "Kh8",
              "c5",
              "Qxc5",
              "b4",
              "Qd6",
              "b5",
              "d3",
              "b6",
              "d2",
              "Rd1",
              "Qxb6+",
              "Kh1",
              "Qe3",
              "Qf1",
              "h6",
              "h3",
              "Qd3",
              "Qf2",
              "e4",
              "Qh4",
              "e3",
              "Kh2",
              "e2",
              "Rxd2",
              "Qxd2",
              "a4",
              "e1=Q",
              "Qxe1",
              "Qxe1",
              "a5",
              "Qxa5",
              "h4",
              "Qe5+",
              "Kh3",
              "Rd3+",
              "Kg4",
              "Rg3#",
              "e4",
              "d5",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Nbd2",
              "c5",
              "c3",
              "Nc6",
              "O-O",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh3",
              "Qf5",
              "g4",
              "Qf6",
              "g5",
              "Qf5",
              "Qh6",
              "Re7",
              "Rh3",
              "Rg7",
              "Be2",
              "d4",
              "Bg4",
              "Qf8",
              "Bxe6+",
              "Kh8",
              "Nxg6+",
              "Rxg6",
              "Qxg6",
              "Qg7",
              "Qxg7+",
              "Kxg7",
              "Bf5",
              "dxc3",
              "Rxh7+",
              "Kg8",
              "Rxb7",
              "cxb2",
              "Rb1",
              "Nc3",
              "Rxb2",
              "Nd1",
              "Re2",
              "Nc3",
              "Re1",
              "Nxa2",
              "Be6+",
              "Kh8",
              "Bxa2",
              "Rd2",
              "Bb1",
              "c4",
              "Rxa7",
              "c3",
              "Rc7",
              "b5",
              "Rxc3",
              "b4",
              "Rb3",
              "Kg7",
              "Rxb4",
              "Kf7",
              "Rb6",
              "Kg7",
              "Rc1",
              "Rd7",
              "h4",
              "Re7",
              "Kf2",
              "Rd7",
              "h5",
              "Re7",
              "h6+",
              "Kf7",
              "g6+",
              "Ke8",
              "h7",
              "Kd7",
              "Rb7+",
              "Ke6",
              "Rxe7+",
              "Kxe7",
              "h8=Q",
              "Ke6",
              "Qe5+",
              "Kd7",
              "Rc7+",
              "Kd8",
              "Qe7#",
              "e4",
              "d3",
              "Qd4+",
              "Kf8",
              "Qf7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Nbd2",
              "c5",
              "c3",
              "Nc6",
              "O-O",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Ne5",
              "Bb7",
              "Ne5",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh3",
              "Rae8",
              "Rf3",
              "Ne4",
              "Qh5",
              "Rf6",
              "g4",
              "Rh6",
              "Qg2",
              "Qh4",
              "g5",
              "Rh5",
              "Be2",
              "d4",
              "Rg3",
              "Nxg3",
              "Qxg3",
              "Qxg3+",
              "hxg3",
              "Rh1+",
              "Kf2",
              "Rxa1",
              "exd4",
              "cxd4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 140,
            "completion_tokens": 394,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 140,
            "completion_tokens": 500,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 419,
          "total_completion_tokens": 1534,
          "total_tokens": 1953
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 140,
            "completion_tokens": 394,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 140,
            "completion_tokens": 500,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp1bppp/4pn2/3p2B1/3P4/4PN2/PPP2PPP/RN1QKB1R w KQkq - 1 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh6 Qg7 18. Qxg7+ Kxg7 19. g3 Rf7 20. Nf3 h6 21. Nh4 Nf8 22. Rad1 Rd8 23. Bc2 Rfd7 24. Ba4 Re7 25. Bc2 Red7 26. Ba4 Re7 27. Bc2 Red7 28. Ba4 Re7 29. Bc2 Red7 30. Ba4 Re7 31. Bc2 Red7 32. Ba4 Re7 33. Bc2 Red7 34. Ba4 Re7 35. Bc2 Red7 36. Ba4 Re7 37. Bc2 Red7 38. Ba4 Re7 39. Bc2 Red7 40. Ba4 Re7 41. Bc2 Red7 42. Ba4 Re7 43. Bc2 Red7 44. Ba4 Re7 45. Bc2 Red7 46. Ba4 Re7 47. Bc2 Red7 48. Ba4 Re7 49. Bc2 Red7 50. Ba4 Re7 51. Bc2 Red7 52. Ba4 Re7 53. Bc2 Red7 54. Ba4 Re7 55. Bc2 Red7 56. Ba4 Re7 57. Bc2 Red7 58. Ba4 Re7 59. Bc2 Red7 60. Ba4 Re7 61. Bc2 Red7 62. Ba4 Re7 63. Bc2 Red7 64. Ba4 Re7 65. Bc2 Red7 66. Ba4 Re7 67. Bc2 Red7 68. Ba4 Re7 69. Bc2 Red7 70. Ba4 Re7 71. Bc2 Red7 72. Ba4 Re7 73. Bc2 Rd7 74. Ba4 Re7 75. Bc2 Rd7 76. Ba4 Re7 77. Bc2 Rd7 78. Ba4 Re7 79. Bc2 Rd7 80. Ba4 Re7 81. Bc2 Rd7 82. Ba4 Re7 83. Bc2 Rd7 84. Ba4 Re7 85. Bc2 Rd7 86. Ba4 Re7 87. Bc2 Rd7 88. Ba4 Re7 89. Bc",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qxg7+",
            "Kxg7",
            "g3",
            "Rf7",
            "Nf3",
            "h6",
            "Nh4",
            "Nf8",
            "Rad1",
            "Rd8",
            "Bc2",
            "Rfd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh3 Qf5 24. g4 Qf6 25. g5 Qf5 26. Qh6 Re7 27. Rh3 Rg7 28. Be2 d4 29. Bg4 Qf8 30. Bxe6+ Kh8 31. Nxg6+ Rxg6 32. Qxh7# d4 33. Qxg6 dxe3 34. Rxh7# d3 35. Qh5# d2",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 254,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh3",
            "Qf5",
            "g4",
            "Qf6",
            "g5",
            "Qf5",
            "Qh6",
            "Re7",
            "Rh3",
            "Rg7",
            "Be2",
            "d4",
            "Bg4",
            "Qf8",
            "Bxe6+",
            "Kh8",
            "Nxg6+",
            "Rxg6",
            "Qxh7#",
            "d4",
            "Qxg6",
            "dxe3",
            "Rxh7#",
            "d3",
            "Qh5#",
            "d2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 Rf7 18. Rae1 Raf8 19. Qg4 c4 20. Bc2 Nc5 21. g3 b5 22. Nf3 a5 23. Nd4 b4 24. h4 bxc3 25. bxc3 Bc8 26. h5 Rg7 27. hxg6 hxg6 28. Kg2 g5 29. f5 exf5 30. Bxf5 Bxf5 31. Nxf5 Qe6 32. Nh6+ Qxh6 33. Rxf8+ Kxf8 34. Qc8+ Kf7 35. Rf1+ Ke7 36. Qxc5+ Kd7 37. Qxd5+ Kc7 38. Qxc4+ Kb7 39. Rb1+ Ka7 40. Qc5+ Ka8 41. Qxa5+ Ra7 42. Qd8# Nf6+ Kh2 Qh7#",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 321,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "Rf7",
            "Rae1",
            "Raf8",
            "Qg4",
            "c4",
            "Bc2",
            "Nc5",
            "g3",
            "b5",
            "Nf3",
            "a5",
            "Nd4",
            "b4",
            "h4",
            "bxc3",
            "bxc3",
            "Bc8",
            "h5",
            "Rg7",
            "hxg6",
            "hxg6",
            "Kg2",
            "g5",
            "f5",
            "exf5",
            "Bxf5",
            "Bxf5",
            "Nxf5",
            "Qe6",
            "Nh6+",
            "Qxh6",
            "Rxf8+",
            "Kxf8",
            "Qc8+",
            "Kf7",
            "Rf1+",
            "Ke7",
            "Qxc5+",
            "Kd7",
            "Qxd5+",
            "Kc7",
            "Qxc4+",
            "Kb7",
            "Rb1+",
            "Ka7",
            "Qc5+",
            "Ka8",
            "Qxa5+",
            "Ra7",
            "Qd8#",
            "Nf6+",
            "Kh2",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qxg7+",
              "Kxg7",
              "g3",
              "Rf7",
              "Nf3",
              "h6",
              "Nh4",
              "Nf8",
              "Rad1",
              "Rd8",
              "Bc2",
              "Rfd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh3",
              "Qf5",
              "g4",
              "Qf6",
              "g5",
              "Qf5",
              "Qh6",
              "Re7",
              "Rh3",
              "Rg7",
              "Be2",
              "d4",
              "Bg4",
              "Qf8",
              "Bxe6+",
              "Kh8",
              "Nxg6+",
              "Rxg6",
              "Qxh7#",
              "d4",
              "Qxg6",
              "dxe3",
              "Rxh7#",
              "d3",
              "Qh5#",
              "d2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "Rf7",
              "Rae1",
              "Raf8",
              "Qg4",
              "c4",
              "Bc2",
              "Nc5",
              "g3",
              "b5",
              "Nf3",
              "a5",
              "Nd4",
              "b4",
              "h4",
              "bxc3",
              "bxc3",
              "Bc8",
              "h5",
              "Rg7",
              "hxg6",
              "hxg6",
              "Kg2",
              "g5",
              "f5",
              "exf5",
              "Bxf5",
              "Bxf5",
              "Nxf5",
              "Qe6",
              "Nh6+",
              "Qxh6",
              "Rxf8+",
              "Kxf8",
              "Qc8+",
              "Kf7",
              "Rf1+",
              "Ke7",
              "Qxc5+",
              "Kd7",
              "Qxd5+",
              "Kc7",
              "Qxc4+",
              "Kb7",
              "Rb1+",
              "Ka7",
              "Qc5+",
              "Ka8",
              "Qxa5+",
              "Ra7",
              "Qd8#",
              "Nf6+",
              "Kh2",
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 254,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 321,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 1215,
          "total_tokens": 1655
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 254,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 321,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1QK2R w KQ - 3 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bh4",
          "aggressive_uci": "g5h4",
          "aggressive_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 f6 14. exf6 Nxf6 15. Nf3 Bb7 16. Ne5 Qc7 17. Qe2 Nd7 18. Ng6 Rf6 19. Qh5 Nf8 20. Ne5 Nd7 21. Ng4 Rf7 22. Qg6 Kf8 23. Qxe6 Re8 24. Qg6 Nf6 25. Ne5 Rfe7 26. Rae1 Kg8 27. g4 Re6 28. g5 hxg5 29. Qxg5 Ne4 30. Bxe4 dxe4 31. Rd1 Qe7 32. Qxe7 R8xe7 33. Rd8+ Kh7 34. Rfd1 g5 35. R1d7 gxf4 36. exf4 Kg7 37. Kf2 Kf6 38. Rf8+ Kg7 39. Rf7+ Rxf7 40. Rxf7+ Kh6 41. Rxb7 Rd6 42. Ke3 Rd1 43. Kxe4 Re1+ 44. Kf5 Re2 45. Ng4+ Kh5 46. Rh7# 1-0\n\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 f6 14. exf6 Nxf6 15. Nf3 Bb7 16. Ne5 Qc7 17. Qe2 Nd7 18. Ng6 Rf6 19. Qh5 Nf8 20. Ne5 Nd7 21. Ng4 Rf7 22. Qg6 Kf8 23. Qxe6 Re8 24. Qg6 Nf6 25. Ne5 Rfe7 26. Rae1 Kg8 27. g4 Re6 28. g5 hxg5 29. Qxg5 Ne4 30. Bxe4 dxe4 31. Rd1 Qe7 32. Qxe7 R8xe7 33. Rd8+ Kh7 34. Rfd1 g5 35. R1d7 gxf4 36. exf4 Kg7 37. Kf2 Kf6 38. Rf",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Qc7",
            "Qe2",
            "Nd7",
            "Ng6",
            "Rf6",
            "Qh5",
            "Nf8",
            "Ne5",
            "Nd7",
            "Ng4",
            "Rf7",
            "Qg6",
            "Kf8",
            "Qxe6",
            "Re8",
            "Qg6",
            "Nf6",
            "Ne5",
            "Rfe7",
            "Rae1",
            "Kg8",
            "g4",
            "Re6",
            "g5",
            "hxg5",
            "Qxg5",
            "Ne4",
            "Bxe4",
            "dxe4",
            "Rd1",
            "Qe7",
            "Qxe7",
            "R8xe7",
            "Rd8+",
            "Kh7",
            "Rfd1",
            "g5",
            "R1d7",
            "gxf4",
            "exf4",
            "Kg7",
            "Kf2",
            "Kf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bh4",
          "positional_uci": "g5h4",
          "positional_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 f5 14. exf6 Nxf6 15. Nf3 Bb7 16. Ne5 Rfd8 17. Qe2 Nd7 18. Ng6 Qf6 19. Qh5 Nf8 20. Ne5 Nd7 21. Ng4 Qf7 22. Bg6 Qe7 23. Rf3 Nf6 24. Nxf6+ Qxf6 25. Rg3 d4 26. cxd4 cxd4 27. Rf1 dxe3 28. Rxe3 Rd2 29. Rg3 Qxb2 30. Bf7+ Kf8 31. Bxe6 Rxg2+ 32. Kh1 Rxg3+ 33. Bd5 Qg2+ 34. Bxg2 Bxg2+ 35. Kg1 Bf3+ 36. hxg3 Bxh5 37. Rc1 Re8 38. Rc7 Re7 39. Rc8+ Kf7 40. Rc2 Bg4 41. Kf2 Re2+ 42. Rxe2 Bxe2 43. Kxe2 Ke6 44. Ke3 Kd5 45. Kd3 b5 46. a3 a5 47. g4 b4 48. axb4 axb4 49. f5 Ke5 50. Kc4 Kf4 51. Kxb4 Kxg4 52. Kc4 Kxf5 53. Kd3 Kf4 54. Ke2 Kg3 55. Kf1 Kh2 56. Kf2 g5 57. Kf3 h5 58. Kf2 g4 59. Kf1 g3 60. Ke2 g2 61. Kf3 g1=Q 62. Kf4 Qg4+ 63. Ke5 Kg3 64. Kd5 Kf3 65. Ke5 Qe4+ 66. Kd6 Qf5 67. Kc6 Ke4 68. Kd6 Qd5+ 69. Ke7 Qc6 70. Kf7 Kf5 71. Ke7 Qe6+ 72. Kd8 Qf7 73. Kc8 Ke6 74. Kb8 Kd6 75. Ka8 Kc6 76. Kb8 Qb7# d4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O Bh4 Nbd7 c5 Ne5 Nxe5 dxe5 f4 exf6 Nxf6 Ne5 B",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "c5",
            "Ne5",
            "Nxe5",
            "dxe5",
            "f4",
            "exf6",
            "Nxf6",
            "Ne5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bh4",
          "neutral_uci": "g5h4",
          "neutral_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Rc1 Bb7 11. Bb1 Rc8 12. Qc2 Re8 13. Ne5 Nf8 14. f4 cxd4 15. exd4 Ne4 16. Bxe7 Qxe7 17. Nxe4 dxe4 18. Qe2 f5 19. g4 Qh4 20. gxf5 exf5 21. Qe3 Re6 22. Rf2 Ng6 23. Rg2 Nxe5 24. fxe5 f4 25. Qe1 Qxe1+ 26. Rxe1 e3 27. Rg4 Rf8 28. a3 g5 29. Ba2 Kf7 30. h4 Ke7 31. Bxe6 Kxe6 32. hxg5 hxg5 33. Rxg5 Rh8 34. Kf1 Rh2 35. c4 Be4 36. d5+ Kf7 37. e6+ Kf6 38. Rg8 Bd3+ 39. Kg1 Rxb2 40. Rf8+ Ke7 41. Rf7+ Ke8 42. Rxf4 e2 43. d6 Rd2 44. d7+ Ke7 45. Rf7+ Kd8 46. Rf8+ Ke7 47. d8=Q+ Kxe6 48. Rf6+ Ke5 49. Qd6+ Ke4 50. Rf4+ Ke3 51. Qd4# Nf6+ gxf6+ Kxf6",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 388,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Rc1",
            "Bb7",
            "Bb1",
            "Rc8",
            "Qc2",
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxe4",
            "dxe4",
            "Qe2",
            "f5",
            "g4",
            "Qh4",
            "gxf5",
            "exf5",
            "Qe3",
            "Re6",
            "Rf2",
            "Ng6",
            "Rg2",
            "Nxe5",
            "fxe5",
            "f4",
            "Qe1",
            "Qxe1+",
            "Rxe1",
            "e3",
            "Rg4",
            "Rf8",
            "a3",
            "g5",
            "Ba2",
            "Kf7",
            "h4",
            "Ke7",
            "Bxe6",
            "Kxe6",
            "hxg5",
            "hxg5",
            "Rxg5",
            "Rh8",
            "Kf1",
            "Rh2",
            "c4",
            "Be4",
            "d5+",
            "Kf7",
            "e6+",
            "Kf6",
            "Rg8",
            "Bd3+",
            "Kg1",
            "Rxb2",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rxf4",
            "e2",
            "d6",
            "Rd2",
            "d7+",
            "Ke7",
            "Rf7+",
            "Kd8",
            "Rf8+",
            "Ke7",
            "d8=Q+",
            "Kxe6",
            "Rf6+",
            "Ke5",
            "Qd6+",
            "Ke4",
            "Rf4+",
            "Ke3",
            "Qd4#",
            "Nf6+",
            "gxf6+",
            "Kxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5h4",
          "positional_uci": "g5h4",
          "neutral_uci": "g5h4",
          "consensus_move": "g5h4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Qc7",
              "Qe2",
              "Nd7",
              "Ng6",
              "Rf6",
              "Qh5",
              "Nf8",
              "Ne5",
              "Nd7",
              "Ng4",
              "Rf7",
              "Qg6",
              "Kf8",
              "Qxe6",
              "Re8",
              "Qg6",
              "Nf6",
              "Ne5",
              "Rfe7",
              "Rae1",
              "Kg8",
              "g4",
              "Re6",
              "g5",
              "hxg5",
              "Qxg5",
              "Ne4",
              "Bxe4",
              "dxe4",
              "Rd1",
              "Qe7",
              "Qxe7",
              "R8xe7",
              "Rd8+",
              "Kh7",
              "Rfd1",
              "g5",
              "R1d7",
              "gxf4",
              "exf4",
              "Kg7",
              "Kf2",
              "Kf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "c5",
              "Ne5",
              "Nxe5",
              "dxe5",
              "f4",
              "exf6",
              "Nxf6",
              "Ne5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Rc1",
              "Bb7",
              "Bb1",
              "Rc8",
              "Qc2",
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxe4",
              "dxe4",
              "Qe2",
              "f5",
              "g4",
              "Qh4",
              "gxf5",
              "exf5",
              "Qe3",
              "Re6",
              "Rf2",
              "Ng6",
              "Rg2",
              "Nxe5",
              "fxe5",
              "f4",
              "Qe1",
              "Qxe1+",
              "Rxe1",
              "e3",
              "Rg4",
              "Rf8",
              "a3",
              "g5",
              "Ba2",
              "Kf7",
              "h4",
              "Ke7",
              "Bxe6",
              "Kxe6",
              "hxg5",
              "hxg5",
              "Rxg5",
              "Rh8",
              "Kf1",
              "Rh2",
              "c4",
              "Be4",
              "d5+",
              "Kf7",
              "e6+",
              "Kf6",
              "Rg8",
              "Bd3+",
              "Kg1",
              "Rxb2",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rxf4",
              "e2",
              "d6",
              "Rd2",
              "d7+",
              "Ke7",
              "Rf7+",
              "Kd8",
              "Rf8+",
              "Ke7",
              "d8=Q+",
              "Kxe6",
              "Rf6+",
              "Ke5",
              "Qd6+",
              "Ke4",
              "Rf4+",
              "Ke3",
              "Qd4#",
              "Nf6+",
              "gxf6+",
              "Kxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 388,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 1668,
          "total_tokens": 2129
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 388,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bpp1/4pn1p/3p2B1/3P4/3BPN2/PPP2PPP/RN1Q1RK1 w - - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c4",
          "aggressive_uci": "c2c4",
          "aggressive_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qe6+ Kh7 30. Qf5+ Kg8 31. Qe6+ Kh7 32. Qf5+ Kg8 33. Qe6+ Kh7 34. Qf5+ Kg8 35. Qe6+ Kh7 36. Qf5+ Kg8 37. Qe6+ Kh7 38. Qf5+ Kg8 39. Qe6+ Kh7 40. Qf5+ Kg8 41. Qe6+ Kh7 42. Qf5+ Kg8 43. Qe6+ Kh7 44. Qf5+ Kg8 45. Qe6+ Kh7 46. Qf5+ Kg8 47. Qe6+ Kh7 48. Qf5+ Kg8 49. Qe6+ Kh7 50. Qf5+ Kg8 51. Qe6+ Kh7 52. Qf5+ Kg8 53. Qe6+ Kh7 54. Qf5+ Kg8 55. Qe6+ Kh7 56. Qf5+ Kg8 57. Qe6+ Kh7 58. Qf5+ Kg8 59. Qe6+ Kh7 60. Qf5+ Kg8 61. Qe6+ Kh7 62. Qf5+ Kg8 63. Qe6+ Kh7 64. Qf5+ Kg8 65. Qe6+ Kh7 66. Qf5+ Kg8 67. Qe6+ Kh7 68. Qf5+ Kg8 69. Qe6+ Kh7 70. Qf5+ Kg8 71. Qe6+ Kh7 72. Qf5+ Kg8 73. Qe6+ Kh7 74. Qf5+ Kg8 75. Qe6+ Kh7 76. Qf5+ Kg8 77. Qe6+ Kh7 78. Qf5+ Kg8 79. Qe6+ Kh7 80.",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c4",
          "positional_uci": "c2c4",
          "positional_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qc3+ 39. Ke2 Qc2+ 40. Kf3 Qc3+ 41. Ke2 Qc2+ 42. Kf3 Qc3+ 43. Ke2 Qc2+ 44. Kf3 Qc3+ 45. Ke2 Qc2+ 46. Kf3 Qc3+ 47. Ke2 Qc2+ 48. Kf3 Qc3+ 49. Ke2 Qc2+ 50. Kf3 Qc3+ 51. Ke2 Qc2+ 52. Kf3 Qc3+ 53. Ke2 Qc2+ 54. Kf3 Qc3+ 55. Ke2 Qc2+ 56. Kf3 Qc3+ 57. Ke2 Qc2+ 58. Kf3 Qc3+ 59. Ke2 Qc2+ 60. Kf3 Qc3+ 61. Ke2 Qc2+ 62. Kf3 Qc3+ 63. Ke2 Qc2+ 64. Kf3 Qc3+ 65. Ke2 Qc2+ 66. Kf3 Qc3+ 67. Ke2 Qc2+ 68. Kf3 Qc3+ 69. Ke2 Qc2+ 70. Kf3 Qc3+ 71. Ke2 Qc2+ 72. Kf3 Qc3+ 73. Ke2 Qc2+ 74. Kf3 Qc3+ 75. Ke2 Qc2+ 76. Kf3 Qc3+ 77. Ke2",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c4",
          "neutral_uci": "c2c4",
          "neutral_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80.",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c2c4",
          "positional_uci": "c2c4",
          "neutral_uci": "c2c4",
          "consensus_move": "c2c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 1920,
          "total_tokens": 2402
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbq1rk1/p1p1bpp1/1p2pn1p/3p4/3P3B/3BPN2/PPP2PPP/RN1Q1RK1 w - - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc3",
          "aggressive_uci": "b1c3",
          "aggressive_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 e5 19. bxc5 Rxd4 20. Qb3 bxc5 21. Rxc5 Qxc5 22. Qxb7 Rad8 23. Qb3 Rd2 24. Rf1 Re2 25. Bd3 Rd2 26. Bc4 R8d7 27. Bd5 Kh7 28. Qf3 f6 29. Qf5+ Kh8 30. Qxd7 Kh7 31. Qf5+ Kh8 32. Qe6 Kh7 33. Qg8+ Kg6 34. Bf7+ Kg5 35. Qxg7+ Kf4 36. Qg3+ Kxe4 37. Qf3+ Kd4 38. Qe3# d4 e5 Qd6",
          "aggressive_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 264,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "e5",
            "bxc5",
            "Rxd4",
            "Qb3",
            "bxc5",
            "Rxc5",
            "Qxc5",
            "Qxb7",
            "Rad8",
            "Qb3",
            "Rd2",
            "Rf1",
            "Re2",
            "Bd3",
            "Rd2",
            "Bc4",
            "R8d7",
            "Bd5",
            "Kh7",
            "Qf3",
            "f6",
            "Qf5+",
            "Kh8",
            "Qxd7",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qe6",
            "Kh7",
            "Qg8+",
            "Kg6",
            "Bf7+",
            "Kg5",
            "Qxg7+",
            "Kf4",
            "Qg3+",
            "Kxe4",
            "Qf3+",
            "Kd4",
            "Qe3#",
            "d4",
            "e5",
            "Qd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc3",
          "positional_uci": "b1c3",
          "positional_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qc3+ 39. Ke2 Qc2+ 40. Kf3 Qc3+ 41. Ke2 Qc2+ 42. Kf3 Qc3+ 43. Ke2 Qc2+ 44. Kf3 Qc3+ 45. Ke2 Qc2+ 46. Kf3 Qc3+ 47. Ke2 Qc2+ 48. Kf3 Qc3+ 49. Ke2 Qc2+ 50. Kf3 Qc3+ 51. Ke2 Qc2+ 52. Kf3 Qc3+ 53. Ke2 Qc2+ 54. Kf3 Qc3+ 55. Ke2 Qc2+ 56. Kf3 Qc3+ 57. Ke2 Qc2+ 58. Kf3 Qc3+ 59. Ke2 Qc2+ 60. Kf3 Qc3+ 61. Ke2 Qc2+ 62. Kf3 Qc3+ 63. Ke2 Qc2+ 64. Kf3 Qc3+ 65. Ke2 Qc2+ 66. Kf3 Qc3+ 67. Ke2 Qc2+ 68. Kf3 Qc3+ 69. Ke2 Qc2+ 70. Kf3 Qc3+ 71. Ke2 Qc2+ 72. Kf3 Qc3+ 73. Ke2 Qc2+ 74. Kf3 Qc3+ 75. Ke2 Qc2+ 76. Kf3 Qc3+ 77. Ke2 Qc2+ 78. K",
          "positional_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc3",
          "neutral_uci": "b1c3",
          "neutral_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81",
          "neutral_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b1c3",
          "positional_uci": "b1c3",
          "neutral_uci": "b1c3",
          "consensus_move": "b1c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "e5",
              "bxc5",
              "Rxd4",
              "Qb3",
              "bxc5",
              "Rxc5",
              "Qxc5",
              "Qxb7",
              "Rad8",
              "Qb3",
              "Rd2",
              "Rf1",
              "Re2",
              "Bd3",
              "Rd2",
              "Bc4",
              "R8d7",
              "Bd5",
              "Kh7",
              "Qf3",
              "f6",
              "Qf5+",
              "Kh8",
              "Qxd7",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qe6",
              "Kh7",
              "Qg8+",
              "Kg6",
              "Bf7+",
              "Kg5",
              "Qxg7+",
              "Kf4",
              "Qg3+",
              "Kxe4",
              "Qf3+",
              "Kd4",
              "Qe3#",
              "d4",
              "e5",
              "Qd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 170,
            "completion_tokens": 264,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 509,
          "total_completion_tokens": 1544,
          "total_tokens": 2053
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 170,
            "completion_tokens": 264,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rn1q1rk1/pbp1bpp1/1p2pn1p/3p4/2PP3B/3BPN2/PP3PPP/RN1Q1RK1 w - - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rc1",
          "aggressive_uci": "a1c1",
          "aggressive_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. h4 Qf6 24. Rd1 Rd8 25. Rxd8+ Qxd8 26. Qg4 Qf6 27. Ba2 Kh7 28. h5 Nc7 29. Qd1 Bxe4 30. Nd6 Qd8 31. Bxf7 Nb5 32. Bg6+ Bxg6 33. hxg6+ Kxg6 34. Qd3+ Kf6 35. Ne4+ Ke7 36. Qxb5 Qd1+ 37. Qf1 Qd4 38. Qe1 Ke6 39. Qe3 Qa1+ 40. Kh2 Qd1 41. Qh3+ Kd5 42. Nc3+ 1-0\nd4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 c5 cxd5 Nxd5 Bxe7 Qxe7 Nxd5 Bxd5 e4 Bb7 Re1 cxd4 Nxd4 Nc5 Bb1 Rfd8 b4 Na6 a3 e5 Nf5 Qg5 Qf3 Rac8 Rxc8 Rxc8 h4 Qf6 Qg4 Kh7 h5 Nc7 Qd1 Nb5 Qd7 Bc6 Qxc8 Nd4 Nxd4 exd4 e5+ 1-0 d4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 c5 cxd5 Nxd5 Bxe7 Qxe7 Nxd5 Bxd5 e4 Bb7 Re1 cxd4 Nxd4 Nc5 Bb1 Rfd8 b4 Na6 a3 e5 Nf5 Qg5 Qf3 Rac8 Rxc8 Rxc8 h4 Qf6 Qg4 Kh7 h5 Nc7 Qd1 Nb5 Qd7 Bc6 Qxc8 Nd4 Nxd4 exd4 e5+ 1-0 d4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd",
          "aggressive_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "h4",
            "Qf6",
            "Qg4",
            "Kh7",
            "h5",
            "Nc7",
            "Qd1",
            "Nb5",
            "Qd7",
            "Bc6",
            "Qxc8",
            "Nd4",
            "Nxd4",
            "exd4",
            "e5+",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4",
            "b6",
            "c4",
            "Bb7",
            "Nc3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rc1",
          "positional_uci": "a1c1",
          "positional_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82",
          "positional_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rc1",
          "neutral_uci": "a1c1",
          "neutral_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82",
          "neutral_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a1c1",
          "positional_uci": "a1c1",
          "neutral_uci": "a1c1",
          "consensus_move": "a1c1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "h4",
              "Qf6",
              "Qg4",
              "Kh7",
              "h5",
              "Nc7",
              "Qd1",
              "Nb5",
              "Qd7",
              "Bc6",
              "Qxc8",
              "Nd4",
              "Nxd4",
              "exd4",
              "e5+",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4",
              "b6",
              "c4",
              "Bb7",
              "Nc3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 536,
          "total_completion_tokens": 1920,
          "total_tokens": 2456
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2q1rk1/pbpnbpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/R2Q1RK1 w - - 3 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd5",
          "aggressive_uci": "c4d5",
          "aggressive_response": "11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Qe2 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. Rfd1 Rac8 19. b4 Na4 20. Rxc8 Rxc8 21. Qd2 Nc3 22. Rc1 Nxb1 23. Rxb1 Bxe4 24. Re1 Bd5 25. a3 Qf6 26. Nb5 Qg6 27. g3 Rc2 28. Qe3 Qh5 29. Nd4 Qh3 30. Nf3 Qg4 31. Nd4 Qh3 32. Nf3 Qf5 33. Nd4 Qh3 34. Nf3 Qf5 35. Nd4 Qh3 36. Nf3 Qf5 37. Nd4 Qh3 38. Nf3 Qf5 39. Nd4 Qh3 40. Nf3 Qf5 41. Nd4 Qh3 42. Nf3 Qf5 43. Nd4 Qh3 44. Nf3 Qf5 45. Nd4 Qh3 46. Nf3 Qf5 47. Nd4 Qh3 48. Nf3 Qf5 49. Nd4 Qh3 50. Nf3 Qf5 51. Nd4 Qh3 52. Nf3 Qf5 53. Nd4 Qh3 54. Nf3 Qf5 55. Nd4 Qh3 56. Nf3 Qf5 57. Nd4 Qh3 58. Nf3 Qf5 59. Nd4 Qh3 60. Nf3 Qf5 61. Nd4 Qh3 62. Nf3 Qf5 63. Nd4 Qh3 64. Nf3 Qf5 65. Nd4 Qh3 66. Nf3 Qf5 67. Nd4 Qh3 68. Nf3 Qf5 69. Nd4 Qh3 70. Nf3 Qf5 71. Nd4 Qh3 72. Nf3 Qf5 73. Nd4 Qh3 74. Nf3 Qf5 75. Nd4 Qh3 76. Nf3 Qf5 77. Nd4 Qh3 78. Nf3 Qf5 79. Nd4 Qh3 80. Nf3 Qf5 81. Nd4 Qh3 82. Nf3 Qf5 83. Nd4 Qh3 84. Nf3 Qf5 85. Nd4 Qh3 86. Nf",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Qe2",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "Rfd1",
            "Rac8",
            "b4",
            "Na4",
            "Rxc8",
            "Rxc8",
            "Qd2",
            "Nc3",
            "Rc1",
            "Nxb1",
            "Rxb1",
            "Bxe4",
            "Re1",
            "Bd5",
            "a3",
            "Qf6",
            "Nb5",
            "Qg6",
            "g3",
            "Rc2",
            "Qe3",
            "Qh5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qg4",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "cxd5",
          "positional_uci": "c4d5",
          "positional_response": "11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qc3+ 39. Ke2 Qc2+ 40. Kf3 Qf5+ 41. Ke2 Qe4+ 42. Kf1 Qb1+ 43. Ke2 Qc2+ 44. Kf3 Qc3+ 45. Ke2 Qc2+ 46. Kf3 Qf5+ 47. Ke2 Qe4+ 48. Kf1 Qb1+ 49. Ke2 Qc2+ 50. Kf3 Qc3+ 51. Ke2 Qc2+ 52. Kf3 Qf5+ 53. Ke2 Qe4+ 54. Kf1 Qb1+ 55. Ke2 Qc2+ 56. Kf3 Qc3+ 57. Ke2 Qc2+ 58. Kf3 Qf5+ 59. Ke2 Qe4+ 60. Kf1 Qb1+ 61. Ke2 Qc2+ 62. Kf3 Qc3+ 63. Ke2 Qc2+ 64. Kf3 Qf5+ 65. Ke2 Qe4+ 66. Kf1 Qb1+ 67. Ke2 Qc2+ 68. Kf3 Qc3+ 69. Ke2 Qc2+ 70. Kf3 Qf5+ 71. Ke2 Qe4+ 72. Kf1 Qb1+ 73. Ke2 Qc2+ 74. Kf3 Qc3+ 75. Ke2 Qc2+ 76. Kf3 Qf5+ 77. Ke2 Qe4+ 78. Kf1 Qb1+ 79. Ke2 Qc2+",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "cxd5",
          "neutral_uci": "c4d5",
          "neutral_response": "11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82. Qf5+ Kg8",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c4d5",
          "positional_uci": "c4d5",
          "neutral_uci": "c4d5",
          "consensus_move": "c4d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Qe2",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "Rfd1",
              "Rac8",
              "b4",
              "Na4",
              "Rxc8",
              "Rxc8",
              "Qd2",
              "Nc3",
              "Rc1",
              "Nxb1",
              "Rxb1",
              "Bxe4",
              "Re1",
              "Bd5",
              "a3",
              "Qf6",
              "Nb5",
              "Qg6",
              "g3",
              "Rc2",
              "Qe3",
              "Qh5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qg4",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 1920,
          "total_tokens": 2477
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p2pn1p/2pp4/2PP3B/2NBPN2/PP3PPP/2RQ1RK1 w - - 0 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb1",
          "aggressive_uci": "d3b1",
          "aggressive_response": "12. Bb1 Rc8 13. Qc2 Re8 14. Ne5 Nf8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18.\nQd3 f6 19. Ng4 Qd7 20. Ne3 f5 21. a3 Kh8 22. Ba2 Nxc3 23. Rxc3 Rxc3 24. bxc3\ng6 25. c4 dxc4 26. Bxc4 Re4 27. d5 Qd6 28. g3 Nd7 29. Rd1 Nf6 30. Qc3 Kh7 31.\nRd4 Re7 32. Qd3 Qc5 33. Kf1 b5 34. Bxb5 Rxe3 35. Qxe3 Qxb5+ 36. Kg1 Qb1+ 37.\nKg2 Qc2+ 38. Kh3 Qc5 39. Qe5 Kg7 40. d6 Qc6 41. Qe7+ Kg8 42. Qe6+ Kg7 43. Qe7+\nKg8 44. Qe6+ Kg7 45. Qe7+ Kg8 46. Qe6+ Kg7 47. Qe7+ Kg8 48. Qe6+ Kg7 49. Qe7+\nKg8 50. Qe6+ Kg7 51. Qe7+ Kg8 52. Qe6+ Kg7 53. Qe7+ Kg8 54. Qe6+ Kg7 55. Qe7+\nKg8 56. Qe6+ Kg7 57. Qe7+ Kg8 58. Qe6+ Kg7 59. Qe7+ Kg8 60. Qe6+ Kg7 61. Qe7+\nKg8 62. Qe6+ Kg7 63. Qe7+ Kg8 64. Qe6+ Kg7 65. Qe7+ Kg8 66. Qe6+ Kg7 67. Qe7+\nKg8 68. Qe6+ Kg7 69. Qe7+ Kg8 70. Qe6+ Kg7 71. Qe7+ Kg8 72. Qe6+ Kg7 73. Qe7+\nKg8 74. Qe6+ Kg7 75. Qe7+ Kg8 76. Qe6+ Kg7 77. Qe7+ Kg8 78. Qe6+ Kg7 79. Qe7+\nKg8 80. Qe6+ Kg7 81. Qe7+ Kg8 82. Qe6+ Kg7 83. Qe7+ Kg8 84. Qe6+",
          "aggressive_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rc8",
            "Qc2",
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Qd3",
            "f6",
            "Ng4",
            "Qd7",
            "Ne3",
            "f5",
            "a3",
            "Kh8",
            "Ba2",
            "Nxc3",
            "Rxc3",
            "Rxc3",
            "bxc3",
            "g6",
            "c4",
            "dxc4",
            "Bxc4",
            "Re4",
            "d5",
            "Qd6",
            "g3",
            "Nd7",
            "Rd1",
            "Nf6",
            "Qc3",
            "Kh7",
            "Rd4",
            "Re7",
            "Qd3",
            "Qc5",
            "Kf1",
            "b5",
            "Bxb5",
            "Rxe3",
            "Qxe3",
            "Qxb5+",
            "Kg1",
            "Qb1+",
            "Kg2",
            "Qc2+",
            "Kh3",
            "Qc5",
            "Qe5",
            "Kg7",
            "d6",
            "Qc6",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb1",
          "positional_uci": "d3b1",
          "positional_response": "12. Bb1 Re8 13. Qc2 Nf8 14. Ne5 Rc8 15. Qf5 cxd4 16. exd4 Rc7 17. Nb5 Rxc1 18.\nRxc1 Bc8 19. Qf3 a6 20. Nc7 Ne6 21. Nxe8 Qxe8 22. Qd3 g6 23. Qf3 Kg7 24. Bxf6+\nBxf6 25. Qxd5 Nf4 26. Qe4 Bg5 27. Rc7 Be6 28. g3 Bd5 29. Qc2 Nh3+ 30. Kf1 Qb5+\n31. Qd3 Qxb2 32. Qxg6+ Kf8 33. Rxf7+ Ke8 34. Qg8#",
          "positional_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 195,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Qc2",
            "Nf8",
            "Ne5",
            "Rc8",
            "Qf5",
            "cxd4",
            "exd4",
            "Rc7",
            "Nb5",
            "Rxc1",
            "Rxc1",
            "Bc8",
            "Qf3",
            "a6",
            "Nc7",
            "Ne6",
            "Nxe8",
            "Qxe8",
            "Qd3",
            "g6",
            "Qf3",
            "Kg7",
            "Bxf6+",
            "Bxf6",
            "Qxd5",
            "Nf4",
            "Qe4",
            "Bg5",
            "Rc7",
            "Be6",
            "g3",
            "Bd5",
            "Qc2",
            "Nh3+",
            "Kf1",
            "Qb5+",
            "Qd3",
            "Qxb2",
            "Qxg6+",
            "Kf8",
            "Rxf7+",
            "Ke8",
            "Qg8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb1",
          "neutral_uci": "d3b1",
          "neutral_response": "12. Bb1 Re8 13. Qc2 Nf8 14. Ne5 Rc8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18. Qd3 f6 19. Ng4 Qd7 20. Ne3 f5 21. a3 Kh8 22. Ba2 Nxc3 23. Rxc3 Rxc3 24. Qxc3 Ne6 25. Nxf5 Rf8 26. Bb1 Ba6 27. Rf2 Qa4 28. b3 Qxa3 29. Ra2 Rc8 30. Qxc8+ Bxc8 31. Rxa3 Nxf4 32. Rxa7 Bxf5 33. Bxf5 Ne2+ 34. Kf2 Nxd4 35. Ra8# Nf3 Nf6 Nxf6",
          "neutral_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 206,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba6",
            "Rf2",
            "Qa4",
            "b3",
            "Qxa3",
            "Ra2",
            "Rc8",
            "Qxc8+",
            "Bxc8",
            "Rxa3",
            "Nxf4",
            "Rxa7",
            "Bxf5",
            "Bxf5",
            "Ne2+",
            "Kf2",
            "Nxd4",
            "Ra8#",
            "Nf3",
            "Nf6",
            "Nxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3b1",
          "positional_uci": "d3b1",
          "neutral_uci": "d3b1",
          "consensus_move": "d3b1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rc8",
              "Qc2",
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Qd3",
              "f6",
              "Ng4",
              "Qd7",
              "Ne3",
              "f5",
              "a3",
              "Kh8",
              "Ba2",
              "Nxc3",
              "Rxc3",
              "Rxc3",
              "bxc3",
              "g6",
              "c4",
              "dxc4",
              "Bxc4",
              "Re4",
              "d5",
              "Qd6",
              "g3",
              "Nd7",
              "Rd1",
              "Nf6",
              "Qc3",
              "Kh7",
              "Rd4",
              "Re7",
              "Qd3",
              "Qc5",
              "Kf1",
              "b5",
              "Bxb5",
              "Rxe3",
              "Qxe3",
              "Qxb5+",
              "Kg1",
              "Qb1+",
              "Kg2",
              "Qc2+",
              "Kh3",
              "Qc5",
              "Qe5",
              "Kg7",
              "d6",
              "Qc6",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Qc2",
              "Nf8",
              "Ne5",
              "Rc8",
              "Qf5",
              "cxd4",
              "exd4",
              "Rc7",
              "Nb5",
              "Rxc1",
              "Rxc1",
              "Bc8",
              "Qf3",
              "a6",
              "Nc7",
              "Ne6",
              "Nxe8",
              "Qxe8",
              "Qd3",
              "g6",
              "Qf3",
              "Kg7",
              "Bxf6+",
              "Bxf6",
              "Qxd5",
              "Nf4",
              "Qe4",
              "Bg5",
              "Rc7",
              "Be6",
              "g3",
              "Bd5",
              "Qc2",
              "Nh3+",
              "Kf1",
              "Qb5+",
              "Qd3",
              "Qxb2",
              "Qxg6+",
              "Kf8",
              "Rxf7+",
              "Ke8",
              "Qg8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ba6",
              "Rf2",
              "Qa4",
              "b3",
              "Qxa3",
              "Ra2",
              "Rc8",
              "Qxc8+",
              "Bxc8",
              "Rxa3",
              "Nxf4",
              "Rxa7",
              "Bxf5",
              "Bxf5",
              "Ne2+",
              "Kf2",
              "Nxd4",
              "Ra8#",
              "Nf3",
              "Nf6",
              "Nxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 195,
            "completion_tokens": 195,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 194,
            "completion_tokens": 206,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 584,
          "total_completion_tokens": 1041,
          "total_tokens": 1625
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 195,
            "completion_tokens": 195,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 194,
            "completion_tokens": 206,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2NBPN2/PP3PPP/2RQ1RK1 w - - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qd3",
          "aggressive_uci": "d1d3",
          "aggressive_response": "13. Qd3 Re8 14. Ne5 Nf8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18. f5 f6 19. Ng4 Qb4 20. Rc2 Rc4 21. Rd1 Rec8 22. a3 Qb3 23. Ba2 Rxc3 24. Bxb3 Rxd3 25. Rxd3 Rxc2 26. Bxc2 Nd6 27. Ne3 Nd7 28. Rc3 Nb5 29. Rd3 Nd6 30. Bb3 Kf8 31. Bxd5 Ba6 32. Rc3 Nb5 33. Rc4 Nd6 34. Ra4 Nb8 35. Be6 Nc6 36. d5 Bb5 37. Rh4 Ne5 38. a4 Bd3 39. Rd4 Be4 40. b4 Ke7 41. a5 bxa5 42. bxa5 a6 43. Rb4 Bd3 44. Rb8 Bb5 45. Rg8 Ne8 46. Nc2 Nc4 47. Nd4 Nxa5 48. Nxb5 axb5 49. d6+ Nxd6 50. Rxg7+ Kf8 51. Rd7 Nac4 52. Bxc4 Nxc4 53. Rb7 Nd6 54. Rb6 Ke7 55. g4 Kd7 56. Kf2 Kc7 57. Ra6 b4 58. Ke3 b3 59. Kd3 b2 60. Kc2 Nc4 61. Rxf6 Ne3+ 62. Kxb2 Nxg4 63. Rg6 Ne3 64. f6 Kd7 65. Rxh6 Ke6 66. Kc3 Ng4 67. Rh4 Nxf6 68. Kd4 Kf5 69. Rh8 Kg6 70. Ke5 Ng4+ 71. Kf4 Nf6 72. Ra8 Nh5+ 73. Kg4 Nf6+ 74. Kh4 Kh6 75. Ra6 Kg6 76. h3 Kf5 77. Ra5+ Kg6 78. Rg5+ Kh6 79. Rg1 Nh7 80. Kg4 Nf6+ 81. Kf5 Nh5 82. Rg6+ Kh7 83. Kg5 Ng7 84. Ra6 Kg8 85. Kg6 Ne8 86. Ra8 Kf8 87. h4 Ke7 88. Rxe8+ Kxe8 89. Kg7 Ke7 90. h5 Ke6 91. h6 Kf5 92. h7 Kg5 93",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "f5",
            "f6",
            "Ng4",
            "Qb4",
            "Rc2",
            "Rc4",
            "Rd1",
            "Rec8",
            "a3",
            "Qb3",
            "Ba2",
            "Rxc3",
            "Bxb3",
            "Rxd3",
            "Rxd3",
            "Rxc2",
            "Bxc2",
            "Nd6",
            "Ne3",
            "Nd7",
            "Rc3",
            "Nb5",
            "Rd3",
            "Nd6",
            "Bb3",
            "Kf8",
            "Bxd5",
            "Ba6",
            "Rc3",
            "Nb5",
            "Rc4",
            "Nd6",
            "Ra4",
            "Nb8",
            "Be6",
            "Nc6",
            "d5",
            "Bb5",
            "Rh4",
            "Ne5",
            "a4",
            "Bd3",
            "Rd4",
            "Be4",
            "b4",
            "Ke7",
            "a5",
            "bxa5",
            "bxa5",
            "a6",
            "Rb4",
            "Bd3",
            "Rb8",
            "Bb5",
            "Rg8",
            "Ne8",
            "Nc2",
            "Nc4",
            "Nd4",
            "Nxa5",
            "Nxb5",
            "axb5",
            "d6+",
            "Nxd6",
            "Rxg7+",
            "Kf8",
            "Rd7",
            "Nac4",
            "Bxc4",
            "Nxc4",
            "Rb7",
            "Nd6",
            "Rb6",
            "Ke7",
            "g4",
            "Kd7",
            "Kf2",
            "Kc7",
            "Ra6",
            "b4",
            "Ke3",
            "b3",
            "Kd3",
            "b2",
            "Kc2",
            "Nc4",
            "Rxf6",
            "Ne3+",
            "Kxb2",
            "Nxg4",
            "Rg6",
            "Ne3",
            "f6",
            "Kd7",
            "Rxh6",
            "Ke6",
            "Kc3",
            "Ng4",
            "Rh4",
            "Nxf6",
            "Kd4",
            "Kf5",
            "Rh8",
            "Kg6",
            "Ke5",
            "Ng4+",
            "Kf4",
            "Nf6",
            "Ra8",
            "Nh5+",
            "Kg4",
            "Nf6+",
            "Kh4",
            "Kh6",
            "Ra6",
            "Kg6",
            "h3",
            "Kf5",
            "Ra5+",
            "Kg6",
            "Rg5+",
            "Kh6",
            "Rg1",
            "Nh7",
            "Kg4",
            "Nf6+",
            "Kf5",
            "Nh5",
            "Rg6+",
            "Kh7",
            "Kg5",
            "Ng7",
            "Ra6",
            "Kg8",
            "Kg6",
            "Ne8",
            "Ra8",
            "Kf8",
            "h4",
            "Ke7",
            "Rxe8+",
            "Kxe8",
            "Kg7",
            "Ke7",
            "h5",
            "Ke6",
            "h6",
            "Kf5",
            "h7",
            "Kg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd3",
          "positional_uci": "d1d3",
          "positional_response": "13. Qd3 Re8 14. Ne5 Nf8 15. f4 c4 16. Qc2 a6 17. Rf3 b5 18. Rg3 b4 19. Ne2 Ne4 20. Bxe7 Qxe7 21. Rh3 f6 22. Ng4 Qe6 23. Nf2 Nxf2 24. Kxf2 Rc7 25. Rg1 Rce7 26. g4 Bc8 27. Rhg3 Qf7 28. h4 Re4 29. Qd2 R4e7 30. g5 fxg5 31. hxg5 hxg5 32. Rxg5 Qe6 33. R1g3 Qh6 34. Ng1 Qh2+ 35. Rg2 Qh4+ 36. R5g3 Rxe3 37. Nf3 Qxf4 38. Rxg7+ Kh8 39. Rg8# d4 d3 Qd8#",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 236,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "c4",
            "Qc2",
            "a6",
            "Rf3",
            "b5",
            "Rg3",
            "b4",
            "Ne2",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Rh3",
            "f6",
            "Ng4",
            "Qe6",
            "Nf2",
            "Nxf2",
            "Kxf2",
            "Rc7",
            "Rg1",
            "Rce7",
            "g4",
            "Bc8",
            "Rhg3",
            "Qf7",
            "h4",
            "Re4",
            "Qd2",
            "R4e7",
            "g5",
            "fxg5",
            "hxg5",
            "hxg5",
            "Rxg5",
            "Qe6",
            "R1g3",
            "Qh6",
            "Ng1",
            "Qh2+",
            "Rg2",
            "Qh4+",
            "R5g3",
            "Rxe3",
            "Nf3",
            "Qxf4",
            "Rxg7+",
            "Kh8",
            "Rg8#",
            "d4",
            "d3",
            "Qd8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qc2",
          "neutral_uci": "d1c2",
          "neutral_response": "13. Qc2 Re8 14. Ne5 Nf8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18. Qd3 f6 19. Ng4 Qd7 20. Ne3 f5 21. a3 Ne6 22. Ba2 Nxc3 23. Rxc3 Rxc3 24. bxc3 g6 25. g4 fxg4 26. Nxg4 Kg7 27. Ne5 Qe7 28. Qxg6+ Kf8 29. Qxh6+ Qg7+ 30. Qxg7+ Kxg7 31. f5 Ng5 32. f6+ Kf8 33. f7 Re6 34. Nd7+ Ke7 35. f8=Q+ Kxd7 36. Qg7+ Kc6 37. Qxg5 Kb5 38. Bxd5 Bxd5 39. Qxd5+ Ka4 40. Qxe6 Kxa3 41. Rb1 a5 42. Qb3# Bb7 cxb7 43. Qxb7 a4 44. Qxb6 Ka2 45. Qb2#",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 287,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Qd3",
            "f6",
            "Ng4",
            "Qd7",
            "Ne3",
            "f5",
            "a3",
            "Ne6",
            "Ba2",
            "Nxc3",
            "Rxc3",
            "Rxc3",
            "bxc3",
            "g6",
            "g4",
            "fxg4",
            "Nxg4",
            "Kg7",
            "Ne5",
            "Qe7",
            "Qxg6+",
            "Kf8",
            "Qxh6+",
            "Qg7+",
            "Qxg7+",
            "Kxg7",
            "f5",
            "Ng5",
            "f6+",
            "Kf8",
            "f7",
            "Re6",
            "Nd7+",
            "Ke7",
            "f8=Q+",
            "Kxd7",
            "Qg7+",
            "Kc6",
            "Qxg5",
            "Kb5",
            "Bxd5",
            "Bxd5",
            "Qxd5+",
            "Ka4",
            "Qxe6",
            "Kxa3",
            "Rb1",
            "a5",
            "Qb3#",
            "Bb7",
            "cxb7",
            "Qxb7",
            "a4",
            "Qxb6",
            "Ka2",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1d3",
          "positional_uci": "d1d3",
          "neutral_uci": "d1c2",
          "consensus_move": "d1d3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "f5",
              "f6",
              "Ng4",
              "Qb4",
              "Rc2",
              "Rc4",
              "Rd1",
              "Rec8",
              "a3",
              "Qb3",
              "Ba2",
              "Rxc3",
              "Bxb3",
              "Rxd3",
              "Rxd3",
              "Rxc2",
              "Bxc2",
              "Nd6",
              "Ne3",
              "Nd7",
              "Rc3",
              "Nb5",
              "Rd3",
              "Nd6",
              "Bb3",
              "Kf8",
              "Bxd5",
              "Ba6",
              "Rc3",
              "Nb5",
              "Rc4",
              "Nd6",
              "Ra4",
              "Nb8",
              "Be6",
              "Nc6",
              "d5",
              "Bb5",
              "Rh4",
              "Ne5",
              "a4",
              "Bd3",
              "Rd4",
              "Be4",
              "b4",
              "Ke7",
              "a5",
              "bxa5",
              "bxa5",
              "a6",
              "Rb4",
              "Bd3",
              "Rb8",
              "Bb5",
              "Rg8",
              "Ne8",
              "Nc2",
              "Nc4",
              "Nd4",
              "Nxa5",
              "Nxb5",
              "axb5",
              "d6+",
              "Nxd6",
              "Rxg7+",
              "Kf8",
              "Rd7",
              "Nac4",
              "Bxc4",
              "Nxc4",
              "Rb7",
              "Nd6",
              "Rb6",
              "Ke7",
              "g4",
              "Kd7",
              "Kf2",
              "Kc7",
              "Ra6",
              "b4",
              "Ke3",
              "b3",
              "Kd3",
              "b2",
              "Kc2",
              "Nc4",
              "Rxf6",
              "Ne3+",
              "Kxb2",
              "Nxg4",
              "Rg6",
              "Ne3",
              "f6",
              "Kd7",
              "Rxh6",
              "Ke6",
              "Kc3",
              "Ng4",
              "Rh4",
              "Nxf6",
              "Kd4",
              "Kf5",
              "Rh8",
              "Kg6",
              "Ke5",
              "Ng4+",
              "Kf4",
              "Nf6",
              "Ra8",
              "Nh5+",
              "Kg4",
              "Nf6+",
              "Kh4",
              "Kh6",
              "Ra6",
              "Kg6",
              "h3",
              "Kf5",
              "Ra5+",
              "Kg6",
              "Rg5+",
              "Kh6",
              "Rg1",
              "Nh7",
              "Kg4",
              "Nf6+",
              "Kf5",
              "Nh5",
              "Rg6+",
              "Kh7",
              "Kg5",
              "Ng7",
              "Ra6",
              "Kg8",
              "Kg6",
              "Ne8",
              "Ra8",
              "Kf8",
              "h4",
              "Ke7",
              "Rxe8+",
              "Kxe8",
              "Kg7",
              "Ke7",
              "h5",
              "Ke6",
              "h6",
              "Kf5",
              "h7",
              "Kg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "c4",
              "Qc2",
              "a6",
              "Rf3",
              "b5",
              "Rg3",
              "b4",
              "Ne2",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Rh3",
              "f6",
              "Ng4",
              "Qe6",
              "Nf2",
              "Nxf2",
              "Kxf2",
              "Rc7",
              "Rg1",
              "Rce7",
              "g4",
              "Bc8",
              "Rhg3",
              "Qf7",
              "h4",
              "Re4",
              "Qd2",
              "R4e7",
              "g5",
              "fxg5",
              "hxg5",
              "hxg5",
              "Rxg5",
              "Qe6",
              "R1g3",
              "Qh6",
              "Ng1",
              "Qh2+",
              "Rg2",
              "Qh4+",
              "R5g3",
              "Rxe3",
              "Nf3",
              "Qxf4",
              "Rxg7+",
              "Kh8",
              "Rg8#",
              "d4",
              "d3",
              "Qd8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Qd3",
              "f6",
              "Ng4",
              "Qd7",
              "Ne3",
              "f5",
              "a3",
              "Ne6",
              "Ba2",
              "Nxc3",
              "Rxc3",
              "Rxc3",
              "bxc3",
              "g6",
              "g4",
              "fxg4",
              "Nxg4",
              "Kg7",
              "Ne5",
              "Qe7",
              "Qxg6+",
              "Kf8",
              "Qxh6+",
              "Qg7+",
              "Qxg7+",
              "Kxg7",
              "f5",
              "Ng5",
              "f6+",
              "Kf8",
              "f7",
              "Re6",
              "Nd7+",
              "Ke7",
              "f8=Q+",
              "Kxd7",
              "Qg7+",
              "Kc6",
              "Qxg5",
              "Kb5",
              "Bxd5",
              "Bxd5",
              "Qxd5+",
              "Ka4",
              "Qxe6",
              "Kxa3",
              "Rb1",
              "a5",
              "Qb3#",
              "Bb7",
              "cxb7",
              "Qxb7",
              "a4",
              "Qxb6",
              "Ka2",
              "Qb2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 236,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 287,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 1163,
          "total_tokens": 1771
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 236,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 287,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2rq1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2N1PN2/PP3PPP/1BRQ1RK1 w - - 2 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne5",
          "aggressive_uci": "f3e5",
          "aggressive_response": "14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3\nBe7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5\nexd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3\nBe7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5\nexd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6.",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe5",
            "dxe5",
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne5",
          "positional_uci": "f3e5",
          "positional_response": "14. Ne5 Nxe5 15. dxe5 Ne4 16. Bxe7 Qxe7 17. Nxd5 Bxd5 18. Qxd5 Ng5 19. f4 Rfd8 20. Qc4 Ne6 21. Qe4 g6 22. f5 Ng5 23. Qf4 Rd2 24. fxg6 fxg6 25. Bxg6 Rf8 26. Qc4+ Kg7 27. Rxf8 Qxf8 28. Rf1 Qe7 29. Qc3 Rd8 30. Bc2 Ne6 31. Rf6 Nf8 32. e4 Nh7 33. Qg3+ Kh8 34. Rxh6 Rg8 35. Qh3 Rg7 36. e6 Kg8 37. e5 Qg5 38. Bxh7+ Kf8 39. Rf6+ Ke7 40. Rf7+ Rxf7 41. exf7 Qc1+ 42. Kf2 Qxb2+ 43. Kg3 Qxe5+ 44. Kh4 Qf6+ 45. Kg3 Qe5+ 46. Kf2 Qf6+ 47. Qf3 Qd4+ 48. Kg3 Qg7+ 49. Kh3 Qxh7+ 50. Kg3 Qg7+ 51. Kh3 Qh6+ 52. Kg3 Qg5+ 53. Kh3 Qh6+ 54. Kg3 Qg5+ 55. Kh3 Qh6+ 56. Kg3 Qg5+ 57. Kh3 Qh6+ 58. Kg3 Qg5+ 59. Kh3 Qh6+ 60. Kg3 Qg5+ 61. Kh3 Qh6+ 62. Kg3 Qg5+ 63. Kh3 Qh6+ 64. Kg3 Qg5+ 65. Kh3 Qh6+ 66. Kg3 Qg5+ 67. Kh3 Qh6+ 68. Kg3 Qg5+ 69. Kh3 Qh6+ 70. Kg3 Qg5+ 71. Kh3 Qh6+ 72. Kg3 Qg5+ 73. Kh3 Qh6+ 74. Kg3 Qg5+ 75. Kh3 Qh6+ 76. Kg3 Qg5+ 77. Kh3 Qh6+ 78. Kg3 Qg5+ 79. Kh3 Qh6+ 80. Kg3 Qg5+ 81. Kh3 Qh6+ 82. Kg3 Qg5+ 83. Kh3 Qh6+ 84. Kg3 Qg5+ 85. Kh3 Qh6",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe5",
            "dxe5",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "Qxd5",
            "Ng5",
            "f4",
            "Rfd8",
            "Qc4",
            "Ne6",
            "Qe4",
            "g6",
            "f5",
            "Ng5",
            "Qf4",
            "Rd2",
            "fxg6",
            "fxg6",
            "Bxg6",
            "Rf8",
            "Qc4+",
            "Kg7",
            "Rxf8",
            "Qxf8",
            "Rf1",
            "Qe7",
            "Qc3",
            "Rd8",
            "Bc2",
            "Ne6",
            "Rf6",
            "Nf8",
            "e4",
            "Nh7",
            "Qg3+",
            "Kh8",
            "Rxh6",
            "Rg8",
            "Qh3",
            "Rg7",
            "e6",
            "Kg8",
            "e5",
            "Qg5",
            "Bxh7+",
            "Kf8",
            "Rf6+",
            "Ke7",
            "Rf7+",
            "Rxf7",
            "exf7",
            "Qc1+",
            "Kf2",
            "Qxb2+",
            "Kg3",
            "Qxe5+",
            "Kh4",
            "Qf6+",
            "Kg3",
            "Qe5+",
            "Kf2",
            "Qf6+",
            "Qf3",
            "Qd4+",
            "Kg3",
            "Qg7+",
            "Kh3",
            "Qxh7+",
            "Kg3",
            "Qg7+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne5",
          "neutral_uci": "f3e5",
          "neutral_response": "14. Ne5 Nxe5 15. dxe5 Ne4 16. Bxe7 Qxe7 17. Nxd5 Bxd5 18. Qxd5 Ng5 19. f4 Ne6 20. Qe4 g6 21. f5 Ng5 22. Qf4 Rce8 23. h4 Nh7 24. Qxh6 Qxe5 25. fxg6 fxg6 26. Qxg6+ Qg7 27. Rxf8+ Rxf8 28. Qxg7+ Kxg7 29. Bxh7 Kxh7 30. Rf1 Re8 31. Rf7+ Kg6 32. Rxa7 Rxe3 33. Rb7 Re6 34. g4 Re4 35. Rxb6+ Kg7 36. Kf2 Rxg4 37. h5 Rh4 38. h6+ Kh7 39. Ke3 Rh2 40. Kd3 Rh4 41. Kc3 Rg4 42. b3 Rh4 43. a4 Rg4 44. a5 Rg1 45. a6 Ra1 46. Kc4 Ra5 47. Rc6 Kh8 48. Rxc5 Rxa6 49. Rh5 Kh7 50. b4 Ra1 51. b5 Rc1+ 52. Kd5 Rd1+ 53. Kc6 Rc1+ 54. Kb7 Rb1 55. b6 Rb2 56. Kc7 Rc2+ 57. Kb8 Rb2 58. b7 Rb1 59. Rc5 Kxh6 60. Kc7 1-0 61. b8=Q Rxb8 62. Kxb8 Kg6 63. Kc7 Kf6 64. Kd6 Kf7 65. Re5 Kf6 66. Kd5 Kf7 67. Re6 Kg7 68. Ke5 Kf7 69. Kf5 Kg7 70. Rf6 Kh7 71. Rg6 Kh8 72. Kf6 Kh7 73. Kf7 Kh8 74. Rh6# 1-0 Qc7 Qc7 Qc7",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 522,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe5",
            "dxe5",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "Qxd5",
            "Ng5",
            "f4",
            "Ne6",
            "Qe4",
            "g6",
            "f5",
            "Ng5",
            "Qf4",
            "Rce8",
            "h4",
            "Nh7",
            "Qxh6",
            "Qxe5",
            "fxg6",
            "fxg6",
            "Qxg6+",
            "Qg7",
            "Rxf8+",
            "Rxf8",
            "Qxg7+",
            "Kxg7",
            "Bxh7",
            "Kxh7",
            "Rf1",
            "Re8",
            "Rf7+",
            "Kg6",
            "Rxa7",
            "Rxe3",
            "Rb7",
            "Re6",
            "g4",
            "Re4",
            "Rxb6+",
            "Kg7",
            "Kf2",
            "Rxg4",
            "h5",
            "Rh4",
            "h6+",
            "Kh7",
            "Ke3",
            "Rh2",
            "Kd3",
            "Rh4",
            "Kc3",
            "Rg4",
            "b3",
            "Rh4",
            "a4",
            "Rg4",
            "a5",
            "Rg1",
            "a6",
            "Ra1",
            "Kc4",
            "Ra5",
            "Rc6",
            "Kh8",
            "Rxc5",
            "Rxa6",
            "Rh5",
            "Kh7",
            "b4",
            "Ra1",
            "b5",
            "Rc1+",
            "Kd5",
            "Rd1+",
            "Kc6",
            "Rc1+",
            "Kb7",
            "Rb1",
            "b6",
            "Rb2",
            "Kc7",
            "Rc2+",
            "Kb8",
            "Rb2",
            "b7",
            "Rb1",
            "Rc5",
            "Kxh6",
            "Kc7",
            "b8=Q",
            "Rxb8",
            "Kxb8",
            "Kg6",
            "Kc7",
            "Kf6",
            "Kd6",
            "Kf7",
            "Re5",
            "Kf6",
            "Kd5",
            "Kf7",
            "Re6",
            "Kg7",
            "Ke5",
            "Kf7",
            "Kf5",
            "Kg7",
            "Rf6",
            "Kh7",
            "Rg6",
            "Kh8",
            "Kf6",
            "Kh7",
            "Kf7",
            "Kh8",
            "Rh6#",
            "Qc7",
            "Qc7",
            "Qc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3e5",
          "positional_uci": "f3e5",
          "neutral_uci": "f3e5",
          "consensus_move": "f3e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxe5",
              "dxe5",
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxe5",
              "dxe5",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "Qxd5",
              "Ng5",
              "f4",
              "Rfd8",
              "Qc4",
              "Ne6",
              "Qe4",
              "g6",
              "f5",
              "Ng5",
              "Qf4",
              "Rd2",
              "fxg6",
              "fxg6",
              "Bxg6",
              "Rf8",
              "Qc4+",
              "Kg7",
              "Rxf8",
              "Qxf8",
              "Rf1",
              "Qe7",
              "Qc3",
              "Rd8",
              "Bc2",
              "Ne6",
              "Rf6",
              "Nf8",
              "e4",
              "Nh7",
              "Qg3+",
              "Kh8",
              "Rxh6",
              "Rg8",
              "Qh3",
              "Rg7",
              "e6",
              "Kg8",
              "e5",
              "Qg5",
              "Bxh7+",
              "Kf8",
              "Rf6+",
              "Ke7",
              "Rf7+",
              "Rxf7",
              "exf7",
              "Qc1+",
              "Kf2",
              "Qxb2+",
              "Kg3",
              "Qxe5+",
              "Kh4",
              "Qf6+",
              "Kg3",
              "Qe5+",
              "Kf2",
              "Qf6+",
              "Qf3",
              "Qd4+",
              "Kg3",
              "Qg7+",
              "Kh3",
              "Qxh7+",
              "Kg3",
              "Qg7+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxe5",
              "dxe5",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "Qxd5",
              "Ng5",
              "f4",
              "Ne6",
              "Qe4",
              "g6",
              "f5",
              "Ng5",
              "Qf4",
              "Rce8",
              "h4",
              "Nh7",
              "Qxh6",
              "Qxe5",
              "fxg6",
              "fxg6",
              "Qxg6+",
              "Qg7",
              "Rxf8+",
              "Rxf8",
              "Qxg7+",
              "Kxg7",
              "Bxh7",
              "Kxh7",
              "Rf1",
              "Re8",
              "Rf7+",
              "Kg6",
              "Rxa7",
              "Rxe3",
              "Rb7",
              "Re6",
              "g4",
              "Re4",
              "Rxb6+",
              "Kg7",
              "Kf2",
              "Rxg4",
              "h5",
              "Rh4",
              "h6+",
              "Kh7",
              "Ke3",
              "Rh2",
              "Kd3",
              "Rh4",
              "Kc3",
              "Rg4",
              "b3",
              "Rh4",
              "a4",
              "Rg4",
              "a5",
              "Rg1",
              "a6",
              "Ra1",
              "Kc4",
              "Ra5",
              "Rc6",
              "Kh8",
              "Rxc5",
              "Rxa6",
              "Rh5",
              "Kh7",
              "b4",
              "Ra1",
              "b5",
              "Rc1+",
              "Kd5",
              "Rd1+",
              "Kc6",
              "Rc1+",
              "Kb7",
              "Rb1",
              "b6",
              "Rb2",
              "Kc7",
              "Rc2+",
              "Kb8",
              "Rb2",
              "b7",
              "Rb1",
              "Rc5",
              "Kxh6",
              "Kc7",
              "b8=Q",
              "Rxb8",
              "Kxb8",
              "Kg6",
              "Kc7",
              "Kf6",
              "Kd6",
              "Kf7",
              "Re5",
              "Kf6",
              "Kd5",
              "Kf7",
              "Re6",
              "Kg7",
              "Ke5",
              "Kf7",
              "Kf5",
              "Kg7",
              "Rf6",
              "Kh7",
              "Rg6",
              "Kh8",
              "Kf6",
              "Kh7",
              "Kf7",
              "Kh8",
              "Rh6#",
              "Qc7",
              "Qc7",
              "Qc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 522,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 1802,
          "total_tokens": 2437
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 522,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pbqnbpp1/1p3n1p/2pp4/3P3B/2NQPN2/PP3PPP/1BR2RK1 w - - 4 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxe5",
          "aggressive_uci": "d4e5",
          "aggressive_response": "15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 17. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7#",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxe5",
          "positional_uci": "d4e5",
          "positional_response": "15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxe5",
          "neutral_uci": "d4e5",
          "neutral_response": "15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 640,
            "total_tokens": 859,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4e5",
          "positional_uci": "d4e5",
          "neutral_uci": "d4e5",
          "consensus_move": "d4e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 640,
            "total_tokens": 859,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 1920,
          "total_tokens": 2579
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 640,
            "total_tokens": 859,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "2r2rk1/pbq1bpp1/1p3n1p/2ppn3/3P3B/2NQP3/PP3PPP/1BR2RK1 w - - 0 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": "h4f6",
          "aggressive_response": "16. Bxf6 Bxf6 17. Qh7# cxd5 e4 Bxe4 Qh8#",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 28,
            "total_tokens": 257,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh7#",
            "cxd5",
            "e4",
            "Bxe4",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf6",
          "positional_uci": "h4f6",
          "positional_response": "16. Bxf6 Bxf6 17. Qh7# d5 18. Qh8# d4 19. Qh7# d3",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 36,
            "total_tokens": 265,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh7#",
            "d5",
            "Qh8#",
            "d4",
            "Qh7#",
            "d3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "h4f6",
          "neutral_response": "16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1-0",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 304,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4f6",
          "positional_uci": "h4f6",
          "neutral_uci": "h4f6",
          "consensus_move": "h4f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh7#",
              "cxd5",
              "e4",
              "Bxe4",
              "Qh8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qh7#",
              "d5",
              "Qh8#",
              "d4",
              "Qh7#",
              "d3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 28,
            "total_tokens": 257,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 36,
            "total_tokens": 265,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 304,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 368,
          "total_tokens": 1054
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 28,
            "total_tokens": 257,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 36,
            "total_tokens": 265,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 304,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pb2bpp1/1p3n1p/2ppq3/7B/2NQP3/PP3PPP/1BR2RK1 w - - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh7#",
          "aggressive_uci": "d3h7",
          "aggressive_response": "17. Qh7# gxf6 18. Qh7# Kh8 19. Qxh6+ Kg8 20. Qh7# Kh8 21. Qxh6+ Kg8 22. Qh7# Kh8 23. Qxh6+ Kg8 24. Qh7# Kh8 25. Qxh6+ Kg8 26. Qh7# Kh8 27. Qxh6+ Kg8 28. Qh7# Kh8 29. Qxh6+ Kg8 30. Qh7# Kh8 31. Qxh6+ Kg8 32. Qh7# Kh8 33. Qxh6+ Kg8 34. Qh7# Kh8 35. Qxh6+ Kg8 36. Qh7# Kh8 37. Qxh6+ Kg8 38. Qh7# Kh8 39. Qxh6+ Kg8 40. Qh7# Kh8 41. Qxh6+ Kg8 42. Qh7# Kh8 43. Qxh6+ Kg8 44. Qh7# Kh8 45. Qxh6+ Kg8 46. Qh7# Kh8 47. Qxh6+ Kg8 48. Qh7# Kh8 49. Qxh6+ Kg8 50. Qh7# Kh8 51. Qxh6+ Kg8 52. Qh7# Kh8 53. Qxh6+ Kg8 54. Qh7# Kh8 55. Qxh6+ Kg8 56. Qh7# Kh8 57. Qxh6+ Kg8 58. Qh7# Kh8 59. Qxh6+ Kg8 60. Qh7# Kh8 61. Qxh6+ Kg8 62. Qh7# Kh8 63. Qxh6+ Kg8 64. Qh7# Kh8 65. Qxh6+ Kg8 66. Qh7# Kh8 67. Qxh6+ Kg8 68. Qh7# Kh8 69. Qxh6+ Kg8 70. Qh7# Kh8 71. Qxh6+ Kg8 72. Qh7# Kh8 73. Qxh6+ Kg8 74. Qh7# Kh8 75. Qxh6+ Kg8 76. Qh7# Kh8 77. Qxh6+ Kg8 78. Qh7# Kh8 79. Qxh6+ Kg8 80. Qh7# Kh8 81. Qxh6+ Kg8 82. Qh7# Kh8 83. Qxh6+ Kg8 84.",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 640,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh8",
            "Qxh6+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qh7#",
          "positional_uci": "d3h7",
          "positional_response": "17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 gxf6 17. Qh7# 1-0\nd4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 c5 cxd5 exd5 Bb1 Rc8 Qd3 Qc7 Ne5 Nxe5 dxe5 Qxe5 Bxf6 gxf6 Qh7#",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 236,
            "total_tokens": 474,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh7#",
          "neutral_uci": "d3h7",
          "neutral_response": "17. Qh7# gxf6 18. Qh7# Kh8 19. Qxh6+ Kg8 20. Qh7# Kh8 21. Qxh6+ Kg8 22. Qh7# Kh8 23. Qxh6+ Kg8 24. Qh7# Kh8 25. Qxh6+ Kg8 26. Qh7# Kh8 27. Qxh6+ Kg8 28. Qh7# Kh8 29. Qxh6+ Kg8 30. Qh7# Kh8 31. Qxh6+ Kg8 32. Qh7# Kh8 33. Qxh6+ Kg8 34. Qh7# Kh8 35. Qxh6+ Kg8 36. Qh7# Kh8 37. Qxh6+ Kg8 38. Qh7# Kh8 39. Qxh6+ Kg8 40. Qh7# Kh8 41. Qxh6+ Kg8 42. Qh7# Kh8 43. Qxh6+ Kg8 44. Qh7# Kh8 45. Qxh6+ Kg8 46. Qh7# Kh8 47. Qxh6+ Kg8 48. Qh7# Kh8 49. Qxh6+ Kg8 50. Qh7# Kh8 51. Qxh6+ Kg8 52. Qh7# Kh8 53. Qxh6+ Kg8 54. Qh7# Kh8 55. Qxh6+ Kg8 56. Qh7# Kh8 57. Qxh6+ Kg8 58. Qh7# Kh8 59. Qxh6+ Kg8 60. Qh7# Kh8 61. Qxh6+ Kg8 62. Qh7# Kh8 63. Qxh6+ Kg8 64. Qh7# Kh8 65. Qxh6+ Kg8 66. Qh7# Kh8 67. Qxh6+ Kg8 68. Qh7# Kh8 69. Qxh6+ Kg8 70. Qh7# Kh8 71. Qxh6+ Kg8 72. Qh7# Kh8 73. Qxh6+ Kg8 74. Qh7# Kh8 75. Qxh6+ Kg8 76. Qh7# Kh8 77. Qxh6+ Kg8 78. Qh7# Kh8 79. Qxh6+ Kg8 80. Qh7# Kh8 81. Qxh6+ Kg8 82. Qh7# Kh8 83. Qxh6+ Kg8 84.",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh8",
            "Qxh6+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3h7",
          "positional_uci": "d3h7",
          "neutral_uci": "d3h7",
          "consensus_move": "d3h7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kh8",
              "Qxh6+",
              "Kg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kh8",
              "Qxh6+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 640,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 236,
            "total_tokens": 474,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 1516,
          "total_tokens": 2229
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 640,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 236,
            "total_tokens": 474,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "2r2rk1/pb2bp2/1p3p1p/2ppq3/8/2NQP3/PP3PPP/1BR2RK1 w - - 0 17"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5\n11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Qf3 Bg4\n16. Qg2 Qh5 17. Be3 Rae8 18. Nd2 Re6 19. a4 b4 20. c4 Nxe3\n21. Rxe3 Rxe3 22. fxe3 c5 23. Re1 Re8 24. Qc6 Rd8 25. Ne4 Bf3\n26. Bd1 Bxd1 27. Nxd6 Bf3 28. Qc7 Rf8 29. Qxc5 Qh3 30. Re2 Bxe2\n31. Qf5 Bg4 32. Qf4 Be6 33. d5 Bd7 34. c5 Bxa4 35. c6 Bb3\n36. e4 Qh5 37. c7 Qd1+ 38. Kg2 Qc2+ 39. Kh3 Qxc7 40. Nf5 Qxf4\n41. gxf4 Re8 42. d6 Be6 43. Kg3 Bxf5 44. exf5 Rd8 45. Kf3 Rxd6\n46. Ke4 a5 47. Ke5 Rd2 48. b3 a4 49. bxa4 b3 50. a5 b2\n51. a6 b1=Q 52. a7 Qb5+ 53. Ke4 Qd5+ 54. Ke3 Qd3# 1-0\n55. f6 gxf6 56. a8=Q+ Kg7 57. Qf3 Qd4#",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 465,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Qh5",
            "Be3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "b4",
            "c4",
            "Nxe3",
            "Rxe3",
            "Rxe3",
            "fxe3",
            "c5",
            "Re1",
            "Re8",
            "Qc6",
            "Rd8",
            "Ne4",
            "Bf3",
            "Bd1",
            "Bxd1",
            "Nxd6",
            "Bf3",
            "Qc7",
            "Rf8",
            "Qxc5",
            "Qh3",
            "Re2",
            "Bxe2",
            "Qf5",
            "Bg4",
            "Qf4",
            "Be6",
            "d5",
            "Bd7",
            "c5",
            "Bxa4",
            "c6",
            "Bb3",
            "e4",
            "Qh5",
            "c7",
            "Qd1+",
            "Kg2",
            "Qc2+",
            "Kh3",
            "Qxc7",
            "Nf5",
            "Qxf4",
            "gxf4",
            "Re8",
            "d6",
            "Be6",
            "Kg3",
            "Bxf5",
            "exf5",
            "Rd8",
            "Kf3",
            "Rxd6",
            "Ke4",
            "a5",
            "Ke5",
            "Rd2",
            "b3",
            "a4",
            "bxa4",
            "b3",
            "a5",
            "b2",
            "a6",
            "b1=Q",
            "a7",
            "Qb5+",
            "Ke4",
            "Qd5+",
            "Ke3",
            "Qd3#",
            "f6",
            "gxf6",
            "a8=Q+",
            "Kg7",
            "Qf3",
            "Qd4#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Kf7\n39. Bxb5 Bxb5 40. Rxb5 Rc8 41. Rb4 Rc1+ 42. Kh2 Rc2\n43. Kg3 Nc6 44. Rxa4 Rxb2 45. Ra6 Nb4 46. Ra7+ Kg6\n47. Nh4+ Kh6 48. Nf5+ Kg6 49. Rg7+ Kh5 50. Rxh7+ Kg6\n51. Rg7+ Kh5 52. Kf3 Nd3 53. g4# Nxf2 54. Rh7+ Kg6\n55. Rh6+ Kf7 56. Rh7+ Kg6 57. Rg7# Nxe4 58. Kxe4 Rxa2\n59. h4 Ra4+ 60. Kf3 Rf4+ 61. Kg3 Rxf5 62. gxf5+ Kxg7\n63. Kg4 Kh6 64. h5 Kg7 65. Kh4 Kh6 66. Kg4 Kg7\n67. Kh4 Kh6 68. Kg4 Kg7 69. Kh4 Kh6 70. Kg4 Kg7\n71. Kh4 Kh6 72. Kg4 Kg7 73. Kh4 Kh6 74. Kg4 Kg7\n75. Kh4 Kh6 76. Kg4 Kg7 77. Kh4 Kh6 78. Kg4 Kg7\n79. Kh4 Kh6 80. Kg4 Kg7",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Kf7",
            "Bxb5",
            "Bxb5",
            "Rxb5",
            "Rc8",
            "Rb4",
            "Rc1+",
            "Kh2",
            "Rc2",
            "Kg3",
            "Nc6",
            "Rxa4",
            "Rxb2",
            "Ra6",
            "Nb4",
            "Ra7+",
            "Kg6",
            "Nh4+",
            "Kh6",
            "Nf5+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Rxh7+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Kf3",
            "Nd3",
            "g4#",
            "Nxf2",
            "Rh7+",
            "Kg6",
            "Rh6+",
            "Kf7",
            "Rh7+",
            "Kg6",
            "Rg7#",
            "Nxe4",
            "Kxe4",
            "Rxa2",
            "h4",
            "Ra4+",
            "Kf3",
            "Rf4+",
            "Kg3",
            "Rxf5",
            "gxf5+",
            "Kxg7",
            "Kg4",
            "Kh6",
            "h5",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Bb7\n10. d4 Re8 11. Nbd2 Bf8 12. a4 h6\n13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5\n16. d5 Nd7 17. Ra3 f5 18. Rae3 fxe4\n19. Nxe4 Nxd5 20. Ba2 c4 21. Nxd6 Rxe3\n22. Nxb7 Rxe1+ 23. Nxe1 Qe7 24. Qxd5+ Kh8\n25. Nf3 Nf6 26. Qc6 Rb8 27. Na5 Qd8\n28. Bd2 Bb4 29. Bxb4 Qd1+ 30. Kh2 Qxa4\n31. Qd6 Re8 32. Bb1 Qa1 33. Bg6 Rc8\n34. Bc3 Qc1 35. Bxf6 gxf6 36. Qxf6+ Kg8\n37. Qf7+ Kh8 38. Qh7# e5 Nf6 Qf4",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 318,
            "total_tokens": 431,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Qf4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Qh5",
              "Be3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "b4",
              "c4",
              "Nxe3",
              "Rxe3",
              "Rxe3",
              "fxe3",
              "c5",
              "Re1",
              "Re8",
              "Qc6",
              "Rd8",
              "Ne4",
              "Bf3",
              "Bd1",
              "Bxd1",
              "Nxd6",
              "Bf3",
              "Qc7",
              "Rf8",
              "Qxc5",
              "Qh3",
              "Re2",
              "Bxe2",
              "Qf5",
              "Bg4",
              "Qf4",
              "Be6",
              "d5",
              "Bd7",
              "c5",
              "Bxa4",
              "c6",
              "Bb3",
              "e4",
              "Qh5",
              "c7",
              "Qd1+",
              "Kg2",
              "Qc2+",
              "Kh3",
              "Qxc7",
              "Nf5",
              "Qxf4",
              "gxf4",
              "Re8",
              "d6",
              "Be6",
              "Kg3",
              "Bxf5",
              "exf5",
              "Rd8",
              "Kf3",
              "Rxd6",
              "Ke4",
              "a5",
              "Ke5",
              "Rd2",
              "b3",
              "a4",
              "bxa4",
              "b3",
              "a5",
              "b2",
              "a6",
              "b1=Q",
              "a7",
              "Qb5+",
              "Ke4",
              "Qd5+",
              "Ke3",
              "Qd3#",
              "f6",
              "gxf6",
              "a8=Q+",
              "Kg7",
              "Qf3",
              "Qd4#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Kf7",
              "Bxb5",
              "Bxb5",
              "Rxb5",
              "Rc8",
              "Rb4",
              "Rc1+",
              "Kh2",
              "Rc2",
              "Kg3",
              "Nc6",
              "Rxa4",
              "Rxb2",
              "Ra6",
              "Nb4",
              "Ra7+",
              "Kg6",
              "Nh4+",
              "Kh6",
              "Nf5+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Rxh7+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Kf3",
              "Nd3",
              "g4#",
              "Nxf2",
              "Rh7+",
              "Kg6",
              "Rh6+",
              "Kf7",
              "Rh7+",
              "Kg6",
              "Rg7#",
              "Nxe4",
              "Kxe4",
              "Rxa2",
              "h4",
              "Ra4+",
              "Kf3",
              "Rf4+",
              "Kg3",
              "Rxf5",
              "gxf5+",
              "Kxg7",
              "Kg4",
              "Kh6",
              "h5",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Qf4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 465,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 318,
            "total_tokens": 431,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1423,
          "total_tokens": 1764
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 465,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 318,
            "total_tokens": 431,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    }
  ],
  "white_errors": [],
  "black_errors": [],
  "white_plan_log": [],
  "black_plan_log": [],
  "timestamp": "2025-11-29T23:01:09.711178",
  "game_id": "deepseek-ai_deepseek-v3_vs_gpt-3.5-turbo-instruct_SC_2",
  "configuration": "SC"
}