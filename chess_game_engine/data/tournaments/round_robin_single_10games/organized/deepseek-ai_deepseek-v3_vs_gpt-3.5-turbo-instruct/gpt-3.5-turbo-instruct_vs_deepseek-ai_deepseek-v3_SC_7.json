{
  "result": "gpt-3.5-turbo-instruct wins by disqualification (deepseek-ai/deepseek-v3 failed to produce a legal move)",
  "white_player": "gpt-3.5-turbo-instruct",
  "black_player": "deepseek-ai/deepseek-v3",
  "white_score": 1.0,
  "black_score": 0.0,
  "total_moves": 29,
  "moves": [
    "e2e4",
    "e7e5",
    "g1f3",
    "b8c6",
    "f1b5",
    "a7a6",
    "b5c6",
    "d7c6",
    "f3e5",
    "d8d4",
    "e5f3",
    "d4e4",
    "e1f1",
    "e4f5",
    "d2d3",
    "f5f3",
    "d1f3",
    "c8e6",
    "b1c3",
    "e8c8",
    "c1g5",
    "f7f6",
    "a1e1",
    "e6g4",
    "f3g4",
    "c8b8",
    "g4e6",
    "d8d3",
    "c2d3"
  ],
  "game_history": [
    {
      "move_number": 1,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e4",
      "move_san": "e4",
      "fen_after": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "move_number": 2,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "e7e5",
      "move_san": "e5",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "move_number": 3,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1f3",
      "move_san": "Nf3",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "move_number": 4,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "b8c6",
      "move_san": "Nc6",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "move_number": 5,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1b5",
      "move_san": "Bb5",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "move_number": 6,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "a7a6",
      "move_san": "a6",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "move_number": 7,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b5c6",
      "move_san": "Bxc6",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1B5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 0 4"
    },
    {
      "move_number": 8,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "d7c6",
      "move_san": "dxc6",
      "fen_after": "r1bqkbnr/1pp2ppp/p1p5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 5"
    },
    {
      "move_number": 9,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f3e5",
      "move_san": "Nxe5",
      "fen_after": "r1bqkbnr/1pp2ppp/p1p5/4N3/4P3/8/PPPP1PPP/RNBQK2R b KQkq - 0 5"
    },
    {
      "move_number": 10,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "d8d4",
      "move_san": "Qd4",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/4N3/3qP3/8/PPPP1PPP/RNBQK2R w KQkq - 1 6"
    },
    {
      "move_number": 11,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e5f3",
      "move_san": "Nf3",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/3qP3/5N2/PPPP1PPP/RNBQK2R b KQkq - 2 6"
    },
    {
      "move_number": 12,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "d4e4",
      "move_san": "Qxe4+",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 7"
    },
    {
      "move_number": 13,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1f1",
      "move_san": "Kf1",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQ1K1R b kq - 1 7"
    },
    {
      "move_number": 14,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "e4f5",
      "move_san": "Qf5",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/5q2/8/5N2/PPPP1PPP/RNBQ1K1R w kq - 2 8"
    },
    {
      "move_number": 15,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2d3",
      "move_san": "d3",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/5q2/8/3P1N2/PPP2PPP/RNBQ1K1R b kq - 0 8"
    },
    {
      "move_number": 16,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "f5f3",
      "move_san": "Qxf3",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/8/3P1q2/PPP2PPP/RNBQ1K1R w kq - 0 9"
    },
    {
      "move_number": 17,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1f3",
      "move_san": "Qxf3",
      "fen_after": "r1b1kbnr/1pp2ppp/p1p5/8/8/3P1Q2/PPP2PPP/RNB2K1R b kq - 0 9"
    },
    {
      "move_number": 18,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "c8e6",
      "move_san": "Be6",
      "fen_after": "r3kbnr/1pp2ppp/p1p1b3/8/8/3P1Q2/PPP2PPP/RNB2K1R w kq - 1 10"
    },
    {
      "move_number": 19,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b1c3",
      "move_san": "Nc3",
      "fen_after": "r3kbnr/1pp2ppp/p1p1b3/8/8/2NP1Q2/PPP2PPP/R1B2K1R b kq - 2 10"
    },
    {
      "move_number": 20,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "e8c8",
      "move_san": "O-O-O",
      "fen_after": "2kr1bnr/1pp2ppp/p1p1b3/8/8/2NP1Q2/PPP2PPP/R1B2K1R w - - 3 11"
    },
    {
      "move_number": 21,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c1g5",
      "move_san": "Bg5",
      "fen_after": "2kr1bnr/1pp2ppp/p1p1b3/6B1/8/2NP1Q2/PPP2PPP/R4K1R b - - 4 11"
    },
    {
      "move_number": 22,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "f7f6",
      "move_san": "f6",
      "fen_after": "2kr1bnr/1pp3pp/p1p1bp2/6B1/8/2NP1Q2/PPP2PPP/R4K1R w - - 0 12"
    },
    {
      "move_number": 23,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a1e1",
      "move_san": "Re1",
      "fen_after": "2kr1bnr/1pp3pp/p1p1bp2/6B1/8/2NP1Q2/PPP2PPP/4RK1R b - - 1 12"
    },
    {
      "move_number": 24,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "e6g4",
      "move_san": "Bg4",
      "fen_after": "2kr1bnr/1pp3pp/p1p2p2/6B1/6b1/2NP1Q2/PPP2PPP/4RK1R w - - 2 13"
    },
    {
      "move_number": 25,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f3g4",
      "move_san": "Qxg4+",
      "fen_after": "2kr1bnr/1pp3pp/p1p2p2/6B1/6Q1/2NP4/PPP2PPP/4RK1R b - - 0 13"
    },
    {
      "move_number": 26,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "c8b8",
      "move_san": "Kb8",
      "fen_after": "1k1r1bnr/1pp3pp/p1p2p2/6B1/6Q1/2NP4/PPP2PPP/4RK1R w - - 1 14"
    },
    {
      "move_number": 27,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g4e6",
      "move_san": "Qe6",
      "fen_after": "1k1r1bnr/1pp3pp/p1p1Qp2/6B1/8/2NP4/PPP2PPP/4RK1R b - - 2 14"
    },
    {
      "move_number": 28,
      "player": "deepseek-ai/deepseek-v3",
      "color": "black",
      "move_uci": "d8d3",
      "move_san": "Rxd3",
      "fen_after": "1k3bnr/1pp3pp/p1p1Qp2/6B1/8/2Nr4/PPP2PPP/4RK1R w - - 0 15"
    },
    {
      "move_number": 29,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c2d3",
      "move_san": "cxd3",
      "fen_after": "1k3bnr/1pp3pp/p1p1Qp2/6B1/8/2NP4/PP3PPP/4RK1R b - - 0 15"
    }
  ],
  "final_fen": "1k3bnr/1pp3pp/p1p1Qp2/6B1/8/2NP4/PP3PPP/4RK1R b - - 0 15",
  "white_tokens": {
    "prompt_tokens": 48974,
    "completion_tokens": 127571,
    "total_tokens": 176545
  },
  "black_tokens": {
    "prompt_tokens": 47289,
    "completion_tokens": 31138,
    "total_tokens": 78427
  },
  "white_token_log": [
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 470,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 616,
          "total_tokens": 726,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1726,
        "total_tokens": 2055
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 470,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 616,
          "total_tokens": 726,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 603,
          "total_tokens": 719,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1883,
        "total_tokens": 2230
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 603,
          "total_tokens": 719,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 545,
          "total_tokens": 670,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 457,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 460,
          "total_tokens": 584,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1462,
        "total_tokens": 1836
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 545,
          "total_tokens": 670,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 457,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 460,
          "total_tokens": 584,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 251,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1531,
        "total_tokens": 1929
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 251,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 394,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 500,
          "total_tokens": 640,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 419,
        "total_completion_tokens": 1534,
        "total_tokens": 1953
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 394,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 500,
          "total_tokens": 640,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 254,
          "total_tokens": 401,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 321,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 1215,
        "total_tokens": 1655
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 254,
          "total_tokens": 401,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 321,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 388,
          "total_tokens": 541,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 1668,
        "total_tokens": 2129
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 388,
          "total_tokens": 541,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 1920,
        "total_tokens": 2402
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 170,
          "completion_tokens": 264,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 509,
        "total_completion_tokens": 1544,
        "total_tokens": 2053
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 170,
          "completion_tokens": 264,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 536,
        "total_completion_tokens": 1920,
        "total_tokens": 2456
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 640,
          "total_tokens": 825,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 557,
        "total_completion_tokens": 1920,
        "total_tokens": 2477
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 640,
          "total_tokens": 825,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 195,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 206,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 584,
        "total_completion_tokens": 1041,
        "total_tokens": 1625
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 195,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 206,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 236,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 287,
          "total_tokens": 489,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 1163,
        "total_tokens": 1771
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 236,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 287,
          "total_tokens": 489,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 522,
          "total_tokens": 733,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 1802,
        "total_tokens": 2437
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 522,
          "total_tokens": 733,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 640,
          "total_tokens": 859,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 1920,
        "total_tokens": 2579
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 640,
          "total_tokens": 860,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 640,
          "total_tokens": 859,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 28,
          "total_tokens": 257,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 36,
          "total_tokens": 265,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 304,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 686,
        "total_completion_tokens": 368,
        "total_tokens": 1054
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 28,
          "total_tokens": 257,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 36,
          "total_tokens": 265,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 304,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 640,
          "total_tokens": 878,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 236,
          "total_tokens": 474,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 640,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 713,
        "total_completion_tokens": 1516,
        "total_tokens": 2229
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 640,
          "total_tokens": 878,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 236,
          "total_tokens": 474,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 640,
          "total_tokens": 877,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 465,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 318,
          "total_tokens": 431,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1423,
        "total_tokens": 1764
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 465,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 318,
          "total_tokens": 431,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 377,
          "total_tokens": 487,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 334,
          "total_tokens": 444,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1351,
        "total_tokens": 1680
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 377,
          "total_tokens": 487,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 334,
          "total_tokens": 444,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1920,
        "total_tokens": 2267
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 455,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 266,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1361,
        "total_tokens": 1735
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 455,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 266,
          "total_tokens": 390,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 176,
          "total_tokens": 309,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1456,
        "total_tokens": 1854
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 176,
          "total_tokens": 309,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 138,
          "total_tokens": 280,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 425,
        "total_completion_tokens": 1418,
        "total_tokens": 1843
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 138,
          "total_tokens": 280,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 379,
          "total_tokens": 530,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 402,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 452,
        "total_completion_tokens": 1421,
        "total_tokens": 1873
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 379,
          "total_tokens": 530,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 402,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 363,
          "total_tokens": 524,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 625,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 592,
          "total_tokens": 752,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 1580,
        "total_tokens": 2062
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 363,
          "total_tokens": 524,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 625,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 592,
          "total_tokens": 752,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 422,
          "total_tokens": 592,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1702,
        "total_tokens": 2214
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 422,
          "total_tokens": 592,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 207,
          "total_tokens": 386,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 349,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 536,
        "total_completion_tokens": 1196,
        "total_tokens": 1732
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 207,
          "total_tokens": 386,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 349,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 189,
          "completion_tokens": 207,
          "total_tokens": 396,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 189,
          "completion_tokens": 226,
          "total_tokens": 415,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 188,
          "completion_tokens": 640,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 566,
        "total_completion_tokens": 1073,
        "total_tokens": 1639
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 189,
          "completion_tokens": 207,
          "total_tokens": 396,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 189,
          "completion_tokens": 226,
          "total_tokens": 415,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 188,
          "completion_tokens": 640,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 198,
          "completion_tokens": 317,
          "total_tokens": 515,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 198,
          "completion_tokens": 256,
          "total_tokens": 454,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 197,
          "completion_tokens": 196,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 593,
        "total_completion_tokens": 769,
        "total_tokens": 1362
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 198,
          "completion_tokens": 317,
          "total_tokens": 515,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 198,
          "completion_tokens": 256,
          "total_tokens": 454,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 197,
          "completion_tokens": 196,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 205,
          "completion_tokens": 640,
          "total_tokens": 845,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 205,
          "completion_tokens": 183,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 204,
          "completion_tokens": 640,
          "total_tokens": 844,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 614,
        "total_completion_tokens": 1463,
        "total_tokens": 2077
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 205,
          "completion_tokens": 640,
          "total_tokens": 845,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 205,
          "completion_tokens": 183,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 204,
          "completion_tokens": 640,
          "total_tokens": 844,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 213,
          "completion_tokens": 120,
          "total_tokens": 333,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 213,
          "completion_tokens": 344,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 212,
          "completion_tokens": 308,
          "total_tokens": 520,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 638,
        "total_completion_tokens": 772,
        "total_tokens": 1410
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 213,
          "completion_tokens": 120,
          "total_tokens": 333,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 213,
          "completion_tokens": 344,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 212,
          "completion_tokens": 308,
          "total_tokens": 520,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 194,
          "total_tokens": 416,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 89,
          "total_tokens": 311,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 665,
        "total_completion_tokens": 923,
        "total_tokens": 1588
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 194,
          "total_tokens": 416,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 89,
          "total_tokens": 311,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 89,
          "total_tokens": 320,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 107,
          "total_tokens": 338,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 107,
          "total_tokens": 337,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 692,
        "total_completion_tokens": 303,
        "total_tokens": 995
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 89,
          "total_tokens": 320,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 107,
          "total_tokens": 338,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 107,
          "total_tokens": 337,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 239,
          "completion_tokens": 640,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 239,
          "completion_tokens": 372,
          "total_tokens": 611,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 238,
          "completion_tokens": 7,
          "total_tokens": 245,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 716,
        "total_completion_tokens": 1019,
        "total_tokens": 1735
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 239,
          "completion_tokens": 640,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 239,
          "completion_tokens": 372,
          "total_tokens": 611,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 238,
          "completion_tokens": 7,
          "total_tokens": 245,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 248,
          "completion_tokens": 103,
          "total_tokens": 351,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 248,
          "completion_tokens": 11,
          "total_tokens": 259,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 247,
          "completion_tokens": 640,
          "total_tokens": 887,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 743,
        "total_completion_tokens": 754,
        "total_tokens": 1497
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 248,
          "completion_tokens": 103,
          "total_tokens": 351,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 248,
          "completion_tokens": 11,
          "total_tokens": 259,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 247,
          "completion_tokens": 640,
          "total_tokens": 887,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 214,
          "total_tokens": 328,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 355,
          "total_tokens": 469,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 283,
          "total_tokens": 396,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 852,
        "total_tokens": 1193
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 214,
          "total_tokens": 328,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 355,
          "total_tokens": 469,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 283,
          "total_tokens": 396,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 640,
          "total_tokens": 761,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 365,
        "total_completion_tokens": 1920,
        "total_tokens": 2285
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 640,
          "total_tokens": 761,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 392,
        "total_completion_tokens": 1920,
        "total_tokens": 2312
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 139,
          "completion_tokens": 529,
          "total_tokens": 668,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 416,
        "total_completion_tokens": 1809,
        "total_tokens": 2225
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 139,
          "completion_tokens": 529,
          "total_tokens": 668,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 640,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 1920,
        "total_tokens": 2360
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 640,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 553,
          "total_tokens": 706,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 1833,
        "total_tokens": 2294
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 553,
          "total_tokens": 706,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 162,
          "completion_tokens": 640,
          "total_tokens": 802,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 162,
          "completion_tokens": 384,
          "total_tokens": 546,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 485,
        "total_completion_tokens": 1664,
        "total_tokens": 2149
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 162,
          "completion_tokens": 640,
          "total_tokens": 802,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 162,
          "completion_tokens": 384,
          "total_tokens": 546,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 457,
          "total_tokens": 628,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1737,
        "total_tokens": 2249
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 457,
          "total_tokens": 628,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 418,
          "total_tokens": 598,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 576,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 539,
        "total_completion_tokens": 1634,
        "total_tokens": 2173
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 418,
          "total_tokens": 598,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 576,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 189,
          "completion_tokens": 640,
          "total_tokens": 829,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 189,
          "completion_tokens": 604,
          "total_tokens": 793,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 188,
          "completion_tokens": 640,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 566,
        "total_completion_tokens": 1884,
        "total_tokens": 2450
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 189,
          "completion_tokens": 640,
          "total_tokens": 829,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 189,
          "completion_tokens": 604,
          "total_tokens": 793,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 188,
          "completion_tokens": 640,
          "total_tokens": 828,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 489,
          "total_tokens": 686,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 396,
          "total_tokens": 593,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 323,
          "total_tokens": 519,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 590,
        "total_completion_tokens": 1208,
        "total_tokens": 1798
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 489,
          "total_tokens": 686,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 396,
          "total_tokens": 593,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 323,
          "total_tokens": 519,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 207,
          "completion_tokens": 319,
          "total_tokens": 526,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 207,
          "completion_tokens": 180,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 206,
          "completion_tokens": 58,
          "total_tokens": 264,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 620,
        "total_completion_tokens": 557,
        "total_tokens": 1177
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 207,
          "completion_tokens": 319,
          "total_tokens": 526,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 207,
          "completion_tokens": 180,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 206,
          "completion_tokens": 58,
          "total_tokens": 264,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 215,
          "completion_tokens": 640,
          "total_tokens": 855,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 215,
          "completion_tokens": 281,
          "total_tokens": 496,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 214,
          "completion_tokens": 640,
          "total_tokens": 854,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 644,
        "total_completion_tokens": 1561,
        "total_tokens": 2205
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 215,
          "completion_tokens": 640,
          "total_tokens": 855,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 215,
          "completion_tokens": 281,
          "total_tokens": 496,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 214,
          "completion_tokens": 640,
          "total_tokens": 854,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 224,
          "completion_tokens": 210,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 224,
          "completion_tokens": 318,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 223,
          "completion_tokens": 119,
          "total_tokens": 342,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 671,
        "total_completion_tokens": 647,
        "total_tokens": 1318
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 224,
          "completion_tokens": 210,
          "total_tokens": 434,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 224,
          "completion_tokens": 318,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 223,
          "completion_tokens": 119,
          "total_tokens": 342,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 234,
          "completion_tokens": 229,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 234,
          "completion_tokens": 640,
          "total_tokens": 874,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 233,
          "completion_tokens": 356,
          "total_tokens": 589,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 701,
        "total_completion_tokens": 1225,
        "total_tokens": 1926
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 234,
          "completion_tokens": 229,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 234,
          "completion_tokens": 640,
          "total_tokens": 874,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 233,
          "completion_tokens": 356,
          "total_tokens": 589,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 242,
          "completion_tokens": 211,
          "total_tokens": 453,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 242,
          "completion_tokens": 270,
          "total_tokens": 512,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 241,
          "completion_tokens": 440,
          "total_tokens": 681,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 725,
        "total_completion_tokens": 921,
        "total_tokens": 1646
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 242,
          "completion_tokens": 211,
          "total_tokens": 453,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 242,
          "completion_tokens": 270,
          "total_tokens": 512,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 241,
          "completion_tokens": 440,
          "total_tokens": 681,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 34,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 250,
          "completion_tokens": 172,
          "total_tokens": 422,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 250,
          "completion_tokens": 402,
          "total_tokens": 652,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 249,
          "completion_tokens": 35,
          "total_tokens": 284,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 749,
        "total_completion_tokens": 609,
        "total_tokens": 1358
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 250,
          "completion_tokens": 172,
          "total_tokens": 422,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 250,
          "completion_tokens": 402,
          "total_tokens": 652,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 249,
          "completion_tokens": 35,
          "total_tokens": 284,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 405,
          "total_tokens": 514,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1685,
        "total_tokens": 2014
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 405,
          "total_tokens": 514,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 580,
          "total_tokens": 696,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1860,
        "total_tokens": 2207
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 580,
          "total_tokens": 696,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 359,
          "total_tokens": 484,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1639,
        "total_tokens": 2013
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 359,
          "total_tokens": 484,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1920,
        "total_tokens": 2318
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 435,
          "total_tokens": 575,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 419,
        "total_completion_tokens": 1715,
        "total_tokens": 2134
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 435,
          "total_tokens": 575,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 317,
          "total_tokens": 464,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 497,
          "total_tokens": 643,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 1454,
        "total_tokens": 1894
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 317,
          "total_tokens": 464,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 497,
          "total_tokens": 643,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 640,
          "total_tokens": 793,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 1920,
        "total_tokens": 2381
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 640,
          "total_tokens": 793,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 1920,
        "total_tokens": 2402
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 170,
          "completion_tokens": 210,
          "total_tokens": 380,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 509,
        "total_completion_tokens": 1490,
        "total_tokens": 1999
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 170,
          "completion_tokens": 210,
          "total_tokens": 380,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 169,
          "completion_tokens": 640,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 367,
          "total_tokens": 545,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 536,
        "total_completion_tokens": 1647,
        "total_tokens": 2183
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 367,
          "total_tokens": 545,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 640,
          "total_tokens": 827,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 640,
          "total_tokens": 827,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 339,
          "total_tokens": 525,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 560,
        "total_completion_tokens": 1619,
        "total_tokens": 2179
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 640,
          "total_tokens": 827,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 640,
          "total_tokens": 827,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 339,
          "total_tokens": 525,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 493,
          "total_tokens": 688,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 587,
        "total_completion_tokens": 1773,
        "total_tokens": 2360
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 493,
          "total_tokens": 688,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 204,
          "completion_tokens": 163,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 204,
          "completion_tokens": 180,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 203,
          "completion_tokens": 163,
          "total_tokens": 366,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 611,
        "total_completion_tokens": 506,
        "total_tokens": 1117
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 204,
          "completion_tokens": 163,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 204,
          "completion_tokens": 180,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 203,
          "completion_tokens": 163,
          "total_tokens": 366,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 213,
          "completion_tokens": 361,
          "total_tokens": 574,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 213,
          "completion_tokens": 250,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 638,
        "total_completion_tokens": 1251,
        "total_tokens": 1889
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 213,
          "completion_tokens": 361,
          "total_tokens": 574,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 213,
          "completion_tokens": 250,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 212,
          "completion_tokens": 640,
          "total_tokens": 852,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 223,
          "completion_tokens": 279,
          "total_tokens": 502,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 223,
          "completion_tokens": 331,
          "total_tokens": 554,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 222,
          "completion_tokens": 387,
          "total_tokens": 609,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 668,
        "total_completion_tokens": 997,
        "total_tokens": 1665
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 223,
          "completion_tokens": 279,
          "total_tokens": 502,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 223,
          "completion_tokens": 331,
          "total_tokens": 554,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 222,
          "completion_tokens": 387,
          "total_tokens": 609,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 232,
          "completion_tokens": 640,
          "total_tokens": 872,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 232,
          "completion_tokens": 640,
          "total_tokens": 872,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 695,
        "total_completion_tokens": 1920,
        "total_tokens": 2615
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 232,
          "completion_tokens": 640,
          "total_tokens": 872,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 232,
          "completion_tokens": 640,
          "total_tokens": 872,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 241,
          "completion_tokens": 119,
          "total_tokens": 360,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 241,
          "completion_tokens": 114,
          "total_tokens": 355,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 722,
        "total_completion_tokens": 873,
        "total_tokens": 1595
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 241,
          "completion_tokens": 119,
          "total_tokens": 360,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 241,
          "completion_tokens": 114,
          "total_tokens": 355,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 35,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 228,
          "total_tokens": 479,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 640,
          "total_tokens": 891,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 108,
          "total_tokens": 358,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 752,
        "total_completion_tokens": 976,
        "total_tokens": 1728
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 228,
          "total_tokens": 479,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 640,
          "total_tokens": 891,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 108,
          "total_tokens": 358,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 37,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 259,
          "completion_tokens": 195,
          "total_tokens": 454,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 259,
          "completion_tokens": 640,
          "total_tokens": 899,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 258,
          "completion_tokens": 640,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 776,
        "total_completion_tokens": 1475,
        "total_tokens": 2251
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 259,
          "completion_tokens": 195,
          "total_tokens": 454,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 259,
          "completion_tokens": 640,
          "total_tokens": 899,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 258,
          "completion_tokens": 640,
          "total_tokens": 898,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 39,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 268,
          "completion_tokens": 64,
          "total_tokens": 332,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 268,
          "completion_tokens": 273,
          "total_tokens": 541,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 267,
          "completion_tokens": 76,
          "total_tokens": 343,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 803,
        "total_completion_tokens": 413,
        "total_tokens": 1216
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 268,
          "completion_tokens": 64,
          "total_tokens": 332,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 268,
          "completion_tokens": 273,
          "total_tokens": 541,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 267,
          "completion_tokens": 76,
          "total_tokens": 343,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 41,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 277,
          "completion_tokens": 640,
          "total_tokens": 917,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 277,
          "completion_tokens": 41,
          "total_tokens": 318,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 276,
          "completion_tokens": 32,
          "total_tokens": 308,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 830,
        "total_completion_tokens": 713,
        "total_tokens": 1543
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 277,
          "completion_tokens": 640,
          "total_tokens": 917,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 277,
          "completion_tokens": 41,
          "total_tokens": 318,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 276,
          "completion_tokens": 32,
          "total_tokens": 308,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 43,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 285,
          "completion_tokens": 640,
          "total_tokens": 925,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 285,
          "completion_tokens": 640,
          "total_tokens": 925,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 284,
          "completion_tokens": 89,
          "total_tokens": 373,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 854,
        "total_completion_tokens": 1369,
        "total_tokens": 2223
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 285,
          "completion_tokens": 640,
          "total_tokens": 925,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 285,
          "completion_tokens": 640,
          "total_tokens": 925,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 284,
          "completion_tokens": 89,
          "total_tokens": 373,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 45,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 294,
          "completion_tokens": 640,
          "total_tokens": 934,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 294,
          "completion_tokens": 94,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 293,
          "completion_tokens": 640,
          "total_tokens": 933,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 881,
        "total_completion_tokens": 1374,
        "total_tokens": 2255
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 294,
          "completion_tokens": 640,
          "total_tokens": 934,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 294,
          "completion_tokens": 94,
          "total_tokens": 388,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 293,
          "completion_tokens": 640,
          "total_tokens": 933,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 234,
          "total_tokens": 348,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 640,
          "total_tokens": 753,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1514,
        "total_tokens": 1855
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 234,
          "total_tokens": 348,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 640,
          "total_tokens": 753,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 382,
          "total_tokens": 491,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1662,
        "total_tokens": 1991
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 382,
          "total_tokens": 491,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 469,
          "total_tokens": 585,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1749,
        "total_tokens": 2096
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 469,
          "total_tokens": 585,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 241,
          "total_tokens": 366,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1521,
        "total_tokens": 1895
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 241,
          "total_tokens": 366,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 350,
          "total_tokens": 482,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1630,
        "total_tokens": 2028
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 350,
          "total_tokens": 482,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 517,
          "total_tokens": 659,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 415,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 425,
        "total_completion_tokens": 1572,
        "total_tokens": 1997
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 517,
          "total_tokens": 659,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 415,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 405,
          "total_tokens": 556,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 402,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 322,
          "total_tokens": 472,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 452,
        "total_completion_tokens": 1129,
        "total_tokens": 1581
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 405,
          "total_tokens": 556,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 402,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 322,
          "total_tokens": 472,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 1920,
        "total_tokens": 2402
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 640,
          "total_tokens": 801,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 640,
          "total_tokens": 800,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 550,
          "total_tokens": 721,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 531,
          "total_tokens": 701,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1721,
        "total_tokens": 2233
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 550,
          "total_tokens": 721,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 531,
          "total_tokens": 701,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 533,
        "total_completion_tokens": 1920,
        "total_tokens": 2453
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 230,
          "total_tokens": 416,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 640,
          "total_tokens": 825,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 557,
        "total_completion_tokens": 1510,
        "total_tokens": 2067
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 640,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 230,
          "total_tokens": 416,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 640,
          "total_tokens": 825,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 465,
          "total_tokens": 660,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 111,
          "total_tokens": 306,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 496,
          "total_tokens": 690,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 584,
        "total_completion_tokens": 1072,
        "total_tokens": 1656
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 465,
          "total_tokens": 660,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 111,
          "total_tokens": 306,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 496,
          "total_tokens": 690,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 96,
          "total_tokens": 299,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 106,
          "total_tokens": 309,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 175,
          "total_tokens": 377,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 377,
        "total_tokens": 985
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 96,
          "total_tokens": 299,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 106,
          "total_tokens": 309,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 175,
          "total_tokens": 377,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 211,
          "completion_tokens": 613,
          "total_tokens": 824,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 211,
          "completion_tokens": 310,
          "total_tokens": 521,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 210,
          "completion_tokens": 335,
          "total_tokens": 545,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 632,
        "total_completion_tokens": 1258,
        "total_tokens": 1890
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 211,
          "completion_tokens": 613,
          "total_tokens": 824,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 211,
          "completion_tokens": 310,
          "total_tokens": 521,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 210,
          "completion_tokens": 335,
          "total_tokens": 545,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 221,
          "completion_tokens": 227,
          "total_tokens": 448,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 220,
          "completion_tokens": 279,
          "total_tokens": 499,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 662,
        "total_completion_tokens": 1146,
        "total_tokens": 1808
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 221,
          "completion_tokens": 227,
          "total_tokens": 448,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 220,
          "completion_tokens": 279,
          "total_tokens": 499,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 230,
          "completion_tokens": 171,
          "total_tokens": 401,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 230,
          "completion_tokens": 612,
          "total_tokens": 842,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 229,
          "completion_tokens": 640,
          "total_tokens": 869,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 689,
        "total_completion_tokens": 1423,
        "total_tokens": 2112
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 230,
          "completion_tokens": 171,
          "total_tokens": 401,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 230,
          "completion_tokens": 612,
          "total_tokens": 842,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 229,
          "completion_tokens": 640,
          "total_tokens": 869,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    }
  ],
  "black_token_log": [
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 14,
          "total_tokens": 130,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 10,
          "total_tokens": 126,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 32,
        "total_tokens": 379
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 14,
          "total_tokens": 130,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 10,
          "total_tokens": 126,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 33,
          "total_tokens": 157,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 32,
          "total_tokens": 156,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 371,
        "total_completion_tokens": 705,
        "total_tokens": 1076
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 33,
          "total_tokens": 157,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 32,
          "total_tokens": 156,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 640,
          "total_tokens": 763,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 30,
          "total_tokens": 163,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 34,
          "total_tokens": 167,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 47,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 111,
        "total_tokens": 509
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 30,
          "total_tokens": 163,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 34,
          "total_tokens": 167,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 47,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 38,
          "total_tokens": 178,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 43,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 419,
        "total_completion_tokens": 721,
        "total_tokens": 1140
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 38,
          "total_tokens": 178,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 43,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 45,
          "total_tokens": 192,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 50,
          "total_tokens": 197,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 44,
          "total_tokens": 190,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 139,
        "total_tokens": 579
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 45,
          "total_tokens": 192,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 50,
          "total_tokens": 197,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 44,
          "total_tokens": 190,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 58,
          "total_tokens": 211,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 174,
        "total_tokens": 635
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 58,
          "total_tokens": 211,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 76,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 74,
          "total_tokens": 235,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 66,
          "total_tokens": 226,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 216,
        "total_tokens": 698
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 76,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 74,
          "total_tokens": 235,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 66,
          "total_tokens": 226,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 84,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 75,
          "total_tokens": 242,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 503,
        "total_completion_tokens": 234,
        "total_tokens": 737
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 84,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 75,
          "total_tokens": 242,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 83,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 86,
          "total_tokens": 263,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 86,
          "total_tokens": 262,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 530,
        "total_completion_tokens": 255,
        "total_tokens": 785
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 83,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 86,
          "total_tokens": 263,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 86,
          "total_tokens": 262,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 91,
          "total_tokens": 277,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 95,
          "total_tokens": 280,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 557,
        "total_completion_tokens": 272,
        "total_tokens": 829
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 91,
          "total_tokens": 277,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 95,
          "total_tokens": 280,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 194,
          "completion_tokens": 101,
          "total_tokens": 295,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 194,
          "completion_tokens": 112,
          "total_tokens": 306,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 193,
          "completion_tokens": 115,
          "total_tokens": 308,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 581,
        "total_completion_tokens": 328,
        "total_tokens": 909
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 194,
          "completion_tokens": 101,
          "total_tokens": 295,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 194,
          "completion_tokens": 112,
          "total_tokens": 306,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 193,
          "completion_tokens": 115,
          "total_tokens": 308,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 110,
          "total_tokens": 313,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 111,
          "total_tokens": 314,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 125,
          "total_tokens": 327,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 346,
        "total_tokens": 954
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 110,
          "total_tokens": 313,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 111,
          "total_tokens": 314,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 125,
          "total_tokens": 327,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 122,
          "total_tokens": 334,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 132,
          "total_tokens": 344,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 126,
          "total_tokens": 337,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 380,
        "total_tokens": 1015
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 122,
          "total_tokens": 334,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 132,
          "total_tokens": 344,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 126,
          "total_tokens": 337,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 125,
          "total_tokens": 345,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 135,
          "total_tokens": 355,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 141,
          "total_tokens": 360,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 401,
        "total_tokens": 1060
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 125,
          "total_tokens": 345,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 135,
          "total_tokens": 355,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 141,
          "total_tokens": 360,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 128,
          "total_tokens": 357,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 145,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 686,
        "total_completion_tokens": 419,
        "total_tokens": 1105
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 128,
          "total_tokens": 357,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 145,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 154,
          "total_tokens": 392,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 145,
          "total_tokens": 383,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 151,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 713,
        "total_completion_tokens": 450,
        "total_tokens": 1163
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 154,
          "total_tokens": 392,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 145,
          "total_tokens": 383,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 151,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 335,
        "total_completion_tokens": 1920,
        "total_tokens": 2255
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 13,
          "total_tokens": 129,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 23,
          "total_tokens": 139,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 676,
        "total_tokens": 1023
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 13,
          "total_tokens": 129,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 23,
          "total_tokens": 139,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 22,
          "total_tokens": 145,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 371,
        "total_completion_tokens": 82,
        "total_tokens": 453
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 22,
          "total_tokens": 145,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 26,
          "total_tokens": 159,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 49,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 43,
          "total_tokens": 175,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 118,
        "total_tokens": 516
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 26,
          "total_tokens": 159,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 49,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 43,
          "total_tokens": 175,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 46,
          "total_tokens": 187,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 48,
          "total_tokens": 189,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 45,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 139,
        "total_tokens": 561
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 46,
          "total_tokens": 187,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 48,
          "total_tokens": 189,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 45,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 57,
          "total_tokens": 207,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 58,
          "total_tokens": 208,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 57,
          "total_tokens": 206,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 449,
        "total_completion_tokens": 172,
        "total_tokens": 621
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 57,
          "total_tokens": 207,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 58,
          "total_tokens": 208,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 57,
          "total_tokens": 206,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 159,
          "completion_tokens": 65,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 159,
          "completion_tokens": 65,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 158,
          "completion_tokens": 79,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 476,
        "total_completion_tokens": 209,
        "total_tokens": 685
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 159,
          "completion_tokens": 65,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 159,
          "completion_tokens": 65,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 158,
          "completion_tokens": 79,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 169,
          "completion_tokens": 80,
          "total_tokens": 249,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 169,
          "completion_tokens": 83,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 168,
          "completion_tokens": 68,
          "total_tokens": 236,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 506,
        "total_completion_tokens": 231,
        "total_tokens": 737
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 169,
          "completion_tokens": 80,
          "total_tokens": 249,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 169,
          "completion_tokens": 83,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 168,
          "completion_tokens": 68,
          "total_tokens": 236,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 80,
          "total_tokens": 258,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 93,
          "total_tokens": 271,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 75,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 533,
        "total_completion_tokens": 248,
        "total_tokens": 781
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 80,
          "total_tokens": 258,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 93,
          "total_tokens": 271,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 75,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 92,
          "total_tokens": 279,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 105,
          "total_tokens": 292,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 560,
        "total_completion_tokens": 283,
        "total_tokens": 843
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 92,
          "total_tokens": 279,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 105,
          "total_tokens": 292,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 86,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 104,
          "total_tokens": 301,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 104,
          "total_tokens": 301,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 111,
          "total_tokens": 307,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 590,
        "total_completion_tokens": 319,
        "total_tokens": 909
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 104,
          "total_tokens": 301,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 104,
          "total_tokens": 301,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 111,
          "total_tokens": 307,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 204,
          "completion_tokens": 103,
          "total_tokens": 307,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 204,
          "completion_tokens": 116,
          "total_tokens": 320,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 203,
          "completion_tokens": 101,
          "total_tokens": 304,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 611,
        "total_completion_tokens": 320,
        "total_tokens": 931
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 204,
          "completion_tokens": 103,
          "total_tokens": 307,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 204,
          "completion_tokens": 116,
          "total_tokens": 320,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 203,
          "completion_tokens": 101,
          "total_tokens": 304,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 120,
          "total_tokens": 332,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 117,
          "total_tokens": 329,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 130,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 367,
        "total_tokens": 1002
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 120,
          "total_tokens": 332,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 117,
          "total_tokens": 329,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 130,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 121,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 149,
          "total_tokens": 369,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 123,
          "total_tokens": 342,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 393,
        "total_tokens": 1052
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 121,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 149,
          "total_tokens": 369,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 123,
          "total_tokens": 342,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 134,
          "total_tokens": 363,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 144,
          "total_tokens": 373,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 686,
        "total_completion_tokens": 424,
        "total_tokens": 1110
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 134,
          "total_tokens": 363,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 144,
          "total_tokens": 373,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 143,
          "total_tokens": 381,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 150,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 143,
          "total_tokens": 380,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 713,
        "total_completion_tokens": 436,
        "total_tokens": 1149
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 238,
          "completion_tokens": 143,
          "total_tokens": 381,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 238,
          "completion_tokens": 150,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 237,
          "completion_tokens": 143,
          "total_tokens": 380,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 246,
          "completion_tokens": 151,
          "total_tokens": 397,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 246,
          "completion_tokens": 151,
          "total_tokens": 397,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 245,
          "completion_tokens": 142,
          "total_tokens": 387,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 737,
        "total_completion_tokens": 444,
        "total_tokens": 1181
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 246,
          "completion_tokens": 151,
          "total_tokens": 397,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 246,
          "completion_tokens": 151,
          "total_tokens": 397,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 245,
          "completion_tokens": 142,
          "total_tokens": 387,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 617,
          "total_tokens": 729,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 335,
        "total_completion_tokens": 1897,
        "total_tokens": 2232
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 617,
          "total_tokens": 729,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 118,
          "completion_tokens": 27,
          "total_tokens": 145,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 118,
          "completion_tokens": 18,
          "total_tokens": 136,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 117,
          "completion_tokens": 18,
          "total_tokens": 135,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 353,
        "total_completion_tokens": 63,
        "total_tokens": 416
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 118,
          "completion_tokens": 27,
          "total_tokens": 145,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 118,
          "completion_tokens": 18,
          "total_tokens": 136,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 117,
          "completion_tokens": 18,
          "total_tokens": 135,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 127,
          "completion_tokens": 25,
          "total_tokens": 152,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 127,
          "completion_tokens": 23,
          "total_tokens": 150,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 126,
          "completion_tokens": 28,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 380,
        "total_completion_tokens": 76,
        "total_tokens": 456
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 127,
          "completion_tokens": 25,
          "total_tokens": 152,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 127,
          "completion_tokens": 23,
          "total_tokens": 150,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 126,
          "completion_tokens": 28,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 136,
          "completion_tokens": 34,
          "total_tokens": 170,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 136,
          "completion_tokens": 34,
          "total_tokens": 170,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 135,
          "completion_tokens": 34,
          "total_tokens": 169,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 407,
        "total_completion_tokens": 102,
        "total_tokens": 509
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 136,
          "completion_tokens": 34,
          "total_tokens": 170,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 136,
          "completion_tokens": 34,
          "total_tokens": 170,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 135,
          "completion_tokens": 34,
          "total_tokens": 169,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 144,
          "completion_tokens": 42,
          "total_tokens": 186,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 144,
          "completion_tokens": 42,
          "total_tokens": 186,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 143,
          "completion_tokens": 42,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 431,
        "total_completion_tokens": 126,
        "total_tokens": 557
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 144,
          "completion_tokens": 42,
          "total_tokens": 186,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 144,
          "completion_tokens": 42,
          "total_tokens": 186,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 143,
          "completion_tokens": 42,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 48,
          "total_tokens": 199,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 49,
          "total_tokens": 200,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 48,
          "total_tokens": 198,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 452,
        "total_completion_tokens": 145,
        "total_tokens": 597
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 48,
          "total_tokens": 199,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 49,
          "total_tokens": 200,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 48,
          "total_tokens": 198,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 158,
          "completion_tokens": 55,
          "total_tokens": 213,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 158,
          "completion_tokens": 86,
          "total_tokens": 244,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 157,
          "completion_tokens": 102,
          "total_tokens": 259,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 473,
        "total_completion_tokens": 243,
        "total_tokens": 716
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 158,
          "completion_tokens": 55,
          "total_tokens": 213,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 158,
          "completion_tokens": 86,
          "total_tokens": 244,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 157,
          "completion_tokens": 102,
          "total_tokens": 259,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 167,
          "completion_tokens": 63,
          "total_tokens": 230,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 167,
          "completion_tokens": 70,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 166,
          "completion_tokens": 70,
          "total_tokens": 236,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 500,
        "total_completion_tokens": 203,
        "total_tokens": 703
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 167,
          "completion_tokens": 63,
          "total_tokens": 230,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 167,
          "completion_tokens": 70,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 166,
          "completion_tokens": 70,
          "total_tokens": 236,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 176,
          "completion_tokens": 70,
          "total_tokens": 246,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 176,
          "completion_tokens": 71,
          "total_tokens": 247,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 175,
          "completion_tokens": 71,
          "total_tokens": 246,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 527,
        "total_completion_tokens": 212,
        "total_tokens": 739
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 176,
          "completion_tokens": 70,
          "total_tokens": 246,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 176,
          "completion_tokens": 71,
          "total_tokens": 247,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 175,
          "completion_tokens": 71,
          "total_tokens": 246,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 87,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 83,
          "total_tokens": 268,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 82,
          "total_tokens": 266,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 554,
        "total_completion_tokens": 252,
        "total_tokens": 806
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 87,
          "total_tokens": 272,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 83,
          "total_tokens": 268,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 82,
          "total_tokens": 266,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 193,
          "completion_tokens": 91,
          "total_tokens": 284,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 193,
          "completion_tokens": 91,
          "total_tokens": 284,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 192,
          "completion_tokens": 91,
          "total_tokens": 283,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 578,
        "total_completion_tokens": 273,
        "total_tokens": 851
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 193,
          "completion_tokens": 91,
          "total_tokens": 284,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 193,
          "completion_tokens": 91,
          "total_tokens": 284,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 192,
          "completion_tokens": 91,
          "total_tokens": 283,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 202,
          "completion_tokens": 97,
          "total_tokens": 299,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 202,
          "completion_tokens": 100,
          "total_tokens": 302,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 201,
          "completion_tokens": 98,
          "total_tokens": 299,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 605,
        "total_completion_tokens": 295,
        "total_tokens": 900
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 202,
          "completion_tokens": 97,
          "total_tokens": 299,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 202,
          "completion_tokens": 100,
          "total_tokens": 302,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 201,
          "completion_tokens": 98,
          "total_tokens": 299,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 109,
          "total_tokens": 321,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 128,
          "total_tokens": 340,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 110,
          "total_tokens": 321,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 347,
        "total_tokens": 982
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 109,
          "total_tokens": 321,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 128,
          "total_tokens": 340,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 110,
          "total_tokens": 321,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 221,
          "completion_tokens": 117,
          "total_tokens": 338,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 221,
          "completion_tokens": 116,
          "total_tokens": 337,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 220,
          "completion_tokens": 116,
          "total_tokens": 336,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 662,
        "total_completion_tokens": 349,
        "total_tokens": 1011
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 221,
          "completion_tokens": 117,
          "total_tokens": 338,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 221,
          "completion_tokens": 116,
          "total_tokens": 337,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 220,
          "completion_tokens": 116,
          "total_tokens": 336,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 128,
          "total_tokens": 359,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 128,
          "total_tokens": 359,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 133,
          "total_tokens": 363,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 692,
        "total_completion_tokens": 389,
        "total_tokens": 1081
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 128,
          "total_tokens": 359,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 128,
          "total_tokens": 359,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 133,
          "total_tokens": 363,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 239,
          "completion_tokens": 134,
          "total_tokens": 373,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 239,
          "completion_tokens": 136,
          "total_tokens": 375,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 238,
          "completion_tokens": 133,
          "total_tokens": 371,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 716,
        "total_completion_tokens": 403,
        "total_tokens": 1119
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 239,
          "completion_tokens": 134,
          "total_tokens": 373,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 239,
          "completion_tokens": 136,
          "total_tokens": 375,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 238,
          "completion_tokens": 133,
          "total_tokens": 371,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 246,
          "completion_tokens": 143,
          "total_tokens": 389,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 246,
          "completion_tokens": 157,
          "total_tokens": 403,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 245,
          "completion_tokens": 143,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 737,
        "total_completion_tokens": 443,
        "total_tokens": 1180
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 246,
          "completion_tokens": 143,
          "total_tokens": 389,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 246,
          "completion_tokens": 157,
          "total_tokens": 403,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 245,
          "completion_tokens": 143,
          "total_tokens": 388,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 24,
          "total_tokens": 140,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 672,
        "total_tokens": 1019
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 24,
          "total_tokens": 140,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 33,
          "total_tokens": 157,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 32,
          "total_tokens": 156,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 32,
          "total_tokens": 155,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 371,
        "total_completion_tokens": 97,
        "total_tokens": 468
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 33,
          "total_tokens": 157,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 32,
          "total_tokens": 156,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 32,
          "total_tokens": 155,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 29,
          "total_tokens": 162,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 50,
          "total_tokens": 183,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 47,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 126,
        "total_tokens": 524
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 29,
          "total_tokens": 162,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 50,
          "total_tokens": 183,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 47,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 38,
          "total_tokens": 178,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 45,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 36,
          "total_tokens": 175,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 419,
        "total_completion_tokens": 119,
        "total_tokens": 538
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 140,
          "completion_tokens": 38,
          "total_tokens": 178,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 140,
          "completion_tokens": 45,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 139,
          "completion_tokens": 36,
          "total_tokens": 175,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 45,
          "total_tokens": 192,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 50,
          "total_tokens": 197,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 45,
          "total_tokens": 191,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 140,
        "total_tokens": 580
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 45,
          "total_tokens": 192,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 50,
          "total_tokens": 197,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 45,
          "total_tokens": 191,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 68,
          "total_tokens": 222,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 52,
          "total_tokens": 205,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 178,
        "total_tokens": 639
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 58,
          "total_tokens": 212,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 68,
          "total_tokens": 222,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 52,
          "total_tokens": 205,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 77,
          "total_tokens": 238,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 76,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 60,
          "total_tokens": 220,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 482,
        "total_completion_tokens": 213,
        "total_tokens": 695
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 161,
          "completion_tokens": 77,
          "total_tokens": 238,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 161,
          "completion_tokens": 76,
          "total_tokens": 237,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 160,
          "completion_tokens": 60,
          "total_tokens": 220,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 75,
          "total_tokens": 242,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 503,
        "total_completion_tokens": 225,
        "total_tokens": 728
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 75,
          "total_tokens": 243,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 75,
          "total_tokens": 242,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 83,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 92,
          "total_tokens": 269,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 84,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 530,
        "total_completion_tokens": 259,
        "total_tokens": 789
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 83,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 92,
          "total_tokens": 269,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 84,
          "total_tokens": 260,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 85,
          "total_tokens": 271,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 91,
          "total_tokens": 277,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 84,
          "total_tokens": 269,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 557,
        "total_completion_tokens": 260,
        "total_tokens": 817
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 85,
          "total_tokens": 271,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 91,
          "total_tokens": 277,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 84,
          "total_tokens": 269,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 101,
          "total_tokens": 296,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 110,
          "total_tokens": 305,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 101,
          "total_tokens": 295,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 584,
        "total_completion_tokens": 312,
        "total_tokens": 896
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 101,
          "total_tokens": 296,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 110,
          "total_tokens": 305,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 101,
          "total_tokens": 295,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 109,
          "total_tokens": 312,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 118,
          "total_tokens": 321,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 122,
          "total_tokens": 324,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 349,
        "total_tokens": 957
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 109,
          "total_tokens": 312,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 118,
          "total_tokens": 321,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 122,
          "total_tokens": 324,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 118,
          "total_tokens": 330,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 129,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 111,
          "total_tokens": 322,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 358,
        "total_tokens": 993
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 118,
          "total_tokens": 330,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 129,
          "total_tokens": 341,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 111,
          "total_tokens": 322,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 221,
          "completion_tokens": 128,
          "total_tokens": 349,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 221,
          "completion_tokens": 138,
          "total_tokens": 359,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 220,
          "completion_tokens": 138,
          "total_tokens": 358,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 662,
        "total_completion_tokens": 404,
        "total_tokens": 1066
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 221,
          "completion_tokens": 128,
          "total_tokens": 349,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 221,
          "completion_tokens": 138,
          "total_tokens": 359,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 220,
          "completion_tokens": 138,
          "total_tokens": 358,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 147,
          "total_tokens": 378,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 147,
          "total_tokens": 378,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 137,
          "total_tokens": 367,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 692,
        "total_completion_tokens": 431,
        "total_tokens": 1123
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 147,
          "total_tokens": 378,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 147,
          "total_tokens": 378,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 137,
          "total_tokens": 367,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 240,
          "completion_tokens": 146,
          "total_tokens": 386,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 240,
          "completion_tokens": 158,
          "total_tokens": 398,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 239,
          "completion_tokens": 146,
          "total_tokens": 385,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 719,
        "total_completion_tokens": 450,
        "total_tokens": 1169
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 240,
          "completion_tokens": 146,
          "total_tokens": 386,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 240,
          "completion_tokens": 158,
          "total_tokens": 398,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 239,
          "completion_tokens": 146,
          "total_tokens": 385,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 34,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 249,
          "completion_tokens": 155,
          "total_tokens": 404,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 249,
          "completion_tokens": 168,
          "total_tokens": 417,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 248,
          "completion_tokens": 155,
          "total_tokens": 403,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 746,
        "total_completion_tokens": 478,
        "total_tokens": 1224
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 249,
          "completion_tokens": 155,
          "total_tokens": 404,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 249,
          "completion_tokens": 168,
          "total_tokens": 417,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 248,
          "completion_tokens": 155,
          "total_tokens": 403,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 36,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 258,
          "completion_tokens": 175,
          "total_tokens": 433,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 258,
          "completion_tokens": 171,
          "total_tokens": 429,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 257,
          "completion_tokens": 172,
          "total_tokens": 429,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 773,
        "total_completion_tokens": 518,
        "total_tokens": 1291
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 258,
          "completion_tokens": 175,
          "total_tokens": 433,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 258,
          "completion_tokens": 171,
          "total_tokens": 429,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 257,
          "completion_tokens": 172,
          "total_tokens": 429,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 38,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 267,
          "completion_tokens": 184,
          "total_tokens": 451,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 267,
          "completion_tokens": 184,
          "total_tokens": 451,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 266,
          "completion_tokens": 185,
          "total_tokens": 451,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 800,
        "total_completion_tokens": 553,
        "total_tokens": 1353
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 267,
          "completion_tokens": 184,
          "total_tokens": 451,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 267,
          "completion_tokens": 184,
          "total_tokens": 451,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 266,
          "completion_tokens": 185,
          "total_tokens": 451,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 40,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 275,
          "completion_tokens": 176,
          "total_tokens": 451,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 275,
          "completion_tokens": 192,
          "total_tokens": 467,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 274,
          "completion_tokens": 180,
          "total_tokens": 454,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 824,
        "total_completion_tokens": 548,
        "total_tokens": 1372
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 275,
          "completion_tokens": 176,
          "total_tokens": 451,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 275,
          "completion_tokens": 192,
          "total_tokens": 467,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 274,
          "completion_tokens": 180,
          "total_tokens": 454,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 42,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 284,
          "completion_tokens": 193,
          "total_tokens": 477,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 284,
          "completion_tokens": 202,
          "total_tokens": 486,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 283,
          "completion_tokens": 191,
          "total_tokens": 474,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 851,
        "total_completion_tokens": 586,
        "total_tokens": 1437
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 284,
          "completion_tokens": 193,
          "total_tokens": 477,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 284,
          "completion_tokens": 202,
          "total_tokens": 486,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 283,
          "completion_tokens": 191,
          "total_tokens": 474,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 44,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 293,
          "completion_tokens": 198,
          "total_tokens": 491,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 293,
          "completion_tokens": 198,
          "total_tokens": 491,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 292,
          "completion_tokens": 198,
          "total_tokens": 490,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 878,
        "total_completion_tokens": 594,
        "total_tokens": 1472
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 293,
          "completion_tokens": 198,
          "total_tokens": 491,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 293,
          "completion_tokens": 198,
          "total_tokens": 491,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 292,
          "completion_tokens": 198,
          "total_tokens": 490,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 366,
          "total_tokens": 478,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 335,
        "total_completion_tokens": 1646,
        "total_tokens": 1981
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 112,
          "completion_tokens": 640,
          "total_tokens": 752,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 112,
          "completion_tokens": 366,
          "total_tokens": 478,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 111,
          "completion_tokens": 640,
          "total_tokens": 751,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 11,
          "total_tokens": 127,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 659,
        "total_tokens": 1006
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 11,
          "total_tokens": 127,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 8,
          "total_tokens": 123,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 20,
          "total_tokens": 144,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 30,
          "total_tokens": 153,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 371,
        "total_completion_tokens": 80,
        "total_tokens": 451
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 20,
          "total_tokens": 144,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 30,
          "total_tokens": 154,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 30,
          "total_tokens": 153,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 46,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 53,
          "total_tokens": 186,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 49,
          "total_tokens": 181,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 148,
        "total_tokens": 546
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 46,
          "total_tokens": 179,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 53,
          "total_tokens": 186,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 49,
          "total_tokens": 181,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 46,
          "total_tokens": 187,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 41,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 45,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 132,
        "total_tokens": 554
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 46,
          "total_tokens": 187,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 41,
          "total_tokens": 182,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 45,
          "total_tokens": 185,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 57,
          "total_tokens": 207,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 57,
          "total_tokens": 207,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 57,
          "total_tokens": 206,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 449,
        "total_completion_tokens": 171,
        "total_tokens": 620
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 57,
          "total_tokens": 207,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 57,
          "total_tokens": 207,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 57,
          "total_tokens": 206,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 159,
          "completion_tokens": 69,
          "total_tokens": 228,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 159,
          "completion_tokens": 68,
          "total_tokens": 227,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 158,
          "completion_tokens": 65,
          "total_tokens": 223,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 476,
        "total_completion_tokens": 202,
        "total_tokens": 678
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 159,
          "completion_tokens": 69,
          "total_tokens": 228,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 159,
          "completion_tokens": 68,
          "total_tokens": 227,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 158,
          "completion_tokens": 65,
          "total_tokens": 223,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 169,
          "completion_tokens": 81,
          "total_tokens": 250,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 169,
          "completion_tokens": 75,
          "total_tokens": 244,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 168,
          "completion_tokens": 73,
          "total_tokens": 241,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 506,
        "total_completion_tokens": 229,
        "total_tokens": 735
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 169,
          "completion_tokens": 81,
          "total_tokens": 250,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 169,
          "completion_tokens": 75,
          "total_tokens": 244,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 168,
          "completion_tokens": 73,
          "total_tokens": 241,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 87,
          "total_tokens": 264,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 91,
          "total_tokens": 268,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 76,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 530,
        "total_completion_tokens": 254,
        "total_tokens": 784
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 177,
          "completion_tokens": 87,
          "total_tokens": 264,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 177,
          "completion_tokens": 91,
          "total_tokens": 268,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 176,
          "completion_tokens": 76,
          "total_tokens": 252,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 88,
          "total_tokens": 274,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 83,
          "total_tokens": 269,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 39,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 557,
        "total_completion_tokens": 210,
        "total_tokens": 767
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 186,
          "completion_tokens": 88,
          "total_tokens": 274,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 186,
          "completion_tokens": 83,
          "total_tokens": 269,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 185,
          "completion_tokens": 39,
          "total_tokens": 224,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 194,
          "completion_tokens": 99,
          "total_tokens": 293,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 194,
          "completion_tokens": 100,
          "total_tokens": 294,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 193,
          "completion_tokens": 100,
          "total_tokens": 293,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 581,
        "total_completion_tokens": 299,
        "total_tokens": 880
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 194,
          "completion_tokens": 99,
          "total_tokens": 293,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 194,
          "completion_tokens": 100,
          "total_tokens": 294,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 193,
          "completion_tokens": 100,
          "total_tokens": 293,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 102,
          "total_tokens": 305,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 119,
          "total_tokens": 322,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 108,
          "total_tokens": 310,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 329,
        "total_tokens": 937
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 102,
          "total_tokens": 305,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 119,
          "total_tokens": 322,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 108,
          "total_tokens": 310,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 210,
          "completion_tokens": 114,
          "total_tokens": 324,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 210,
          "completion_tokens": 110,
          "total_tokens": 320,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 209,
          "completion_tokens": 110,
          "total_tokens": 319,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 629,
        "total_completion_tokens": 334,
        "total_tokens": 963
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 210,
          "completion_tokens": 114,
          "total_tokens": 324,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 210,
          "completion_tokens": 110,
          "total_tokens": 320,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 209,
          "completion_tokens": 110,
          "total_tokens": 319,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 127,
          "total_tokens": 347,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 126,
          "total_tokens": 346,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 119,
          "total_tokens": 338,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 372,
        "total_tokens": 1031
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 127,
          "total_tokens": 347,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 126,
          "total_tokens": 346,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 119,
          "total_tokens": 338,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 3,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 127,
          "total_tokens": 356,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 148,
          "total_tokens": 377,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 686,
        "total_completion_tokens": 421,
        "total_tokens": 1107
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 229,
          "completion_tokens": 127,
          "total_tokens": 356,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 229,
          "completion_tokens": 148,
          "total_tokens": 377,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 228,
          "completion_tokens": 146,
          "total_tokens": 374,
          "model": "deepseek-ai/deepseek-v3",
          "finish_reason": "stop"
        }
      }
    }
  ],
  "white_responses": [
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 Nf6\nd4 Nf6 Nc3 d5 Bg5 Nbd7 e3 e6 Bd3 Be7 Nf3 O-O O-O c5 dxc5 Nxc5 Ne5 Nxd3 cxd3 Nd7 Bxe7 Qxe7 Nxd7 Bxd7 d4 Rac8 Rc1 Rc7 Qd2 Rfc8 Rc2 Qb4 Rfc1 Ba4 b3 Bb5 Nxb5 Qxd2 Rxc7 Qxc1+ Rxc1 Rxc1#\nd4 Nf6 Nc3 d5 Bg5 Nbd7 e3 e6 Bd3 Be7 Nf3 O-O O-O c5 dxc5 Nxc5 Ne5 Nxd3 cxd3 Nd7 Bxe7 Qxe7 Nxd7 Bxd7 d4 Rac8 Rc1 Rc7 Qd2 Rfc8 Rfc1 Qb4 Rxc7 Qxd2 Rxc8+ Bxc8 Nxd2 Kf8 Kf1 Ke7 Ke2 Kd6 Kd3 b6 Kc3 a5 b4 Ba6 bxa5 bxa5 Nb3 a4 Nc5 Bb5 Kb4 Bc6 Nxa4 e5 Nc3 f6 a4 e5 a5 exd4 exd4 Kc7 Kc5 Kb7 Kxd4 Ka6 Kc5 Kxa5 Nxd5 Kb7 Kd6 Bb5+ Ke7 Kc5 Bf1 g3 Ke6 Kd4 Kf5 Ke3 Kg4 Kf2 Kh3 Kg1 Bc4 Nf5 g6 Ne3 Bd3 Nd5 f5 Nf6 h6 Ne5 Be4 Nxg6 h5 Ne5 Be4 Nf7 Bd5 Ng5 Bf3 Nxf3+ Kf2 Kxh2 Kxf3 Kh3 Kf2 Kg4 Kg2 h4 gxh4 Kxh4 Kf3 Kh3 Kf2 Kg4 Ke3 Kg3 Ke2 Kxf4 Kf2 Ke4 Ke2 f4 Kf2 f3 Kf1 Ke3 Ke1 f2+ Kf1 Kf3#",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 470,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rac8",
            "Rc1",
            "Rc7",
            "Qd2",
            "Rfc8",
            "Rfc1",
            "Qb4",
            "Rxc7",
            "Qxd2",
            "Rxc8+",
            "Bxc8",
            "Nxd2",
            "Kf8",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd6",
            "Kd3",
            "b6",
            "Kc3",
            "a5",
            "b4",
            "Ba6",
            "bxa5",
            "bxa5",
            "Nb3",
            "a4",
            "Nc5",
            "Bb5",
            "Kb4",
            "Bc6",
            "Nxa4",
            "e5",
            "Nc3",
            "f6",
            "a4",
            "e5",
            "a5",
            "exd4",
            "exd4",
            "Kc7",
            "Kc5",
            "Kb7",
            "Kxd4",
            "Ka6",
            "Kc5",
            "Kxa5",
            "Nxd5",
            "Kb7",
            "Kd6",
            "Bb5+",
            "Ke7",
            "Kc5",
            "Bf1",
            "g3",
            "Ke6",
            "Kd4",
            "Kf5",
            "Ke3",
            "Kg4",
            "Kf2",
            "Kh3",
            "Kg1",
            "Bc4",
            "Nf5",
            "g6",
            "Ne3",
            "Bd3",
            "Nd5",
            "f5",
            "Nf6",
            "h6",
            "Ne5",
            "Be4",
            "Nxg6",
            "h5",
            "Ne5",
            "Be4",
            "Nf7",
            "Bd5",
            "Ng5",
            "Bf3",
            "Nxf3+",
            "Kf2",
            "Kxh2",
            "Kxf3",
            "Kh3",
            "Kf2",
            "Kg4",
            "Kg2",
            "h4",
            "gxh4",
            "Kxh4",
            "Kf3",
            "Kh3",
            "Kf2",
            "Kg4",
            "Ke3",
            "Kg3",
            "Ke2",
            "Kxf4",
            "Kf2",
            "Ke4",
            "Ke2",
            "f4",
            "Kf2",
            "f3",
            "Kf1",
            "Ke3",
            "Ke1",
            "f2+",
            "Kf1",
            "Kf3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5\n4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4\n7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8\n10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5\n13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8\n16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6\n19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8\n22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8\n25. Qe7+ Kg8 26. Qg7# 1-0\n*1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5\n4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4\n7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8\n10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5\n13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8\n16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6\n19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8\n22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8\n25. Qe7+ Kg8 26. Qg7# 1-0 1-0 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Bg7 Qe6 Nf6+ Qxf6 Bxf6 Be6 Qxb7 Rc8 Rad1 Bd7 Rxd6 Nb8 Rfd1 Rxc2 Rxd7 Nxd7 Qxd7+ Kf8 Qe7+ Kg8 Qg7#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 616,
            "total_tokens": 726,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Be6",
            "Qxb7",
            "Rc8",
            "Rad1",
            "Bd7",
            "Rxd6",
            "Nb8",
            "Rfd1",
            "Rxc2",
            "Rxd7",
            "Nxd7",
            "Qxd7+",
            "Kf8",
            "Qe7+",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 d5 2. Nf3 Nf6 3. Bg5 Bf5 4. e3 e6 5. Bd3 Bxd3 6. Qxd3 Be7 7. O-O O-O 8. Nbd2 Nbd7 9. c4 c6 10. Rac1 Re8 11. Rfe1 Nf8 12. Ne5 N6d7 13. Bxe7 Qxe7 14. Nxd7 Nxd7 15. cxd5 exd5 16. e4 dxe4 17. Rxe4 Qd6 18. Rce1 Rxe4 19. Nxe4 Qd5 20. Nc3 Qd6 21. Qe4 Nf6 22. Qe5 Qxe5 23. dxe5 Nd7 24. f4 Re8 25. Kf2 Kf8 26. Kf3 f6 27. e6 Nc5 28. f5 g6 29. g4 Ke7 30. Rd1 Rd8 31. Rxd8 Kxd8 32. Ne4 Nxe4 33. Kxe4 Ke7 34. Kd4 b6 35. b4 a6 36. a4 Kd6 37. a5 bxa5 38. bxa5 g5 39. Kc4 c5 40. e7 Kxe7 41. Kxc5 Kd7 42. Kb6 Kd6 43. Kxa6 Kc6 44. Ka7 Kc7 45. a6 Kc8 46. Kb6 Kb8 47. Kc6 Ka7 48. Kd6 Kxa6 49. Ke6 Kb6 50. Kxf6 Kc6 51. Kxg5 Kd6 52. Kh6 Ke7 53. Kxh7 Kf6 54. h4 Kf7 55. g5 Kf8 56. g6 Ke7 57. g7 Kf6 58. g8=Q Kxf5 59. Qg5+ Ke6 60. Kg6 Kd6 61. h5 Ke6 62. h6 Kd6 63. h7 Ke6 64. h8=Q Kd6 65. Qhf6+ Kd7 66. Qd5+ Kc7 67. Qdf7+ Kc8 68. Qh8# d4 d5 Nf3 Nf6 Bg5 Bf5 e3 e6 Bd3 Bxd3 Qxd3 Be7 O-O O-O Nbd2 c6 Rac1 Re8 Rfe1 Nf8 Ne5 N6d7 Bxe7 Qxe7 cxd5 exd5 Rxe4 Qd6 Qe4 Nf6 Qe",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "Bf5",
            "e3",
            "e6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "Be7",
            "O-O",
            "O-O",
            "Nbd2",
            "c6",
            "Rac1",
            "Re8",
            "Rfe1",
            "Nf8",
            "Ne5",
            "N6d7",
            "Bxe7",
            "Qxe7",
            "cxd5",
            "exd5",
            "Rxe4",
            "Qd6",
            "Qe4",
            "Nf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rac8",
              "Rc1",
              "Rc7",
              "Qd2",
              "Rfc8",
              "Rfc1",
              "Qb4",
              "Rxc7",
              "Qxd2",
              "Rxc8+",
              "Bxc8",
              "Nxd2",
              "Kf8",
              "Kf1",
              "Ke7",
              "Ke2",
              "Kd6",
              "Kd3",
              "b6",
              "Kc3",
              "a5",
              "b4",
              "Ba6",
              "bxa5",
              "bxa5",
              "Nb3",
              "a4",
              "Nc5",
              "Bb5",
              "Kb4",
              "Bc6",
              "Nxa4",
              "e5",
              "Nc3",
              "f6",
              "a4",
              "e5",
              "a5",
              "exd4",
              "exd4",
              "Kc7",
              "Kc5",
              "Kb7",
              "Kxd4",
              "Ka6",
              "Kc5",
              "Kxa5",
              "Nxd5",
              "Kb7",
              "Kd6",
              "Bb5+",
              "Ke7",
              "Kc5",
              "Bf1",
              "g3",
              "Ke6",
              "Kd4",
              "Kf5",
              "Ke3",
              "Kg4",
              "Kf2",
              "Kh3",
              "Kg1",
              "Bc4",
              "Nf5",
              "g6",
              "Ne3",
              "Bd3",
              "Nd5",
              "f5",
              "Nf6",
              "h6",
              "Ne5",
              "Be4",
              "Nxg6",
              "h5",
              "Ne5",
              "Be4",
              "Nf7",
              "Bd5",
              "Ng5",
              "Bf3",
              "Nxf3+",
              "Kf2",
              "Kxh2",
              "Kxf3",
              "Kh3",
              "Kf2",
              "Kg4",
              "Kg2",
              "h4",
              "gxh4",
              "Kxh4",
              "Kf3",
              "Kh3",
              "Kf2",
              "Kg4",
              "Ke3",
              "Kg3",
              "Ke2",
              "Kxf4",
              "Kf2",
              "Ke4",
              "Ke2",
              "f4",
              "Kf2",
              "f3",
              "Kf1",
              "Ke3",
              "Ke1",
              "f2+",
              "Kf1",
              "Kf3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Bg7",
              "Qe6",
              "Nf6+",
              "Qxf6",
              "Bxf6",
              "Be6",
              "Qxb7",
              "Rc8",
              "Rad1",
              "Bd7",
              "Rxd6",
              "Nb8",
              "Rfd1",
              "Rxc2",
              "Rxd7",
              "Nxd7",
              "Qxd7+",
              "Kf8",
              "Qe7+",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "Bf5",
              "e3",
              "e6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "Be7",
              "O-O",
              "O-O",
              "Nbd2",
              "c6",
              "Rac1",
              "Re8",
              "Rfe1",
              "Nf8",
              "Ne5",
              "N6d7",
              "Bxe7",
              "Qxe7",
              "cxd5",
              "exd5",
              "Rxe4",
              "Qd6",
              "Qe4",
              "Nf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 470,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 616,
            "total_tokens": 726,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1726,
          "total_tokens": 2055
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 470,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 616,
            "total_tokens": 726,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nf6 *\n3. c4 c6 *\n4. Nc3 dxc4 *\n5. a4 Bf5 *\n6. e3 e6 *\n7. Bxc4 Bb4 *\n8. O-O O-O *\n9. Qe2 Nbd7 *\n10. e4 Bg6 *\n11. Bd3 Bh5 *\n12. e5 Nd5 *\n13. Nxd5 cxd5 *\n14. Qe3 Bg6 *\n15. Bxg6 hxg6 *\n16. Ng5 Re8 *\n17. Qh3 Nf8 *\n18. Rd1 Rc8 *\n19. Rd3 f6 *\n20. Nf3 Qc7 *\n21. Bf4 Qc2 *\n22. Rad1 Qxb2 *\n23. exf6 gxf6 *\n24. Qh6 Rc2 *\n25. Ne5 Rxf2 *\n26. Rh3 Rxg2+ *\n27. Kh1 fxe5 *\n28. Bxe5 Re7 *\n29. Qh8+ Kf7 *\n30. Rf1+ Rf2 *\n31. Rf3+ Rxf3 *\n32. Rxf3+ Ke8 *\n33. Qxf8+ Kd7 *\n34. Qb8 Qb6 *\n35. Rf8 Kc6 *\n36. Qd6# Qxd6 *\n37. Rc8+ Kd7 *\n38. Rc7+ Qxc7 *\n39. Bxc7 Kxc7 *\n40. Kg2 Kd6 *\n41. Kf3 e5 *\n42. dxe5+ Rxe5 *\n43. Kf4 d4 *\n44. h4 d3 *\n45. h5 gxh5 *\n46. a5 d2 *\n47. a6 bxa6 *\n48. Kf3 d1=Q+ *\n49. Kf4 Qd4+ *\n50. Kf3 Re3+ *\n51. Kf2 Qd2+ *\n52. Kf1 Re1# *\nd4 d5 Nf3 Nf6 c4 c6 Nc3 dxc4 a4 Bf5 e3 e6 Bxc4 Bb4 O-O O-O Qe2 Nbd7 e4 Bg6 Bd3 Bh5 e5 Nd5 Nxd5 cxd5 Qe3 Bg6 Bxg6 hxg6 Ng5 Re8 Qh3 Nf8 Rd1 Rc8 Rd3 f6 Nf3 Qc7 Bf4 Qc2 Rd2 Qc1+ Ke2 Qc4+ Rd3 Qxb2+ exf6 gxf6 Qh6 Rc2 Ne5 Rxf2 Rh3 Rxg2 Rh8+ K",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qc7",
            "Bf4",
            "Qc2",
            "Rd2",
            "Qc1+",
            "Ke2",
            "Qc4+",
            "Rd3",
            "Qxb2+",
            "exf6",
            "gxf6",
            "Qh6",
            "Rc2",
            "Ne5",
            "Rxf2",
            "Rh3",
            "Rxg2",
            "Rh8+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nf6 3. c4 c6 4. Nc3 dxc4 5. a4 Bf5 6. e3 e6 7. Bxc4 Bb4 8. O-O O-O 9. Qe2 Nbd7 10. e4 Bg6 11. Bd3 Bh5 12. e5 Nd5 13. Nxd5 cxd5 14. Qe3 Bg6 15. Bxg6 hxg6 16. Ng5 Re8 17. Qh3 Nf8 18. Rd1 Rc8 19. Qb3 Qe7 20. Rd3 Rc4 21. Be3 Rec8 22. h4 f6 23. Nf3 Qc7 24. Bf4 Qb6 25. Qd1 Be7 26. Rb3 Qc6 27. a5 Rb4 28. Rxb4 Bxb4 29. Rc1 Qd7 30. Rxc8 Qxc8 31. Qa4 Be7 32. Qb5 Qc6 33. Qxc6 bxc6 34. Bd2 Nd7 35. exf6 gxf6 36. Kf1 e5 37. dxe5 fxe5 38. Bg5 Kf7 39. Bxe7 Kxe7 40. g4 e4 41. Nd4 c5 42. Nc6+ Kd6 43. Nxa7 Ne5 44. h5 gxh5 45. gxh5 Nf7 46. Nb5+ Kc6 47. Nc3 c4 48. Ke2 Kc5 49. a6 Kb6 50. Nxd5+ Kxa6 51. Ke3 Kb5 52. Kxe4 Kc5 53. Nc3 Kb4 54. Kd5 Kb3 55. f4 Kxb2 56. Kxc4 Kc2 57. Kd4 Kd2 58. Ne4+ Ke2 59. Ng5 Nh6 60. Ke5 Ke3 61. f5 Ng4+ 62. Ke6 Kf4 63. f6 Nh6 64. Nf7 Ng4 65. h6 Nxh6 66. Nxh6 Kg5 67. f7 Kxh6 68. f8=Q+ Kg5 69. Qf5+ Kh4 70. Qg6 Kh3 71. Kf5 Kh2 72. Kf4 Kh1 73. Kf3 Kh2 74. Qg2# e4 d5",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 603,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc7",
            "Bf4",
            "Qb6",
            "Qd1",
            "Be7",
            "Rb3",
            "Qc6",
            "a5",
            "Rb4",
            "Rxb4",
            "Bxb4",
            "Rc1",
            "Qd7",
            "Rxc8",
            "Qxc8",
            "Qa4",
            "Be7",
            "Qb5",
            "Qc6",
            "Qxc6",
            "bxc6",
            "Bd2",
            "Nd7",
            "exf6",
            "gxf6",
            "Kf1",
            "e5",
            "dxe5",
            "fxe5",
            "Bg5",
            "Kf7",
            "Bxe7",
            "Kxe7",
            "g4",
            "e4",
            "Nd4",
            "c5",
            "Nc6+",
            "Kd6",
            "Nxa7",
            "Ne5",
            "h5",
            "gxh5",
            "gxh5",
            "Nf7",
            "Nb5+",
            "Kc6",
            "Nc3",
            "c4",
            "Ke2",
            "Kc5",
            "a6",
            "Kb6",
            "Nxd5+",
            "Kxa6",
            "Ke3",
            "Kb5",
            "Kxe4",
            "Kc5",
            "Nc3",
            "Kb4",
            "Kd5",
            "Kb3",
            "f4",
            "Kxb2",
            "Kxc4",
            "Kc2",
            "Kd4",
            "Kd2",
            "Ne4+",
            "Ke2",
            "Ng5",
            "Nh6",
            "Ke5",
            "Ke3",
            "f5",
            "Ng4+",
            "Ke6",
            "Kf4",
            "f6",
            "Nh6",
            "Nf7",
            "Ng4",
            "h6",
            "Nxh6",
            "Nxh6",
            "Kg5",
            "f7",
            "Kxh6",
            "f8=Q+",
            "Kg5",
            "Qf5+",
            "Kh4",
            "Qg6",
            "Kh3",
            "Kf5",
            "Kh2",
            "Kf4",
            "Kh1",
            "Kf3",
            "Kh2",
            "Qg2#",
            "e4",
            "d5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nf6 3. c4 c6 4. Nc3 dxc4 5. a4 Bf5 6. e3 e6 7. Bxc4 Bb4 8. O-O O-O 9. Qe2 Nbd7 10. e4 Bg6 11. Bd3 Bh5 12. e5 Nd5 13. Nxd5 cxd5 14. Qe3 Bg6 15. Bxg6 hxg6 16. Ng5 Re8 17. Qh3 Nf8 18. Rd1 Rc8 19. Qb3 Qb6 20. Rd3 Be7 21. Qxb6 axb6 22. Nf3 Rc4 23. Bd2 Ra8 24. b3 Rc2 25. Rc1 Rxc1+ 26. Bxc1 Rc8 27. Bd2 Nd7 28. Rc3 Rxc3 29. Bxc3 Nb8 30. Kf1 Nc6 31. Ke2 Kf8 32. Kd3 Ke8 33. Ne1 Kd7 34. Nc2 f6 35. f4 g5 36. g3 gxf4 37. gxf4 f5 38. Ne1 g5 39. fxg5 Bxg5 40. Nf3 Be7 41. h4 Ke8 42. Bd2 Kf7 43. Bg5 Bf8 44. Bd2 Kg6 45. Ng5 Nd8 46. Nf3 Kh5 47. Bg5 Nc6 48. Bd2 Kg4 49. Ng5 Nd8 50. Nh7 Be7 51. Bg5 Bxg5 52. hxg5 Kh5 53. Nf8 Kxg5 54. Nd7 f4 55. Nxb6 Kg4 56. Ke2 Kg3 57. Kf1 Nc6 58. Nd7 Nxd4 59. b4 Nc2 60. b5 f3 61. Nc5 Ne3+ 62. Ke1 f2+ 63. Ke2 f1=Q+ 64. Kxe3 Qf2+ 65. Kd3 Qxc5 66. Kd2 Qa3 67. Kc2 Kf3 68. Kd2 Qb3 69. Kc1 Ke3 70. a5 Kd3 71. a6 Qc2# d4 d5 Nf3 Nf6 c4 c6 Nc3 dxc4 a4 Bf5 e3 e6 Bxc4 Bb4 O-O O-O Qe2 Nbd7 e5 Bg6 Bd3 Bh5 e5 Nd5 Nxd5 cxd5 Qe3 Bg6",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "c4",
            "c6",
            "Nc3",
            "dxc4",
            "a4",
            "Bf5",
            "e3",
            "e6",
            "Bxc4",
            "Bb4",
            "O-O",
            "O-O",
            "Qe2",
            "Nbd7",
            "e5",
            "Bg6",
            "Bd3",
            "Bh5",
            "e5",
            "Nd5",
            "Nxd5",
            "cxd5",
            "Qe3",
            "Bg6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qc7",
              "Bf4",
              "Qc2",
              "Rd2",
              "Qc1+",
              "Ke2",
              "Qc4+",
              "Rd3",
              "Qxb2+",
              "exf6",
              "gxf6",
              "Qh6",
              "Rc2",
              "Ne5",
              "Rxf2",
              "Rh3",
              "Rxg2",
              "Rh8+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qc7",
              "Bf4",
              "Qb6",
              "Qd1",
              "Be7",
              "Rb3",
              "Qc6",
              "a5",
              "Rb4",
              "Rxb4",
              "Bxb4",
              "Rc1",
              "Qd7",
              "Rxc8",
              "Qxc8",
              "Qa4",
              "Be7",
              "Qb5",
              "Qc6",
              "Qxc6",
              "bxc6",
              "Bd2",
              "Nd7",
              "exf6",
              "gxf6",
              "Kf1",
              "e5",
              "dxe5",
              "fxe5",
              "Bg5",
              "Kf7",
              "Bxe7",
              "Kxe7",
              "g4",
              "e4",
              "Nd4",
              "c5",
              "Nc6+",
              "Kd6",
              "Nxa7",
              "Ne5",
              "h5",
              "gxh5",
              "gxh5",
              "Nf7",
              "Nb5+",
              "Kc6",
              "Nc3",
              "c4",
              "Ke2",
              "Kc5",
              "a6",
              "Kb6",
              "Nxd5+",
              "Kxa6",
              "Ke3",
              "Kb5",
              "Kxe4",
              "Kc5",
              "Nc3",
              "Kb4",
              "Kd5",
              "Kb3",
              "f4",
              "Kxb2",
              "Kxc4",
              "Kc2",
              "Kd4",
              "Kd2",
              "Ne4+",
              "Ke2",
              "Ng5",
              "Nh6",
              "Ke5",
              "Ke3",
              "f5",
              "Ng4+",
              "Ke6",
              "Kf4",
              "f6",
              "Nh6",
              "Nf7",
              "Ng4",
              "h6",
              "Nxh6",
              "Nxh6",
              "Kg5",
              "f7",
              "Kxh6",
              "f8=Q+",
              "Kg5",
              "Qf5+",
              "Kh4",
              "Qg6",
              "Kh3",
              "Kf5",
              "Kh2",
              "Kf4",
              "Kh1",
              "Kf3",
              "Kh2",
              "Qg2#",
              "e4",
              "d5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "c4",
              "c6",
              "Nc3",
              "dxc4",
              "a4",
              "Bf5",
              "e3",
              "e6",
              "Bxc4",
              "Bb4",
              "O-O",
              "O-O",
              "Qe2",
              "Nbd7",
              "e5",
              "Bg6",
              "Bd3",
              "Bh5",
              "e5",
              "Nd5",
              "Nxd5",
              "cxd5",
              "Qe3",
              "Bg6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 603,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1883,
          "total_tokens": 2230
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 603,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": "c1g5",
          "aggressive_response": "3. Bg5 Bf5 4. e3 e6 5. Bd3 Bxd3 6. Qxd3 Nbd7 7. Nbd2 Be7 8. O-O O-O 9. c4 c6 10. Rac1 Rc8 11. Rc2 h6 12. Bh4 Nh7 13. Bxe7 Qxe7 14. Rfc1 f5 15. cxd5 exd5 16. Nb3 Ng5 17. Nxg5 Qxg5 18. Nc5 Nxc5 19. Rxc5 f4 20. e4 f3 21. g3 Qg4 22. exd5 cxd5 23. Rxc8 Rxc8 24. Rxc8+ Qxc8 25. Qxf3 Qc1+ 26. Kg2 Qxb2 27. Qxd5+ Kh7 28. Qe4+ Kg8 29. d5 Qxa2 30. d6 Qf7 31. Qe7 Qd5+ 32. Kh3 Qf5+ 33. Kg2 Qd5+ 34. f3 Qd2+ 35. Kh3 Qd5 36. d7 Qf5+ 37. Kg2 Qc2+ 38. Kf1 Qd1+ 39. Kf2 Qd2+ 40. Kg1 Qd1+ 41. Kg2 Qd2+ 42. Kh3 Qd5 43. d8=Q+ Qxd8 44. Qxd8+ Kh7 45. Qc7 b5 46. Qxa7 b4 47. Qb6 b3 48. Qxb3 Kg6 49. Qd3+ Kf6 50. Qe4 g5 51. f4 gxf4 52. gxf4 h5 53. Qe5+ Kg6 54. Qg5+ Kf7 55. Qxh5+ Kf6 56. Qg5+ Ke6 57. Kg4 Kd6 58. h4 Ke6 59. h5 Kd6 60. h6 Ke6 61. h7 Kd6 62. h8=Q Ke6 63. Qhh6+ Kf7 64. Qgg7+ Ke8 65. Qhh8# d4 d5 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 545,
            "total_tokens": 670,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bf5",
            "e3",
            "e6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "Nbd7",
            "Nbd2",
            "Be7",
            "O-O",
            "O-O",
            "c4",
            "c6",
            "Rac1",
            "Rc8",
            "Rc2",
            "h6",
            "Bh4",
            "Nh7",
            "Bxe7",
            "Qxe7",
            "Rfc1",
            "f5",
            "cxd5",
            "exd5",
            "Nb3",
            "Ng5",
            "Nxg5",
            "Qxg5",
            "Nc5",
            "Nxc5",
            "Rxc5",
            "f4",
            "e4",
            "f3",
            "g3",
            "Qg4",
            "exd5",
            "cxd5",
            "Rxc8",
            "Rxc8",
            "Rxc8+",
            "Qxc8",
            "Qxf3",
            "Qc1+",
            "Kg2",
            "Qxb2",
            "Qxd5+",
            "Kh7",
            "Qe4+",
            "Kg8",
            "d5",
            "Qxa2",
            "d6",
            "Qf7",
            "Qe7",
            "Qd5+",
            "Kh3",
            "Qf5+",
            "Kg2",
            "Qd5+",
            "f3",
            "Qd2+",
            "Kh3",
            "Qd5",
            "d7",
            "Qf5+",
            "Kg2",
            "Qc2+",
            "Kf1",
            "Qd1+",
            "Kf2",
            "Qd2+",
            "Kg1",
            "Qd1+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Qd5",
            "d8=Q+",
            "Qxd8",
            "Qxd8+",
            "Kh7",
            "Qc7",
            "b5",
            "Qxa7",
            "b4",
            "Qb6",
            "b3",
            "Qxb3",
            "Kg6",
            "Qd3+",
            "Kf6",
            "Qe4",
            "g5",
            "f4",
            "gxf4",
            "gxf4",
            "h5",
            "Qe5+",
            "Kg6",
            "Qg5+",
            "Kf7",
            "Qxh5+",
            "Kf6",
            "Qg5+",
            "Ke6",
            "Kg4",
            "Kd6",
            "h4",
            "Ke6",
            "h5",
            "Kd6",
            "h6",
            "Ke6",
            "h7",
            "Kd6",
            "h8=Q",
            "Ke6",
            "Qhh6+",
            "Kf7",
            "Qgg7+",
            "Ke8",
            "Qhh8#",
            "d4",
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 c4 18. Bc2 Nc5 19. Nf3 Rxf4 20. Nd4 Raf8 21. Rxf4 Rxf4 22. Qe3 Rf8 23. Nb5 Bc6 24. Nd6 Nb7 25. Nxb7 Bxb7 26. Rf1 Rxf1+ 27. Kxf1 Qf7+ 28. Ke2 Kg7 29. Qg5 Bc6 30. h4 Be8 31. h5 h6 32. hxg6 hxg5 33. gxf7 Bxf7 34. Ke3 Bg6 35. Ba4 Bb1 36. a3 Kg6 37. Bd7 Kf5 38. Kd4 Be4 39. g3 Kg4 40. Bxe6+ Kxg3 41. Bxd5 Bxd5 42. Kxd5 Kf4 43. e6 g4 44. e7 g3 45. e8=Q g2 46. Qe1 Kf3 47. Qg1 b5 48. Kc5 a6 49. Kb6 Ke2 50. Kxa6 Kd2 51. Kxb5 Kc2 52. Kxc4 Kxb2 53. Qxg2+ Kxa3 54. Qb7 Ka2 55. Kd3 Ka1 56. Kc2 Ka2 57. Qb2# e4 e5 g5",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 457,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "c4",
            "Bc2",
            "Nc5",
            "Nf3",
            "Rxf4",
            "Nd4",
            "Raf8",
            "Rxf4",
            "Rxf4",
            "Qe3",
            "Rf8",
            "Nb5",
            "Bc6",
            "Nd6",
            "Nb7",
            "Nxb7",
            "Bxb7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qf7+",
            "Ke2",
            "Kg7",
            "Qg5",
            "Bc6",
            "h4",
            "Be8",
            "h5",
            "h6",
            "hxg6",
            "hxg5",
            "gxf7",
            "Bxf7",
            "Ke3",
            "Bg6",
            "Ba4",
            "Bb1",
            "a3",
            "Kg6",
            "Bd7",
            "Kf5",
            "Kd4",
            "Be4",
            "g3",
            "Kg4",
            "Bxe6+",
            "Kxg3",
            "Bxd5",
            "Bxd5",
            "Kxd5",
            "Kf4",
            "e6",
            "g4",
            "e7",
            "g3",
            "e8=Q",
            "g2",
            "Qe1",
            "Kf3",
            "Qg1",
            "b5",
            "Kc5",
            "a6",
            "Kb6",
            "Ke2",
            "Kxa6",
            "Kd2",
            "Kxb5",
            "Kc2",
            "Kxc4",
            "Kxb2",
            "Qxg2+",
            "Kxa3",
            "Qb7",
            "Ka2",
            "Kd3",
            "Ka1",
            "Kc2",
            "Ka2",
            "Qb2#",
            "e4",
            "e5",
            "g5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": null,
          "neutral_response": "3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 c4 18. Bc2 Nc5 19. Nf3 Rxf4 20. Nd4 Raf8 21. Rxf4 Rxf4 22. Qg3 Qf7 23. h4 Ne4 24. Bxe4 dxe4 25. h5 Bd5 26. hxg6 hxg6 27. Re1 Kg7 28. Qg5 Rf2 29. Re3 Rxb2 30. Rh3 Qf2+ 31. Kh2 Qxg2+ 32. Qxg2 Rxg2+ 33. Kxg2 e3+ 34. Kf1 g5 35. Rxe3 Kg6 36. Kf2 g4 37. Kg3 Kg5 38. Re1 a6 39. Rf1 b5 40. Rf6 b4 41. Nxe6+ Bxe6 42. Rxe6 bxc3 43. Rc6 Kf5 44. Rxc4 Kxe5 45. Rxc3 Kd4 46. Ra3 Kc4 47. Rxa6 Kb4 48. Kxg4 Kb5 49. Ra8 Kb6 50. Kf5 Kb7 51. Ra3 Kb6 52. Ke5 Kb5 53. Kd5 Kb4 54. Rb3+ Ka4 55. Kc5 Ka5 56. Ra3# 1-0 3. Bxf6 gxf6 4. Qxf6#",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 460,
            "total_tokens": 584,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf6",
            "Qxf6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1g5",
          "positional_uci": "c1g5",
          "neutral_uci": null,
          "consensus_move": "c1g5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bf5",
              "e3",
              "e6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "Nbd7",
              "Nbd2",
              "Be7",
              "O-O",
              "O-O",
              "c4",
              "c6",
              "Rac1",
              "Rc8",
              "Rc2",
              "h6",
              "Bh4",
              "Nh7",
              "Bxe7",
              "Qxe7",
              "Rfc1",
              "f5",
              "cxd5",
              "exd5",
              "Nb3",
              "Ng5",
              "Nxg5",
              "Qxg5",
              "Nc5",
              "Nxc5",
              "Rxc5",
              "f4",
              "e4",
              "f3",
              "g3",
              "Qg4",
              "exd5",
              "cxd5",
              "Rxc8",
              "Rxc8",
              "Rxc8+",
              "Qxc8",
              "Qxf3",
              "Qc1+",
              "Kg2",
              "Qxb2",
              "Qxd5+",
              "Kh7",
              "Qe4+",
              "Kg8",
              "d5",
              "Qxa2",
              "d6",
              "Qf7",
              "Qe7",
              "Qd5+",
              "Kh3",
              "Qf5+",
              "Kg2",
              "Qd5+",
              "f3",
              "Qd2+",
              "Kh3",
              "Qd5",
              "d7",
              "Qf5+",
              "Kg2",
              "Qc2+",
              "Kf1",
              "Qd1+",
              "Kf2",
              "Qd2+",
              "Kg1",
              "Qd1+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Qd5",
              "d8=Q+",
              "Qxd8",
              "Qxd8+",
              "Kh7",
              "Qc7",
              "b5",
              "Qxa7",
              "b4",
              "Qb6",
              "b3",
              "Qxb3",
              "Kg6",
              "Qd3+",
              "Kf6",
              "Qe4",
              "g5",
              "f4",
              "gxf4",
              "gxf4",
              "h5",
              "Qe5+",
              "Kg6",
              "Qg5+",
              "Kf7",
              "Qxh5+",
              "Kf6",
              "Qg5+",
              "Ke6",
              "Kg4",
              "Kd6",
              "h4",
              "Ke6",
              "h5",
              "Kd6",
              "h6",
              "Ke6",
              "h7",
              "Kd6",
              "h8=Q",
              "Ke6",
              "Qhh6+",
              "Kf7",
              "Qgg7+",
              "Ke8",
              "Qhh8#",
              "d4",
              "d5",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "c4",
              "Bc2",
              "Nc5",
              "Nf3",
              "Rxf4",
              "Nd4",
              "Raf8",
              "Rxf4",
              "Rxf4",
              "Qe3",
              "Rf8",
              "Nb5",
              "Bc6",
              "Nd6",
              "Nb7",
              "Nxb7",
              "Bxb7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qf7+",
              "Ke2",
              "Kg7",
              "Qg5",
              "Bc6",
              "h4",
              "Be8",
              "h5",
              "h6",
              "hxg6",
              "hxg5",
              "gxf7",
              "Bxf7",
              "Ke3",
              "Bg6",
              "Ba4",
              "Bb1",
              "a3",
              "Kg6",
              "Bd7",
              "Kf5",
              "Kd4",
              "Be4",
              "g3",
              "Kg4",
              "Bxe6+",
              "Kxg3",
              "Bxd5",
              "Bxd5",
              "Kxd5",
              "Kf4",
              "e6",
              "g4",
              "e7",
              "g3",
              "e8=Q",
              "g2",
              "Qe1",
              "Kf3",
              "Qg1",
              "b5",
              "Kc5",
              "a6",
              "Kb6",
              "Ke2",
              "Kxa6",
              "Kd2",
              "Kxb5",
              "Kc2",
              "Kxc4",
              "Kxb2",
              "Qxg2+",
              "Kxa3",
              "Qb7",
              "Ka2",
              "Kd3",
              "Ka1",
              "Kc2",
              "Ka2",
              "Qb2#",
              "e4",
              "e5",
              "g5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf6",
              "Qxf6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 545,
            "total_tokens": 670,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 457,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 460,
            "total_tokens": 584,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1462,
          "total_tokens": 1836
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 545,
            "total_tokens": 670,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 457,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 460,
            "total_tokens": 584,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e3",
          "aggressive_uci": "e2e3",
          "aggressive_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 Nf6 17. Qh4 Rae8 18. Rf3 Ne4 19. Qh5 Rf5 20. Qg4 Nf6 21. Qh4 Rh5 22. Qf2 Nd7 23. g4 Nxe5 24. fxe5 Rxe5 25. Rf1 d4 26. Rf7 dxe3 27. Qf4 Qd6 28. Rxg7+ Kxg7 29. Qf7+ Kh6 30. Qxh7+ Kg5 31. Qh5# e4 dxe3 Qxe3+ Kh8 Qe5 Qg7#",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 251,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rae8",
            "Rf3",
            "Ne4",
            "Qh5",
            "Rf5",
            "Qg4",
            "Nf6",
            "Qh4",
            "Rh5",
            "Qf2",
            "Nd7",
            "g4",
            "Nxe5",
            "fxe5",
            "Rxe5",
            "Rf1",
            "d4",
            "Rf7",
            "dxe3",
            "Qf4",
            "Qd6",
            "Rxg7+",
            "Kxg7",
            "Qf7+",
            "Kh6",
            "Qxh7+",
            "Kg5",
            "Qh5#",
            "e4",
            "dxe3",
            "Qxe3+",
            "Kh8",
            "Qe5",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e3",
          "positional_uci": "e2e3",
          "positional_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh6 Qg7 18. Qh3 Rae8 19. Rae1 c4 20. Bc2 Nc5 21. Re3 Rf7 22. Rg3 Ref8 23. Rg4 Bc8 24. Qg3 Kh8 25. h4 Qh6 26. Rg5 Rg7 27. Nf3 Bd7 28. Nd4 Rgf7 29. Rg4 Rg7 30. Rg5 Rgf7 31. Rg4 Rg7 32. Rg5 Rgf7 33. Rg4 Rg7 34. Rg5 Rgf7 35. Rg4 Rg7 36. Rg5 Rgf7 37. Rg4 Rg7 38. Rg5 Rgf7 39. Rg4 Rg7 40. Rg5 Rgf7 41. Rg4 Rg7 42. Rg5 Rgf7 43. Rg4 Rg7 44. Rg5 Rgf7 45. Rg4 Rg7 46. Rg5 Rgf7 47. Rg4 Rg7 48. Rg5 Rgf7 49. Rg4 Rg7 50. Rg5 Rgf7 51. Rg4 Rg7 52. Rg5 Rgf7 53. Rg4 Rg7 54. Rg5 Rgf7 55. Rg4 Rg7 56. Rg5 Rgf7 57. Rg4 Rg7 58. Rg5 Rgf7 59. Rg4 Rg7 60. Rg5 Rgf7 61. Rg4 Rg7 62. Rg5 Rgf7 63. Rg4 Rg7 64. Rg5 Rgf7 65. Rg4 Rg7 66. Rg5 Rgf7 67. Rg4 Rg7 68. Rg5 Rgf7 69. Rg4 Rg7 70. Rg5 Rgf7 71. Rg4 Rg7 72. Rg5 Rgf7 73. Rg4 Rg7 74. Rg5 Rgf7 75. Rg4 Rg7 76. Rg5 Rgf7 77. Rg4 Rg",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh3",
            "Rae8",
            "Rae1",
            "c4",
            "Bc2",
            "Nc5",
            "Re3",
            "Rf7",
            "Rg3",
            "Ref8",
            "Rg4",
            "Bc8",
            "Qg3",
            "Kh8",
            "h4",
            "Qh6",
            "Rg5",
            "Rg7",
            "Nf3",
            "Bd7",
            "Nd4",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4",
            "Rg7",
            "Rg5",
            "Rgf7",
            "Rg4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e3",
          "neutral_uci": "e2e3",
          "neutral_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh6 Qg7 24. Qh4 Qf6 25. Qh6 Qg7 26. Qh4 Qf6 27. Qh6 Qg7 28. Qh4 Qf6 29. Qh6 Qg7 30. Qh4 Qf6 31. Qh6 Qg7 32. Qh4 Qf6 33. Qh6 Qg7 34. Qh4 Qf6 35. Qh6 Qg7 36. Qh4 Qf6 37. Qh6 Qg7 38. Qh4 Qf6 39. Qh6 Qg7 40. Qh4 Qf6 41. Qh6 Qg7 42. Qh4 Qf6 43. Qh6 Qg7 44. Qh4 Qf6 45. Qh6 Qg7 46. Qh4 Qf6 47. Qh6 Qg7 48. Qh4 Qf6 49. Qh6 Qg7 50. Qh4 Qf6 51. Qh6 Qg7 52. Qh4 Qf6 53. Qh6 Qg7 54. Qh4 Qf6 55. Qh6 Qg7 56. Qh4 Qf6 57. Qh6 Qg7 58. Qh4 Qf6 59. Qh6 Qg7 60. Qh4 Qf6 61. Qh6 Qg7 62. Qh4 Qf6 63. Qh6 Qg7 64. Qh4 Qf6 65. Qh6 Qg7 66. Qh4 Qf6 67. Qh6 Qg7 68. Qh4 Qf6 69. Qh6 Qg7 70. Qh4 Qf6 71. Qh6 Qg7 72. Qh4 Qf6 73. Qh6 Qg7 74. Qh4 Qf6 75. Qh6 Qg7 76. Qh4 Qf6",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e3",
          "positional_uci": "e2e3",
          "neutral_uci": "e2e3",
          "consensus_move": "e2e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rae8",
              "Rf3",
              "Ne4",
              "Qh5",
              "Rf5",
              "Qg4",
              "Nf6",
              "Qh4",
              "Rh5",
              "Qf2",
              "Nd7",
              "g4",
              "Nxe5",
              "fxe5",
              "Rxe5",
              "Rf1",
              "d4",
              "Rf7",
              "dxe3",
              "Qf4",
              "Qd6",
              "Rxg7+",
              "Kxg7",
              "Qf7+",
              "Kh6",
              "Qxh7+",
              "Kg5",
              "Qh5#",
              "e4",
              "dxe3",
              "Qxe3+",
              "Kh8",
              "Qe5",
              "Qg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh3",
              "Rae8",
              "Rae1",
              "c4",
              "Bc2",
              "Nc5",
              "Re3",
              "Rf7",
              "Rg3",
              "Ref8",
              "Rg4",
              "Bc8",
              "Qg3",
              "Kh8",
              "h4",
              "Qh6",
              "Rg5",
              "Rg7",
              "Nf3",
              "Bd7",
              "Nd4",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4",
              "Rg7",
              "Rg5",
              "Rgf7",
              "Rg4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 251,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1531,
          "total_tokens": 1929
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 251,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p2B1/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bd3",
          "aggressive_uci": "f1d3",
          "aggressive_response": "5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Bb7 10. f4 Ne4 11. Bxe7 Qxe7 12. Nxd7 Qxd7 13. Nf3 f6 14. Qe2 Rac8 15. Rad1 Qe7 16. Nd2 Nxd2 17. Rxd2 e5 18. fxe5 fxe5 19. Rxf8+ Rxf8 20. dxc5 bxc5 21. e4 d4 22. Bc4+ Kh8 23. Bd5 Bxd5 24. exd5 Qd6 25. c4 Re8 26. Qe4 Qh6 27. Rd1 Qh5 28. Rf1 Kg8 29. d6 Qg6 30. Qd5+ Qe6 31. Qxc5 Rd8 32. Qxa7 Qxd6 33. Qf7+ Kh8 34. c5 Qxc5 35. b4 Qd6 36. b5 d3 37. b6 d2 38. Rd1 Qxb6+ 39. Kh1 Qe3 40. Qf1 h6 41. h3 Qd3 42. Qf2 e4 43. Qh4 e3 44. Kh2 e2 45. Rxd2 Qxd2 46. a4 e1=Q 47. Qxe1 Qxe1 48. a5 Qxa5 49. h4 Qe5+ 50. Kh3 Rd3+ 51. Kg4 Rg3# e4 d5 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 394,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Bb7",
            "f4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxd7",
            "Qxd7",
            "Nf3",
            "f6",
            "Qe2",
            "Rac8",
            "Rad1",
            "Qe7",
            "Nd2",
            "Nxd2",
            "Rxd2",
            "e5",
            "fxe5",
            "fxe5",
            "Rxf8+",
            "Rxf8",
            "dxc5",
            "bxc5",
            "e4",
            "d4",
            "Bc4+",
            "Kh8",
            "Bd5",
            "Bxd5",
            "exd5",
            "Qd6",
            "c4",
            "Re8",
            "Qe4",
            "Qh6",
            "Rd1",
            "Qh5",
            "Rf1",
            "Kg8",
            "d6",
            "Qg6",
            "Qd5+",
            "Qe6",
            "Qxc5",
            "Rd8",
            "Qxa7",
            "Qxd6",
            "Qf7+",
            "Kh8",
            "c5",
            "Qxc5",
            "b4",
            "Qd6",
            "b5",
            "d3",
            "b6",
            "d2",
            "Rd1",
            "Qxb6+",
            "Kh1",
            "Qe3",
            "Qf1",
            "h6",
            "h3",
            "Qd3",
            "Qf2",
            "e4",
            "Qh4",
            "e3",
            "Kh2",
            "e2",
            "Rxd2",
            "Qxd2",
            "a4",
            "e1=Q",
            "Qxe1",
            "Qxe1",
            "a5",
            "Qxa5",
            "h4",
            "Qe5+",
            "Kh3",
            "Rd3+",
            "Kg4",
            "Rg3#",
            "e4",
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bd3",
          "positional_uci": "f1d3",
          "positional_response": "5. Bd3 O-O 6. Nbd2 c5 7. c3 Nc6 8. O-O b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh3 Qf5 24. g4 Qf6 25. g5 Qf5 26. Qh6 Re7 27. Rh3 Rg7 28. Be2 d4 29. Bg4 Qf8 30. Bxe6+ Kh8 31. Nxg6+ Rxg6 32. Qxg6 Qg7 33. Qxg7+ Kxg7 34. Bf5 dxc3 35. Rxh7+ Kg8 36. Rxb7 cxb2 37. Rb1 Nc3 38. Rxb2 Nd1 39. Re2 Nc3 40. Re1 Nxa2 41. Be6+ Kh8 42. Bxa2 Rd2 43. Bb1 c4 44. Rxa7 c3 45. Rc7 b5 46. Rxc3 b4 47. Rb3 Kg7 48. Rxb4 Kf7 49. Rb6 Kg7 50. Rc1 Rd7 51. h4 Re7 52. Kf2 Rd7 53. h5 Re7 54. h6+ Kf7 55. g6+ Ke8 56. h7 Kd7 57. Rb7+ Ke6 58. Rxe7+ Kxe7 59. h8=Q Ke6 60. Qe5+ Kd7 61. Rc7+ Kd8 62. Qe7# e4 d3 Qd4+ Kf8 Qf7#",
          "positional_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 500,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "c5",
            "c3",
            "Nc6",
            "O-O",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh3",
            "Qf5",
            "g4",
            "Qf6",
            "g5",
            "Qf5",
            "Qh6",
            "Re7",
            "Rh3",
            "Rg7",
            "Be2",
            "d4",
            "Bg4",
            "Qf8",
            "Bxe6+",
            "Kh8",
            "Nxg6+",
            "Rxg6",
            "Qxg6",
            "Qg7",
            "Qxg7+",
            "Kxg7",
            "Bf5",
            "dxc3",
            "Rxh7+",
            "Kg8",
            "Rxb7",
            "cxb2",
            "Rb1",
            "Nc3",
            "Rxb2",
            "Nd1",
            "Re2",
            "Nc3",
            "Re1",
            "Nxa2",
            "Be6+",
            "Kh8",
            "Bxa2",
            "Rd2",
            "Bb1",
            "c4",
            "Rxa7",
            "c3",
            "Rc7",
            "b5",
            "Rxc3",
            "b4",
            "Rb3",
            "Kg7",
            "Rxb4",
            "Kf7",
            "Rb6",
            "Kg7",
            "Rc1",
            "Rd7",
            "h4",
            "Re7",
            "Kf2",
            "Rd7",
            "h5",
            "Re7",
            "h6+",
            "Kf7",
            "g6+",
            "Ke8",
            "h7",
            "Kd7",
            "Rb7+",
            "Ke6",
            "Rxe7+",
            "Kxe7",
            "h8=Q",
            "Ke6",
            "Qe5+",
            "Kd7",
            "Rc7+",
            "Kd8",
            "Qe7#",
            "e4",
            "d3",
            "Qd4+",
            "Kf8",
            "Qf7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bd3",
          "neutral_uci": "f1d3",
          "neutral_response": "5. Bd3 O-O 6. Nbd2 c5 7. c3 Nc6 8. O-O b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 Nf6 17. Qh4 Rae8 18. Rf3 Ne4 19. Qh5 Rf5 20. Qh3 Rf6 21. g4 Rh6 22. Qg2 Qh4 23. g5 Rh5 24. Be2 d4 25. Rg3 Nxg3 26. Qxg3 Qxg3+ 27. hxg3 Rh1+ 28. Kf2 Rxa1 29. exd4 cxd4 30. cxd4 Rxa2 31. Ke3 Rxb2 32. Bc4 Bd5 33. Bd3 Rb3 34. Kd2 Rc8 35. g4 Rcc3 36. f5 exf5 37. gxf5 a5 38. f6 gxf6 39. gxf6 a4 40. Bc2 Rb2 41. Kxc3 a3 42. Nd3 Rxc2+ 43. Kxc2 a2 44. Kb2 Kf7 45. Nb4 Bc4 46. Nxa2 Bxa2 47. Kxa2 Kxf6 48. Kb3 Ke6 49. Kc4 h5 50. d5+ Kd6 51. Kd4 h4 52. Ke4 h3 53. Kf3 Kxd5 54. Kg3 b5 55. Kxh3 b4 56. Kg3 b3 57. Kf3 b2 58. Ke3 b1=Q 59. Kd2 Qb3 60. Ke2 Ke4 61. Kd2 Qd3+ 62. Kc1 Qe2 63. Kb1 Kd3 64. Ka1 Kc3 65. Kb1 Qb2# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O Nbd2 c5 c3 Nc6 O-O b6 Ne5 Nxe5 dxe5 Nd7 f4 f6 exf6 Nxf6 Ne5 Bb7 Ne5 Nd7 Qh5 Nf6 Qh3 Rae8 Rf3 Ne4 Qh5 Rf6 g4 Rh6 Qg2 Qh4 g5 Rh5 Be2 d4 Rg3 Nxg3 Qxg3 Qxg3+ hxg3 Rh1+ Kf2 Rxa1 exd4 cxd4",
          "neutral_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "c5",
            "c3",
            "Nc6",
            "O-O",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Ne5",
            "Bb7",
            "Ne5",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh3",
            "Rae8",
            "Rf3",
            "Ne4",
            "Qh5",
            "Rf6",
            "g4",
            "Rh6",
            "Qg2",
            "Qh4",
            "g5",
            "Rh5",
            "Be2",
            "d4",
            "Rg3",
            "Nxg3",
            "Qxg3",
            "Qxg3+",
            "hxg3",
            "Rh1+",
            "Kf2",
            "Rxa1",
            "exd4",
            "cxd4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1d3",
          "positional_uci": "f1d3",
          "neutral_uci": "f1d3",
          "consensus_move": "f1d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Bb7",
              "f4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxd7",
              "Qxd7",
              "Nf3",
              "f6",
              "Qe2",
              "Rac8",
              "Rad1",
              "Qe7",
              "Nd2",
              "Nxd2",
              "Rxd2",
              "e5",
              "fxe5",
              "fxe5",
              "Rxf8+",
              "Rxf8",
              "dxc5",
              "bxc5",
              "e4",
              "d4",
              "Bc4+",
              "Kh8",
              "Bd5",
              "Bxd5",
              "exd5",
              "Qd6",
              "c4",
              "Re8",
              "Qe4",
              "Qh6",
              "Rd1",
              "Qh5",
              "Rf1",
              "Kg8",
              "d6",
              "Qg6",
              "Qd5+",
              "Qe6",
              "Qxc5",
              "Rd8",
              "Qxa7",
              "Qxd6",
              "Qf7+",
              "Kh8",
              "c5",
              "Qxc5",
              "b4",
              "Qd6",
              "b5",
              "d3",
              "b6",
              "d2",
              "Rd1",
              "Qxb6+",
              "Kh1",
              "Qe3",
              "Qf1",
              "h6",
              "h3",
              "Qd3",
              "Qf2",
              "e4",
              "Qh4",
              "e3",
              "Kh2",
              "e2",
              "Rxd2",
              "Qxd2",
              "a4",
              "e1=Q",
              "Qxe1",
              "Qxe1",
              "a5",
              "Qxa5",
              "h4",
              "Qe5+",
              "Kh3",
              "Rd3+",
              "Kg4",
              "Rg3#",
              "e4",
              "d5",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Nbd2",
              "c5",
              "c3",
              "Nc6",
              "O-O",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh3",
              "Qf5",
              "g4",
              "Qf6",
              "g5",
              "Qf5",
              "Qh6",
              "Re7",
              "Rh3",
              "Rg7",
              "Be2",
              "d4",
              "Bg4",
              "Qf8",
              "Bxe6+",
              "Kh8",
              "Nxg6+",
              "Rxg6",
              "Qxg6",
              "Qg7",
              "Qxg7+",
              "Kxg7",
              "Bf5",
              "dxc3",
              "Rxh7+",
              "Kg8",
              "Rxb7",
              "cxb2",
              "Rb1",
              "Nc3",
              "Rxb2",
              "Nd1",
              "Re2",
              "Nc3",
              "Re1",
              "Nxa2",
              "Be6+",
              "Kh8",
              "Bxa2",
              "Rd2",
              "Bb1",
              "c4",
              "Rxa7",
              "c3",
              "Rc7",
              "b5",
              "Rxc3",
              "b4",
              "Rb3",
              "Kg7",
              "Rxb4",
              "Kf7",
              "Rb6",
              "Kg7",
              "Rc1",
              "Rd7",
              "h4",
              "Re7",
              "Kf2",
              "Rd7",
              "h5",
              "Re7",
              "h6+",
              "Kf7",
              "g6+",
              "Ke8",
              "h7",
              "Kd7",
              "Rb7+",
              "Ke6",
              "Rxe7+",
              "Kxe7",
              "h8=Q",
              "Ke6",
              "Qe5+",
              "Kd7",
              "Rc7+",
              "Kd8",
              "Qe7#",
              "e4",
              "d3",
              "Qd4+",
              "Kf8",
              "Qf7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Nbd2",
              "c5",
              "c3",
              "Nc6",
              "O-O",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Ne5",
              "Bb7",
              "Ne5",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh3",
              "Rae8",
              "Rf3",
              "Ne4",
              "Qh5",
              "Rf6",
              "g4",
              "Rh6",
              "Qg2",
              "Qh4",
              "g5",
              "Rh5",
              "Be2",
              "d4",
              "Rg3",
              "Nxg3",
              "Qxg3",
              "Qxg3+",
              "hxg3",
              "Rh1+",
              "Kf2",
              "Rxa1",
              "exd4",
              "cxd4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 140,
            "completion_tokens": 394,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 140,
            "completion_tokens": 500,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 419,
          "total_completion_tokens": 1534,
          "total_tokens": 1953
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 140,
            "completion_tokens": 394,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 140,
            "completion_tokens": 500,
            "total_tokens": 640,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp1bppp/4pn2/3p2B1/3P4/4PN2/PPP2PPP/RN1QKB1R w KQkq - 1 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh6 Qg7 18. Qxg7+ Kxg7 19. g3 Rf7 20. Nf3 h6 21. Nh4 Nf8 22. Rad1 Rd8 23. Bc2 Rfd7 24. Ba4 Re7 25. Bc2 Red7 26. Ba4 Re7 27. Bc2 Red7 28. Ba4 Re7 29. Bc2 Red7 30. Ba4 Re7 31. Bc2 Red7 32. Ba4 Re7 33. Bc2 Red7 34. Ba4 Re7 35. Bc2 Red7 36. Ba4 Re7 37. Bc2 Red7 38. Ba4 Re7 39. Bc2 Red7 40. Ba4 Re7 41. Bc2 Red7 42. Ba4 Re7 43. Bc2 Red7 44. Ba4 Re7 45. Bc2 Red7 46. Ba4 Re7 47. Bc2 Red7 48. Ba4 Re7 49. Bc2 Red7 50. Ba4 Re7 51. Bc2 Red7 52. Ba4 Re7 53. Bc2 Red7 54. Ba4 Re7 55. Bc2 Red7 56. Ba4 Re7 57. Bc2 Red7 58. Ba4 Re7 59. Bc2 Red7 60. Ba4 Re7 61. Bc2 Red7 62. Ba4 Re7 63. Bc2 Red7 64. Ba4 Re7 65. Bc2 Red7 66. Ba4 Re7 67. Bc2 Red7 68. Ba4 Re7 69. Bc2 Red7 70. Ba4 Re7 71. Bc2 Red7 72. Ba4 Re7 73. Bc2 Rd7 74. Ba4 Re7 75. Bc2 Rd7 76. Ba4 Re7 77. Bc2 Rd7 78. Ba4 Re7 79. Bc2 Rd7 80. Ba4 Re7 81. Bc2 Rd7 82. Ba4 Re7 83. Bc2 Rd7 84. Ba4 Re7 85. Bc2 Rd7 86. Ba4 Re7 87. Bc2 Rd7 88. Ba4 Re7 89. Bc",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qxg7+",
            "Kxg7",
            "g3",
            "Rf7",
            "Nf3",
            "h6",
            "Nh4",
            "Nf8",
            "Rad1",
            "Rd8",
            "Bc2",
            "Rfd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Red7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7",
            "Bc2",
            "Rd7",
            "Ba4",
            "Re7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh3 Qf5 24. g4 Qf6 25. g5 Qf5 26. Qh6 Re7 27. Rh3 Rg7 28. Be2 d4 29. Bg4 Qf8 30. Bxe6+ Kh8 31. Nxg6+ Rxg6 32. Qxh7# d4 33. Qxg6 dxe3 34. Rxh7# d3 35. Qh5# d2",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 254,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh3",
            "Qf5",
            "g4",
            "Qf6",
            "g5",
            "Qf5",
            "Qh6",
            "Re7",
            "Rh3",
            "Rg7",
            "Be2",
            "d4",
            "Bg4",
            "Qf8",
            "Bxe6+",
            "Kh8",
            "Nxg6+",
            "Rxg6",
            "Qxh7#",
            "d4",
            "Qxg6",
            "dxe3",
            "Rxh7#",
            "d3",
            "Qh5#",
            "d2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 Rf7 18. Rae1 Raf8 19. Qg4 c4 20. Bc2 Nc5 21. g3 b5 22. Nf3 a5 23. Nd4 b4 24. h4 bxc3 25. bxc3 Bc8 26. h5 Rg7 27. hxg6 hxg6 28. Kg2 g5 29. f5 exf5 30. Bxf5 Bxf5 31. Nxf5 Qe6 32. Nh6+ Qxh6 33. Rxf8+ Kxf8 34. Qc8+ Kf7 35. Rf1+ Ke7 36. Qxc5+ Kd7 37. Qxd5+ Kc7 38. Qxc4+ Kb7 39. Rb1+ Ka7 40. Qc5+ Ka8 41. Qxa5+ Ra7 42. Qd8# Nf6+ Kh2 Qh7#",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 321,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "Rf7",
            "Rae1",
            "Raf8",
            "Qg4",
            "c4",
            "Bc2",
            "Nc5",
            "g3",
            "b5",
            "Nf3",
            "a5",
            "Nd4",
            "b4",
            "h4",
            "bxc3",
            "bxc3",
            "Bc8",
            "h5",
            "Rg7",
            "hxg6",
            "hxg6",
            "Kg2",
            "g5",
            "f5",
            "exf5",
            "Bxf5",
            "Bxf5",
            "Nxf5",
            "Qe6",
            "Nh6+",
            "Qxh6",
            "Rxf8+",
            "Kxf8",
            "Qc8+",
            "Kf7",
            "Rf1+",
            "Ke7",
            "Qxc5+",
            "Kd7",
            "Qxd5+",
            "Kc7",
            "Qxc4+",
            "Kb7",
            "Rb1+",
            "Ka7",
            "Qc5+",
            "Ka8",
            "Qxa5+",
            "Ra7",
            "Qd8#",
            "Nf6+",
            "Kh2",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qxg7+",
              "Kxg7",
              "g3",
              "Rf7",
              "Nf3",
              "h6",
              "Nh4",
              "Nf8",
              "Rad1",
              "Rd8",
              "Bc2",
              "Rfd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Red7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7",
              "Bc2",
              "Rd7",
              "Ba4",
              "Re7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh3",
              "Qf5",
              "g4",
              "Qf6",
              "g5",
              "Qf5",
              "Qh6",
              "Re7",
              "Rh3",
              "Rg7",
              "Be2",
              "d4",
              "Bg4",
              "Qf8",
              "Bxe6+",
              "Kh8",
              "Nxg6+",
              "Rxg6",
              "Qxh7#",
              "d4",
              "Qxg6",
              "dxe3",
              "Rxh7#",
              "d3",
              "Qh5#",
              "d2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "Rf7",
              "Rae1",
              "Raf8",
              "Qg4",
              "c4",
              "Bc2",
              "Nc5",
              "g3",
              "b5",
              "Nf3",
              "a5",
              "Nd4",
              "b4",
              "h4",
              "bxc3",
              "bxc3",
              "Bc8",
              "h5",
              "Rg7",
              "hxg6",
              "hxg6",
              "Kg2",
              "g5",
              "f5",
              "exf5",
              "Bxf5",
              "Bxf5",
              "Nxf5",
              "Qe6",
              "Nh6+",
              "Qxh6",
              "Rxf8+",
              "Kxf8",
              "Qc8+",
              "Kf7",
              "Rf1+",
              "Ke7",
              "Qxc5+",
              "Kd7",
              "Qxd5+",
              "Kc7",
              "Qxc4+",
              "Kb7",
              "Rb1+",
              "Ka7",
              "Qc5+",
              "Ka8",
              "Qxa5+",
              "Ra7",
              "Qd8#",
              "Nf6+",
              "Kh2",
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 254,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 321,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 1215,
          "total_tokens": 1655
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 254,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 321,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1QK2R w KQ - 3 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bh4",
          "aggressive_uci": "g5h4",
          "aggressive_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 f6 14. exf6 Nxf6 15. Nf3 Bb7 16. Ne5 Qc7 17. Qe2 Nd7 18. Ng6 Rf6 19. Qh5 Nf8 20. Ne5 Nd7 21. Ng4 Rf7 22. Qg6 Kf8 23. Qxe6 Re8 24. Qg6 Nf6 25. Ne5 Rfe7 26. Rae1 Kg8 27. g4 Re6 28. g5 hxg5 29. Qxg5 Ne4 30. Bxe4 dxe4 31. Rd1 Qe7 32. Qxe7 R8xe7 33. Rd8+ Kh7 34. Rfd1 g5 35. R1d7 gxf4 36. exf4 Kg7 37. Kf2 Kf6 38. Rf8+ Kg7 39. Rf7+ Rxf7 40. Rxf7+ Kh6 41. Rxb7 Rd6 42. Ke3 Rd1 43. Kxe4 Re1+ 44. Kf5 Re2 45. Ng4+ Kh5 46. Rh7# 1-0\n\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 f6 14. exf6 Nxf6 15. Nf3 Bb7 16. Ne5 Qc7 17. Qe2 Nd7 18. Ng6 Rf6 19. Qh5 Nf8 20. Ne5 Nd7 21. Ng4 Rf7 22. Qg6 Kf8 23. Qxe6 Re8 24. Qg6 Nf6 25. Ne5 Rfe7 26. Rae1 Kg8 27. g4 Re6 28. g5 hxg5 29. Qxg5 Ne4 30. Bxe4 dxe4 31. Rd1 Qe7 32. Qxe7 R8xe7 33. Rd8+ Kh7 34. Rfd1 g5 35. R1d7 gxf4 36. exf4 Kg7 37. Kf2 Kf6 38. Rf",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Qc7",
            "Qe2",
            "Nd7",
            "Ng6",
            "Rf6",
            "Qh5",
            "Nf8",
            "Ne5",
            "Nd7",
            "Ng4",
            "Rf7",
            "Qg6",
            "Kf8",
            "Qxe6",
            "Re8",
            "Qg6",
            "Nf6",
            "Ne5",
            "Rfe7",
            "Rae1",
            "Kg8",
            "g4",
            "Re6",
            "g5",
            "hxg5",
            "Qxg5",
            "Ne4",
            "Bxe4",
            "dxe4",
            "Rd1",
            "Qe7",
            "Qxe7",
            "R8xe7",
            "Rd8+",
            "Kh7",
            "Rfd1",
            "g5",
            "R1d7",
            "gxf4",
            "exf4",
            "Kg7",
            "Kf2",
            "Kf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bh4",
          "positional_uci": "g5h4",
          "positional_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 f5 14. exf6 Nxf6 15. Nf3 Bb7 16. Ne5 Rfd8 17. Qe2 Nd7 18. Ng6 Qf6 19. Qh5 Nf8 20. Ne5 Nd7 21. Ng4 Qf7 22. Bg6 Qe7 23. Rf3 Nf6 24. Nxf6+ Qxf6 25. Rg3 d4 26. cxd4 cxd4 27. Rf1 dxe3 28. Rxe3 Rd2 29. Rg3 Qxb2 30. Bf7+ Kf8 31. Bxe6 Rxg2+ 32. Kh1 Rxg3+ 33. Bd5 Qg2+ 34. Bxg2 Bxg2+ 35. Kg1 Bf3+ 36. hxg3 Bxh5 37. Rc1 Re8 38. Rc7 Re7 39. Rc8+ Kf7 40. Rc2 Bg4 41. Kf2 Re2+ 42. Rxe2 Bxe2 43. Kxe2 Ke6 44. Ke3 Kd5 45. Kd3 b5 46. a3 a5 47. g4 b4 48. axb4 axb4 49. f5 Ke5 50. Kc4 Kf4 51. Kxb4 Kxg4 52. Kc4 Kxf5 53. Kd3 Kf4 54. Ke2 Kg3 55. Kf1 Kh2 56. Kf2 g5 57. Kf3 h5 58. Kf2 g4 59. Kf1 g3 60. Ke2 g2 61. Kf3 g1=Q 62. Kf4 Qg4+ 63. Ke5 Kg3 64. Kd5 Kf3 65. Ke5 Qe4+ 66. Kd6 Qf5 67. Kc6 Ke4 68. Kd6 Qd5+ 69. Ke7 Qc6 70. Kf7 Kf5 71. Ke7 Qe6+ 72. Kd8 Qf7 73. Kc8 Ke6 74. Kb8 Kd6 75. Ka8 Kc6 76. Kb8 Qb7# d4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O Bh4 Nbd7 c5 Ne5 Nxe5 dxe5 f4 exf6 Nxf6 Ne5 B",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "c5",
            "Ne5",
            "Nxe5",
            "dxe5",
            "f4",
            "exf6",
            "Nxf6",
            "Ne5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bh4",
          "neutral_uci": "g5h4",
          "neutral_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Rc1 Bb7 11. Bb1 Rc8 12. Qc2 Re8 13. Ne5 Nf8 14. f4 cxd4 15. exd4 Ne4 16. Bxe7 Qxe7 17. Nxe4 dxe4 18. Qe2 f5 19. g4 Qh4 20. gxf5 exf5 21. Qe3 Re6 22. Rf2 Ng6 23. Rg2 Nxe5 24. fxe5 f4 25. Qe1 Qxe1+ 26. Rxe1 e3 27. Rg4 Rf8 28. a3 g5 29. Ba2 Kf7 30. h4 Ke7 31. Bxe6 Kxe6 32. hxg5 hxg5 33. Rxg5 Rh8 34. Kf1 Rh2 35. c4 Be4 36. d5+ Kf7 37. e6+ Kf6 38. Rg8 Bd3+ 39. Kg1 Rxb2 40. Rf8+ Ke7 41. Rf7+ Ke8 42. Rxf4 e2 43. d6 Rd2 44. d7+ Ke7 45. Rf7+ Kd8 46. Rf8+ Ke7 47. d8=Q+ Kxe6 48. Rf6+ Ke5 49. Qd6+ Ke4 50. Rf4+ Ke3 51. Qd4# Nf6+ gxf6+ Kxf6",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 388,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Rc1",
            "Bb7",
            "Bb1",
            "Rc8",
            "Qc2",
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxe4",
            "dxe4",
            "Qe2",
            "f5",
            "g4",
            "Qh4",
            "gxf5",
            "exf5",
            "Qe3",
            "Re6",
            "Rf2",
            "Ng6",
            "Rg2",
            "Nxe5",
            "fxe5",
            "f4",
            "Qe1",
            "Qxe1+",
            "Rxe1",
            "e3",
            "Rg4",
            "Rf8",
            "a3",
            "g5",
            "Ba2",
            "Kf7",
            "h4",
            "Ke7",
            "Bxe6",
            "Kxe6",
            "hxg5",
            "hxg5",
            "Rxg5",
            "Rh8",
            "Kf1",
            "Rh2",
            "c4",
            "Be4",
            "d5+",
            "Kf7",
            "e6+",
            "Kf6",
            "Rg8",
            "Bd3+",
            "Kg1",
            "Rxb2",
            "Rf8+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Rxf4",
            "e2",
            "d6",
            "Rd2",
            "d7+",
            "Ke7",
            "Rf7+",
            "Kd8",
            "Rf8+",
            "Ke7",
            "d8=Q+",
            "Kxe6",
            "Rf6+",
            "Ke5",
            "Qd6+",
            "Ke4",
            "Rf4+",
            "Ke3",
            "Qd4#",
            "Nf6+",
            "gxf6+",
            "Kxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5h4",
          "positional_uci": "g5h4",
          "neutral_uci": "g5h4",
          "consensus_move": "g5h4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Qc7",
              "Qe2",
              "Nd7",
              "Ng6",
              "Rf6",
              "Qh5",
              "Nf8",
              "Ne5",
              "Nd7",
              "Ng4",
              "Rf7",
              "Qg6",
              "Kf8",
              "Qxe6",
              "Re8",
              "Qg6",
              "Nf6",
              "Ne5",
              "Rfe7",
              "Rae1",
              "Kg8",
              "g4",
              "Re6",
              "g5",
              "hxg5",
              "Qxg5",
              "Ne4",
              "Bxe4",
              "dxe4",
              "Rd1",
              "Qe7",
              "Qxe7",
              "R8xe7",
              "Rd8+",
              "Kh7",
              "Rfd1",
              "g5",
              "R1d7",
              "gxf4",
              "exf4",
              "Kg7",
              "Kf2",
              "Kf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "c5",
              "Ne5",
              "Nxe5",
              "dxe5",
              "f4",
              "exf6",
              "Nxf6",
              "Ne5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Rc1",
              "Bb7",
              "Bb1",
              "Rc8",
              "Qc2",
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxe4",
              "dxe4",
              "Qe2",
              "f5",
              "g4",
              "Qh4",
              "gxf5",
              "exf5",
              "Qe3",
              "Re6",
              "Rf2",
              "Ng6",
              "Rg2",
              "Nxe5",
              "fxe5",
              "f4",
              "Qe1",
              "Qxe1+",
              "Rxe1",
              "e3",
              "Rg4",
              "Rf8",
              "a3",
              "g5",
              "Ba2",
              "Kf7",
              "h4",
              "Ke7",
              "Bxe6",
              "Kxe6",
              "hxg5",
              "hxg5",
              "Rxg5",
              "Rh8",
              "Kf1",
              "Rh2",
              "c4",
              "Be4",
              "d5+",
              "Kf7",
              "e6+",
              "Kf6",
              "Rg8",
              "Bd3+",
              "Kg1",
              "Rxb2",
              "Rf8+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Rxf4",
              "e2",
              "d6",
              "Rd2",
              "d7+",
              "Ke7",
              "Rf7+",
              "Kd8",
              "Rf8+",
              "Ke7",
              "d8=Q+",
              "Kxe6",
              "Rf6+",
              "Ke5",
              "Qd6+",
              "Ke4",
              "Rf4+",
              "Ke3",
              "Qd4#",
              "Nf6+",
              "gxf6+",
              "Kxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 388,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 1668,
          "total_tokens": 2129
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 388,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bpp1/4pn1p/3p2B1/3P4/3BPN2/PPP2PPP/RN1Q1RK1 w - - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c4",
          "aggressive_uci": "c2c4",
          "aggressive_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qe6+ Kh7 30. Qf5+ Kg8 31. Qe6+ Kh7 32. Qf5+ Kg8 33. Qe6+ Kh7 34. Qf5+ Kg8 35. Qe6+ Kh7 36. Qf5+ Kg8 37. Qe6+ Kh7 38. Qf5+ Kg8 39. Qe6+ Kh7 40. Qf5+ Kg8 41. Qe6+ Kh7 42. Qf5+ Kg8 43. Qe6+ Kh7 44. Qf5+ Kg8 45. Qe6+ Kh7 46. Qf5+ Kg8 47. Qe6+ Kh7 48. Qf5+ Kg8 49. Qe6+ Kh7 50. Qf5+ Kg8 51. Qe6+ Kh7 52. Qf5+ Kg8 53. Qe6+ Kh7 54. Qf5+ Kg8 55. Qe6+ Kh7 56. Qf5+ Kg8 57. Qe6+ Kh7 58. Qf5+ Kg8 59. Qe6+ Kh7 60. Qf5+ Kg8 61. Qe6+ Kh7 62. Qf5+ Kg8 63. Qe6+ Kh7 64. Qf5+ Kg8 65. Qe6+ Kh7 66. Qf5+ Kg8 67. Qe6+ Kh7 68. Qf5+ Kg8 69. Qe6+ Kh7 70. Qf5+ Kg8 71. Qe6+ Kh7 72. Qf5+ Kg8 73. Qe6+ Kh7 74. Qf5+ Kg8 75. Qe6+ Kh7 76. Qf5+ Kg8 77. Qe6+ Kh7 78. Qf5+ Kg8 79. Qe6+ Kh7 80.",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c4",
          "positional_uci": "c2c4",
          "positional_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qc3+ 39. Ke2 Qc2+ 40. Kf3 Qc3+ 41. Ke2 Qc2+ 42. Kf3 Qc3+ 43. Ke2 Qc2+ 44. Kf3 Qc3+ 45. Ke2 Qc2+ 46. Kf3 Qc3+ 47. Ke2 Qc2+ 48. Kf3 Qc3+ 49. Ke2 Qc2+ 50. Kf3 Qc3+ 51. Ke2 Qc2+ 52. Kf3 Qc3+ 53. Ke2 Qc2+ 54. Kf3 Qc3+ 55. Ke2 Qc2+ 56. Kf3 Qc3+ 57. Ke2 Qc2+ 58. Kf3 Qc3+ 59. Ke2 Qc2+ 60. Kf3 Qc3+ 61. Ke2 Qc2+ 62. Kf3 Qc3+ 63. Ke2 Qc2+ 64. Kf3 Qc3+ 65. Ke2 Qc2+ 66. Kf3 Qc3+ 67. Ke2 Qc2+ 68. Kf3 Qc3+ 69. Ke2 Qc2+ 70. Kf3 Qc3+ 71. Ke2 Qc2+ 72. Kf3 Qc3+ 73. Ke2 Qc2+ 74. Kf3 Qc3+ 75. Ke2 Qc2+ 76. Kf3 Qc3+ 77. Ke2",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c4",
          "neutral_uci": "c2c4",
          "neutral_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80.",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c2c4",
          "positional_uci": "c2c4",
          "neutral_uci": "c2c4",
          "consensus_move": "c2c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 1920,
          "total_tokens": 2402
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbq1rk1/p1p1bpp1/1p2pn1p/3p4/3P3B/3BPN2/PPP2PPP/RN1Q1RK1 w - - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc3",
          "aggressive_uci": "b1c3",
          "aggressive_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 e5 19. bxc5 Rxd4 20. Qb3 bxc5 21. Rxc5 Qxc5 22. Qxb7 Rad8 23. Qb3 Rd2 24. Rf1 Re2 25. Bd3 Rd2 26. Bc4 R8d7 27. Bd5 Kh7 28. Qf3 f6 29. Qf5+ Kh8 30. Qxd7 Kh7 31. Qf5+ Kh8 32. Qe6 Kh7 33. Qg8+ Kg6 34. Bf7+ Kg5 35. Qxg7+ Kf4 36. Qg3+ Kxe4 37. Qf3+ Kd4 38. Qe3# d4 e5 Qd6",
          "aggressive_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 264,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "e5",
            "bxc5",
            "Rxd4",
            "Qb3",
            "bxc5",
            "Rxc5",
            "Qxc5",
            "Qxb7",
            "Rad8",
            "Qb3",
            "Rd2",
            "Rf1",
            "Re2",
            "Bd3",
            "Rd2",
            "Bc4",
            "R8d7",
            "Bd5",
            "Kh7",
            "Qf3",
            "f6",
            "Qf5+",
            "Kh8",
            "Qxd7",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qe6",
            "Kh7",
            "Qg8+",
            "Kg6",
            "Bf7+",
            "Kg5",
            "Qxg7+",
            "Kf4",
            "Qg3+",
            "Kxe4",
            "Qf3+",
            "Kd4",
            "Qe3#",
            "d4",
            "e5",
            "Qd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc3",
          "positional_uci": "b1c3",
          "positional_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qc3+ 39. Ke2 Qc2+ 40. Kf3 Qc3+ 41. Ke2 Qc2+ 42. Kf3 Qc3+ 43. Ke2 Qc2+ 44. Kf3 Qc3+ 45. Ke2 Qc2+ 46. Kf3 Qc3+ 47. Ke2 Qc2+ 48. Kf3 Qc3+ 49. Ke2 Qc2+ 50. Kf3 Qc3+ 51. Ke2 Qc2+ 52. Kf3 Qc3+ 53. Ke2 Qc2+ 54. Kf3 Qc3+ 55. Ke2 Qc2+ 56. Kf3 Qc3+ 57. Ke2 Qc2+ 58. Kf3 Qc3+ 59. Ke2 Qc2+ 60. Kf3 Qc3+ 61. Ke2 Qc2+ 62. Kf3 Qc3+ 63. Ke2 Qc2+ 64. Kf3 Qc3+ 65. Ke2 Qc2+ 66. Kf3 Qc3+ 67. Ke2 Qc2+ 68. Kf3 Qc3+ 69. Ke2 Qc2+ 70. Kf3 Qc3+ 71. Ke2 Qc2+ 72. Kf3 Qc3+ 73. Ke2 Qc2+ 74. Kf3 Qc3+ 75. Ke2 Qc2+ 76. Kf3 Qc3+ 77. Ke2 Qc2+ 78. K",
          "positional_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc3",
          "neutral_uci": "b1c3",
          "neutral_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81",
          "neutral_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b1c3",
          "positional_uci": "b1c3",
          "neutral_uci": "b1c3",
          "consensus_move": "b1c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "e5",
              "bxc5",
              "Rxd4",
              "Qb3",
              "bxc5",
              "Rxc5",
              "Qxc5",
              "Qxb7",
              "Rad8",
              "Qb3",
              "Rd2",
              "Rf1",
              "Re2",
              "Bd3",
              "Rd2",
              "Bc4",
              "R8d7",
              "Bd5",
              "Kh7",
              "Qf3",
              "f6",
              "Qf5+",
              "Kh8",
              "Qxd7",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qe6",
              "Kh7",
              "Qg8+",
              "Kg6",
              "Bf7+",
              "Kg5",
              "Qxg7+",
              "Kf4",
              "Qg3+",
              "Kxe4",
              "Qf3+",
              "Kd4",
              "Qe3#",
              "d4",
              "e5",
              "Qd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 170,
            "completion_tokens": 264,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 509,
          "total_completion_tokens": 1544,
          "total_tokens": 2053
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 170,
            "completion_tokens": 264,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rn1q1rk1/pbp1bpp1/1p2pn1p/3p4/2PP3B/3BPN2/PP3PPP/RN1Q1RK1 w - - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rc1",
          "aggressive_uci": "a1c1",
          "aggressive_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. h4 Qf6 24. Rd1 Rd8 25. Rxd8+ Qxd8 26. Qg4 Qf6 27. Ba2 Kh7 28. h5 Nc7 29. Qd1 Bxe4 30. Nd6 Qd8 31. Bxf7 Nb5 32. Bg6+ Bxg6 33. hxg6+ Kxg6 34. Qd3+ Kf6 35. Ne4+ Ke7 36. Qxb5 Qd1+ 37. Qf1 Qd4 38. Qe1 Ke6 39. Qe3 Qa1+ 40. Kh2 Qd1 41. Qh3+ Kd5 42. Nc3+ 1-0\nd4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 c5 cxd5 Nxd5 Bxe7 Qxe7 Nxd5 Bxd5 e4 Bb7 Re1 cxd4 Nxd4 Nc5 Bb1 Rfd8 b4 Na6 a3 e5 Nf5 Qg5 Qf3 Rac8 Rxc8 Rxc8 h4 Qf6 Qg4 Kh7 h5 Nc7 Qd1 Nb5 Qd7 Bc6 Qxc8 Nd4 Nxd4 exd4 e5+ 1-0 d4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 c5 cxd5 Nxd5 Bxe7 Qxe7 Nxd5 Bxd5 e4 Bb7 Re1 cxd4 Nxd4 Nc5 Bb1 Rfd8 b4 Na6 a3 e5 Nf5 Qg5 Qf3 Rac8 Rxc8 Rxc8 h4 Qf6 Qg4 Kh7 h5 Nc7 Qd1 Nb5 Qd7 Bc6 Qxc8 Nd4 Nxd4 exd4 e5+ 1-0 d4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd",
          "aggressive_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "h4",
            "Qf6",
            "Qg4",
            "Kh7",
            "h5",
            "Nc7",
            "Qd1",
            "Nb5",
            "Qd7",
            "Bc6",
            "Qxc8",
            "Nd4",
            "Nxd4",
            "exd4",
            "e5+",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4",
            "b6",
            "c4",
            "Bb7",
            "Nc3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rc1",
          "positional_uci": "a1c1",
          "positional_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82",
          "positional_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rc1",
          "neutral_uci": "a1c1",
          "neutral_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82",
          "neutral_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a1c1",
          "positional_uci": "a1c1",
          "neutral_uci": "a1c1",
          "consensus_move": "a1c1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "h4",
              "Qf6",
              "Qg4",
              "Kh7",
              "h5",
              "Nc7",
              "Qd1",
              "Nb5",
              "Qd7",
              "Bc6",
              "Qxc8",
              "Nd4",
              "Nxd4",
              "exd4",
              "e5+",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4",
              "b6",
              "c4",
              "Bb7",
              "Nc3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 536,
          "total_completion_tokens": 1920,
          "total_tokens": 2456
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2q1rk1/pbpnbpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/R2Q1RK1 w - - 3 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd5",
          "aggressive_uci": "c4d5",
          "aggressive_response": "11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Qe2 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. Rfd1 Rac8 19. b4 Na4 20. Rxc8 Rxc8 21. Qd2 Nc3 22. Rc1 Nxb1 23. Rxb1 Bxe4 24. Re1 Bd5 25. a3 Qf6 26. Nb5 Qg6 27. g3 Rc2 28. Qe3 Qh5 29. Nd4 Qh3 30. Nf3 Qg4 31. Nd4 Qh3 32. Nf3 Qf5 33. Nd4 Qh3 34. Nf3 Qf5 35. Nd4 Qh3 36. Nf3 Qf5 37. Nd4 Qh3 38. Nf3 Qf5 39. Nd4 Qh3 40. Nf3 Qf5 41. Nd4 Qh3 42. Nf3 Qf5 43. Nd4 Qh3 44. Nf3 Qf5 45. Nd4 Qh3 46. Nf3 Qf5 47. Nd4 Qh3 48. Nf3 Qf5 49. Nd4 Qh3 50. Nf3 Qf5 51. Nd4 Qh3 52. Nf3 Qf5 53. Nd4 Qh3 54. Nf3 Qf5 55. Nd4 Qh3 56. Nf3 Qf5 57. Nd4 Qh3 58. Nf3 Qf5 59. Nd4 Qh3 60. Nf3 Qf5 61. Nd4 Qh3 62. Nf3 Qf5 63. Nd4 Qh3 64. Nf3 Qf5 65. Nd4 Qh3 66. Nf3 Qf5 67. Nd4 Qh3 68. Nf3 Qf5 69. Nd4 Qh3 70. Nf3 Qf5 71. Nd4 Qh3 72. Nf3 Qf5 73. Nd4 Qh3 74. Nf3 Qf5 75. Nd4 Qh3 76. Nf3 Qf5 77. Nd4 Qh3 78. Nf3 Qf5 79. Nd4 Qh3 80. Nf3 Qf5 81. Nd4 Qh3 82. Nf3 Qf5 83. Nd4 Qh3 84. Nf3 Qf5 85. Nd4 Qh3 86. Nf",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Qe2",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "Rfd1",
            "Rac8",
            "b4",
            "Na4",
            "Rxc8",
            "Rxc8",
            "Qd2",
            "Nc3",
            "Rc1",
            "Nxb1",
            "Rxb1",
            "Bxe4",
            "Re1",
            "Bd5",
            "a3",
            "Qf6",
            "Nb5",
            "Qg6",
            "g3",
            "Rc2",
            "Qe3",
            "Qh5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qg4",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3",
            "Nf3",
            "Qf5",
            "Nd4",
            "Qh3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "cxd5",
          "positional_uci": "c4d5",
          "positional_response": "11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qc3+ 39. Ke2 Qc2+ 40. Kf3 Qf5+ 41. Ke2 Qe4+ 42. Kf1 Qb1+ 43. Ke2 Qc2+ 44. Kf3 Qc3+ 45. Ke2 Qc2+ 46. Kf3 Qf5+ 47. Ke2 Qe4+ 48. Kf1 Qb1+ 49. Ke2 Qc2+ 50. Kf3 Qc3+ 51. Ke2 Qc2+ 52. Kf3 Qf5+ 53. Ke2 Qe4+ 54. Kf1 Qb1+ 55. Ke2 Qc2+ 56. Kf3 Qc3+ 57. Ke2 Qc2+ 58. Kf3 Qf5+ 59. Ke2 Qe4+ 60. Kf1 Qb1+ 61. Ke2 Qc2+ 62. Kf3 Qc3+ 63. Ke2 Qc2+ 64. Kf3 Qf5+ 65. Ke2 Qe4+ 66. Kf1 Qb1+ 67. Ke2 Qc2+ 68. Kf3 Qc3+ 69. Ke2 Qc2+ 70. Kf3 Qf5+ 71. Ke2 Qe4+ 72. Kf1 Qb1+ 73. Ke2 Qc2+ 74. Kf3 Qc3+ 75. Ke2 Qc2+ 76. Kf3 Qf5+ 77. Ke2 Qe4+ 78. Kf1 Qb1+ 79. Ke2 Qc2+",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qc3+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "cxd5",
          "neutral_uci": "c4d5",
          "neutral_response": "11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82. Qf5+ Kg8",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c4d5",
          "positional_uci": "c4d5",
          "neutral_uci": "c4d5",
          "consensus_move": "c4d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Qe2",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "Rfd1",
              "Rac8",
              "b4",
              "Na4",
              "Rxc8",
              "Rxc8",
              "Qd2",
              "Nc3",
              "Rc1",
              "Nxb1",
              "Rxb1",
              "Bxe4",
              "Re1",
              "Bd5",
              "a3",
              "Qf6",
              "Nb5",
              "Qg6",
              "g3",
              "Rc2",
              "Qe3",
              "Qh5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qg4",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3",
              "Nf3",
              "Qf5",
              "Nd4",
              "Qh3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qc3+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 1920,
          "total_tokens": 2477
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p2pn1p/2pp4/2PP3B/2NBPN2/PP3PPP/2RQ1RK1 w - - 0 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb1",
          "aggressive_uci": "d3b1",
          "aggressive_response": "12. Bb1 Rc8 13. Qc2 Re8 14. Ne5 Nf8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18.\nQd3 f6 19. Ng4 Qd7 20. Ne3 f5 21. a3 Kh8 22. Ba2 Nxc3 23. Rxc3 Rxc3 24. bxc3\ng6 25. c4 dxc4 26. Bxc4 Re4 27. d5 Qd6 28. g3 Nd7 29. Rd1 Nf6 30. Qc3 Kh7 31.\nRd4 Re7 32. Qd3 Qc5 33. Kf1 b5 34. Bxb5 Rxe3 35. Qxe3 Qxb5+ 36. Kg1 Qb1+ 37.\nKg2 Qc2+ 38. Kh3 Qc5 39. Qe5 Kg7 40. d6 Qc6 41. Qe7+ Kg8 42. Qe6+ Kg7 43. Qe7+\nKg8 44. Qe6+ Kg7 45. Qe7+ Kg8 46. Qe6+ Kg7 47. Qe7+ Kg8 48. Qe6+ Kg7 49. Qe7+\nKg8 50. Qe6+ Kg7 51. Qe7+ Kg8 52. Qe6+ Kg7 53. Qe7+ Kg8 54. Qe6+ Kg7 55. Qe7+\nKg8 56. Qe6+ Kg7 57. Qe7+ Kg8 58. Qe6+ Kg7 59. Qe7+ Kg8 60. Qe6+ Kg7 61. Qe7+\nKg8 62. Qe6+ Kg7 63. Qe7+ Kg8 64. Qe6+ Kg7 65. Qe7+ Kg8 66. Qe6+ Kg7 67. Qe7+\nKg8 68. Qe6+ Kg7 69. Qe7+ Kg8 70. Qe6+ Kg7 71. Qe7+ Kg8 72. Qe6+ Kg7 73. Qe7+\nKg8 74. Qe6+ Kg7 75. Qe7+ Kg8 76. Qe6+ Kg7 77. Qe7+ Kg8 78. Qe6+ Kg7 79. Qe7+\nKg8 80. Qe6+ Kg7 81. Qe7+ Kg8 82. Qe6+ Kg7 83. Qe7+ Kg8 84. Qe6+",
          "aggressive_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rc8",
            "Qc2",
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Qd3",
            "f6",
            "Ng4",
            "Qd7",
            "Ne3",
            "f5",
            "a3",
            "Kh8",
            "Ba2",
            "Nxc3",
            "Rxc3",
            "Rxc3",
            "bxc3",
            "g6",
            "c4",
            "dxc4",
            "Bxc4",
            "Re4",
            "d5",
            "Qd6",
            "g3",
            "Nd7",
            "Rd1",
            "Nf6",
            "Qc3",
            "Kh7",
            "Rd4",
            "Re7",
            "Qd3",
            "Qc5",
            "Kf1",
            "b5",
            "Bxb5",
            "Rxe3",
            "Qxe3",
            "Qxb5+",
            "Kg1",
            "Qb1+",
            "Kg2",
            "Qc2+",
            "Kh3",
            "Qc5",
            "Qe5",
            "Kg7",
            "d6",
            "Qc6",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Qe6+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb1",
          "positional_uci": "d3b1",
          "positional_response": "12. Bb1 Re8 13. Qc2 Nf8 14. Ne5 Rc8 15. Qf5 cxd4 16. exd4 Rc7 17. Nb5 Rxc1 18.\nRxc1 Bc8 19. Qf3 a6 20. Nc7 Ne6 21. Nxe8 Qxe8 22. Qd3 g6 23. Qf3 Kg7 24. Bxf6+\nBxf6 25. Qxd5 Nf4 26. Qe4 Bg5 27. Rc7 Be6 28. g3 Bd5 29. Qc2 Nh3+ 30. Kf1 Qb5+\n31. Qd3 Qxb2 32. Qxg6+ Kf8 33. Rxf7+ Ke8 34. Qg8#",
          "positional_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 195,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Qc2",
            "Nf8",
            "Ne5",
            "Rc8",
            "Qf5",
            "cxd4",
            "exd4",
            "Rc7",
            "Nb5",
            "Rxc1",
            "Rxc1",
            "Bc8",
            "Qf3",
            "a6",
            "Nc7",
            "Ne6",
            "Nxe8",
            "Qxe8",
            "Qd3",
            "g6",
            "Qf3",
            "Kg7",
            "Bxf6+",
            "Bxf6",
            "Qxd5",
            "Nf4",
            "Qe4",
            "Bg5",
            "Rc7",
            "Be6",
            "g3",
            "Bd5",
            "Qc2",
            "Nh3+",
            "Kf1",
            "Qb5+",
            "Qd3",
            "Qxb2",
            "Qxg6+",
            "Kf8",
            "Rxf7+",
            "Ke8",
            "Qg8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb1",
          "neutral_uci": "d3b1",
          "neutral_response": "12. Bb1 Re8 13. Qc2 Nf8 14. Ne5 Rc8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18. Qd3 f6 19. Ng4 Qd7 20. Ne3 f5 21. a3 Kh8 22. Ba2 Nxc3 23. Rxc3 Rxc3 24. Qxc3 Ne6 25. Nxf5 Rf8 26. Bb1 Ba6 27. Rf2 Qa4 28. b3 Qxa3 29. Ra2 Rc8 30. Qxc8+ Bxc8 31. Rxa3 Nxf4 32. Rxa7 Bxf5 33. Bxf5 Ne2+ 34. Kf2 Nxd4 35. Ra8# Nf3 Nf6 Nxf6",
          "neutral_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 206,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba6",
            "Rf2",
            "Qa4",
            "b3",
            "Qxa3",
            "Ra2",
            "Rc8",
            "Qxc8+",
            "Bxc8",
            "Rxa3",
            "Nxf4",
            "Rxa7",
            "Bxf5",
            "Bxf5",
            "Ne2+",
            "Kf2",
            "Nxd4",
            "Ra8#",
            "Nf3",
            "Nf6",
            "Nxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3b1",
          "positional_uci": "d3b1",
          "neutral_uci": "d3b1",
          "consensus_move": "d3b1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rc8",
              "Qc2",
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Qd3",
              "f6",
              "Ng4",
              "Qd7",
              "Ne3",
              "f5",
              "a3",
              "Kh8",
              "Ba2",
              "Nxc3",
              "Rxc3",
              "Rxc3",
              "bxc3",
              "g6",
              "c4",
              "dxc4",
              "Bxc4",
              "Re4",
              "d5",
              "Qd6",
              "g3",
              "Nd7",
              "Rd1",
              "Nf6",
              "Qc3",
              "Kh7",
              "Rd4",
              "Re7",
              "Qd3",
              "Qc5",
              "Kf1",
              "b5",
              "Bxb5",
              "Rxe3",
              "Qxe3",
              "Qxb5+",
              "Kg1",
              "Qb1+",
              "Kg2",
              "Qc2+",
              "Kh3",
              "Qc5",
              "Qe5",
              "Kg7",
              "d6",
              "Qc6",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Qe6+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Qc2",
              "Nf8",
              "Ne5",
              "Rc8",
              "Qf5",
              "cxd4",
              "exd4",
              "Rc7",
              "Nb5",
              "Rxc1",
              "Rxc1",
              "Bc8",
              "Qf3",
              "a6",
              "Nc7",
              "Ne6",
              "Nxe8",
              "Qxe8",
              "Qd3",
              "g6",
              "Qf3",
              "Kg7",
              "Bxf6+",
              "Bxf6",
              "Qxd5",
              "Nf4",
              "Qe4",
              "Bg5",
              "Rc7",
              "Be6",
              "g3",
              "Bd5",
              "Qc2",
              "Nh3+",
              "Kf1",
              "Qb5+",
              "Qd3",
              "Qxb2",
              "Qxg6+",
              "Kf8",
              "Rxf7+",
              "Ke8",
              "Qg8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ba6",
              "Rf2",
              "Qa4",
              "b3",
              "Qxa3",
              "Ra2",
              "Rc8",
              "Qxc8+",
              "Bxc8",
              "Rxa3",
              "Nxf4",
              "Rxa7",
              "Bxf5",
              "Bxf5",
              "Ne2+",
              "Kf2",
              "Nxd4",
              "Ra8#",
              "Nf3",
              "Nf6",
              "Nxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 195,
            "completion_tokens": 195,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 194,
            "completion_tokens": 206,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 584,
          "total_completion_tokens": 1041,
          "total_tokens": 1625
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 195,
            "completion_tokens": 195,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 194,
            "completion_tokens": 206,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2NBPN2/PP3PPP/2RQ1RK1 w - - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qd3",
          "aggressive_uci": "d1d3",
          "aggressive_response": "13. Qd3 Re8 14. Ne5 Nf8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18. f5 f6 19. Ng4 Qb4 20. Rc2 Rc4 21. Rd1 Rec8 22. a3 Qb3 23. Ba2 Rxc3 24. Bxb3 Rxd3 25. Rxd3 Rxc2 26. Bxc2 Nd6 27. Ne3 Nd7 28. Rc3 Nb5 29. Rd3 Nd6 30. Bb3 Kf8 31. Bxd5 Ba6 32. Rc3 Nb5 33. Rc4 Nd6 34. Ra4 Nb8 35. Be6 Nc6 36. d5 Bb5 37. Rh4 Ne5 38. a4 Bd3 39. Rd4 Be4 40. b4 Ke7 41. a5 bxa5 42. bxa5 a6 43. Rb4 Bd3 44. Rb8 Bb5 45. Rg8 Ne8 46. Nc2 Nc4 47. Nd4 Nxa5 48. Nxb5 axb5 49. d6+ Nxd6 50. Rxg7+ Kf8 51. Rd7 Nac4 52. Bxc4 Nxc4 53. Rb7 Nd6 54. Rb6 Ke7 55. g4 Kd7 56. Kf2 Kc7 57. Ra6 b4 58. Ke3 b3 59. Kd3 b2 60. Kc2 Nc4 61. Rxf6 Ne3+ 62. Kxb2 Nxg4 63. Rg6 Ne3 64. f6 Kd7 65. Rxh6 Ke6 66. Kc3 Ng4 67. Rh4 Nxf6 68. Kd4 Kf5 69. Rh8 Kg6 70. Ke5 Ng4+ 71. Kf4 Nf6 72. Ra8 Nh5+ 73. Kg4 Nf6+ 74. Kh4 Kh6 75. Ra6 Kg6 76. h3 Kf5 77. Ra5+ Kg6 78. Rg5+ Kh6 79. Rg1 Nh7 80. Kg4 Nf6+ 81. Kf5 Nh5 82. Rg6+ Kh7 83. Kg5 Ng7 84. Ra6 Kg8 85. Kg6 Ne8 86. Ra8 Kf8 87. h4 Ke7 88. Rxe8+ Kxe8 89. Kg7 Ke7 90. h5 Ke6 91. h6 Kf5 92. h7 Kg5 93",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "f5",
            "f6",
            "Ng4",
            "Qb4",
            "Rc2",
            "Rc4",
            "Rd1",
            "Rec8",
            "a3",
            "Qb3",
            "Ba2",
            "Rxc3",
            "Bxb3",
            "Rxd3",
            "Rxd3",
            "Rxc2",
            "Bxc2",
            "Nd6",
            "Ne3",
            "Nd7",
            "Rc3",
            "Nb5",
            "Rd3",
            "Nd6",
            "Bb3",
            "Kf8",
            "Bxd5",
            "Ba6",
            "Rc3",
            "Nb5",
            "Rc4",
            "Nd6",
            "Ra4",
            "Nb8",
            "Be6",
            "Nc6",
            "d5",
            "Bb5",
            "Rh4",
            "Ne5",
            "a4",
            "Bd3",
            "Rd4",
            "Be4",
            "b4",
            "Ke7",
            "a5",
            "bxa5",
            "bxa5",
            "a6",
            "Rb4",
            "Bd3",
            "Rb8",
            "Bb5",
            "Rg8",
            "Ne8",
            "Nc2",
            "Nc4",
            "Nd4",
            "Nxa5",
            "Nxb5",
            "axb5",
            "d6+",
            "Nxd6",
            "Rxg7+",
            "Kf8",
            "Rd7",
            "Nac4",
            "Bxc4",
            "Nxc4",
            "Rb7",
            "Nd6",
            "Rb6",
            "Ke7",
            "g4",
            "Kd7",
            "Kf2",
            "Kc7",
            "Ra6",
            "b4",
            "Ke3",
            "b3",
            "Kd3",
            "b2",
            "Kc2",
            "Nc4",
            "Rxf6",
            "Ne3+",
            "Kxb2",
            "Nxg4",
            "Rg6",
            "Ne3",
            "f6",
            "Kd7",
            "Rxh6",
            "Ke6",
            "Kc3",
            "Ng4",
            "Rh4",
            "Nxf6",
            "Kd4",
            "Kf5",
            "Rh8",
            "Kg6",
            "Ke5",
            "Ng4+",
            "Kf4",
            "Nf6",
            "Ra8",
            "Nh5+",
            "Kg4",
            "Nf6+",
            "Kh4",
            "Kh6",
            "Ra6",
            "Kg6",
            "h3",
            "Kf5",
            "Ra5+",
            "Kg6",
            "Rg5+",
            "Kh6",
            "Rg1",
            "Nh7",
            "Kg4",
            "Nf6+",
            "Kf5",
            "Nh5",
            "Rg6+",
            "Kh7",
            "Kg5",
            "Ng7",
            "Ra6",
            "Kg8",
            "Kg6",
            "Ne8",
            "Ra8",
            "Kf8",
            "h4",
            "Ke7",
            "Rxe8+",
            "Kxe8",
            "Kg7",
            "Ke7",
            "h5",
            "Ke6",
            "h6",
            "Kf5",
            "h7",
            "Kg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd3",
          "positional_uci": "d1d3",
          "positional_response": "13. Qd3 Re8 14. Ne5 Nf8 15. f4 c4 16. Qc2 a6 17. Rf3 b5 18. Rg3 b4 19. Ne2 Ne4 20. Bxe7 Qxe7 21. Rh3 f6 22. Ng4 Qe6 23. Nf2 Nxf2 24. Kxf2 Rc7 25. Rg1 Rce7 26. g4 Bc8 27. Rhg3 Qf7 28. h4 Re4 29. Qd2 R4e7 30. g5 fxg5 31. hxg5 hxg5 32. Rxg5 Qe6 33. R1g3 Qh6 34. Ng1 Qh2+ 35. Rg2 Qh4+ 36. R5g3 Rxe3 37. Nf3 Qxf4 38. Rxg7+ Kh8 39. Rg8# d4 d3 Qd8#",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 236,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "c4",
            "Qc2",
            "a6",
            "Rf3",
            "b5",
            "Rg3",
            "b4",
            "Ne2",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Rh3",
            "f6",
            "Ng4",
            "Qe6",
            "Nf2",
            "Nxf2",
            "Kxf2",
            "Rc7",
            "Rg1",
            "Rce7",
            "g4",
            "Bc8",
            "Rhg3",
            "Qf7",
            "h4",
            "Re4",
            "Qd2",
            "R4e7",
            "g5",
            "fxg5",
            "hxg5",
            "hxg5",
            "Rxg5",
            "Qe6",
            "R1g3",
            "Qh6",
            "Ng1",
            "Qh2+",
            "Rg2",
            "Qh4+",
            "R5g3",
            "Rxe3",
            "Nf3",
            "Qxf4",
            "Rxg7+",
            "Kh8",
            "Rg8#",
            "d4",
            "d3",
            "Qd8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qc2",
          "neutral_uci": "d1c2",
          "neutral_response": "13. Qc2 Re8 14. Ne5 Nf8 15. f4 cxd4 16. exd4 Ne4 17. Bxe7 Qxe7 18. Qd3 f6 19. Ng4 Qd7 20. Ne3 f5 21. a3 Ne6 22. Ba2 Nxc3 23. Rxc3 Rxc3 24. bxc3 g6 25. g4 fxg4 26. Nxg4 Kg7 27. Ne5 Qe7 28. Qxg6+ Kf8 29. Qxh6+ Qg7+ 30. Qxg7+ Kxg7 31. f5 Ng5 32. f6+ Kf8 33. f7 Re6 34. Nd7+ Ke7 35. f8=Q+ Kxd7 36. Qg7+ Kc6 37. Qxg5 Kb5 38. Bxd5 Bxd5 39. Qxd5+ Ka4 40. Qxe6 Kxa3 41. Rb1 a5 42. Qb3# Bb7 cxb7 43. Qxb7 a4 44. Qxb6 Ka2 45. Qb2#",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 287,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Ne5",
            "Nf8",
            "f4",
            "cxd4",
            "exd4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Qd3",
            "f6",
            "Ng4",
            "Qd7",
            "Ne3",
            "f5",
            "a3",
            "Ne6",
            "Ba2",
            "Nxc3",
            "Rxc3",
            "Rxc3",
            "bxc3",
            "g6",
            "g4",
            "fxg4",
            "Nxg4",
            "Kg7",
            "Ne5",
            "Qe7",
            "Qxg6+",
            "Kf8",
            "Qxh6+",
            "Qg7+",
            "Qxg7+",
            "Kxg7",
            "f5",
            "Ng5",
            "f6+",
            "Kf8",
            "f7",
            "Re6",
            "Nd7+",
            "Ke7",
            "f8=Q+",
            "Kxd7",
            "Qg7+",
            "Kc6",
            "Qxg5",
            "Kb5",
            "Bxd5",
            "Bxd5",
            "Qxd5+",
            "Ka4",
            "Qxe6",
            "Kxa3",
            "Rb1",
            "a5",
            "Qb3#",
            "Bb7",
            "cxb7",
            "Qxb7",
            "a4",
            "Qxb6",
            "Ka2",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1d3",
          "positional_uci": "d1d3",
          "neutral_uci": "d1c2",
          "consensus_move": "d1d3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "f5",
              "f6",
              "Ng4",
              "Qb4",
              "Rc2",
              "Rc4",
              "Rd1",
              "Rec8",
              "a3",
              "Qb3",
              "Ba2",
              "Rxc3",
              "Bxb3",
              "Rxd3",
              "Rxd3",
              "Rxc2",
              "Bxc2",
              "Nd6",
              "Ne3",
              "Nd7",
              "Rc3",
              "Nb5",
              "Rd3",
              "Nd6",
              "Bb3",
              "Kf8",
              "Bxd5",
              "Ba6",
              "Rc3",
              "Nb5",
              "Rc4",
              "Nd6",
              "Ra4",
              "Nb8",
              "Be6",
              "Nc6",
              "d5",
              "Bb5",
              "Rh4",
              "Ne5",
              "a4",
              "Bd3",
              "Rd4",
              "Be4",
              "b4",
              "Ke7",
              "a5",
              "bxa5",
              "bxa5",
              "a6",
              "Rb4",
              "Bd3",
              "Rb8",
              "Bb5",
              "Rg8",
              "Ne8",
              "Nc2",
              "Nc4",
              "Nd4",
              "Nxa5",
              "Nxb5",
              "axb5",
              "d6+",
              "Nxd6",
              "Rxg7+",
              "Kf8",
              "Rd7",
              "Nac4",
              "Bxc4",
              "Nxc4",
              "Rb7",
              "Nd6",
              "Rb6",
              "Ke7",
              "g4",
              "Kd7",
              "Kf2",
              "Kc7",
              "Ra6",
              "b4",
              "Ke3",
              "b3",
              "Kd3",
              "b2",
              "Kc2",
              "Nc4",
              "Rxf6",
              "Ne3+",
              "Kxb2",
              "Nxg4",
              "Rg6",
              "Ne3",
              "f6",
              "Kd7",
              "Rxh6",
              "Ke6",
              "Kc3",
              "Ng4",
              "Rh4",
              "Nxf6",
              "Kd4",
              "Kf5",
              "Rh8",
              "Kg6",
              "Ke5",
              "Ng4+",
              "Kf4",
              "Nf6",
              "Ra8",
              "Nh5+",
              "Kg4",
              "Nf6+",
              "Kh4",
              "Kh6",
              "Ra6",
              "Kg6",
              "h3",
              "Kf5",
              "Ra5+",
              "Kg6",
              "Rg5+",
              "Kh6",
              "Rg1",
              "Nh7",
              "Kg4",
              "Nf6+",
              "Kf5",
              "Nh5",
              "Rg6+",
              "Kh7",
              "Kg5",
              "Ng7",
              "Ra6",
              "Kg8",
              "Kg6",
              "Ne8",
              "Ra8",
              "Kf8",
              "h4",
              "Ke7",
              "Rxe8+",
              "Kxe8",
              "Kg7",
              "Ke7",
              "h5",
              "Ke6",
              "h6",
              "Kf5",
              "h7",
              "Kg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "c4",
              "Qc2",
              "a6",
              "Rf3",
              "b5",
              "Rg3",
              "b4",
              "Ne2",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Rh3",
              "f6",
              "Ng4",
              "Qe6",
              "Nf2",
              "Nxf2",
              "Kxf2",
              "Rc7",
              "Rg1",
              "Rce7",
              "g4",
              "Bc8",
              "Rhg3",
              "Qf7",
              "h4",
              "Re4",
              "Qd2",
              "R4e7",
              "g5",
              "fxg5",
              "hxg5",
              "hxg5",
              "Rxg5",
              "Qe6",
              "R1g3",
              "Qh6",
              "Ng1",
              "Qh2+",
              "Rg2",
              "Qh4+",
              "R5g3",
              "Rxe3",
              "Nf3",
              "Qxf4",
              "Rxg7+",
              "Kh8",
              "Rg8#",
              "d4",
              "d3",
              "Qd8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re8",
              "Ne5",
              "Nf8",
              "f4",
              "cxd4",
              "exd4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Qd3",
              "f6",
              "Ng4",
              "Qd7",
              "Ne3",
              "f5",
              "a3",
              "Ne6",
              "Ba2",
              "Nxc3",
              "Rxc3",
              "Rxc3",
              "bxc3",
              "g6",
              "g4",
              "fxg4",
              "Nxg4",
              "Kg7",
              "Ne5",
              "Qe7",
              "Qxg6+",
              "Kf8",
              "Qxh6+",
              "Qg7+",
              "Qxg7+",
              "Kxg7",
              "f5",
              "Ng5",
              "f6+",
              "Kf8",
              "f7",
              "Re6",
              "Nd7+",
              "Ke7",
              "f8=Q+",
              "Kxd7",
              "Qg7+",
              "Kc6",
              "Qxg5",
              "Kb5",
              "Bxd5",
              "Bxd5",
              "Qxd5+",
              "Ka4",
              "Qxe6",
              "Kxa3",
              "Rb1",
              "a5",
              "Qb3#",
              "Bb7",
              "cxb7",
              "Qxb7",
              "a4",
              "Qxb6",
              "Ka2",
              "Qb2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 236,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 287,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 1163,
          "total_tokens": 1771
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 236,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 287,
            "total_tokens": 489,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2rq1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2N1PN2/PP3PPP/1BRQ1RK1 w - - 2 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne5",
          "aggressive_uci": "f3e5",
          "aggressive_response": "14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3\nBe7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5\nexd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3\nBe7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5\nexd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6.",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe5",
            "dxe5",
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne5",
          "positional_uci": "f3e5",
          "positional_response": "14. Ne5 Nxe5 15. dxe5 Ne4 16. Bxe7 Qxe7 17. Nxd5 Bxd5 18. Qxd5 Ng5 19. f4 Rfd8 20. Qc4 Ne6 21. Qe4 g6 22. f5 Ng5 23. Qf4 Rd2 24. fxg6 fxg6 25. Bxg6 Rf8 26. Qc4+ Kg7 27. Rxf8 Qxf8 28. Rf1 Qe7 29. Qc3 Rd8 30. Bc2 Ne6 31. Rf6 Nf8 32. e4 Nh7 33. Qg3+ Kh8 34. Rxh6 Rg8 35. Qh3 Rg7 36. e6 Kg8 37. e5 Qg5 38. Bxh7+ Kf8 39. Rf6+ Ke7 40. Rf7+ Rxf7 41. exf7 Qc1+ 42. Kf2 Qxb2+ 43. Kg3 Qxe5+ 44. Kh4 Qf6+ 45. Kg3 Qe5+ 46. Kf2 Qf6+ 47. Qf3 Qd4+ 48. Kg3 Qg7+ 49. Kh3 Qxh7+ 50. Kg3 Qg7+ 51. Kh3 Qh6+ 52. Kg3 Qg5+ 53. Kh3 Qh6+ 54. Kg3 Qg5+ 55. Kh3 Qh6+ 56. Kg3 Qg5+ 57. Kh3 Qh6+ 58. Kg3 Qg5+ 59. Kh3 Qh6+ 60. Kg3 Qg5+ 61. Kh3 Qh6+ 62. Kg3 Qg5+ 63. Kh3 Qh6+ 64. Kg3 Qg5+ 65. Kh3 Qh6+ 66. Kg3 Qg5+ 67. Kh3 Qh6+ 68. Kg3 Qg5+ 69. Kh3 Qh6+ 70. Kg3 Qg5+ 71. Kh3 Qh6+ 72. Kg3 Qg5+ 73. Kh3 Qh6+ 74. Kg3 Qg5+ 75. Kh3 Qh6+ 76. Kg3 Qg5+ 77. Kh3 Qh6+ 78. Kg3 Qg5+ 79. Kh3 Qh6+ 80. Kg3 Qg5+ 81. Kh3 Qh6+ 82. Kg3 Qg5+ 83. Kh3 Qh6+ 84. Kg3 Qg5+ 85. Kh3 Qh6",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe5",
            "dxe5",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "Qxd5",
            "Ng5",
            "f4",
            "Rfd8",
            "Qc4",
            "Ne6",
            "Qe4",
            "g6",
            "f5",
            "Ng5",
            "Qf4",
            "Rd2",
            "fxg6",
            "fxg6",
            "Bxg6",
            "Rf8",
            "Qc4+",
            "Kg7",
            "Rxf8",
            "Qxf8",
            "Rf1",
            "Qe7",
            "Qc3",
            "Rd8",
            "Bc2",
            "Ne6",
            "Rf6",
            "Nf8",
            "e4",
            "Nh7",
            "Qg3+",
            "Kh8",
            "Rxh6",
            "Rg8",
            "Qh3",
            "Rg7",
            "e6",
            "Kg8",
            "e5",
            "Qg5",
            "Bxh7+",
            "Kf8",
            "Rf6+",
            "Ke7",
            "Rf7+",
            "Rxf7",
            "exf7",
            "Qc1+",
            "Kf2",
            "Qxb2+",
            "Kg3",
            "Qxe5+",
            "Kh4",
            "Qf6+",
            "Kg3",
            "Qe5+",
            "Kf2",
            "Qf6+",
            "Qf3",
            "Qd4+",
            "Kg3",
            "Qg7+",
            "Kh3",
            "Qxh7+",
            "Kg3",
            "Qg7+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6+",
            "Kg3",
            "Qg5+",
            "Kh3",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne5",
          "neutral_uci": "f3e5",
          "neutral_response": "14. Ne5 Nxe5 15. dxe5 Ne4 16. Bxe7 Qxe7 17. Nxd5 Bxd5 18. Qxd5 Ng5 19. f4 Ne6 20. Qe4 g6 21. f5 Ng5 22. Qf4 Rce8 23. h4 Nh7 24. Qxh6 Qxe5 25. fxg6 fxg6 26. Qxg6+ Qg7 27. Rxf8+ Rxf8 28. Qxg7+ Kxg7 29. Bxh7 Kxh7 30. Rf1 Re8 31. Rf7+ Kg6 32. Rxa7 Rxe3 33. Rb7 Re6 34. g4 Re4 35. Rxb6+ Kg7 36. Kf2 Rxg4 37. h5 Rh4 38. h6+ Kh7 39. Ke3 Rh2 40. Kd3 Rh4 41. Kc3 Rg4 42. b3 Rh4 43. a4 Rg4 44. a5 Rg1 45. a6 Ra1 46. Kc4 Ra5 47. Rc6 Kh8 48. Rxc5 Rxa6 49. Rh5 Kh7 50. b4 Ra1 51. b5 Rc1+ 52. Kd5 Rd1+ 53. Kc6 Rc1+ 54. Kb7 Rb1 55. b6 Rb2 56. Kc7 Rc2+ 57. Kb8 Rb2 58. b7 Rb1 59. Rc5 Kxh6 60. Kc7 1-0 61. b8=Q Rxb8 62. Kxb8 Kg6 63. Kc7 Kf6 64. Kd6 Kf7 65. Re5 Kf6 66. Kd5 Kf7 67. Re6 Kg7 68. Ke5 Kf7 69. Kf5 Kg7 70. Rf6 Kh7 71. Rg6 Kh8 72. Kf6 Kh7 73. Kf7 Kh8 74. Rh6# 1-0 Qc7 Qc7 Qc7",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 522,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe5",
            "dxe5",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "Qxd5",
            "Ng5",
            "f4",
            "Ne6",
            "Qe4",
            "g6",
            "f5",
            "Ng5",
            "Qf4",
            "Rce8",
            "h4",
            "Nh7",
            "Qxh6",
            "Qxe5",
            "fxg6",
            "fxg6",
            "Qxg6+",
            "Qg7",
            "Rxf8+",
            "Rxf8",
            "Qxg7+",
            "Kxg7",
            "Bxh7",
            "Kxh7",
            "Rf1",
            "Re8",
            "Rf7+",
            "Kg6",
            "Rxa7",
            "Rxe3",
            "Rb7",
            "Re6",
            "g4",
            "Re4",
            "Rxb6+",
            "Kg7",
            "Kf2",
            "Rxg4",
            "h5",
            "Rh4",
            "h6+",
            "Kh7",
            "Ke3",
            "Rh2",
            "Kd3",
            "Rh4",
            "Kc3",
            "Rg4",
            "b3",
            "Rh4",
            "a4",
            "Rg4",
            "a5",
            "Rg1",
            "a6",
            "Ra1",
            "Kc4",
            "Ra5",
            "Rc6",
            "Kh8",
            "Rxc5",
            "Rxa6",
            "Rh5",
            "Kh7",
            "b4",
            "Ra1",
            "b5",
            "Rc1+",
            "Kd5",
            "Rd1+",
            "Kc6",
            "Rc1+",
            "Kb7",
            "Rb1",
            "b6",
            "Rb2",
            "Kc7",
            "Rc2+",
            "Kb8",
            "Rb2",
            "b7",
            "Rb1",
            "Rc5",
            "Kxh6",
            "Kc7",
            "b8=Q",
            "Rxb8",
            "Kxb8",
            "Kg6",
            "Kc7",
            "Kf6",
            "Kd6",
            "Kf7",
            "Re5",
            "Kf6",
            "Kd5",
            "Kf7",
            "Re6",
            "Kg7",
            "Ke5",
            "Kf7",
            "Kf5",
            "Kg7",
            "Rf6",
            "Kh7",
            "Rg6",
            "Kh8",
            "Kf6",
            "Kh7",
            "Kf7",
            "Kh8",
            "Rh6#",
            "Qc7",
            "Qc7",
            "Qc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3e5",
          "positional_uci": "f3e5",
          "neutral_uci": "f3e5",
          "consensus_move": "f3e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxe5",
              "dxe5",
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxe5",
              "dxe5",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "Qxd5",
              "Ng5",
              "f4",
              "Rfd8",
              "Qc4",
              "Ne6",
              "Qe4",
              "g6",
              "f5",
              "Ng5",
              "Qf4",
              "Rd2",
              "fxg6",
              "fxg6",
              "Bxg6",
              "Rf8",
              "Qc4+",
              "Kg7",
              "Rxf8",
              "Qxf8",
              "Rf1",
              "Qe7",
              "Qc3",
              "Rd8",
              "Bc2",
              "Ne6",
              "Rf6",
              "Nf8",
              "e4",
              "Nh7",
              "Qg3+",
              "Kh8",
              "Rxh6",
              "Rg8",
              "Qh3",
              "Rg7",
              "e6",
              "Kg8",
              "e5",
              "Qg5",
              "Bxh7+",
              "Kf8",
              "Rf6+",
              "Ke7",
              "Rf7+",
              "Rxf7",
              "exf7",
              "Qc1+",
              "Kf2",
              "Qxb2+",
              "Kg3",
              "Qxe5+",
              "Kh4",
              "Qf6+",
              "Kg3",
              "Qe5+",
              "Kf2",
              "Qf6+",
              "Qf3",
              "Qd4+",
              "Kg3",
              "Qg7+",
              "Kh3",
              "Qxh7+",
              "Kg3",
              "Qg7+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6+",
              "Kg3",
              "Qg5+",
              "Kh3",
              "Qh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxe5",
              "dxe5",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "Qxd5",
              "Ng5",
              "f4",
              "Ne6",
              "Qe4",
              "g6",
              "f5",
              "Ng5",
              "Qf4",
              "Rce8",
              "h4",
              "Nh7",
              "Qxh6",
              "Qxe5",
              "fxg6",
              "fxg6",
              "Qxg6+",
              "Qg7",
              "Rxf8+",
              "Rxf8",
              "Qxg7+",
              "Kxg7",
              "Bxh7",
              "Kxh7",
              "Rf1",
              "Re8",
              "Rf7+",
              "Kg6",
              "Rxa7",
              "Rxe3",
              "Rb7",
              "Re6",
              "g4",
              "Re4",
              "Rxb6+",
              "Kg7",
              "Kf2",
              "Rxg4",
              "h5",
              "Rh4",
              "h6+",
              "Kh7",
              "Ke3",
              "Rh2",
              "Kd3",
              "Rh4",
              "Kc3",
              "Rg4",
              "b3",
              "Rh4",
              "a4",
              "Rg4",
              "a5",
              "Rg1",
              "a6",
              "Ra1",
              "Kc4",
              "Ra5",
              "Rc6",
              "Kh8",
              "Rxc5",
              "Rxa6",
              "Rh5",
              "Kh7",
              "b4",
              "Ra1",
              "b5",
              "Rc1+",
              "Kd5",
              "Rd1+",
              "Kc6",
              "Rc1+",
              "Kb7",
              "Rb1",
              "b6",
              "Rb2",
              "Kc7",
              "Rc2+",
              "Kb8",
              "Rb2",
              "b7",
              "Rb1",
              "Rc5",
              "Kxh6",
              "Kc7",
              "b8=Q",
              "Rxb8",
              "Kxb8",
              "Kg6",
              "Kc7",
              "Kf6",
              "Kd6",
              "Kf7",
              "Re5",
              "Kf6",
              "Kd5",
              "Kf7",
              "Re6",
              "Kg7",
              "Ke5",
              "Kf7",
              "Kf5",
              "Kg7",
              "Rf6",
              "Kh7",
              "Rg6",
              "Kh8",
              "Kf6",
              "Kh7",
              "Kf7",
              "Kh8",
              "Rh6#",
              "Qc7",
              "Qc7",
              "Qc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 522,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 1802,
          "total_tokens": 2437
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 522,
            "total_tokens": 733,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pbqnbpp1/1p3n1p/2pp4/3P3B/2NQPN2/PP3PPP/1BR2RK1 w - - 4 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxe5",
          "aggressive_uci": "d4e5",
          "aggressive_response": "15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 17. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7# 1-0 cxd4 18. Qh7#",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#",
            "cxd4",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxe5",
          "positional_uci": "d4e5",
          "positional_response": "15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxe5",
          "neutral_uci": "d4e5",
          "neutral_response": "15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 640,
            "total_tokens": 859,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe5",
            "Bxf6",
            "Bxf6",
            "Qh7#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4e5",
          "positional_uci": "d4e5",
          "neutral_uci": "d4e5",
          "consensus_move": "d4e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#",
              "cxd4",
              "Qh7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxe5",
              "Bxf6",
              "Bxf6",
              "Qh7#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 640,
            "total_tokens": 859,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 1920,
          "total_tokens": 2579
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 640,
            "total_tokens": 860,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 640,
            "total_tokens": 859,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "2r2rk1/pbq1bpp1/1p3n1p/2ppn3/3P3B/2NQP3/PP3PPP/1BR2RK1 w - - 0 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": "h4f6",
          "aggressive_response": "16. Bxf6 Bxf6 17. Qh7# cxd5 e4 Bxe4 Qh8#",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 28,
            "total_tokens": 257,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh7#",
            "cxd5",
            "e4",
            "Bxe4",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf6",
          "positional_uci": "h4f6",
          "positional_response": "16. Bxf6 Bxf6 17. Qh7# d5 18. Qh8# d4 19. Qh7# d3",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 36,
            "total_tokens": 265,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh7#",
            "d5",
            "Qh8#",
            "d4",
            "Qh7#",
            "d3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "h4f6",
          "neutral_response": "16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qh7# 1-0 1-0",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 304,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4f6",
          "positional_uci": "h4f6",
          "neutral_uci": "h4f6",
          "consensus_move": "h4f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh7#",
              "cxd5",
              "e4",
              "Bxe4",
              "Qh8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qh7#",
              "d5",
              "Qh8#",
              "d4",
              "Qh7#",
              "d3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 28,
            "total_tokens": 257,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 36,
            "total_tokens": 265,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 304,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 368,
          "total_tokens": 1054
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 28,
            "total_tokens": 257,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 36,
            "total_tokens": 265,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 304,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pb2bpp1/1p3n1p/2ppq3/7B/2NQP3/PP3PPP/1BR2RK1 w - - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh7#",
          "aggressive_uci": "d3h7",
          "aggressive_response": "17. Qh7# gxf6 18. Qh7# Kh8 19. Qxh6+ Kg8 20. Qh7# Kh8 21. Qxh6+ Kg8 22. Qh7# Kh8 23. Qxh6+ Kg8 24. Qh7# Kh8 25. Qxh6+ Kg8 26. Qh7# Kh8 27. Qxh6+ Kg8 28. Qh7# Kh8 29. Qxh6+ Kg8 30. Qh7# Kh8 31. Qxh6+ Kg8 32. Qh7# Kh8 33. Qxh6+ Kg8 34. Qh7# Kh8 35. Qxh6+ Kg8 36. Qh7# Kh8 37. Qxh6+ Kg8 38. Qh7# Kh8 39. Qxh6+ Kg8 40. Qh7# Kh8 41. Qxh6+ Kg8 42. Qh7# Kh8 43. Qxh6+ Kg8 44. Qh7# Kh8 45. Qxh6+ Kg8 46. Qh7# Kh8 47. Qxh6+ Kg8 48. Qh7# Kh8 49. Qxh6+ Kg8 50. Qh7# Kh8 51. Qxh6+ Kg8 52. Qh7# Kh8 53. Qxh6+ Kg8 54. Qh7# Kh8 55. Qxh6+ Kg8 56. Qh7# Kh8 57. Qxh6+ Kg8 58. Qh7# Kh8 59. Qxh6+ Kg8 60. Qh7# Kh8 61. Qxh6+ Kg8 62. Qh7# Kh8 63. Qxh6+ Kg8 64. Qh7# Kh8 65. Qxh6+ Kg8 66. Qh7# Kh8 67. Qxh6+ Kg8 68. Qh7# Kh8 69. Qxh6+ Kg8 70. Qh7# Kh8 71. Qxh6+ Kg8 72. Qh7# Kh8 73. Qxh6+ Kg8 74. Qh7# Kh8 75. Qxh6+ Kg8 76. Qh7# Kh8 77. Qxh6+ Kg8 78. Qh7# Kh8 79. Qxh6+ Kg8 80. Qh7# Kh8 81. Qxh6+ Kg8 82. Qh7# Kh8 83. Qxh6+ Kg8 84.",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 640,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh8",
            "Qxh6+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qh7#",
          "positional_uci": "d3h7",
          "positional_response": "17. Qh7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5\n15. dxe5 Qxe5 16. Bxf6 gxf6 17. Qh7# 1-0\nd4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 c5 cxd5 exd5 Bb1 Rc8 Qd3 Qc7 Ne5 Nxe5 dxe5 Qxe5 Bxf6 gxf6 Qh7#",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 236,
            "total_tokens": 474,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh7#",
          "neutral_uci": "d3h7",
          "neutral_response": "17. Qh7# gxf6 18. Qh7# Kh8 19. Qxh6+ Kg8 20. Qh7# Kh8 21. Qxh6+ Kg8 22. Qh7# Kh8 23. Qxh6+ Kg8 24. Qh7# Kh8 25. Qxh6+ Kg8 26. Qh7# Kh8 27. Qxh6+ Kg8 28. Qh7# Kh8 29. Qxh6+ Kg8 30. Qh7# Kh8 31. Qxh6+ Kg8 32. Qh7# Kh8 33. Qxh6+ Kg8 34. Qh7# Kh8 35. Qxh6+ Kg8 36. Qh7# Kh8 37. Qxh6+ Kg8 38. Qh7# Kh8 39. Qxh6+ Kg8 40. Qh7# Kh8 41. Qxh6+ Kg8 42. Qh7# Kh8 43. Qxh6+ Kg8 44. Qh7# Kh8 45. Qxh6+ Kg8 46. Qh7# Kh8 47. Qxh6+ Kg8 48. Qh7# Kh8 49. Qxh6+ Kg8 50. Qh7# Kh8 51. Qxh6+ Kg8 52. Qh7# Kh8 53. Qxh6+ Kg8 54. Qh7# Kh8 55. Qxh6+ Kg8 56. Qh7# Kh8 57. Qxh6+ Kg8 58. Qh7# Kh8 59. Qxh6+ Kg8 60. Qh7# Kh8 61. Qxh6+ Kg8 62. Qh7# Kh8 63. Qxh6+ Kg8 64. Qh7# Kh8 65. Qxh6+ Kg8 66. Qh7# Kh8 67. Qxh6+ Kg8 68. Qh7# Kh8 69. Qxh6+ Kg8 70. Qh7# Kh8 71. Qxh6+ Kg8 72. Qh7# Kh8 73. Qxh6+ Kg8 74. Qh7# Kh8 75. Qxh6+ Kg8 76. Qh7# Kh8 77. Qxh6+ Kg8 78. Qh7# Kh8 79. Qxh6+ Kg8 80. Qh7# Kh8 81. Qxh6+ Kg8 82. Qh7# Kh8 83. Qxh6+ Kg8 84.",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh8",
            "Qxh6+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3h7",
          "positional_uci": "d3h7",
          "neutral_uci": "d3h7",
          "consensus_move": "d3h7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kh8",
              "Qxh6+",
              "Kg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kh8",
              "Qxh6+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 640,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 236,
            "total_tokens": 474,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 1516,
          "total_tokens": 2229
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 640,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 236,
            "total_tokens": 474,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 640,
            "total_tokens": 877,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "2r2rk1/pb2bp2/1p3p1p/2ppq3/8/2NQP3/PP3PPP/1BR2RK1 w - - 0 17"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5\n11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Qf3 Bg4\n16. Qg2 Qh5 17. Be3 Rae8 18. Nd2 Re6 19. a4 b4 20. c4 Nxe3\n21. Rxe3 Rxe3 22. fxe3 c5 23. Re1 Re8 24. Qc6 Rd8 25. Ne4 Bf3\n26. Bd1 Bxd1 27. Nxd6 Bf3 28. Qc7 Rf8 29. Qxc5 Qh3 30. Re2 Bxe2\n31. Qf5 Bg4 32. Qf4 Be6 33. d5 Bd7 34. c5 Bxa4 35. c6 Bb3\n36. e4 Qh5 37. c7 Qd1+ 38. Kg2 Qc2+ 39. Kh3 Qxc7 40. Nf5 Qxf4\n41. gxf4 Re8 42. d6 Be6 43. Kg3 Bxf5 44. exf5 Rd8 45. Kf3 Rxd6\n46. Ke4 a5 47. Ke5 Rd2 48. b3 a4 49. bxa4 b3 50. a5 b2\n51. a6 b1=Q 52. a7 Qb5+ 53. Ke4 Qd5+ 54. Ke3 Qd3# 1-0\n55. f6 gxf6 56. a8=Q+ Kg7 57. Qf3 Qd4#",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 465,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Qh5",
            "Be3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "b4",
            "c4",
            "Nxe3",
            "Rxe3",
            "Rxe3",
            "fxe3",
            "c5",
            "Re1",
            "Re8",
            "Qc6",
            "Rd8",
            "Ne4",
            "Bf3",
            "Bd1",
            "Bxd1",
            "Nxd6",
            "Bf3",
            "Qc7",
            "Rf8",
            "Qxc5",
            "Qh3",
            "Re2",
            "Bxe2",
            "Qf5",
            "Bg4",
            "Qf4",
            "Be6",
            "d5",
            "Bd7",
            "c5",
            "Bxa4",
            "c6",
            "Bb3",
            "e4",
            "Qh5",
            "c7",
            "Qd1+",
            "Kg2",
            "Qc2+",
            "Kh3",
            "Qxc7",
            "Nf5",
            "Qxf4",
            "gxf4",
            "Re8",
            "d6",
            "Be6",
            "Kg3",
            "Bxf5",
            "exf5",
            "Rd8",
            "Kf3",
            "Rxd6",
            "Ke4",
            "a5",
            "Ke5",
            "Rd2",
            "b3",
            "a4",
            "bxa4",
            "b3",
            "a5",
            "b2",
            "a6",
            "b1=Q",
            "a7",
            "Qb5+",
            "Ke4",
            "Qd5+",
            "Ke3",
            "Qd3#",
            "f6",
            "gxf6",
            "a8=Q+",
            "Kg7",
            "Qf3",
            "Qd4#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Kf7\n39. Bxb5 Bxb5 40. Rxb5 Rc8 41. Rb4 Rc1+ 42. Kh2 Rc2\n43. Kg3 Nc6 44. Rxa4 Rxb2 45. Ra6 Nb4 46. Ra7+ Kg6\n47. Nh4+ Kh6 48. Nf5+ Kg6 49. Rg7+ Kh5 50. Rxh7+ Kg6\n51. Rg7+ Kh5 52. Kf3 Nd3 53. g4# Nxf2 54. Rh7+ Kg6\n55. Rh6+ Kf7 56. Rh7+ Kg6 57. Rg7# Nxe4 58. Kxe4 Rxa2\n59. h4 Ra4+ 60. Kf3 Rf4+ 61. Kg3 Rxf5 62. gxf5+ Kxg7\n63. Kg4 Kh6 64. h5 Kg7 65. Kh4 Kh6 66. Kg4 Kg7\n67. Kh4 Kh6 68. Kg4 Kg7 69. Kh4 Kh6 70. Kg4 Kg7\n71. Kh4 Kh6 72. Kg4 Kg7 73. Kh4 Kh6 74. Kg4 Kg7\n75. Kh4 Kh6 76. Kg4 Kg7 77. Kh4 Kh6 78. Kg4 Kg7\n79. Kh4 Kh6 80. Kg4 Kg7",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Kf7",
            "Bxb5",
            "Bxb5",
            "Rxb5",
            "Rc8",
            "Rb4",
            "Rc1+",
            "Kh2",
            "Rc2",
            "Kg3",
            "Nc6",
            "Rxa4",
            "Rxb2",
            "Ra6",
            "Nb4",
            "Ra7+",
            "Kg6",
            "Nh4+",
            "Kh6",
            "Nf5+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Rxh7+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Kf3",
            "Nd3",
            "g4#",
            "Nxf2",
            "Rh7+",
            "Kg6",
            "Rh6+",
            "Kf7",
            "Rh7+",
            "Kg6",
            "Rg7#",
            "Nxe4",
            "Kxe4",
            "Rxa2",
            "h4",
            "Ra4+",
            "Kf3",
            "Rf4+",
            "Kg3",
            "Rxf5",
            "gxf5+",
            "Kxg7",
            "Kg4",
            "Kh6",
            "h5",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh6",
            "Kg4",
            "Kg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Bb7\n10. d4 Re8 11. Nbd2 Bf8 12. a4 h6\n13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5\n16. d5 Nd7 17. Ra3 f5 18. Rae3 fxe4\n19. Nxe4 Nxd5 20. Ba2 c4 21. Nxd6 Rxe3\n22. Nxb7 Rxe1+ 23. Nxe1 Qe7 24. Qxd5+ Kh8\n25. Nf3 Nf6 26. Qc6 Rb8 27. Na5 Qd8\n28. Bd2 Bb4 29. Bxb4 Qd1+ 30. Kh2 Qxa4\n31. Qd6 Re8 32. Bb1 Qa1 33. Bg6 Rc8\n34. Bc3 Qc1 35. Bxf6 gxf6 36. Qxf6+ Kg8\n37. Qf7+ Kh8 38. Qh7# e5 Nf6 Qf4",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 318,
            "total_tokens": 431,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Qf4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Qh5",
              "Be3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "b4",
              "c4",
              "Nxe3",
              "Rxe3",
              "Rxe3",
              "fxe3",
              "c5",
              "Re1",
              "Re8",
              "Qc6",
              "Rd8",
              "Ne4",
              "Bf3",
              "Bd1",
              "Bxd1",
              "Nxd6",
              "Bf3",
              "Qc7",
              "Rf8",
              "Qxc5",
              "Qh3",
              "Re2",
              "Bxe2",
              "Qf5",
              "Bg4",
              "Qf4",
              "Be6",
              "d5",
              "Bd7",
              "c5",
              "Bxa4",
              "c6",
              "Bb3",
              "e4",
              "Qh5",
              "c7",
              "Qd1+",
              "Kg2",
              "Qc2+",
              "Kh3",
              "Qxc7",
              "Nf5",
              "Qxf4",
              "gxf4",
              "Re8",
              "d6",
              "Be6",
              "Kg3",
              "Bxf5",
              "exf5",
              "Rd8",
              "Kf3",
              "Rxd6",
              "Ke4",
              "a5",
              "Ke5",
              "Rd2",
              "b3",
              "a4",
              "bxa4",
              "b3",
              "a5",
              "b2",
              "a6",
              "b1=Q",
              "a7",
              "Qb5+",
              "Ke4",
              "Qd5+",
              "Ke3",
              "Qd3#",
              "f6",
              "gxf6",
              "a8=Q+",
              "Kg7",
              "Qf3",
              "Qd4#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Kf7",
              "Bxb5",
              "Bxb5",
              "Rxb5",
              "Rc8",
              "Rb4",
              "Rc1+",
              "Kh2",
              "Rc2",
              "Kg3",
              "Nc6",
              "Rxa4",
              "Rxb2",
              "Ra6",
              "Nb4",
              "Ra7+",
              "Kg6",
              "Nh4+",
              "Kh6",
              "Nf5+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Rxh7+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Kf3",
              "Nd3",
              "g4#",
              "Nxf2",
              "Rh7+",
              "Kg6",
              "Rh6+",
              "Kf7",
              "Rh7+",
              "Kg6",
              "Rg7#",
              "Nxe4",
              "Kxe4",
              "Rxa2",
              "h4",
              "Ra4+",
              "Kf3",
              "Rf4+",
              "Kg3",
              "Rxf5",
              "gxf5+",
              "Kxg7",
              "Kg4",
              "Kh6",
              "h5",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh6",
              "Kg4",
              "Kg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Qf4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 465,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 318,
            "total_tokens": 431,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1423,
          "total_tokens": 1764
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 465,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 318,
            "total_tokens": 431,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Bd7 19. Qxd6 Rc8 20. Rad1 Kf7 21. Qxd7+ Kxf6 22. Qxc8 Ne5 23. Qf5+ Ke7 24. Qxe5+ Kf7 25. Rd7+ Kg6 26. Rg7+ Kh6 27. Qg5# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Bg7 Qe6 Nf6+ Qxf6 Bxf6 Bd7 Qxd6 Rc8 Rad1 Kf7 Qxd7+ Kg6 Qf5+ Kg7 Rd7+ Kg8 Qxh7#",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 377,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Bd7",
            "Qxd6",
            "Rc8",
            "Rad1",
            "Kf7",
            "Qxd7+",
            "Kg6",
            "Qf5+",
            "Kg7",
            "Rd7+",
            "Kg8",
            "Qxh7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "Game 1\n1. e4 e5\n2. Nc3 Nc6\n3. Bc4 Bc5\n4. d3 d6\n5. Nge2 Nf6\n6. O-O O-O\n7. Bg5 Bg4\n8. Nd5 Nd4\n9. Re1 Nxe2+\n10. Rxe2 Bxe2\n11. Qxe2 c6\n12. Nxf6+ gxf6\n13. Bh6 Re8\n14. Qg4+ Kh8\n\n15. Qg7# 1-0\n1. e4 e5\n2. Nc3 Nc6\n3. Bc4 Bc5\n4. d3 d6\n5. Nge2 Nf6\n6. O-O O-O\n7. Bg5 Bg4\n8. Nd5 Nd4\n9. Re1 Nxe2+\n10. Rxe2 Bxe2\n11. Qxe2 c6\n12. Nxf6+ gxf6\n13. Bh6 Re8\n14. Qg4+ Kh8\n15. Qg7# 1-0 e4 e5 Nc3 Nc6 Bc4 Bc5 d3 d6 Nge2 Nf6 O-O O-O Bg5 Bg4 Nd5 Nd4 Re1 Nxe2+ Rxe2 Bxe2 Qxe2 c6 Nxf6+ gxf6 Bh6 Re8 Qg4+ Kh8 Qg7#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 334,
            "total_tokens": 444,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nc3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6",
            "Nge2",
            "Nf6",
            "O-O",
            "O-O",
            "Bg5",
            "Bg4",
            "Nd5",
            "Nd4",
            "Re1",
            "Nxe2+",
            "Rxe2",
            "Bxe2",
            "Qxe2",
            "c6",
            "Nxf6+",
            "gxf6",
            "Bh6",
            "Re8",
            "Qg4+",
            "Kh8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 d5 2. Nf3 Nf6 3. Bg5 Bf5 4. e3 e6 5. Bd3 Bxd3 6. Qxd3 Be7\n7. O-O O-O 8. Nbd2 Nbd7 9. c4 c6 10. Rac1 Rc8 11. cxd5 cxd5\n12. Rxc8 Qxc8 13. Nb3 Qc4 14. Qxc4 dxc4 15. Nbd2 b5 16. Rc1 Rc8\n17. Ne5 Nxe5 18. dxe5 Nd5 19. Bxe7 Nxe7 20. Ne4 Nc6 21. Nd6 Rb8\n22. f4 Nb4 23. a3 Nd3 24. Rc2 Kf8 25. Kf1 Ke7 26. Ke2 f6\n27. Ne4 fxe5 28. fxe5 Nxe5 29. Nc5 Rc8 30. Na6 Nd3 31. Nb4 Nxb4\n32. axb4 Kd6 33. Rd2+ Ke5 34. Rd7 a6 35. Rxg7 c3 36. bxc3 Rxc3\n37. Rxh7 Rb3 38. Rh4 Kd5 39. Rd4+ Ke5 40. h4 Kf5 41. g4+ Kg6\n42. Kf3 e5 43. Re4 Kf6 44. g5+ Kf5 45. Rg4 Rb1 46. Rg2 Rxb4\n47. g6 e4+ 48. Kg3 Kxg6 49. Kf4+ Kh5 50. Rg5+ Kxh4 51. Rg6 Kh5\n52. Rxa6 Ra4 53. Rb6 b4 54. Kxe4 b3+ 55. Kd3 Ra3 56. Kc3 b2+\n57. Kxb2 Rxe3 58. Rb5+ Kg4 59. Rb4+ Kf3 60. Rb3 Rxb3+ 61. Kxb3\nRg8 62. Kc4 Ke4 63. Kc5 Rg6 64. Kc4 Rc6+ 65. Kb5 Kd5 66. Kb4\nRc5 67. Kb3 Kd4 68. Kb4 Kd5 69. Kb3 Rc4 70. Kb2 Kd4 71. Kb3 Kd3\n72. Kb2 Rc3 73. Kb1 Rc2 74. Ka1 Kc3 75. Kb1 Kb3 76. Ka1 Rc1#\nd4 d5 2. Nf3 Nf6 3. Bg",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Bg7",
              "Qe6",
              "Nf6+",
              "Qxf6",
              "Bxf6",
              "Bd7",
              "Qxd6",
              "Rc8",
              "Rad1",
              "Kf7",
              "Qxd7+",
              "Kg6",
              "Qf5+",
              "Kg7",
              "Rd7+",
              "Kg8",
              "Qxh7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nc3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6",
              "Nge2",
              "Nf6",
              "O-O",
              "O-O",
              "Bg5",
              "Bg4",
              "Nd5",
              "Nd4",
              "Re1",
              "Nxe2+",
              "Rxe2",
              "Bxe2",
              "Qxe2",
              "c6",
              "Nxf6+",
              "gxf6",
              "Bh6",
              "Re8",
              "Qg4+",
              "Kh8",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf3",
              "Nf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 377,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 334,
            "total_tokens": 444,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1351,
          "total_tokens": 1680
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 377,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 334,
            "total_tokens": 444,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nc6 *\n3. Bb5 a6 *\n4. Ba4 Nf6 *\n5. O-O Be7 *\n6. Re1 b5 *\n7. Bb3 d6 *\n8. c3 O-O *\n9. h3 Na5 *\n10. Bc2 c5 *\n11. d4 Qc7 *\n12. Nbd2 cxd4 *\n13. cxd4 Nc6 *\n14. Nb3 a5 *\n15. Be3 a4 *\n16. Nbd2 Bd7 *\n17. Rc1 Qb7 *\n18. Bb1 Rfc8 *\n19. Nf1 Bd8 *\n20. Ng3 Bb6 *\n21. Qd2 Ba5 *\n22. Qe2 Bxe1 *\n23. Rxe1 exd4 *\n24. Nxd4 Nxd4 *\n25. Bxd4 Ne8 *\n26. Qh5 g6 *\n27. Qh6 Be6 *\n28. Nh5 f6 *\n29. Nxf6+ Nxf6 *\n30. Bxf6 Qf7 *\n31. Bd4 Bxa2 *\n32. Bd3 Bc4 *\n33. Bb1 Re8 *\n34. Re3 Re7 *\n35. Rf3 Qe6 *\n36. Rf6 Qd7 *\n37. e5 dxe5 *\n38. Bc5 Rg7 *\n39. Be4 Re8 *\n40. Bc6 Qd1+ *\n41. Kh2 Rc8 *\n42. Rd6 Qh5 *\n43. Qd2 Rgc7 *\n44. Rd8+ Kg7 *\n45. Bf8+ Kf7 *\n46. Be8+ Kf6 *\n47. Rd6+ Be6 *\n48. Bd7 Rxd7 *\n49. Rxd7 Bxd7 *\n50. Qxd7 Rxf8 *\n51. Qd6+ Kg7 *\n52. Qe7+ Rf7 *\n53. Qe6 Qf5 *\n54. Qd5 Qf4+ *\n55. Kh1 Qxf2 *\n56. Qxe5+ Qf6 *\n57. Qxb5 Qf1+ *\n58. Qxf1 Rxf1+ *\n59. Kh2 Rb1 *\n60. Kg3 Rxb2 *\n61. Kf3 a3 *\n62. Ke3 a2 *\n63. Kd3 a1=Q *\n64. Kc3 Qc1+ *\n65. Kd3 Rd2+ *\n66. Ke3 Qe1+ *\n67. Kf3 Rf2+ *\n68. Kg3 Qe3+ *\n69. Kh2 Q",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "exd4",
            "Nxd4",
            "Nxd4",
            "Bxd4",
            "Ne8",
            "Qh5",
            "g6",
            "Qh6",
            "Be6",
            "Nh5",
            "f6",
            "Nxf6+",
            "Nxf6",
            "Bxf6",
            "Qf7",
            "Bd4",
            "Bxa2",
            "Bd3",
            "Bc4",
            "Bb1",
            "Re8",
            "Re3",
            "Re7",
            "Rf3",
            "Qe6",
            "Rf6",
            "Qd7",
            "e5",
            "dxe5",
            "Bc5",
            "Rg7",
            "Be4",
            "Re8",
            "Bc6",
            "Qd1+",
            "Kh2",
            "Rc8",
            "Rd6",
            "Qh5",
            "Qd2",
            "Rgc7",
            "Rd8+",
            "Kg7",
            "Bf8+",
            "Kf7",
            "Be8+",
            "Kf6",
            "Rd6+",
            "Be6",
            "Bd7",
            "Rxd7",
            "Rxd7",
            "Bxd7",
            "Qxd7",
            "Rxf8",
            "Qd6+",
            "Kg7",
            "Qe7+",
            "Rf7",
            "Qe6",
            "Qf5",
            "Qd5",
            "Qf4+",
            "Kh1",
            "Qxf2",
            "Qxe5+",
            "Qf6",
            "Qxb5",
            "Qf1+",
            "Qxf1",
            "Rxf1+",
            "Kh2",
            "Rb1",
            "Kg3",
            "Rxb2",
            "Kf3",
            "a3",
            "Ke3",
            "a2",
            "Kd3",
            "a1=Q",
            "Kc3",
            "Qc1+",
            "Kd3",
            "Rd2+",
            "Ke3",
            "Qe1+",
            "Kf3",
            "Rf2+",
            "Kg3",
            "Qe3+",
            "Kh2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nc6 *\n3. Bb5 a6 *\n4. Ba4 Nf6 *\n5. O-O Be7 *\n6. Re1 b5 *\n7. Bb3 d6 *\n8. c3 O-O *\n9. h3 Na5 *\n10. Bc2 c5 *\n11. d4 Qc7 *\n12. Nbd2 cxd4 *\n13. cxd4 Nc6 *\n14. Nb3 a5 *\n15. Be3 a4 *\n16. Nbd2 Bd7 *\n17. Rc1 Qb7 *\n18. Bb1 Rfc8 *\n19. Nf1 Bd8 *\n20. Ng3 Bb6 *\n21. Qd2 Ba5 *\n22. Qe2 Bxe1 *\n23. Rxe1 Re8 *\n24. d5 Ne7 *\n25. Nh4 Rac8 *\n26. Bg5 Kh8 *\n27. Bxf6 gxf6 *\n28. Qh5 Rf8 *\n29. Qh6 Ng8 *\n30. Qh5 Ne7 *\n31. Qh6 Ng8 *\n32. Qh5 Ne7 *\n33. Qh6 Ng8 *\n34. Qh5 Ne7 *\n35. Qh6 Ng8 *\n36. Qh5 Ne7 *\n37. Qh6 Ng8 *\n38. Qh5 Ne7 *\n39. Qh6 Ng8 *\n40. Qh5 Ne7 *\n41. Qh6 Ng8 *\n42. Qh5 Ne7 *\n43. Qh6 Ng8 *\n44. Qh5 Ne7 *\n45. Qh6 Ng8 *\n46. Qh5 Ne7 *\n47. Qh6 Ng8 *\n48. Qh5 Ne7 *\n49. Qh6 Ng8 *\n50. Qh5 Ne7 *\n51. Qh6 Ng8 *\n52. Qh5 Ne7 *\n53. Qh6 Ng8 *\n54. Qh5 Ne7 *\n55. Qh6 Ng8 *\n56. Qh5 Ne7 *\n57. Qh6 Ng8 *\n58. Qh5 Ne7 *\n59. Qh6 Ng8 *\n60. Qh5 Ne7 *\n61. Qh6 Ng8 *\n62. Qh5 Ne7 *\n63. Qh6 Ng8 *\n64. Qh5 Ne7 *\n65. Qh6 Ng8 *\n66. Qh5 Ne7 *\n67. Qh6 Ng8 *\n68. Qh5 Ne7 *\n69. Qh6 Ng8 *\n70. Qh5 Ne7 *\n71. Qh6 Ng8 *\n72. Qh5 Ne7 *\n73",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh5",
            "Rf8",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7",
            "Qh6",
            "Ng8",
            "Qh5",
            "Ne7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nc6 *\n3. Bb5 a6 *\n4. Ba4 Nf6 *\n5. O-O Be7 *\n6. Re1 b5 *\n7. Bb3 d6 *\n8. c3 O-O *\n9. h3 Na5 *\n10. Bc2 c5 *\n11. d4 Qc7 *\n12. Nbd2 cxd4 *\n13. cxd4 Nc6 *\n14. Nb3 a5 *\n15. Be3 a4 *\n16. Nbd2 Bd7 *\n17. Rc1 Qb7 *\n18. Bb1 Rfc8 *\n19. Nf1 Bd8 *\n20. Ng3 Bb6 *\n21. Qd2 Ba5 *\n22. Qe2 Bxe1 *\n23. Rxe1 Re8 *\n24. Qd2 Rac8 *\n25. Bg5 Kh8 *\n26. Bxf6 gxf6 *\n27. Qh6 Rg8 *\n28. Qxf6+ Rg7 *\n29. Nh5 Rg8 *\n30. Ng5 Be8 *\n31. Nxg7 Rxg7 *\n32. dxe5 dxe5 *\n33. Rd1 Qe7 *\n34. Qxe7 Nxe7 *\n35. Rd8 Rxg5 *\n36. Rxe8+ Ng8 *\n37. Bd3 Kg7 *\n38. Bxb5 Nf6 *\n39. Ra8 Nxe4 *\n40. Rxa4 Nd6 *\n41. Be2 e4 *\n42. Rd4 Rg6 *\n43. a4 f5 *\n44. a5 Nc8 *\n45. a6 Rc6 *\n46. Rc4 Rxc4 *\n47. Bxc4 Kf6 *\n48. b4 Ke7 *\n49. b5 Kd6 *\n50. Bxf7 Kc5 *\n51. Be6 Nb6 *\n52. Bxf5 Kxb5 *\n53. a7 Ka6 *\n54. Bxe4 Kxa7 *\n55. Bxh7 Kb7 *\n56. h4 Kc7 *\n57. h5 Kd7 *\n58. h6 Ke7 *\n59. Bg6 Kf6 *\n60. h7 Kg7 *\n61. f4 Nd5 *\n62. f5 Nf6 *\n63. Kf2 Ng4+ *\n64. Kf3 Nf6 *\n65. Kf4 Nd5+ *\n66. Ke5 Nf6 *\n67. h8=Q+ Kxh8 *\n68. Kxf6 Kg8 *\n69. Ke7 Kg7 *\n70. f6+ Kxg6 *\n71. f7 Kg5 *",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rxg5",
            "Rxe8+",
            "Ng8",
            "Bd3",
            "Kg7",
            "Bxb5",
            "Nf6",
            "Ra8",
            "Nxe4",
            "Rxa4",
            "Nd6",
            "Be2",
            "e4",
            "Rd4",
            "Rg6",
            "a4",
            "f5",
            "a5",
            "Nc8",
            "a6",
            "Rc6",
            "Rc4",
            "Rxc4",
            "Bxc4",
            "Kf6",
            "b4",
            "Ke7",
            "b5",
            "Kd6",
            "Bxf7",
            "Kc5",
            "Be6",
            "Nb6",
            "Bxf5",
            "Kxb5",
            "a7",
            "Ka6",
            "Bxe4",
            "Kxa7",
            "Bxh7",
            "Kb7",
            "h4",
            "Kc7",
            "h5",
            "Kd7",
            "h6",
            "Ke7",
            "Bg6",
            "Kf6",
            "h7",
            "Kg7",
            "f4",
            "Nd5",
            "f5",
            "Nf6",
            "Kf2",
            "Ng4+",
            "Kf3",
            "Nf6",
            "Kf4",
            "Nd5+",
            "Ke5",
            "Nf6",
            "h8=Q+",
            "Kxh8",
            "Kxf6",
            "Kg8",
            "Ke7",
            "Kg7",
            "f6+",
            "Kxg6",
            "f7",
            "Kg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "exd4",
              "Nxd4",
              "Nxd4",
              "Bxd4",
              "Ne8",
              "Qh5",
              "g6",
              "Qh6",
              "Be6",
              "Nh5",
              "f6",
              "Nxf6+",
              "Nxf6",
              "Bxf6",
              "Qf7",
              "Bd4",
              "Bxa2",
              "Bd3",
              "Bc4",
              "Bb1",
              "Re8",
              "Re3",
              "Re7",
              "Rf3",
              "Qe6",
              "Rf6",
              "Qd7",
              "e5",
              "dxe5",
              "Bc5",
              "Rg7",
              "Be4",
              "Re8",
              "Bc6",
              "Qd1+",
              "Kh2",
              "Rc8",
              "Rd6",
              "Qh5",
              "Qd2",
              "Rgc7",
              "Rd8+",
              "Kg7",
              "Bf8+",
              "Kf7",
              "Be8+",
              "Kf6",
              "Rd6+",
              "Be6",
              "Bd7",
              "Rxd7",
              "Rxd7",
              "Bxd7",
              "Qxd7",
              "Rxf8",
              "Qd6+",
              "Kg7",
              "Qe7+",
              "Rf7",
              "Qe6",
              "Qf5",
              "Qd5",
              "Qf4+",
              "Kh1",
              "Qxf2",
              "Qxe5+",
              "Qf6",
              "Qxb5",
              "Qf1+",
              "Qxf1",
              "Rxf1+",
              "Kh2",
              "Rb1",
              "Kg3",
              "Rxb2",
              "Kf3",
              "a3",
              "Ke3",
              "a2",
              "Kd3",
              "a1=Q",
              "Kc3",
              "Qc1+",
              "Kd3",
              "Rd2+",
              "Ke3",
              "Qe1+",
              "Kf3",
              "Rf2+",
              "Kg3",
              "Qe3+",
              "Kh2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "d5",
              "Ne7",
              "Nh4",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh5",
              "Rf8",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7",
              "Qh6",
              "Ng8",
              "Qh5",
              "Ne7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rxg5",
              "Rxe8+",
              "Ng8",
              "Bd3",
              "Kg7",
              "Bxb5",
              "Nf6",
              "Ra8",
              "Nxe4",
              "Rxa4",
              "Nd6",
              "Be2",
              "e4",
              "Rd4",
              "Rg6",
              "a4",
              "f5",
              "a5",
              "Nc8",
              "a6",
              "Rc6",
              "Rc4",
              "Rxc4",
              "Bxc4",
              "Kf6",
              "b4",
              "Ke7",
              "b5",
              "Kd6",
              "Bxf7",
              "Kc5",
              "Be6",
              "Nb6",
              "Bxf5",
              "Kxb5",
              "a7",
              "Ka6",
              "Bxe4",
              "Kxa7",
              "Bxh7",
              "Kb7",
              "h4",
              "Kc7",
              "h5",
              "Kd7",
              "h6",
              "Ke7",
              "Bg6",
              "Kf6",
              "h7",
              "Kg7",
              "f4",
              "Nd5",
              "f5",
              "Nf6",
              "Kf2",
              "Ng4+",
              "Kf3",
              "Nf6",
              "Kf4",
              "Nd5+",
              "Ke5",
              "Nf6",
              "h8=Q+",
              "Kxh8",
              "Kxf6",
              "Kg8",
              "Ke7",
              "Kg7",
              "f6+",
              "Kxg6",
              "f7",
              "Kg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1920,
          "total_tokens": 2267
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb5",
          "aggressive_uci": "f1b5",
          "aggressive_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bb8 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qf3 Bg4 26. Qg2 Bh3 27. Qf3 Bg4 28. Qg2 Bh3 29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3 33. Qf3 Bg4 34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3 37. Qf3 Bg4 38. Qg2 Bh3 39. Qf3 Bg4 40. Qg2 Bh3 41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4 44. Qg2 Bh3 45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3 49. Qf3 Bg4 50. Qg2 Bh3 51. Qf3 Bg4 52. Qg2 Bh3 53. Qf3 Bg4 54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3 57. Qf3 Bg4 58. Qg2 Bh3 59. Qf3 Bg4 60. Qg2 Bh3 61. Qf3 Bg4 62. Qg2 Bh3 63. Qf3 Bg4 64. Qg2 Bh3 65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3 69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3 73. Qf3 Bg4 74. Qg2 Bh3 75. Qf3 Bg4 76. Qg2 Bh3 77. Qf3 Bg4 78. Qg2 Bh3 79. Q",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb5",
          "positional_uci": "f1b5",
          "positional_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Ra6 Bf8 24. Rxc6 Bh3 25. Qh1 Rxc6 26. Qxc6 Re6 27. Qf3 Bg4 28. Qa8 g5 29. Ra1 Rh6 30. Qg2 Bh3 31. Qd5 Be6 32. Qxg5+ Qxg5 33. Bxg5 Rg6 34. Be3 b4 35. c4 Bf5 36. Ra8 Kg7 37. d5 Bd6 38. Bd4+ Kh6 39. Ra6 Bf4 40. Rxg6+ hxg6 41. gxf4 Kh5 42. Kg2 Kg4 43. Be3 Bd3 44. c5 Kf5 45. c6 Ba6 46. d6 Ke6 47. d7 Ke7 48. Bc5+ Kd8 49. Bb6+ Ke7 50. d8=Q+ Ke6 51. Qd7+ Kf6 52. Bd4# Bb7 53. cxb7# Kf5 54. Qxf7+ Kg4 55. Qxg6+ Kh4 56. Nf3# Kg4 57. Qg5#",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 455,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Ra6",
            "Bf8",
            "Rxc6",
            "Bh3",
            "Qh1",
            "Rxc6",
            "Qxc6",
            "Re6",
            "Qf3",
            "Bg4",
            "Qa8",
            "g5",
            "Ra1",
            "Rh6",
            "Qg2",
            "Bh3",
            "Qd5",
            "Be6",
            "Qxg5+",
            "Qxg5",
            "Bxg5",
            "Rg6",
            "Be3",
            "b4",
            "c4",
            "Bf5",
            "Ra8",
            "Kg7",
            "d5",
            "Bd6",
            "Bd4+",
            "Kh6",
            "Ra6",
            "Bf4",
            "Rxg6+",
            "hxg6",
            "gxf4",
            "Kh5",
            "Kg2",
            "Kg4",
            "Be3",
            "Bd3",
            "c5",
            "Kf5",
            "c6",
            "Ba6",
            "d6",
            "Ke6",
            "d7",
            "Ke7",
            "Bc5+",
            "Kd8",
            "Bb6+",
            "Ke7",
            "d8=Q+",
            "Ke6",
            "Qd7+",
            "Kf6",
            "Bd4#",
            "Bb7",
            "cxb7#",
            "Kf5",
            "Qxf7+",
            "Kg4",
            "Qxg6+",
            "Kh4",
            "Nf3#",
            "Kg4",
            "Qg5#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb5",
          "neutral_uci": "f1b5",
          "neutral_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 266,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1b5",
          "positional_uci": "f1b5",
          "neutral_uci": "f1b5",
          "consensus_move": "f1b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Ra6",
              "Bf8",
              "Rxc6",
              "Bh3",
              "Qh1",
              "Rxc6",
              "Qxc6",
              "Re6",
              "Qf3",
              "Bg4",
              "Qa8",
              "g5",
              "Ra1",
              "Rh6",
              "Qg2",
              "Bh3",
              "Qd5",
              "Be6",
              "Qxg5+",
              "Qxg5",
              "Bxg5",
              "Rg6",
              "Be3",
              "b4",
              "c4",
              "Bf5",
              "Ra8",
              "Kg7",
              "d5",
              "Bd6",
              "Bd4+",
              "Kh6",
              "Ra6",
              "Bf4",
              "Rxg6+",
              "hxg6",
              "gxf4",
              "Kh5",
              "Kg2",
              "Kg4",
              "Be3",
              "Bd3",
              "c5",
              "Kf5",
              "c6",
              "Ba6",
              "d6",
              "Ke6",
              "d7",
              "Ke7",
              "Bc5+",
              "Kd8",
              "Bb6+",
              "Ke7",
              "d8=Q+",
              "Ke6",
              "Qd7+",
              "Kf6",
              "Bd4#",
              "Bb7",
              "cxb7#",
              "Kf5",
              "Qxf7+",
              "Kg4",
              "Qxg6+",
              "Kh4",
              "Nf3#",
              "Kg4",
              "Qg5#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 455,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 266,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1361,
          "total_tokens": 1735
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 455,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 266,
            "total_tokens": 390,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxc6",
          "aggressive_uci": "b5c6",
          "aggressive_response": "4. Bxc6 dxc6 5. O-O Bg4 6. h3 h5 7. d3 Qf6 8. Nbd2 Ne7 9. Re1 Ng6 10. hxg4 hxg4 11. Nh2 Rxh2 12. Kxh2 Qh4+ 13. Kg1 Bc5 14. d4 Bxd4 15. Re3 O-O-O 16. Qe1 Rh8 17. Kf1 Nf4 18. Rh3 gxh3 19. g3 h2 20. gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re3 O-O-O Qe1 Rh8 Kf1 Nf4 Rh3 gxh3 g3 h2 gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re3 O-O-O Qe1 Rh8 Kf1 Nf4 Rh3 gxh3 g3 h2 gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re3 O-O-O Qe1 Rh8 Kf1 Nf4 Rh3 gxh3 g3 h2 gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re3 O-O-O Qe1 Rh8 Kf1 Nf4 Rh3 gxh3 g3 h2 gxh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h3 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qh4+ Kg1 Bc5 d4 Bxd4 Re",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc6",
            "O-O",
            "Bg4",
            "h3",
            "h5",
            "d3",
            "Qf6",
            "Nbd2",
            "Ne7",
            "Re1",
            "Ng6",
            "hxg4",
            "hxg4",
            "Nh2",
            "Rxh2",
            "Kxh2",
            "Qh4+",
            "Kg1",
            "Bc5",
            "d4",
            "Bxd4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxc6",
          "positional_uci": "b5c6",
          "positional_response": "4. Bxc6 dxc6 5. O-O Bg4 6. h3 h5 7. d3 Qf6 8. Nbd2 Ne7 9. Re1 Ng6 10. d4 O-O-O 11. hxg4 hxg4 12. Nh2 Rxh2 13. Qxg4+ Kb8 14. Kxh2 Qxf2 15. Nf3 Bd6 16. Kh1 Rh8+ 17. Qh3 Rxh3+ 18. gxh3 Qxf3+ 19. Kg1 Nh4 20. Re2 Qxe2 21. Bg5 Qg2# 0-1\n22. Kh1 Qxh3+ 23. Kg1 Qg2#",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 176,
            "total_tokens": 309,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc6",
            "O-O",
            "Bg4",
            "h3",
            "h5",
            "d3",
            "Qf6",
            "Nbd2",
            "Ne7",
            "Re1",
            "Ng6",
            "d4",
            "O-O-O",
            "hxg4",
            "hxg4",
            "Nh2",
            "Rxh2",
            "Qxg4+",
            "Kb8",
            "Kxh2",
            "Qxf2",
            "Nf3",
            "Bd6",
            "Kh1",
            "Rh8+",
            "Qh3",
            "Rxh3+",
            "gxh3",
            "Qxf3+",
            "Kg1",
            "Nh4",
            "Re2",
            "Qxe2",
            "Bg5",
            "Qg2#",
            "Kh1",
            "Qxh3+",
            "Kg1",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxc6",
          "neutral_uci": "b5c6",
          "neutral_response": "4. Bxc6 dxc6 5. O-O Bg4 6. h3 h5 7. d3 Qf6 8. Nbd2 Ne7 9. Re1 Ng6 10. d4 O-O-O 11. hxg4 hxg4 12. Nh2 Rxh2 13. Qxg4+ Kb8 14. Kxh2 Qxf2 15. Nf3 Bd6 16. Kh1 Rh8+ 17. Nh2 Qxe1+ 18. Nf1 Qxf1# 19. Kh2 exd4+ 20. g3 Qf2+ 21. Kh1 Qf1+ 22. Kh2 Ne5 23. Qf5 Nf3+ 24. Qxf3 Qxf3 25. Bf4 Bxf4 26. gxf4 Rxh3+ 27. Kg1 Rh1# 28. Kxh1 Qh3+ 29. Kg1 Qg3+ 30. Kh1 Qxf4 31. Kg1 Qxe4 32. Kh2 Qxc2+ 33. Kh3 Qxb2 34. Kh4 Qxa1 35. Kh5 Qxa2 36. Kg5 Qe6 37. Kh5 Qg6+ 38. Kh4 d3 39. Kh3 d2 40. Kh2 d1=Q 41. Kh3 Qdh5# 42. Kh2 Qhg5 43. Kh3 Qg4+ 44. Kh2 Qg3+ 45. Kh1 Qg2# 46. Kh2 Q6g3# 47. Kh1 Qg4 48. Kh2 Qg5 49. Kh1 Qg6 50. Kh2 Q6g5 51. Kh1 Q5g4 52. Kh2 Qg1# 53. Kh3 Q1g3# 54. Kh1 Qg2# 55. Kh2 Q2g3# 56. Kh1 Qg1# 57. Kh2 Q1g2# 58. Kh1 Qg1# 59. Kh2 Q1g2# 60. Kh1 Qg1# 61. Kh2 Q1g2# 62. Kh1 Qg1# 63. Kh2 Q1g2# 64. Kh1 Qg1# 65. Kh2 Q1g2# 66. Kh1 Qg1# 67. Kh2 Q1g2# 68. Kh1 Qg1# 69. Kh2 Q1g2# 70. Kh1 Qg1# 71. Kh2 Q1g2# 72. Kh1 Qg1# 73. Kh2 Q1g2# 74. Kh1 Qg1# 75. Kh2 Q1g2#",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc6",
            "O-O",
            "Bg4",
            "h3",
            "h5",
            "d3",
            "Qf6",
            "Nbd2",
            "Ne7",
            "Re1",
            "Ng6",
            "d4",
            "O-O-O",
            "hxg4",
            "hxg4",
            "Nh2",
            "Rxh2",
            "Qxg4+",
            "Kb8",
            "Kxh2",
            "Qxf2",
            "Nf3",
            "Bd6",
            "Kh1",
            "Rh8+",
            "Nh2",
            "Qxe1+",
            "Nf1",
            "Qxf1#",
            "Kh2",
            "exd4+",
            "g3",
            "Qf2+",
            "Kh1",
            "Qf1+",
            "Kh2",
            "Ne5",
            "Qf5",
            "Nf3+",
            "Qxf3",
            "Qxf3",
            "Bf4",
            "Bxf4",
            "gxf4",
            "Rxh3+",
            "Kg1",
            "Rh1#",
            "Kxh1",
            "Qh3+",
            "Kg1",
            "Qg3+",
            "Kh1",
            "Qxf4",
            "Kg1",
            "Qxe4",
            "Kh2",
            "Qxc2+",
            "Kh3",
            "Qxb2",
            "Kh4",
            "Qxa1",
            "Kh5",
            "Qxa2",
            "Kg5",
            "Qe6",
            "Kh5",
            "Qg6+",
            "Kh4",
            "d3",
            "Kh3",
            "d2",
            "Kh2",
            "d1=Q",
            "Kh3",
            "Qdh5#",
            "Kh2",
            "Qhg5",
            "Kh3",
            "Qg4+",
            "Kh2",
            "Qg3+",
            "Kh1",
            "Qg2#",
            "Kh2",
            "Q6g3#",
            "Kh1",
            "Qg4",
            "Kh2",
            "Qg5",
            "Kh1",
            "Qg6",
            "Kh2",
            "Q6g5",
            "Kh1",
            "Q5g4",
            "Kh2",
            "Qg1#",
            "Kh3",
            "Q1g3#",
            "Kh1",
            "Qg2#",
            "Kh2",
            "Q2g3#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Q1g2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b5c6",
          "positional_uci": "b5c6",
          "neutral_uci": "b5c6",
          "consensus_move": "b5c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc6",
              "O-O",
              "Bg4",
              "h3",
              "h5",
              "d3",
              "Qf6",
              "Nbd2",
              "Ne7",
              "Re1",
              "Ng6",
              "hxg4",
              "hxg4",
              "Nh2",
              "Rxh2",
              "Kxh2",
              "Qh4+",
              "Kg1",
              "Bc5",
              "d4",
              "Bxd4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc6",
              "O-O",
              "Bg4",
              "h3",
              "h5",
              "d3",
              "Qf6",
              "Nbd2",
              "Ne7",
              "Re1",
              "Ng6",
              "d4",
              "O-O-O",
              "hxg4",
              "hxg4",
              "Nh2",
              "Rxh2",
              "Qxg4+",
              "Kb8",
              "Kxh2",
              "Qxf2",
              "Nf3",
              "Bd6",
              "Kh1",
              "Rh8+",
              "Qh3",
              "Rxh3+",
              "gxh3",
              "Qxf3+",
              "Kg1",
              "Nh4",
              "Re2",
              "Qxe2",
              "Bg5",
              "Qg2#",
              "Kh1",
              "Qxh3+",
              "Kg1",
              "Qg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc6",
              "O-O",
              "Bg4",
              "h3",
              "h5",
              "d3",
              "Qf6",
              "Nbd2",
              "Ne7",
              "Re1",
              "Ng6",
              "d4",
              "O-O-O",
              "hxg4",
              "hxg4",
              "Nh2",
              "Rxh2",
              "Qxg4+",
              "Kb8",
              "Kxh2",
              "Qxf2",
              "Nf3",
              "Bd6",
              "Kh1",
              "Rh8+",
              "Nh2",
              "Qxe1+",
              "Nf1",
              "Qxf1#",
              "Kh2",
              "exd4+",
              "g3",
              "Qf2+",
              "Kh1",
              "Qf1+",
              "Kh2",
              "Ne5",
              "Qf5",
              "Nf3+",
              "Qxf3",
              "Qxf3",
              "Bf4",
              "Bxf4",
              "gxf4",
              "Rxh3+",
              "Kg1",
              "Rh1#",
              "Kxh1",
              "Qh3+",
              "Kg1",
              "Qg3+",
              "Kh1",
              "Qxf4",
              "Kg1",
              "Qxe4",
              "Kh2",
              "Qxc2+",
              "Kh3",
              "Qxb2",
              "Kh4",
              "Qxa1",
              "Kh5",
              "Qxa2",
              "Kg5",
              "Qe6",
              "Kh5",
              "Qg6+",
              "Kh4",
              "d3",
              "Kh3",
              "d2",
              "Kh2",
              "d1=Q",
              "Kh3",
              "Qdh5#",
              "Kh2",
              "Qhg5",
              "Kh3",
              "Qg4+",
              "Kh2",
              "Qg3+",
              "Kh1",
              "Qg2#",
              "Kh2",
              "Q6g3#",
              "Kh1",
              "Qg4",
              "Kh2",
              "Qg5",
              "Kh1",
              "Qg6",
              "Kh2",
              "Q6g5",
              "Kh1",
              "Q5g4",
              "Kh2",
              "Qg1#",
              "Kh3",
              "Q1g3#",
              "Kh1",
              "Qg2#",
              "Kh2",
              "Q2g3#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Q1g2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 176,
            "total_tokens": 309,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1456,
          "total_tokens": 1854
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 176,
            "total_tokens": 309,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": "f3e5",
          "aggressive_response": "5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Be3 Nd5 16. Bd4 Re1 17. b3 Nf4+ 18. Kg3 Rg1+ 19. Kh4 g5# g4 Qg5# Qxg5#",
          "aggressive_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 138,
            "total_tokens": 280,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd4",
            "Nf3",
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Be3",
            "Nd5",
            "Bd4",
            "Re1",
            "b3",
            "Nf4+",
            "Kg3",
            "Rg1+",
            "Kh4",
            "g5#",
            "g4",
            "Qg5#",
            "Qxg5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe5",
          "positional_uci": "f3e5",
          "positional_response": "5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. d3 Re8+ 11. Kf1 Rxe1+ 12. Nxe1 Nf6 13. Nc3 Bb4 14. Bd2 Re8 15. f3 Be6 16. a3 Bd6 17. g3 Bh3+ 18. Ng2 Nd5 19. Ne4 Be5 20. c3 f5 21. Ng5 Bxg2+ 22. Kxg2 Bf6 23. Kf2 h6 24. Nh3 g5 25. Re1 Rxe1 26. Kxe1 Kd7 27. Ke2 Ke6 28. Nf2 b5 29. Nd1 c5 30. Ne3 Nxe3 31. Bxe3 Kd5 32. Kd2 c4 33. d4 Be7 34. h3 c5 35. dxc5 Bxc5 36. Bxc5 Kxc5 37. Ke3 Kd5 38. f4 g4 39. hxg4 fxg4 40. f5 Ke5 41. f6 Kxf6 42. Kf4 h5 43. Ke4 Kg5 44. Ke3 h4 45. gxh4+ Kxh4 46. Kf2 Kh3 47. Kg1 Kg3 48. Kh1 Kf2 49. Kh2 g3+ 50. Kh1 g2+ 51. Kh2 g1=Q+ 52. Kh3 Qg3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Qxe4 Qxe4 Qxe4 Kxe2 Bg4 Re1+ Kf1 Rxe1+ Nxe1 Nf6 Bb4 Bd6 a3 Bd7 g3 Bc6 Ng2 Bxg2+ Kxg2 Nd5 Ne4 Be7 Kf3 Kf7 c4 Nb6 b3 Ke6 a4 Nd7 g4 Nc5 Nxc5+ Bxc5 Ke4 Bb4 f5+ Kf6 Kf4 Bd2+ Ke4 Kg5 Kf3 Bc3 Kg3 Be5+ Kf3 Kh4 Ke4 Kxh3 Kd5 Kxg4 Ke6 h5 Kd5 h4 Kc6 h3 Kb6 h2 Kxa6 h1=Q Kb5 Qb7+ Kc5 Qb5+ Kd6 Qd5+ Ke7 Qe6+ Kf8 Qf7# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc",
          "positional_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qd4",
            "Qxe4",
            "Qxe4",
            "Qxe4",
            "Kxe2",
            "Bg4",
            "Re1+",
            "Kf1",
            "Rxe1+",
            "Nxe1",
            "Nf6",
            "Bb4",
            "Bd6",
            "a3",
            "Bd7",
            "g3",
            "Bc6",
            "Ng2",
            "Bxg2+",
            "Kxg2",
            "Nd5",
            "Ne4",
            "Be7",
            "Kf3",
            "Kf7",
            "c4",
            "Nb6",
            "b3",
            "Ke6",
            "a4",
            "Nd7",
            "g4",
            "Nc5",
            "Nxc5+",
            "Bxc5",
            "Ke4",
            "Bb4",
            "f5+",
            "Kf6",
            "Kf4",
            "Bd2+",
            "Ke4",
            "Kg5",
            "Kf3",
            "Bc3",
            "Kg3",
            "Be5+",
            "Kf3",
            "Kh4",
            "Ke4",
            "Kxh3",
            "Kd5",
            "Kxg4",
            "Ke6",
            "h5",
            "Kd5",
            "h4",
            "Kc6",
            "h3",
            "Kb6",
            "h2",
            "Kxa6",
            "h1=Q",
            "Kb5",
            "Qb7+",
            "Kc5",
            "Qb5+",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qe6+",
            "Kf8",
            "Qf7#",
            "e4",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Bxc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe5",
          "neutral_uci": "f3e5",
          "neutral_response": "5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Bd6 27. Kg4 Bc5 28. Kh5 Bxe3 29. fxe3 Kf5 30. Kh6 Kg4 31. e4 Kf4 32. Kh5 c5 33. a3 b5 34. c3 c6 35. b4 cxb4 36. axb4 Ke3 37. Kh6 Kxd3 38. Kxh7 Kxe4 39. Kg7 Kf5 40. Kxf7 Kxg5 41. Ke6 Kf4 42. Kd6 Ke4 43. Kxc6 Kd3 44. Kb6 Kxc3 45. Kxa6 Kxb4 46. Kb6 Kc4 47. Ka5 b4 48. Ka4 Kc3 49. Kb5 b3 50. Ka4 b2 51. Ka3 b1=Q 52. Ka4 Qb4# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf6 Qxe4 Qd6 Qxe6 Qxe6 Qe2 Qd4 Qe3 Qxe3 fxe3 Nf6 Kf2 Kd7 Ke2 Ke6 Kd2 Ke5 Kc2 Ke4 Kb2 Kd3 Ka2 Kxc3 Ka3 Kc4 Ka4 Kc3 Kb5 Kb3 Kxc5 Kc3 Kd5 Kd3 Ke5 Ke3 Kf5 Kf3 Kg5 Kg3 Kh5 Kh3 g5 Kg3 g4 Kg2 Kh4 Kh2 g3+ Kg2 Kg4 Kg1 Kf3 Kf1 g2+ Kg1 Kg3 * e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4 Qd3 Qxe3 fxe3 Nf6 Kf2 Kd7 Ke2 Ke6 Kd2 Ke5 Kc2 Ke4 Kb2 Kd3 Ka2 Kxc3 Ka3",
          "neutral_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qd4",
            "Nf3",
            "Qxe4",
            "Qd3",
            "Qxe3",
            "fxe3",
            "Nf6",
            "Kf2",
            "Kd7",
            "Ke2",
            "Ke6",
            "Kd2",
            "Ke5",
            "Kc2",
            "Ke4",
            "Kb2",
            "Kd3",
            "Ka2",
            "Kxc3",
            "Ka3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3e5",
          "positional_uci": "f3e5",
          "neutral_uci": "f3e5",
          "consensus_move": "f3e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd4",
              "Nf3",
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Be3",
              "Nd5",
              "Bd4",
              "Re1",
              "b3",
              "Nf4+",
              "Kg3",
              "Rg1+",
              "Kh4",
              "g5#",
              "g4",
              "Qg5#",
              "Qxg5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd4",
              "Qxe4",
              "Qxe4",
              "Qxe4",
              "Kxe2",
              "Bg4",
              "Re1+",
              "Kf1",
              "Rxe1+",
              "Nxe1",
              "Nf6",
              "Bb4",
              "Bd6",
              "a3",
              "Bd7",
              "g3",
              "Bc6",
              "Ng2",
              "Bxg2+",
              "Kxg2",
              "Nd5",
              "Ne4",
              "Be7",
              "Kf3",
              "Kf7",
              "c4",
              "Nb6",
              "b3",
              "Ke6",
              "a4",
              "Nd7",
              "g4",
              "Nc5",
              "Nxc5+",
              "Bxc5",
              "Ke4",
              "Bb4",
              "f5+",
              "Kf6",
              "Kf4",
              "Bd2+",
              "Ke4",
              "Kg5",
              "Kf3",
              "Bc3",
              "Kg3",
              "Be5+",
              "Kf3",
              "Kh4",
              "Ke4",
              "Kxh3",
              "Kd5",
              "Kxg4",
              "Ke6",
              "h5",
              "Kd5",
              "h4",
              "Kc6",
              "h3",
              "Kb6",
              "h2",
              "Kxa6",
              "h1=Q",
              "Kb5",
              "Qb7+",
              "Kc5",
              "Qb5+",
              "Kd6",
              "Qd5+",
              "Ke7",
              "Qe6+",
              "Kf8",
              "Qf7#",
              "e4",
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Bxc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd4",
              "Nf3",
              "Qxe4",
              "Qd3",
              "Qxe3",
              "fxe3",
              "Nf6",
              "Kf2",
              "Kd7",
              "Ke2",
              "Ke6",
              "Kd2",
              "Ke5",
              "Kc2",
              "Ke4",
              "Kb2",
              "Kd3",
              "Ka2",
              "Kxc3",
              "Ka3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 142,
            "completion_tokens": 138,
            "total_tokens": 280,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 425,
          "total_completion_tokens": 1418,
          "total_tokens": 1843
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 142,
            "completion_tokens": 138,
            "total_tokens": 280,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1pp2ppp/p1p5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "e5f3",
          "aggressive_response": "6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Bd6 27. Kg4 Bc5 28. Kf4 Bxe3+ 29. fxe3 f6 30. gxf6 Kxf6 31. e4 h5 32. d4 h4 33. Kg4 h3 34. Kxh3 Kg5 35. Kg3 b6 36. Kf3 c5 37. d5 Kf6 38. Kf4 b5 39. e5+ Ke7 40. Kf5 a5 41. c4 bxc4 42. bxc4 a4 43. a3 Kd7 44. Kf6 Ke8 45. Ke6 Kd8 46. Kf7 Kd7 47. e6+ Kd8 48. e7+ Kd7 49. e8=Q+ Kd6 50. Qe6# e4 d5 Qd6",
          "aggressive_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 379,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "Kg3",
            "Ke6",
            "Kf4",
            "Be5+",
            "Ke4",
            "Bxh2",
            "f4",
            "g6",
            "Kf3",
            "g5",
            "fxg5",
            "Bd6",
            "Kg4",
            "Bc5",
            "Kf4",
            "Bxe3+",
            "fxe3",
            "f6",
            "gxf6",
            "Kxf6",
            "e4",
            "h5",
            "d4",
            "h4",
            "Kg4",
            "h3",
            "Kxh3",
            "Kg5",
            "Kg3",
            "b6",
            "Kf3",
            "c5",
            "d5",
            "Kf6",
            "Kf4",
            "b5",
            "e5+",
            "Ke7",
            "Kf5",
            "a5",
            "c4",
            "bxc4",
            "bxc4",
            "a4",
            "a3",
            "Kd7",
            "Kf6",
            "Ke8",
            "Ke6",
            "Kd8",
            "Kf7",
            "Kd7",
            "e6+",
            "Kd8",
            "e7+",
            "Kd7",
            "e8=Q+",
            "Kd6",
            "Qe6#",
            "e4",
            "d5",
            "Qd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "e5f3",
          "positional_response": "6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Bd6 27. Kg4 Bc5 28. Kf4 Bxe3+ 29. fxe3 f6 30. gxf6 Kxf6 31. e4 h5 32. d4 b6 33. c4 c5 34. d5 h4 35. e5+ Ke7 36. Kg4 b5 37. Kxh4 bxc4 38. bxc4 a5 39. Kg5 a4 40. Kf5 a3 41. e6 Kd6 42. Kf6 c6 43. e7 cxd5 44. e8=Q dxc4 45. Qe6+ Kc7 46. Qxc4 Kc6 47. Ke5 Kb6 48. Kd5 Ka5 49. Qxc5+ Ka4 50. Qc4+ Ka5 51. Qb3 Ka6 52. Kc6 Ka5 53. Qb5# e4 d5 dxe4",
          "positional_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 402,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "Kg3",
            "Ke6",
            "Kf4",
            "Be5+",
            "Ke4",
            "Bxh2",
            "f4",
            "g6",
            "Kf3",
            "g5",
            "fxg5",
            "Bd6",
            "Kg4",
            "Bc5",
            "Kf4",
            "Bxe3+",
            "fxe3",
            "f6",
            "gxf6",
            "Kxf6",
            "e4",
            "h5",
            "d4",
            "b6",
            "c4",
            "c5",
            "d5",
            "h4",
            "e5+",
            "Ke7",
            "Kg4",
            "b5",
            "Kxh4",
            "bxc4",
            "bxc4",
            "a5",
            "Kg5",
            "a4",
            "Kf5",
            "a3",
            "e6",
            "Kd6",
            "Kf6",
            "c6",
            "e7",
            "cxd5",
            "e8=Q",
            "dxc4",
            "Qe6+",
            "Kc7",
            "Qxc4",
            "Kc6",
            "Ke5",
            "Kb6",
            "Kd5",
            "Ka5",
            "Qxc5+",
            "Ka4",
            "Qc4+",
            "Ka5",
            "Qb3",
            "Ka6",
            "Kc6",
            "Ka5",
            "Qb5#",
            "e4",
            "d5",
            "dxe4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "e5f3",
          "neutral_response": "6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. f4 Ke6 22. Kf3 f5 23. h4 g6 24. Nc4 Bf6 25. Kg3 Kd5 26. Na5 b6 27. Nc4 Kd4 28. Ne3 Kc3 29. h5 Kb2 30. a4 Kc3 31. hxg6 hxg6 32. Kf3 Bd4 33. Ke2 Bxe3 34. Kxe3 Kxc2 35. Kd4 Kxb3 36. Ke5 Kxa4 37. Kf6 b5 38. Kxg6 b4 39. Kxf5 b3 40. Ke6 b2 41. f5 b1=Q 42. f6 Qxd3 43. f7 Qd5+ 44. Ke7 Qxf7+ 45. Kxf7 c5 46. f4 c4 47. f5 c3 48. f6 c2 49. Kg7 c1=Q 50. f7 Qg5+ 51. Kf8 Kb5 52. Ke8 Qe5+ 53. Kf8 Kc6 54. Kg8 Qg5+ 55. Kf8 Kd6 56. Ke8 Qe7# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf6 Qxe4+ Qxe4 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke1 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Rxe8 Rxe8 Nc3 Re1 b3 Be5 Bb2 Bxc3 Bxc3 Rc1 Bb2 Rxa1 Bxa1 Ne3 Kd7 f4 Ke6 f5+ Ke5 Kf3 Bd4 Ng4+ Kxf5 h4 g6 Nf2 Bxf2 Kxf2 Kf4 Kg2 Kg4 h5 gxh5 Kh2 Kf3 Kh3 Ke3 Kh4 Kxd3 Kg3 Kc3 Kf3 Kxb3 Ke4 Kxa4 Kd4 Kb4 Kd3 a5 Kc2 a4 Kb2 a3+ Ka2 c5 Kb1 c4 K",
          "neutral_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Bxc6",
            "dxc6",
            "Nxe5",
            "Qd4",
            "Nf6",
            "Qxe4+",
            "Qxe4",
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Ke1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Bxc3",
            "Bxc3",
            "Rc1",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Ne3",
            "Kd7",
            "f4",
            "Ke6",
            "f5+",
            "Ke5",
            "Kf3",
            "Bd4",
            "Ng4+",
            "Kxf5",
            "h4",
            "g6",
            "Nf2",
            "Bxf2",
            "Kxf2",
            "Kf4",
            "Kg2",
            "Kg4",
            "h5",
            "gxh5",
            "Kh2",
            "Kf3",
            "Kh3",
            "Ke3",
            "Kh4",
            "Kxd3",
            "Kg3",
            "Kc3",
            "Kf3",
            "Kxb3",
            "Ke4",
            "Kxa4",
            "Kd4",
            "Kb4",
            "Kd3",
            "a5",
            "Kc2",
            "a4",
            "Kb2",
            "a3+",
            "Ka2",
            "c5",
            "Kb1",
            "c4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5f3",
          "positional_uci": "e5f3",
          "neutral_uci": "e5f3",
          "consensus_move": "e5f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "Kg3",
              "Ke6",
              "Kf4",
              "Be5+",
              "Ke4",
              "Bxh2",
              "f4",
              "g6",
              "Kf3",
              "g5",
              "fxg5",
              "Bd6",
              "Kg4",
              "Bc5",
              "Kf4",
              "Bxe3+",
              "fxe3",
              "f6",
              "gxf6",
              "Kxf6",
              "e4",
              "h5",
              "d4",
              "h4",
              "Kg4",
              "h3",
              "Kxh3",
              "Kg5",
              "Kg3",
              "b6",
              "Kf3",
              "c5",
              "d5",
              "Kf6",
              "Kf4",
              "b5",
              "e5+",
              "Ke7",
              "Kf5",
              "a5",
              "c4",
              "bxc4",
              "bxc4",
              "a4",
              "a3",
              "Kd7",
              "Kf6",
              "Ke8",
              "Ke6",
              "Kd8",
              "Kf7",
              "Kd7",
              "e6+",
              "Kd8",
              "e7+",
              "Kd7",
              "e8=Q+",
              "Kd6",
              "Qe6#",
              "e4",
              "d5",
              "Qd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "Kg3",
              "Ke6",
              "Kf4",
              "Be5+",
              "Ke4",
              "Bxh2",
              "f4",
              "g6",
              "Kf3",
              "g5",
              "fxg5",
              "Bd6",
              "Kg4",
              "Bc5",
              "Kf4",
              "Bxe3+",
              "fxe3",
              "f6",
              "gxf6",
              "Kxf6",
              "e4",
              "h5",
              "d4",
              "b6",
              "c4",
              "c5",
              "d5",
              "h4",
              "e5+",
              "Ke7",
              "Kg4",
              "b5",
              "Kxh4",
              "bxc4",
              "bxc4",
              "a5",
              "Kg5",
              "a4",
              "Kf5",
              "a3",
              "e6",
              "Kd6",
              "Kf6",
              "c6",
              "e7",
              "cxd5",
              "e8=Q",
              "dxc4",
              "Qe6+",
              "Kc7",
              "Qxc4",
              "Kc6",
              "Ke5",
              "Kb6",
              "Kd5",
              "Ka5",
              "Qxc5+",
              "Ka4",
              "Qc4+",
              "Ka5",
              "Qb3",
              "Ka6",
              "Kc6",
              "Ka5",
              "Qb5#",
              "e4",
              "d5",
              "dxe4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Bxc6",
              "dxc6",
              "Nxe5",
              "Qd4",
              "Nf6",
              "Qxe4+",
              "Qxe4",
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Ke1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Bxc3",
              "Bxc3",
              "Rc1",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Ne3",
              "Kd7",
              "f4",
              "Ke6",
              "f5+",
              "Ke5",
              "Kf3",
              "Bd4",
              "Ng4+",
              "Kxf5",
              "h4",
              "g6",
              "Nf2",
              "Bxf2",
              "Kxf2",
              "Kf4",
              "Kg2",
              "Kg4",
              "h5",
              "gxh5",
              "Kh2",
              "Kf3",
              "Kh3",
              "Ke3",
              "Kh4",
              "Kxd3",
              "Kg3",
              "Kc3",
              "Kf3",
              "Kxb3",
              "Ke4",
              "Kxa4",
              "Kd4",
              "Kb4",
              "Kd3",
              "a5",
              "Kc2",
              "a4",
              "Kb2",
              "a3+",
              "Ka2",
              "c5",
              "Kb1",
              "c4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 151,
            "completion_tokens": 379,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 151,
            "completion_tokens": 402,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 452,
          "total_completion_tokens": 1421,
          "total_tokens": 1873
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 151,
            "completion_tokens": 379,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 151,
            "completion_tokens": 402,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/4N3/3qP3/8/PPPP1PPP/RNBQK2R w KQkq - 1 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf1",
          "aggressive_uci": "e1f1",
          "aggressive_response": "7. Kf1 Bg4 8. d3 Bxf3 9. Qxf3 Qxf3 10. gxf3 O-O-O 11. Nc3 Nf6 12. Bg5 Be7 13. Re1 Rhe8 14. Kg2 h6 15. Bh4 g5 16. Bg3 Nd5 17. Nxd5 cxd5 18. Re2 Bf6 19. Rxe8 Rxe8 20. c3 Re2 21. Rb1 Rd2 22. d4 Kd7 23. f4 g4 24. h3 h5 25. hxg4 hxg4 26. Kf1 Be7 27. Ke1 Rc2 28. Kd1 Rxf2 29. Bxf2 f5 30. Ke2 Bd6 31. Bg3 c5 32. dxc5 Bxc5 33. Rd1 Kc6 34. b4 Bb6 35. a4 a5 36. b5+ Kc5 37. Bf2+ Kc4 38. Bxb6 Kxc3 39. Rxd5 Kb4 40. Rxf5 Kxa4 41. Rg5 Kb4 42. Rxg4 Kxb5 43. Bxa5 Kxa5 44. f5 b5 45. f6 b4 46. f7 b3 47. f8=Q b2 48. Qb8 b1=Q 49. Qxb1 Ka6 50. Ra4# e5 e6 e7",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 363,
            "total_tokens": 524,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "Ke1",
            "Rc2",
            "Kd1",
            "Rxf2",
            "Bxf2",
            "f5",
            "Ke2",
            "Bd6",
            "Bg3",
            "c5",
            "dxc5",
            "Bxc5",
            "Rd1",
            "Kc6",
            "b4",
            "Bb6",
            "a4",
            "a5",
            "b5+",
            "Kc5",
            "Bf2+",
            "Kc4",
            "Bxb6",
            "Kxc3",
            "Rxd5",
            "Kb4",
            "Rxf5",
            "Kxa4",
            "Rg5",
            "Kb4",
            "Rxg4",
            "Kxb5",
            "Bxa5",
            "Kxa5",
            "f5",
            "b5",
            "f6",
            "b4",
            "f7",
            "b3",
            "f8=Q",
            "b2",
            "Qb8",
            "b1=Q",
            "Qxb1",
            "Ka6",
            "Ra4#",
            "e5",
            "e6",
            "e7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe2",
          "positional_uci": "d1e2",
          "positional_response": "7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Be3 Nd5 16. Bd4 Re1 17. b3 Nf4+ 18. Kg3 Rg1+ 19. Kh4 g5# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke3 O-O-O Kf4 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Be3 Nd5 Bd4 Re2 c4 Nf4+ Kf1 Rxc2 Bxg7 Nxd3 Nc3 Rxf2+ Kg1 Rg8 Ne4 Rxg7+ Ng3 Bxg3 hxg3 Rxg3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke3 O-O-O Kf4 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Be3 Nd5 Bd4 Re2 c4 Nf4 Kf1 Rxc2 Bxg7 Nxd3 Nc3 Rxf2+ Kg1 Rg8 Ne4 Rxg7+ Ng3 Bxg3 hxg3 Rxg3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke3 O-O-O Kf4 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Be3 Nd5 Bd4 Re2 c4 Nf4 Kf1 Rxc2 Bxg7 Nxd3 Nc3 Rxf2+ Kg1 Rg8 Ne4 Rxg7+ Ng3 Bxg3 hxg3 Rxg3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Qe2 Qxe2+ Kxe2 Bg4 Ke3 O-O-O Kf4 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Be3 Nd5 Bd4 Re2 c4 Nf4 Kf1 Rxc2 Bxg7 Nxd3 Nc3 Rxf2+ Kg1 Rg8 Ne4 Rxg7+ Ng3 Bxg3 hxg3 Rxg3#",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 625,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Ke3",
            "O-O-O",
            "Kf4",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Be3",
            "Nd5",
            "Bd4",
            "Re2",
            "c4",
            "Nf4",
            "Kf1",
            "Rxc2",
            "Bxg7",
            "Nxd3",
            "Nc3",
            "Rxf2+",
            "Kg1",
            "Rg8",
            "Ne4",
            "Rxg7+",
            "Ng3",
            "Bxg3",
            "hxg3",
            "Rxg3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kf1",
          "neutral_uci": "e1f1",
          "neutral_response": "7. Kf1 Bg4 8. d3 Bxf3 9. Qxf3 Qxf3 10. gxf3 O-O-O 11. Nc3 Nf6 12. Bg5 Be7 13. Re1 Rhe8 14. Kg2 h6 15. Bh4 g5 16. Bg3 Nh5 17. Re2 Bb4 18. Rhe1 Rxe2 19. Rxe2 Bxc3 20. bxc3 f5 21. h3 f4 22. Bh2 Kd7 23. Re4 Re8 24. Kf1 Nf6 25. Rxe8 Nxe8 26. Ke2 Nd6 27. Kd2 Nf5 28. Ke2 Kd6 29. Kd2 Kd5 30. Ke2 c5 31. Kd2 b5 32. Ke2 c4 33. Kd2 c5 34. Ke2 b4 35. Kd2 a5 36. cxb4 cxb4 37. c3 b3 38. axb3 cxb3 39. Kc1 a4 40. Kb2 Kc5 41. Ka3 Kb5 42. Kb2 Nd6 43. Ka3 Nc4+ 44. dxc4+ Kxc4 45. Kb2 a3+ 46. Kxa3 Kxc3 47. Bxf4 gxf4 48. h4 b2 49. Ka2 Kc2 50. h5 b1=Q+ 51. Ka3 Qb3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nxf3 Kf1 Bg4 d3 Bxf3 Qxf3 Qxf3 gxf3 O-O-O Nc3 Nf6 Bg5 Be7 Re1 Rhe8 Kg2 h6 Bh4 g5 Bg3 Nh5 Re2 Bb4 Re4 Rxe4 fxe4 Bxc3 bxc3 f5 exf5 Nf6 Kf3 Kd7 Be5 Ke7 Bxf6+ Kxf6 Ke4 h5 f3 a5 c4 a4 d4 a3 d5 cxd5+ Kxd5 a2 Kc3 a1=Q Kd3 Qd4+ Ke2 Qc3 Kf2 Qd3 Kg2 Qe3 Kg3 Qf4+ Kg2 Kd3 Kf2 Kd2 Kg2 Ke2 Kh3 Qxf3+ Kg1 Qf2+ Kh1 Kf3 h4 Qg2#",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 592,
            "total_tokens": 752,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "d3",
            "Bxf3",
            "Qxf3",
            "Qxf3",
            "gxf3",
            "O-O-O",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "Re1",
            "Rhe8",
            "Kg2",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Nh5",
            "Re2",
            "Bb4",
            "Re4",
            "Rxe4",
            "fxe4",
            "Bxc3",
            "bxc3",
            "f5",
            "exf5",
            "Nf6",
            "Kf3",
            "Kd7",
            "Be5",
            "Ke7",
            "Bxf6+",
            "Kxf6",
            "Ke4",
            "h5",
            "f3",
            "a5",
            "c4",
            "a4",
            "d4",
            "a3",
            "d5",
            "cxd5+",
            "Kxd5",
            "a2",
            "Kc3",
            "a1=Q",
            "Kd3",
            "Qd4+",
            "Ke2",
            "Qc3",
            "Kf2",
            "Qd3",
            "Kg2",
            "Qe3",
            "Kg3",
            "Qf4+",
            "Kg2",
            "Kd3",
            "Kf2",
            "Kd2",
            "Kg2",
            "Ke2",
            "Kh3",
            "Qxf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Kf3",
            "h4",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1f1",
          "positional_uci": "d1e2",
          "neutral_uci": "e1f1",
          "consensus_move": "e1f1",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "Ke1",
              "Rc2",
              "Kd1",
              "Rxf2",
              "Bxf2",
              "f5",
              "Ke2",
              "Bd6",
              "Bg3",
              "c5",
              "dxc5",
              "Bxc5",
              "Rd1",
              "Kc6",
              "b4",
              "Bb6",
              "a4",
              "a5",
              "b5+",
              "Kc5",
              "Bf2+",
              "Kc4",
              "Bxb6",
              "Kxc3",
              "Rxd5",
              "Kb4",
              "Rxf5",
              "Kxa4",
              "Rg5",
              "Kb4",
              "Rxg4",
              "Kxb5",
              "Bxa5",
              "Kxa5",
              "f5",
              "b5",
              "f6",
              "b4",
              "f7",
              "b3",
              "f8=Q",
              "b2",
              "Qb8",
              "b1=Q",
              "Qxb1",
              "Ka6",
              "Ra4#",
              "e5",
              "e6",
              "e7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Ke3",
              "O-O-O",
              "Kf4",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Be3",
              "Nd5",
              "Bd4",
              "Re2",
              "c4",
              "Nf4",
              "Kf1",
              "Rxc2",
              "Bxg7",
              "Nxd3",
              "Nc3",
              "Rxf2+",
              "Kg1",
              "Rg8",
              "Ne4",
              "Rxg7+",
              "Ng3",
              "Bxg3",
              "hxg3",
              "Rxg3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bg4",
              "d3",
              "Bxf3",
              "Qxf3",
              "Qxf3",
              "gxf3",
              "O-O-O",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "Re1",
              "Rhe8",
              "Kg2",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Nh5",
              "Re2",
              "Bb4",
              "Re4",
              "Rxe4",
              "fxe4",
              "Bxc3",
              "bxc3",
              "f5",
              "exf5",
              "Nf6",
              "Kf3",
              "Kd7",
              "Be5",
              "Ke7",
              "Bxf6+",
              "Kxf6",
              "Ke4",
              "h5",
              "f3",
              "a5",
              "c4",
              "a4",
              "d4",
              "a3",
              "d5",
              "cxd5+",
              "Kxd5",
              "a2",
              "Kc3",
              "a1=Q",
              "Kd3",
              "Qd4+",
              "Ke2",
              "Qc3",
              "Kf2",
              "Qd3",
              "Kg2",
              "Qe3",
              "Kg3",
              "Qf4+",
              "Kg2",
              "Kd3",
              "Kf2",
              "Kd2",
              "Kg2",
              "Ke2",
              "Kh3",
              "Qxf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Kf3",
              "h4",
              "Qg2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 363,
            "total_tokens": 524,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 625,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 592,
            "total_tokens": 752,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 1580,
          "total_tokens": 2062
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 363,
            "total_tokens": 524,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 625,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 592,
            "total_tokens": 752,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxf3",
          "aggressive_uci": "d1f3",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bxf6 Bxf6 15. g4 Bxc3 16. bxc3 Bd5 17. Qf5+ Be6 18. Qf4 Bd5 19. Rg1 Rxe1+ 20. Kxe1 Re8+ 21. Kd2 g5 22. Qf5+ Be6 23. Qf6 Bxa2 24. c4 b5 25. Qxc6 Re6 26. Qa8+ Kd7 27. cxb5 axb5 28. Qxa2 1-0\n*1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bxf6 Bxf6 15. g4 Bxc3 16. bxc3 Bd5 17. Qf5+ Be6 18. Qf4 Bd5 19. Rg1 Rxe1+ 20. Kxe1 Re8+ 21. Kd2 g5 22. Qf5+ Be6 23. Qf6 Bxa2 24. c4 b5 25. Qxc6 Re6 26. Qa8+ Kd7 27. cxb5 axb5 28. Qxa2 1-0 29. Re1 Rxe1 30. Kxe1 Be6 31. Qa5 c6 32. Qa7+ Kd6 33. Qd4+ Ke7 34. Qc5+ Kd7 35. Qf8 Kc7 36. Qxh6 Kb6 37. Qxg5 c5 38. Qd8+ Kc6 39. Qa8+ Kb6 40. Qb8+ Kc6 41. Qa7 Kd5 42. Qxa6 b4 43. Qb7+ Kd4 44. Qe4+ Kc3 45. Kd1 b3 46. Qe5+ Kb",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be6",
            "d3",
            "O-O-O",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "Re1",
            "Rhe8",
            "h3",
            "h6",
            "Bxf6",
            "Bxf6",
            "g4",
            "Bxc3",
            "bxc3",
            "Bd5",
            "Qf5+",
            "Be6",
            "Qf4",
            "Bd5",
            "Rg1",
            "Rxe1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "g5",
            "Qf5+",
            "Be6",
            "Qf6",
            "Bxa2",
            "c4",
            "b5",
            "Qxc6",
            "Re6",
            "Qa8+",
            "Kd7",
            "cxb5",
            "axb5",
            "Qxa2",
            "Re1",
            "Rxe1",
            "Kxe1",
            "Be6",
            "Qa5",
            "c6",
            "Qa7+",
            "Kd6",
            "Qd4+",
            "Ke7",
            "Qc5+",
            "Kd7",
            "Qf8",
            "Kc7",
            "Qxh6",
            "Kb6",
            "Qxg5",
            "c5",
            "Qd8+",
            "Kc6",
            "Qa8+",
            "Kb6",
            "Qb8+",
            "Kc6",
            "Qa7",
            "Kd5",
            "Qxa6",
            "b4",
            "Qb7+",
            "Kd4",
            "Qe4+",
            "Kc3",
            "Kd1",
            "b3",
            "Qe5+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxf3",
          "positional_uci": "d1f3",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bxf6 Bxf6 15. g4 Bxc3 16. bxc3 Bd5 17. Qf5+ Kb8 18. Rxe8 Rxe8 19. Rg1 Bxa2 20. c4 Bb1 21. Qxf7 Rc8 22. Qxg7 Bxc2 23. Qc3 Ba4 24. Kg2 c5 25. Rb1 Bc6+ 26. Kg3 Rf8 27. f4 Re8 28. Re1 Rd8 29. Re6 h5 30. Rxc6 bxc6 31. gxh5 Rg8+ 32. Kf3 Rg1 33. h6 Rf1+ 34. Kg4 Rg1+ 35. Kf5 Rg8 36. h7 Rf8+ 37. Kg6 Rxf4 38. h8=Q+ Kb7 39. Qb3+ Ka7 40. Qhb8#\n*1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bxf6 Bxf6 15. g4 Bxc3 16. bxc3 Bd5 17. Qf5+ Kb8 18. Rxe8 Rxe8 19. Rg1 Bxa2 20. c4 Bb1 21. Qxf7 Rc8 22. Qxg7 Bxc2 23. Qc3 Ba4 24. Kg2 c5 25. Rb1 Bc6+ 26. Kg3 Rf8 27. f4 Re8 28. Re1 Rd8 29. Re6 h5 30. Rxc6 bxc6 31. gxh5 Rg8+ 32. Kf3 Rg1 33. h6 Rf1+ 34. Kg4 Rg1+ 35. Kf5 Rg8 36. h7 Rf",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be6",
            "d3",
            "O-O-O",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "Re1",
            "Rhe8",
            "h3",
            "h6",
            "Bxf6",
            "Bxf6",
            "g4",
            "Bxc3",
            "bxc3",
            "Bd5",
            "Qf5+",
            "Kb8",
            "Rxe8",
            "Rxe8",
            "Rg1",
            "Bxa2",
            "c4",
            "Bb1",
            "Qxf7",
            "Rc8",
            "Qxg7",
            "Bxc2",
            "Qc3",
            "Ba4",
            "Kg2",
            "c5",
            "Rb1",
            "Bc6+",
            "Kg3",
            "Rf8",
            "f4",
            "Re8",
            "Re1",
            "Rd8",
            "Re6",
            "h5",
            "Rxc6",
            "bxc6",
            "gxh5",
            "Rg8+",
            "Kf3",
            "Rg1",
            "h6",
            "Rf1+",
            "Kg4",
            "Rg1+",
            "Kf5",
            "Rg8",
            "h7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxf3",
          "neutral_uci": "d1f3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bf4 Nd5 15. Nxd5 Bxd5 16. Qg3 Bf6 17. Bxc7 Rxe1+ 18. Kxe1 Re8+ 19. Kd2 Bxb2 20. Bb8 Re7 21. Re1 Rd7 22. Re8+ Rd8 23. Qc7#\n*8... Be6 9. d3 O-O-O 10. Nc3 Nf6 11. Bg5 Be7 12. Re1 Rhe8 13. h3 h6 14. Bf4 Nd5 15. Nxd5 Bxd5 16. Qg3 Bf6 17. Bxc7 Rxe1+ 18. Kxe1 Re8+ 19. Kd2 Bxb2 20. Bb8 Re7 21. Re1 Rd7 22. Re8+ Rd8 23. Qc7# e5 Nc6 Bb5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Be6 d3 O-O-O Nc3 Nf6 Bg5 Be7 Re1 Rhe8 h3 h6 Bf4 Nd5 Nxd5 Bxd5 Qg3 Bf6 Bxc7 Rxe1+ Kxe1 Re8+ Kd2 Bxb2 Bb8 Re7 Re1 Rd7 Qc7#",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 422,
            "total_tokens": 592,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be6",
            "d3",
            "O-O-O",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "Re1",
            "Rhe8",
            "h3",
            "h6",
            "Bf4",
            "Nd5",
            "Nxd5",
            "Bxd5",
            "Qg3",
            "Bf6",
            "Bxc7",
            "Rxe1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Bxb2",
            "Bb8",
            "Re7",
            "Re1",
            "Rd7",
            "Qc7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1f3",
          "positional_uci": "d1f3",
          "neutral_uci": "d1f3",
          "consensus_move": "d1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be6",
              "d3",
              "O-O-O",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "Re1",
              "Rhe8",
              "h3",
              "h6",
              "Bxf6",
              "Bxf6",
              "g4",
              "Bxc3",
              "bxc3",
              "Bd5",
              "Qf5+",
              "Be6",
              "Qf4",
              "Bd5",
              "Rg1",
              "Rxe1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "g5",
              "Qf5+",
              "Be6",
              "Qf6",
              "Bxa2",
              "c4",
              "b5",
              "Qxc6",
              "Re6",
              "Qa8+",
              "Kd7",
              "cxb5",
              "axb5",
              "Qxa2",
              "Re1",
              "Rxe1",
              "Kxe1",
              "Be6",
              "Qa5",
              "c6",
              "Qa7+",
              "Kd6",
              "Qd4+",
              "Ke7",
              "Qc5+",
              "Kd7",
              "Qf8",
              "Kc7",
              "Qxh6",
              "Kb6",
              "Qxg5",
              "c5",
              "Qd8+",
              "Kc6",
              "Qa8+",
              "Kb6",
              "Qb8+",
              "Kc6",
              "Qa7",
              "Kd5",
              "Qxa6",
              "b4",
              "Qb7+",
              "Kd4",
              "Qe4+",
              "Kc3",
              "Kd1",
              "b3",
              "Qe5+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be6",
              "d3",
              "O-O-O",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "Re1",
              "Rhe8",
              "h3",
              "h6",
              "Bxf6",
              "Bxf6",
              "g4",
              "Bxc3",
              "bxc3",
              "Bd5",
              "Qf5+",
              "Kb8",
              "Rxe8",
              "Rxe8",
              "Rg1",
              "Bxa2",
              "c4",
              "Bb1",
              "Qxf7",
              "Rc8",
              "Qxg7",
              "Bxc2",
              "Qc3",
              "Ba4",
              "Kg2",
              "c5",
              "Rb1",
              "Bc6+",
              "Kg3",
              "Rf8",
              "f4",
              "Re8",
              "Re1",
              "Rd8",
              "Re6",
              "h5",
              "Rxc6",
              "bxc6",
              "gxh5",
              "Rg8+",
              "Kf3",
              "Rg1",
              "h6",
              "Rf1+",
              "Kg4",
              "Rg1+",
              "Kf5",
              "Rg8",
              "h7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be6",
              "d3",
              "O-O-O",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "Re1",
              "Rhe8",
              "h3",
              "h6",
              "Bf4",
              "Nd5",
              "Nxd5",
              "Bxd5",
              "Qg3",
              "Bf6",
              "Bxc7",
              "Rxe1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Bxb2",
              "Bb8",
              "Re7",
              "Re1",
              "Rd7",
              "Qc7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 422,
            "total_tokens": 592,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1702,
          "total_tokens": 2214
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 422,
            "total_tokens": 592,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/8/5q2/PPPP1PPP/RNBQ1K1R w kq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxg4",
          "aggressive_uci": "f3g4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O-O 12. Qxe7 Rhe8 13. Qxf7 Rd7\n14. Qb3 Rde7 15. Bd2 Re2 16. Qf7 R8e7 17. Qf8+ Kd7 18. Qb8 Ng4 19. Qxb7 Rxf2+\n20. Kg1 Ree2 21. Qxc6+ Kxc6 22. h3 Rxg2+ 23. Kf1 Ref2+ 24. Ke1 Re2+ 25. Kd1 Nf2+\n26. Kxe2 Nxh1+ 27. Kf3 Rf2+ 28. Ke3 Rf1 29. Ke2 Ng3+ 30. Ke3 Kd5 31. c4+ Ke5\n32. Bc3+ Kf5 33. b3 c5 34. Bxg7 Re1+ 35. Kf2 Re7 36. Kxg3 Rxg7+ 37. Kf3 Rd7\n38. Ke3 Re7+ 39. Kd2 Kf4 40. Nc3 Kg3 41. Ne4+ Kxh3 42. Nxc5 h5 43. Nxa6 h4\n44. Nc5 Kg2 45. Ne4 h3 46. Re1 h2 47. Re2+ Kh3 48. Nf2+ Kg2 49. Rxe7 Kxf2\n50. Rh7 Kg2 51. Rxh2+ Kxh2 52. a4 Kg3 53. a5 Kf4 54. a6 Ke5 55. a7 Kd6\n56. a8=Q Kc5 57. Qd5+ Kb4 58. Qb5+ Ka3 59. Kc3 Ka2 60. Qa4+ Kb1 61. b4 c5\n62. Qc2+ Ka1 63. Qb2# 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O-O",
          "aggressive_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Qe2+",
            "Be7",
            "d3",
            "O-O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxg4",
          "positional_uci": "f3g4",
          "positional_response": "9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O-O 12. Bg5 Rhe8 13. Bxf6 Bxf6 14. Qg4+ Kb8 15. Nc3 Rd4 16. Qf3 Rb4 17. Re1 Rd8 18. Ne4 Bxb2 19. Rb1 Ba3 20. Rxb4 Bxb4 21. Qxf7 Rf8 22. Qxg7 h5 23. Ke2 Re8 24. Rb1 Ba5 25. Qf7 Re5 26. Qf8+ Ka7 27. Qc8 Bb6 28. f4 Ra5 29. Rb2 h4 30. f5 Re5 31. f6 Bd4 32. Qxb7# Qxb7 Rxb7 Rxb7#",
          "positional_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 207,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Qe2+",
            "Be7",
            "d3",
            "O-O-O",
            "Bg5",
            "Rhe8",
            "Bxf6",
            "Bxf6",
            "Qg4+",
            "Kb8",
            "Nc3",
            "Rd4",
            "Qf3",
            "Rb4",
            "Re1",
            "Rd8",
            "Ne4",
            "Bxb2",
            "Rb1",
            "Ba3",
            "Rxb4",
            "Bxb4",
            "Qxf7",
            "Rf8",
            "Qxg7",
            "h5",
            "Ke2",
            "Re8",
            "Rb1",
            "Ba5",
            "Qf7",
            "Re5",
            "Qf8+",
            "Ka7",
            "Qc8",
            "Bb6",
            "f4",
            "Ra5",
            "Rb2",
            "h4",
            "f5",
            "Re5",
            "f6",
            "Bd4",
            "Qxb7#",
            "Qxb7",
            "Rxb7",
            "Rxb7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxg4",
          "neutral_uci": "f3g4",
          "neutral_response": "9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O-O 12. Bg5 Rhe8 13. Bxf6 Bxf6 14. Qg4+ Kb8\n15. Nc3 Rd4 16. Qf3 Rb4 17. Re1 Rd8 18. Ne4 Bxb2 19. Rb1 a5 20. c3 Rb6 21. Qe2 Ba3\n22. Rxb6 cxb6 23. g3 f5 24. Ng5 h6 25. Ne6 Re8 26. Qe5+ Ka7 27. Qxf5 Bb2 28. c4 Bf6\n29. Kg2 Re7 30. Re1 Rd7 31. Re3 Rd6 32. c5 Rd5 33. cxb6+ Kxb6 34. Qe4 Ka6 35. Nc7+ Ka7\n36. Nxd5 cxd5 37. Qxd5 b6 38. Qd7+ Ka6 39. Re8 b5 40. Ra8+ Kb6 41. Qd6+ Kb7 42. Qa6+ Kc7\n43. Ra7+ Kd8 44. Qd6+ Ke8 45. Qb8+ Bd8 46. Qxb5+ Kf8 47. Qf5+ Kg8 48. Qf7+ Kh8 49. Qxg7# Qe4 Qg4",
          "neutral_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 349,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Qe2+",
            "Be7",
            "d3",
            "O-O-O",
            "Bg5",
            "Rhe8",
            "Bxf6",
            "Bxf6",
            "Qg4+",
            "Kb8",
            "Nc3",
            "Rd4",
            "Qf3",
            "Rb4",
            "Re1",
            "Rd8",
            "Ne4",
            "Bxb2",
            "Rb1",
            "a5",
            "c3",
            "Rb6",
            "Qe2",
            "Ba3",
            "Rxb6",
            "cxb6",
            "g3",
            "f5",
            "Ng5",
            "h6",
            "Ne6",
            "Re8",
            "Qe5+",
            "Ka7",
            "Qxf5",
            "Bb2",
            "c4",
            "Bf6",
            "Kg2",
            "Re7",
            "Re1",
            "Rd7",
            "Re3",
            "Rd6",
            "c5",
            "Rd5",
            "cxb6+",
            "Kxb6",
            "Qe4",
            "Ka6",
            "Nc7+",
            "Ka7",
            "Nxd5",
            "cxd5",
            "Qxd5",
            "b6",
            "Qd7+",
            "Ka6",
            "Re8",
            "b5",
            "Ra8+",
            "Kb6",
            "Qd6+",
            "Kb7",
            "Qa6+",
            "Kc7",
            "Ra7+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qb8+",
            "Bd8",
            "Qxb5+",
            "Kf8",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qxg7#",
            "Qe4",
            "Qg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3g4",
          "positional_uci": "f3g4",
          "neutral_uci": "f3g4",
          "consensus_move": "f3g4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Qe2+",
              "Be7",
              "d3",
              "O-O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Qe2+",
              "Be7",
              "d3",
              "O-O-O",
              "Bg5",
              "Rhe8",
              "Bxf6",
              "Bxf6",
              "Qg4+",
              "Kb8",
              "Nc3",
              "Rd4",
              "Qf3",
              "Rb4",
              "Re1",
              "Rd8",
              "Ne4",
              "Bxb2",
              "Rb1",
              "Ba3",
              "Rxb4",
              "Bxb4",
              "Qxf7",
              "Rf8",
              "Qxg7",
              "h5",
              "Ke2",
              "Re8",
              "Rb1",
              "Ba5",
              "Qf7",
              "Re5",
              "Qf8+",
              "Ka7",
              "Qc8",
              "Bb6",
              "f4",
              "Ra5",
              "Rb2",
              "h4",
              "f5",
              "Re5",
              "f6",
              "Bd4",
              "Qxb7#",
              "Qxb7",
              "Rxb7",
              "Rxb7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Qe2+",
              "Be7",
              "d3",
              "O-O-O",
              "Bg5",
              "Rhe8",
              "Bxf6",
              "Bxf6",
              "Qg4+",
              "Kb8",
              "Nc3",
              "Rd4",
              "Qf3",
              "Rb4",
              "Re1",
              "Rd8",
              "Ne4",
              "Bxb2",
              "Rb1",
              "a5",
              "c3",
              "Rb6",
              "Qe2",
              "Ba3",
              "Rxb6",
              "cxb6",
              "g3",
              "f5",
              "Ng5",
              "h6",
              "Ne6",
              "Re8",
              "Qe5+",
              "Ka7",
              "Qxf5",
              "Bb2",
              "c4",
              "Bf6",
              "Kg2",
              "Re7",
              "Re1",
              "Rd7",
              "Re3",
              "Rd6",
              "c5",
              "Rd5",
              "cxb6+",
              "Kxb6",
              "Qe4",
              "Ka6",
              "Nc7+",
              "Ka7",
              "Nxd5",
              "cxd5",
              "Qxd5",
              "b6",
              "Qd7+",
              "Ka6",
              "Re8",
              "b5",
              "Ra8+",
              "Kb6",
              "Qd6+",
              "Kb7",
              "Qa6+",
              "Kc7",
              "Ra7+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qb8+",
              "Bd8",
              "Qxb5+",
              "Kf8",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qxg7#",
              "Qe4",
              "Qg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 179,
            "completion_tokens": 207,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 178,
            "completion_tokens": 349,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 536,
          "total_completion_tokens": 1196,
          "total_tokens": 1732
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 179,
            "completion_tokens": 207,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 178,
            "completion_tokens": 349,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3kbnr/1pp2ppp/p1p5/8/6b1/5Q2/PPPP1PPP/RNB2K1R w kq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe2+",
          "aggressive_uci": "g4e2",
          "aggressive_response": "10. Qe2+ Be7 11. d3 O-O-O 12. Qxe7 Rhe8 13. Qxf7 Rd7 14. Qb3 Rde7 15. Be3 Ng4 16. Nd2 Nxe3+ 17. fxe3 Rxe3 18. Ne4 Rf8+ 19. Kg1 Re2 20. Qe6+ Kb8 21. Qe7 Rf4 22. Qxg7 Rxc2 23. Qxh7 Rxb2 24. Qh8+ Ka7 25. Qxb2 Rf5 26. Rb1 Rb5 27. Qd4+ b6 28. Rxb5 axb5 29. Qd7 Kb7 30. Nd6+ Ka6 31. Qxc6 Ka5 32. Qxb5# Qd4+ Nxd4 Nf3",
          "aggressive_tokens": {
            "prompt_tokens": 189,
            "completion_tokens": 207,
            "total_tokens": 396,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "d3",
            "O-O-O",
            "Qxe7",
            "Rhe8",
            "Qxf7",
            "Rd7",
            "Qb3",
            "Rde7",
            "Be3",
            "Ng4",
            "Nd2",
            "Nxe3+",
            "fxe3",
            "Rxe3",
            "Ne4",
            "Rf8+",
            "Kg1",
            "Re2",
            "Qe6+",
            "Kb8",
            "Qe7",
            "Rf4",
            "Qxg7",
            "Rxc2",
            "Qxh7",
            "Rxb2",
            "Qh8+",
            "Ka7",
            "Qxb2",
            "Rf5",
            "Rb1",
            "Rb5",
            "Qd4+",
            "b6",
            "Rxb5",
            "axb5",
            "Qd7",
            "Kb7",
            "Nd6+",
            "Ka6",
            "Qxc6",
            "Ka5",
            "Qxb5#",
            "Qd4+",
            "Nxd4",
            "Nf3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe2+",
          "positional_uci": "g4e2",
          "positional_response": "10. Qe2+ Be7 11. d3 O-O-O 12. Bg5 Rhe8 13. Bxf6 Bxf6 14. Qg4+ Kb8 15. Nc3 Rd4 16. Qf3 Rb4 17. Re1 Rd8 18. Ne4 Bxb2 19. Rb1 Ba3 20. Rxb4 Bxb4 21. Qxf7 Rf8 22. Qxg7 Re8 23. Qxh7 Re7 24. Qg8+ Ka7 25. Qc4 Ba5 26. Qc5+ Bb6 27. Qxe7 c5 28. Nxc5 a5 29. Nd7 a4 30. Nxb6 cxb6 31. Ke2 Ka6 32. Rb1 b5 33. Qd6+ b6 34. Qb8 Ka5 35. Qa7# Qd4 Qe2 Qe3",
          "positional_tokens": {
            "prompt_tokens": 189,
            "completion_tokens": 226,
            "total_tokens": 415,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe2+",
          "neutral_uci": "g4e2",
          "neutral_response": "10. Qe2+ Be7 11. d3 O-O-O 12. Bg5 Rhe8 13. Bxf6 Bxf6 14. Qg4+ Kb8 15. Nc3 Rd4 16. Qf3 Rb4 17. Re1 Rd8 18. Ne4 Bxb2 19. Rb1 Ba3 20. Rxb4 Bxb4 21. Qxf7 Rd5 22. Qxg7 Ra5 23. Qg8+ Ka7 24. Qb3 c5 25. c3 Ra3 26. Qxa3 Bxa3 27. Ke2 b5 28. Rb1 b4 29. cxb4 cxb4 30. Nc5 Kb6 31. Nb3 a5 32. f4 a4 33. Nd4 Kc5 34. Nc2 b3 35. axb3 axb3 36. Nxa3 Kb4 37. Nc4 Kc3 38. f5 Kc2 39. Rb2+ Kc3 40. f6 c5 41. f7 h5 42. f8=Q h4 43. Qf6+ Kb4 44. Qb6+ Kc3 45. Qxb3+ Kd4 46. Qb6 h3 47. Qd6+ Kc3 48. Qe5# Qxe5+ 49. Nxe5 Kxb2 50. gxh3 Kc3 51. h4 Kd4 52. Nf3+ Kd5 53. h5 Ke6 54. h6 Kf7 55. Ng5+ Kg6 56. h7 Kg7 57. Ke3 Kh8 58. Ke4 Kg7 59. Kd5 Kh8 60. Kxc5 Kg7 61. d4 Kh8 62. d5 Kg7 63. d6 Kh8 64. d7 Kg7 65. d8=Q Kh6 66. h8=Q+ Kg6 67. Qdf6# Qxf6 68. Qxf6+ Kxf6 69. Ne4+ Ke5 70. h4 Kf4 71. h5 Kf5 72. Kd5 Kg4 73. h6 Kh5 74. h7 Kg6 75. h8=Q Kf7 76. Qf6+ Kg8 77. Qe7 Kh8 78. Ke6 Kg8 79. Nf6+ Kh8 80. Qh7# Qxf6+ 81. Kxf6 c5 82. Qg7# Qxf6+ 83. Kxf6 c4 84. Kg6 cxd3 85. Qf8# Qxf6+ 86",
          "neutral_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "d3",
            "O-O-O",
            "Bg5",
            "Rhe8",
            "Bxf6",
            "Bxf6",
            "Qg4+",
            "Kb8",
            "Nc3",
            "Rd4",
            "Qf3",
            "Rb4",
            "Re1",
            "Rd8",
            "Ne4",
            "Bxb2",
            "Rb1",
            "Ba3",
            "Rxb4",
            "Bxb4",
            "Qxf7",
            "Rd5",
            "Qxg7",
            "Ra5",
            "Qg8+",
            "Ka7",
            "Qb3",
            "c5",
            "c3",
            "Ra3",
            "Qxa3",
            "Bxa3",
            "Ke2",
            "b5",
            "Rb1",
            "b4",
            "cxb4",
            "cxb4",
            "Nc5",
            "Kb6",
            "Nb3",
            "a5",
            "f4",
            "a4",
            "Nd4",
            "Kc5",
            "Nc2",
            "b3",
            "axb3",
            "axb3",
            "Nxa3",
            "Kb4",
            "Nc4",
            "Kc3",
            "f5",
            "Kc2",
            "Rb2+",
            "Kc3",
            "f6",
            "c5",
            "f7",
            "h5",
            "f8=Q",
            "h4",
            "Qf6+",
            "Kb4",
            "Qb6+",
            "Kc3",
            "Qxb3+",
            "Kd4",
            "Qb6",
            "h3",
            "Qd6+",
            "Kc3",
            "Qe5#",
            "Qxe5+",
            "Nxe5",
            "Kxb2",
            "gxh3",
            "Kc3",
            "h4",
            "Kd4",
            "Nf3+",
            "Kd5",
            "h5",
            "Ke6",
            "h6",
            "Kf7",
            "Ng5+",
            "Kg6",
            "h7",
            "Kg7",
            "Ke3",
            "Kh8",
            "Ke4",
            "Kg7",
            "Kd5",
            "Kh8",
            "Kxc5",
            "Kg7",
            "d4",
            "Kh8",
            "d5",
            "Kg7",
            "d6",
            "Kh8",
            "d7",
            "Kg7",
            "d8=Q",
            "Kh6",
            "h8=Q+",
            "Kg6",
            "Qdf6#",
            "Qxf6",
            "Qxf6+",
            "Kxf6",
            "Ne4+",
            "Ke5",
            "h4",
            "Kf4",
            "h5",
            "Kf5",
            "Kd5",
            "Kg4",
            "h6",
            "Kh5",
            "h7",
            "Kg6",
            "h8=Q",
            "Kf7",
            "Qf6+",
            "Kg8",
            "Qe7",
            "Kh8",
            "Ke6",
            "Kg8",
            "Nf6+",
            "Kh8",
            "Qh7#",
            "Qxf6+",
            "Kxf6",
            "c5",
            "Qg7#",
            "Qxf6+",
            "Kxf6",
            "c4",
            "Kg6",
            "cxd3",
            "Qf8#",
            "Qxf6+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4e2",
          "positional_uci": "g4e2",
          "neutral_uci": "g4e2",
          "consensus_move": "g4e2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "d3",
              "O-O-O",
              "Qxe7",
              "Rhe8",
              "Qxf7",
              "Rd7",
              "Qb3",
              "Rde7",
              "Be3",
              "Ng4",
              "Nd2",
              "Nxe3+",
              "fxe3",
              "Rxe3",
              "Ne4",
              "Rf8+",
              "Kg1",
              "Re2",
              "Qe6+",
              "Kb8",
              "Qe7",
              "Rf4",
              "Qxg7",
              "Rxc2",
              "Qxh7",
              "Rxb2",
              "Qh8+",
              "Ka7",
              "Qxb2",
              "Rf5",
              "Rb1",
              "Rb5",
              "Qd4+",
              "b6",
              "Rxb5",
              "axb5",
              "Qd7",
              "Kb7",
              "Nd6+",
              "Ka6",
              "Qxc6",
              "Ka5",
              "Qxb5#",
              "Qd4+",
              "Nxd4",
              "Nf3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "d3",
              "O-O-O",
              "Bg5",
              "Rhe8",
              "Bxf6",
              "Bxf6",
              "Qg4+",
              "Kb8",
              "Nc3",
              "Rd4",
              "Qf3",
              "Rb4",
              "Re1",
              "Rd8",
              "Ne4",
              "Bxb2",
              "Rb1",
              "Ba3",
              "Rxb4",
              "Bxb4",
              "Qxf7",
              "Rd5",
              "Qxg7",
              "Ra5",
              "Qg8+",
              "Ka7",
              "Qb3",
              "c5",
              "c3",
              "Ra3",
              "Qxa3",
              "Bxa3",
              "Ke2",
              "b5",
              "Rb1",
              "b4",
              "cxb4",
              "cxb4",
              "Nc5",
              "Kb6",
              "Nb3",
              "a5",
              "f4",
              "a4",
              "Nd4",
              "Kc5",
              "Nc2",
              "b3",
              "axb3",
              "axb3",
              "Nxa3",
              "Kb4",
              "Nc4",
              "Kc3",
              "f5",
              "Kc2",
              "Rb2+",
              "Kc3",
              "f6",
              "c5",
              "f7",
              "h5",
              "f8=Q",
              "h4",
              "Qf6+",
              "Kb4",
              "Qb6+",
              "Kc3",
              "Qxb3+",
              "Kd4",
              "Qb6",
              "h3",
              "Qd6+",
              "Kc3",
              "Qe5#",
              "Qxe5+",
              "Nxe5",
              "Kxb2",
              "gxh3",
              "Kc3",
              "h4",
              "Kd4",
              "Nf3+",
              "Kd5",
              "h5",
              "Ke6",
              "h6",
              "Kf7",
              "Ng5+",
              "Kg6",
              "h7",
              "Kg7",
              "Ke3",
              "Kh8",
              "Ke4",
              "Kg7",
              "Kd5",
              "Kh8",
              "Kxc5",
              "Kg7",
              "d4",
              "Kh8",
              "d5",
              "Kg7",
              "d6",
              "Kh8",
              "d7",
              "Kg7",
              "d8=Q",
              "Kh6",
              "h8=Q+",
              "Kg6",
              "Qdf6#",
              "Qxf6",
              "Qxf6+",
              "Kxf6",
              "Ne4+",
              "Ke5",
              "h4",
              "Kf4",
              "h5",
              "Kf5",
              "Kd5",
              "Kg4",
              "h6",
              "Kh5",
              "h7",
              "Kg6",
              "h8=Q",
              "Kf7",
              "Qf6+",
              "Kg8",
              "Qe7",
              "Kh8",
              "Ke6",
              "Kg8",
              "Nf6+",
              "Kh8",
              "Qh7#",
              "Qxf6+",
              "Kxf6",
              "c5",
              "Qg7#",
              "Qxf6+",
              "Kxf6",
              "c4",
              "Kg6",
              "cxd3",
              "Qf8#",
              "Qxf6+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 189,
            "completion_tokens": 207,
            "total_tokens": 396,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 189,
            "completion_tokens": 226,
            "total_tokens": 415,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 566,
          "total_completion_tokens": 1073,
          "total_tokens": 1639
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 189,
            "completion_tokens": 207,
            "total_tokens": 396,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 189,
            "completion_tokens": 226,
            "total_tokens": 415,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r3kb1r/1pp2ppp/p1p2n2/8/6Q1/8/PPPP1PPP/RNB2K1R w kq - 1 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d3",
          "aggressive_uci": "d2d3",
          "aggressive_response": "11. d3 O-O-O 12. Qxe7 Rhe8 13. Qxf7 Rd7 14. Qc4 Rde7 15. Be3 Nd5 16. Nc3 Nxe3+ 17. fxe3 Rxe3 18. Qg4+ Kb8 19. Qxg7 R3e7 20. Qg4 Rf8+ 21. Kg1 Ref7 22. h3 Rf4 23. Qg3 R4f7 24. Kh2 Rf6 25. Rhe1 Rg6 26. Qe3 Rfg8 27. Re2 Rg3 28. Qxg3 Rxg3 29. Kxg3 Ka7 30. Re7 Kb6 31. Rxh7 Kc5 32. Rxc7 Kd4 33. Rxb7 Ke3 34. Rb6 Kd2 35. Rxc6 Kxc2 36. Rxa6 Kxb2 37. Rb1+ Kxc3 38. Rc6+ Kxd3 39. Rd1+ Ke4 40. Re6+ Kf5 41. Re8 Kf6 42. Rf1+ Kg7 43. Re4 Kg6 44. Rg4+ Kh5 45. Rf8 Kh6 46. Rh8# e4 Nf6+ Kg5",
          "aggressive_tokens": {
            "prompt_tokens": 198,
            "completion_tokens": 317,
            "total_tokens": 515,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O-O",
            "Qxe7",
            "Rhe8",
            "Qxf7",
            "Rd7",
            "Qc4",
            "Rde7",
            "Be3",
            "Nd5",
            "Nc3",
            "Nxe3+",
            "fxe3",
            "Rxe3",
            "Qg4+",
            "Kb8",
            "Qxg7",
            "R3e7",
            "Qg4",
            "Rf8+",
            "Kg1",
            "Ref7",
            "h3",
            "Rf4",
            "Qg3",
            "R4f7",
            "Kh2",
            "Rf6",
            "Rhe1",
            "Rg6",
            "Qe3",
            "Rfg8",
            "Re2",
            "Rg3",
            "Qxg3",
            "Rxg3",
            "Kxg3",
            "Ka7",
            "Re7",
            "Kb6",
            "Rxh7",
            "Kc5",
            "Rxc7",
            "Kd4",
            "Rxb7",
            "Ke3",
            "Rb6",
            "Kd2",
            "Rxc6",
            "Kxc2",
            "Rxa6",
            "Kxb2",
            "Rb1+",
            "Kxc3",
            "Rc6+",
            "Kxd3",
            "Rd1+",
            "Ke4",
            "Re6+",
            "Kf5",
            "Re8",
            "Kf6",
            "Rf1+",
            "Kg7",
            "Re4",
            "Kg6",
            "Rg4+",
            "Kh5",
            "Rf8",
            "Kh6",
            "Rh8#",
            "e4",
            "Nf6+",
            "Kg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d3",
          "positional_uci": "d2d3",
          "positional_response": "11. d3 O-O 12. Qxe7 Rfe8 13. Qxc7 Rac8 14. Qxb7 Rb8 15. Qxa6 Ra8 16. Qxc6 Rac8 17. Qa4 Ra8 18. Qb3 Rab8 19. Qc3 Rbc8 20. Qd2 Rcd8 21. Nc3 Rc8 22. Qf4 Rcd8 23. Be3 Rc8 24. Re1 Rcd8 25. Bd4 Rc8 26. Rxe8+ Rxe8 27. Bxf6 gxf6 28. Qxf6 Re6 29. Qxe6 fxe6 30. Ke2 Kf7 31. Ke3 Ke7 32. Ke4 Kd6 33. d4 Ke7 34. Ke5 Kd7 35. d5 Ke7 36. dxe6 Ke8 37. Kf6 Kf8 38. e7+ Ke8 39. Ke6 h5 40. Nd5 h4 41. Nc7# e5 e4 dxe4",
          "positional_tokens": {
            "prompt_tokens": 198,
            "completion_tokens": 256,
            "total_tokens": 454,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Qxe7",
            "Rfe8",
            "Qxc7",
            "Rac8",
            "Qxb7",
            "Rb8",
            "Qxa6",
            "Ra8",
            "Qxc6",
            "Rac8",
            "Qa4",
            "Ra8",
            "Qb3",
            "Rab8",
            "Qc3",
            "Rbc8",
            "Qd2",
            "Rcd8",
            "Nc3",
            "Rc8",
            "Qf4",
            "Rcd8",
            "Be3",
            "Rc8",
            "Re1",
            "Rcd8",
            "Bd4",
            "Rc8",
            "Rxe8+",
            "Rxe8",
            "Bxf6",
            "gxf6",
            "Qxf6",
            "Re6",
            "Qxe6",
            "fxe6",
            "Ke2",
            "Kf7",
            "Ke3",
            "Ke7",
            "Ke4",
            "Kd6",
            "d4",
            "Ke7",
            "Ke5",
            "Kd7",
            "d5",
            "Ke7",
            "dxe6",
            "Ke8",
            "Kf6",
            "Kf8",
            "e7+",
            "Ke8",
            "Ke6",
            "h5",
            "Nd5",
            "h4",
            "Nc7#",
            "e5",
            "e4",
            "dxe4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d3",
          "neutral_uci": "d2d3",
          "neutral_response": "11. d3 O-O 12. Qxe7 Rfe8 13. Qxc7 Rac8 14. Qxb7 Rb8 15. Qxc6 Rbc8 16. Qxa6 Ra8\n17. Qc4 Rac8 18. Qb3 Rb8 19. Qa3 Ra8 20. Qc5 Rac8 21. Qf5 Rxc2 22. Nc3 Rc8\n23. Qxc8+ Ne8 24. Qxe8# Qxe8 25. Be3 Rxb2 26. Re1 Qc8 27. Bd4 Qd8 28. Nd5 Rxa2\n29. Ne7+ Kh8 30. Nf5 Kg8 31. Nxg7 Qxd4 32. Nf5 Qxf2# Qxf2+ 34. Nxf2",
          "neutral_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 196,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Qxe7",
            "Rfe8",
            "Qxc7",
            "Rac8",
            "Qxb7",
            "Rb8",
            "Qxc6",
            "Rbc8",
            "Qxa6",
            "Ra8",
            "Qc4",
            "Rac8",
            "Qb3",
            "Rb8",
            "Qa3",
            "Ra8",
            "Qc5",
            "Rac8",
            "Qf5",
            "Rxc2",
            "Nc3",
            "Rc8",
            "Qxc8+",
            "Ne8",
            "Qxe8#",
            "Qxe8",
            "Be3",
            "Rxb2",
            "Re1",
            "Qc8",
            "Bd4",
            "Qd8",
            "Nd5",
            "Rxa2",
            "Ne7+",
            "Kh8",
            "Nf5",
            "Kg8",
            "Nxg7",
            "Qxd4",
            "Nf5",
            "Qxf2#",
            "Qxf2+",
            "Nxf2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d3",
          "positional_uci": "d2d3",
          "neutral_uci": "d2d3",
          "consensus_move": "d2d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O-O",
              "Qxe7",
              "Rhe8",
              "Qxf7",
              "Rd7",
              "Qc4",
              "Rde7",
              "Be3",
              "Nd5",
              "Nc3",
              "Nxe3+",
              "fxe3",
              "Rxe3",
              "Qg4+",
              "Kb8",
              "Qxg7",
              "R3e7",
              "Qg4",
              "Rf8+",
              "Kg1",
              "Ref7",
              "h3",
              "Rf4",
              "Qg3",
              "R4f7",
              "Kh2",
              "Rf6",
              "Rhe1",
              "Rg6",
              "Qe3",
              "Rfg8",
              "Re2",
              "Rg3",
              "Qxg3",
              "Rxg3",
              "Kxg3",
              "Ka7",
              "Re7",
              "Kb6",
              "Rxh7",
              "Kc5",
              "Rxc7",
              "Kd4",
              "Rxb7",
              "Ke3",
              "Rb6",
              "Kd2",
              "Rxc6",
              "Kxc2",
              "Rxa6",
              "Kxb2",
              "Rb1+",
              "Kxc3",
              "Rc6+",
              "Kxd3",
              "Rd1+",
              "Ke4",
              "Re6+",
              "Kf5",
              "Re8",
              "Kf6",
              "Rf1+",
              "Kg7",
              "Re4",
              "Kg6",
              "Rg4+",
              "Kh5",
              "Rf8",
              "Kh6",
              "Rh8#",
              "e4",
              "Nf6+",
              "Kg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Qxe7",
              "Rfe8",
              "Qxc7",
              "Rac8",
              "Qxb7",
              "Rb8",
              "Qxa6",
              "Ra8",
              "Qxc6",
              "Rac8",
              "Qa4",
              "Ra8",
              "Qb3",
              "Rab8",
              "Qc3",
              "Rbc8",
              "Qd2",
              "Rcd8",
              "Nc3",
              "Rc8",
              "Qf4",
              "Rcd8",
              "Be3",
              "Rc8",
              "Re1",
              "Rcd8",
              "Bd4",
              "Rc8",
              "Rxe8+",
              "Rxe8",
              "Bxf6",
              "gxf6",
              "Qxf6",
              "Re6",
              "Qxe6",
              "fxe6",
              "Ke2",
              "Kf7",
              "Ke3",
              "Ke7",
              "Ke4",
              "Kd6",
              "d4",
              "Ke7",
              "Ke5",
              "Kd7",
              "d5",
              "Ke7",
              "dxe6",
              "Ke8",
              "Kf6",
              "Kf8",
              "e7+",
              "Ke8",
              "Ke6",
              "h5",
              "Nd5",
              "h4",
              "Nc7#",
              "e5",
              "e4",
              "dxe4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Qxe7",
              "Rfe8",
              "Qxc7",
              "Rac8",
              "Qxb7",
              "Rb8",
              "Qxc6",
              "Rbc8",
              "Qxa6",
              "Ra8",
              "Qc4",
              "Rac8",
              "Qb3",
              "Rb8",
              "Qa3",
              "Ra8",
              "Qc5",
              "Rac8",
              "Qf5",
              "Rxc2",
              "Nc3",
              "Rc8",
              "Qxc8+",
              "Ne8",
              "Qxe8#",
              "Qxe8",
              "Be3",
              "Rxb2",
              "Re1",
              "Qc8",
              "Bd4",
              "Qd8",
              "Nd5",
              "Rxa2",
              "Ne7+",
              "Kh8",
              "Nf5",
              "Kg8",
              "Nxg7",
              "Qxd4",
              "Nf5",
              "Qxf2#",
              "Qxf2+",
              "Nxf2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 198,
            "completion_tokens": 317,
            "total_tokens": 515,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 198,
            "completion_tokens": 256,
            "total_tokens": 454,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 197,
            "completion_tokens": 196,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 593,
          "total_completion_tokens": 769,
          "total_tokens": 1362
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 198,
            "completion_tokens": 317,
            "total_tokens": 515,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 198,
            "completion_tokens": 256,
            "total_tokens": 454,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 197,
            "completion_tokens": 196,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3k2r/1pp1bppp/p1p2n2/8/8/8/PPPPQPPP/RNB2K1R w kq - 3 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe7",
          "aggressive_uci": "e2e7",
          "aggressive_response": "12. Qxe7 Rfe8 13. Qxc7 Rac8 14. Qxb7 Rb8 15. Qxc6 Rbc8 16. Qxa6 Ra8 17. Qc4 Rac8\n18. Qb3 Rb8 19. Qa3 Ra8 20. Qc3 Rac8 21. Qd2 Rcd8 22. Nc3 Rc8 23. Qg5 h6 24. Qg3\nNh5 25. Qg4 Nf6 26. Qg3 Nh5 27. Qh4 Nf6 28. Bxh6 gxh6 29. Qxf6 Re6 30. Qf5 Rce8\n31. Ne4 Re5 32. Nf6+ Kf8 33. Qh7 Ke7 34. Nxe8 Kxe8 35. Qh8+ Ke7 36. Qxe5+ Kf8\n37. Qh8+ Ke7 38. Qxh6 f6 39. Re1+ Kf7 40. Qh7+ Kf8 41. Qe7+ Kg8 42. Qxf6 Kh7\n43. Re7+ Kg8 44. Qg7# Qxe7 45. Qxe7 Kh8 46. Qf8+ Kh7 47. Qf7+ Kh8 48. Qf6+ Kh7\n49. Qf5+ Kh8 50. Qh5+ Kg7 51. Qg5+ Kh8 52. Qh6+ Kg8 53. Qg6+ Kh8 54. Qh6+ Kg8\n55. Qg6+ Kh8 56. Qh6+ Kg8 57. Qg6+ Kh8 58. Qh6+ Kg8 59. Qg6+ Kh8 60. Qh6+ Kg8\n61. Qg6+ Kh8 62. Qh6+ Kg8 63. Qg6+ Kh8 64. Qh6+ Kg8 65. Qg6+ Kh8 66. Qh6+ Kg8\n67. Qg6+ Kh8 68. Qh6+ Kg8 69. Qg6+ Kh8 70. Qh6+ Kg8 71. Qg6+ Kh8 72. Qh6+ Kg8\n73. Qg6+ Kh8 74. Qh6+ Kg8 75. Qg6+ Kh8 76. Qh6+ Kg8 77. Qg6+ Kh8 78. Qh6+ Kg8\n79. Qg6+ Kh8 80. Qh6+ Kg8 81. Qg6+ Kh8 82. Qh6+ Kg8 83. Qg6+ Kh8 84",
          "aggressive_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 640,
            "total_tokens": 845,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh8",
            "Qf8+",
            "Kh7",
            "Qf7+",
            "Kh8",
            "Qf6+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qh5+",
            "Kg7",
            "Qg5+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe7",
          "positional_uci": "e2e7",
          "positional_response": "12. Qxe7 Rae8 13. Qxc7 Nd5 14. Qxb7 Re7 15. Qxc6 Rfe8 16. Bd2 Nb4 17. Bxb4 Re6\n18. Qc4 a5 19. Bxa5 Ra8 20. Qd5 Rae8 21. Nc3 Re5 22. Qd7 R5e7 23. Qd4 Re5\n24. Bb4 R5e6 25. Ne4 f5 26. Ng5 Re5 27. Qc4+ Kh8 28. Nf7+ Kg8 29. Nxe5+ Kh8\n30. Nf7+ Kg8 31. Nh6+ Kh8 32. Qg8+ Rxg8 33. Nf7#",
          "positional_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 183,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qxc7",
            "Nd5",
            "Qxb7",
            "Re7",
            "Qxc6",
            "Rfe8",
            "Bd2",
            "Nb4",
            "Bxb4",
            "Re6",
            "Qc4",
            "a5",
            "Bxa5",
            "Ra8",
            "Qd5",
            "Rae8",
            "Nc3",
            "Re5",
            "Qd7",
            "R5e7",
            "Qd4",
            "Re5",
            "Bb4",
            "R5e6",
            "Ne4",
            "f5",
            "Ng5",
            "Re5",
            "Qc4+",
            "Kh8",
            "Nf7+",
            "Kg8",
            "Nxe5+",
            "Kh8",
            "Nf7+",
            "Kg8",
            "Nh6+",
            "Kh8",
            "Qg8+",
            "Rxg8",
            "Nf7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe7",
          "neutral_uci": "e2e7",
          "neutral_response": "12. Qxe7 Rfe8 13. Qxc7 Rac8 14. Qxb7 Rb8 15. Qxc6 Rbc8 16. Qxa6 Ra8 17. Qc4 Rac8\n18. Qb3 Rb8 19. Qa3 Ra8 20. Qc3 Rac8 21. Qd2 Rcd8 22. Nc3 Rc8 23. Qf4 Rcd8 24. Be3 Rc8\n25. Re1 Rcd8 26. Bd4 Rc8 27. Rxe8+ Rxe8 28. Bxf6 gxf6 29. Qxf6 Rf8 30. Nd5 Re8 31. Ne7+ Kf8\n32. Nf5 Re6 33. Qh8# Rxe7 34. Qh8# Rxe7 35. Qxh7# Rxe7 36. Qh8# Rxe7 37. Qxh7# Rxe7 38. Qh8# Rxe7 39. Qxh7# Rxe7 40. Qh8# Rxe7 41. Qxh7# Rxe7 42. Qh8# Rxe7 43. Qxh7# Rxe7 44. Qh8# Rxe7 45. Qxh7# Rxe7 46. Qh8# Rxe7 47. Qxh7# Rxe7 48. Qh8# Rxe7 49. Qxh7# Rxe7 50. Qh8# Rxe7 51. Qxh7# Rxe7 52. Qh8# Rxe7 53. Qxh7# Rxe7 54. Qh8# Rxe7 55. Qxh7# Rxe7 56. Qh8# Rxe7 57. Qxh7# Rxe7 58. Qh8# Rxe7 59. Qxh7# Rxe7 60. Qh8# Rxe7 61. Qxh7# Rxe7 62. Qh8# Rxe7 63. Qxh7# Rxe7 64. Qh8# Rxe7 65. Qxh7# Rxe7 66. Qh8# Rxe7 67. Qxh7# Rxe7 68. Qh8# Rxe7 69. Qxh7# Rxe7 70. Qh8# Rxe7 71. Qxh7# Rxe7 72. Qh8# Rxe7 73. Qxh7# Rxe7 74. Qh8# Rxe7 75. Qxh7# Rxe7 76. Qh8# Rxe7 77.",
          "neutral_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 640,
            "total_tokens": 844,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rfe8",
            "Qxc7",
            "Rac8",
            "Qxb7",
            "Rb8",
            "Qxc6",
            "Rbc8",
            "Qxa6",
            "Ra8",
            "Qc4",
            "Rac8",
            "Qb3",
            "Rb8",
            "Qa3",
            "Ra8",
            "Qc3",
            "Rac8",
            "Qd2",
            "Rcd8",
            "Nc3",
            "Rc8",
            "Qf4",
            "Rcd8",
            "Be3",
            "Rc8",
            "Re1",
            "Rcd8",
            "Bd4",
            "Rc8",
            "Rxe8+",
            "Rxe8",
            "Bxf6",
            "gxf6",
            "Qxf6",
            "Rf8",
            "Nd5",
            "Re8",
            "Ne7+",
            "Kf8",
            "Nf5",
            "Re6",
            "Qh8#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7",
            "Qxh7#",
            "Rxe7",
            "Qh8#",
            "Rxe7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e7",
          "positional_uci": "e2e7",
          "neutral_uci": "e2e7",
          "consensus_move": "e2e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kh8",
              "Qf8+",
              "Kh7",
              "Qf7+",
              "Kh8",
              "Qf6+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qh5+",
              "Kg7",
              "Qg5+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rae8",
              "Qxc7",
              "Nd5",
              "Qxb7",
              "Re7",
              "Qxc6",
              "Rfe8",
              "Bd2",
              "Nb4",
              "Bxb4",
              "Re6",
              "Qc4",
              "a5",
              "Bxa5",
              "Ra8",
              "Qd5",
              "Rae8",
              "Nc3",
              "Re5",
              "Qd7",
              "R5e7",
              "Qd4",
              "Re5",
              "Bb4",
              "R5e6",
              "Ne4",
              "f5",
              "Ng5",
              "Re5",
              "Qc4+",
              "Kh8",
              "Nf7+",
              "Kg8",
              "Nxe5+",
              "Kh8",
              "Nf7+",
              "Kg8",
              "Nh6+",
              "Kh8",
              "Qg8+",
              "Rxg8",
              "Nf7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rfe8",
              "Qxc7",
              "Rac8",
              "Qxb7",
              "Rb8",
              "Qxc6",
              "Rbc8",
              "Qxa6",
              "Ra8",
              "Qc4",
              "Rac8",
              "Qb3",
              "Rb8",
              "Qa3",
              "Ra8",
              "Qc3",
              "Rac8",
              "Qd2",
              "Rcd8",
              "Nc3",
              "Rc8",
              "Qf4",
              "Rcd8",
              "Be3",
              "Rc8",
              "Re1",
              "Rcd8",
              "Bd4",
              "Rc8",
              "Rxe8+",
              "Rxe8",
              "Bxf6",
              "gxf6",
              "Qxf6",
              "Rf8",
              "Nd5",
              "Re8",
              "Ne7+",
              "Kf8",
              "Nf5",
              "Re6",
              "Qh8#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7",
              "Qxh7#",
              "Rxe7",
              "Qh8#",
              "Rxe7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 205,
            "completion_tokens": 640,
            "total_tokens": 845,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 205,
            "completion_tokens": 183,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 204,
            "completion_tokens": 640,
            "total_tokens": 844,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 614,
          "total_completion_tokens": 1463,
          "total_tokens": 2077
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 205,
            "completion_tokens": 640,
            "total_tokens": 845,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 205,
            "completion_tokens": 183,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 204,
            "completion_tokens": 640,
            "total_tokens": 844,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r4rk1/1pp1bppp/p1p2n2/8/8/3P4/PPP1QPPP/RNB2K1R w - - 1 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe2",
          "aggressive_uci": "e7e2",
          "aggressive_response": "13. Qe2 Rae8 14. Qd1 Re6 15. Nc3 Rfe8 16. Nxd5 cxd5 17. Be3 c5 18. Bxc5 b6 19. Be3 d4 20. Bxd4 b5 21. Qg4 g6 22. Qh4 h5 23. Qg5 Kh7 24. g4 hxg4 25. Qh4+ Kg8 26. Qh8# e4 Nxe4 dxe4",
          "aggressive_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 120,
            "total_tokens": 333,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qd1",
            "Re6",
            "Nc3",
            "Rfe8",
            "Nxd5",
            "cxd5",
            "Be3",
            "c5",
            "Bxc5",
            "b6",
            "Be3",
            "d4",
            "Bxd4",
            "b5",
            "Qg4",
            "g6",
            "Qh4",
            "h5",
            "Qg5",
            "Kh7",
            "g4",
            "hxg4",
            "Qh4+",
            "Kg8",
            "Qh8#",
            "e4",
            "Nxe4",
            "dxe4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe2",
          "positional_uci": "e7e2",
          "positional_response": "13. Qe2 Rae8 14. Qd1 Re6 15. Nc3 Rfe8 16. Nxd5 cxd5 17. Be3 c5 18. Bxc5 b6 19. Be3 d4 20. Bxd4 Rd6 21. Be3 Rde6 22. Qd2 f5 23. Re1 f4 24. Bxf4 Rxe1+ 25. Qxe1 Rxe1+ 26. Kxe1 Kf7 27. Kd2 Ke6 28. Re1+ Kf5 29. Be3 g5 30. Bxb6 h5 31. Re4 g4 32. Ra4 h4 33. Rxa6 g3 34. fxg3 hxg3 35. hxg3 Kg4 36. Bc7 Kf5 37. Ra4 Ke6 38. Rf4 Kd7 39. Ba5 Kc6 40. Bc3 Kd5 41. g4 Ke6 42. g5 Kd5 43. g6 Ke6 44. g7 Kd5 45. g8=Q+ Kc6 46. Qg5 Kd7 47. Rf6 Ke8 48. Qg7 Kd8 49. Rf8# e4 50. dxe4 Ke8 51. e5 Kd8 52. e6 Ke8 53. Qf7# e3+ 54. Kxe3",
          "positional_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 344,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qd1",
            "Re6",
            "Nc3",
            "Rfe8",
            "Nxd5",
            "cxd5",
            "Be3",
            "c5",
            "Bxc5",
            "b6",
            "Be3",
            "d4",
            "Bxd4",
            "Rd6",
            "Be3",
            "Rde6",
            "Qd2",
            "f5",
            "Re1",
            "f4",
            "Bxf4",
            "Rxe1+",
            "Qxe1",
            "Rxe1+",
            "Kxe1",
            "Kf7",
            "Kd2",
            "Ke6",
            "Re1+",
            "Kf5",
            "Be3",
            "g5",
            "Bxb6",
            "h5",
            "Re4",
            "g4",
            "Ra4",
            "h4",
            "Rxa6",
            "g3",
            "fxg3",
            "hxg3",
            "hxg3",
            "Kg4",
            "Bc7",
            "Kf5",
            "Ra4",
            "Ke6",
            "Rf4",
            "Kd7",
            "Ba5",
            "Kc6",
            "Bc3",
            "Kd5",
            "g4",
            "Ke6",
            "g5",
            "Kd5",
            "g6",
            "Ke6",
            "g7",
            "Kd5",
            "g8=Q+",
            "Kc6",
            "Qg5",
            "Kd7",
            "Rf6",
            "Ke8",
            "Qg7",
            "Kd8",
            "Rf8#",
            "e4",
            "dxe4",
            "Ke8",
            "e5",
            "Kd8",
            "e6",
            "Ke8",
            "Qf7#",
            "e3+",
            "Kxe3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe2",
          "neutral_uci": "e7e2",
          "neutral_response": "13. Qe2 Rae8 14. Qd1 Re6 15. Nc3 Rfe8 16. Nxd5 cxd5 17. Be3 c5 18. Bxc5 b6 19. Be3 d4 20. Bxd4 Rd6 21. Be3 Rde6 22. Qd2 f5 23. Re1 f4 24. Bxf4 Rxe1+ 25. Qxe1 Rxe1+ 26. Kxe1 Kf7 27. Kd2 Ke6 28. Re1+ Kd5 29. Re5+ Kd6 30. Rg5+ Ke6 31. Rxg7 Kf6 32. Rxh7 Kg6 33. Rh6+ Kf5 34. Rxb6 Kxf4 35. Rxa6 Ke5 36. Ra4 Kd5 37. Re4 Kc5 38. f4 Kd5 39. f5 Kd6 40. f6 Kd5 41. f7 Kd6 42. f8=Q+ Kd5 43. Qf5+ Kd6 44. Re6+ Kd7 45. Qf7+ Kd8 46. Re8# e4 47. Qe7# e5 48. Qxe5# e6",
          "neutral_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 308,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qd1",
            "Re6",
            "Nc3",
            "Rfe8",
            "Nxd5",
            "cxd5",
            "Be3",
            "c5",
            "Bxc5",
            "b6",
            "Be3",
            "d4",
            "Bxd4",
            "Rd6",
            "Be3",
            "Rde6",
            "Qd2",
            "f5",
            "Re1",
            "f4",
            "Bxf4",
            "Rxe1+",
            "Qxe1",
            "Rxe1+",
            "Kxe1",
            "Kf7",
            "Kd2",
            "Ke6",
            "Re1+",
            "Kd5",
            "Re5+",
            "Kd6",
            "Rg5+",
            "Ke6",
            "Rxg7",
            "Kf6",
            "Rxh7",
            "Kg6",
            "Rh6+",
            "Kf5",
            "Rxb6",
            "Kxf4",
            "Rxa6",
            "Ke5",
            "Ra4",
            "Kd5",
            "Re4",
            "Kc5",
            "f4",
            "Kd5",
            "f5",
            "Kd6",
            "f6",
            "Kd5",
            "f7",
            "Kd6",
            "f8=Q+",
            "Kd5",
            "Qf5+",
            "Kd6",
            "Re6+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Re8#",
            "e4",
            "Qe7#",
            "e5",
            "Qxe5#",
            "e6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e2",
          "positional_uci": "e7e2",
          "neutral_uci": "e7e2",
          "consensus_move": "e7e2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rae8",
              "Qd1",
              "Re6",
              "Nc3",
              "Rfe8",
              "Nxd5",
              "cxd5",
              "Be3",
              "c5",
              "Bxc5",
              "b6",
              "Be3",
              "d4",
              "Bxd4",
              "b5",
              "Qg4",
              "g6",
              "Qh4",
              "h5",
              "Qg5",
              "Kh7",
              "g4",
              "hxg4",
              "Qh4+",
              "Kg8",
              "Qh8#",
              "e4",
              "Nxe4",
              "dxe4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rae8",
              "Qd1",
              "Re6",
              "Nc3",
              "Rfe8",
              "Nxd5",
              "cxd5",
              "Be3",
              "c5",
              "Bxc5",
              "b6",
              "Be3",
              "d4",
              "Bxd4",
              "Rd6",
              "Be3",
              "Rde6",
              "Qd2",
              "f5",
              "Re1",
              "f4",
              "Bxf4",
              "Rxe1+",
              "Qxe1",
              "Rxe1+",
              "Kxe1",
              "Kf7",
              "Kd2",
              "Ke6",
              "Re1+",
              "Kf5",
              "Be3",
              "g5",
              "Bxb6",
              "h5",
              "Re4",
              "g4",
              "Ra4",
              "h4",
              "Rxa6",
              "g3",
              "fxg3",
              "hxg3",
              "hxg3",
              "Kg4",
              "Bc7",
              "Kf5",
              "Ra4",
              "Ke6",
              "Rf4",
              "Kd7",
              "Ba5",
              "Kc6",
              "Bc3",
              "Kd5",
              "g4",
              "Ke6",
              "g5",
              "Kd5",
              "g6",
              "Ke6",
              "g7",
              "Kd5",
              "g8=Q+",
              "Kc6",
              "Qg5",
              "Kd7",
              "Rf6",
              "Ke8",
              "Qg7",
              "Kd8",
              "Rf8#",
              "e4",
              "dxe4",
              "Ke8",
              "e5",
              "Kd8",
              "e6",
              "Ke8",
              "Qf7#",
              "e3+",
              "Kxe3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rae8",
              "Qd1",
              "Re6",
              "Nc3",
              "Rfe8",
              "Nxd5",
              "cxd5",
              "Be3",
              "c5",
              "Bxc5",
              "b6",
              "Be3",
              "d4",
              "Bxd4",
              "Rd6",
              "Be3",
              "Rde6",
              "Qd2",
              "f5",
              "Re1",
              "f4",
              "Bxf4",
              "Rxe1+",
              "Qxe1",
              "Rxe1+",
              "Kxe1",
              "Kf7",
              "Kd2",
              "Ke6",
              "Re1+",
              "Kd5",
              "Re5+",
              "Kd6",
              "Rg5+",
              "Ke6",
              "Rxg7",
              "Kf6",
              "Rxh7",
              "Kg6",
              "Rh6+",
              "Kf5",
              "Rxb6",
              "Kxf4",
              "Rxa6",
              "Ke5",
              "Ra4",
              "Kd5",
              "Re4",
              "Kc5",
              "f4",
              "Kd5",
              "f5",
              "Kd6",
              "f6",
              "Kd5",
              "f7",
              "Kd6",
              "f8=Q+",
              "Kd5",
              "Qf5+",
              "Kd6",
              "Re6+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Re8#",
              "e4",
              "Qe7#",
              "e5",
              "Qxe5#",
              "e6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 213,
            "completion_tokens": 120,
            "total_tokens": 333,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 213,
            "completion_tokens": 344,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 212,
            "completion_tokens": 308,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 638,
          "total_completion_tokens": 772,
          "total_tokens": 1410
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 213,
            "completion_tokens": 120,
            "total_tokens": 333,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 213,
            "completion_tokens": 344,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 212,
            "completion_tokens": 308,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp1Qppp/p1p5/3n4/8/3P4/PPP2PPP/RNB2K1R w - - 1 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf4",
          "aggressive_uci": "c1f4",
          "aggressive_response": "14. Bxf4 Rfe8 15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 h5 19. Qxh5 g6 20. Qh6 f5 21. Be5 Kf7 22. Qg7+ Ke6 23. Qf6+ Kd5 24. c4+ Kc5 25. Bd4+ Kb4 26. a3+ Kb3 27. Nd2+ Kc2 28. Rhc1# Qd8 29. Qxd8 b5 30. Qxc7 c5 31. Qxc5 b4 32. Qxb4 a5 33. Qc3# Qd8 34. Qxc2# Qd8 35. Qc3# Qd8",
          "aggressive_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 194,
            "total_tokens": 416,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rfe8",
            "Qg4",
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "h5",
            "Qxh5",
            "g6",
            "Qh6",
            "f5",
            "Be5",
            "Kf7",
            "Qg7+",
            "Ke6",
            "Qf6+",
            "Kd5",
            "c4+",
            "Kc5",
            "Bd4+",
            "Kb4",
            "a3+",
            "Kb3",
            "Nd2+",
            "Kc2",
            "Rhc1#",
            "Qd8",
            "Qxd8",
            "b5",
            "Qxc7",
            "c5",
            "Qxc5",
            "b4",
            "Qxb4",
            "a5",
            "Qc3#",
            "Qd8",
            "Qxc2#",
            "Qd8",
            "Qc3#",
            "Qd8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf4",
          "positional_uci": "c1f4",
          "positional_response": "14. Bxf4 Rae8 15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 f5 19. Qxf5 g6 20. Qe6+ Kg7 21. Be5+ Kh6 22. Qh3+ Kg5 23. f4# e5 d5 d4",
          "positional_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 89,
            "total_tokens": 311,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rae8",
            "Qg4",
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "f5",
            "Qxf5",
            "g6",
            "Qe6+",
            "Kg7",
            "Be5+",
            "Kh6",
            "Qh3+",
            "Kg5",
            "f4#",
            "e5",
            "d5",
            "d4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf4",
          "neutral_uci": "c1f4",
          "neutral_response": "14. Bxf4 Rfe8 15. Qd2 Re1+ 16. Qxe1 Re8 17. Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1 Qxf3 Qxf3 Bg4 Qxg4 Nf6 Qe2+ Be7 d3 O-O Qxe7 Nd5 Qe2 Nf4 Bxf4 Rfe8 Qd2 Re1+ Qxe1 Re8 Qxe8# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf3 Qxe4+ Kf1",
          "neutral_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rfe8",
            "Qd2",
            "Re1+",
            "Qxe1",
            "Re8",
            "Qxe8#",
            "e4",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Bxc6",
            "dxc6",
            "Nxe5",
            "Qd4",
            "Nf3",
            "Qxe4+",
            "Kf1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1f4",
          "positional_uci": "c1f4",
          "neutral_uci": "c1f4",
          "consensus_move": "c1f4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rfe8",
              "Qg4",
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "h5",
              "Qxh5",
              "g6",
              "Qh6",
              "f5",
              "Be5",
              "Kf7",
              "Qg7+",
              "Ke6",
              "Qf6+",
              "Kd5",
              "c4+",
              "Kc5",
              "Bd4+",
              "Kb4",
              "a3+",
              "Kb3",
              "Nd2+",
              "Kc2",
              "Rhc1#",
              "Qd8",
              "Qxd8",
              "b5",
              "Qxc7",
              "c5",
              "Qxc5",
              "b4",
              "Qxb4",
              "a5",
              "Qc3#",
              "Qd8",
              "Qxc2#",
              "Qd8",
              "Qc3#",
              "Qd8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rae8",
              "Qg4",
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "f5",
              "Qxf5",
              "g6",
              "Qe6+",
              "Kg7",
              "Be5+",
              "Kh6",
              "Qh3+",
              "Kg5",
              "f4#",
              "e5",
              "d5",
              "d4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rfe8",
              "Qd2",
              "Re1+",
              "Qxe1",
              "Re8",
              "Qxe8#",
              "e4",
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Bxc6",
              "dxc6",
              "Nxe5",
              "Qd4",
              "Nf3",
              "Qxe4+",
              "Kf1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 222,
            "completion_tokens": 194,
            "total_tokens": 416,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 222,
            "completion_tokens": 89,
            "total_tokens": 311,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 665,
          "total_completion_tokens": 923,
          "total_tokens": 1588
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 222,
            "completion_tokens": 194,
            "total_tokens": 416,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 222,
            "completion_tokens": 89,
            "total_tokens": 311,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r4rk1/1pp2ppp/p1p5/8/5n2/3P4/PPP1QPPP/RNB2K1R w - - 3 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qg4",
          "aggressive_uci": "e2g4",
          "aggressive_response": "15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 g5 19. Qxg5+ Kf8 20. Be5\nf6 21. Qxf6+ Ke8 22. Qe6+ Kd8 23. Bf6# e4 Nf6 Qe7#",
          "aggressive_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 89,
            "total_tokens": 320,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Qxg5+",
            "Kf8",
            "Be5",
            "f6",
            "Qxf6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Bf6#",
            "e4",
            "Nf6",
            "Qe7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qg4",
          "positional_uci": "e2g4",
          "positional_response": "15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 g5 19. Qxg5+ Kf8 20. Qd8+ Kg7 21. Be5+ Kg6 22. Qf6+ Kh5 23. g4+ Kxg4 24. Rg1+ Kh3 25. Qh6# e5 Nxe5 Qg7#",
          "positional_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 107,
            "total_tokens": 338,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Qxg5+",
            "Kf8",
            "Qd8+",
            "Kg7",
            "Be5+",
            "Kg6",
            "Qf6+",
            "Kh5",
            "g4+",
            "Kxg4",
            "Rg1+",
            "Kh3",
            "Qh6#",
            "e5",
            "Nxe5",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qg4",
          "neutral_uci": "e2g4",
          "neutral_response": "15. Qg4 Re1+ 16. Kxe1 Re8+ 17. Kd2 Re2+ 18. Kxe2 g5 19. Qxg5+ Kf8 20. Qd8+ Kg7\n21. Be5+ Kg6 22. Qf6+ Kh5 23. g4+ Kxg4 24. Rg1+ Kh3 25. Qh6# e5 Nxe5 Qg7#",
          "neutral_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 107,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Qxg5+",
            "Kf8",
            "Qd8+",
            "Kg7",
            "Be5+",
            "Kg6",
            "Qf6+",
            "Kh5",
            "g4+",
            "Kxg4",
            "Rg1+",
            "Kh3",
            "Qh6#",
            "e5",
            "Nxe5",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2g4",
          "positional_uci": "e2g4",
          "neutral_uci": "e2g4",
          "consensus_move": "e2g4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Qxg5+",
              "Kf8",
              "Be5",
              "f6",
              "Qxf6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Bf6#",
              "e4",
              "Nf6",
              "Qe7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Qxg5+",
              "Kf8",
              "Qd8+",
              "Kg7",
              "Be5+",
              "Kg6",
              "Qf6+",
              "Kh5",
              "g4+",
              "Kxg4",
              "Rg1+",
              "Kh3",
              "Qh6#",
              "e5",
              "Nxe5",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Qxg5+",
              "Kf8",
              "Qd8+",
              "Kg7",
              "Be5+",
              "Kg6",
              "Qf6+",
              "Kh5",
              "g4+",
              "Kxg4",
              "Rg1+",
              "Kh3",
              "Qh6#",
              "e5",
              "Nxe5",
              "Qg7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 231,
            "completion_tokens": 89,
            "total_tokens": 320,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 231,
            "completion_tokens": 107,
            "total_tokens": 338,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 230,
            "completion_tokens": 107,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 692,
          "total_completion_tokens": 303,
          "total_tokens": 995
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 231,
            "completion_tokens": 89,
            "total_tokens": 320,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 231,
            "completion_tokens": 107,
            "total_tokens": 338,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 230,
            "completion_tokens": 107,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2ppp/p1p5/8/5B2/3P4/PPP1QPPP/RN3K1R w - - 1 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxh5",
          "aggressive_uci": "g4h5",
          "aggressive_response": "16. Qxh5 g6 17. Qh6 Re6 18. Nc3 Rae8 19. Ne4 f5 20. Ng5 R6e7 21. Qxg6+ Rg7 22.\nQxe8# g5 23. Be5 Rxe8 24. Bxg7 Kxg7 25. Re1 Rf8 26. Ne6+ Kf7 27. Nxf8 Kxf8 28.\nRe5 Kf7 29. Rxf5+ Kg6 30. g4 b5 31. Kg2 a5 32. Re1 a4 33. Re6+ Kg7 34. Rxc6 b4\n35. Rxc7+ Kg6 36. Rc6+ Kg7 37. Rb5 b3 38. Rb7+ Kf8 39. Rc8# Kd8 40. Rh7 bxa2\n41. Ra8# Kxc8 42. Rh8+ Kb7 43. Rh7+ Kb6 44. Rh6+ Kb5 45. c4+ Kb4 46. Rb6+ Ka5\n47. Rb5+ Ka6 48. Rxg5 a1=Q 49. Rg6+ Kb7 50. Rg7+ Kc6 51. Rg6+ Kd7 52. Rg7+ Ke6\n53. Rg6+ Kf7 54. Rb6 Qd1 55. Rb7+ Ke6 56. Rb6+ Kd7 57. Rb7+ Kc6 58. Rg7 Qxd3\n59. Rg6+ Kc5 60. Rg5+ Kxc4 61. h4 Qe4+ 62. Kg3 Qd3+ 63. f3 Qd6+ 64. Kh3 Qd3\n65. Kg3 Qd6+ 66. Kh3 Qd3 67. Kg3 Qd6+ 68. Kh3 Qd3 69. Kg3 Qd6+ 70. Kh3 Qd3\n71. Kg3 Qd6+ 72. Kh3 Qd3 73. Kg3 Qd6+ 74. Kh3 Qd3 75. Kg3 Qd6+ 76. Kh3 Qd3\n77. Kg3 Qd6+ 78. Kh3 Qd3 79. Kg3 Qd6+ 80. Kh3 Qd3 81. Kg3 Qd6+ 82. Kh3 Qd3\n83. Kg3 Qd6+ 84. Kh3 Qd3 85. Kg3 Qd6+ 86. Kh3 Qd3 87. Kg3 Qd6+ 88. Kh3 Qd3\n89. Kg3",
          "aggressive_tokens": {
            "prompt_tokens": 239,
            "completion_tokens": 640,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "g6",
            "Qh6",
            "Re6",
            "Nc3",
            "Rae8",
            "Ne4",
            "f5",
            "Ng5",
            "R6e7",
            "Qxg6+",
            "Rg7",
            "Qxe8#",
            "g5",
            "Be5",
            "Rxe8",
            "Bxg7",
            "Kxg7",
            "Re1",
            "Rf8",
            "Ne6+",
            "Kf7",
            "Nxf8",
            "Kxf8",
            "Re5",
            "Kf7",
            "Rxf5+",
            "Kg6",
            "g4",
            "b5",
            "Kg2",
            "a5",
            "Re1",
            "a4",
            "Re6+",
            "Kg7",
            "Rxc6",
            "b4",
            "Rxc7+",
            "Kg6",
            "Rc6+",
            "Kg7",
            "Rb5",
            "b3",
            "Rb7+",
            "Kf8",
            "Rc8#",
            "Kd8",
            "Rh7",
            "bxa2",
            "Ra8#",
            "Kxc8",
            "Rh8+",
            "Kb7",
            "Rh7+",
            "Kb6",
            "Rh6+",
            "Kb5",
            "c4+",
            "Kb4",
            "Rb6+",
            "Ka5",
            "Rb5+",
            "Ka6",
            "Rxg5",
            "a1=Q",
            "Rg6+",
            "Kb7",
            "Rg7+",
            "Kc6",
            "Rg6+",
            "Kd7",
            "Rg7+",
            "Ke6",
            "Rg6+",
            "Kf7",
            "Rb6",
            "Qd1",
            "Rb7+",
            "Ke6",
            "Rb6+",
            "Kd7",
            "Rb7+",
            "Kc6",
            "Rg7",
            "Qxd3",
            "Rg6+",
            "Kc5",
            "Rg5+",
            "Kxc4",
            "h4",
            "Qe4+",
            "Kg3",
            "Qd3+",
            "f3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3",
            "Qd6+",
            "Kh3",
            "Qd3",
            "Kg3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxh5",
          "positional_uci": "g4h5",
          "positional_response": "16. Qxh5 g6 17. Qh6 Re6 18. Nc3 Rae8 19. Ne4 f5 20. Ng5 R6e7 21. Qxg6+ Rg7 22.\nQxe8# Qxe8 23. Re1 Qg6 24. h4 Qh5 25. Rh3 Rd7 26. Rhe3 Qxh4 27. Re8+ Kg7 28. Be5+\nKg6 29. Rg8+ Kh5 30. Rh8+ Kxg5 31. Rxh4 Kxh4 32. Bf6+ Kh5 33. Re7 Rxe7 34.\nBxe7 Kg6 35. Bd8 Kf7 36. Bxc7 Ke6 37. Ke2 Kd5 38. Ke3 c5 39. c4+ Kc6 40. Be5 b5\n41. Kf4 bxc4 42. dxc4 Kb6 43. Kxf5 Ka5 44. g4 Kb4 45. g5 Kxc4 46. g6 Kd3 47.\ng7 c4 48. g8=Q c3 49. Qd5+ Kc2 50. Qb3+ Kd3 51. Qxc3+ Ke2 52. Qe3+ Kf1 53. f4\nKg2 54. Kg4 Kh2 55. Qg3+ Kh1 56. Kh3 a5 57. Qg2# Qxg2# 58. Bxg2# e5 Nf3",
          "positional_tokens": {
            "prompt_tokens": 239,
            "completion_tokens": 372,
            "total_tokens": 611,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g6",
            "Qh6",
            "Re6",
            "Nc3",
            "Rae8",
            "Ne4",
            "f5",
            "Ng5",
            "R6e7",
            "Qxg6+",
            "Rg7",
            "Qxe8#",
            "Qxe8",
            "Re1",
            "Qg6",
            "h4",
            "Qh5",
            "Rh3",
            "Rd7",
            "Rhe3",
            "Qxh4",
            "Re8+",
            "Kg7",
            "Be5+",
            "Kg6",
            "Rg8+",
            "Kh5",
            "Rh8+",
            "Kxg5",
            "Rxh4",
            "Kxh4",
            "Bf6+",
            "Kh5",
            "Re7",
            "Rxe7",
            "Bxe7",
            "Kg6",
            "Bd8",
            "Kf7",
            "Bxc7",
            "Ke6",
            "Ke2",
            "Kd5",
            "Ke3",
            "c5",
            "c4+",
            "Kc6",
            "Be5",
            "b5",
            "Kf4",
            "bxc4",
            "dxc4",
            "Kb6",
            "Kxf5",
            "Ka5",
            "g4",
            "Kb4",
            "g5",
            "Kxc4",
            "g6",
            "Kd3",
            "g7",
            "c4",
            "g8=Q",
            "c3",
            "Qd5+",
            "Kc2",
            "Qb3+",
            "Kd3",
            "Qxc3+",
            "Ke2",
            "Qe3+",
            "Kf1",
            "f4",
            "Kg2",
            "Kg4",
            "Kh2",
            "Qg3+",
            "Kh1",
            "Kh3",
            "a5",
            "Qg2#",
            "Qxg2#",
            "Bxg2#",
            "e5",
            "Nf3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re1+",
          "neutral_uci": null,
          "neutral_response": "Re1+ Rxe1#",
          "neutral_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 7,
            "total_tokens": 245,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4h5",
          "positional_uci": "g4h5",
          "neutral_uci": null,
          "consensus_move": "g4h5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "g6",
              "Qh6",
              "Re6",
              "Nc3",
              "Rae8",
              "Ne4",
              "f5",
              "Ng5",
              "R6e7",
              "Qxg6+",
              "Rg7",
              "Qxe8#",
              "g5",
              "Be5",
              "Rxe8",
              "Bxg7",
              "Kxg7",
              "Re1",
              "Rf8",
              "Ne6+",
              "Kf7",
              "Nxf8",
              "Kxf8",
              "Re5",
              "Kf7",
              "Rxf5+",
              "Kg6",
              "g4",
              "b5",
              "Kg2",
              "a5",
              "Re1",
              "a4",
              "Re6+",
              "Kg7",
              "Rxc6",
              "b4",
              "Rxc7+",
              "Kg6",
              "Rc6+",
              "Kg7",
              "Rb5",
              "b3",
              "Rb7+",
              "Kf8",
              "Rc8#",
              "Kd8",
              "Rh7",
              "bxa2",
              "Ra8#",
              "Kxc8",
              "Rh8+",
              "Kb7",
              "Rh7+",
              "Kb6",
              "Rh6+",
              "Kb5",
              "c4+",
              "Kb4",
              "Rb6+",
              "Ka5",
              "Rb5+",
              "Ka6",
              "Rxg5",
              "a1=Q",
              "Rg6+",
              "Kb7",
              "Rg7+",
              "Kc6",
              "Rg6+",
              "Kd7",
              "Rg7+",
              "Ke6",
              "Rg6+",
              "Kf7",
              "Rb6",
              "Qd1",
              "Rb7+",
              "Ke6",
              "Rb6+",
              "Kd7",
              "Rb7+",
              "Kc6",
              "Rg7",
              "Qxd3",
              "Rg6+",
              "Kc5",
              "Rg5+",
              "Kxc4",
              "h4",
              "Qe4+",
              "Kg3",
              "Qd3+",
              "f3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3",
              "Qd6+",
              "Kh3",
              "Qd3",
              "Kg3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "g6",
              "Qh6",
              "Re6",
              "Nc3",
              "Rae8",
              "Ne4",
              "f5",
              "Ng5",
              "R6e7",
              "Qxg6+",
              "Rg7",
              "Qxe8#",
              "Qxe8",
              "Re1",
              "Qg6",
              "h4",
              "Qh5",
              "Rh3",
              "Rd7",
              "Rhe3",
              "Qxh4",
              "Re8+",
              "Kg7",
              "Be5+",
              "Kg6",
              "Rg8+",
              "Kh5",
              "Rh8+",
              "Kxg5",
              "Rxh4",
              "Kxh4",
              "Bf6+",
              "Kh5",
              "Re7",
              "Rxe7",
              "Bxe7",
              "Kg6",
              "Bd8",
              "Kf7",
              "Bxc7",
              "Ke6",
              "Ke2",
              "Kd5",
              "Ke3",
              "c5",
              "c4+",
              "Kc6",
              "Be5",
              "b5",
              "Kf4",
              "bxc4",
              "dxc4",
              "Kb6",
              "Kxf5",
              "Ka5",
              "g4",
              "Kb4",
              "g5",
              "Kxc4",
              "g6",
              "Kd3",
              "g7",
              "c4",
              "g8=Q",
              "c3",
              "Qd5+",
              "Kc2",
              "Qb3+",
              "Kd3",
              "Qxc3+",
              "Ke2",
              "Qe3+",
              "Kf1",
              "f4",
              "Kg2",
              "Kg4",
              "Kh2",
              "Qg3+",
              "Kh1",
              "Kh3",
              "a5",
              "Qg2#",
              "Qxg2#",
              "Bxg2#",
              "e5",
              "Nf3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxe1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 239,
            "completion_tokens": 640,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 239,
            "completion_tokens": 372,
            "total_tokens": 611,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 238,
            "completion_tokens": 7,
            "total_tokens": 245,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 716,
          "total_completion_tokens": 1019,
          "total_tokens": 1735
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 239,
            "completion_tokens": 640,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 239,
            "completion_tokens": 372,
            "total_tokens": 611,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 238,
            "completion_tokens": 7,
            "total_tokens": 245,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2pp1/p1p5/7p/5BQ1/3P4/PPP2PPP/RN3K1R w - - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh6",
          "aggressive_uci": "h5h6",
          "aggressive_response": "17. Qh6 Re1+ 18. Kxe1 Re8+ 19. Kd2 Re2+ 20. Kxe2 g5 21. Bxg5 f6 22. Bxf6 Kf7 23. Qg7+ Ke6 24. Qe7+ Kd5 25. Qe5# e4 Nxe5 dxe5 Bxe5+ Kxe5 f5+ Kd4 c5#",
          "aggressive_tokens": {
            "prompt_tokens": 248,
            "completion_tokens": 103,
            "total_tokens": 351,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Bxg5",
            "f6",
            "Bxf6",
            "Kf7",
            "Qg7+",
            "Ke6",
            "Qe7+",
            "Kd5",
            "Qe5#",
            "e4",
            "Nxe5",
            "dxe5",
            "Bxe5+",
            "Kxe5",
            "f5+",
            "Kd4",
            "c5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re1+",
          "positional_uci": null,
          "positional_response": "Re1+ Rxe1+ Qxe1#",
          "positional_tokens": {
            "prompt_tokens": 248,
            "completion_tokens": 11,
            "total_tokens": 259,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe1+",
            "Qxe1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": "h5h6",
          "neutral_response": "17. Qh6 Re1+ 18. Kxe1 Re8+ 19. Kd2 Re2+ 20. Kxe2 g5 21. Bxg5 f6 22. Bxf6 Kf7\n23. Qg7+ Ke6 24. Qe7+ Kd5 25. Qe5# e5 Nc5+ Kc6 Qc5# e6 Nc6+ Kc6 Qc5# e7 Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ Kc6 Qc5# e8=Q+ Nc6+ K",
          "neutral_tokens": {
            "prompt_tokens": 247,
            "completion_tokens": 640,
            "total_tokens": 887,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re2+",
            "Kxe2",
            "g5",
            "Bxg5",
            "f6",
            "Bxf6",
            "Kf7",
            "Qg7+",
            "Ke6",
            "Qe7+",
            "Kd5",
            "Qe5#",
            "e5",
            "Nc5+",
            "Kc6",
            "Qc5#",
            "e6",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e7",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+",
            "Kc6",
            "Qc5#",
            "e8=Q+",
            "Nc6+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h5h6",
          "positional_uci": null,
          "neutral_uci": "h5h6",
          "consensus_move": "h5h6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Bxg5",
              "f6",
              "Bxf6",
              "Kf7",
              "Qg7+",
              "Ke6",
              "Qe7+",
              "Kd5",
              "Qe5#",
              "e4",
              "Nxe5",
              "dxe5",
              "Bxe5+",
              "Kxe5",
              "f5+",
              "Kd4",
              "c5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxe1+",
              "Qxe1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re2+",
              "Kxe2",
              "g5",
              "Bxg5",
              "f6",
              "Bxf6",
              "Kf7",
              "Qg7+",
              "Ke6",
              "Qe7+",
              "Kd5",
              "Qe5#",
              "e5",
              "Nc5+",
              "Kc6",
              "Qc5#",
              "e6",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e7",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+",
              "Kc6",
              "Qc5#",
              "e8=Q+",
              "Nc6+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 248,
            "completion_tokens": 103,
            "total_tokens": 351,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 248,
            "completion_tokens": 11,
            "total_tokens": 259,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 247,
            "completion_tokens": 640,
            "total_tokens": 887,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 743,
          "total_completion_tokens": 754,
          "total_tokens": 1497
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 248,
            "completion_tokens": 103,
            "total_tokens": 351,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 248,
            "completion_tokens": 11,
            "total_tokens": 259,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 247,
            "completion_tokens": 640,
            "total_tokens": 887,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2p2/p1p3p1/7Q/5B2/3P4/PPP2PPP/RN3K1R w - - 0 17"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Na5\n10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4\n13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4\n16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5\n22. Qe2 Bxe1 23. Rxe1 h6 24. Qd2 Qa6\n25. Bxh6 gxh6 26. Qxh6 Nh7 27. Nh5 *",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 214,
            "total_tokens": 328,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "h6",
            "Qd2",
            "Qa6",
            "Bxh6",
            "gxh6",
            "Qxh6",
            "Nh7",
            "Nh5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Bb7\n10. d4 Re8 11. Nbd2 Bf8 12. a4 h6\n13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5\n16. d5 Nd7 17. Ra3 c4 18. Nd4 Qf6\n19. N2f3 Nc5 20. axb5 Nbd3 21. Bxd3 Nxd3\n22. Re2 axb5 23. Nxb5 Rxa3 24. Nxa3 Ba6\n25. Qa4 Ra8 26. Nxc4 Nxc1 27. Rc2 Nd3\n28. Nb6 Ra7 29. Nd7 Qd8 30. Nxf8 Kxf8\n31. Nd4 Nc5 32. Qa3 Qb6 33. Nc6 Ra8\n34. e5 Bb7 35. Qf3 dxe5 36. Nxe5 Qc7\n37. Qf5 Bc8 38. Qh5 Ra1+ 39. Kh2 f6\n40. d6 Qxd6 41. Qf7# d4 Nf3+ Kh2 Qxe5+ g3 Qe1\n42. Kg2 Qh1#",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 355,
            "total_tokens": 469,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb7",
            "Qf3",
            "dxe5",
            "Nxe5",
            "Qc7",
            "Qf5",
            "Bc8",
            "Qh5",
            "Ra1+",
            "Kh2",
            "f6",
            "d6",
            "Qxd6",
            "Qf7#",
            "d4",
            "Nf3+",
            "Kh2",
            "Qxe5+",
            "g3",
            "Qe1",
            "Kg2",
            "Qh1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 Nf6 4. O-O d6 5. d4 exd4 6. Nxd4 Bd7 7. Nc3 Be7 8. Bxc6 bxc6 9. Qf3 O-O 10. e5 dxe5 11. Nxc6 Bxc6 12. Qxc6 Qd6 13. Qxd6 cxd6 14. Bg5 Rfc8 15. Rfd1 Rab8 16. Rab1 Kf8 17. Bxf6 gxf6 18. Rd3 f5 19. b3 e4 20. Rh3 Bf6 21. Nd5 Be5 22. c4 Rxc4 23. Rxh7 Rc2 24. a4 Rxb3 25. Rd1 Rd3 26. Rb1 Rxd5 27. g3 Rdd2 28. Rb7 Rxf2 29. Rhxf7+ Kg8 30. Rfd7 Rg2+ 31. Kf1 Rcf2+ 32. Ke1 Bc3+ 33. Kd1 Rg1# Rxf2 Rxf2 Rxf2",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 283,
            "total_tokens": 396,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Nxc6",
            "Bxc6",
            "Qxc6",
            "Qd6",
            "Qxd6",
            "cxd6",
            "Bg5",
            "Rfc8",
            "Rfd1",
            "Rab8",
            "Rab1",
            "Kf8",
            "Bxf6",
            "gxf6",
            "Rd3",
            "f5",
            "b3",
            "e4",
            "Rh3",
            "Bf6",
            "Nd5",
            "Be5",
            "c4",
            "Rxc4",
            "Rxh7",
            "Rc2",
            "a4",
            "Rxb3",
            "Rd1",
            "Rd3",
            "Rb1",
            "Rxd5",
            "g3",
            "Rdd2",
            "Rb7",
            "Rxf2",
            "Rhxf7+",
            "Kg8",
            "Rfd7",
            "Rg2+",
            "Kf1",
            "Rcf2+",
            "Ke1",
            "Bc3+",
            "Kd1",
            "Rg1#",
            "Rxf2",
            "Rxf2",
            "Rxf2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "h6",
              "Qd2",
              "Qa6",
              "Bxh6",
              "gxh6",
              "Qxh6",
              "Nh7",
              "Nh5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "Qf3",
              "dxe5",
              "Nxe5",
              "Qc7",
              "Qf5",
              "Bc8",
              "Qh5",
              "Ra1+",
              "Kh2",
              "f6",
              "d6",
              "Qxd6",
              "Qf7#",
              "d4",
              "Nf3+",
              "Kh2",
              "Qxe5+",
              "g3",
              "Qe1",
              "Kg2",
              "Qh1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxe5",
              "Nxc6",
              "Bxc6",
              "Qxc6",
              "Qd6",
              "Qxd6",
              "cxd6",
              "Bg5",
              "Rfc8",
              "Rfd1",
              "Rab8",
              "Rab1",
              "Kf8",
              "Bxf6",
              "gxf6",
              "Rd3",
              "f5",
              "b3",
              "e4",
              "Rh3",
              "Bf6",
              "Nd5",
              "Be5",
              "c4",
              "Rxc4",
              "Rxh7",
              "Rc2",
              "a4",
              "Rxb3",
              "Rd1",
              "Rd3",
              "Rb1",
              "Rxd5",
              "g3",
              "Rdd2",
              "Rb7",
              "Rxf2",
              "Rhxf7+",
              "Kg8",
              "Rfd7",
              "Rg2+",
              "Kf1",
              "Rcf2+",
              "Ke1",
              "Bc3+",
              "Kd1",
              "Rg1#",
              "Rxf2",
              "Rxf2",
              "Rxf2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 214,
            "total_tokens": 328,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 355,
            "total_tokens": 469,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 283,
            "total_tokens": 396,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 852,
          "total_tokens": 1193
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 214,
            "total_tokens": 328,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 355,
            "total_tokens": 469,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 283,
            "total_tokens": 396,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bb8\n21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qf3 Bg4 26. Qg2 Bh3\n27. Qf3 Bg4 28. Qg2 Bh3 29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3\n33. Qf3 Bg4 34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3 37. Qf3 Bg4 38. Qg2 Bh3\n39. Qf3 Bg4 40. Qg2 Bh3 41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4 44. Qg2 Bh3\n45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3 49. Qf3 Bg4 50. Qg2 Bh3\n51. Qf3 Bg4 52. Qg2 Bh3 53. Qf3 Bg4 54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3\n57. Qf3 Bg4 58. Qg2 Bh3 59. Qf3 Bg4 60. Qg2 Bh3 61. Qf3 Bg4 62. Qg2 Bh3\n63. Qf3 Bg4 64. Qg2 Bh3 65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3\n69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3 73. Qf3 Bg4 74. Qg2 Bh3\n75. Qf3 Bg4 76. Qg2 Bh3 77. Qf3 Bg4 78. Qg2",
          "aggressive_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bb8\n21. Bxd5 Qxd5 22. c4 bxc4 23. Qxc4 Qh5 24. Rxc6 Rxc6 25. Qxc6 Rc8 26. Qe4 f5\n27. Qe6+ Kf8 28. Qxc8+ Kf7 29. Qxb8 Kg6 30. Qe8+ Kf6 31. Qxh5 Bxh5 32. Bf4 g5\n33. Be5+ Ke6 34. b4 Kd5 35. b5 Be8 36. b6 Bc6 37. Rc1 Bb7 38. Rc7 Ba6\n39. b7 Bxb7 40. Rxb7 f4 41. Rxh7 fxg3 42. hxg3 g4 43. Rg7 Ke6 44. Rxg4 Kf5\n45. Rf4+ Ke6 46. g4 Kd5 47. g5 Ke6 48. g6 Kd5 49. g7 Ke6 50. g8=Q+ Kd7\n51. Qd5+ Ke7 52. Rf7+ Ke8 53. Qd7# Qd7 54. Rxd7 Kf8 55. Qf7# Qxf7 56. Rxf7+ Kxf7\n57. f4 Ke6 58. Kf2 Kd5 59. Ke3 Ke6 60. Ke4 Kd7 61. f5 Ke7 62. d5 Kd7\n63. f6 Ke8 64. Kf5 Kf7 65. d6 Ke8 66. Ke6 Kd8 67. f7 Kc8 68. f8=Q+ Kb7\n69. d7 Kc6 70. d8=Q Kb5 71. Qfd6 Kc4 72. Q8c7+ Kb3 73. Qdb6+ Ka4 74. Qca7# Qa6\n75. Qaxa6# Qxa6 76. Qxa6# Qxa6 77. d5 Qc8+",
          "positional_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Bxd5",
            "Qxd5",
            "c4",
            "bxc4",
            "Qxc4",
            "Qh5",
            "Rxc6",
            "Rxc6",
            "Qxc6",
            "Rc8",
            "Qe4",
            "f5",
            "Qe6+",
            "Kf8",
            "Qxc8+",
            "Kf7",
            "Qxb8",
            "Kg6",
            "Qe8+",
            "Kf6",
            "Qxh5",
            "Bxh5",
            "Bf4",
            "g5",
            "Be5+",
            "Ke6",
            "b4",
            "Kd5",
            "b5",
            "Be8",
            "b6",
            "Bc6",
            "Rc1",
            "Bb7",
            "Rc7",
            "Ba6",
            "b7",
            "Bxb7",
            "Rxb7",
            "f4",
            "Rxh7",
            "fxg3",
            "hxg3",
            "g4",
            "Rg7",
            "Ke6",
            "Rxg4",
            "Kf5",
            "Rf4+",
            "Ke6",
            "g4",
            "Kd5",
            "g5",
            "Ke6",
            "g6",
            "Kd5",
            "g7",
            "Ke6",
            "g8=Q+",
            "Kd7",
            "Qd5+",
            "Ke7",
            "Rf7+",
            "Ke8",
            "Qd7#",
            "Qd7",
            "Rxd7",
            "Kf8",
            "Qf7#",
            "Qxf7",
            "Rxf7+",
            "Kxf7",
            "f4",
            "Ke6",
            "Kf2",
            "Kd5",
            "Ke3",
            "Ke6",
            "Ke4",
            "Kd7",
            "f5",
            "Ke7",
            "d5",
            "Kd7",
            "f6",
            "Ke8",
            "Kf5",
            "Kf7",
            "d6",
            "Ke8",
            "Ke6",
            "Kd8",
            "f7",
            "Kc8",
            "f8=Q+",
            "Kb7",
            "d7",
            "Kc6",
            "d8=Q",
            "Kb5",
            "Qfd6",
            "Kc4",
            "Q8c7+",
            "Kb3",
            "Qdb6+",
            "Ka4",
            "Qca7#",
            "Qa6",
            "Qaxa6#",
            "Qxa6",
            "Qxa6#",
            "Qxa6",
            "d5",
            "Qc8+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bc7 21. Bd1 Bxd1 22. Rxd1 Qxd1+ 23. Kg2 Nxe3+ 24. fxe3 Rfe8 25. e4 Rxe4 26. Qxe4 Qxd2+ 27. Kh3 Qh6+ 28. Kg2 Qe6 29. Qxe6 fxe6 30. Rxc6 Re7 31. Rc5 b4 32. cxb4 Bb6 33. Rc4 Rd7 34. Rc6 Bxd4 35. Rxe6 Bxb2 36. b5 Rb7 37. b6 Kf7 38. Rc6 Be5 39. Kf3 Ke7 40. Ke4 Bd6 41. Kd5 Rd7 42. Kc4 Bb8 43. Kb5 Rd5+ 44. Ka6 Rd6 45. Rc8 Rd8 46. Rc6 Kd7 47. Rc2 Rc8 48. Rd2+ Kc6 49. Rc2+ Kd7 50. Rd2+ Bd6 51. b7 Rb8 52. Kb6 Ke6 53. Kc6 Be5 54. Re2 Kf6 55. Rf2+ Ke7 56. Re2 Ke6 57. Re1 g5 58. Re2 h5 59. Re1 h4 60. gxh4 gxh4 61. h3 Kf5 62. Rf1+ Bf4 63. Rf3 Ke4 64. Rb3 Bg3 65. Ra3 Kf4 66. Ra8 Kf3 67. Ra3+ Kg2 68. Ra2+ Kxh3 69. Ra8 Kg2 70. Ra2+ Bf2 71. Ra8 Bg3 72. Ra2+ Kf3 73. Ra3+ Kg4 74. Ra4+ Bf4 75. Ra8 h3 76. Ra4 h2 77. Ra1 Kh3 78. Ra3+ Bg3 79. Ra1 Kg2 80. Ra2+ Bf2 81. Ra",
          "neutral_tokens": {
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bd1",
            "Bxd1",
            "Rxd1",
            "Qxd1+",
            "Kg2",
            "Nxe3+",
            "fxe3",
            "Rfe8",
            "e4",
            "Rxe4",
            "Qxe4",
            "Qxd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qe6",
            "Qxe6",
            "fxe6",
            "Rxc6",
            "Re7",
            "Rc5",
            "b4",
            "cxb4",
            "Bb6",
            "Rc4",
            "Rd7",
            "Rc6",
            "Bxd4",
            "Rxe6",
            "Bxb2",
            "b5",
            "Rb7",
            "b6",
            "Kf7",
            "Rc6",
            "Be5",
            "Kf3",
            "Ke7",
            "Ke4",
            "Bd6",
            "Kd5",
            "Rd7",
            "Kc4",
            "Bb8",
            "Kb5",
            "Rd5+",
            "Ka6",
            "Rd6",
            "Rc8",
            "Rd8",
            "Rc6",
            "Kd7",
            "Rc2",
            "Rc8",
            "Rd2+",
            "Kc6",
            "Rc2+",
            "Kd7",
            "Rd2+",
            "Bd6",
            "b7",
            "Rb8",
            "Kb6",
            "Ke6",
            "Kc6",
            "Be5",
            "Re2",
            "Kf6",
            "Rf2+",
            "Ke7",
            "Re2",
            "Ke6",
            "Re1",
            "g5",
            "Re2",
            "h5",
            "Re1",
            "h4",
            "gxh4",
            "gxh4",
            "h3",
            "Kf5",
            "Rf1+",
            "Bf4",
            "Rf3",
            "Ke4",
            "Rb3",
            "Bg3",
            "Ra3",
            "Kf4",
            "Ra8",
            "Kf3",
            "Ra3+",
            "Kg2",
            "Ra2+",
            "Kxh3",
            "Ra8",
            "Kg2",
            "Ra2+",
            "Bf2",
            "Ra8",
            "Bg3",
            "Ra2+",
            "Kf3",
            "Ra3+",
            "Kg4",
            "Ra4+",
            "Bf4",
            "Ra8",
            "h3",
            "Ra4",
            "h2",
            "Ra1",
            "Kh3",
            "Ra3+",
            "Bg3",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Bf2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Bxd5",
              "Qxd5",
              "c4",
              "bxc4",
              "Qxc4",
              "Qh5",
              "Rxc6",
              "Rxc6",
              "Qxc6",
              "Rc8",
              "Qe4",
              "f5",
              "Qe6+",
              "Kf8",
              "Qxc8+",
              "Kf7",
              "Qxb8",
              "Kg6",
              "Qe8+",
              "Kf6",
              "Qxh5",
              "Bxh5",
              "Bf4",
              "g5",
              "Be5+",
              "Ke6",
              "b4",
              "Kd5",
              "b5",
              "Be8",
              "b6",
              "Bc6",
              "Rc1",
              "Bb7",
              "Rc7",
              "Ba6",
              "b7",
              "Bxb7",
              "Rxb7",
              "f4",
              "Rxh7",
              "fxg3",
              "hxg3",
              "g4",
              "Rg7",
              "Ke6",
              "Rxg4",
              "Kf5",
              "Rf4+",
              "Ke6",
              "g4",
              "Kd5",
              "g5",
              "Ke6",
              "g6",
              "Kd5",
              "g7",
              "Ke6",
              "g8=Q+",
              "Kd7",
              "Qd5+",
              "Ke7",
              "Rf7+",
              "Ke8",
              "Qd7#",
              "Qd7",
              "Rxd7",
              "Kf8",
              "Qf7#",
              "Qxf7",
              "Rxf7+",
              "Kxf7",
              "f4",
              "Ke6",
              "Kf2",
              "Kd5",
              "Ke3",
              "Ke6",
              "Ke4",
              "Kd7",
              "f5",
              "Ke7",
              "d5",
              "Kd7",
              "f6",
              "Ke8",
              "Kf5",
              "Kf7",
              "d6",
              "Ke8",
              "Ke6",
              "Kd8",
              "f7",
              "Kc8",
              "f8=Q+",
              "Kb7",
              "d7",
              "Kc6",
              "d8=Q",
              "Kb5",
              "Qfd6",
              "Kc4",
              "Q8c7+",
              "Kb3",
              "Qdb6+",
              "Ka4",
              "Qca7#",
              "Qa6",
              "Qaxa6#",
              "Qxa6",
              "Qxa6#",
              "Qxa6",
              "d5",
              "Qc8+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bd1",
              "Bxd1",
              "Rxd1",
              "Qxd1+",
              "Kg2",
              "Nxe3+",
              "fxe3",
              "Rfe8",
              "e4",
              "Rxe4",
              "Qxe4",
              "Qxd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qe6",
              "Qxe6",
              "fxe6",
              "Rxc6",
              "Re7",
              "Rc5",
              "b4",
              "cxb4",
              "Bb6",
              "Rc4",
              "Rd7",
              "Rc6",
              "Bxd4",
              "Rxe6",
              "Bxb2",
              "b5",
              "Rb7",
              "b6",
              "Kf7",
              "Rc6",
              "Be5",
              "Kf3",
              "Ke7",
              "Ke4",
              "Bd6",
              "Kd5",
              "Rd7",
              "Kc4",
              "Bb8",
              "Kb5",
              "Rd5+",
              "Ka6",
              "Rd6",
              "Rc8",
              "Rd8",
              "Rc6",
              "Kd7",
              "Rc2",
              "Rc8",
              "Rd2+",
              "Kc6",
              "Rc2+",
              "Kd7",
              "Rd2+",
              "Bd6",
              "b7",
              "Rb8",
              "Kb6",
              "Ke6",
              "Kc6",
              "Be5",
              "Re2",
              "Kf6",
              "Rf2+",
              "Ke7",
              "Re2",
              "Ke6",
              "Re1",
              "g5",
              "Re2",
              "h5",
              "Re1",
              "h4",
              "gxh4",
              "gxh4",
              "h3",
              "Kf5",
              "Rf1+",
              "Bf4",
              "Rf3",
              "Ke4",
              "Rb3",
              "Bg3",
              "Ra3",
              "Kf4",
              "Ra8",
              "Kf3",
              "Ra3+",
              "Kg2",
              "Ra2+",
              "Kxh3",
              "Ra8",
              "Kg2",
              "Ra2+",
              "Bf2",
              "Ra8",
              "Bg3",
              "Ra2+",
              "Kf3",
              "Ra3+",
              "Kg4",
              "Ra4+",
              "Bf4",
              "Ra8",
              "h3",
              "Ra4",
              "h2",
              "Ra1",
              "Kh3",
              "Ra3+",
              "Bg3",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Bf2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 365,
          "total_completion_tokens": 1920,
          "total_tokens": 2285
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": "c6e5",
          "aggressive_response": "3... Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Be3 d6 8. Nc3 Nf6 9. Qd2 Be7 10. O-O-O O-O 11. h3 Re8 12. g4 Bf8 13. Bd3 c6 14. g5 Nd7 15. h4 cxd5 16. Nxd5 Nb6 17. h5 Nxd5 18. hxg6 Nxe3 19. Rxh7 fxg6 20. Rdh1 Kf7 21. Qxe3 d5 22. Qd4 dxe4 23. Bc4+ Be6 24. Qxe4 Qb6 25. f5 gxf5 26. Qxf5+ Ke7 27. Bxe6 Qxe6 28. Qc5+ Kd7 29. Rd1+ Bd6 30. Rxg7+ Re7 31. Qb5+ Kc7 32. Rxe7+ Qxe7 33. Qc4+ Kd7 34. Qb5+ Kc7 35. Qc4+ Kd7 36. Qb5+ Kc7 37. Qc4+ Kd7 38. Qb5+ Kc7 39. Qc4+ Kd7 40. Qb5+ Kc7 41. Qc4+ Kd7 42. Qb5+ Kc7 43. Qc4+ Kd7 44. Qb5+ Kc7 45. Qc4+ Kd7 46. Qb5+ Kc7 47. Qc4+ Kd7 48. Qb5+ Kc7 49. Qc4+ Kd7 50. Qb5+ Kc7 51. Qc4+ Kd7 52. Qb5+ Kc7 53. Qc4+ Kd7 54. Qb5+ Kc7 55. Qc4+ Kd7 56. Qb5+ Kc7 57. Qc4+ Kd7 58. Qb5+ Kc7 59. Qc4+ Kd7 60. Qb5+ Kc7 61. Qc4+ Kd7 62. Qb5+ Kc7 63. Qc4+ Kd7 64. Qb5+ Kc7 65. Qc4+ Kd7 66. Qb5+ Kc7 67. Qc4+ Kd7 68. Qb5+ Kc7 69. Qc4+ Kd7 70. Qb5+ Kc7 71. Qc4+ Kd7 72",
          "aggressive_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "Nc6",
            "d5",
            "Ne5",
            "f4",
            "Ng6",
            "Be3",
            "d6",
            "Nc3",
            "Nf6",
            "Qd2",
            "Be7",
            "O-O-O",
            "O-O",
            "h3",
            "Re8",
            "g4",
            "Bf8",
            "Bd3",
            "c6",
            "g5",
            "Nd7",
            "h4",
            "cxd5",
            "Nxd5",
            "Nb6",
            "h5",
            "Nxd5",
            "hxg6",
            "Nxe3",
            "Rxh7",
            "fxg6",
            "Rdh1",
            "Kf7",
            "Qxe3",
            "d5",
            "Qd4",
            "dxe4",
            "Bc4+",
            "Be6",
            "Qxe4",
            "Qb6",
            "f5",
            "gxf5",
            "Qxf5+",
            "Ke7",
            "Bxe6",
            "Qxe6",
            "Qc5+",
            "Kd7",
            "Rd1+",
            "Bd6",
            "Rxg7+",
            "Re7",
            "Qb5+",
            "Kc7",
            "Rxe7+",
            "Qxe7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe5",
          "positional_uci": "c6e5",
          "positional_response": "3... Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Be3 d6 8. Nc3 Nf6 9. Bd3 Be7 10. O-O O-O 11. Qe1 Re8 12. Qg3 Nh5 13. Qf3 Nf6 14. Rae1 Bg4 15. Qg3 Bd7 16. Bd4 Nh5 17. Qf3 Nf6 18. e5 dxe5 19. fxe5 Bg4 20. Qg3 Nxd5 21. Qxg4 Nxc3 22. Bxc3 Bc5+ 23. Kh1 Qh4 24. Qf5 Rf8 25. Re4 Qe7 26. Bc4 Rae8 27. e6 fxe6 28. Bxe6+ Kh8 29. Bf7 Qxe4 30. Qxe4 Rxe4 31. Bxg6 Rxf1# 0-1\n1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Be3 d6 8. Nc3 Nf6 9. Bd3 Be7 10. O-O O-O 11. Qe1 Re8 12. Qg3 Nh5 13. Qf3 Nf6 14. Rae1 Bg4 15. Qg3 Bd7 16. Bd4 Nh5 17. Qf3 Nf6 18. e5 dxe5 19. fxe5 Bg4 20. Qg3 Nxd5 21. Qxg4 Nxc3 22. Bxc3 Bc5+ 23. Kh1 Qh4 24. Qf5 Rf8 25. Re4 Qe7 26. Bc4 Rae8 27. e6 fxe6 28. Bxe6+ Kh8 29. Bf7 Qxe4 30. Qxe4 Rxe4 31. Bxg6 Rxf1# 0-1 e4 e5 Nf3 Nc6 Nxe5 Nxe5 d4 Nc6 d5 Ne5 f4 Ng6 Be3 d6 Nc3 Nf6 Bd3 Be7 O-O O-O Qe1 Re8 Qg3 Nh5 Qf3 Nf6 Rae1 Bg4 Qg3 Bd7 Bd4 Nh5 Qf3 Nf6 e5 dxe5 fxe5 Bg4 Qg3 Nxd5 Qxg4 Nxc3 Bxc3 Bc5+ Kh1 Qh4 Qf5 Rf8 Re4 Qe7 Bc4",
          "positional_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "Nc6",
            "d5",
            "Ne5",
            "f4",
            "Ng6",
            "Be3",
            "d6",
            "Nc3",
            "Nf6",
            "Bd3",
            "Be7",
            "O-O",
            "O-O",
            "Qe1",
            "Re8",
            "Qg3",
            "Nh5",
            "Qf3",
            "Nf6",
            "Rae1",
            "Bg4",
            "Qg3",
            "Bd7",
            "Bd4",
            "Nh5",
            "Qf3",
            "Nf6",
            "e5",
            "dxe5",
            "fxe5",
            "Bg4",
            "Qg3",
            "Nxd5",
            "Qxg4",
            "Nxc3",
            "Bxc3",
            "Bc5+",
            "Kh1",
            "Qh4",
            "Qf5",
            "Rf8",
            "Re4",
            "Qe7",
            "Bc4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe5",
          "neutral_uci": "c6e5",
          "neutral_response": "3... Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Be3 d6 8. Nc3 Nf6 9. Qd2 Be7 10. O-O-O O-O 11. h3 Re8 12. g4 Bf8 13. Bd3 c6 14. g5 Nd7 15. h4 cxd5 16. Nxd5 Nb6 17. h5 Nxd5 18. hxg6 Nxe3 19. Rxh7 fxg6 20. Rdh1 Kf7 21. Qxe3 d5 22. Qd4 dxe4 23. Bc4+ Be6 24. Qxe4 Qb6 25. f5 gxf5 26. Qxf5+ Ke7 27. Bxe6 Qxe6 28. Qc5+ Kd7 29. Rd1+ Bd6 30. Rxg7+ Re7 31. Qb5+ Kc7 32. Rxe7+ Qxe7 33. Qc4+ Kd7 34. Qb5+ Kc7 35. Qc4+ Kd7 36. Qb5+ Kc7 37. Qc4+ Kd7 38. Qb5+ Kc7 39. Qc4+ Kd7 40. Qb5+ Kc7 41. Qc4+ Kd7 42. Qb5+ Kc7 43. Qc4+ Kd7 44. Qb5+ Kc7 45. Qc4+ Kd7 46. Qb5+ Kc7 47. Qc4+ Kd7 48. Qb5+ Kc7 49. Qc4+ Kd7 50. Qb5+ Kc7 51. Qc4+ Kd7 52. Qb5+ Kc7 53. Qc4+ Kd7 54. Qb5+ Kc7 55. Qc4+ Kd7 56. Qb5+ Kc7 57. Qc4+ Kd7 58. Qb5+ Kc7 59. Qc4+ Kd7 60. Qb5+ Kc7 61. Qc4+ Kd7 62. Qb5+ Kc7 63. Qc4+ Kd7 64. Qb5+ Kc7 65. Qc4+ Kd7 66. Qb5+ Kc7 67. Qc4+ Kd7 68. Qb5+ Kc7 69. Qc4+ Kd7 70. Qb5+ Kc7 71. Qc4+ Kd7 72",
          "neutral_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "Nc6",
            "d5",
            "Ne5",
            "f4",
            "Ng6",
            "Be3",
            "d6",
            "Nc3",
            "Nf6",
            "Qd2",
            "Be7",
            "O-O-O",
            "O-O",
            "h3",
            "Re8",
            "g4",
            "Bf8",
            "Bd3",
            "c6",
            "g5",
            "Nd7",
            "h4",
            "cxd5",
            "Nxd5",
            "Nb6",
            "h5",
            "Nxd5",
            "hxg6",
            "Nxe3",
            "Rxh7",
            "fxg6",
            "Rdh1",
            "Kf7",
            "Qxe3",
            "d5",
            "Qd4",
            "dxe4",
            "Bc4+",
            "Be6",
            "Qxe4",
            "Qb6",
            "f5",
            "gxf5",
            "Qxf5+",
            "Ke7",
            "Bxe6",
            "Qxe6",
            "Qc5+",
            "Kd7",
            "Rd1+",
            "Bd6",
            "Rxg7+",
            "Re7",
            "Qb5+",
            "Kc7",
            "Rxe7+",
            "Qxe7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7",
            "Qb5+",
            "Kc7",
            "Qc4+",
            "Kd7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c6e5",
          "positional_uci": "c6e5",
          "neutral_uci": "c6e5",
          "consensus_move": "c6e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d4",
              "Nc6",
              "d5",
              "Ne5",
              "f4",
              "Ng6",
              "Be3",
              "d6",
              "Nc3",
              "Nf6",
              "Qd2",
              "Be7",
              "O-O-O",
              "O-O",
              "h3",
              "Re8",
              "g4",
              "Bf8",
              "Bd3",
              "c6",
              "g5",
              "Nd7",
              "h4",
              "cxd5",
              "Nxd5",
              "Nb6",
              "h5",
              "Nxd5",
              "hxg6",
              "Nxe3",
              "Rxh7",
              "fxg6",
              "Rdh1",
              "Kf7",
              "Qxe3",
              "d5",
              "Qd4",
              "dxe4",
              "Bc4+",
              "Be6",
              "Qxe4",
              "Qb6",
              "f5",
              "gxf5",
              "Qxf5+",
              "Ke7",
              "Bxe6",
              "Qxe6",
              "Qc5+",
              "Kd7",
              "Rd1+",
              "Bd6",
              "Rxg7+",
              "Re7",
              "Qb5+",
              "Kc7",
              "Rxe7+",
              "Qxe7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d4",
              "Nc6",
              "d5",
              "Ne5",
              "f4",
              "Ng6",
              "Be3",
              "d6",
              "Nc3",
              "Nf6",
              "Bd3",
              "Be7",
              "O-O",
              "O-O",
              "Qe1",
              "Re8",
              "Qg3",
              "Nh5",
              "Qf3",
              "Nf6",
              "Rae1",
              "Bg4",
              "Qg3",
              "Bd7",
              "Bd4",
              "Nh5",
              "Qf3",
              "Nf6",
              "e5",
              "dxe5",
              "fxe5",
              "Bg4",
              "Qg3",
              "Nxd5",
              "Qxg4",
              "Nxc3",
              "Bxc3",
              "Bc5+",
              "Kh1",
              "Qh4",
              "Qf5",
              "Rf8",
              "Re4",
              "Qe7",
              "Bc4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d4",
              "Nc6",
              "d5",
              "Ne5",
              "f4",
              "Ng6",
              "Be3",
              "d6",
              "Nc3",
              "Nf6",
              "Qd2",
              "Be7",
              "O-O-O",
              "O-O",
              "h3",
              "Re8",
              "g4",
              "Bf8",
              "Bd3",
              "c6",
              "g5",
              "Nd7",
              "h4",
              "cxd5",
              "Nxd5",
              "Nb6",
              "h5",
              "Nxd5",
              "hxg6",
              "Nxe3",
              "Rxh7",
              "fxg6",
              "Rdh1",
              "Kf7",
              "Qxe3",
              "d5",
              "Qd4",
              "dxe4",
              "Bc4+",
              "Be6",
              "Qxe4",
              "Qb6",
              "f5",
              "gxf5",
              "Qxf5+",
              "Ke7",
              "Bxe6",
              "Qxe6",
              "Qc5+",
              "Kd7",
              "Rd1+",
              "Bd6",
              "Rxg7+",
              "Re7",
              "Qb5+",
              "Kc7",
              "Rxe7+",
              "Qxe7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7",
              "Qb5+",
              "Kc7",
              "Qc4+",
              "Kd7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 392,
          "total_completion_tokens": 1920,
          "total_tokens": 2312
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4N3/4P3/8/PPPP1PPP/RNBQKB1R b KQkq - 0 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "e5c6",
          "aggressive_response": "4... Nc6 5. d5 Ne5 6. f4 Ng6 7. Be3 d6 8. Nc3 Nf6 9. Qd2 Be7 10. O-O-O O-O 11. h3 Re8 12. g4 Bf8 13. Bd3 c6 14. g5 Nd7 15. h4 Nc5 16. h5 Nxd3+ 17. Qxd3 Ne7 18. f5 cxd5 19. Nxd5 Nxd5 20. Qxd5 Qe7 21. g6 Qxe4 22. Qxf7+ Kh8 23. Bd4 Bxf5 24. Rh2 Rac8 25. c3 Qb1+ 26. Kd2 Qc2# 27. Kxc2 Bxg6+ 28. hxg6 h6 29. Rxh6# Bxh6 30. Rh1 Re2+ 31. Kb3 Rxb2+ 32. Kxb2 Rxc3 33. Rxh6# Rb3+ 34. axb3 d5 35. Qxg7# Rb8 36. Rh8# Rb7 37. Qxb7# Rxb7 38. Rh7# Rb8 39. Rh8# Rb7 40. Rh7# Rb8 41. Rh8# Rb7 42. Rh7# Rb8 43. Rh8# Rb7 44. Rh7# Rb8 45. Rh8# Rb7 46. Rh7# Rb8 47. Rh8# Rb7 48. Rh7# Rb8 49. Rh8# Rb7 50. Rh7# Rb8 51. Rh8# Rb7 52. Rh7# Rb8 53. Rh8# Rb7 54. Rh7# Rb8 55. Rh8# Rb7 56. Rh7# Rb8 57. Rh8# Rb7 58. Rh7# Rb8 59. Rh8# Rb7 60. Rh7# Rb8 61. Rh8# Rb7 62. Rh7# Rb8 63. Rh8# Rb7 64. Rh7# Rb8 65. Rh8# Rb7 66. Rh7# Rb8 67. Rh8# Rb7 68. Rh7# Rb8 69. Rh8# Rb7 70. Rh7# Rb8 71. Rh8# Rb7 72. Rh7# Rb8 73. Rh8# Rb7 74. Rh7# Rb8 75. Rh8# Rb7 76. Rh7# Rb8",
          "aggressive_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Ne5",
            "f4",
            "Ng6",
            "Be3",
            "d6",
            "Nc3",
            "Nf6",
            "Qd2",
            "Be7",
            "O-O-O",
            "O-O",
            "h3",
            "Re8",
            "g4",
            "Bf8",
            "Bd3",
            "c6",
            "g5",
            "Nd7",
            "h4",
            "Nc5",
            "h5",
            "Nxd3+",
            "Qxd3",
            "Ne7",
            "f5",
            "cxd5",
            "Nxd5",
            "Nxd5",
            "Qxd5",
            "Qe7",
            "g6",
            "Qxe4",
            "Qxf7+",
            "Kh8",
            "Bd4",
            "Bxf5",
            "Rh2",
            "Rac8",
            "c3",
            "Qb1+",
            "Kd2",
            "Qc2#",
            "Kxc2",
            "Bxg6+",
            "hxg6",
            "h6",
            "Rxh6#",
            "Bxh6",
            "Rh1",
            "Re2+",
            "Kb3",
            "Rxb2+",
            "Kxb2",
            "Rxc3",
            "Rxh6#",
            "Rb3+",
            "axb3",
            "d5",
            "Qxg7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Qxb7#",
            "Rxb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8",
            "Rh8#",
            "Rb7",
            "Rh7#",
            "Rb8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "e5c6",
          "positional_response": "4... Nc6 5. d5 Ne5 6. f4 Ng6 7. Be3 d6 8. Nc3 Nf6 9. Qd2 Be7 10. O-O-O O-O 11. h3 Re8 12. g4 Bf8 13. Bd3 c6 14. g5 Nh5 15. Be2 Ng3 16. Rhg1 Nxe4 17. Nxe4 Rxe4 18. Bd3 Re8 19. f5 Ne5 20. g6 Nxd3+ 21. Qxd3 fxg6 22. fxg6 h6 23. Rdf1 Qe7 24. Bd2 Qe4 25. Qg3 Bf5 26. Qc3 cxd5 27. Rf4 Qe6 28. Re1 Qxg6 29. Ref1 Rac8 30. Qd4 Rxc2+ 31. Kd1 Qh5+ 32. R4f3 Be4 33. Bc3 Bxf3+ 34. Kxc2 Qf5+ 35. Kb3 Bd1+ 36. Rxd1 Qe4 37. Qxd5+ Qxd5+ 38. Rxd5 Re3 39. h4 Rh3 40. Rd4 Be7 41. Rg4 g5 42. hxg5 hxg5 43. Kc4 Rh4 44. Rxh4 gxh4 45. Bd4 h3 46. Bg1 Bf6 47. b3 Be5 48. Kd5 h2 49. Bxh2 Bxh2 50. Ke6 Kf8 51. Kd7 d5 52. Kc8 d4 53. Kxb7 d3 54. Kxa7 d2 55. b4 d1=Q 56. b5 Qa4+ 57. Kb6 Qxa2 58. Kc6 Qc4+ 59. Kb6 Bg1+ 60. Ka6 Qa4+ 61. Kb7 Qxb5+ 62. Kc7 Bh2+ 63. Kd8 Qd5+ 64. Kc8 Qc6+ 65. Kd8 Qc7# d4 d5 d6",
          "positional_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 529,
            "total_tokens": 668,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Ne5",
            "f4",
            "Ng6",
            "Be3",
            "d6",
            "Nc3",
            "Nf6",
            "Qd2",
            "Be7",
            "O-O-O",
            "O-O",
            "h3",
            "Re8",
            "g4",
            "Bf8",
            "Bd3",
            "c6",
            "g5",
            "Nh5",
            "Be2",
            "Ng3",
            "Rhg1",
            "Nxe4",
            "Nxe4",
            "Rxe4",
            "Bd3",
            "Re8",
            "f5",
            "Ne5",
            "g6",
            "Nxd3+",
            "Qxd3",
            "fxg6",
            "fxg6",
            "h6",
            "Rdf1",
            "Qe7",
            "Bd2",
            "Qe4",
            "Qg3",
            "Bf5",
            "Qc3",
            "cxd5",
            "Rf4",
            "Qe6",
            "Re1",
            "Qxg6",
            "Ref1",
            "Rac8",
            "Qd4",
            "Rxc2+",
            "Kd1",
            "Qh5+",
            "R4f3",
            "Be4",
            "Bc3",
            "Bxf3+",
            "Kxc2",
            "Qf5+",
            "Kb3",
            "Bd1+",
            "Rxd1",
            "Qe4",
            "Qxd5+",
            "Qxd5+",
            "Rxd5",
            "Re3",
            "h4",
            "Rh3",
            "Rd4",
            "Be7",
            "Rg4",
            "g5",
            "hxg5",
            "hxg5",
            "Kc4",
            "Rh4",
            "Rxh4",
            "gxh4",
            "Bd4",
            "h3",
            "Bg1",
            "Bf6",
            "b3",
            "Be5",
            "Kd5",
            "h2",
            "Bxh2",
            "Bxh2",
            "Ke6",
            "Kf8",
            "Kd7",
            "d5",
            "Kc8",
            "d4",
            "Kxb7",
            "d3",
            "Kxa7",
            "d2",
            "b4",
            "d1=Q",
            "b5",
            "Qa4+",
            "Kb6",
            "Qxa2",
            "Kc6",
            "Qc4+",
            "Kb6",
            "Bg1+",
            "Ka6",
            "Qa4+",
            "Kb7",
            "Qxb5+",
            "Kc7",
            "Bh2+",
            "Kd8",
            "Qd5+",
            "Kc8",
            "Qc6+",
            "Kd8",
            "Qc7#",
            "d4",
            "d5",
            "d6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "e5c6",
          "neutral_response": "4... Nc6 5. d5 Ne5 6. f4 Ng6 7. Be3 d6 8. Nc3 Nf6 9. Qd2 Be7 10. O-O-O O-O 11. h3 Re8 12. g4 Bf8 13. Bd3 c6 14. g5 Nd7 15. h4 cxd5 16. Nxd5 Nc5 17. h5 Nxd3+ 18. Qxd3 Ne7 19. h6 Nxd5 20. hxg7 Bxg7 21. exd5 Qa5 22. Qxh7+ Kf8 23. Bd4 Bxd4 24. Rxd4 Re1+ 25. Rd1 Rxh1 26. Rxh1 Qxd5 27. Qh8+ Ke7 28. Qf6+ Kd7 29. Rd1 Qe6 30. Qd4 b6 31. Qa4+ Kc7 32. Qd4 Bb7 33. Qc3+ Bc6 34. Re1 Qd7 35. Qf6 Re8 36. Rxe8 Qxe8 37. b3 Qe6 38. Qc3 Kb7 39. Kb2 Qf5 40. Qd4 d5 41. a4 Qe4 42. Qf6 Qe6 43. Qd4 a5 44. Qd3 Qe4 45. Qd2 d4 46. Qf2 d3 47. cxd3 Qxd3 48. Qe1 Qd4+ 49. Ka2 Qxf4 50. Qe7+ Qc7 51. Qf6 Bd5 52. Qf5 Be6 53. Qe4+ Ka7 54. g6 Qh2+ 55. Ka3 Qd6+ 56. Kb2 fxg6 57. Qxg6 Qd4+ 58. Ka2 Qxa4+ 59. Kb2 Qxb3+ 60. Kc1 Qc3+ 61. Kd1 Bb3+ 62. Ke2 Qc2+ 63. Qxc2 Bxc2 64. Kd2 Bf5 65. Kc3 b5 66. Kb3 Kb6 67. Ka3 Kc5 68. Kb3 a4+ 69. Ka3 Kc4 70. Kb2 b4 71. Ka2 Kc3 72. Ka1 a3 73. Ka2 b3+ 74. Ka1 b2+ 75. Ka2 b1=Q+ 76. Kxa3 Qb3# e4 e5 Nf3 Nc6 Nxe5 Nxe5 d4 Nc6",
          "neutral_tokens": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5c6",
          "positional_uci": "e5c6",
          "neutral_uci": "e5c6",
          "consensus_move": "e5c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Ne5",
              "f4",
              "Ng6",
              "Be3",
              "d6",
              "Nc3",
              "Nf6",
              "Qd2",
              "Be7",
              "O-O-O",
              "O-O",
              "h3",
              "Re8",
              "g4",
              "Bf8",
              "Bd3",
              "c6",
              "g5",
              "Nd7",
              "h4",
              "Nc5",
              "h5",
              "Nxd3+",
              "Qxd3",
              "Ne7",
              "f5",
              "cxd5",
              "Nxd5",
              "Nxd5",
              "Qxd5",
              "Qe7",
              "g6",
              "Qxe4",
              "Qxf7+",
              "Kh8",
              "Bd4",
              "Bxf5",
              "Rh2",
              "Rac8",
              "c3",
              "Qb1+",
              "Kd2",
              "Qc2#",
              "Kxc2",
              "Bxg6+",
              "hxg6",
              "h6",
              "Rxh6#",
              "Bxh6",
              "Rh1",
              "Re2+",
              "Kb3",
              "Rxb2+",
              "Kxb2",
              "Rxc3",
              "Rxh6#",
              "Rb3+",
              "axb3",
              "d5",
              "Qxg7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Qxb7#",
              "Rxb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8",
              "Rh8#",
              "Rb7",
              "Rh7#",
              "Rb8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d5",
              "Ne5",
              "f4",
              "Ng6",
              "Be3",
              "d6",
              "Nc3",
              "Nf6",
              "Qd2",
              "Be7",
              "O-O-O",
              "O-O",
              "h3",
              "Re8",
              "g4",
              "Bf8",
              "Bd3",
              "c6",
              "g5",
              "Nh5",
              "Be2",
              "Ng3",
              "Rhg1",
              "Nxe4",
              "Nxe4",
              "Rxe4",
              "Bd3",
              "Re8",
              "f5",
              "Ne5",
              "g6",
              "Nxd3+",
              "Qxd3",
              "fxg6",
              "fxg6",
              "h6",
              "Rdf1",
              "Qe7",
              "Bd2",
              "Qe4",
              "Qg3",
              "Bf5",
              "Qc3",
              "cxd5",
              "Rf4",
              "Qe6",
              "Re1",
              "Qxg6",
              "Ref1",
              "Rac8",
              "Qd4",
              "Rxc2+",
              "Kd1",
              "Qh5+",
              "R4f3",
              "Be4",
              "Bc3",
              "Bxf3+",
              "Kxc2",
              "Qf5+",
              "Kb3",
              "Bd1+",
              "Rxd1",
              "Qe4",
              "Qxd5+",
              "Qxd5+",
              "Rxd5",
              "Re3",
              "h4",
              "Rh3",
              "Rd4",
              "Be7",
              "Rg4",
              "g5",
              "hxg5",
              "hxg5",
              "Kc4",
              "Rh4",
              "Rxh4",
              "gxh4",
              "Bd4",
              "h3",
              "Bg1",
              "Bf6",
              "b3",
              "Be5",
              "Kd5",
              "h2",
              "Bxh2",
              "Bxh2",
              "Ke6",
              "Kf8",
              "Kd7",
              "d5",
              "Kc8",
              "d4",
              "Kxb7",
              "d3",
              "Kxa7",
              "d2",
              "b4",
              "d1=Q",
              "b5",
              "Qa4+",
              "Kb6",
              "Qxa2",
              "Kc6",
              "Qc4+",
              "Kb6",
              "Bg1+",
              "Ka6",
              "Qa4+",
              "Kb7",
              "Qxb5+",
              "Kc7",
              "Bh2+",
              "Kd8",
              "Qd5+",
              "Kc8",
              "Qc6+",
              "Kd8",
              "Qc7#",
              "d4",
              "d5",
              "d6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 139,
            "completion_tokens": 529,
            "total_tokens": 668,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 416,
          "total_completion_tokens": 1809,
          "total_tokens": 2225
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 139,
            "completion_tokens": 529,
            "total_tokens": 668,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/8/4n3/3PP3/8/PPP2PPP/RNBQKB1R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne5",
          "aggressive_uci": "c6e5",
          "aggressive_response": "5... Ne5 6. f4 Ng6 7. Nc3 Bb4 8. Bd3 d6 9. O-O Nf6 10. Be3 O-O 11. Bd4 c5 12. dxc6 bxc6 13. a3 Ba5 14. b4 Bb6 15. Bxb6 Qxb6+ 16. Kh1 Ng4 17. Qe2 Qd4 18. Na4 f5 19. c3 Qe3 20. Qxe3 Nxe3 21. Rf3 Ng4 22. exf5 Bxf5 23. Bxf5 Rxf5 24. h3 Nf6 25. g4 Rxf4 26. Rxf4 Nxf4 27. Kh2 Re8 28. Kg3 g5 29. h4 Re3+ 30. Kf2 Nxg4+ 31. Kf1 gxh4 32. Re1 Rf3+ 33. Kg1 h3 34. Re8+ Kf7 35. Re1 h2+ 36. Kh1 Rg3 37. Rf1 Nf2+ 38. Rxf2 Rg1+ 39. Kxh2 Rg4 40. Nb2 Kg6 41. Nd1 Kg5 42. Ne3 Rh4+ 43. Kg3 Rh3# 0-1\n5... Ne5 6. f4 Ng6 7. Nc3 Bb4 8. Bd3 d6 9. O-O Nf6 10. Be3 O-O 11. Bd4 c5 12. dxc6 bxc6 13. a3 Ba5 14. b4 Bb6 15. Bxb6 Qxb6+ 16. Kh1 Ng4 17. Qe2 Qd4 18. Na4 f5 19. c3 Qe3 20. Qxe3 Nxe3 21. Rf3 Ng4 22. exf5 Bxf5 23. Bxf5 Rxf5 24. h3 Nf6 25. g4 Rxf4 26. Rxf4 Nxf4 27. Kh2 Re8 28. Kg3 g5 29. h4 Re3+ 30. Kf2 Nxg4+ 31. Kf1 gxh4 32. Re1 Rf3+ 33. Kg1 h3 34. Re8+ Kf7 35. Re1 h2+ 36. Kh1 Rg3 37. Rf1 Nf2+ 38. Rxf2 Rg1+ 39. Kxh2 Rg4 40. Nb2 Kg6 41. Nd1 Kg5 42. Ne3 Rh4+ 43. Kg3 Rh3# 0",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f4",
            "Ng6",
            "Nc3",
            "Bb4",
            "Bd3",
            "d6",
            "O-O",
            "Nf6",
            "Be3",
            "O-O",
            "Bd4",
            "c5",
            "dxc6",
            "bxc6",
            "a3",
            "Ba5",
            "b4",
            "Bb6",
            "Bxb6",
            "Qxb6+",
            "Kh1",
            "Ng4",
            "Qe2",
            "Qd4",
            "Na4",
            "f5",
            "c3",
            "Qe3",
            "Qxe3",
            "Nxe3",
            "Rf3",
            "Ng4",
            "exf5",
            "Bxf5",
            "Bxf5",
            "Rxf5",
            "h3",
            "Nf6",
            "g4",
            "Rxf4",
            "Rxf4",
            "Nxf4",
            "Kh2",
            "Re8",
            "Kg3",
            "g5",
            "h4",
            "Re3+",
            "Kf2",
            "Nxg4+",
            "Kf1",
            "gxh4",
            "Re1",
            "Rf3+",
            "Kg1",
            "h3",
            "Re8+",
            "Kf7",
            "Re1",
            "h2+",
            "Kh1",
            "Rg3",
            "Rf1",
            "Nf2+",
            "Rxf2",
            "Rg1+",
            "Kxh2",
            "Rg4",
            "Nb2",
            "Kg6",
            "Nd1",
            "Kg5",
            "Ne3",
            "Rh4+",
            "Kg3",
            "Rh3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne5",
          "positional_uci": "c6e5",
          "positional_response": "5... Ne5 6. f4 Ng6 7. Be3 d6 8. Nc3 Nf6 9. Qd2 Be7 10. O-O-O O-O 11. h3 Re8 12. g4 Bf8 13. Bd3 c6 14. g5 Nd7 15. h4 cxd5 16. Nxd5 Nc5 17. h5 Ne7 18. Bxc5 dxc5 19. Bc4 Nxd5 20. Bxd5 Qc7 21. g6 Be6 22. h6 Bxd5 23. gxh7+ Kh8 24. hxg7+ Bxg7 25. exd5 Qb6 26. c3 Rad8 27. Rdg1 Qf6 28. Rg5 Re4 29. Rhg1 Bh6 30. Rg8+ Kxh7 31. Rxd8 Bxf4 32. Rh1+ Kg7 33. Rg1+ Kh6 34. Rh1+ Kg5 35. Rg8+ Kf5 36. Rh5+ Bg5 37. Rgxg5+ Qxg5 38. Qxg5# Bg5 39. Rxg5# Kxg5 40. Qg2+ Kf5 41. Qxe4+ Kxe4 42. d6 f5 43. d7 f4 44. d8=Q f3 45. Qe7+ Kf4 46. Qxc5 Kg3 47. Qxa7 Kg2 48. Qxb7 Kg1 49. Qxf3 Kh2 50. Qg4 Kh1 51. Kd2 Kh2 52. Ke2 Kh1 53. Kf2 Kh2 54. Qg2# Kg5 55. Qf3 Kg6 56. Qf4 Kg7 57. Qf5 Kg8 58. Qf6 Kh7 59. Qg5 Kh8 60. Kf3 Kh7 61. Kf4 Kh8 62. Kf5 Kh7 63. Kf6 Kh8 64. Qg7# Kg8 65. Qf7+ Kh8 66. Qg7# Kg8 67. Qf7+ Kh8 68. Qg7# Kg8 69. Qf7+ Kh8 70. Qg7# Kg8 71. Qf7+ Kh8 72. Qg7# Kg8 73. Qf7+ Kh8 74. Qg7# Kg8 75. Qf7+ Kh8 76. Qg7# Kg8 77. Qf7+ Kh8 78. Qg7# Kg8 79. Qf7+ Kh8",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f4",
            "Ng6",
            "Be3",
            "d6",
            "Nc3",
            "Nf6",
            "Qd2",
            "Be7",
            "O-O-O",
            "O-O",
            "h3",
            "Re8",
            "g4",
            "Bf8",
            "Bd3",
            "c6",
            "g5",
            "Nd7",
            "h4",
            "cxd5",
            "Nxd5",
            "Nc5",
            "h5",
            "Ne7",
            "Bxc5",
            "dxc5",
            "Bc4",
            "Nxd5",
            "Bxd5",
            "Qc7",
            "g6",
            "Be6",
            "h6",
            "Bxd5",
            "gxh7+",
            "Kh8",
            "hxg7+",
            "Bxg7",
            "exd5",
            "Qb6",
            "c3",
            "Rad8",
            "Rdg1",
            "Qf6",
            "Rg5",
            "Re4",
            "Rhg1",
            "Bh6",
            "Rg8+",
            "Kxh7",
            "Rxd8",
            "Bxf4",
            "Rh1+",
            "Kg7",
            "Rg1+",
            "Kh6",
            "Rh1+",
            "Kg5",
            "Rg8+",
            "Kf5",
            "Rh5+",
            "Bg5",
            "Rgxg5+",
            "Qxg5",
            "Qxg5#",
            "Bg5",
            "Rxg5#",
            "Kxg5",
            "Qg2+",
            "Kf5",
            "Qxe4+",
            "Kxe4",
            "d6",
            "f5",
            "d7",
            "f4",
            "d8=Q",
            "f3",
            "Qe7+",
            "Kf4",
            "Qxc5",
            "Kg3",
            "Qxa7",
            "Kg2",
            "Qxb7",
            "Kg1",
            "Qxf3",
            "Kh2",
            "Qg4",
            "Kh1",
            "Kd2",
            "Kh2",
            "Ke2",
            "Kh1",
            "Kf2",
            "Kh2",
            "Qg2#",
            "Kg5",
            "Qf3",
            "Kg6",
            "Qf4",
            "Kg7",
            "Qf5",
            "Kg8",
            "Qf6",
            "Kh7",
            "Qg5",
            "Kh8",
            "Kf3",
            "Kh7",
            "Kf4",
            "Kh8",
            "Kf5",
            "Kh7",
            "Kf6",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne5",
          "neutral_uci": "c6e5",
          "neutral_response": "5... Ne5 6. f4 Ng6 7. Be3 d6 8. Nc3 Nf6 9. Qd2 Be7 10. O-O-O O-O 11. h3 Re8 12. g4 Bf8 13. Bd3 c6 14. g5 Nd7 15. h4 Nc5 16. h5 Nxd3+ 17. Qxd3 Ne7 18. f5 cxd5 19. Nxd5 Nxd5 20. Qxd5 Qe7 21. g6 Qxe4 22. Qxf7+ Kh8 23. Bd4 Bxf5 24. Rh2 Rac8 25. c3 Qb1+ 26. Kd2 Qxb2# 27. Ke1 Qxh2 28. h6 Qxh6 29. Qxf5 Qxg6 30. Qxg6 hxg6 31. Kd2 Kg8 32. Rg1 Re6 33. Rg5 Be7 34. Rb5 b6 35. a4 Bf6 36. a5 Bxd4 37. cxd4 bxa5 38. Rxa5 Rc7 39. Kd3 Kf7 40. Ra1 Rf6 41. Ra5 Rf5 42. Ra6 Ke6 43. Ra1 g5 44. Re1+ Kf6 45. Re8 g4 46. Rf8+ Kg5 47. Rd8 g3 48. Rxd6 g2 49. Ke4 g1=Q 50. Rg6+ Kxg6 51. d5 Qg4+ 52. Ke3 Rf3+ 53. Ke2 Qg2+ 54. Ke1 Rf1# 55. d6 Rc2 56. d7 Qe2# 57. Kxf1 Qf2# 58. Kg1 Qg2# 59. Kh1 Qh2# 60. Kg1 Qf2# 61. Kh1 Qg2# 62. Kg1 Qf2# 63. Kh1 Qg2# 64. Kg1 Qf2# 65. Kh1 Qg2# 66. Kg1 Qf2# 67. Kh1 Qg2# 68. Kg1 Qf2# 69. Kh1 Qg2# 70. Kg1 Qf2# 71. Kh1 Qg2# 72. Kg1 Qf2# 73. Kh1 Qg2# 74. Kg1 Qf2# 75. Kh1 Qg2# 76. Kg1 Qf2# 77. Kh1 Qg2# 78. Kg1 Qf2# 79. Kh1 Qg2# 80.",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f4",
            "Ng6",
            "Be3",
            "d6",
            "Nc3",
            "Nf6",
            "Qd2",
            "Be7",
            "O-O-O",
            "O-O",
            "h3",
            "Re8",
            "g4",
            "Bf8",
            "Bd3",
            "c6",
            "g5",
            "Nd7",
            "h4",
            "Nc5",
            "h5",
            "Nxd3+",
            "Qxd3",
            "Ne7",
            "f5",
            "cxd5",
            "Nxd5",
            "Nxd5",
            "Qxd5",
            "Qe7",
            "g6",
            "Qxe4",
            "Qxf7+",
            "Kh8",
            "Bd4",
            "Bxf5",
            "Rh2",
            "Rac8",
            "c3",
            "Qb1+",
            "Kd2",
            "Qxb2#",
            "Ke1",
            "Qxh2",
            "h6",
            "Qxh6",
            "Qxf5",
            "Qxg6",
            "Qxg6",
            "hxg6",
            "Kd2",
            "Kg8",
            "Rg1",
            "Re6",
            "Rg5",
            "Be7",
            "Rb5",
            "b6",
            "a4",
            "Bf6",
            "a5",
            "Bxd4",
            "cxd4",
            "bxa5",
            "Rxa5",
            "Rc7",
            "Kd3",
            "Kf7",
            "Ra1",
            "Rf6",
            "Ra5",
            "Rf5",
            "Ra6",
            "Ke6",
            "Ra1",
            "g5",
            "Re1+",
            "Kf6",
            "Re8",
            "g4",
            "Rf8+",
            "Kg5",
            "Rd8",
            "g3",
            "Rxd6",
            "g2",
            "Ke4",
            "g1=Q",
            "Rg6+",
            "Kxg6",
            "d5",
            "Qg4+",
            "Ke3",
            "Rf3+",
            "Ke2",
            "Qg2+",
            "Ke1",
            "Rf1#",
            "d6",
            "Rc2",
            "d7",
            "Qe2#",
            "Kxf1",
            "Qf2#",
            "Kg1",
            "Qg2#",
            "Kh1",
            "Qh2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#",
            "Kg1",
            "Qf2#",
            "Kh1",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c6e5",
          "positional_uci": "c6e5",
          "neutral_uci": "c6e5",
          "consensus_move": "c6e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "f4",
              "Ng6",
              "Nc3",
              "Bb4",
              "Bd3",
              "d6",
              "O-O",
              "Nf6",
              "Be3",
              "O-O",
              "Bd4",
              "c5",
              "dxc6",
              "bxc6",
              "a3",
              "Ba5",
              "b4",
              "Bb6",
              "Bxb6",
              "Qxb6+",
              "Kh1",
              "Ng4",
              "Qe2",
              "Qd4",
              "Na4",
              "f5",
              "c3",
              "Qe3",
              "Qxe3",
              "Nxe3",
              "Rf3",
              "Ng4",
              "exf5",
              "Bxf5",
              "Bxf5",
              "Rxf5",
              "h3",
              "Nf6",
              "g4",
              "Rxf4",
              "Rxf4",
              "Nxf4",
              "Kh2",
              "Re8",
              "Kg3",
              "g5",
              "h4",
              "Re3+",
              "Kf2",
              "Nxg4+",
              "Kf1",
              "gxh4",
              "Re1",
              "Rf3+",
              "Kg1",
              "h3",
              "Re8+",
              "Kf7",
              "Re1",
              "h2+",
              "Kh1",
              "Rg3",
              "Rf1",
              "Nf2+",
              "Rxf2",
              "Rg1+",
              "Kxh2",
              "Rg4",
              "Nb2",
              "Kg6",
              "Nd1",
              "Kg5",
              "Ne3",
              "Rh4+",
              "Kg3",
              "Rh3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "f4",
              "Ng6",
              "Be3",
              "d6",
              "Nc3",
              "Nf6",
              "Qd2",
              "Be7",
              "O-O-O",
              "O-O",
              "h3",
              "Re8",
              "g4",
              "Bf8",
              "Bd3",
              "c6",
              "g5",
              "Nd7",
              "h4",
              "cxd5",
              "Nxd5",
              "Nc5",
              "h5",
              "Ne7",
              "Bxc5",
              "dxc5",
              "Bc4",
              "Nxd5",
              "Bxd5",
              "Qc7",
              "g6",
              "Be6",
              "h6",
              "Bxd5",
              "gxh7+",
              "Kh8",
              "hxg7+",
              "Bxg7",
              "exd5",
              "Qb6",
              "c3",
              "Rad8",
              "Rdg1",
              "Qf6",
              "Rg5",
              "Re4",
              "Rhg1",
              "Bh6",
              "Rg8+",
              "Kxh7",
              "Rxd8",
              "Bxf4",
              "Rh1+",
              "Kg7",
              "Rg1+",
              "Kh6",
              "Rh1+",
              "Kg5",
              "Rg8+",
              "Kf5",
              "Rh5+",
              "Bg5",
              "Rgxg5+",
              "Qxg5",
              "Qxg5#",
              "Bg5",
              "Rxg5#",
              "Kxg5",
              "Qg2+",
              "Kf5",
              "Qxe4+",
              "Kxe4",
              "d6",
              "f5",
              "d7",
              "f4",
              "d8=Q",
              "f3",
              "Qe7+",
              "Kf4",
              "Qxc5",
              "Kg3",
              "Qxa7",
              "Kg2",
              "Qxb7",
              "Kg1",
              "Qxf3",
              "Kh2",
              "Qg4",
              "Kh1",
              "Kd2",
              "Kh2",
              "Ke2",
              "Kh1",
              "Kf2",
              "Kh2",
              "Qg2#",
              "Kg5",
              "Qf3",
              "Kg6",
              "Qf4",
              "Kg7",
              "Qf5",
              "Kg8",
              "Qf6",
              "Kh7",
              "Qg5",
              "Kh8",
              "Kf3",
              "Kh7",
              "Kf4",
              "Kh8",
              "Kf5",
              "Kh7",
              "Kf6",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "f4",
              "Ng6",
              "Be3",
              "d6",
              "Nc3",
              "Nf6",
              "Qd2",
              "Be7",
              "O-O-O",
              "O-O",
              "h3",
              "Re8",
              "g4",
              "Bf8",
              "Bd3",
              "c6",
              "g5",
              "Nd7",
              "h4",
              "Nc5",
              "h5",
              "Nxd3+",
              "Qxd3",
              "Ne7",
              "f5",
              "cxd5",
              "Nxd5",
              "Nxd5",
              "Qxd5",
              "Qe7",
              "g6",
              "Qxe4",
              "Qxf7+",
              "Kh8",
              "Bd4",
              "Bxf5",
              "Rh2",
              "Rac8",
              "c3",
              "Qb1+",
              "Kd2",
              "Qxb2#",
              "Ke1",
              "Qxh2",
              "h6",
              "Qxh6",
              "Qxf5",
              "Qxg6",
              "Qxg6",
              "hxg6",
              "Kd2",
              "Kg8",
              "Rg1",
              "Re6",
              "Rg5",
              "Be7",
              "Rb5",
              "b6",
              "a4",
              "Bf6",
              "a5",
              "Bxd4",
              "cxd4",
              "bxa5",
              "Rxa5",
              "Rc7",
              "Kd3",
              "Kf7",
              "Ra1",
              "Rf6",
              "Ra5",
              "Rf5",
              "Ra6",
              "Ke6",
              "Ra1",
              "g5",
              "Re1+",
              "Kf6",
              "Re8",
              "g4",
              "Rf8+",
              "Kg5",
              "Rd8",
              "g3",
              "Rxd6",
              "g2",
              "Ke4",
              "g1=Q",
              "Rg6+",
              "Kxg6",
              "d5",
              "Qg4+",
              "Ke3",
              "Rf3+",
              "Ke2",
              "Qg2+",
              "Ke1",
              "Rf1#",
              "d6",
              "Rc2",
              "d7",
              "Qe2#",
              "Kxf1",
              "Qf2#",
              "Kg1",
              "Qg2#",
              "Kh1",
              "Qh2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#",
              "Kg1",
              "Qf2#",
              "Kh1",
              "Qg2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 1920,
          "total_tokens": 2360
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/3P4/4P3/8/PPP2PPP/RNBQKB1R b KQkq - 0 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ng6",
          "aggressive_uci": "e5g6",
          "aggressive_response": "6... Ng6 7. Nc3 Bb4 8. Bd2 Nf6 9. Bd3 O-O 10. O-O d6 11. a3 Bxc3 12. Bxc3 Bg4 13. Qe1 Re8 14. h3 Bd7 15. f5 Ne5 16. Qg3 Nxd3 17. cxd3 Bb5 18. Rf4 Nh5 19. Qg4 Nf6 20. Qg3 Nh5 21. Qg4 Nf6 22. Qg3 Nh5 23. Qg4 Nf6 24. Qg3 Nh5 25. Qg4 Nf6 26. Qg3 Nh5 27. Qg4 Nf6 28. Qg3 Nh5 29. Qg4 Nf6 30. Qg3 Nh5 31. Qg4 Nf6 32. Qg3 Nh5 33. Qg4 Nf6 34. Qg3 Nh5 35. Qg4 Nf6 36. Qg3 Nh5 37. Qg4 Nf6 38. Qg3 Nh5 39. Qg4 Nf6 40. Qg3 Nh5 41. Qg4 Nf6 42. Qg3 Nh5 43. Qg4 Nf6 44. Qg3 Nh5 45. Qg4 Nf6 46. Qg3 Nh5 47. Qg4 Nf6 48. Qg3 Nh5 49. Qg4 Nf6 50. Qg3 Nh5 51. Qg4 Nf6 52. Qg3 Nh5 53. Qg4 Nf6 54. Qg3 Nh5 55. Qg4 Nf6 56. Qg3 Nh5 57. Qg4 Nf6 58. Qg3 Nh5 59. Qg4 Nf6 60. Qg3 Nh5 61. Qg4 Nf6 62. Qg3 Nh5 63. Qg4 Nf6 64. Qg3 Nh5 65. Qg4 Nf6 66. Qg3 Nh5 67. Qg4 Nf6 68. Qg3 Nh5 69. Qg4 Nf6 70. Qg3 Nh5 71. Qg4 Nf6 72. Qg3 Nh5 73. Qg4 Nf6 74. Qg3 Nh5 75. Qg4 Nf6 76. Qg3 Nh5 77. Qg4 Nf6 78. Qg3 Nh5 79. Qg4 Nf6 80. Qg3 Nh5 81. Qg4 Nf6 82.",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc3",
            "Bb4",
            "Bd2",
            "Nf6",
            "Bd3",
            "O-O",
            "O-O",
            "d6",
            "a3",
            "Bxc3",
            "Bxc3",
            "Bg4",
            "Qe1",
            "Re8",
            "h3",
            "Bd7",
            "f5",
            "Ne5",
            "Qg3",
            "Nxd3",
            "cxd3",
            "Bb5",
            "Rf4",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ng6",
          "positional_uci": "e5g6",
          "positional_response": "6... Ng6 7. Nc3 Bb4 8. Bd2 Nf6 9. Bd3 O-O 10. O-O d6 11. a3 Bxc3 12. Bxc3 Re8 13. Qf3 Bg4 14. Qg3 Bd7 15. Rae1 c6 16. e5 dxe5 17. fxe5 Nxd5 18. Bxg6 hxg6 19. Qf3 Be6 20. Bd2 Qb6+ 21. Kh1 Qxb2 22. Rb1 Qxc2 23. Bg5 b6 24. Rbc1 Qa4 25. h4 Rac8 26. h5 gxh5 27. Qxh5 Qxa3 28. Rf3 Qb2 29. Rcf1 Qxe5 30. Rxf7 Bxf7 31. Qxf7+ Kh8 32. Qh5+ Kg8 33. Qf7+ Kh7 34. Qh5+ Kg8 35. Qf7+ Kh8 36. Qh5+ Kg8 37. Qf7+ Kh7 38. Qh5+ Kg8 39. Qf7+ Kh8 40. Qh5+ Kg8 41. Qf7+ Kh7 42. Qh5+ Kg8 43. Qf7+ Kh8 44. Qh5+ Kg8 45. Qf7+ Kh7 46. Qh5+ Kg8 47. Qf7+ Kh8 48. Qh5+ Kg8 49. Qf7+ Kh7 50. Qh5+ Kg8 51. Qf7+ Kh8 52. Qh5+ Kg8 53. Qf7+ Kh7 54. Qh5+ Kg8 55. Qf7+ Kh8 56. Qh5+ Kg8 57. Qf7+ Kh7 58. Qh5+ Kg8 59. Qf7+ Kh8 60. Qh5+ Kg8 61. Qf7+ Kh7 62. Qh5+ Kg8 63. Qf7+ Kh8 64. Qh5+ Kg8 65. Qf7+ Kh7 66. Qh5+ Kg8 67. Qf7+ Kh8 68. Qh5+ Kg8 69. Qf7+ Kh7 70. Qh5+ Kg8 71. Qf7+ Kh8 72. Qh5+ Kg8 73. Qf7+ Kh7 74. Qh5+ Kg8 75. Qf7+ Kh8 76. Qh5+ Kg8 77. Qf7+ Kh7 78. Qh5+ Kg8 79",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc3",
            "Bb4",
            "Bd2",
            "Nf6",
            "Bd3",
            "O-O",
            "O-O",
            "d6",
            "a3",
            "Bxc3",
            "Bxc3",
            "Re8",
            "Qf3",
            "Bg4",
            "Qg3",
            "Bd7",
            "Rae1",
            "c6",
            "e5",
            "dxe5",
            "fxe5",
            "Nxd5",
            "Bxg6",
            "hxg6",
            "Qf3",
            "Be6",
            "Bd2",
            "Qb6+",
            "Kh1",
            "Qxb2",
            "Rb1",
            "Qxc2",
            "Bg5",
            "b6",
            "Rbc1",
            "Qa4",
            "h4",
            "Rac8",
            "h5",
            "gxh5",
            "Qxh5",
            "Qxa3",
            "Rf3",
            "Qb2",
            "Rcf1",
            "Qxe5",
            "Rxf7",
            "Bxf7",
            "Qxf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qh5+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ng6",
          "neutral_uci": "e5g6",
          "neutral_response": "6... Ng6 7. Bd3 Bc5 8. Qe2 d6 9. Be3 Bxe3 10. Qxe3 Nf6 11. O-O O-O 12. Nc3 Re8 13. Rae1 c6 14. dxc6 bxc6 15. Qd4 Qb6 16. Qxb6 axb6 17. a3 Ba6 18. Bxa6 Rxa6 19. g3 Ra7 20. Kg2 Rae7 21. Kf3 d5 22. e5 Nd7 23. Rd1 f6 24. exf6 Nxf6 25. Rd3 Ne4 26. Na4 b5 27. Nc3 Nxc3 28. Rxc3 Re6 29. Rd1 Ne7 30. g4 Nc8 31. f5 Rd6 32. Rd4 Nb6 33. b3 Nd7 34. Kf4 c5 35. Rd1 Re4+ 36. Kg3 d4 37. Rf3 Ne5 38. Rf4 Re3+ 39. Kh4 Rh6+ 40. Kg5 Nf7# 0-1\n6... Ng6 7. Bd3 Bc5 8. Qe2 d6 9. Be3 Bxe3 10. Qxe3 Nf6 11. O-O O-O 12. Nc3 Re8 13. Rae1 c6 14. dxc6 bxc6 15. Qd4 Qb6 16. Qxb6 axb6 17. a3 Ba6 18. Bxa6 Rxa6 19. g3 Ra7 20. Kg2 Rae7 21. Kf3 d5 22. e5 Nd7 23. Rd1 f6 24. exf6 Nxf6 25. Rd3 Ne4 26. Na4 b5 27. Nc3 Nxc3 28. Rxc3 Re6 29. Rd1 Nf8 30. g4 Nc8 31. f5 Rd6 32. Rd4 Nb6 33. b3 Nd7 34. Kf4 c5 35. Rd1 Re4+ 36. Kg3 d4 37. Rf3 Ne5 38. Rf4 Re3+ 39. Kh4 Rh6+ 40. Kg5 Nf7# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 553,
            "total_tokens": 706,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3",
            "Bc5",
            "Qe2",
            "d6",
            "Be3",
            "Bxe3",
            "Qxe3",
            "Nf6",
            "O-O",
            "O-O",
            "Nc3",
            "Re8",
            "Rae1",
            "c6",
            "dxc6",
            "bxc6",
            "Qd4",
            "Qb6",
            "Qxb6",
            "axb6",
            "a3",
            "Ba6",
            "Bxa6",
            "Rxa6",
            "g3",
            "Ra7",
            "Kg2",
            "Rae7",
            "Kf3",
            "d5",
            "e5",
            "Nd7",
            "Rd1",
            "f6",
            "exf6",
            "Nxf6",
            "Rd3",
            "Ne4",
            "Na4",
            "b5",
            "Nc3",
            "Nxc3",
            "Rxc3",
            "Re6",
            "Rd1",
            "Nf8",
            "g4",
            "Nc8",
            "f5",
            "Rd6",
            "Rd4",
            "Nb6",
            "b3",
            "Nd7",
            "Kf4",
            "c5",
            "Rd1",
            "Re4+",
            "Kg3",
            "d4",
            "Rf3",
            "Ne5",
            "Rf4",
            "Re3+",
            "Kh4",
            "Rh6+",
            "Kg5",
            "Nf7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5g6",
          "positional_uci": "e5g6",
          "neutral_uci": "e5g6",
          "consensus_move": "e5g6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Bb4",
              "Bd2",
              "Nf6",
              "Bd3",
              "O-O",
              "O-O",
              "d6",
              "a3",
              "Bxc3",
              "Bxc3",
              "Bg4",
              "Qe1",
              "Re8",
              "h3",
              "Bd7",
              "f5",
              "Ne5",
              "Qg3",
              "Nxd3",
              "cxd3",
              "Bb5",
              "Rf4",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Bb4",
              "Bd2",
              "Nf6",
              "Bd3",
              "O-O",
              "O-O",
              "d6",
              "a3",
              "Bxc3",
              "Bxc3",
              "Re8",
              "Qf3",
              "Bg4",
              "Qg3",
              "Bd7",
              "Rae1",
              "c6",
              "e5",
              "dxe5",
              "fxe5",
              "Nxd5",
              "Bxg6",
              "hxg6",
              "Qf3",
              "Be6",
              "Bd2",
              "Qb6+",
              "Kh1",
              "Qxb2",
              "Rb1",
              "Qxc2",
              "Bg5",
              "b6",
              "Rbc1",
              "Qa4",
              "h4",
              "Rac8",
              "h5",
              "gxh5",
              "Qxh5",
              "Qxa3",
              "Rf3",
              "Qb2",
              "Rcf1",
              "Qxe5",
              "Rxf7",
              "Bxf7",
              "Qxf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qh5+",
              "Kg8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bd3",
              "Bc5",
              "Qe2",
              "d6",
              "Be3",
              "Bxe3",
              "Qxe3",
              "Nf6",
              "O-O",
              "O-O",
              "Nc3",
              "Re8",
              "Rae1",
              "c6",
              "dxc6",
              "bxc6",
              "Qd4",
              "Qb6",
              "Qxb6",
              "axb6",
              "a3",
              "Ba6",
              "Bxa6",
              "Rxa6",
              "g3",
              "Ra7",
              "Kg2",
              "Rae7",
              "Kf3",
              "d5",
              "e5",
              "Nd7",
              "Rd1",
              "f6",
              "exf6",
              "Nxf6",
              "Rd3",
              "Ne4",
              "Na4",
              "b5",
              "Nc3",
              "Nxc3",
              "Rxc3",
              "Re6",
              "Rd1",
              "Nf8",
              "g4",
              "Nc8",
              "f5",
              "Rd6",
              "Rd4",
              "Nb6",
              "b3",
              "Nd7",
              "Kf4",
              "c5",
              "Rd1",
              "Re4+",
              "Kg3",
              "d4",
              "Rf3",
              "Ne5",
              "Rf4",
              "Re3+",
              "Kh4",
              "Rh6+",
              "Kg5",
              "Nf7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 553,
            "total_tokens": 706,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 1833,
          "total_tokens": 2294
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 553,
            "total_tokens": 706,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/8/3Pn3/4PP2/8/PPP3PP/RNBQKB1R b KQkq - 0 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qf6",
          "aggressive_uci": "d8f6",
          "aggressive_response": "7... Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. Bxc3 Nxf4 13. O-O-O Ne7 14. d6 cxd6 15. exd6 Nf5 16. g4 Ne3 17. Re1 Nfd5 18. Bd4 O-O 19. Bxe3 Rxa2 20. Kb1 Ra4 21. Bg2 Nxe3 22. Rxe3 Rxg4 23. Bd5 Rd4 24. c4 b5 25. b3 bxc4 26. bxc4 b5 27. Re4 Rxe4 28. Bxe4 bxc4 29. Rc1 Ba6 30. Bd5 Rc8 31. Rf1 Rf8 32. Rc1 Rc8 33. Rf1 Rf8 34. Rc1 Rc8 35. Rf1 Rf8 36. Rc1 Rc8 37. Rf1 Rf8 38. Rc1 Rc8 39. Rf1 Rf8 40. Rc1 Rc8 41. Rf1 Rf8 42. Rc1 Rc8 43. Rf1 Rf8 44. Rc1 Rc8 45. Rf1 Rf8 46. Rc1 Rc8 47. Rf1 Rf8 48. Rc1 Rc8 49. Rf1 Rf8 50. Rc1 Rc8 51. Rf1 Rf8 52. Rc1 Rc8 53. Rf1 Rf8 54. Rc1 Rc8 55. Rf1 Rf8 56. Rc1 Rc8 57. Rf1 Rf8 58. Rc1 Rc8 59. Rf1 Rf8 60. Rc1 Rc8 61. Rf1 Rf8 62. Rc1 Rc8 63. Rf1 Rf8 64. Rc1 Rc8 65. Rf1 Rf8 66. Rc1 Rc8 67. Rf1 Rf8 68. Rc1 Rc8 69. Rf1 Rf8 70. Rc1 Rc8 71. Rf1 Rf8 72. Rc1 Rc8 73. Rf1 Rf8 74. Rc1 Rc8 75. Rf1 Rf8 76. Rc1 Rc8 77. Rf1 Rf8 78. Rc1 Rc8 79. Rf1 Rf8 80. Rc1 Rc8 81. Rf1 Rf8 82. Rc1 Rc8 83. Rf1 Rf8 84. Rc1 Rc8 85. Rf1 Rf8 86. Rc1 Rc8",
          "aggressive_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 640,
            "total_tokens": 802,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Qb6",
            "Qxb6",
            "axb6",
            "Nc3",
            "Bb4",
            "Bd2",
            "Bxc3",
            "Bxc3",
            "Nxf4",
            "O-O-O",
            "Ne7",
            "d6",
            "cxd6",
            "exd6",
            "Nf5",
            "g4",
            "Ne3",
            "Re1",
            "Nfd5",
            "Bd4",
            "O-O",
            "Bxe3",
            "Rxa2",
            "Kb1",
            "Ra4",
            "Bg2",
            "Nxe3",
            "Rxe3",
            "Rxg4",
            "Bd5",
            "Rd4",
            "c4",
            "b5",
            "b3",
            "bxc4",
            "bxc4",
            "b5",
            "Re4",
            "Rxe4",
            "Bxe4",
            "bxc4",
            "Rc1",
            "Ba6",
            "Bd5",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8",
            "Rf1",
            "Rf8",
            "Rc1",
            "Rc8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qf6",
          "positional_uci": "d8f6",
          "positional_response": "7... Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. Bxc3 Nxf4 13. O-O-O Ne7 14. d6 cxd6 15. exd6 Nf5 16. g4 Ne3 17. Re1 Nfd5 18. Bxg7 Rg8 19. Bd4 Rxa2 20. Kb1 Ra4 21. c3 Kd8 22. Bxe3 Nxe3 23. Rxe3 Raxg4 24. Bd3 Rg1+ 25. Rxg1 Rxg1+ 26. Kc2 Rg2+ 27. Kb3 Rxh2 28. Rg3 Re2 29. Bxe2 Ke8 30. Rg8# Qxg8 31. Bc4 Qg6 32. Kb4 Qxd6+ 33. Kb3 Qc5 34. Bd3 d5 35. Bxh7 Be6 36. Kc2 d4 37. Bd3 dxc3 38. bxc3 b5 39. Kd2 b4 40. cxb4 Qxb4+ 41. Ke3 Qc3 42. Ke4 Bf5+ 43. Kxf5 Qxd3+ 44. Ke5 b5 45. Kf6 b4 46. Kg7 b3 47. Kg8 b2 48. Kg7 b1=Q 49. Kg8 Qg1+ 50. Kh8 Qh3# Qg8+ 51. Kxg8 *",
          "positional_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 384,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Qb6",
            "Qxb6",
            "axb6",
            "Nc3",
            "Bb4",
            "Bd2",
            "Bxc3",
            "Bxc3",
            "Nxf4",
            "O-O-O",
            "Ne7",
            "d6",
            "cxd6",
            "exd6",
            "Nf5",
            "g4",
            "Ne3",
            "Re1",
            "Nfd5",
            "Bxg7",
            "Rg8",
            "Bd4",
            "Rxa2",
            "Kb1",
            "Ra4",
            "c3",
            "Kd8",
            "Bxe3",
            "Nxe3",
            "Rxe3",
            "Raxg4",
            "Bd3",
            "Rg1+",
            "Rxg1",
            "Rxg1+",
            "Kc2",
            "Rg2+",
            "Kb3",
            "Rxh2",
            "Rg3",
            "Re2",
            "Bxe2",
            "Ke8",
            "Rg8#",
            "Qxg8",
            "Bc4",
            "Qg6",
            "Kb4",
            "Qxd6+",
            "Kb3",
            "Qc5",
            "Bd3",
            "d5",
            "Bxh7",
            "Be6",
            "Kc2",
            "d4",
            "Bd3",
            "dxc3",
            "bxc3",
            "b5",
            "Kd2",
            "b4",
            "cxb4",
            "Qxb4+",
            "Ke3",
            "Qc3",
            "Ke4",
            "Bf5+",
            "Kxf5",
            "Qxd3+",
            "Ke5",
            "b5",
            "Kf6",
            "b4",
            "Kg7",
            "b3",
            "Kg8",
            "b2",
            "Kg7",
            "b1=Q",
            "Kg8",
            "Qg1+",
            "Kh8",
            "Qh3#",
            "Qg8+",
            "Kxg8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c5",
          "neutral_uci": "c7c5",
          "neutral_response": "7... c5 8. Qe3 d6 9. Nc3 Nf6 10. Bd2 Be7 11. O-O-O O-O 12. h3 Re8 13. g4 Bf8 14. g5 Nd7 15. h4 a6 16. h5 Ne7 17. g6 fxg6 18. hxg6 Nxg6 19. Qh3 Nf6 20. f5 Ne5 21. Bg5 h6 22. Bxh6 gxh6 23. Rg1+ Kh7 24. Qg3 Qe7 25. Be2 Qg7 26. Qh4 Qf7 27. Rg3 Be7 28. Rh1 Ng8 29. Qh3 Qf6 30. Bh5 Rf8 31. Bg6+ Nxg6 32. Rxg6 Qxg6 33. fxg6+ Kxg6 34. Qg3+ Kh7 35. Rg1 Bg5+ 36. Kb1 Rf6 37. e5 dxe5 38. Ne4 Rg6 39. Qxe5 Bd7 40. Nxg5+ hxg5 41. Rh1+ Rh6 42. Rxh6+ Kxh6 43. Qd6+ Kh5 44. Qxd7 Rf8 45. Qh3+ Kg6 46. Qd3+ Kh5 47. d6 Nf6 48. Qf3+ Kg6 49. Qxb7 Re8 50. b3 g4 51. d7 Rd8 52. Qxa6 Rxd7 53. Qc6 Rd5 54. a4 g3 55. Qc7 g2 56. Qg3+ Rg5 57. Qd3+ Kh6 58. Qh3+ Kg6 59. Qd3+ Kh6 60. Qh3+ Kg6 61. Qd3+ Kh6 62. Qh3+ Kg6 63. Qd3+ Kh6 64. Qh3+ Kg6 65. Qd3+ Kh6 66. Qh3+ Kg6 67. Qd3+ Kh6 68. Qh3+ Kg6 69. Qd3+ Kh6 70. Qh3+ Kg6 71. Qd3+ Kh6 72. Qh3+ Kg6 73. Qd3+ Kh6 74. Qh3+ Kg6 75. Qd3+ Kh6 76. Qh3+ Kg6 77. Qd3+ Kh6 78. Qh3+ Kg6 79. Qd3+ Kh6 80. Qh3+ Kg6 81. Qd",
          "neutral_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qe3",
            "d6",
            "Nc3",
            "Nf6",
            "Bd2",
            "Be7",
            "O-O-O",
            "O-O",
            "h3",
            "Re8",
            "g4",
            "Bf8",
            "g5",
            "Nd7",
            "h4",
            "a6",
            "h5",
            "Ne7",
            "g6",
            "fxg6",
            "hxg6",
            "Nxg6",
            "Qh3",
            "Nf6",
            "f5",
            "Ne5",
            "Bg5",
            "h6",
            "Bxh6",
            "gxh6",
            "Rg1+",
            "Kh7",
            "Qg3",
            "Qe7",
            "Be2",
            "Qg7",
            "Qh4",
            "Qf7",
            "Rg3",
            "Be7",
            "Rh1",
            "Ng8",
            "Qh3",
            "Qf6",
            "Bh5",
            "Rf8",
            "Bg6+",
            "Nxg6",
            "Rxg6",
            "Qxg6",
            "fxg6+",
            "Kxg6",
            "Qg3+",
            "Kh7",
            "Rg1",
            "Bg5+",
            "Kb1",
            "Rf6",
            "e5",
            "dxe5",
            "Ne4",
            "Rg6",
            "Qxe5",
            "Bd7",
            "Nxg5+",
            "hxg5",
            "Rh1+",
            "Rh6",
            "Rxh6+",
            "Kxh6",
            "Qd6+",
            "Kh5",
            "Qxd7",
            "Rf8",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh5",
            "d6",
            "Nf6",
            "Qf3+",
            "Kg6",
            "Qxb7",
            "Re8",
            "b3",
            "g4",
            "d7",
            "Rd8",
            "Qxa6",
            "Rxd7",
            "Qc6",
            "Rd5",
            "a4",
            "g3",
            "Qc7",
            "g2",
            "Qg3+",
            "Rg5",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6",
            "Qd3+",
            "Kh6",
            "Qh3+",
            "Kg6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8f6",
          "positional_uci": "d8f6",
          "neutral_uci": "c7c5",
          "consensus_move": "d8f6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Qb6",
              "Qxb6",
              "axb6",
              "Nc3",
              "Bb4",
              "Bd2",
              "Bxc3",
              "Bxc3",
              "Nxf4",
              "O-O-O",
              "Ne7",
              "d6",
              "cxd6",
              "exd6",
              "Nf5",
              "g4",
              "Ne3",
              "Re1",
              "Nfd5",
              "Bd4",
              "O-O",
              "Bxe3",
              "Rxa2",
              "Kb1",
              "Ra4",
              "Bg2",
              "Nxe3",
              "Rxe3",
              "Rxg4",
              "Bd5",
              "Rd4",
              "c4",
              "b5",
              "b3",
              "bxc4",
              "bxc4",
              "b5",
              "Re4",
              "Rxe4",
              "Bxe4",
              "bxc4",
              "Rc1",
              "Ba6",
              "Bd5",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8",
              "Rf1",
              "Rf8",
              "Rc1",
              "Rc8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Qb6",
              "Qxb6",
              "axb6",
              "Nc3",
              "Bb4",
              "Bd2",
              "Bxc3",
              "Bxc3",
              "Nxf4",
              "O-O-O",
              "Ne7",
              "d6",
              "cxd6",
              "exd6",
              "Nf5",
              "g4",
              "Ne3",
              "Re1",
              "Nfd5",
              "Bxg7",
              "Rg8",
              "Bd4",
              "Rxa2",
              "Kb1",
              "Ra4",
              "c3",
              "Kd8",
              "Bxe3",
              "Nxe3",
              "Rxe3",
              "Raxg4",
              "Bd3",
              "Rg1+",
              "Rxg1",
              "Rxg1+",
              "Kc2",
              "Rg2+",
              "Kb3",
              "Rxh2",
              "Rg3",
              "Re2",
              "Bxe2",
              "Ke8",
              "Rg8#",
              "Qxg8",
              "Bc4",
              "Qg6",
              "Kb4",
              "Qxd6+",
              "Kb3",
              "Qc5",
              "Bd3",
              "d5",
              "Bxh7",
              "Be6",
              "Kc2",
              "d4",
              "Bd3",
              "dxc3",
              "bxc3",
              "b5",
              "Kd2",
              "b4",
              "cxb4",
              "Qxb4+",
              "Ke3",
              "Qc3",
              "Ke4",
              "Bf5+",
              "Kxf5",
              "Qxd3+",
              "Ke5",
              "b5",
              "Kf6",
              "b4",
              "Kg7",
              "b3",
              "Kg8",
              "b2",
              "Kg7",
              "b1=Q",
              "Kg8",
              "Qg1+",
              "Kh8",
              "Qh3#",
              "Qg8+",
              "Kxg8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe3",
              "d6",
              "Nc3",
              "Nf6",
              "Bd2",
              "Be7",
              "O-O-O",
              "O-O",
              "h3",
              "Re8",
              "g4",
              "Bf8",
              "g5",
              "Nd7",
              "h4",
              "a6",
              "h5",
              "Ne7",
              "g6",
              "fxg6",
              "hxg6",
              "Nxg6",
              "Qh3",
              "Nf6",
              "f5",
              "Ne5",
              "Bg5",
              "h6",
              "Bxh6",
              "gxh6",
              "Rg1+",
              "Kh7",
              "Qg3",
              "Qe7",
              "Be2",
              "Qg7",
              "Qh4",
              "Qf7",
              "Rg3",
              "Be7",
              "Rh1",
              "Ng8",
              "Qh3",
              "Qf6",
              "Bh5",
              "Rf8",
              "Bg6+",
              "Nxg6",
              "Rxg6",
              "Qxg6",
              "fxg6+",
              "Kxg6",
              "Qg3+",
              "Kh7",
              "Rg1",
              "Bg5+",
              "Kb1",
              "Rf6",
              "e5",
              "dxe5",
              "Ne4",
              "Rg6",
              "Qxe5",
              "Bd7",
              "Nxg5+",
              "hxg5",
              "Rh1+",
              "Rh6",
              "Rxh6+",
              "Kxh6",
              "Qd6+",
              "Kh5",
              "Qxd7",
              "Rf8",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh5",
              "d6",
              "Nf6",
              "Qf3+",
              "Kg6",
              "Qxb7",
              "Re8",
              "b3",
              "g4",
              "d7",
              "Rd8",
              "Qxa6",
              "Rxd7",
              "Qc6",
              "Rd5",
              "a4",
              "g3",
              "Qc7",
              "g2",
              "Qg3+",
              "Rg5",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6",
              "Qd3+",
              "Kh6",
              "Qh3+",
              "Kg6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 162,
            "completion_tokens": 640,
            "total_tokens": 802,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 162,
            "completion_tokens": 384,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 485,
          "total_completion_tokens": 1664,
          "total_tokens": 2149
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 162,
            "completion_tokens": 640,
            "total_tokens": 802,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 162,
            "completion_tokens": 384,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/6n1/3P4/3QPP2/8/PPP3PP/RNB1KB1R b KQkq - 2 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qb6",
          "aggressive_uci": "f6b6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. bxc3 N8e7 13. c4 O-O 14. Bd3 d6 15. exd6 cxd6 16. O-O Bf5 17. Bb4 Bxd3 18. cxd3 Rfd8 19. g4 f5 20. g5 Nc8 21. a3 Re8 22. Rae1 Rxe1 23. Rxe1 Nxf4 24. Re8+ Kf7 25. Rd8 Nxd3 26. Bxd6 Nxd6 27. Rxa8 Nxc4 28. Ra7 Nd6 29. Ra8 Nf4 30. Rd8 Ke7 31. Rg8 Ne8 32. Rh8 Nxd5 33. Rxh7 Kf7 34. Rh3 Kg6 35. Rd3 Nec7 36. h4 Kh5 37. Rd4 g6 38. Kh2 b5 39. Kh3 b6 40. Kg3 f4+ 41. Kh3 f3 42. Kg3 f2 43. Kxf2 Nc3 44. Kg3 Ne6 45. Rd7 Ne4+ 46. Kh3 Nf4+ 47. Kh2 Kxh4 48. Rd4 Nxg5 49. Rxf4+ Kh5 50. Rb4 Nf3+ 51. Kg3 Ne5 52. Rxb5\n*1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. bxc3 N8e7 13. c4 O-O 14. Bd3 d6 15. exd6 cxd6 16. O-O Bf5 17. Bb4 Bxd3 18. cxd3 Rfd8 19. g4 f5 20. g5 Nc8 21. a3 Re8 22. Rae1 Rxe1 23. Rxe1 Nxf4 24. Re8+ Kf7 25. Rd8 Nxd3 26. Bxd6 Nxd6 27. Rxa8 Nxc4",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxb6",
            "axb6",
            "Nc3",
            "Bb4",
            "Bd2",
            "Bxc3",
            "bxc3",
            "N8e7",
            "c4",
            "O-O",
            "Bd3",
            "d6",
            "exd6",
            "cxd6",
            "O-O",
            "Bf5",
            "Bb4",
            "Bxd3",
            "cxd3",
            "Rfd8",
            "g4",
            "f5",
            "g5",
            "Nc8",
            "a3",
            "Re8",
            "Rae1",
            "Rxe1",
            "Rxe1",
            "Nxf4",
            "Re8+",
            "Kf7",
            "Rd8",
            "Nxd3",
            "Bxd6",
            "Nxd6",
            "Rxa8",
            "Nxc4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qb6",
          "positional_uci": "f6b6",
          "positional_response": "8... Qb6 9. Qxb6 axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. Bxc3 Nxf4 13. O-O-O Ne7 14. d6 cxd6 15. exd6 Nf5 16. g4 Ne3 17. Re1 Nfd5 18. Bd4 O-O 19. Bxe3 Nxe3 20. Rxe3 Rxa2 21. Kb1 Ra4 22. h3 Rd4 23. Rd3 Rxd3 24. Bxd3 Re8 25. Rf1 Re6 26. Bc4 Rf6 27. Rxf6 gxf6 28. Kc1 Kg7 29. Kd2 Kg6 30. Ke3 f5 31. Kf4 fxg4 32. hxg4 f6 33. Bd3+ Kg7 34. Kf5 b5 35. Bxb5 b6 36. b4 Bb7 37. Bxd7 Bd5 38. Be6 Bc6 39. d7 Bxd7 40. Bxd7 Kf7 41. c4 Ke7 42. Be6 Kd6 43. Kxf6 Kc6 44. Kg7 Kd6 45. Bd5 Ke5 46. Kxh7 Kf4 47. Be6 Ke5 48. Bf5 Kd4 49. Be6 Ke5 50. Bd5 Kf4 51. Kg6 Kxg4 52. Kf6 Kf4 53. Ke6 Ke3 54. Kd6 Kd4 55. Kc6 Kc3 56. b5 Kb4 57. Kxb6 Ka4 58. c5 Kb4 59. c6 Ka4 60. c7 Kb4 61. c8=Q Ka4 62. Qc4+ Ka3 63. Qb3# Qb6 Qxb6",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 457,
            "total_tokens": 628,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxb6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qb6",
          "neutral_uci": "f6b6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qe4 Bc5 10. Nc3 Bf2+ 11. Kd1 Qd4+ 12. Bd3 Qxe4 13. Nxe4 Bb6 14. c4 d6 15. exd6 Bf5 16. Re1 O-O-O 17. c5 Bxe4 18. cxb6 Bxd3 19. bxa7 Kd7 20. dxc7 Ra8 21. Be3 Nf6 22. Rc1 Nxd5 23. Bd4 Nxc7 24. Bxg7 Rhc8 25. Rc3 Bf5 26. Bd4 Nb5 27. Rxc8 Rxc8 28. Bb6 Ra8 29. a4 Nxa7 30. Kd2 Nc6 31. b3 Re8 32. Rxe8 Kxe8 33. g3 Kd7 34. Kc3 Nge7 35. b4 Nd5+ 36. Kc4 Nxb6+ 37. Kb5 Kc7 38. a5 Bd3+ 39. Kc5 Nd7+ 40. Kd5 Nxb4+ 41. Kd4 Bf5 42. Kc4 Nc6 43. Kb5 Nxa5 44. Kxa5 Kc6 45. Kb4 Kd5 46. Kc3 Ke4 47. Kd2 Kf3 48. Ke1 Kg2 49. Ke2 Kxh2 50. Kf3 b5 51. g4 Bxg4+ 52. Kxg4 b4 53. Kf3 b3 54. Ke2 b2 55. Kd2 b1=Q 56. Ke3 Qb4 57. Kf3 Qd4 58. Kg4 Qe4 59. Kg5 Kg3 60. Kh6 Qg6#\n*1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qe4 Bc5 10. Nc3 Bf2+ 11. Kd1 Qd4+ 12. Bd3 Qxe4 13. Nxe4 Bb6 14. c4 d6 15. exd6 Bf5 16. Re1 O-O-O",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qe4",
            "Bc5",
            "Nc3",
            "Bf2+",
            "Kd1",
            "Qd4+",
            "Bd3",
            "Qxe4",
            "Nxe4",
            "Bb6",
            "c4",
            "d6",
            "exd6",
            "Bf5",
            "Re1",
            "O-O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f6b6",
          "positional_uci": "f6b6",
          "neutral_uci": "f6b6",
          "consensus_move": "f6b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxb6",
              "axb6",
              "Nc3",
              "Bb4",
              "Bd2",
              "Bxc3",
              "bxc3",
              "N8e7",
              "c4",
              "O-O",
              "Bd3",
              "d6",
              "exd6",
              "cxd6",
              "O-O",
              "Bf5",
              "Bb4",
              "Bxd3",
              "cxd3",
              "Rfd8",
              "g4",
              "f5",
              "g5",
              "Nc8",
              "a3",
              "Re8",
              "Rae1",
              "Rxe1",
              "Rxe1",
              "Nxf4",
              "Re8+",
              "Kf7",
              "Rd8",
              "Nxd3",
              "Bxd6",
              "Nxd6",
              "Rxa8",
              "Nxc4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxb6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe4",
              "Bc5",
              "Nc3",
              "Bf2+",
              "Kd1",
              "Qd4+",
              "Bd3",
              "Qxe4",
              "Nxe4",
              "Bb6",
              "c4",
              "d6",
              "exd6",
              "Bf5",
              "Re1",
              "O-O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 457,
            "total_tokens": 628,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1737,
          "total_tokens": 2249
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 457,
            "total_tokens": 628,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b1kbnr/pppp1ppp/5qn1/3PP3/3Q1P2/8/PPP3PP/RNB1KB1R b KQkq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "axb6",
          "aggressive_uci": "a7b6",
          "aggressive_response": "9... axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. Bxc3 Nxf4 13. Bc4 Ne7 14. O-O-O O-O 15. Rhf1 Nfg6 16. d6 cxd6 17. exd6 Nc6 18. Rde1 b5 19. Bxb5 Rxa2 20. Kb1 Ra8 21. Bc4 b6 22. Rxf7 Rxf7 23. Re8+ Nf8 24. Bd5 Bb7 25. Bxf7+ Kxf7 26. Re3 Ne6 27. Rf3+ Kg8 28. Rg3 Rf8 29. b3 Rf1+ 30. Kb2 Rf2 31. h4 Ncd4 32. Bxd4 Nxd4 33. Rc3 Rxg2 34. Rc7 Bc6 35. Kc3 Nb5+ 36. Kb4 Nxc7 37. dxc7 Bb7 38. Kb5 Rxc2 39. Kxb6 Bc8 40. b4 d5 41. b5 d4 42. Ka7 Rxc7+ 43. Kb8 Rc1 44. b6 d3 45. b7 Bxb7 46. Kxb7 d2 47. Kb6 d1=Q 48. Kb5 Qb3+ 49. Ka5 Ra1# 0-1\n9... axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. Bxc3 Nxf4 13. Bc4 Ne7 14. O-O-O O-O 15. Rhf1 Nfg6 16. d6 cxd6 17. exd6 Nc6 18. Rde1 b5 19. Bxb5 Rxa2 20. Kb1 Ra8 21. Bc4 b6 22. Rxf7 Rxf7 23. Re8+ Nf8 24. Bd5 Bb7 25. Bxf7+ Kxf7 26. Re3 Ne6 27. Rf3+ Kg8 28. Rg3 Rf8 29. b3 Rf1+ 30. Kb2 Rf2 31. h4 Ncd4 32. Bxd4 Nxd4 33. Rc3 Rxg2 34. Rc7 Bc6 35. Kc3 Nb5+ 36. Kb4 Nxc7 37. dxc7 Bb7 38. Kb5 Rxc2 39. Kxb6 Bc8 40. b4 d5 41. b5 d4 42. Ka7 Rxc7+ 43. Kb8 Rc1 44. b6 d3",
          "aggressive_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nc3",
            "Bb4",
            "Bd2",
            "Bxc3",
            "Bxc3",
            "Nxf4",
            "Bc4",
            "Ne7",
            "O-O-O",
            "O-O",
            "Rhf1",
            "Nfg6",
            "d6",
            "cxd6",
            "exd6",
            "Nc6",
            "Rde1",
            "b5",
            "Bxb5",
            "Rxa2",
            "Kb1",
            "Ra8",
            "Bc4",
            "b6",
            "Rxf7",
            "Rxf7",
            "Re8+",
            "Nf8",
            "Bd5",
            "Bb7",
            "Bxf7+",
            "Kxf7",
            "Re3",
            "Ne6",
            "Rf3+",
            "Kg8",
            "Rg3",
            "Rf8",
            "b3",
            "Rf1+",
            "Kb2",
            "Rf2",
            "h4",
            "Ncd4",
            "Bxd4",
            "Nxd4",
            "Rc3",
            "Rxg2",
            "Rc7",
            "Bc6",
            "Kc3",
            "Nb5+",
            "Kb4",
            "Nxc7",
            "dxc7",
            "Bb7",
            "Kb5",
            "Rxc2",
            "Kxb6",
            "Bc8",
            "b4",
            "d5",
            "b5",
            "d4",
            "Ka7",
            "Rxc7+",
            "Kb8",
            "Rc1",
            "b6",
            "d3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "axb6",
          "positional_uci": "a7b6",
          "positional_response": "9... axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. Bxc3 Nxf4 13. Bc4 Ne7 14. O-O-O O-O 15. Rhf1 Nfg6 16. d6 Nc6 17. Rde1 cxd6 18. exd6 b5 19. Bxb5 Rxa2 20. b3 b6 21. Kb1 Ra8 22. Bc4 Ba6 23. Bxa6 Rxa6 24. Re4 Rfa8 25. Rfe1 h6 26. Re8+ Rxe8 27. Rxe8+ Kh7 28. Rc8 Ra7 29. Rc7 Nge5 30. Bxe5 Rxc7 31. dxc7 Ne7 32. Bd6 Nc8 33. Bg3 Kg6 34. Kb2 Kf6 35. Kc3 Ke6 36. Kc4 d6 37. Kb5 Kd7 38. Ka6 Kxc7 39. c4 Kc6 40. b4 Ne7 41. b5+ Kc5 42. Bf2+ Kxc4 43. Kxb6 Nd5+ 44. Kc6 Nb4+ 45. Kb6 d5 46. Ka5 d4 47. b6 d3 48. Be1 Nc6+ 49. Ka6 Kd4 50. b7 Ke3 51. Kb6 Nb8 52. Kc7 Na6+ 53. Kb6 Nb8 54. Kc7 Na6+ 55. Kb6 Nb8 56. Kc7 1/2-1/2\n56... Kd4 57. Kxb8 d2 58. Kc8 d1=Q",
          "positional_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 418,
            "total_tokens": 598,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Bb4",
            "Bd2",
            "Bxc3",
            "Bxc3",
            "Nxf4",
            "Bc4",
            "Ne7",
            "O-O-O",
            "O-O",
            "Rhf1",
            "Nfg6",
            "d6",
            "Nc6",
            "Rde1",
            "cxd6",
            "exd6",
            "b5",
            "Bxb5",
            "Rxa2",
            "b3",
            "b6",
            "Kb1",
            "Ra8",
            "Bc4",
            "Ba6",
            "Bxa6",
            "Rxa6",
            "Re4",
            "Rfa8",
            "Rfe1",
            "h6",
            "Re8+",
            "Rxe8",
            "Rxe8+",
            "Kh7",
            "Rc8",
            "Ra7",
            "Rc7",
            "Nge5",
            "Bxe5",
            "Rxc7",
            "dxc7",
            "Ne7",
            "Bd6",
            "Nc8",
            "Bg3",
            "Kg6",
            "Kb2",
            "Kf6",
            "Kc3",
            "Ke6",
            "Kc4",
            "d6",
            "Kb5",
            "Kd7",
            "Ka6",
            "Kxc7",
            "c4",
            "Kc6",
            "b4",
            "Ne7",
            "b5+",
            "Kc5",
            "Bf2+",
            "Kxc4",
            "Kxb6",
            "Nd5+",
            "Kc6",
            "Nb4+",
            "Kb6",
            "d5",
            "Ka5",
            "d4",
            "b6",
            "d3",
            "Be1",
            "Nc6+",
            "Ka6",
            "Kd4",
            "b7",
            "Ke3",
            "Kb6",
            "Nb8",
            "Kc7",
            "Na6+",
            "Kb6",
            "Nb8",
            "Kc7",
            "Na6+",
            "Kb6",
            "Nb8",
            "Kc7",
            "Kd4",
            "Kxb8",
            "d2",
            "Kc8",
            "d1=Q"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "axb6",
          "neutral_uci": "a7b6",
          "neutral_response": "9... axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. Bxc3 Nxf4 13. Bc4 Ne7 14. O-O-O O-O 15. Rhf1 Nfg6 16. d6 Nc6 17. Rde1 cxd6 18. exd6 Na5 19. Bd5 Nc6 20. Rxf7 Rxf7 21. Re8+ Nf8 22. b4 b5 23. Kb2 b6 24. a3 Bb7 25. Bxf7+ Kxf7 26. Re3 Re8 27. Rf3+ Kg8 28. Rg3 g6 29. h4 Ne6 30. h5 Kf7 31. Rf3+ Kg8 32. Rg3 Nf8 33. Rf3 Ne5 34. Rf6 Nc4+ 35. Kb3 Re6 36. Rf4 Nxd6 37. g4 Bd5+ 38. Kb2 Nc4+ 39. Kc1 Re4 40. Rf6 Rxg4 41. hxg6 Rg1+ 42. Be1 Rxe1# 0-1\n9... axb6 10. Nc3 Bb4 11. Bd2 Bxc3 12. Bxc3 Nxf4 13. Bc4 Ne7 14. O-O-O O-O 15. Rhf1 Nfg6 16. d6 Nc6 17. Rde1 cxd6 18. exd6 Na5 19. Bd5 Nc6 20. Rxf7 Rxf7 21. Re8+ Nf8 22. b4 b5 23. Kb2 b6 24. a3 Bb7 25. Bxf7+ Kxf7 26. Re3 Re8 27. Rf3+ Kg8 28. Rg3 g6 29. h4 Ne6 30. h5 Kf7 31. Rf3+ Kg8 32. Rg3 Nf8 33. Rf3 Ne5 34. Rf6 Nc4+ 35. Kb3 Re6 36. Rf4 Nxd6 37. g4 Bd5+ 38. Kb2 Nc4+ 39. Kc1 Re4 40. Rf6 Rxg4 41. hxg6 Rg1+ 42. Be1 Rxe1# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 576,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Bb4",
            "Bd2",
            "Bxc3",
            "Bxc3",
            "Nxf4",
            "Bc4",
            "Ne7",
            "O-O-O",
            "O-O",
            "Rhf1",
            "Nfg6",
            "d6",
            "Nc6",
            "Rde1",
            "cxd6",
            "exd6",
            "Na5",
            "Bd5",
            "Nc6",
            "Rxf7",
            "Rxf7",
            "Re8+",
            "Nf8",
            "b4",
            "b5",
            "Kb2",
            "b6",
            "a3",
            "Bb7",
            "Bxf7+",
            "Kxf7",
            "Re3",
            "Re8",
            "Rf3+",
            "Kg8",
            "Rg3",
            "g6",
            "h4",
            "Ne6",
            "h5",
            "Kf7",
            "Rf3+",
            "Kg8",
            "Rg3",
            "Nf8",
            "Rf3",
            "Ne5",
            "Rf6",
            "Nc4+",
            "Kb3",
            "Re6",
            "Rf4",
            "Nxd6",
            "g4",
            "Bd5+",
            "Kb2",
            "Nc4+",
            "Kc1",
            "Re4",
            "Rf6",
            "Rxg4",
            "hxg6",
            "Rg1+",
            "Be1",
            "Rxe1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a7b6",
          "positional_uci": "a7b6",
          "neutral_uci": "a7b6",
          "consensus_move": "a7b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Bb4",
              "Bd2",
              "Bxc3",
              "Bxc3",
              "Nxf4",
              "Bc4",
              "Ne7",
              "O-O-O",
              "O-O",
              "Rhf1",
              "Nfg6",
              "d6",
              "cxd6",
              "exd6",
              "Nc6",
              "Rde1",
              "b5",
              "Bxb5",
              "Rxa2",
              "Kb1",
              "Ra8",
              "Bc4",
              "b6",
              "Rxf7",
              "Rxf7",
              "Re8+",
              "Nf8",
              "Bd5",
              "Bb7",
              "Bxf7+",
              "Kxf7",
              "Re3",
              "Ne6",
              "Rf3+",
              "Kg8",
              "Rg3",
              "Rf8",
              "b3",
              "Rf1+",
              "Kb2",
              "Rf2",
              "h4",
              "Ncd4",
              "Bxd4",
              "Nxd4",
              "Rc3",
              "Rxg2",
              "Rc7",
              "Bc6",
              "Kc3",
              "Nb5+",
              "Kb4",
              "Nxc7",
              "dxc7",
              "Bb7",
              "Kb5",
              "Rxc2",
              "Kxb6",
              "Bc8",
              "b4",
              "d5",
              "b5",
              "d4",
              "Ka7",
              "Rxc7+",
              "Kb8",
              "Rc1",
              "b6",
              "d3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Bb4",
              "Bd2",
              "Bxc3",
              "Bxc3",
              "Nxf4",
              "Bc4",
              "Ne7",
              "O-O-O",
              "O-O",
              "Rhf1",
              "Nfg6",
              "d6",
              "Nc6",
              "Rde1",
              "cxd6",
              "exd6",
              "b5",
              "Bxb5",
              "Rxa2",
              "b3",
              "b6",
              "Kb1",
              "Ra8",
              "Bc4",
              "Ba6",
              "Bxa6",
              "Rxa6",
              "Re4",
              "Rfa8",
              "Rfe1",
              "h6",
              "Re8+",
              "Rxe8",
              "Rxe8+",
              "Kh7",
              "Rc8",
              "Ra7",
              "Rc7",
              "Nge5",
              "Bxe5",
              "Rxc7",
              "dxc7",
              "Ne7",
              "Bd6",
              "Nc8",
              "Bg3",
              "Kg6",
              "Kb2",
              "Kf6",
              "Kc3",
              "Ke6",
              "Kc4",
              "d6",
              "Kb5",
              "Kd7",
              "Ka6",
              "Kxc7",
              "c4",
              "Kc6",
              "b4",
              "Ne7",
              "b5+",
              "Kc5",
              "Bf2+",
              "Kxc4",
              "Kxb6",
              "Nd5+",
              "Kc6",
              "Nb4+",
              "Kb6",
              "d5",
              "Ka5",
              "d4",
              "b6",
              "d3",
              "Be1",
              "Nc6+",
              "Ka6",
              "Kd4",
              "b7",
              "Ke3",
              "Kb6",
              "Nb8",
              "Kc7",
              "Na6+",
              "Kb6",
              "Nb8",
              "Kc7",
              "Na6+",
              "Kb6",
              "Nb8",
              "Kc7",
              "Kd4",
              "Kxb8",
              "d2",
              "Kc8",
              "d1=Q"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc3",
              "Bb4",
              "Bd2",
              "Bxc3",
              "Bxc3",
              "Nxf4",
              "Bc4",
              "Ne7",
              "O-O-O",
              "O-O",
              "Rhf1",
              "Nfg6",
              "d6",
              "Nc6",
              "Rde1",
              "cxd6",
              "exd6",
              "Na5",
              "Bd5",
              "Nc6",
              "Rxf7",
              "Rxf7",
              "Re8+",
              "Nf8",
              "b4",
              "b5",
              "Kb2",
              "b6",
              "a3",
              "Bb7",
              "Bxf7+",
              "Kxf7",
              "Re3",
              "Re8",
              "Rf3+",
              "Kg8",
              "Rg3",
              "g6",
              "h4",
              "Ne6",
              "h5",
              "Kf7",
              "Rf3+",
              "Kg8",
              "Rg3",
              "Nf8",
              "Rf3",
              "Ne5",
              "Rf6",
              "Nc4+",
              "Kb3",
              "Re6",
              "Rf4",
              "Nxd6",
              "g4",
              "Bd5+",
              "Kb2",
              "Nc4+",
              "Kc1",
              "Re4",
              "Rf6",
              "Rxg4",
              "hxg6",
              "Rg1+",
              "Be1",
              "Rxe1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 180,
            "completion_tokens": 418,
            "total_tokens": 598,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 179,
            "completion_tokens": 576,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 539,
          "total_completion_tokens": 1634,
          "total_tokens": 2173
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 180,
            "completion_tokens": 418,
            "total_tokens": 598,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 179,
            "completion_tokens": 576,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/pppp1ppp/1Q4n1/3PP3/5P2/8/PPP3PP/RNB1KB1R b KQkq - 0 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c6",
          "aggressive_uci": "c7c6",
          "aggressive_response": "10... c6 11. dxc6 bxc6 12. Bc4 d5 13. exd6 Bxd6 14. O-O N8e7 15. Nc3 O-O 16. Ne4 Bc7 17. Ng5 h6 18. Nxf7 Rxf7 19. Bxf7+ Kxf7 20. f5 Ne5 21. Bf4 Nd5 22. Bxe5 Bxe5 23. c3 Ne3 24. Rf3 Nc4 25. b3 Nd6 26. Re1 Bf6 27. Rd1 Nxf5 28. g4 Nh4 29. Rf4 Rxa2 30. Rd8 Be6 31. Rd6 Ke7 32. Rxc6 Be5 33. Re4 Nf3+ 34. Kf1 Nxh2+ 35. Ke1 Nf3+ 36. Kd1 Bxb3+ 37. Kc1 Rc2+ 38. Kb1 Nd2+ 39. Ka1 Ra2# 1-0\n\n1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5\nQb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 bxc6 12. Bc4 d5 13. exd6 Bxd6 14. O-O N8e7 15. Nc3 O-O 16. Ne4 Bc7 17. Ng5 h6 18. Nxf7 Rxf7 19. Bxf7+ Kxf7 20. f5 Ne5 21. Bf4 Nd5 22. Bxe5 Bxe5 23. c3 Ne3 24. Rf3 Nc4 25. b3 Nd6 26. Re1 Bf6 27. Rd1 Nxf5 28. g4 Nh4 29. Rf4 Rxa2 30. Rd8 Be6 31. Rd6 Ke7 32. Rxc6 Be5 33. Re4 Nf3+ 34. Kf1 Nxh2+ 35. Ke1 Nf3+ 36. Kd1 Bxb3+ 37. Kc1 Rc2+ 38. Kb1 Nd2+ 39. Ka1 Ra2# 1-0 10... c6 11. dxc6 bxc6 12. Bc4 d5 13. exd6 Bxd6 14. O-O N8e7 15. Nc3 O-O 16. Ne4 Bc7 17. Ng5 h6",
          "aggressive_tokens": {
            "prompt_tokens": 189,
            "completion_tokens": 640,
            "total_tokens": 829,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc6",
            "bxc6",
            "Bc4",
            "d5",
            "exd6",
            "Bxd6",
            "O-O",
            "N8e7",
            "Nc3",
            "O-O",
            "Ne4",
            "Bc7",
            "Ng5",
            "h6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c6",
          "positional_uci": "c7c6",
          "positional_response": "10... c6 11. dxc6 bxc6 12. Bc4 Ba6 13. Bxa6 Rxa6 14. O-O Bc5+ 15. Kh1 N8e7 16. Nc3 O-O 17. Ne4 Ra4 18. Nxc5 bxc5 19. b3 Re4 20. Ba3 Nxf4 21. Bxc5 Re8 22. Rad1 Ned5 23. c4 Nc3 24. Rxd7 R4xe5 25. Bd6 Re1 26. Kg1 Nfe2+ 27. Kf2 Rxf1+ 28. Kxf1 Nxa2 29. Rc7 Nd4 30. b4 Nc3 31. Bc5 Ne6 32. Rxc6 Nxc5 33. Rxc5 Ne4 34. Rc7 Nd2+ 35. Kf2 Kf8 36. b5 Re4 37. c5 Rb4 38. b6 Ne4+ 39. Ke3 Nxc5 40. Rxc5 Rxb6 41. Rc8+ Ke7 42. Rc7+ Kf6 43. Rc4 Rb3+ 44. Kf4 g5+ 45. Kg4 Kg6 46. Rc6+ f6 47. h4 h5# 48. Kh3 g4+ 49. Kh2 Rb2 50. Kg3 Rb3+ 51. Kh2 Kf5 52. Rc5+ Kg6 53. Rc6 Re3 54. Rc5 Re5 55. Rc6 Kf5 56. Rc4 Re4 57. Rc5+ Kg6 58. Rc6 Kf5 59. Rc5+ Re5 60. Rc6 Kf4 61. Rxf6+ Rf5 62. Rh6 g3+ 63. Kh3 Re5 64. Rf6+ Rf5 65. Rxf5+ Kxf5 66. Kxg3 Kg6 67. Kf4 Kf6 68. g3 Kg6 69. Ke5 Kh6 70. Kf5 Kg7 71. Kg5 Kh7 72. Kxh5 Kg7 73. Kg5 Kh7 74. Kf6 Kh6 75. g4 Kh7 76. g5 Kg8 77. h5 Kh7 78. Kf7 Kh8 79. h6 Kh7 80. g6+ Kh8 81. g7+ Kh7 82. g8=Q+ Kxh6 83. Qg6# 1-0",
          "positional_tokens": {
            "prompt_tokens": 189,
            "completion_tokens": 604,
            "total_tokens": 793,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc6",
            "bxc6",
            "Bc4",
            "Ba6",
            "Bxa6",
            "Rxa6",
            "O-O",
            "Bc5+",
            "Kh1",
            "N8e7",
            "Nc3",
            "O-O",
            "Ne4",
            "Ra4",
            "Nxc5",
            "bxc5",
            "b3",
            "Re4",
            "Ba3",
            "Nxf4",
            "Bxc5",
            "Re8",
            "Rad1",
            "Ned5",
            "c4",
            "Nc3",
            "Rxd7",
            "R4xe5",
            "Bd6",
            "Re1",
            "Kg1",
            "Nfe2+",
            "Kf2",
            "Rxf1+",
            "Kxf1",
            "Nxa2",
            "Rc7",
            "Nd4",
            "b4",
            "Nc3",
            "Bc5",
            "Ne6",
            "Rxc6",
            "Nxc5",
            "Rxc5",
            "Ne4",
            "Rc7",
            "Nd2+",
            "Kf2",
            "Kf8",
            "b5",
            "Re4",
            "c5",
            "Rb4",
            "b6",
            "Ne4+",
            "Ke3",
            "Nxc5",
            "Rxc5",
            "Rxb6",
            "Rc8+",
            "Ke7",
            "Rc7+",
            "Kf6",
            "Rc4",
            "Rb3+",
            "Kf4",
            "g5+",
            "Kg4",
            "Kg6",
            "Rc6+",
            "f6",
            "h4",
            "h5#",
            "Kh3",
            "g4+",
            "Kh2",
            "Rb2",
            "Kg3",
            "Rb3+",
            "Kh2",
            "Kf5",
            "Rc5+",
            "Kg6",
            "Rc6",
            "Re3",
            "Rc5",
            "Re5",
            "Rc6",
            "Kf5",
            "Rc4",
            "Re4",
            "Rc5+",
            "Kg6",
            "Rc6",
            "Kf5",
            "Rc5+",
            "Re5",
            "Rc6",
            "Kf4",
            "Rxf6+",
            "Rf5",
            "Rh6",
            "g3+",
            "Kh3",
            "Re5",
            "Rf6+",
            "Rf5",
            "Rxf5+",
            "Kxf5",
            "Kxg3",
            "Kg6",
            "Kf4",
            "Kf6",
            "g3",
            "Kg6",
            "Ke5",
            "Kh6",
            "Kf5",
            "Kg7",
            "Kg5",
            "Kh7",
            "Kxh5",
            "Kg7",
            "Kg5",
            "Kh7",
            "Kf6",
            "Kh6",
            "g4",
            "Kh7",
            "g5",
            "Kg8",
            "h5",
            "Kh7",
            "Kf7",
            "Kh8",
            "h6",
            "Kh7",
            "g6+",
            "Kh8",
            "g7+",
            "Kh7",
            "g8=Q+",
            "Kxh6",
            "Qg6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c6",
          "neutral_uci": "c7c6",
          "neutral_response": "10... c6 11. dxc6 bxc6 12. Bc4 d5 13. exd6 Bxd6 14. O-O N8e7 15. Nc3 O-O 16. Ne4 Bc7 17. Ng5 h6 18. Nxf7 Rxf7 19. Bxf7+ Kxf7 20. Be3 Nd5 21. Bd4 c5 22. Bf2 Bf5 23. c3 Ngxf4 24. Bg3 g5 25. Bxf4 Nxf4 26. g3 Nh3+ 27. Kg2 Kg6 28. Rxf5 Kxf5 29. Kxh3 Re8 30. Rf1+ Kg6 31. Rf2 h5 32. Kg2 g4 33. Rd2 Re7 34. b4 cxb4 35. cxb4 Re4 36. a3 Re3 37. Ra2 Rb3 38. Kf2 Be5 39. Kg2 Rb2+ 40. Rxb2 Bxb2 41. a4 Bc3 42. b5 Kf5 43. Kf2 Ke4 44. Ke2 Kd4 45. Kf2 Kc4 46. Ke3 Kb4 47. Kf4 Kxa4 48. Kg5 Kxb5 49. Kxh5 Kc4 50. Kxg4 b5 51. h4 b4 52. h5 b3 53. h6 b2 54. h7 b1=Q 55. h8=Q Bxh8 56. Kh5 Qf5+ 57. Kh4 Bf6# 58. Kg3 Be5+ 59. Kh4 Bf4 60. gxf4 Qxf4+ 61. Kh5 Qg3 62. Kh6 Kd5 63. Kh7 Ke6 64. Kh8 Kf7 65. Kh7 Qg7# 66. Kh8 Qg8# 67. Kh7 Qg7# 68. Kh8 Qg8# 69. Kh7 Qg7# 70. Kh8 Qg8# 71. Kh7 Qg7# 72. Kh8 Qg8# 73. Kh7 Qg7# 74. Kh8 Qg8# 75. Kh7 Qg7# 76. Kh8 Qg8# 77. Kh7 Qg7# 78. Kh8 Qg8# 79. Kh7 Qg7# 80. Kh8 Qg8# 81. Kh7 Qg7# 82. Kh8 Qg8# 83. Kh7 Qg7# 84. Kh8 Qg8# 85. Kh7 Qg7#",
          "neutral_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc6",
            "bxc6",
            "Bc4",
            "d5",
            "exd6",
            "Bxd6",
            "O-O",
            "N8e7",
            "Nc3",
            "O-O",
            "Ne4",
            "Bc7",
            "Ng5",
            "h6",
            "Nxf7",
            "Rxf7",
            "Bxf7+",
            "Kxf7",
            "Be3",
            "Nd5",
            "Bd4",
            "c5",
            "Bf2",
            "Bf5",
            "c3",
            "Ngxf4",
            "Bg3",
            "g5",
            "Bxf4",
            "Nxf4",
            "g3",
            "Nh3+",
            "Kg2",
            "Kg6",
            "Rxf5",
            "Kxf5",
            "Kxh3",
            "Re8",
            "Rf1+",
            "Kg6",
            "Rf2",
            "h5",
            "Kg2",
            "g4",
            "Rd2",
            "Re7",
            "b4",
            "cxb4",
            "cxb4",
            "Re4",
            "a3",
            "Re3",
            "Ra2",
            "Rb3",
            "Kf2",
            "Be5",
            "Kg2",
            "Rb2+",
            "Rxb2",
            "Bxb2",
            "a4",
            "Bc3",
            "b5",
            "Kf5",
            "Kf2",
            "Ke4",
            "Ke2",
            "Kd4",
            "Kf2",
            "Kc4",
            "Ke3",
            "Kb4",
            "Kf4",
            "Kxa4",
            "Kg5",
            "Kxb5",
            "Kxh5",
            "Kc4",
            "Kxg4",
            "b5",
            "h4",
            "b4",
            "h5",
            "b3",
            "h6",
            "b2",
            "h7",
            "b1=Q",
            "h8=Q",
            "Bxh8",
            "Kh5",
            "Qf5+",
            "Kh4",
            "Bf6#",
            "Kg3",
            "Be5+",
            "Kh4",
            "Bf4",
            "gxf4",
            "Qxf4+",
            "Kh5",
            "Qg3",
            "Kh6",
            "Kd5",
            "Kh7",
            "Ke6",
            "Kh8",
            "Kf7",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c7c6",
          "positional_uci": "c7c6",
          "neutral_uci": "c7c6",
          "consensus_move": "c7c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc6",
              "bxc6",
              "Bc4",
              "d5",
              "exd6",
              "Bxd6",
              "O-O",
              "N8e7",
              "Nc3",
              "O-O",
              "Ne4",
              "Bc7",
              "Ng5",
              "h6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc6",
              "bxc6",
              "Bc4",
              "Ba6",
              "Bxa6",
              "Rxa6",
              "O-O",
              "Bc5+",
              "Kh1",
              "N8e7",
              "Nc3",
              "O-O",
              "Ne4",
              "Ra4",
              "Nxc5",
              "bxc5",
              "b3",
              "Re4",
              "Ba3",
              "Nxf4",
              "Bxc5",
              "Re8",
              "Rad1",
              "Ned5",
              "c4",
              "Nc3",
              "Rxd7",
              "R4xe5",
              "Bd6",
              "Re1",
              "Kg1",
              "Nfe2+",
              "Kf2",
              "Rxf1+",
              "Kxf1",
              "Nxa2",
              "Rc7",
              "Nd4",
              "b4",
              "Nc3",
              "Bc5",
              "Ne6",
              "Rxc6",
              "Nxc5",
              "Rxc5",
              "Ne4",
              "Rc7",
              "Nd2+",
              "Kf2",
              "Kf8",
              "b5",
              "Re4",
              "c5",
              "Rb4",
              "b6",
              "Ne4+",
              "Ke3",
              "Nxc5",
              "Rxc5",
              "Rxb6",
              "Rc8+",
              "Ke7",
              "Rc7+",
              "Kf6",
              "Rc4",
              "Rb3+",
              "Kf4",
              "g5+",
              "Kg4",
              "Kg6",
              "Rc6+",
              "f6",
              "h4",
              "h5#",
              "Kh3",
              "g4+",
              "Kh2",
              "Rb2",
              "Kg3",
              "Rb3+",
              "Kh2",
              "Kf5",
              "Rc5+",
              "Kg6",
              "Rc6",
              "Re3",
              "Rc5",
              "Re5",
              "Rc6",
              "Kf5",
              "Rc4",
              "Re4",
              "Rc5+",
              "Kg6",
              "Rc6",
              "Kf5",
              "Rc5+",
              "Re5",
              "Rc6",
              "Kf4",
              "Rxf6+",
              "Rf5",
              "Rh6",
              "g3+",
              "Kh3",
              "Re5",
              "Rf6+",
              "Rf5",
              "Rxf5+",
              "Kxf5",
              "Kxg3",
              "Kg6",
              "Kf4",
              "Kf6",
              "g3",
              "Kg6",
              "Ke5",
              "Kh6",
              "Kf5",
              "Kg7",
              "Kg5",
              "Kh7",
              "Kxh5",
              "Kg7",
              "Kg5",
              "Kh7",
              "Kf6",
              "Kh6",
              "g4",
              "Kh7",
              "g5",
              "Kg8",
              "h5",
              "Kh7",
              "Kf7",
              "Kh8",
              "h6",
              "Kh7",
              "g6+",
              "Kh8",
              "g7+",
              "Kh7",
              "g8=Q+",
              "Kxh6",
              "Qg6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc6",
              "bxc6",
              "Bc4",
              "d5",
              "exd6",
              "Bxd6",
              "O-O",
              "N8e7",
              "Nc3",
              "O-O",
              "Ne4",
              "Bc7",
              "Ng5",
              "h6",
              "Nxf7",
              "Rxf7",
              "Bxf7+",
              "Kxf7",
              "Be3",
              "Nd5",
              "Bd4",
              "c5",
              "Bf2",
              "Bf5",
              "c3",
              "Ngxf4",
              "Bg3",
              "g5",
              "Bxf4",
              "Nxf4",
              "g3",
              "Nh3+",
              "Kg2",
              "Kg6",
              "Rxf5",
              "Kxf5",
              "Kxh3",
              "Re8",
              "Rf1+",
              "Kg6",
              "Rf2",
              "h5",
              "Kg2",
              "g4",
              "Rd2",
              "Re7",
              "b4",
              "cxb4",
              "cxb4",
              "Re4",
              "a3",
              "Re3",
              "Ra2",
              "Rb3",
              "Kf2",
              "Be5",
              "Kg2",
              "Rb2+",
              "Rxb2",
              "Bxb2",
              "a4",
              "Bc3",
              "b5",
              "Kf5",
              "Kf2",
              "Ke4",
              "Ke2",
              "Kd4",
              "Kf2",
              "Kc4",
              "Ke3",
              "Kb4",
              "Kf4",
              "Kxa4",
              "Kg5",
              "Kxb5",
              "Kxh5",
              "Kc4",
              "Kxg4",
              "b5",
              "h4",
              "b4",
              "h5",
              "b3",
              "h6",
              "b2",
              "h7",
              "b1=Q",
              "h8=Q",
              "Bxh8",
              "Kh5",
              "Qf5+",
              "Kh4",
              "Bf6#",
              "Kg3",
              "Be5+",
              "Kh4",
              "Bf4",
              "gxf4",
              "Qxf4+",
              "Kh5",
              "Qg3",
              "Kh6",
              "Kd5",
              "Kh7",
              "Ke6",
              "Kh8",
              "Kf7",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 189,
            "completion_tokens": 640,
            "total_tokens": 829,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 189,
            "completion_tokens": 604,
            "total_tokens": 793,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 566,
          "total_completion_tokens": 1884,
          "total_tokens": 2450
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 189,
            "completion_tokens": 640,
            "total_tokens": 829,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 189,
            "completion_tokens": 604,
            "total_tokens": 793,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 188,
            "completion_tokens": 640,
            "total_tokens": 828,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1ppp1ppp/1p4n1/1B1PP3/5P2/8/PPP3PP/RNB1K2R b KQkq - 1 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxc6",
          "aggressive_uci": "d7c6",
          "aggressive_response": "11... dxc6 12. Bc4 Be6 13. Bxe6 fxe6 14. O-O Bc5+ 15. Kh1 N8e7 16. Nc3 O-O 17. Ne4 Nd5 18. Nxc5 bxc5 19. g3 Nxe5 20. Re1 Nf3 21. Rxe6 Rae8 22. Rxe8 Rxe8 23. Kg2 Ne1+ 24. Kf2 Nxc2 25. Rb1 Re1 26. b3 Ndb4 27. a3 Nd3+ 28. Kf3 Rxc1 29. Rxc1 Nxc1 30. b4 cxb4 31. axb4 Nxb4 32. Ke4 Kf7 33. Kd4 Ke6 34. Kc5 Nbd3+ 35. Kb6 c5 36. Kxb7 c4 37. Kc6 c3 38. Kb5 c2 39. Kc4 Nf2 40. Kc3 Ncd3 41. Kxc2 Kf5 42. Kd2 Kg4 43. Ke3 Kh3 44. Kf3 Kxh2 45. g4 Kh3 46. g5 Kh4 47. Ke3 Kg4 48. f5 Kxf5 49. Kf3 Kxg5 50. Kg3 h5 51. Kh2 h4 52. Kg2 Kg4 53. Kh2 h3 54. Kg1 Kg3 55. Kf1 h2 56. Ke2 h1=Q 57. Ke3 Qe4+ 58. Kd2 Nf4 59. Kc3 Qd3+ 60. Kb4 Qc2 61. Kb5 Qc3 62. Kb6 Qc4 63. Kb7 Qc5 64. Kb8 Qc6 65. Ka7 Qb5 66. Ka8 Nd5 67. Ka7 Ne7 68. Ka8 Kf4 69. Ka7 Nc6+ 70. Ka8 Qb8#",
          "aggressive_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 489,
            "total_tokens": 686,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "Be6",
            "Bxe6",
            "fxe6",
            "O-O",
            "Bc5+",
            "Kh1",
            "N8e7",
            "Nc3",
            "O-O",
            "Ne4",
            "Nd5",
            "Nxc5",
            "bxc5",
            "g3",
            "Nxe5",
            "Re1",
            "Nf3",
            "Rxe6",
            "Rae8",
            "Rxe8",
            "Rxe8",
            "Kg2",
            "Ne1+",
            "Kf2",
            "Nxc2",
            "Rb1",
            "Re1",
            "b3",
            "Ndb4",
            "a3",
            "Nd3+",
            "Kf3",
            "Rxc1",
            "Rxc1",
            "Nxc1",
            "b4",
            "cxb4",
            "axb4",
            "Nxb4",
            "Ke4",
            "Kf7",
            "Kd4",
            "Ke6",
            "Kc5",
            "Nbd3+",
            "Kb6",
            "c5",
            "Kxb7",
            "c4",
            "Kc6",
            "c3",
            "Kb5",
            "c2",
            "Kc4",
            "Nf2",
            "Kc3",
            "Ncd3",
            "Kxc2",
            "Kf5",
            "Kd2",
            "Kg4",
            "Ke3",
            "Kh3",
            "Kf3",
            "Kxh2",
            "g4",
            "Kh3",
            "g5",
            "Kh4",
            "Ke3",
            "Kg4",
            "f5",
            "Kxf5",
            "Kf3",
            "Kxg5",
            "Kg3",
            "h5",
            "Kh2",
            "h4",
            "Kg2",
            "Kg4",
            "Kh2",
            "h3",
            "Kg1",
            "Kg3",
            "Kf1",
            "h2",
            "Ke2",
            "h1=Q",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Nf4",
            "Kc3",
            "Qd3+",
            "Kb4",
            "Qc2",
            "Kb5",
            "Qc3",
            "Kb6",
            "Qc4",
            "Kb7",
            "Qc5",
            "Kb8",
            "Qc6",
            "Ka7",
            "Qb5",
            "Ka8",
            "Nd5",
            "Ka7",
            "Ne7",
            "Ka8",
            "Kf4",
            "Ka7",
            "Nc6+",
            "Ka8",
            "Qb8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxc6",
          "positional_uci": "d7c6",
          "positional_response": "11... dxc6 12. Bc4 Be6 13. Bxe6 fxe6 14. O-O Bc5+ 15. Kh1 N8e7 16. Nc3 O-O 17. Ne4\nRa4 18. Nxc5 bxc5 19. g3 Nxe5 20. b3 Ra6 21. Bb2 Ng4 22. Rae1 Rxa2 23. Rxe6 Rxb2\n24. Rxe7 Rxc2 25. Rxb7 Rxh2+ 26. Kg1 Rb2 27. Re1 Rd8 28. Rc7 Rxb3 29. Rxc6 Rxg3+\n30. Kf1 Rf3+ 31. Kg2 Rxf4 32. Rxc5 Rd3 33. Rc8+ Kf7 34. Rc7+ Kg6 35. Rc6+ Kh5 36.\nRh1+ Kg5 37. Rc5+ Rf5 38. Rxf5+ Kxf5 39. Rxh7 g5 40. Rf7+ Kg6 41. Rf8 Ne3+ 42. Kf2\nNf5 43. Rg8+ Kh5 44. Rh8+ Kg4 45. Rg8 Rd2+ 46. Ke1 Ra2 47. Kf1 Kf4 48. Rf8 g4\n49. Kg1 g3 50. Rf7 Kg4 51. Rf8 Nh4 52. Rg8+ Kh3 53. Kf1 g2+ 54. Kg1 Nf3# 0-1\n55. Kf2 g1=Q+ 56. Kxf3 Qxg8",
          "positional_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 396,
            "total_tokens": 593,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "Be6",
            "Bxe6",
            "fxe6",
            "O-O",
            "Bc5+",
            "Kh1",
            "N8e7",
            "Nc3",
            "O-O",
            "Ne4",
            "Ra4",
            "Nxc5",
            "bxc5",
            "g3",
            "Nxe5",
            "b3",
            "Ra6",
            "Bb2",
            "Ng4",
            "Rae1",
            "Rxa2",
            "Rxe6",
            "Rxb2",
            "Rxe7",
            "Rxc2",
            "Rxb7",
            "Rxh2+",
            "Kg1",
            "Rb2",
            "Re1",
            "Rd8",
            "Rc7",
            "Rxb3",
            "Rxc6",
            "Rxg3+",
            "Kf1",
            "Rf3+",
            "Kg2",
            "Rxf4",
            "Rxc5",
            "Rd3",
            "Rc8+",
            "Kf7",
            "Rc7+",
            "Kg6",
            "Rc6+",
            "Kh5",
            "Rh1+",
            "Kg5",
            "Rc5+",
            "Rf5",
            "Rxf5+",
            "Kxf5",
            "Rxh7",
            "g5",
            "Rf7+",
            "Kg6",
            "Rf8",
            "Ne3+",
            "Kf2",
            "Nf5",
            "Rg8+",
            "Kh5",
            "Rh8+",
            "Kg4",
            "Rg8",
            "Rd2+",
            "Ke1",
            "Ra2",
            "Kf1",
            "Kf4",
            "Rf8",
            "g4",
            "Kg1",
            "g3",
            "Rf7",
            "Kg4",
            "Rf8",
            "Nh4",
            "Rg8+",
            "Kh3",
            "Kf1",
            "g2+",
            "Kg1",
            "Nf3#",
            "Kf2",
            "g1=Q+",
            "Kxf3",
            "Qxg8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 12. cxd7+ Bxd7 13. Bxd7+ Kxd7 14. O-O\nBc5+ 15. Kh1 N8e7 16. Nc3 Nf5 17. Ne4 Kc6 18. Nxc5 bxc5 19. c3 Rd8 20. b4 cxb4\n21. cxb4 Rd4 22. a3 Rhd8 23. Bb2 Rd2 24. Rac1+ Kb5 25. Bc3 Ra2 26. Ra1 Rxa1 27.\nRxa1 Nxf4 28. a4+ Kc4 29. Be1 Ne3 30. Rc1+ Kb3 31. Rc3+ Kxa4 32. Rxe3 Rd1 33. Kg1\nNd3 34. Kf1 Nxe1 35. Rxe1 Rxe1+ 36. Kxe1 Kxb4 37. Kd2 Kc4 38. Ke3 b5 39. Kd2 b4\n40. Kc2 b3+ 41. Kb2 Kb4 42. g3 h5 43. h3 g5 44. g4 h4 45. Kb1 Kc3 46. Kc1 b2+\n47. Kb1 Kb3 48. e6 fxe6 49. 1-0 1-0 1-0",
          "neutral_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 323,
            "total_tokens": 519,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "cxd7+",
            "Bxd7",
            "Bxd7+",
            "Kxd7",
            "O-O",
            "Bc5+",
            "Kh1",
            "N8e7",
            "Nc3",
            "Nf5",
            "Ne4",
            "Kc6",
            "Nxc5",
            "bxc5",
            "c3",
            "Rd8",
            "b4",
            "cxb4",
            "cxb4",
            "Rd4",
            "a3",
            "Rhd8",
            "Bb2",
            "Rd2",
            "Rac1+",
            "Kb5",
            "Bc3",
            "Ra2",
            "Ra1",
            "Rxa1",
            "Rxa1",
            "Nxf4",
            "a4+",
            "Kc4",
            "Be1",
            "Ne3",
            "Rc1+",
            "Kb3",
            "Rc3+",
            "Kxa4",
            "Rxe3",
            "Rd1",
            "Kg1",
            "Nd3",
            "Kf1",
            "Nxe1",
            "Rxe1",
            "Rxe1+",
            "Kxe1",
            "Kxb4",
            "Kd2",
            "Kc4",
            "Ke3",
            "b5",
            "Kd2",
            "b4",
            "Kc2",
            "b3+",
            "Kb2",
            "Kb4",
            "g3",
            "h5",
            "h3",
            "g5",
            "g4",
            "h4",
            "Kb1",
            "Kc3",
            "Kc1",
            "b2+",
            "Kb1",
            "Kb3",
            "e6",
            "fxe6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7c6",
          "positional_uci": "d7c6",
          "neutral_uci": null,
          "consensus_move": "d7c6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc4",
              "Be6",
              "Bxe6",
              "fxe6",
              "O-O",
              "Bc5+",
              "Kh1",
              "N8e7",
              "Nc3",
              "O-O",
              "Ne4",
              "Nd5",
              "Nxc5",
              "bxc5",
              "g3",
              "Nxe5",
              "Re1",
              "Nf3",
              "Rxe6",
              "Rae8",
              "Rxe8",
              "Rxe8",
              "Kg2",
              "Ne1+",
              "Kf2",
              "Nxc2",
              "Rb1",
              "Re1",
              "b3",
              "Ndb4",
              "a3",
              "Nd3+",
              "Kf3",
              "Rxc1",
              "Rxc1",
              "Nxc1",
              "b4",
              "cxb4",
              "axb4",
              "Nxb4",
              "Ke4",
              "Kf7",
              "Kd4",
              "Ke6",
              "Kc5",
              "Nbd3+",
              "Kb6",
              "c5",
              "Kxb7",
              "c4",
              "Kc6",
              "c3",
              "Kb5",
              "c2",
              "Kc4",
              "Nf2",
              "Kc3",
              "Ncd3",
              "Kxc2",
              "Kf5",
              "Kd2",
              "Kg4",
              "Ke3",
              "Kh3",
              "Kf3",
              "Kxh2",
              "g4",
              "Kh3",
              "g5",
              "Kh4",
              "Ke3",
              "Kg4",
              "f5",
              "Kxf5",
              "Kf3",
              "Kxg5",
              "Kg3",
              "h5",
              "Kh2",
              "h4",
              "Kg2",
              "Kg4",
              "Kh2",
              "h3",
              "Kg1",
              "Kg3",
              "Kf1",
              "h2",
              "Ke2",
              "h1=Q",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Nf4",
              "Kc3",
              "Qd3+",
              "Kb4",
              "Qc2",
              "Kb5",
              "Qc3",
              "Kb6",
              "Qc4",
              "Kb7",
              "Qc5",
              "Kb8",
              "Qc6",
              "Ka7",
              "Qb5",
              "Ka8",
              "Nd5",
              "Ka7",
              "Ne7",
              "Ka8",
              "Kf4",
              "Ka7",
              "Nc6+",
              "Ka8",
              "Qb8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bc4",
              "Be6",
              "Bxe6",
              "fxe6",
              "O-O",
              "Bc5+",
              "Kh1",
              "N8e7",
              "Nc3",
              "O-O",
              "Ne4",
              "Ra4",
              "Nxc5",
              "bxc5",
              "g3",
              "Nxe5",
              "b3",
              "Ra6",
              "Bb2",
              "Ng4",
              "Rae1",
              "Rxa2",
              "Rxe6",
              "Rxb2",
              "Rxe7",
              "Rxc2",
              "Rxb7",
              "Rxh2+",
              "Kg1",
              "Rb2",
              "Re1",
              "Rd8",
              "Rc7",
              "Rxb3",
              "Rxc6",
              "Rxg3+",
              "Kf1",
              "Rf3+",
              "Kg2",
              "Rxf4",
              "Rxc5",
              "Rd3",
              "Rc8+",
              "Kf7",
              "Rc7+",
              "Kg6",
              "Rc6+",
              "Kh5",
              "Rh1+",
              "Kg5",
              "Rc5+",
              "Rf5",
              "Rxf5+",
              "Kxf5",
              "Rxh7",
              "g5",
              "Rf7+",
              "Kg6",
              "Rf8",
              "Ne3+",
              "Kf2",
              "Nf5",
              "Rg8+",
              "Kh5",
              "Rh8+",
              "Kg4",
              "Rg8",
              "Rd2+",
              "Ke1",
              "Ra2",
              "Kf1",
              "Kf4",
              "Rf8",
              "g4",
              "Kg1",
              "g3",
              "Rf7",
              "Kg4",
              "Rf8",
              "Nh4",
              "Rg8+",
              "Kh3",
              "Kf1",
              "g2+",
              "Kg1",
              "Nf3#",
              "Kf2",
              "g1=Q+",
              "Kxf3",
              "Qxg8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "cxd7+",
              "Bxd7",
              "Bxd7+",
              "Kxd7",
              "O-O",
              "Bc5+",
              "Kh1",
              "N8e7",
              "Nc3",
              "Nf5",
              "Ne4",
              "Kc6",
              "Nxc5",
              "bxc5",
              "c3",
              "Rd8",
              "b4",
              "cxb4",
              "cxb4",
              "Rd4",
              "a3",
              "Rhd8",
              "Bb2",
              "Rd2",
              "Rac1+",
              "Kb5",
              "Bc3",
              "Ra2",
              "Ra1",
              "Rxa1",
              "Rxa1",
              "Nxf4",
              "a4+",
              "Kc4",
              "Be1",
              "Ne3",
              "Rc1+",
              "Kb3",
              "Rc3+",
              "Kxa4",
              "Rxe3",
              "Rd1",
              "Kg1",
              "Nd3",
              "Kf1",
              "Nxe1",
              "Rxe1",
              "Rxe1+",
              "Kxe1",
              "Kxb4",
              "Kd2",
              "Kc4",
              "Ke3",
              "b5",
              "Kd2",
              "b4",
              "Kc2",
              "b3+",
              "Kb2",
              "Kb4",
              "g3",
              "h5",
              "h3",
              "g5",
              "g4",
              "h4",
              "Kb1",
              "Kc3",
              "Kc1",
              "b2+",
              "Kb1",
              "Kb3",
              "e6",
              "fxe6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 197,
            "completion_tokens": 489,
            "total_tokens": 686,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 197,
            "completion_tokens": 396,
            "total_tokens": 593,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 196,
            "completion_tokens": 323,
            "total_tokens": 519,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 590,
          "total_completion_tokens": 1208,
          "total_tokens": 1798
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 197,
            "completion_tokens": 489,
            "total_tokens": 686,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 197,
            "completion_tokens": 396,
            "total_tokens": 593,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 196,
            "completion_tokens": 323,
            "total_tokens": 519,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1p1p1ppp/1pP3n1/1B2P3/5P2/8/PPP3PP/RNB1K2R b KQkq - 0 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "bxc6",
          "aggressive_uci": "b7c6",
          "aggressive_response": "12... bxc6 13. O-O Bc5+ 14. Kh1 Ba6 15. Rd1 Rd8 16. Rxd8+ Kxd8 17. Nc3 N8e7 18. Ne4 Nd5 19. Nxc5 bxc5 20. g3 Kc7 21. b3 Rd8 22. c4 Nb4 23. Ba3 Nc2 24. Bxc5 Nxa1 25. Bd6+ Rxd6 26. exd6+ Kxd6 27. Kg2 Nc2 28. Kf3 Nb4 29. a3 Nc2 30. a4 Nd4+ 31. Ke4 Nxb3 32. Kd3 Nc5+ 33. Kd4 Nxa4 34. c5+ Nxc5 35. f5 Ne5 36. h3 Nf3+ 37. Ke3 Ng5 38. h4 Nge4 39. g4 Ke5 40. Kf3 Nd3 41. Ke3 c5 42. Kf3 c4 43. Ke3 c3 44. Ke2 c2 45. Ke3 c1=Q+ 46. Kf3 Qf4+ 47. Ke2 Qf2+ 48. Kd1 Qd2# 0-1\ncxd6 Nxd6 Bb7",
          "aggressive_tokens": {
            "prompt_tokens": 207,
            "completion_tokens": 319,
            "total_tokens": 526,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bc5+",
            "Kh1",
            "Ba6",
            "Rd1",
            "Rd8",
            "Rxd8+",
            "Kxd8",
            "Nc3",
            "N8e7",
            "Ne4",
            "Nd5",
            "Nxc5",
            "bxc5",
            "g3",
            "Kc7",
            "b3",
            "Rd8",
            "c4",
            "Nb4",
            "Ba3",
            "Nc2",
            "Bxc5",
            "Nxa1",
            "Bd6+",
            "Rxd6",
            "exd6+",
            "Kxd6",
            "Kg2",
            "Nc2",
            "Kf3",
            "Nb4",
            "a3",
            "Nc2",
            "a4",
            "Nd4+",
            "Ke4",
            "Nxb3",
            "Kd3",
            "Nc5+",
            "Kd4",
            "Nxa4",
            "c5+",
            "Nxc5",
            "f5",
            "Ne5",
            "h3",
            "Nf3+",
            "Ke3",
            "Ng5",
            "h4",
            "Nge4",
            "g4",
            "Ke5",
            "Kf3",
            "Nd3",
            "Ke3",
            "c5",
            "Kf3",
            "c4",
            "Ke3",
            "c3",
            "Ke2",
            "c2",
            "Ke3",
            "c1=Q+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qf2+",
            "Kd1",
            "Qd2#",
            "cxd6",
            "Nxd6",
            "Bb7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "bxc6",
          "positional_uci": "b7c6",
          "positional_response": "12... bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. Nc3 O-O 16. Ne4 Bf5 17. Nxc5 bxc5 18. c3 Nd5 19. Bd2 Rfb8 20. b3 Ra3 21. c4 Nb4 22. Bxb4 cxb4 23. Rfd1 Rba8 24. Rd2 Rxb3 25. Rad1 Rba3 26. Rd8+ Rxd8 27. Rxd8+ Nf8 28. h3 Rxa2 29. g4 Be4+ 30. Kg1 b3 31. f5 b2 32. e6 b1=Q+ 33. Rd1 Qxd1#",
          "positional_tokens": {
            "prompt_tokens": 207,
            "completion_tokens": 180,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bc5+",
            "Kh1",
            "N8e7",
            "Nc3",
            "O-O",
            "Ne4",
            "Bf5",
            "Nxc5",
            "bxc5",
            "c3",
            "Nd5",
            "Bd2",
            "Rfb8",
            "b3",
            "Ra3",
            "c4",
            "Nb4",
            "Bxb4",
            "cxb4",
            "Rfd1",
            "Rba8",
            "Rd2",
            "Rxb3",
            "Rad1",
            "Rba3",
            "Rd8+",
            "Rxd8",
            "Rxd8+",
            "Nf8",
            "h3",
            "Rxa2",
            "g4",
            "Be4+",
            "Kg1",
            "b3",
            "f5",
            "b2",
            "e6",
            "b1=Q+",
            "Rd1",
            "Qxd1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "bxc6",
          "neutral_uci": "b7c6",
          "neutral_response": "12... bxc6 13. O-O Bc5+ 14. Kh1 Ba6 15. Re1 Bf2 16. Rd1 Be2 17. Rd2 Nxf4 18. g3 Bf3# Bf3#",
          "neutral_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 58,
            "total_tokens": 264,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bc5+",
            "Kh1",
            "Ba6",
            "Re1",
            "Bf2",
            "Rd1",
            "Be2",
            "Rd2",
            "Nxf4",
            "g3",
            "Bf3#",
            "Bf3#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b7c6",
          "positional_uci": "b7c6",
          "neutral_uci": "b7c6",
          "consensus_move": "b7c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Bc5+",
              "Kh1",
              "Ba6",
              "Rd1",
              "Rd8",
              "Rxd8+",
              "Kxd8",
              "Nc3",
              "N8e7",
              "Ne4",
              "Nd5",
              "Nxc5",
              "bxc5",
              "g3",
              "Kc7",
              "b3",
              "Rd8",
              "c4",
              "Nb4",
              "Ba3",
              "Nc2",
              "Bxc5",
              "Nxa1",
              "Bd6+",
              "Rxd6",
              "exd6+",
              "Kxd6",
              "Kg2",
              "Nc2",
              "Kf3",
              "Nb4",
              "a3",
              "Nc2",
              "a4",
              "Nd4+",
              "Ke4",
              "Nxb3",
              "Kd3",
              "Nc5+",
              "Kd4",
              "Nxa4",
              "c5+",
              "Nxc5",
              "f5",
              "Ne5",
              "h3",
              "Nf3+",
              "Ke3",
              "Ng5",
              "h4",
              "Nge4",
              "g4",
              "Ke5",
              "Kf3",
              "Nd3",
              "Ke3",
              "c5",
              "Kf3",
              "c4",
              "Ke3",
              "c3",
              "Ke2",
              "c2",
              "Ke3",
              "c1=Q+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qf2+",
              "Kd1",
              "Qd2#",
              "cxd6",
              "Nxd6",
              "Bb7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Bc5+",
              "Kh1",
              "N8e7",
              "Nc3",
              "O-O",
              "Ne4",
              "Bf5",
              "Nxc5",
              "bxc5",
              "c3",
              "Nd5",
              "Bd2",
              "Rfb8",
              "b3",
              "Ra3",
              "c4",
              "Nb4",
              "Bxb4",
              "cxb4",
              "Rfd1",
              "Rba8",
              "Rd2",
              "Rxb3",
              "Rad1",
              "Rba3",
              "Rd8+",
              "Rxd8",
              "Rxd8+",
              "Nf8",
              "h3",
              "Rxa2",
              "g4",
              "Be4+",
              "Kg1",
              "b3",
              "f5",
              "b2",
              "e6",
              "b1=Q+",
              "Rd1",
              "Qxd1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Bc5+",
              "Kh1",
              "Ba6",
              "Re1",
              "Bf2",
              "Rd1",
              "Be2",
              "Rd2",
              "Nxf4",
              "g3",
              "Bf3#",
              "Bf3#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 207,
            "completion_tokens": 319,
            "total_tokens": 526,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 207,
            "completion_tokens": 180,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 206,
            "completion_tokens": 58,
            "total_tokens": 264,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 620,
          "total_completion_tokens": 557,
          "total_tokens": 1177
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 207,
            "completion_tokens": 319,
            "total_tokens": 526,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 207,
            "completion_tokens": 180,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 206,
            "completion_tokens": 58,
            "total_tokens": 264,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1p3ppp/1pB3n1/4P3/5P2/8/PPP3PP/RNB1K2R b KQkq - 0 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc5+",
          "aggressive_uci": "f8c5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. Nc3 O-O 16. Ne4 Bf5 17. Nxc5 bxc5 18. c3 Rfd8 19. Be3 c4 20. Bc5 Rd2 21. Ba3 Be4 22. Rg1 Nxf4 23. Bxe7 Nxg2 24. h4 Nxh4+ 25. Rg2 Rxg2 26. Re1 Re2+ 27. Kg1 Nf3+ 28. Kf1 Rxe1+ 29. Kf2 Rxa2 30. Ba3 Rxa3 31. bxa3 Ra1 32. Ke3 Bd5 33. Kf4 Rxa3 34. Kf5 Rxc3 35. e6 fxe6+ 36. Kf4 g5+ 37. Kg4 Ne5+ 38. Kxg5 Rf3 39. Kh4 c3 40. Kg5 c2 41. Kh4 c1=Q 42. Kh5 Rh3# 0-1\n1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. Nc3 O-O 16. Ne4 Bf5 17. Nxc5 bxc5 18. c3 Rfd8 19. Be3 c4 20. Bc5 Rd2 21. Ba3 Be4 22. Rg1 Nxf4 23. Bxe7 Nxg2 24. h4 Nxh4+ 25. Rg2 Rxg2 26. Re1 Re2+ 27. Kg1 Nf3+ 28. Kf1 Rxe1+ 29. Kf2 Rxa2 30. Ba3 Rxa3 31. bxa3 Ra1 32. Ke3 Bd5 33. Kf4 Rxa3 34. Kf5",
          "aggressive_tokens": {
            "prompt_tokens": 215,
            "completion_tokens": 640,
            "total_tokens": 855,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rd2",
            "Ba3",
            "Be4",
            "Rg1",
            "Nxf4",
            "Bxe7",
            "Nxg2",
            "h4",
            "Nxh4+",
            "Rg2",
            "Rxg2",
            "Re1",
            "Re2+",
            "Kg1",
            "Nf3+",
            "Kf1",
            "Rxe1+",
            "Kf2",
            "Rxa2",
            "Ba3",
            "Rxa3",
            "bxa3",
            "Ra1",
            "Ke3",
            "Bd5",
            "Kf4",
            "Rxa3",
            "Kf5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bc5+",
          "positional_uci": "f8c5",
          "positional_response": "13... Bc5+ 14. Kh1 Ba6 15. Re1 Bf2 16. Re4 O-O-O 17. Nc3 N8e7 18. Be3 Bxe3 19. Rxe3 Nxf4 20. Rf3 Neg6 21. g3 Bb7 22. gxf4 c5 23. Kg2 Nh4+ 24. Kg3 Nxf3 25. Nb5 Rd2 26. Nd6+ Kc7 27. Nxf7 Rf8 28. Nd6 Bc6 29. Rf1 Nxh2 30. Rf2 Rxf2 31. Kxf2 Rxf4+ 32. Kg3 Rf3+ 33. Kxh2 Rf2+ 34. Kg3 Rxc2 35. Nf5 Rxb2 36. Nxg7 Rxa2 37. e6 c4 38. e7 c3 39. Ne6+ Kd6 40. Nd4 Be8 41. Nf5+ Ke5 42. Ng7 c2 43. Nxe8 c1=Q 44. Ng7 Qf4+ 45. Kh3 Rh2# 0-1",
          "positional_tokens": {
            "prompt_tokens": 215,
            "completion_tokens": 281,
            "total_tokens": 496,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kh1",
            "Ba6",
            "Re1",
            "Bf2",
            "Re4",
            "O-O-O",
            "Nc3",
            "N8e7",
            "Be3",
            "Bxe3",
            "Rxe3",
            "Nxf4",
            "Rf3",
            "Neg6",
            "g3",
            "Bb7",
            "gxf4",
            "c5",
            "Kg2",
            "Nh4+",
            "Kg3",
            "Nxf3",
            "Nb5",
            "Rd2",
            "Nd6+",
            "Kc7",
            "Nxf7",
            "Rf8",
            "Nd6",
            "Bc6",
            "Rf1",
            "Nxh2",
            "Rf2",
            "Rxf2",
            "Kxf2",
            "Rxf4+",
            "Kg3",
            "Rf3+",
            "Kxh2",
            "Rf2+",
            "Kg3",
            "Rxc2",
            "Nf5",
            "Rxb2",
            "Nxg7",
            "Rxa2",
            "e6",
            "c4",
            "e7",
            "c3",
            "Ne6+",
            "Kd6",
            "Nd4",
            "Be8",
            "Nf5+",
            "Ke5",
            "Ng7",
            "c2",
            "Nxe8",
            "c1=Q",
            "Ng7",
            "Qf4+",
            "Kh3",
            "Rh2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bc5+",
          "neutral_uci": "f8c5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. Nc3 O-O 16. Ne4 Bf5 17. Nxc5 bxc5 18. c3 Rfd8 19. Be3 c4 20. Bc5 Rd2 21. Ba3 Be4 22. Rg1 Nxf4 23. Bxe7 Nxg2 24. h3 Nh4+ 25. Rg2 Rxg2 26. Re1 Re2+ 27. Kg1 Nf3+ 28. Kf1 Rxe1+ 29. Kf2 Rxa2 30. Ba3 Rxa3 31. bxa3 Ra1 32. Ke3 Bd5 33. Kf4 Rxa3 34. Kf5 Rxc3 35. e6 fxe6+ 36. Kf4 e5+ 37. Kf5 e4 38. Kf4 e3 39. Kg3 e2 40. Kf2 e1=Q+ 41. Kg2 Qg1# 0-1\n1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. Nc3 O-O 16. Ne4 Bf5 17. Nxc5 bxc5 18. c3 Rfd8 19. Be3 c4 20. Bc5 Rd2 21. Ba3 Be4 22. Rg1 Nxf4 23. Bxe7 Nxg2 24. h3 Nh4+ 25. Rg2 Rxg2 26. Re1 Re2+ 27. Kg1 Nf3+ 28. Kf1 Rxe1+ 29. Kf2 Rxa2 30. Ba3 Rxa3 31. bxa3 Ra1 32. Ke3 Bd5 33. Kf4 Rxa3 34. Kf5 Rxc3 35. e6",
          "neutral_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rd2",
            "Ba3",
            "Be4",
            "Rg1",
            "Nxf4",
            "Bxe7",
            "Nxg2",
            "h3",
            "Nh4+",
            "Rg2",
            "Rxg2",
            "Re1",
            "Re2+",
            "Kg1",
            "Nf3+",
            "Kf1",
            "Rxe1+",
            "Kf2",
            "Rxa2",
            "Ba3",
            "Rxa3",
            "bxa3",
            "Ra1",
            "Ke3",
            "Bd5",
            "Kf4",
            "Rxa3",
            "Kf5",
            "Rxc3",
            "e6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8c5",
          "positional_uci": "f8c5",
          "neutral_uci": "f8c5",
          "consensus_move": "f8c5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rd2",
              "Ba3",
              "Be4",
              "Rg1",
              "Nxf4",
              "Bxe7",
              "Nxg2",
              "h4",
              "Nxh4+",
              "Rg2",
              "Rxg2",
              "Re1",
              "Re2+",
              "Kg1",
              "Nf3+",
              "Kf1",
              "Rxe1+",
              "Kf2",
              "Rxa2",
              "Ba3",
              "Rxa3",
              "bxa3",
              "Ra1",
              "Ke3",
              "Bd5",
              "Kf4",
              "Rxa3",
              "Kf5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kh1",
              "Ba6",
              "Re1",
              "Bf2",
              "Re4",
              "O-O-O",
              "Nc3",
              "N8e7",
              "Be3",
              "Bxe3",
              "Rxe3",
              "Nxf4",
              "Rf3",
              "Neg6",
              "g3",
              "Bb7",
              "gxf4",
              "c5",
              "Kg2",
              "Nh4+",
              "Kg3",
              "Nxf3",
              "Nb5",
              "Rd2",
              "Nd6+",
              "Kc7",
              "Nxf7",
              "Rf8",
              "Nd6",
              "Bc6",
              "Rf1",
              "Nxh2",
              "Rf2",
              "Rxf2",
              "Kxf2",
              "Rxf4+",
              "Kg3",
              "Rf3+",
              "Kxh2",
              "Rf2+",
              "Kg3",
              "Rxc2",
              "Nf5",
              "Rxb2",
              "Nxg7",
              "Rxa2",
              "e6",
              "c4",
              "e7",
              "c3",
              "Ne6+",
              "Kd6",
              "Nd4",
              "Be8",
              "Nf5+",
              "Ke5",
              "Ng7",
              "c2",
              "Nxe8",
              "c1=Q",
              "Ng7",
              "Qf4+",
              "Kh3",
              "Rh2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rd2",
              "Ba3",
              "Be4",
              "Rg1",
              "Nxf4",
              "Bxe7",
              "Nxg2",
              "h3",
              "Nh4+",
              "Rg2",
              "Rxg2",
              "Re1",
              "Re2+",
              "Kg1",
              "Nf3+",
              "Kf1",
              "Rxe1+",
              "Kf2",
              "Rxa2",
              "Ba3",
              "Rxa3",
              "bxa3",
              "Ra1",
              "Ke3",
              "Bd5",
              "Kf4",
              "Rxa3",
              "Kf5",
              "Rxc3",
              "e6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 215,
            "completion_tokens": 640,
            "total_tokens": 855,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 215,
            "completion_tokens": 281,
            "total_tokens": 496,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 644,
          "total_completion_tokens": 1561,
          "total_tokens": 2205
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 215,
            "completion_tokens": 640,
            "total_tokens": 855,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 215,
            "completion_tokens": 281,
            "total_tokens": 496,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b1kbnr/5ppp/1pp3n1/4P3/5P2/8/PPP3PP/RNB2RK1 b kq - 1 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "N8e7",
          "aggressive_uci": "g8e7",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5\nQb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. Nc3 O-O 16. Ne4 Bf5 17. Nxc5 bxc5 18. c3 Rfd8 19. Be3 c4 20. Bc5 Rd2 21. Ba3 Nd5 22. g3 Be4+ 23. Kg1 Rg2+ 24. Kh1 Rxg3+ 25. Rf3 Bxf3#",
          "aggressive_tokens": {
            "prompt_tokens": 224,
            "completion_tokens": 210,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "O-O",
            "Ne4",
            "Bf5",
            "Nxc5",
            "bxc5",
            "c3",
            "Rfd8",
            "Be3",
            "c4",
            "Bc5",
            "Rd2",
            "Ba3",
            "Nd5",
            "g3",
            "Be4+",
            "Kg1",
            "Rg2+",
            "Kh1",
            "Rxg3+",
            "Rf3",
            "Bxf3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "N8e7",
          "positional_uci": "g8e7",
          "positional_response": "14... N8e7 15. Nc3 O-O 16. Ne4 Bf5 17. Nxc5 bxc5 18. c3 Rfd8 19. Be3 c4 20. Bc5 Rd2 21. Ba3 Be4 22. Rg1 Nxf4 23. Bxe7 Nxg2 24. h4 Nxh4+ 25. Rg2 Rxg2 26. Bxh4 Rg4+ 27. Kh2 Rxh4+ 28. Kg3 g5 29. a3 Rd8 30. Re1 Rd3+ 31. Kf2 Rh2+ 32. Kg1 Rg2+ 33. Kf1 Rf3+ 34. Kxg2 Re3+ 35. Kf2 Rxe1 36. Kxe1 h5 37. Kf2 h4 38. Kg1 g4 39. Kh2 Kg7 40. a4 Kg6 41. a5 Kg5 42. a6 c5 43. a7 Kf4 44. Kg1 g3 45. Kf1 h3 46. Kg1 h2+ 47. Kf1 h1=Q+ 48. Ke2 Qf3+ 49. Kd2 Qd3+ 50. Ke1 Bf3 51. a8=Q Qe2#",
          "positional_tokens": {
            "prompt_tokens": 224,
            "completion_tokens": 318,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "O-O",
            "Ne4",
            "Bf5",
            "Nxc5",
            "bxc5",
            "c3",
            "Rfd8",
            "Be3",
            "c4",
            "Bc5",
            "Rd2",
            "Ba3",
            "Be4",
            "Rg1",
            "Nxf4",
            "Bxe7",
            "Nxg2",
            "h4",
            "Nxh4+",
            "Rg2",
            "Rxg2",
            "Bxh4",
            "Rg4+",
            "Kh2",
            "Rxh4+",
            "Kg3",
            "g5",
            "a3",
            "Rd8",
            "Re1",
            "Rd3+",
            "Kf2",
            "Rh2+",
            "Kg1",
            "Rg2+",
            "Kf1",
            "Rf3+",
            "Kxg2",
            "Re3+",
            "Kf2",
            "Rxe1",
            "Kxe1",
            "h5",
            "Kf2",
            "h4",
            "Kg1",
            "g4",
            "Kh2",
            "Kg7",
            "a4",
            "Kg6",
            "a5",
            "Kg5",
            "a6",
            "c5",
            "a7",
            "Kf4",
            "Kg1",
            "g3",
            "Kf1",
            "h3",
            "Kg1",
            "h2+",
            "Kf1",
            "h1=Q+",
            "Ke2",
            "Qf3+",
            "Kd2",
            "Qd3+",
            "Ke1",
            "Bf3",
            "a8=Q",
            "Qe2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "N8e7",
          "neutral_uci": "g8e7",
          "neutral_response": "14... N8e7 15. Nc3 O-O 16. Ne4 Bf5 17. Nxc5 bxc5 18. c3 Rfd8 19. Be3 c4 20. Bc5 Rd2 21. Ba3 Be4 22. Rg1 Nxf4 23. Rae1 Bxg2+ 24. Rxg2 Nxg2 25. Re4 Nd5 26. Rxc4 Nde3 27. Rxc6 Rd1# Rxd1#",
          "neutral_tokens": {
            "prompt_tokens": 223,
            "completion_tokens": 119,
            "total_tokens": 342,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "O-O",
            "Ne4",
            "Bf5",
            "Nxc5",
            "bxc5",
            "c3",
            "Rfd8",
            "Be3",
            "c4",
            "Bc5",
            "Rd2",
            "Ba3",
            "Be4",
            "Rg1",
            "Nxf4",
            "Rae1",
            "Bxg2+",
            "Rxg2",
            "Nxg2",
            "Re4",
            "Nd5",
            "Rxc4",
            "Nde3",
            "Rxc6",
            "Rd1#",
            "Rxd1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8e7",
          "positional_uci": "g8e7",
          "neutral_uci": "g8e7",
          "consensus_move": "g8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "O-O",
              "Ne4",
              "Bf5",
              "Nxc5",
              "bxc5",
              "c3",
              "Rfd8",
              "Be3",
              "c4",
              "Bc5",
              "Rd2",
              "Ba3",
              "Nd5",
              "g3",
              "Be4+",
              "Kg1",
              "Rg2+",
              "Kh1",
              "Rxg3+",
              "Rf3",
              "Bxf3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "O-O",
              "Ne4",
              "Bf5",
              "Nxc5",
              "bxc5",
              "c3",
              "Rfd8",
              "Be3",
              "c4",
              "Bc5",
              "Rd2",
              "Ba3",
              "Be4",
              "Rg1",
              "Nxf4",
              "Bxe7",
              "Nxg2",
              "h4",
              "Nxh4+",
              "Rg2",
              "Rxg2",
              "Bxh4",
              "Rg4+",
              "Kh2",
              "Rxh4+",
              "Kg3",
              "g5",
              "a3",
              "Rd8",
              "Re1",
              "Rd3+",
              "Kf2",
              "Rh2+",
              "Kg1",
              "Rg2+",
              "Kf1",
              "Rf3+",
              "Kxg2",
              "Re3+",
              "Kf2",
              "Rxe1",
              "Kxe1",
              "h5",
              "Kf2",
              "h4",
              "Kg1",
              "g4",
              "Kh2",
              "Kg7",
              "a4",
              "Kg6",
              "a5",
              "Kg5",
              "a6",
              "c5",
              "a7",
              "Kf4",
              "Kg1",
              "g3",
              "Kf1",
              "h3",
              "Kg1",
              "h2+",
              "Kf1",
              "h1=Q+",
              "Ke2",
              "Qf3+",
              "Kd2",
              "Qd3+",
              "Ke1",
              "Bf3",
              "a8=Q",
              "Qe2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc3",
              "O-O",
              "Ne4",
              "Bf5",
              "Nxc5",
              "bxc5",
              "c3",
              "Rfd8",
              "Be3",
              "c4",
              "Bc5",
              "Rd2",
              "Ba3",
              "Be4",
              "Rg1",
              "Nxf4",
              "Rae1",
              "Bxg2+",
              "Rxg2",
              "Nxg2",
              "Re4",
              "Nd5",
              "Rxc4",
              "Nde3",
              "Rxc6",
              "Rd1#",
              "Rxd1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 224,
            "completion_tokens": 210,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 224,
            "completion_tokens": 318,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 223,
            "completion_tokens": 119,
            "total_tokens": 342,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 671,
          "total_completion_tokens": 647,
          "total_tokens": 1318
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 224,
            "completion_tokens": 210,
            "total_tokens": 434,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 224,
            "completion_tokens": 318,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 223,
            "completion_tokens": 119,
            "total_tokens": 342,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k1nr/5ppp/1pp3n1/2b1P3/5P2/8/PPP3PP/RNB2R1K b kq - 3 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxf5",
          "aggressive_uci": "e7f5",
          "aggressive_response": "15... Nxf5 16. Rxf5 Bxf5 17. Nc3 O-O 18. Bg5 Nxe5 19. Re1 f6 20. Bf4 Rfe8\n21. Bxe5 Rxe5 22. Rxe5 fxe5 23. h3 Bxc2 24. g4 Bd4 25. Ne2 Rxa2 26. Nxd4 exd4\n27. Kg2 Rxb2 28. Kf3 d3 29. Ke3 c5 30. Kd2 c4 31. Kc3 Rb3+ 32. Kxc4 d2 33. Kd4\nd1=Q+ 34. Ke5 Re3+ 35. Kf4 Qf3+ 36. Kg5 h6+ 37. Kh4 Qxh3#\n37... Qxh3# g5+ 38. Kh5 Qxh3# g5+ 39. Kh6 Qxh3#",
          "aggressive_tokens": {
            "prompt_tokens": 234,
            "completion_tokens": 229,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf5",
            "Bxf5",
            "Nc3",
            "O-O",
            "Bg5",
            "Nxe5",
            "Re1",
            "f6",
            "Bf4",
            "Rfe8",
            "Bxe5",
            "Rxe5",
            "Rxe5",
            "fxe5",
            "h3",
            "Bxc2",
            "g4",
            "Bd4",
            "Ne2",
            "Rxa2",
            "Nxd4",
            "exd4",
            "Kg2",
            "Rxb2",
            "Kf3",
            "d3",
            "Ke3",
            "c5",
            "Kd2",
            "c4",
            "Kc3",
            "Rb3+",
            "Kxc4",
            "d2",
            "Kd4",
            "d1=Q+",
            "Ke5",
            "Re3+",
            "Kf4",
            "Qf3+",
            "Kg5",
            "h6+",
            "Kh4",
            "Qxh3#",
            "Qxh3#",
            "g5+",
            "Kh5",
            "Qxh3#",
            "g5+",
            "Kh6",
            "Qxh3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxf5",
          "positional_uci": "e7f5",
          "positional_response": "15... Nxf5 16. Rxf5 Bxf5 17. Nc3 O-O 18. Bg5 Nxe5 19. Re1 Ng4 20. h3 Nf2+\n21. Kh2 Bd6+ 22. g3 Nxh3 23. Kg2 Nxg5 24. Ne2 Be4+ 25. Kf2 Bc5+ 26. Kf1 Nf3\n27. Rd1 Nh2+ 28. Ke1 Nf3+ 29. Kf1 Rad8 30. Rxd8 Rxd8 31. Nc3 Nd2+ 32. Ke2 Bf3+\n33. Ke1 Be3 34. Ne2 Ne4 35. Nf4 Rd1# Bf2+ 37. Kf1 Bxg3# Bxh2 39. Ke2 Bxf4\n40. Kxd1 Bf3+ 41. Ke1 Bg3+ 42. Kf1 Nd2+ 43. Kg1 h5 44. c4 h4 45. b4 h3 46. c5 h2# Bxh2 48. Kxh2 bxc5 49. bxc5 Ne4 50. a4 Nxc5 51. a5 Nb3 52. a6 c5 53. a7 c4 54. Kg3 Ba8 55. Kf2 c3 56. Ke2 c2 57. Kd3 c1=Q 58. Ke2 Qd2+ 59. Kf1 Bg2+ 60. Kg1 Bf3 61. Kf1 Qe2+ 62. Kg1 Qg2# Bxg2 64. Kxg2 f5 65. Kf3 g5 66. Ke3 f4+ 67. Kd3 f3 68. Kc3 f2 69. Kxb3 f1=Q 70. Kb4 Qb7+ 71. Kc5 Qc1+ 72. Kd4 Qd7+ 73. Ke5 Qe1+ 74. Kf6 Qf7+ 75. Kxg5 Qg1+ 76. Kh4 Qh7# e6 f5 78. Kh3 f4 79. Kh4 f3 80. Kh3 f2 81. Kh4 f1=Q 82. Kh5 Qf3+ 83. Kh4 Qf4+ 84. Kh3 Qf3+ 85. Kh4 Qf4+ 86. Kh3 Qf3+ 87. Kh4 Qf4+ 88. Kh3 Qf3+ 89. Kh4 Qf4+ 90. Kh3 Qf3+ 91. Kh4 Qf4+ 92. Kh3 Qf3",
          "positional_tokens": {
            "prompt_tokens": 234,
            "completion_tokens": 640,
            "total_tokens": 874,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxf5",
            "Bxf5",
            "Nc3",
            "O-O",
            "Bg5",
            "Nxe5",
            "Re1",
            "Ng4",
            "h3",
            "Nf2+",
            "Kh2",
            "Bd6+",
            "g3",
            "Nxh3",
            "Kg2",
            "Nxg5",
            "Ne2",
            "Be4+",
            "Kf2",
            "Bc5+",
            "Kf1",
            "Nf3",
            "Rd1",
            "Nh2+",
            "Ke1",
            "Nf3+",
            "Kf1",
            "Rad8",
            "Rxd8",
            "Rxd8",
            "Nc3",
            "Nd2+",
            "Ke2",
            "Bf3+",
            "Ke1",
            "Be3",
            "Ne2",
            "Ne4",
            "Nf4",
            "Rd1#",
            "Bf2+",
            "Kf1",
            "Bxg3#",
            "Bxh2",
            "Ke2",
            "Bxf4",
            "Kxd1",
            "Bf3+",
            "Ke1",
            "Bg3+",
            "Kf1",
            "Nd2+",
            "Kg1",
            "h5",
            "c4",
            "h4",
            "b4",
            "h3",
            "c5",
            "h2#",
            "Bxh2",
            "Kxh2",
            "bxc5",
            "bxc5",
            "Ne4",
            "a4",
            "Nxc5",
            "a5",
            "Nb3",
            "a6",
            "c5",
            "a7",
            "c4",
            "Kg3",
            "Ba8",
            "Kf2",
            "c3",
            "Ke2",
            "c2",
            "Kd3",
            "c1=Q",
            "Ke2",
            "Qd2+",
            "Kf1",
            "Bg2+",
            "Kg1",
            "Bf3",
            "Kf1",
            "Qe2+",
            "Kg1",
            "Qg2#",
            "Bxg2",
            "Kxg2",
            "f5",
            "Kf3",
            "g5",
            "Ke3",
            "f4+",
            "Kd3",
            "f3",
            "Kc3",
            "f2",
            "Kxb3",
            "f1=Q",
            "Kb4",
            "Qb7+",
            "Kc5",
            "Qc1+",
            "Kd4",
            "Qd7+",
            "Ke5",
            "Qe1+",
            "Kf6",
            "Qf7+",
            "Kxg5",
            "Qg1+",
            "Kh4",
            "Qh7#",
            "e6",
            "f5",
            "Kh3",
            "f4",
            "Kh4",
            "f3",
            "Kh3",
            "f2",
            "Kh4",
            "f1=Q",
            "Kh5",
            "Qf3+",
            "Kh4",
            "Qf4+",
            "Kh3",
            "Qf3+",
            "Kh4",
            "Qf4+",
            "Kh3",
            "Qf3+",
            "Kh4",
            "Qf4+",
            "Kh3",
            "Qf3+",
            "Kh4",
            "Qf4+",
            "Kh3",
            "Qf3+",
            "Kh4",
            "Qf4+",
            "Kh3",
            "Qf3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxf5",
          "neutral_uci": "e7f5",
          "neutral_response": "15... Nxf5 16. Rxf5 Bxf5 17. Nc3 O-O 18. Bg5 Nxe5 19. Re1 f6 20. Bf4 Rfe8\n21. Bxe5 Rxe5 22. Rxe5 fxe5 23. h3 Bxc2 24. g4 Bd4 25. Ne2 Rxa2 26. Nxd4 exd4\n27. Kg2 Rxb2 28. Kf3 d3 29. Ke3 c5 30. Kd2 c4 31. Kc3 Ra2 32. Kxc4 d2 33. Kc3\nd1=Q 34. Kc4 Qd3+ 35. Kb4 Ra4# 1-0\n15... Nxf5 16. Rxf5 Bxf5 17. Nc3 O-O 18. Bg5 Nxe5 19. Re1 f6 20. Bf4 Rfe8\n21. Bxe5 Rxe5 22. Rxe5 fxe5 23. h3 Bxc2 24. g4 Bd4 25. Ne2 Rxa2 26. Nxd4 exd4\n27. Kg2 Rxb2 28. Kf3 d3 29. Ke3 c5 30. Kd2 c4 31. Kc3 Ra2 32. Kxc4 d2 33. Kc3\nd1=Q 34. Kc4 Qd3+ 35. Kb4 Ra4# 1-0",
          "neutral_tokens": {
            "prompt_tokens": 233,
            "completion_tokens": 356,
            "total_tokens": 589,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf5",
            "Bxf5",
            "Nc3",
            "O-O",
            "Bg5",
            "Nxe5",
            "Re1",
            "f6",
            "Bf4",
            "Rfe8",
            "Bxe5",
            "Rxe5",
            "Rxe5",
            "fxe5",
            "h3",
            "Bxc2",
            "g4",
            "Bd4",
            "Ne2",
            "Rxa2",
            "Nxd4",
            "exd4",
            "Kg2",
            "Rxb2",
            "Kf3",
            "d3",
            "Ke3",
            "c5",
            "Kd2",
            "c4",
            "Kc3",
            "Ra2",
            "Kxc4",
            "d2",
            "Kc3",
            "d1=Q",
            "Kc4",
            "Qd3+",
            "Kb4",
            "Ra4#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7f5",
          "positional_uci": "e7f5",
          "neutral_uci": "e7f5",
          "consensus_move": "e7f5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxf5",
              "Bxf5",
              "Nc3",
              "O-O",
              "Bg5",
              "Nxe5",
              "Re1",
              "f6",
              "Bf4",
              "Rfe8",
              "Bxe5",
              "Rxe5",
              "Rxe5",
              "fxe5",
              "h3",
              "Bxc2",
              "g4",
              "Bd4",
              "Ne2",
              "Rxa2",
              "Nxd4",
              "exd4",
              "Kg2",
              "Rxb2",
              "Kf3",
              "d3",
              "Ke3",
              "c5",
              "Kd2",
              "c4",
              "Kc3",
              "Rb3+",
              "Kxc4",
              "d2",
              "Kd4",
              "d1=Q+",
              "Ke5",
              "Re3+",
              "Kf4",
              "Qf3+",
              "Kg5",
              "h6+",
              "Kh4",
              "Qxh3#",
              "Qxh3#",
              "g5+",
              "Kh5",
              "Qxh3#",
              "g5+",
              "Kh6",
              "Qxh3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxf5",
              "Bxf5",
              "Nc3",
              "O-O",
              "Bg5",
              "Nxe5",
              "Re1",
              "Ng4",
              "h3",
              "Nf2+",
              "Kh2",
              "Bd6+",
              "g3",
              "Nxh3",
              "Kg2",
              "Nxg5",
              "Ne2",
              "Be4+",
              "Kf2",
              "Bc5+",
              "Kf1",
              "Nf3",
              "Rd1",
              "Nh2+",
              "Ke1",
              "Nf3+",
              "Kf1",
              "Rad8",
              "Rxd8",
              "Rxd8",
              "Nc3",
              "Nd2+",
              "Ke2",
              "Bf3+",
              "Ke1",
              "Be3",
              "Ne2",
              "Ne4",
              "Nf4",
              "Rd1#",
              "Bf2+",
              "Kf1",
              "Bxg3#",
              "Bxh2",
              "Ke2",
              "Bxf4",
              "Kxd1",
              "Bf3+",
              "Ke1",
              "Bg3+",
              "Kf1",
              "Nd2+",
              "Kg1",
              "h5",
              "c4",
              "h4",
              "b4",
              "h3",
              "c5",
              "h2#",
              "Bxh2",
              "Kxh2",
              "bxc5",
              "bxc5",
              "Ne4",
              "a4",
              "Nxc5",
              "a5",
              "Nb3",
              "a6",
              "c5",
              "a7",
              "c4",
              "Kg3",
              "Ba8",
              "Kf2",
              "c3",
              "Ke2",
              "c2",
              "Kd3",
              "c1=Q",
              "Ke2",
              "Qd2+",
              "Kf1",
              "Bg2+",
              "Kg1",
              "Bf3",
              "Kf1",
              "Qe2+",
              "Kg1",
              "Qg2#",
              "Bxg2",
              "Kxg2",
              "f5",
              "Kf3",
              "g5",
              "Ke3",
              "f4+",
              "Kd3",
              "f3",
              "Kc3",
              "f2",
              "Kxb3",
              "f1=Q",
              "Kb4",
              "Qb7+",
              "Kc5",
              "Qc1+",
              "Kd4",
              "Qd7+",
              "Ke5",
              "Qe1+",
              "Kf6",
              "Qf7+",
              "Kxg5",
              "Qg1+",
              "Kh4",
              "Qh7#",
              "e6",
              "f5",
              "Kh3",
              "f4",
              "Kh4",
              "f3",
              "Kh3",
              "f2",
              "Kh4",
              "f1=Q",
              "Kh5",
              "Qf3+",
              "Kh4",
              "Qf4+",
              "Kh3",
              "Qf3+",
              "Kh4",
              "Qf4+",
              "Kh3",
              "Qf3+",
              "Kh4",
              "Qf4+",
              "Kh3",
              "Qf3+",
              "Kh4",
              "Qf4+",
              "Kh3",
              "Qf3+",
              "Kh4",
              "Qf4+",
              "Kh3",
              "Qf3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxf5",
              "Bxf5",
              "Nc3",
              "O-O",
              "Bg5",
              "Nxe5",
              "Re1",
              "f6",
              "Bf4",
              "Rfe8",
              "Bxe5",
              "Rxe5",
              "Rxe5",
              "fxe5",
              "h3",
              "Bxc2",
              "g4",
              "Bd4",
              "Ne2",
              "Rxa2",
              "Nxd4",
              "exd4",
              "Kg2",
              "Rxb2",
              "Kf3",
              "d3",
              "Ke3",
              "c5",
              "Kd2",
              "c4",
              "Kc3",
              "Ra2",
              "Kxc4",
              "d2",
              "Kc3",
              "d1=Q",
              "Kc4",
              "Qd3+",
              "Kb4",
              "Ra4#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 234,
            "completion_tokens": 229,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 234,
            "completion_tokens": 640,
            "total_tokens": 874,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 233,
            "completion_tokens": 356,
            "total_tokens": 589,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 701,
          "total_completion_tokens": 1225,
          "total_tokens": 1926
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 234,
            "completion_tokens": 229,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 234,
            "completion_tokens": 640,
            "total_tokens": 874,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 233,
            "completion_tokens": 356,
            "total_tokens": 589,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/4nppp/1pp3n1/2b1PP2/8/8/PPP3PP/RNB2R1K b kq - 0 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nh6",
          "aggressive_uci": "f5h6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5\nQb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1\nN8e7 15. f5 Nxf5 16. g4 Nh6 17. Bxh6 gxh6 18. Nc3 Bxg4 19. Ne4 Be6 20. Nf6+ Ke7\n21. Rad1 Rhd8 22. Rxd8 Rxd8 23. Nxh7 Bd5+ 24. Rf3 Bxf3# 1-0",
          "aggressive_tokens": {
            "prompt_tokens": 242,
            "completion_tokens": 211,
            "total_tokens": 453,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxh6",
            "gxh6",
            "Nc3",
            "Bxg4",
            "Ne4",
            "Be6",
            "Nf6+",
            "Ke7",
            "Rad1",
            "Rhd8",
            "Rxd8",
            "Rxd8",
            "Nxh7",
            "Bd5+",
            "Rf3",
            "Bxf3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nd4",
          "positional_uci": "f5d4",
          "positional_response": "Repeating the entire game so far. 16... Nd4 17. Na3 Bxa3 18. bxa3 Nxc2 19. Rb1 Nxa3 20. Rxb6 O-O 21. Rxc6 Bb7 22. Bxa3 Bxc6+ 23. Kg1 Rxa3 24. Rc1 Bd5 25. Rc5 Be6 26. Rc6 Rxa2 27. h4 Rb8 28. h5 Rb1+ 29. Rc1 Rxc1# e4 e5 Nf3 Nc6 Nxe5 Nxe5 d4 Nc6 d5 Ne5 f4 Ng6 Qd4 Qf6 e5 Qb6 Qxb6 axb6 Bb5 c6 dxc6 dxc6 O-O Bc5+ Kh1 N8e7 f5 Nxf5 g4 Nd4 Na3 Bxa3 bxa3 Nxa3 Rb1 Nxb1 Rxb1 O-O Rxc1 Bb7 Bxa3 Bxc6+ Kg1 Rxa3 Rc1 Bd5 Rc5 Be6 Rc6 Rxa2 h4 Rb8 h5 Rb1+ Rc1 Rxc1#",
          "positional_tokens": {
            "prompt_tokens": 242,
            "completion_tokens": 270,
            "total_tokens": 512,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3",
            "Bxa3",
            "bxa3",
            "Nxa3",
            "Rb1",
            "Nxb1",
            "Rxb1",
            "O-O",
            "Rxc1",
            "Bb7",
            "Bxa3",
            "Bxc6+",
            "Kg1",
            "Rxa3",
            "Rc1",
            "Bd5",
            "Rc5",
            "Be6",
            "Rc6",
            "Rxa2",
            "h4",
            "Rb8",
            "h5",
            "Rb1+",
            "Rc1",
            "Rxc1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nd4",
          "neutral_uci": "f5d4",
          "neutral_response": "Repeating the entire game so far. 16...Nd4 17. Na3 Bxa3 18. bxa3 Nxc2 19. Rb1 b5 20. Rb3 Be6 21. Rc3 Nd4 22. Be3 Ne2 23. Rxc6 Bd5+ 24. Rf3 Bxf3# Repeating the entire game so far. 25. Rxf3 Nxe5 26. Rf2 Nxc6 27. Rxe2 O-O 28. Bc5 Rfe8 29. Rb2 Rab8 30. Bd6 Rb7 31. a4 b4 32. a3 b3 33. a5 Nxa5 34. Bb4 Nc4 35. Rxb3 Re3 36. Rb1 Nxa3 37. Rd1 h6 38. Bc5 Reb3 39. Rd8+ Kh7 40. Ra8 Nc4 41. Ra4 Ne3 42. Re4 Rb1# e4 e5 Nf3 Nc6 Nxe5 Nxe5 d4 Nc6 d5 Ne5 f4 Ng6 Qd4 Qf6 e5 Qb6 Qxb6 axb6 Bb5 c6 dxc6 bxc6 O-O Bc5+ Kh1 N8e7 f5 Nxf5 g4 Nd4 Na3 Bxa3 bxa3 Nxc2 Rb1 b5 Rb3 Be6 Rc3 Nd4 Be3 Ne2 Rxc6 Bd5+ Rf3 Bxf3# Rxf3 Nxe5 Rf2 Nxc6 Rxe2 O-O Bc5 Rfe8 Rb2 Rab8 Bd6 Rb7 a4 b4 a5 Nxa5 Bb4 Nc4 Rxb3 Re3 Rb1# Rb2 Rb7 a4 b4 a5 Nxa5 Bb4 Nc4 Rxb3 Re3 Rb1#",
          "neutral_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 440,
            "total_tokens": 681,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be3",
            "Ne2",
            "Rxc6",
            "Bd5+",
            "Rf3",
            "Bxf3#",
            "Rxf3",
            "Nxe5",
            "Rf2",
            "Nxc6",
            "Rxe2",
            "O-O",
            "Bc5",
            "Rfe8",
            "Rb2",
            "Rab8",
            "Bd6",
            "Rb7",
            "a4",
            "b4",
            "a5",
            "Nxa5",
            "Bb4",
            "Nc4",
            "Rxb3",
            "Re3",
            "Rb1#",
            "Rb2",
            "Rb7",
            "a4",
            "b4",
            "a5",
            "Nxa5",
            "Bb4",
            "Nc4",
            "Rxb3",
            "Re3",
            "Rb1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f5h6",
          "positional_uci": "f5d4",
          "neutral_uci": "f5d4",
          "consensus_move": "f5d4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxh6",
              "gxh6",
              "Nc3",
              "Bxg4",
              "Ne4",
              "Be6",
              "Nf6+",
              "Ke7",
              "Rad1",
              "Rhd8",
              "Rxd8",
              "Rxd8",
              "Nxh7",
              "Bd5+",
              "Rf3",
              "Bxf3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Na3",
              "Bxa3",
              "bxa3",
              "Nxa3",
              "Rb1",
              "Nxb1",
              "Rxb1",
              "O-O",
              "Rxc1",
              "Bb7",
              "Bxa3",
              "Bxc6+",
              "Kg1",
              "Rxa3",
              "Rc1",
              "Bd5",
              "Rc5",
              "Be6",
              "Rc6",
              "Rxa2",
              "h4",
              "Rb8",
              "h5",
              "Rb1+",
              "Rc1",
              "Rxc1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be3",
              "Ne2",
              "Rxc6",
              "Bd5+",
              "Rf3",
              "Bxf3#",
              "Rxf3",
              "Nxe5",
              "Rf2",
              "Nxc6",
              "Rxe2",
              "O-O",
              "Bc5",
              "Rfe8",
              "Rb2",
              "Rab8",
              "Bd6",
              "Rb7",
              "a4",
              "b4",
              "a5",
              "Nxa5",
              "Bb4",
              "Nc4",
              "Rxb3",
              "Re3",
              "Rb1#",
              "Rb2",
              "Rb7",
              "a4",
              "b4",
              "a5",
              "Nxa5",
              "Bb4",
              "Nc4",
              "Rxb3",
              "Re3",
              "Rb1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 242,
            "completion_tokens": 211,
            "total_tokens": 453,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 242,
            "completion_tokens": 270,
            "total_tokens": 512,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 241,
            "completion_tokens": 440,
            "total_tokens": 681,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 725,
          "total_completion_tokens": 921,
          "total_tokens": 1646
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 242,
            "completion_tokens": 211,
            "total_tokens": 453,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 242,
            "completion_tokens": 270,
            "total_tokens": 512,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 241,
            "completion_tokens": 440,
            "total_tokens": 681,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/5ppp/1pp3n1/2b1Pn2/6P1/8/PPP4P/RNB2R1K b kq - 0 16"
    },
    {
      "turn": 34,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxc2",
          "aggressive_uci": "d4c2",
          "aggressive_response": "Repeating the entire game so far: 1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 * 17... Nxc2 18. Rb1 Bxg4 19. Bg5 O-O",
          "aggressive_tokens": {
            "prompt_tokens": 250,
            "completion_tokens": 172,
            "total_tokens": 422,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rb1",
            "Bxg4",
            "Bg5",
            "O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxc2",
          "positional_uci": "d4c2",
          "positional_response": "Repeated game\n17... Nxc2 18. Rb1 Bxg4 19. Ne4 O-O 20. Nxc5 bxc5 21. Bg5 Rxa2 22. Rbc1 Rxb2\n23. Rf2 Bf5 24. Rxf5 Nd4 25. Rff1 Nxe5 26. Rxc5 Nef3 27. Be7 Rxh2# 28. Re1 Nxe1 29. Kxh2 Re8 30. Bd6 Re6 31. Bg3 Nd3 32. Ra5 h6 33. Ra8+ Kh7 34. Ra7 Kg6 35. Ra4 c5 36. Ra3 c4 37. Rc3 Rc6 38. Kg2 Ne2 39. Rc2 Nxg3 40. Kxg3 c3 41. Kf3 Nb4 42. Rc1 c2 43. Ke2 Na2 44. Rg1+ Kh7 45. Kd2 c1=Q+ 46. Rxc1 Nxc1 47. Ke3 h5 48. Kf4 Rg6 49. Kf5 h4 50. Kf4 h3 51. Kf5 h2 52. Kf4 h1=Q 53. Kf5 Qf3+ 54. Ke5 Re6+ 55. Kd4 Qd3+ 56. Kc5 Nb3+ 57. Kb4 Rb6+ 58. Ka3 Nc1+ 59. Ka4 Qb3+ 60. Ka5 Qb5# 61.  Repeated game\n61... Qb4# 62. Ka6 Qb5# 63. Ka7 Qb6#",
          "positional_tokens": {
            "prompt_tokens": 250,
            "completion_tokens": 402,
            "total_tokens": 652,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rb1",
            "Bxg4",
            "Ne4",
            "O-O",
            "Nxc5",
            "bxc5",
            "Bg5",
            "Rxa2",
            "Rbc1",
            "Rxb2",
            "Rf2",
            "Bf5",
            "Rxf5",
            "Nd4",
            "Rff1",
            "Nxe5",
            "Rxc5",
            "Nef3",
            "Be7",
            "Rxh2#",
            "Re1",
            "Nxe1",
            "Kxh2",
            "Re8",
            "Bd6",
            "Re6",
            "Bg3",
            "Nd3",
            "Ra5",
            "h6",
            "Ra8+",
            "Kh7",
            "Ra7",
            "Kg6",
            "Ra4",
            "c5",
            "Ra3",
            "c4",
            "Rc3",
            "Rc6",
            "Kg2",
            "Ne2",
            "Rc2",
            "Nxg3",
            "Kxg3",
            "c3",
            "Kf3",
            "Nb4",
            "Rc1",
            "c2",
            "Ke2",
            "Na2",
            "Rg1+",
            "Kh7",
            "Kd2",
            "c1=Q+",
            "Rxc1",
            "Nxc1",
            "Ke3",
            "h5",
            "Kf4",
            "Rg6",
            "Kf5",
            "h4",
            "Kf4",
            "h3",
            "Kf5",
            "h2",
            "Kf4",
            "h1=Q",
            "Kf5",
            "Qf3+",
            "Ke5",
            "Re6+",
            "Kd4",
            "Qd3+",
            "Kc5",
            "Nb3+",
            "Kb4",
            "Rb6+",
            "Ka3",
            "Nc1+",
            "Ka4",
            "Qb3+",
            "Ka5",
            "Qb5#",
            "Qb4#",
            "Ka6",
            "Qb5#",
            "Ka7",
            "Qb6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxc2",
          "neutral_uci": "d4c2",
          "neutral_response": "Repeating the entire game so far, the next 3 moves are:\n17... Nxc2 18. Rb1 Bxg4 19. Ne4",
          "neutral_tokens": {
            "prompt_tokens": 249,
            "completion_tokens": 35,
            "total_tokens": 284,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rb1",
            "Bxg4",
            "Ne4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4c2",
          "positional_uci": "d4c2",
          "neutral_uci": "d4c2",
          "consensus_move": "d4c2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rb1",
              "Bxg4",
              "Bg5",
              "O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rb1",
              "Bxg4",
              "Ne4",
              "O-O",
              "Nxc5",
              "bxc5",
              "Bg5",
              "Rxa2",
              "Rbc1",
              "Rxb2",
              "Rf2",
              "Bf5",
              "Rxf5",
              "Nd4",
              "Rff1",
              "Nxe5",
              "Rxc5",
              "Nef3",
              "Be7",
              "Rxh2#",
              "Re1",
              "Nxe1",
              "Kxh2",
              "Re8",
              "Bd6",
              "Re6",
              "Bg3",
              "Nd3",
              "Ra5",
              "h6",
              "Ra8+",
              "Kh7",
              "Ra7",
              "Kg6",
              "Ra4",
              "c5",
              "Ra3",
              "c4",
              "Rc3",
              "Rc6",
              "Kg2",
              "Ne2",
              "Rc2",
              "Nxg3",
              "Kxg3",
              "c3",
              "Kf3",
              "Nb4",
              "Rc1",
              "c2",
              "Ke2",
              "Na2",
              "Rg1+",
              "Kh7",
              "Kd2",
              "c1=Q+",
              "Rxc1",
              "Nxc1",
              "Ke3",
              "h5",
              "Kf4",
              "Rg6",
              "Kf5",
              "h4",
              "Kf4",
              "h3",
              "Kf5",
              "h2",
              "Kf4",
              "h1=Q",
              "Kf5",
              "Qf3+",
              "Ke5",
              "Re6+",
              "Kd4",
              "Qd3+",
              "Kc5",
              "Nb3+",
              "Kb4",
              "Rb6+",
              "Ka3",
              "Nc1+",
              "Ka4",
              "Qb3+",
              "Ka5",
              "Qb5#",
              "Qb4#",
              "Ka6",
              "Qb5#",
              "Ka7",
              "Qb6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rb1",
              "Bxg4",
              "Ne4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 250,
            "completion_tokens": 172,
            "total_tokens": 422,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 250,
            "completion_tokens": 402,
            "total_tokens": 652,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 249,
            "completion_tokens": 35,
            "total_tokens": 284,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 749,
          "total_completion_tokens": 609,
          "total_tokens": 1358
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 250,
            "completion_tokens": 172,
            "total_tokens": 422,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 250,
            "completion_tokens": 402,
            "total_tokens": 652,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 249,
            "completion_tokens": 35,
            "total_tokens": 284,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/5ppp/1pp3n1/2b1P3/3n2P1/2N5/PPP4P/R1B2R1K b kq - 2 17"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 Nf6\nd4 Nf6 Nc3 d5 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Re1 Qd6 Re3 Bf5 Re8+ Rxe8 Bxf5 Qxd1+ Rxd1 Rad8 Rxd8 Rxd8 Kf1 Rd2 b4 Rxa2 Be4 c6 b5 cxb5 Bxb7 Rc2 Ba6 Rxc3 Bxb5 Rc5 Ke2 Kf8 Kd2 Ra3 Kc2 Ra2+ Kb3 Rxf2 Bb7 Ke7 Kb4 Kd6 Bf3 Rb2+ Ka5 Kc5 Ka6 Rb6+ Ka5 Rb5+ Ka4 Rb7 a5 Rxf7 Kb4 Rxg7 a4 Rxh7 a3 Rb7+ Kc3 Bd5 a2 Ra7 Kb2 Rxa2+ Kxa2 g4 Kc3 Kb3 Kd4 Kc2 Ke3 Kc3 Kf2 Kd4 Kxg4 Ke5 Kxg3 Kf4 Kf2 Kg4 g3 Kg5 g2 Kf4 g1=Q Ke5 Qd4+ Kf6 Qe4+ Kg5 Qf4+ Kg6 Ke5 Kg7 Qf6+ Kg8 Ke6 Kh7 Qg5 Kh8 Kf7 Kh7 Qg7#\nd4 Nf6 Nc3 d5 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Re1 Qd6 Re3 Bf5 Re8+ Rxe8 Bxf5 Qxd1+ Rxd1 Rad8 Rxd8 Rxd8 Kf1 Rd2 b4 Rxa2 Be4 c6 b5 cxb5 Bxb7 Rc2 Ba6 Rxc3 Bxb5 Rc5 Ke2 Kf8 Kd2 Ra3 Kc2 Ra2+ Kb3 Rxf2 Bb7 Ke7 Kb4 Kd6 Bf3 Rb2+ Ka5 Kc5 Ka6 Rb6+ Ka5 Rb5+ Ka4 Rb7 a5 Rxf7 Kb4 Rxg7 a4 Rxh7 a3 Rb7+ Kc3 Bd5 a2 Ra7 Kb2 Rxa2+ Kxa2 g4 Kc3 Kb3 Kd4 Kc2 Ke3 Kc3 Kf2 Kd4 Kxg4 Ke5 Kxg3 Kf4 Kf2 Kg4 g3 Kg5 g2 Kf4 g1=Q Ke5 Qd",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Nc3",
            "d5",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "O-O",
            "Rd8",
            "c3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "Re1",
            "Qd6",
            "Re3",
            "Bf5",
            "Re8+",
            "Rxe8",
            "Bxf5",
            "Qxd1+",
            "Rxd1",
            "Rad8",
            "Rxd8",
            "Rxd8",
            "Kf1",
            "Rd2",
            "b4",
            "Rxa2",
            "Be4",
            "c6",
            "b5",
            "cxb5",
            "Bxb7",
            "Rc2",
            "Ba6",
            "Rxc3",
            "Bxb5",
            "Rc5",
            "Ke2",
            "Kf8",
            "Kd2",
            "Ra3",
            "Kc2",
            "Ra2+",
            "Kb3",
            "Rxf2",
            "Bb7",
            "Ke7",
            "Kb4",
            "Kd6",
            "Bf3",
            "Rb2+",
            "Ka5",
            "Kc5",
            "Ka6",
            "Rb6+",
            "Ka5",
            "Rb5+",
            "Ka4",
            "Rb7",
            "a5",
            "Rxf7",
            "Kb4",
            "Rxg7",
            "a4",
            "Rxh7",
            "a3",
            "Rb7+",
            "Kc3",
            "Bd5",
            "a2",
            "Ra7",
            "Kb2",
            "Rxa2+",
            "Kxa2",
            "g4",
            "Kc3",
            "Kb3",
            "Kd4",
            "Kc2",
            "Ke3",
            "Kc3",
            "Kf2",
            "Kd4",
            "Kxg4",
            "Ke5",
            "Kxg3",
            "Kf4",
            "Kf2",
            "Kg4",
            "g3",
            "Kg5",
            "g2",
            "Kf4",
            "g1=Q",
            "Ke5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O d6 5. c3 Bg4 6. d4 exd4 7. cxd4 Bb6 8. d5 a6 9. Ba4 Bxf3 10. Qxf3 Nge7 11. dxc6 bxc6 12. Nc3 O-O 13. Bg5 f6 14. Be3 c5 15. Nd5 Nxd5 16. exd5 Qe7 17. Rfe1 Qf7 18. Bc6 Rad8 19. Qg4 f5 20. Qg5 h6 21. Qh4 Kh7 22. Bg5 Rb8 23. Re7 Qg6 24. Bf4 Ba5 25. b3 Bc3 26. Rc1 Bf6 27. Qg3 Bxe7 28. Qxg6+ Kxg6 29. Re1 Bf6 30. Re6 Kf7 31. Bd7 Rbd8 32. Bc6 g5 33. Bd2 f4 34. Ba5 Rc8 35. Bd7 Rcd8 36. Bc6 Rc8 37. Bd7 Rcd8 38. Bc6 Rc8 39. Bd7 Rd8 40. Bc6 Rc8 41. Bd7 Rd8 42. Bc6 Rc8 43. Bd7 Rd8 44. Bc6 Rc8 45. Bd7 Rd8 46. Bc6 Rc8 47. Bd7 Rd8 48. Bc6 Rc8 49. Bd7 Rd8 50. Bc6 Rc8 51. Bd7 Rd8 52. Bc6 Rc8 53. Bd7 Rd8 54. Bc6 Rc8 55. Bd7 Rd8 56. Bc6 Rc8 57. Bd7 Rd8 58. Bc6 Rc8 59. Bd7 Rd8 60. Bc6 Rc8 61. Bd7 Rd8 62. Bc6 Rc8 63. Bd7 Rd8 64. Bc6 Rc8 65. Bd7 Rd8 66. Bc6 Rc8 67. Bd7 Rd8 68. Bc6 Rc8 69. Bd7 Rd8 70. Bc6 Rc8 71. Bd7 Rd8 72. Bc6 Rc8 73. Bd7 Rd8 74. Bc6 Rc8 75. Bd7 Rd8 76. Bc6 Rc8 77. Bd7 Rd8 78. Bc6 Rc8 79. Bd7 Rd8 80. Bc6 Rc8 81. Bd7 Rd8 82. Bc6 Rc8",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "d6",
            "c3",
            "Bg4",
            "d4",
            "exd4",
            "cxd4",
            "Bb6",
            "d5",
            "a6",
            "Ba4",
            "Bxf3",
            "Qxf3",
            "Nge7",
            "dxc6",
            "bxc6",
            "Nc3",
            "O-O",
            "Bg5",
            "f6",
            "Be3",
            "c5",
            "Nd5",
            "Nxd5",
            "exd5",
            "Qe7",
            "Rfe1",
            "Qf7",
            "Bc6",
            "Rad8",
            "Qg4",
            "f5",
            "Qg5",
            "h6",
            "Qh4",
            "Kh7",
            "Bg5",
            "Rb8",
            "Re7",
            "Qg6",
            "Bf4",
            "Ba5",
            "b3",
            "Bc3",
            "Rc1",
            "Bf6",
            "Qg3",
            "Bxe7",
            "Qxg6+",
            "Kxg6",
            "Re1",
            "Bf6",
            "Re6",
            "Kf7",
            "Bd7",
            "Rbd8",
            "Bc6",
            "g5",
            "Bd2",
            "f4",
            "Ba5",
            "Rc8",
            "Bd7",
            "Rcd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rcd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8",
            "Bd7",
            "Rd8",
            "Bc6",
            "Rc8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 d5\nd4 d5 Nf3 Nf6 Bf4 Bf5 e3 e6 c4 c6 Nc3 Nbd7 Qb3 Qb6 c5 Qxb3 axb3 Be7 b4 O-O b5 cxb5 Bxb5 a6 Ba4 Rac8 O-O Rfd8 b4 Ne4 Nxe4 Bxe4 Nd2 Bd3 Rfc1 Bb5 Bxb5 axb5 Ra7 b6 Rca1 Nf6 Rxa8 Rxa8 Rxa8+ Bf8 Bd6 Nd7 c6 bxc6 bxc6 Nb6 Bxf8 Kxf8 Nb3 Ke7 Nc5 Kd6 Kf1 Kxc6 Ke2 Nc4 Kd3 e5 f3 f5 e4 fxe4+ fxe4 exd4 Kxd4 Nd6 exd5+ Kc7 Ne6+ Kd7 Nxg7 Ke7 Ke5 Nf7+ Kf5 d3 d2 d1=Q d1=Q Qxd1+ Kxd1 Kf6 Ne8+ Ke7 Nc7 Kd6 Nb5+ Kxd5 Ke2 Ke5 Kf3 Kf5 Nd4+ Kg5 Ne6+ Kf5 Nf8 h6 Kg3 Kg5 h4+ Kf5 Kh3 Kg6 g4 Kf6 Kg3 Kg6 Kf4 Kf6 h5 Kg7 Kf5 Kf7 Ne5+ Kg7 Ke6 Kh7 Kf6 Kh8 Kg6 Kg8 Kxh6 Kh8 Kg6 Kg8 h6 Kh8 Nf7+ Kg8 h7+ Kf8 h8=Q+ Ke7 Qe5+ Kd7 Qd6+ Kc8 Qe7 Kb8 Nd6 Ka8 Qb7# Kh8 Qg7#",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 405,
            "total_tokens": 514,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nf6",
            "Bf4",
            "Bf5",
            "e3",
            "e6",
            "c4",
            "c6",
            "Nc3",
            "Nbd7",
            "Qb3",
            "Qb6",
            "c5",
            "Qxb3",
            "axb3",
            "Be7",
            "b4",
            "O-O",
            "b5",
            "cxb5",
            "Bxb5",
            "a6",
            "Ba4",
            "Rac8",
            "O-O",
            "Rfd8",
            "b4",
            "Ne4",
            "Nxe4",
            "Bxe4",
            "Nd2",
            "Bd3",
            "Rfc1",
            "Bb5",
            "Bxb5",
            "axb5",
            "Ra7",
            "b6",
            "Rca1",
            "Nf6",
            "Rxa8",
            "Rxa8",
            "Rxa8+",
            "Bf8",
            "Bd6",
            "Nd7",
            "c6",
            "bxc6",
            "bxc6",
            "Nb6",
            "Bxf8",
            "Kxf8",
            "Nb3",
            "Ke7",
            "Nc5",
            "Kd6",
            "Kf1",
            "Kxc6",
            "Ke2",
            "Nc4",
            "Kd3",
            "e5",
            "f3",
            "f5",
            "e4",
            "fxe4+",
            "fxe4",
            "exd4",
            "Kxd4",
            "Nd6",
            "exd5+",
            "Kc7",
            "Ne6+",
            "Kd7",
            "Nxg7",
            "Ke7",
            "Ke5",
            "Nf7+",
            "Kf5",
            "d3",
            "d2",
            "d1=Q",
            "d1=Q",
            "Qxd1+",
            "Kxd1",
            "Kf6",
            "Ne8+",
            "Ke7",
            "Nc7",
            "Kd6",
            "Nb5+",
            "Kxd5",
            "Ke2",
            "Ke5",
            "Kf3",
            "Kf5",
            "Nd4+",
            "Kg5",
            "Ne6+",
            "Kf5",
            "Nf8",
            "h6",
            "Kg3",
            "Kg5",
            "h4+",
            "Kf5",
            "Kh3",
            "Kg6",
            "g4",
            "Kf6",
            "Kg3",
            "Kg6",
            "Kf4",
            "Kf6",
            "h5",
            "Kg7",
            "Kf5",
            "Kf7",
            "Ne5+",
            "Kg7",
            "Ke6",
            "Kh7",
            "Kf6",
            "Kh8",
            "Kg6",
            "Kg8",
            "Kxh6",
            "Kh8",
            "Kg6",
            "Kg8",
            "h6",
            "Kh8",
            "Nf7+",
            "Kg8",
            "h7+",
            "Kf8",
            "h8=Q+",
            "Ke7",
            "Qe5+",
            "Kd7",
            "Qd6+",
            "Kc8",
            "Qe7",
            "Kb8",
            "Nd6",
            "Ka8",
            "Qb7#",
            "Kh8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Nc3",
              "d5",
              "Bg5",
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nxf6+",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nf3",
              "O-O",
              "Bd3",
              "Nc6",
              "O-O",
              "Rd8",
              "c3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "Re1",
              "Qd6",
              "Re3",
              "Bf5",
              "Re8+",
              "Rxe8",
              "Bxf5",
              "Qxd1+",
              "Rxd1",
              "Rad8",
              "Rxd8",
              "Rxd8",
              "Kf1",
              "Rd2",
              "b4",
              "Rxa2",
              "Be4",
              "c6",
              "b5",
              "cxb5",
              "Bxb7",
              "Rc2",
              "Ba6",
              "Rxc3",
              "Bxb5",
              "Rc5",
              "Ke2",
              "Kf8",
              "Kd2",
              "Ra3",
              "Kc2",
              "Ra2+",
              "Kb3",
              "Rxf2",
              "Bb7",
              "Ke7",
              "Kb4",
              "Kd6",
              "Bf3",
              "Rb2+",
              "Ka5",
              "Kc5",
              "Ka6",
              "Rb6+",
              "Ka5",
              "Rb5+",
              "Ka4",
              "Rb7",
              "a5",
              "Rxf7",
              "Kb4",
              "Rxg7",
              "a4",
              "Rxh7",
              "a3",
              "Rb7+",
              "Kc3",
              "Bd5",
              "a2",
              "Ra7",
              "Kb2",
              "Rxa2+",
              "Kxa2",
              "g4",
              "Kc3",
              "Kb3",
              "Kd4",
              "Kc2",
              "Ke3",
              "Kc3",
              "Kf2",
              "Kd4",
              "Kxg4",
              "Ke5",
              "Kxg3",
              "Kf4",
              "Kf2",
              "Kg4",
              "g3",
              "Kg5",
              "g2",
              "Kf4",
              "g1=Q",
              "Ke5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "d6",
              "c3",
              "Bg4",
              "d4",
              "exd4",
              "cxd4",
              "Bb6",
              "d5",
              "a6",
              "Ba4",
              "Bxf3",
              "Qxf3",
              "Nge7",
              "dxc6",
              "bxc6",
              "Nc3",
              "O-O",
              "Bg5",
              "f6",
              "Be3",
              "c5",
              "Nd5",
              "Nxd5",
              "exd5",
              "Qe7",
              "Rfe1",
              "Qf7",
              "Bc6",
              "Rad8",
              "Qg4",
              "f5",
              "Qg5",
              "h6",
              "Qh4",
              "Kh7",
              "Bg5",
              "Rb8",
              "Re7",
              "Qg6",
              "Bf4",
              "Ba5",
              "b3",
              "Bc3",
              "Rc1",
              "Bf6",
              "Qg3",
              "Bxe7",
              "Qxg6+",
              "Kxg6",
              "Re1",
              "Bf6",
              "Re6",
              "Kf7",
              "Bd7",
              "Rbd8",
              "Bc6",
              "g5",
              "Bd2",
              "f4",
              "Ba5",
              "Rc8",
              "Bd7",
              "Rcd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rcd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8",
              "Bd7",
              "Rd8",
              "Bc6",
              "Rc8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf3",
              "Nf6",
              "Bf4",
              "Bf5",
              "e3",
              "e6",
              "c4",
              "c6",
              "Nc3",
              "Nbd7",
              "Qb3",
              "Qb6",
              "c5",
              "Qxb3",
              "axb3",
              "Be7",
              "b4",
              "O-O",
              "b5",
              "cxb5",
              "Bxb5",
              "a6",
              "Ba4",
              "Rac8",
              "O-O",
              "Rfd8",
              "b4",
              "Ne4",
              "Nxe4",
              "Bxe4",
              "Nd2",
              "Bd3",
              "Rfc1",
              "Bb5",
              "Bxb5",
              "axb5",
              "Ra7",
              "b6",
              "Rca1",
              "Nf6",
              "Rxa8",
              "Rxa8",
              "Rxa8+",
              "Bf8",
              "Bd6",
              "Nd7",
              "c6",
              "bxc6",
              "bxc6",
              "Nb6",
              "Bxf8",
              "Kxf8",
              "Nb3",
              "Ke7",
              "Nc5",
              "Kd6",
              "Kf1",
              "Kxc6",
              "Ke2",
              "Nc4",
              "Kd3",
              "e5",
              "f3",
              "f5",
              "e4",
              "fxe4+",
              "fxe4",
              "exd4",
              "Kxd4",
              "Nd6",
              "exd5+",
              "Kc7",
              "Ne6+",
              "Kd7",
              "Nxg7",
              "Ke7",
              "Ke5",
              "Nf7+",
              "Kf5",
              "d3",
              "d2",
              "d1=Q",
              "d1=Q",
              "Qxd1+",
              "Kxd1",
              "Kf6",
              "Ne8+",
              "Ke7",
              "Nc7",
              "Kd6",
              "Nb5+",
              "Kxd5",
              "Ke2",
              "Ke5",
              "Kf3",
              "Kf5",
              "Nd4+",
              "Kg5",
              "Ne6+",
              "Kf5",
              "Nf8",
              "h6",
              "Kg3",
              "Kg5",
              "h4+",
              "Kf5",
              "Kh3",
              "Kg6",
              "g4",
              "Kf6",
              "Kg3",
              "Kg6",
              "Kf4",
              "Kf6",
              "h5",
              "Kg7",
              "Kf5",
              "Kf7",
              "Ne5+",
              "Kg7",
              "Ke6",
              "Kh7",
              "Kf6",
              "Kh8",
              "Kg6",
              "Kg8",
              "Kxh6",
              "Kh8",
              "Kg6",
              "Kg8",
              "h6",
              "Kh8",
              "Nf7+",
              "Kg8",
              "h7+",
              "Kf8",
              "h8=Q+",
              "Ke7",
              "Qe5+",
              "Kd7",
              "Qd6+",
              "Kc8",
              "Qe7",
              "Kb8",
              "Nd6",
              "Ka8",
              "Qb7#",
              "Kh8",
              "Qg7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 405,
            "total_tokens": 514,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1685,
          "total_tokens": 2014
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 405,
            "total_tokens": 514,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nf6 3. c4 c6 4. Nc3 dxc4 5. a4 Bf5 6. e3 e6 7. Bxc4 Bb4 8. O-O O-O 9. Qe2 Bg6 10. Ne5 Nbd7 11. Nxg6 hxg6 12. Rd1 Qa5 13. Bd2 e5 14. dxe5 Nxe5 15. Bb3 Rad8 16. Be1 Rxd1 17. Rxd1 Rd8 18. Rxd8+ Qxd8 19. Qd1 Qxd1 20. Bxd1 Nd3 21. Kf1 Nxb2 22. Bb3 Nd3 23. Bd2 Nc5 24. Bc2 Bxc3 25. Bxc3 Nd5 26. Bd4 b6 27. a5 Kf8 28. axb6 axb6 29. Ke2 Ne6 30. Bb2 Ke7 31. g3 Kd6 32. e4 Nb4 33. Bb3 c5 34. f4 b5 35. f5 gxf5 36. exf5 Nd4+ 37. Bxd4 cxd4 38. Bxf7 Ke5 39. Be8 Kxf5 40. Bxb5 Kg4 41. Bd7+ Kg5 42. h4+ Kf6 43. g4 Nd5 44. Kd3 Ke5 45. Bf5 Nf4+ 46. Kd2 Ng2 47. h5 Ne3 48. Bc8 Kf4 49. Kd3 Nxg4 50. Kxd4 Kg5 51. Ke4 Kxh5 52. Kf4 Nf6 53. Bb7 g5+ 54. Kg3 Kg6 55. Bc6 Kf5 56. Bb7 Nh5+ 57. Kg2 Kf4 58. Bc6 Ng3 59. Bb7 Nf5 60. Bc6 Ne3+ 61. Kg1 Kg3 62. Bb7 Nf5 63. Bc6 Nd4 64. Bb7 Nf3+ 65. Kh1 Kf2 66. Bc6 g4 67. Bd7 g3 68. Bh3 Nh4 69. Bg2 Nxg2 70. 1/2-1/2 Nf6 Nc3 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 580,
            "total_tokens": 696,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kh1",
            "Kf2",
            "Bc6",
            "g4",
            "Bd7",
            "g3",
            "Bh3",
            "Nh4",
            "Bg2",
            "Nxg2",
            "Nf6",
            "Nc3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nf6 3. c4 c6 4. Nc3 e6 5. Bg5 Be7 6. e3 O-O 7. Bd3 Nbd7 8. O-O dxc4 9. Bxc4 Nd5 10. Bxe7 Qxe7 11. Rc1 Nxc3 12. Rxc3 e5 13. dxe5 Nxe5 14. Nxe5 Qxe5 15. f4 Qe7 16. f5 Qf6 17. e4 Rd8 18. Qh5 Bd7 19. Rh3 h6 20. Rg3 Be8 21. Rg6 Qd4+ 22. Kh1 Qxc4 23. Rxg7+ Kxg7 24. f6+ Kh7 25. Qf5+ Kh8 26. Qf4 Kh7 27. Qf5+ Kh8 28. Qf4 Kh7 29. Qf5+ Kh8 30. Qf4 Kh7 31. Qf5+ Kh8 32. Qf4 Kh7 33. Qf5+ Kh8 34. Qf4 Kh7 35. Qf5+ Kh8 36. Qf4 Kh7 37. Qf5+ Kh8 38. Qf4 Kh7 39. Qf5+ Kh8 40. Qf4 Kh7 41. Qf5+ Kh8 42. Qf4 Kh7 43. Qf5+ Kh8 44. Qf4 Kh7 45. Qf5+ Kh8 46. Qf4 Kh7 47. Qf5+ Kh8 48. Qf4 Kh7 49. Qf5+ Kh8 50. Qf4 Kh7 51. Qf5+ Kh8 52. Qf4 Kh7 53. Qf5+ Kh8 54. Qf4 Kh7 55. Qf5+ Kh8 56. Qf4 Kh7 57. Qf5+ Kh8 58. Qf4 Kh7 59. Qf5+ Kh8 60. Qf4 Kh7 61. Qf5+ Kh8 62. Qf4 Kh7 63. Qf5+ Kh8 64. Qf4 Kh7 65. Qf5+ Kh8 66. Qf4 Kh7 67. Qf5+ Kh8 68. Qf4 Kh7 69. Qf5+ Kh8 70. Qf4 Kh7 71. Qf5+ Kh8 72. Qf4 Kh7 73. Qf5+ Kh8 74. Qf4 Kh7 75. Qf5+ Kh8 76. Qf4 Kh7 77. Qf5+ Kh8",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "c4",
            "c6",
            "Nc3",
            "e6",
            "Bg5",
            "Be7",
            "e3",
            "O-O",
            "Bd3",
            "Nbd7",
            "O-O",
            "dxc4",
            "Bxc4",
            "Nd5",
            "Bxe7",
            "Qxe7",
            "Rc1",
            "Nxc3",
            "Rxc3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "f4",
            "Qe7",
            "f5",
            "Qf6",
            "e4",
            "Rd8",
            "Qh5",
            "Bd7",
            "Rh3",
            "h6",
            "Rg3",
            "Be8",
            "Rg6",
            "Qd4+",
            "Kh1",
            "Qxc4",
            "Rxg7+",
            "Kxg7",
            "f6+",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qf4",
            "Kh7",
            "Qf5+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c4",
          "neutral_uci": "c2c4",
          "neutral_response": "2. c4 c6 *\n3. Nc3 Nf6 *\n4. Nf3 e6 *\n5. Bg5 dxc4 *\n6. e4 b5 *\n7. e5 h6 *\n8. Bh4 g5 *\n9. Nxg5 hxg5 *\n10. Bxg5 Nbd7 *\n11. exf6 Bb7 *\n12. g3 c5 *\n13. d5 Qb6 *\n14. Bg2 O-O-O *\n15. O-O b4 *\n16. Na4 Qb5 *\n17. a3 Nb8 *\n18. axb4 cxb4 *\n19. Qe2 Bxd5 *\n20. Bxd5 Rxd5 *\n21. Be3 Nc6 *\n22. Rfc1 Ne5 *\n23. b3 c3 *\n24. Qxb5 Nf3 *\n25. Kg2 Rxb5 *\n26. Kxf3 Rxh2 *\n27. Bxa7 Rf5+ *\n28. Ke2 Rxf6 *\n29. Nb6+ Kb7 *\n30. Nc4 Rf5 *\n31. Be3 Bc5 *\n32. Bxc5 Rxc5 *\n33. Ra4 Rb5 *\n34. Nd6+ Kb6 *\n35. Nxb5 Kxb5 *\n36. Ra7 f5 *\n37. Re7 Rh6 *\n38. Kd3 Kc5 *\n39. Re1 Kd6 *\n40. Rb7 Rh2 *\n41. Re2 e5 *\n42. Rxb4 e4+ *\n43. Kxc3 Ke5 *\n44. Rb5+ Kf6 *\n45. Kd4 Kg5 *\n46. Ke3 Kg4 *\n47. Rb8 Rh7 *\n48. Rg8+ Kh3 *\n49. Kf4 Kg2 *\n50. Kxf5 Kf3 *\n51. Rxe4 Rf7+ *\n52. Ke5 Re7+ *\n53. Kd5 Rxe4 *\n54. Rf8+ Ke2 *\n55. Kxe4 Kd2 *\n56. Rc8 Ke2 *\n57. Rc2+ Kd1 *\n58. Kd3 Ke1 *\n59. f4 Kf1 *\n60. Ke3 Kg1 *\n61. Kf3 Kh1 *\n62. g4 Kg1 *\n63. g5 Kh1 *\n64. Kg3 Kg1 *\n65. Rc1# 1-0\n\ne4 d5 Nc3 d4 Nce2 c5 d3 Nc6 f4 e5 Nf3 Bd6 fxe5 Nxe5 Nxe5 Bxe5 g3 Nf6 Bg2 Bg",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c6",
            "Nc3",
            "Nf6",
            "Nf3",
            "e6",
            "Bg5",
            "dxc4",
            "e4",
            "b5",
            "e5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Nbd7",
            "exf6",
            "Bb7",
            "g3",
            "c5",
            "d5",
            "Qb6",
            "Bg2",
            "O-O-O",
            "O-O",
            "b4",
            "Na4",
            "Qb5",
            "a3",
            "Nb8",
            "axb4",
            "cxb4",
            "Qe2",
            "Bxd5",
            "Bxd5",
            "Rxd5",
            "Be3",
            "Nc6",
            "Rfc1",
            "Ne5",
            "b3",
            "c3",
            "Qxb5",
            "Nf3",
            "Kg2",
            "Rxb5",
            "Kxf3",
            "Rxh2",
            "Bxa7",
            "Rf5+",
            "Ke2",
            "Rxf6",
            "Nb6+",
            "Kb7",
            "Nc4",
            "Rf5",
            "Be3",
            "Bc5",
            "Bxc5",
            "Rxc5",
            "Ra4",
            "Rb5",
            "Nd6+",
            "Kb6",
            "Nxb5",
            "Kxb5",
            "Ra7",
            "f5",
            "Re7",
            "Rh6",
            "Kd3",
            "Kc5",
            "Re1",
            "Kd6",
            "Rb7",
            "Rh2",
            "Re2",
            "e5",
            "Rxb4",
            "e4+",
            "Kxc3",
            "Ke5",
            "Rb5+",
            "Kf6",
            "Kd4",
            "Kg5",
            "Ke3",
            "Kg4",
            "Rb8",
            "Rh7",
            "Rg8+",
            "Kh3",
            "Kf4",
            "Kg2",
            "Kxf5",
            "Kf3",
            "Rxe4",
            "Rf7+",
            "Ke5",
            "Re7+",
            "Kd5",
            "Rxe4",
            "Rf8+",
            "Ke2",
            "Kxe4",
            "Kd2",
            "Rc8",
            "Ke2",
            "Rc2+",
            "Kd1",
            "Kd3",
            "Ke1",
            "f4",
            "Kf1",
            "Ke3",
            "Kg1",
            "Kf3",
            "Kh1",
            "g4",
            "Kg1",
            "g5",
            "Kh1",
            "Kg3",
            "Kg1",
            "Rc1#",
            "e4",
            "d5",
            "Nc3",
            "d4",
            "Nce2",
            "c5",
            "d3",
            "Nc6",
            "f4",
            "e5",
            "Nf3",
            "Bd6",
            "fxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "g3",
            "Nf6",
            "Bg2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "c2c4",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kh1",
              "Kf2",
              "Bc6",
              "g4",
              "Bd7",
              "g3",
              "Bh3",
              "Nh4",
              "Bg2",
              "Nxg2",
              "Nf6",
              "Nc3",
              "Nc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "c4",
              "c6",
              "Nc3",
              "e6",
              "Bg5",
              "Be7",
              "e3",
              "O-O",
              "Bd3",
              "Nbd7",
              "O-O",
              "dxc4",
              "Bxc4",
              "Nd5",
              "Bxe7",
              "Qxe7",
              "Rc1",
              "Nxc3",
              "Rxc3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "f4",
              "Qe7",
              "f5",
              "Qf6",
              "e4",
              "Rd8",
              "Qh5",
              "Bd7",
              "Rh3",
              "h6",
              "Rg3",
              "Be8",
              "Rg6",
              "Qd4+",
              "Kh1",
              "Qxc4",
              "Rxg7+",
              "Kxg7",
              "f6+",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qf4",
              "Kh7",
              "Qf5+",
              "Kh8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c6",
              "Nc3",
              "Nf6",
              "Nf3",
              "e6",
              "Bg5",
              "dxc4",
              "e4",
              "b5",
              "e5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Nbd7",
              "exf6",
              "Bb7",
              "g3",
              "c5",
              "d5",
              "Qb6",
              "Bg2",
              "O-O-O",
              "O-O",
              "b4",
              "Na4",
              "Qb5",
              "a3",
              "Nb8",
              "axb4",
              "cxb4",
              "Qe2",
              "Bxd5",
              "Bxd5",
              "Rxd5",
              "Be3",
              "Nc6",
              "Rfc1",
              "Ne5",
              "b3",
              "c3",
              "Qxb5",
              "Nf3",
              "Kg2",
              "Rxb5",
              "Kxf3",
              "Rxh2",
              "Bxa7",
              "Rf5+",
              "Ke2",
              "Rxf6",
              "Nb6+",
              "Kb7",
              "Nc4",
              "Rf5",
              "Be3",
              "Bc5",
              "Bxc5",
              "Rxc5",
              "Ra4",
              "Rb5",
              "Nd6+",
              "Kb6",
              "Nxb5",
              "Kxb5",
              "Ra7",
              "f5",
              "Re7",
              "Rh6",
              "Kd3",
              "Kc5",
              "Re1",
              "Kd6",
              "Rb7",
              "Rh2",
              "Re2",
              "e5",
              "Rxb4",
              "e4+",
              "Kxc3",
              "Ke5",
              "Rb5+",
              "Kf6",
              "Kd4",
              "Kg5",
              "Ke3",
              "Kg4",
              "Rb8",
              "Rh7",
              "Rg8+",
              "Kh3",
              "Kf4",
              "Kg2",
              "Kxf5",
              "Kf3",
              "Rxe4",
              "Rf7+",
              "Ke5",
              "Re7+",
              "Kd5",
              "Rxe4",
              "Rf8+",
              "Ke2",
              "Kxe4",
              "Kd2",
              "Rc8",
              "Ke2",
              "Rc2+",
              "Kd1",
              "Kd3",
              "Ke1",
              "f4",
              "Kf1",
              "Ke3",
              "Kg1",
              "Kf3",
              "Kh1",
              "g4",
              "Kg1",
              "g5",
              "Kh1",
              "Kg3",
              "Kg1",
              "Rc1#",
              "e4",
              "d5",
              "Nc3",
              "d4",
              "Nce2",
              "c5",
              "d3",
              "Nc6",
              "f4",
              "e5",
              "Nf3",
              "Bd6",
              "fxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "g3",
              "Nf6",
              "Bg2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 580,
            "total_tokens": 696,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1860,
          "total_tokens": 2207
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 580,
            "total_tokens": 696,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bf4",
          "aggressive_uci": "c1f4",
          "aggressive_response": "3. Bf4 Bf5 4. e3 e6 5. Bd3 Bxd3 6. Qxd3 c6 7. Nbd2 Bd6 8. Bg3 O-O 9. O-O Bxg3 10. hxg3 Nbd7 11. c4 Re8 12. Rac1 Rc8 13. Rfd1 Qe7 14. a3 a6 15. b4 h6 16. c5 e5 17. dxe5 Nxe5 18. Nxe5 Qxe5 19. Nf3 Qe4 20. Qxe4 Nxe4 21. Nd4 g6 22. g4 Kg7 23. f3 Nf6 24. Kf2 Re7 25. Re1 Rce8 26. Rc3 Nd7 27. a4 Ne5 28. b5 axb5 29. axb5 Ra8 30. bxc6 bxc6 31. Rb1 Ra2+ 32. Kg3 Nc4 33. Nxc6 Rxe3 34. Rxe3 Nxe3 35. Nb4 Rxg2+ 36. Kf4 d4 37. c6 Nc4 38. Rc1 Nd6 39. c7 Re2 40. c8=Q Nxc8 41. Rxc8 Rb2 42. Nd3 Rb3 43. Ke4 f5+ 44. gxf5 gxf5+ 45. Kxd4 Kf6 46. Rc6+ Kg5 47. f4+ Kh5 48. Rf6 Kg4 49. Rxh6 Ra3 50. Rg6+ Kh5 51. Rg5+ Kh6 52. Rxf5 Kg6 53. Rg5+ Kf6 54. Rc5 Ra4+ 55. Rc4 Ra3 56. Ke4 Ra1 57. Rc6+ Ke7 58. f5 Ra4+ 59. Ke5 Ra5+ 60. Nc5 Ra1 61. f6+ Kf7 62. Rc7+ Kf8 63. Ne6+ Kg8 64. f7+ Kh7 65. f8=Q+ Kg6 66. Rg7+ Kh5 67. Qh8# Qe7+ 68. Rxe7 Ra5+ 69. Kf6 Kg4 70. Qg7+ Kf3 71. Nd4+ Kf2 72. Re2+ Kf1 73. Qg2# Qe7+ 74. Rxe7 Ra6+ 75. Ne6 Ra2 76. Qxa2 Ke1 77. Rb7 Kd1 78. Rb1# Qe7+ 79.",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bf5",
            "e3",
            "e6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "c6",
            "Nbd2",
            "Bd6",
            "Bg3",
            "O-O",
            "O-O",
            "Bxg3",
            "hxg3",
            "Nbd7",
            "c4",
            "Re8",
            "Rac1",
            "Rc8",
            "Rfd1",
            "Qe7",
            "a3",
            "a6",
            "b4",
            "h6",
            "c5",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "Nf3",
            "Qe4",
            "Qxe4",
            "Nxe4",
            "Nd4",
            "g6",
            "g4",
            "Kg7",
            "f3",
            "Nf6",
            "Kf2",
            "Re7",
            "Re1",
            "Rce8",
            "Rc3",
            "Nd7",
            "a4",
            "Ne5",
            "b5",
            "axb5",
            "axb5",
            "Ra8",
            "bxc6",
            "bxc6",
            "Rb1",
            "Ra2+",
            "Kg3",
            "Nc4",
            "Nxc6",
            "Rxe3",
            "Rxe3",
            "Nxe3",
            "Nb4",
            "Rxg2+",
            "Kf4",
            "d4",
            "c6",
            "Nc4",
            "Rc1",
            "Nd6",
            "c7",
            "Re2",
            "c8=Q",
            "Nxc8",
            "Rxc8",
            "Rb2",
            "Nd3",
            "Rb3",
            "Ke4",
            "f5+",
            "gxf5",
            "gxf5+",
            "Kxd4",
            "Kf6",
            "Rc6+",
            "Kg5",
            "f4+",
            "Kh5",
            "Rf6",
            "Kg4",
            "Rxh6",
            "Ra3",
            "Rg6+",
            "Kh5",
            "Rg5+",
            "Kh6",
            "Rxf5",
            "Kg6",
            "Rg5+",
            "Kf6",
            "Rc5",
            "Ra4+",
            "Rc4",
            "Ra3",
            "Ke4",
            "Ra1",
            "Rc6+",
            "Ke7",
            "f5",
            "Ra4+",
            "Ke5",
            "Ra5+",
            "Nc5",
            "Ra1",
            "f6+",
            "Kf7",
            "Rc7+",
            "Kf8",
            "Ne6+",
            "Kg8",
            "f7+",
            "Kh7",
            "f8=Q+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Qh8#",
            "Qe7+",
            "Rxe7",
            "Ra5+",
            "Kf6",
            "Kg4",
            "Qg7+",
            "Kf3",
            "Nd4+",
            "Kf2",
            "Re2+",
            "Kf1",
            "Qg2#",
            "Qe7+",
            "Rxe7",
            "Ra6+",
            "Ne6",
            "Ra2",
            "Qxa2",
            "Ke1",
            "Rb7",
            "Kd1",
            "Rb1#",
            "Qe7+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 Rf7 18. Rae1 Raf8 19. g3 c4 20. Bc2 Nc5 21. Nf3 Ne4 22. Nd4 Re8 23. Bxe4 dxe4 24. Re3 Bd5 25. Qg2 Qb7 26. Qe2 b5 27. a3 a5 28. h4 b4 29. axb4 axb4 30. h5 bxc3 31. bxc3 Rb8 32. hxg6 hxg6 33. Qg4 Rg7 34. Nxe6 Qd7 35. f5 gxf5 36. Qxg7+ Qxg7 37. Nxg7 Kxg7 38. Rxf5 Rb1+ 39. Rf1 Rb2 40. Rd1 Bc6 41. Rd6 Ba4 42. Rxe4 Bc2 43. Rxc4 Bf5 44. Rc7+ Kf8 45. Rd8# e4 e5 e6",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 359,
            "total_tokens": 484,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "O-O",
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "Rf7",
            "Rae1",
            "Raf8",
            "g3",
            "c4",
            "Bc2",
            "Nc5",
            "Nf3",
            "Ne4",
            "Nd4",
            "Re8",
            "Bxe4",
            "dxe4",
            "Re3",
            "Bd5",
            "Qg2",
            "Qb7",
            "Qe2",
            "b5",
            "a3",
            "a5",
            "h4",
            "b4",
            "axb4",
            "axb4",
            "h5",
            "bxc3",
            "bxc3",
            "Rb8",
            "hxg6",
            "hxg6",
            "Qg4",
            "Rg7",
            "Nxe6",
            "Qd7",
            "f5",
            "gxf5",
            "Qxg7+",
            "Qxg7",
            "Nxg7",
            "Kxg7",
            "Rxf5",
            "Rb1+",
            "Rf1",
            "Rb2",
            "Rd1",
            "Bc6",
            "Rd6",
            "Ba4",
            "Rxe4",
            "Bc2",
            "Rxc4",
            "Bf5",
            "Rc7+",
            "Kf8",
            "Rd8#",
            "e4",
            "e5",
            "e6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bg5",
          "neutral_uci": "c1g5",
          "neutral_response": "3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 c4 18. Bc2 Nc5 19. Nf3 Rxf4 20. Nd4 Raf8 21. Rxf4 Rxf4 22. Qe3 Qf7 23. g3 Rg4 24. Rf1 Qe7 25. Rf6 Bc8 26. Qf3 Rg5 27. Qf4 Rh5 28. g4 Rh3 29. Kg2 Nd3 30. Bxd3 Rxd3 31. Qh6 Bd7 32. h4 b5 33. h5 gxh5 34. gxh5 Qg7+ 35. Qxg7+ Kxg7 36. h6+ Kg8 37. Nxe6 Bxe6 38. Rxe6 Rd2+ 39. Kf3 Rxb2 40. Rd6 Rxa2 41. e6 Kf8 42. Rd7 Ra6 43. Rxh7 Rxe6 44. Rxa7 Rxh6 45. Ke3 Rh3+ 46. Kd4 Rd3+ 47. Kc5 Rxc3 48. Kxd5 b4 49. Kd4 Rc1 50. Rb7 b3 51. Rb4 Ke7 52. Rb6 Kd7 53. Rb4 Kc6 54. Rb8 Rd1+ 55. Kc3 Rc1+ 56. Kd4 Kc7 57. Rb4 Kd6 58. Rb6+ Kc7 59. Rb4 Kc6 60. Rb8 Rd1+ 61. Kc3 Rc1+ 62. Kd4 Kc7 63. Rb4 Kd6 64. Rb6+ Kc7 65. Rb4 Kc6 66. Rb8 Rd1+ 67. Kc3 Rc1+ 68. Kd4 Kc7 69. Rb4 Kd6 70. Rb6+ Kc7 71. Rb4 Kc6 72. Rb8 Rd1+ 73. Kc3 Rc1+ 74. Kd4 Kc7 75. Rb4 Kd6 76. Rb6+ Kc7 77. Rb4",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "e3",
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "c4",
            "Bc2",
            "Nc5",
            "Nf3",
            "Rxf4",
            "Nd4",
            "Raf8",
            "Rxf4",
            "Rxf4",
            "Qe3",
            "Qf7",
            "g3",
            "Rg4",
            "Rf1",
            "Qe7",
            "Rf6",
            "Bc8",
            "Qf3",
            "Rg5",
            "Qf4",
            "Rh5",
            "g4",
            "Rh3",
            "Kg2",
            "Nd3",
            "Bxd3",
            "Rxd3",
            "Qh6",
            "Bd7",
            "h4",
            "b5",
            "h5",
            "gxh5",
            "gxh5",
            "Qg7+",
            "Qxg7+",
            "Kxg7",
            "h6+",
            "Kg8",
            "Nxe6",
            "Bxe6",
            "Rxe6",
            "Rd2+",
            "Kf3",
            "Rxb2",
            "Rd6",
            "Rxa2",
            "e6",
            "Kf8",
            "Rd7",
            "Ra6",
            "Rxh7",
            "Rxe6",
            "Rxa7",
            "Rxh6",
            "Ke3",
            "Rh3+",
            "Kd4",
            "Rd3+",
            "Kc5",
            "Rxc3",
            "Kxd5",
            "b4",
            "Kd4",
            "Rc1",
            "Rb7",
            "b3",
            "Rb4",
            "Ke7",
            "Rb6",
            "Kd7",
            "Rb4",
            "Kc6",
            "Rb8",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd4",
            "Kc7",
            "Rb4",
            "Kd6",
            "Rb6+",
            "Kc7",
            "Rb4",
            "Kc6",
            "Rb8",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd4",
            "Kc7",
            "Rb4",
            "Kd6",
            "Rb6+",
            "Kc7",
            "Rb4",
            "Kc6",
            "Rb8",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd4",
            "Kc7",
            "Rb4",
            "Kd6",
            "Rb6+",
            "Kc7",
            "Rb4",
            "Kc6",
            "Rb8",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd4",
            "Kc7",
            "Rb4",
            "Kd6",
            "Rb6+",
            "Kc7",
            "Rb4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1f4",
          "positional_uci": "c1g5",
          "neutral_uci": "c1g5",
          "consensus_move": "c1g5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bf5",
              "e3",
              "e6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "c6",
              "Nbd2",
              "Bd6",
              "Bg3",
              "O-O",
              "O-O",
              "Bxg3",
              "hxg3",
              "Nbd7",
              "c4",
              "Re8",
              "Rac1",
              "Rc8",
              "Rfd1",
              "Qe7",
              "a3",
              "a6",
              "b4",
              "h6",
              "c5",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "Nf3",
              "Qe4",
              "Qxe4",
              "Nxe4",
              "Nd4",
              "g6",
              "g4",
              "Kg7",
              "f3",
              "Nf6",
              "Kf2",
              "Re7",
              "Re1",
              "Rce8",
              "Rc3",
              "Nd7",
              "a4",
              "Ne5",
              "b5",
              "axb5",
              "axb5",
              "Ra8",
              "bxc6",
              "bxc6",
              "Rb1",
              "Ra2+",
              "Kg3",
              "Nc4",
              "Nxc6",
              "Rxe3",
              "Rxe3",
              "Nxe3",
              "Nb4",
              "Rxg2+",
              "Kf4",
              "d4",
              "c6",
              "Nc4",
              "Rc1",
              "Nd6",
              "c7",
              "Re2",
              "c8=Q",
              "Nxc8",
              "Rxc8",
              "Rb2",
              "Nd3",
              "Rb3",
              "Ke4",
              "f5+",
              "gxf5",
              "gxf5+",
              "Kxd4",
              "Kf6",
              "Rc6+",
              "Kg5",
              "f4+",
              "Kh5",
              "Rf6",
              "Kg4",
              "Rxh6",
              "Ra3",
              "Rg6+",
              "Kh5",
              "Rg5+",
              "Kh6",
              "Rxf5",
              "Kg6",
              "Rg5+",
              "Kf6",
              "Rc5",
              "Ra4+",
              "Rc4",
              "Ra3",
              "Ke4",
              "Ra1",
              "Rc6+",
              "Ke7",
              "f5",
              "Ra4+",
              "Ke5",
              "Ra5+",
              "Nc5",
              "Ra1",
              "f6+",
              "Kf7",
              "Rc7+",
              "Kf8",
              "Ne6+",
              "Kg8",
              "f7+",
              "Kh7",
              "f8=Q+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Qh8#",
              "Qe7+",
              "Rxe7",
              "Ra5+",
              "Kf6",
              "Kg4",
              "Qg7+",
              "Kf3",
              "Nd4+",
              "Kf2",
              "Re2+",
              "Kf1",
              "Qg2#",
              "Qe7+",
              "Rxe7",
              "Ra6+",
              "Ne6",
              "Ra2",
              "Qxa2",
              "Ke1",
              "Rb7",
              "Kd1",
              "Rb1#",
              "Qe7+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "O-O",
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "Rf7",
              "Rae1",
              "Raf8",
              "g3",
              "c4",
              "Bc2",
              "Nc5",
              "Nf3",
              "Ne4",
              "Nd4",
              "Re8",
              "Bxe4",
              "dxe4",
              "Re3",
              "Bd5",
              "Qg2",
              "Qb7",
              "Qe2",
              "b5",
              "a3",
              "a5",
              "h4",
              "b4",
              "axb4",
              "axb4",
              "h5",
              "bxc3",
              "bxc3",
              "Rb8",
              "hxg6",
              "hxg6",
              "Qg4",
              "Rg7",
              "Nxe6",
              "Qd7",
              "f5",
              "gxf5",
              "Qxg7+",
              "Qxg7",
              "Nxg7",
              "Kxg7",
              "Rxf5",
              "Rb1+",
              "Rf1",
              "Rb2",
              "Rd1",
              "Bc6",
              "Rd6",
              "Ba4",
              "Rxe4",
              "Bc2",
              "Rxc4",
              "Bf5",
              "Rc7+",
              "Kf8",
              "Rd8#",
              "e4",
              "e5",
              "e6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e6",
              "e3",
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "c4",
              "Bc2",
              "Nc5",
              "Nf3",
              "Rxf4",
              "Nd4",
              "Raf8",
              "Rxf4",
              "Rxf4",
              "Qe3",
              "Qf7",
              "g3",
              "Rg4",
              "Rf1",
              "Qe7",
              "Rf6",
              "Bc8",
              "Qf3",
              "Rg5",
              "Qf4",
              "Rh5",
              "g4",
              "Rh3",
              "Kg2",
              "Nd3",
              "Bxd3",
              "Rxd3",
              "Qh6",
              "Bd7",
              "h4",
              "b5",
              "h5",
              "gxh5",
              "gxh5",
              "Qg7+",
              "Qxg7+",
              "Kxg7",
              "h6+",
              "Kg8",
              "Nxe6",
              "Bxe6",
              "Rxe6",
              "Rd2+",
              "Kf3",
              "Rxb2",
              "Rd6",
              "Rxa2",
              "e6",
              "Kf8",
              "Rd7",
              "Ra6",
              "Rxh7",
              "Rxe6",
              "Rxa7",
              "Rxh6",
              "Ke3",
              "Rh3+",
              "Kd4",
              "Rd3+",
              "Kc5",
              "Rxc3",
              "Kxd5",
              "b4",
              "Kd4",
              "Rc1",
              "Rb7",
              "b3",
              "Rb4",
              "Ke7",
              "Rb6",
              "Kd7",
              "Rb4",
              "Kc6",
              "Rb8",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd4",
              "Kc7",
              "Rb4",
              "Kd6",
              "Rb6+",
              "Kc7",
              "Rb4",
              "Kc6",
              "Rb8",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd4",
              "Kc7",
              "Rb4",
              "Kd6",
              "Rb6+",
              "Kc7",
              "Rb4",
              "Kc6",
              "Rb8",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd4",
              "Kc7",
              "Rb4",
              "Kd6",
              "Rb6+",
              "Kc7",
              "Rb4",
              "Kc6",
              "Rb8",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd4",
              "Kc7",
              "Rb4",
              "Kd6",
              "Rb6+",
              "Kc7",
              "Rb4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 359,
            "total_tokens": 484,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1639,
          "total_tokens": 2013
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 359,
            "total_tokens": 484,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e3",
          "aggressive_uci": "e2e3",
          "aggressive_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 g6 17. Bxg6 hxg6 18. Nxg6 Qg7 19. Nxf8 Rxf8 20. Rf3 Nf6 21. Qh4 Kf7 22. Rg3 Qh7 23. Qxh7+ Nxh7 24. Rh3 Nf6 25. Rf1 Rg8 26. Rg3 Rxg3 27. hxg3 Ng4 28. Re1 Kf6 29. Kf1 Kf5 30. Ke2 Ke4 31. Kd2 Ba6 32. b3 Bd3 33. a3 c4 34. b4 b5 35. Rh1 Nxe3 36. Rh6 Nf1+ 37. Ke1 Nxg3 38. Rxe6+ Kxf4 39. Ra6 Ne4 40. Rxa7 Nxc3 41. Kd2 d4 42. Rd7 Ke4 43. Re7+ Kd5 44. Rd7+ Ke5 45. Re7+ Kd6 46. Re8 Nb1+ 47. Kc1 Nxa3 48. Rd8+ Ke5 49. Re8+ Kf4 50. Rf8+ Ke3 51. Re8+ Be4 52. g4 c3 53. g5 d3 54. Rd8 d2+ 55. Kd1 c2# 0-1\nd4 d5 Nf3 Nf6 Bg5 e6 e3 Be7 Bd3 O-O Nbd2 Nbd7 O-O c5 c3 b6 Ne5 Nxe5 dxe5 Nd7 f4 f6 exf6 Nxf6 Ne5 Bb7 Ne5 Nd7 Qh5 g6 Bxg6 hxg6 Nxg6 Qg7 Nxf8 Rxf8 Rf3 Nf6 Qh4 Kf7 Rg3 Qh7 Qxh7+ Nxh7 Rh3 Nf6 Rf1 Rg8 Rg3 Rxg3 hxg3 Ng4 Re1 Kf6 Kf1 Kf5 Ke2 Ke4 Kd2 Ba6 b3 Bd3 a3 c4 b4 b5 Rh1 Nxe3 Rh6 Nf1+ Ke1 Nxg3 Rxe6+ Kxf4 Ra6 Ne4 Rxa7 Nxc3 Kd2",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Ne5",
            "Bb7",
            "Ne5",
            "Nd7",
            "Qh5",
            "g6",
            "Bxg6",
            "hxg6",
            "Nxg6",
            "Qg7",
            "Nxf8",
            "Rxf8",
            "Rf3",
            "Nf6",
            "Qh4",
            "Kf7",
            "Rg3",
            "Qh7",
            "Qxh7+",
            "Nxh7",
            "Rh3",
            "Nf6",
            "Rf1",
            "Rg8",
            "Rg3",
            "Rxg3",
            "hxg3",
            "Ng4",
            "Re1",
            "Kf6",
            "Kf1",
            "Kf5",
            "Ke2",
            "Ke4",
            "Kd2",
            "Ba6",
            "b3",
            "Bd3",
            "a3",
            "c4",
            "b4",
            "b5",
            "Rh1",
            "Nxe3",
            "Rh6",
            "Nf1+",
            "Ke1",
            "Nxg3",
            "Rxe6+",
            "Kxf4",
            "Ra6",
            "Ne4",
            "Rxa7",
            "Nxc3",
            "Kd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e3",
          "positional_uci": "e2e3",
          "positional_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Bb7 10. f4 Ne4 11. Bxe7 Qxe7 12. Ndf3 f6 13. Nxd7 Qxd7 14. Qe2 Rac8 15. Rad1 Qe7 16. Nd2 Nxd2 17. Rxd2 e5 18. fxe5 fxe5 19. Rxf8+ Rxf8 20. dxe5 Qxe5 21. Rd1 Re8 22. Re1 d4 23. cxd4 cxd4 24. e4 Rf8 25. Rf1 Rxf1+ 26. Kxf1 Qf4+ 27. Kg1 Qc1+ 28. Kf2 Qf4+ 29. Kg1 Qc1+ 30. Kf2 Qf4+ 31. Kg1 Qc1+ 32. Kf2 Qf4+ 33. Kg1 Qc1+ 34. Kf2 Qf4+ 35. Kg1 Qc1+ 36. Kf2 Qf4+ 37. Kg1 Qc1+ 38. Kf2 Qf4+ 39. Kg1 Qc1+ 40. Kf2 Qf4+ 41. Kg1 Qc1+ 42. Kf2 Qf4+ 43. Kg1 Qc1+ 44. Kf2 Qf4+ 45. Kg1 Qc1+ 46. Kf2 Qf4+ 47. Kg1 Qc1+ 48. Kf2 Qf4+ 49. Kg1 Qc1+ 50. Kf2 Qf4+ 51. Kg1 Qc1+ 52. Kf2 Qf4+ 53. Kg1 Qc1+ 54. Kf2 Qf4+ 55. Kg1 Qc1+ 56. Kf2 Qf4+ 57. Kg1 Qc1+ 58. Kf2 Qf4+ 59. Kg1 Qc1+ 60. Kf2 Qf4+ 61. Kg1 Qc1+ 62. Kf2 Qf4+ 63. Kg1 Qc1+ 64. Kf2 Qf4+ 65. Kg1 Qc1+ 66. Kf2 Qf4+ 67. Kg1 Qc1+ 68. Kf2 Qf4+ 69. Kg1 Qc1+ 70. Kf2 Qf4+ 71. Kg1 Qc1+ 72. Kf2 Qf4+ 73. Kg1 Qc1+ 74. Kf",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Bb7",
            "f4",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Ndf3",
            "f6",
            "Nxd7",
            "Qxd7",
            "Qe2",
            "Rac8",
            "Rad1",
            "Qe7",
            "Nd2",
            "Nxd2",
            "Rxd2",
            "e5",
            "fxe5",
            "fxe5",
            "Rxf8+",
            "Rxf8",
            "dxe5",
            "Qxe5",
            "Rd1",
            "Re8",
            "Re1",
            "d4",
            "cxd4",
            "cxd4",
            "e4",
            "Rf8",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+",
            "Kf2",
            "Qf4+",
            "Kg1",
            "Qc1+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e3",
          "neutral_uci": "e2e3",
          "neutral_response": "4. e3 Be7 5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Rad8 16. Qe2 Nd7 17. Qh5 Nf6 18. Qh4 Rfe8 19. Rf3 Ne4 20. Qh5 g6 21. Qh6 Qg7 22. Qh4 Qf6 23. Qh6 Qg7 24. Qh4 Qf6 25. Qh6 Qg7 26. Qh4 Qf6 27. Qh6 Qg7 28. Qh4 Qf6 29. Qh6 Qg7 30. Qh4 Qf6 31. Qh6 Qg7 32. Qh4 Qf6 33. Qh6 Qg7 34. Qh4 Qf6 35. Qh6 Qg7 36. Qh4 Qf6 37. Qh6 Qg7 38. Qh4 Qf6 39. Qh6 Qg7 40. Qh4 Qf6 41. Qh6 Qg7 42. Qh4 Qf6 43. Qh6 Qg7 44. Qh4 Qf6 45. Qh6 Qg7 46. Qh4 Qf6 47. Qh6 Qg7 48. Qh4 Qf6 49. Qh6 Qg7 50. Qh4 Qf6 51. Qh6 Qg7 52. Qh4 Qf6 53. Qh6 Qg7 54. Qh4 Qf6 55. Qh6 Qg7 56. Qh4 Qf6 57. Qh6 Qg7 58. Qh4 Qf6 59. Qh6 Qg7 60. Qh4 Qf6 61. Qh6 Qg7 62. Qh4 Qf6 63. Qh6 Qg7 64. Qh4 Qf6 65. Qh6 Qg7 66. Qh4 Qf6 67. Qh6 Qg7 68. Qh4 Qf6 69. Qh6 Qg7 70. Qh4 Qf6 71. Qh6 Qg7 72. Qh4 Qf6 73. Qh6 Qg7 74. Qh4 Qf6 75. Qh6 Qg7 76. Qh4 Qf6",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bd3",
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Rad8",
            "Qe2",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rfe8",
            "Rf3",
            "Ne4",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qh4",
            "Qf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e3",
          "positional_uci": "e2e3",
          "neutral_uci": "e2e3",
          "consensus_move": "e2e3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Ne5",
              "Bb7",
              "Ne5",
              "Nd7",
              "Qh5",
              "g6",
              "Bxg6",
              "hxg6",
              "Nxg6",
              "Qg7",
              "Nxf8",
              "Rxf8",
              "Rf3",
              "Nf6",
              "Qh4",
              "Kf7",
              "Rg3",
              "Qh7",
              "Qxh7+",
              "Nxh7",
              "Rh3",
              "Nf6",
              "Rf1",
              "Rg8",
              "Rg3",
              "Rxg3",
              "hxg3",
              "Ng4",
              "Re1",
              "Kf6",
              "Kf1",
              "Kf5",
              "Ke2",
              "Ke4",
              "Kd2",
              "Ba6",
              "b3",
              "Bd3",
              "a3",
              "c4",
              "b4",
              "b5",
              "Rh1",
              "Nxe3",
              "Rh6",
              "Nf1+",
              "Ke1",
              "Nxg3",
              "Rxe6+",
              "Kxf4",
              "Ra6",
              "Ne4",
              "Rxa7",
              "Nxc3",
              "Kd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Bb7",
              "f4",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Ndf3",
              "f6",
              "Nxd7",
              "Qxd7",
              "Qe2",
              "Rac8",
              "Rad1",
              "Qe7",
              "Nd2",
              "Nxd2",
              "Rxd2",
              "e5",
              "fxe5",
              "fxe5",
              "Rxf8+",
              "Rxf8",
              "dxe5",
              "Qxe5",
              "Rd1",
              "Re8",
              "Re1",
              "d4",
              "cxd4",
              "cxd4",
              "e4",
              "Rf8",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+",
              "Kf2",
              "Qf4+",
              "Kg1",
              "Qc1+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "Bd3",
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Rad8",
              "Qe2",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rfe8",
              "Rf3",
              "Ne4",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qh4",
              "Qf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1920,
          "total_tokens": 2318
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p2B1/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bd3",
          "aggressive_uci": "f1d3",
          "aggressive_response": "5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 Rf7 18. Rae1 Raf8 19. Qg4 c4 20. Bc2 Nc5 21. g3 b5 22. Nf3 a5 23. Nd4 b4 24. h4 bxc3 25. bxc3 Bc8 26. h5 Rg7 27. hxg6 hxg6 28. Kg2 Nd3 29. Bxd3 cxd3 30. Rh1 Qa3 31. Qh4 Qxc3 32. Nf3 d4 33. Qh8+ Kf7 34. Ng5+ Ke8 35. Qxg7 Qc6+ 36. Kh3 d2 37. Qxg6+ Kd8 38. Rd1 Rh8+ 39. Kg4 Rxh1 40. Rxh1 Qxh1 41. Qg8+ Kc7 42. Qf7+ Kb8 43. Qe7 d1=Q+ 44. Nf3 Qhxf3+ 45. Kg5 Qxg3+ 46. Kf6 Qh4+ 47. Kf7 Qxe7+ 48. Kxe7 Qf3 49. Kd6 Qxf4 50. a4 d3 51. Kc5 Qxe5+ 52. Kb6 d2 53. Kc6 d1=Q 54. Kb6 Qdd6# d4 d5 d6",
          "aggressive_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 435,
            "total_tokens": 575,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "Rf7",
            "Rae1",
            "Raf8",
            "Qg4",
            "c4",
            "Bc2",
            "Nc5",
            "g3",
            "b5",
            "Nf3",
            "a5",
            "Nd4",
            "b4",
            "h4",
            "bxc3",
            "bxc3",
            "Bc8",
            "h5",
            "Rg7",
            "hxg6",
            "hxg6",
            "Kg2",
            "Nd3",
            "Bxd3",
            "cxd3",
            "Rh1",
            "Qa3",
            "Qh4",
            "Qxc3",
            "Nf3",
            "d4",
            "Qh8+",
            "Kf7",
            "Ng5+",
            "Ke8",
            "Qxg7",
            "Qc6+",
            "Kh3",
            "d2",
            "Qxg6+",
            "Kd8",
            "Rd1",
            "Rh8+",
            "Kg4",
            "Rxh1",
            "Rxh1",
            "Qxh1",
            "Qg8+",
            "Kc7",
            "Qf7+",
            "Kb8",
            "Qe7",
            "d1=Q+",
            "Nf3",
            "Qhxf3+",
            "Kg5",
            "Qxg3+",
            "Kf6",
            "Qh4+",
            "Kf7",
            "Qxe7+",
            "Kxe7",
            "Qf3",
            "Kd6",
            "Qxf4",
            "a4",
            "d3",
            "Kc5",
            "Qxe5+",
            "Kb6",
            "d2",
            "Kc6",
            "d1=Q",
            "Kb6",
            "Qdd6#",
            "d4",
            "d5",
            "d6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bd3",
          "positional_uci": "f1d3",
          "positional_response": "5. Bd3 O-O 6. Nbd2 Nbd7 7. O-O c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 Nf6 17. Qh4 Rae8 18. Rf3 Ne4 19. Qh5 Rf5 20. Qh3 Rf6 21. g4 Rh6 22. Qg2 g5 23. Raf1 Rf8 24. fxg5 Rxf3 25. Qxf3 Nxg5 26. Qg3 Rh3 27. Qf4 d4 28. e4 Re3 29. h4 Nh3+ 30. Kg2 Nxf4+ 31. Rxf4 Qxh4 32. Nf3 Qh6 33. g5 Qh5 34. Bc4 Bxe4 35. Bxe6+ Kg7 36. Bg4 Bxf3+ 37. Bxf3 Qxg5+ 38. Rg4 Qxg4+ 39. Bxg4 dxc3 40. bxc3 Rxc3 41. Be6 Kf6 42. Bg8 h5 43. Kf2 h4 44. Kg2 h3+ 45. Kh2 Kg5 46. Be6 Kh4 47. Bf5 Ra3 48. Be6 b5 49. Bd5 c4 50. Bc6 Rxa2+ 51. Kh1 Kg3 52. Bxb5 Ra1# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O Nbd2 Nbd7 O-O c5 c3 b6 Ne5 Nxe5 dxe5 Nd7 Qh5 Nf6 Qh4 Rf6 g4 Rh6 Qg2 g5 Rf3 Rf8 fxg5 Rxf3 Qxf3 Nxg5 Qg3 h6 h4 Kh7 hxg5 hxg5 Qxg5 Rg8 Qxg8+ Kxg8 Kf2 Kf7 Ke3 Ke7 Kf4 Kd6 Ke4 a6 Bxa6 Kc6 Bc4 b5 Bxe6 c4 Kd4 Kb6 Bd5 Ka5 e6 Ka4 e7 Kb3 e8=Q Kxc3 Qxb5 Kd2 Qc4 Kd3 Qd4+ Ke2 Qe4+ Kf2 Qf4+ Kg2 Qg4+ Kh2 Qh4+ Kg1 Qg3+ Bg2 Qe1+ Kh2 Qh4+ Kg1 Qe1+",
          "positional_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nbd2",
            "Nbd7",
            "O-O",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Qh5",
            "Nf6",
            "Qh4",
            "Rf6",
            "g4",
            "Rh6",
            "Qg2",
            "g5",
            "Rf3",
            "Rf8",
            "fxg5",
            "Rxf3",
            "Qxf3",
            "Nxg5",
            "Qg3",
            "h6",
            "h4",
            "Kh7",
            "hxg5",
            "hxg5",
            "Qxg5",
            "Rg8",
            "Qxg8+",
            "Kxg8",
            "Kf2",
            "Kf7",
            "Ke3",
            "Ke7",
            "Kf4",
            "Kd6",
            "Ke4",
            "a6",
            "Bxa6",
            "Kc6",
            "Bc4",
            "b5",
            "Bxe6",
            "c4",
            "Kd4",
            "Kb6",
            "Bd5",
            "Ka5",
            "e6",
            "Ka4",
            "e7",
            "Kb3",
            "e8=Q",
            "Kxc3",
            "Qxb5",
            "Kd2",
            "Qc4",
            "Kd3",
            "Qd4+",
            "Ke2",
            "Qe4+",
            "Kf2",
            "Qf4+",
            "Kg2",
            "Qg4+",
            "Kh2",
            "Qh4+",
            "Kg1",
            "Qg3+",
            "Bg2",
            "Qe1+",
            "Kh2",
            "Qh4+",
            "Kg1",
            "Qe1+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bd3",
          "neutral_uci": "f1d3",
          "neutral_response": "5. Bd3 O-O 6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 Nf6 17. Qh4 Rae8 18. Rf3 Ne4 19. Qh5 Rf5 20. Qh3 Rf6 21. g4 Rh6 22. Qg2 Qh4 23. g5 Rh5 24. Be2 d4 25. Rg3 Nxg3 26. Qxg3 Qxg3+ 27. hxg3 Rh1+ 28. Kf2 Rxa1 29. exd4 cxd4 30. cxd4 Rxa2 31. Ke3 Rxb2 32. Bc4 Bd5 33. Bd3 a5 34. g6 hxg6 35. Bxg6 Rc8 36. Bf7+ Kf8 37. Bg6 Rc3+ 38. Bd3 Bc4 39. Nxc4 Rxc4 40. Bxc4 a4 41. Bxe6 a3 42. d5 a2 43. d6 a1=Q 44. d7 Qe1+ 45. Kf3 Qe2# 1-0 1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. Nf3 Bb7 15. Ne5 Nd7 16. Qh5 Nf6 17. Qh4 Rae8 18. Rf3 Ne4 19. Qh5 Rf5 20. Qh3 Rf6 21. g4 Rh6 22. Qg2 Qh4 23. g5 Rh5 24. Be2 d4 25. Rg3 Nxg3 26. Qxg3 Qxg3+ 27. hxg3 Rh1+ 28. Kf2 Rxa1 29. exd4 cxd4 30. cxd4 Rxa2 31. Ke3 Rxb2 32. Bc4 Bd5 33. Bd3 a5 34. g6 hxg6 35. Bxg6 Rc8 36. B",
          "neutral_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a5",
            "g6",
            "hxg6",
            "Bxg6",
            "Rc8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1d3",
          "positional_uci": "f1d3",
          "neutral_uci": "f1d3",
          "consensus_move": "f1d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "Rf7",
              "Rae1",
              "Raf8",
              "Qg4",
              "c4",
              "Bc2",
              "Nc5",
              "g3",
              "b5",
              "Nf3",
              "a5",
              "Nd4",
              "b4",
              "h4",
              "bxc3",
              "bxc3",
              "Bc8",
              "h5",
              "Rg7",
              "hxg6",
              "hxg6",
              "Kg2",
              "Nd3",
              "Bxd3",
              "cxd3",
              "Rh1",
              "Qa3",
              "Qh4",
              "Qxc3",
              "Nf3",
              "d4",
              "Qh8+",
              "Kf7",
              "Ng5+",
              "Ke8",
              "Qxg7",
              "Qc6+",
              "Kh3",
              "d2",
              "Qxg6+",
              "Kd8",
              "Rd1",
              "Rh8+",
              "Kg4",
              "Rxh1",
              "Rxh1",
              "Qxh1",
              "Qg8+",
              "Kc7",
              "Qf7+",
              "Kb8",
              "Qe7",
              "d1=Q+",
              "Nf3",
              "Qhxf3+",
              "Kg5",
              "Qxg3+",
              "Kf6",
              "Qh4+",
              "Kf7",
              "Qxe7+",
              "Kxe7",
              "Qf3",
              "Kd6",
              "Qxf4",
              "a4",
              "d3",
              "Kc5",
              "Qxe5+",
              "Kb6",
              "d2",
              "Kc6",
              "d1=Q",
              "Kb6",
              "Qdd6#",
              "d4",
              "d5",
              "d6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Nbd2",
              "Nbd7",
              "O-O",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Qh5",
              "Nf6",
              "Qh4",
              "Rf6",
              "g4",
              "Rh6",
              "Qg2",
              "g5",
              "Rf3",
              "Rf8",
              "fxg5",
              "Rxf3",
              "Qxf3",
              "Nxg5",
              "Qg3",
              "h6",
              "h4",
              "Kh7",
              "hxg5",
              "hxg5",
              "Qxg5",
              "Rg8",
              "Qxg8+",
              "Kxg8",
              "Kf2",
              "Kf7",
              "Ke3",
              "Ke7",
              "Kf4",
              "Kd6",
              "Ke4",
              "a6",
              "Bxa6",
              "Kc6",
              "Bc4",
              "b5",
              "Bxe6",
              "c4",
              "Kd4",
              "Kb6",
              "Bd5",
              "Ka5",
              "e6",
              "Ka4",
              "e7",
              "Kb3",
              "e8=Q",
              "Kxc3",
              "Qxb5",
              "Kd2",
              "Qc4",
              "Kd3",
              "Qd4+",
              "Ke2",
              "Qe4+",
              "Kf2",
              "Qf4+",
              "Kg2",
              "Qg4+",
              "Kh2",
              "Qh4+",
              "Kg1",
              "Qg3+",
              "Bg2",
              "Qe1+",
              "Kh2",
              "Qh4+",
              "Kg1",
              "Qe1+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "a5",
              "g6",
              "hxg6",
              "Bxg6",
              "Rc8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 140,
            "completion_tokens": 435,
            "total_tokens": 575,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 419,
          "total_completion_tokens": 1715,
          "total_tokens": 2134
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 140,
            "completion_tokens": 435,
            "total_tokens": 575,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp1bppp/4pn2/3p2B1/3P4/4PN2/PPP2PPP/RN1QKB1R w KQkq - 1 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 Rf7 18. Rae1 Raf8 19. Qg4 c4 20. Bc2 Nc5 21. g3 b5 22. Nf3 a5 23. Nd4 b4 24. h4 bxc3 25. bxc3 Bc8 26. h5 Rg7 27. hxg6 hxg6 28. Kg2 g5 29. f5 exf5 30. Bxf5 Bxf5 31. Nxf5 Qe6 32. Nh6+ Qxh6 33. Rxf8+ Kxf8 34. Qc8+ Kf7 35. Rf1+ Ke7 36. Qxc5+ Kd7 37. Qxd5+ Kc7 38. Qxc4+ Kb7 39. Rb1+ Ka7 40. Qc5+ Ka8 41. Qxa5+ Ra7 42. Qd8# e6 d4 e5",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 317,
            "total_tokens": 464,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "Rf7",
            "Rae1",
            "Raf8",
            "Qg4",
            "c4",
            "Bc2",
            "Nc5",
            "g3",
            "b5",
            "Nf3",
            "a5",
            "Nd4",
            "b4",
            "h4",
            "bxc3",
            "bxc3",
            "Bc8",
            "h5",
            "Rg7",
            "hxg6",
            "hxg6",
            "Kg2",
            "g5",
            "f5",
            "exf5",
            "Bxf5",
            "Bxf5",
            "Nxf5",
            "Qe6",
            "Nh6+",
            "Qxh6",
            "Rxf8+",
            "Kxf8",
            "Qc8+",
            "Kf7",
            "Rf1+",
            "Ke7",
            "Qxc5+",
            "Kd7",
            "Qxd5+",
            "Kc7",
            "Qxc4+",
            "Kb7",
            "Rb1+",
            "Ka7",
            "Qc5+",
            "Ka8",
            "Qxa5+",
            "Ra7",
            "Qd8#",
            "e6",
            "d4",
            "e5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh3 Rf7 18. Rae1 Raf8 19. Qg4 c4 20. Bc2 Nc5 21. g3 b5 22. Nf3 a5 23. Nd4 b4 24. h4 bxc3 25. bxc3 Rg7 26. Rb1 Bc8 27. Rb6 Qc7 28. Rfb1 Bd7 29. Kh2 Re8 30. h5 gxh5 31. Qxh5 Rf8 32. Qh6 Re8 33. Qh5 Rf8 34. Qh6 Re8 35. Qh5 Rf8 36. Qh6 Re8 37. Qh5 Rf8 38. Qh6 Re8 39. Qh5 Rf8 40. Qh6 Re8 41. Qh5 Rf8 42. Qh6 Re8 43. Qh5 Rf8 44. Qh6 Re8 45. Qh5 Rf8 46. Qh6 Re8 47. Qh5 Rf8 48. Qh6 Re8 49. Qh5 Rf8 50. Qh6 Re8 51. Qh5 Rf8 52. Qh6 Re8 53. Qh5 Rf8 54. Qh6 Re8 55. Qh5 Rf8 56. Qh6 Re8 57. Qh5 Rf8 58. Qh6 Re8 59. Qh5 Rf8 60. Qh6 Re8 61. Qh5 Rf8 62. Qh6 Re8 63. Qh5 Rf8 64. Qh6 Re8 65. Qh5 Rf8 66. Qh6 Re8 67. Qh5 Rf8 68. Qh6 Re8 69. Qh5 Rf8 70. Qh6 Re8 71. Qh5 Rf8 72. Qh6 Re8 73. Qh5 Rf8 74. Qh6 Re8 75. Qh5 Rf8 76. Qh6 Re8 77. Qh5 Rf8 78. Qh6 Re8 79. Qh5 Rf8 80. Qh6 Re8 81. Qh5 Rf8 82. Qh",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh3",
            "Rf7",
            "Rae1",
            "Raf8",
            "Qg4",
            "c4",
            "Bc2",
            "Nc5",
            "g3",
            "b5",
            "Nf3",
            "a5",
            "Nd4",
            "b4",
            "h4",
            "bxc3",
            "bxc3",
            "Rg7",
            "Rb1",
            "Bc8",
            "Rb6",
            "Qc7",
            "Rfb1",
            "Bd7",
            "Kh2",
            "Re8",
            "h5",
            "gxh5",
            "Qxh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8",
            "Qh6",
            "Re8",
            "Qh5",
            "Rf8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "6. O-O Nbd7 7. Nbd2 c5 8. c3 b6 9. Ne5 Nxe5 10. dxe5 Nd7 11. Bxe7 Qxe7 12. f4 f6 13. exf6 Nxf6 14. e4 Bb7 15. e5 Nd7 16. Qh5 g6 17. Qh6 Qg7 18. Qh3 Rae8 19. Nf3 Rxf4 20. Ng5 Rxf1+ 21. Rxf1 Nxe5 22. Nxe6 Qe7 23. Bb5 Bc6 24. Bxc6 Nxc6 25. Nf4 Qe3+ 26. Qxe3 Rxe3 27. Nxd5 Re2 28. Rf2 Rxf2 29. Kxf2 Kf7 30. Ke3 Ke6 31. Nf4+ Kf5 32. h3 Ne5 33. b3 h5 34. Nd5 g5 35. Ne7+ Ke6 36. Nc8 Nc6 37. Ke4 Kd7 38. Nxa7 Nxa7 39. Kf5 Nb5 40. Kxg5 Nxc3 41. Kxh5 Nxa2 42. g4 Nc1 43. g5 Ke7 44. g6 Kf8 45. Kh6 Kg8 46. h4 Nxb3 47. h5 Nd4 48. Kg5 Ne6+ 49. Kf6 Nf8 50. h6 Nxg6 51. Kxg6 c4 52. h7+ Kh8 53. Kf5 c3 54. Ke4 c2 55. Kd3 c1=Q 56. Kd4 Qc5+ 57. Ke4 Kxh7 58. Kd3 Kg6 59. Ke4 Kf6 60. Kd3 Ke5 61. Ke2 Ke4 62. Kd2 Qc4 63. Kd1 Ke3 64. Ke1 Qc1# c4 c5 c6",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 497,
            "total_tokens": 643,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f6",
            "exf6",
            "Nxf6",
            "e4",
            "Bb7",
            "e5",
            "Nd7",
            "Qh5",
            "g6",
            "Qh6",
            "Qg7",
            "Qh3",
            "Rae8",
            "Nf3",
            "Rxf4",
            "Ng5",
            "Rxf1+",
            "Rxf1",
            "Nxe5",
            "Nxe6",
            "Qe7",
            "Bb5",
            "Bc6",
            "Bxc6",
            "Nxc6",
            "Nf4",
            "Qe3+",
            "Qxe3",
            "Rxe3",
            "Nxd5",
            "Re2",
            "Rf2",
            "Rxf2",
            "Kxf2",
            "Kf7",
            "Ke3",
            "Ke6",
            "Nf4+",
            "Kf5",
            "h3",
            "Ne5",
            "b3",
            "h5",
            "Nd5",
            "g5",
            "Ne7+",
            "Ke6",
            "Nc8",
            "Nc6",
            "Ke4",
            "Kd7",
            "Nxa7",
            "Nxa7",
            "Kf5",
            "Nb5",
            "Kxg5",
            "Nxc3",
            "Kxh5",
            "Nxa2",
            "g4",
            "Nc1",
            "g5",
            "Ke7",
            "g6",
            "Kf8",
            "Kh6",
            "Kg8",
            "h4",
            "Nxb3",
            "h5",
            "Nd4",
            "Kg5",
            "Ne6+",
            "Kf6",
            "Nf8",
            "h6",
            "Nxg6",
            "Kxg6",
            "c4",
            "h7+",
            "Kh8",
            "Kf5",
            "c3",
            "Ke4",
            "c2",
            "Kd3",
            "c1=Q",
            "Kd4",
            "Qc5+",
            "Ke4",
            "Kxh7",
            "Kd3",
            "Kg6",
            "Ke4",
            "Kf6",
            "Kd3",
            "Ke5",
            "Ke2",
            "Ke4",
            "Kd2",
            "Qc4",
            "Kd1",
            "Ke3",
            "Ke1",
            "Qc1#",
            "c4",
            "c5",
            "c6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "Rf7",
              "Rae1",
              "Raf8",
              "Qg4",
              "c4",
              "Bc2",
              "Nc5",
              "g3",
              "b5",
              "Nf3",
              "a5",
              "Nd4",
              "b4",
              "h4",
              "bxc3",
              "bxc3",
              "Bc8",
              "h5",
              "Rg7",
              "hxg6",
              "hxg6",
              "Kg2",
              "g5",
              "f5",
              "exf5",
              "Bxf5",
              "Bxf5",
              "Nxf5",
              "Qe6",
              "Nh6+",
              "Qxh6",
              "Rxf8+",
              "Kxf8",
              "Qc8+",
              "Kf7",
              "Rf1+",
              "Ke7",
              "Qxc5+",
              "Kd7",
              "Qxd5+",
              "Kc7",
              "Qxc4+",
              "Kb7",
              "Rb1+",
              "Ka7",
              "Qc5+",
              "Ka8",
              "Qxa5+",
              "Ra7",
              "Qd8#",
              "e6",
              "d4",
              "e5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh3",
              "Rf7",
              "Rae1",
              "Raf8",
              "Qg4",
              "c4",
              "Bc2",
              "Nc5",
              "g3",
              "b5",
              "Nf3",
              "a5",
              "Nd4",
              "b4",
              "h4",
              "bxc3",
              "bxc3",
              "Rg7",
              "Rb1",
              "Bc8",
              "Rb6",
              "Qc7",
              "Rfb1",
              "Bd7",
              "Kh2",
              "Re8",
              "h5",
              "gxh5",
              "Qxh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8",
              "Qh6",
              "Re8",
              "Qh5",
              "Rf8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f6",
              "exf6",
              "Nxf6",
              "e4",
              "Bb7",
              "e5",
              "Nd7",
              "Qh5",
              "g6",
              "Qh6",
              "Qg7",
              "Qh3",
              "Rae8",
              "Nf3",
              "Rxf4",
              "Ng5",
              "Rxf1+",
              "Rxf1",
              "Nxe5",
              "Nxe6",
              "Qe7",
              "Bb5",
              "Bc6",
              "Bxc6",
              "Nxc6",
              "Nf4",
              "Qe3+",
              "Qxe3",
              "Rxe3",
              "Nxd5",
              "Re2",
              "Rf2",
              "Rxf2",
              "Kxf2",
              "Kf7",
              "Ke3",
              "Ke6",
              "Nf4+",
              "Kf5",
              "h3",
              "Ne5",
              "b3",
              "h5",
              "Nd5",
              "g5",
              "Ne7+",
              "Ke6",
              "Nc8",
              "Nc6",
              "Ke4",
              "Kd7",
              "Nxa7",
              "Nxa7",
              "Kf5",
              "Nb5",
              "Kxg5",
              "Nxc3",
              "Kxh5",
              "Nxa2",
              "g4",
              "Nc1",
              "g5",
              "Ke7",
              "g6",
              "Kf8",
              "Kh6",
              "Kg8",
              "h4",
              "Nxb3",
              "h5",
              "Nd4",
              "Kg5",
              "Ne6+",
              "Kf6",
              "Nf8",
              "h6",
              "Nxg6",
              "Kxg6",
              "c4",
              "h7+",
              "Kh8",
              "Kf5",
              "c3",
              "Ke4",
              "c2",
              "Kd3",
              "c1=Q",
              "Kd4",
              "Qc5+",
              "Ke4",
              "Kxh7",
              "Kd3",
              "Kg6",
              "Ke4",
              "Kf6",
              "Kd3",
              "Ke5",
              "Ke2",
              "Ke4",
              "Kd2",
              "Qc4",
              "Kd1",
              "Ke3",
              "Ke1",
              "Qc1#",
              "c4",
              "c5",
              "c6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 317,
            "total_tokens": 464,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 497,
            "total_tokens": 643,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 1454,
          "total_tokens": 1894
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 317,
            "total_tokens": 464,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 497,
            "total_tokens": 643,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1QK2R w KQ - 3 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bh4",
          "aggressive_uci": "g5h4",
          "aggressive_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 Bb7 14. Qh5 f5 15. exf6 Nxf6 16. Qg6 Qf7 17. Qxf7+ Rxf7 18. Nf3 Nd7 19. Bg6 Re7 20. Rad1 Rf8 21. g3 e5 22. Nh4 exf4 23. exf4 Re2 24. Rf2 Rxf2 25. Kxf2 Nf6 26. Nf5 Rd8 27. Re1 Ne4+ 28. Kg1 Kf8 29. Nh4 Nf6 30. Nf5 Ne4 31. Nh4 Nf6 32. Nf5 Ne4 33. Nh4 Nf6 34. Nf5 Ne4 35. Nh4 Nf6 36. Nf5 Ne4 37. Nh4 Nf6 38. Nf5 Ne4 39. Nh4 Nf6 40. Nf5 Ne4 41. Nh4 Nf6 42. Nf5 Ne4 43. Nh4 Nf6 44. Nf5 Ne4 45. Nh4 Nf6 46. Nf5 Ne4 47. Nh4 Nf6 48. Nf5 Ne4 49. Nh4 Nf6 50. Nf5 Ne4 51. Nh4 Nf6 52. Nf5 Ne4 53. Nh4 Nf6 54. Nf5 Ne4 55. Nh4 Nf6 56. Nf5 Ne4 57. Nh4 Nf6 58. Nf5 Ne4 59. Nh4 Nf6 60. Nf5 Ne4 61. Nh4 Nf6 62. Nf5 Ne4 63. Nh4 Nf6 64. Nf5 Ne4 65. Nh4 Nf6 66. Nf5 Ne4 67. Nh4 Nf6 68. Nf5 Ne4 69. Nh4 Nf6 70. Nf5 Ne4 71. Nh4 Nf6 72. Nf5 Ne4 73. Nh4 Nf6 74. Nf5 Ne4 75. Nh4 Nf6 76. Nf5 Ne4 77. Nh4 Nf6 78. Nf5 Ne4 79. Nh4 Nf6 80. Nf5 Ne4 81. Nh4 Nf6 82. Nf5 Ne4 83. Nh4 Nf6 84. Nf5 Ne4 85. Nh4 Nf6 86.",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "Bb7",
            "Qh5",
            "f5",
            "exf6",
            "Nxf6",
            "Qg6",
            "Qf7",
            "Qxf7+",
            "Rxf7",
            "Nf3",
            "Nd7",
            "Bg6",
            "Re7",
            "Rad1",
            "Rf8",
            "g3",
            "e5",
            "Nh4",
            "exf4",
            "exf4",
            "Re2",
            "Rf2",
            "Rxf2",
            "Kxf2",
            "Nf6",
            "Nf5",
            "Rd8",
            "Re1",
            "Ne4+",
            "Kg1",
            "Kf8",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6",
            "Nf5",
            "Ne4",
            "Nh4",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bh4",
          "positional_uci": "g5h4",
          "positional_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 c4 10. Bc2 b5 11. a3 a5 12. Ne5 Nxe5 13. dxe5 Nd7 14. Bxe7 Qxe7 15. f4 f5 16. exf6 Nxf6 17. Nf3 Bb7 18. Ne5 Qc5 19. Qd4 Qxd4 20. exd4 Rfd8 21. Rae1 Rd6 22. g4 Nd7 23. Ng6 Nf8 24. Ne7+ Kf7 25. f5 Kxe7 26. fxe6 Rxe6 27. Rxe6+ Nxe6 28. Bf5 Rf8 29. Re1 Bc8 30. Re5 Kd6 31. h4 Nf4 32. Bxc8 Rxc8 33. Rf5 Nd3 34. Rf7 Rc7 35. Rf8 Nxb2 36. Rb8 Kc6 37. Ra8 a4 38. Ra6+ Kb7 39. Rd6 Nd1 40. Rxd5 Nxc3 41. Re5 Rd7 42. g5 hxg5 43. hxg5 Rxd4 44. Re7+ Kc6 45. Rxg7 Rg4+ 46. Kf2 Ne4+ 47. Kf3 Rxg5 48. Re7 Nd2+ 49. Ke3 Nb1 50. Re6+ Kd5 51. Rb6 Kc5 52. Rb8 Nxa3 53. Rc8+ Kb4 54. Kd2 Rg2+ 55. Kc1 Kc3 56. Kd1 b4 57. Ra8 b3 58. Rxa4 b2 59. Rxa3+ Kb4 60. Ra8 b1=Q# 0-1 7. Bh4 Nbd7 8. Nbd2 c5 9. c3 c4 10. Bc2 b5 11. a3 a5 12. Ne5 Nxe5 13. dxe5 Nd7 14. Bxe7 Qxe7 15. f4 f5 16. exf6 Nxf6 17. Nf3 Bb7 18. Ne5 Qc5 19. Qd4 Qxd4 20. exd4 Rfd8 21. Rae1 Rd6 22. g4 Nd7 23. Ng6 Nf8 24. Ne7+ Kf7 25. f5 Kxe7 26. fxe6 Rxe6 27. Rxe6+ Nxe6 28. Bf5 Rf8 29. Re",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "c4",
            "Bc2",
            "b5",
            "a3",
            "a5",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "f5",
            "exf6",
            "Nxf6",
            "Nf3",
            "Bb7",
            "Ne5",
            "Qc5",
            "Qd4",
            "Qxd4",
            "exd4",
            "Rfd8",
            "Rae1",
            "Rd6",
            "g4",
            "Nd7",
            "Ng6",
            "Nf8",
            "Ne7+",
            "Kf7",
            "f5",
            "Kxe7",
            "fxe6",
            "Rxe6",
            "Rxe6+",
            "Nxe6",
            "Bf5",
            "Rf8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bh4",
          "neutral_uci": "g5h4",
          "neutral_response": "7. Bh4 Nbd7 8. Nbd2 c5 9. c3 b6 10. Ne5 Nxe5 11. dxe5 Nd7 12. Bxe7 Qxe7 13. f4 Bb7 14. Qh5 f5 15. exf6 Nxf6 16. Qg6 Qf7 17. Qxf7+ Rxf7 18. Nf3 Nd7 19. Bg6 Re7 20. Rad1 Rf8 21. g3 e5 22. fxe5 Nxe5 23. Nxe5 Rxe5 24. Rxf8+ Kxf8 25. Rf1+ Kg8 26. Rf7 Bc6 27. Rc7 Be8 28. Rc8 Kf8 29. Kf2 Re6 30. Bxe8 Rxe8 31. Rc7 Re7 32. Rc8+ Kf7 33. Rd8 Ke6 34. Kf3 Rf7+ 35. Ke2 Rd7 36. Re8+ Re7 37. Rf8 Rf7 38. Re8+ Re7 39. Rf8 Rf7 40. Re8+ Re7 41. Rf8 Rf7 42. Re8+ Re7 43. Rf8 Rf7 44. Re8+ Re7 45. Rf8 Rf7 46. Re8+ Re7 47. Rf8 Rf7 48. Re8+ Re7 49. Rf8 Rf7 50. Re8+ Re7 51. Rf8 Rf7 52. Re8+ Re7 53. Rf8 Rf7 54. Re8+ Re7 55. Rf8 Rf7 56. Re8+ Re7 57. Rf8 Rf7 58. Re8+ Re7 59. Rf8 Rf7 60. Re8+ Re7 61. Rf8 Rf7 62. Re8+ Re7 63. Rf8 Rf7 64. Re8+ Re7 65. Rf8 Rf7 66. Re8+ Re7 67. Rf8 Rf7 68. Re8+ Re7 69. Rf8 Rf7 70. Re8+ Re7 71. Rf8 Rf7 72. Re8+ Re7 73. Rf8 Rf7 74. Re8+ Re7 75. Rf8 Rf7 76. Re8+ Re7 77. Rf8 Rf7 78. Re8+ Re7 79. Rf8 Rf7 80. Re8+ Re7 81. Rf8 Rf7 82. Re8+ Re7",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 640,
            "total_tokens": 793,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Nbd2",
            "c5",
            "c3",
            "b6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Nd7",
            "Bxe7",
            "Qxe7",
            "f4",
            "Bb7",
            "Qh5",
            "f5",
            "exf6",
            "Nxf6",
            "Qg6",
            "Qf7",
            "Qxf7+",
            "Rxf7",
            "Nf3",
            "Nd7",
            "Bg6",
            "Re7",
            "Rad1",
            "Rf8",
            "g3",
            "e5",
            "fxe5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Rxf8+",
            "Kxf8",
            "Rf1+",
            "Kg8",
            "Rf7",
            "Bc6",
            "Rc7",
            "Be8",
            "Rc8",
            "Kf8",
            "Kf2",
            "Re6",
            "Bxe8",
            "Rxe8",
            "Rc7",
            "Re7",
            "Rc8+",
            "Kf7",
            "Rd8",
            "Ke6",
            "Kf3",
            "Rf7+",
            "Ke2",
            "Rd7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7",
            "Rf8",
            "Rf7",
            "Re8+",
            "Re7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5h4",
          "positional_uci": "g5h4",
          "neutral_uci": "g5h4",
          "consensus_move": "g5h4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "Bb7",
              "Qh5",
              "f5",
              "exf6",
              "Nxf6",
              "Qg6",
              "Qf7",
              "Qxf7+",
              "Rxf7",
              "Nf3",
              "Nd7",
              "Bg6",
              "Re7",
              "Rad1",
              "Rf8",
              "g3",
              "e5",
              "Nh4",
              "exf4",
              "exf4",
              "Re2",
              "Rf2",
              "Rxf2",
              "Kxf2",
              "Nf6",
              "Nf5",
              "Rd8",
              "Re1",
              "Ne4+",
              "Kg1",
              "Kf8",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6",
              "Nf5",
              "Ne4",
              "Nh4",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "c4",
              "Bc2",
              "b5",
              "a3",
              "a5",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "f5",
              "exf6",
              "Nxf6",
              "Nf3",
              "Bb7",
              "Ne5",
              "Qc5",
              "Qd4",
              "Qxd4",
              "exd4",
              "Rfd8",
              "Rae1",
              "Rd6",
              "g4",
              "Nd7",
              "Ng6",
              "Nf8",
              "Ne7+",
              "Kf7",
              "f5",
              "Kxe7",
              "fxe6",
              "Rxe6",
              "Rxe6+",
              "Nxe6",
              "Bf5",
              "Rf8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Nbd2",
              "c5",
              "c3",
              "b6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Nd7",
              "Bxe7",
              "Qxe7",
              "f4",
              "Bb7",
              "Qh5",
              "f5",
              "exf6",
              "Nxf6",
              "Qg6",
              "Qf7",
              "Qxf7+",
              "Rxf7",
              "Nf3",
              "Nd7",
              "Bg6",
              "Re7",
              "Rad1",
              "Rf8",
              "g3",
              "e5",
              "fxe5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Rxf8+",
              "Kxf8",
              "Rf1+",
              "Kg8",
              "Rf7",
              "Bc6",
              "Rc7",
              "Be8",
              "Rc8",
              "Kf8",
              "Kf2",
              "Re6",
              "Bxe8",
              "Rxe8",
              "Rc7",
              "Re7",
              "Rc8+",
              "Kf7",
              "Rd8",
              "Ke6",
              "Kf3",
              "Rf7+",
              "Ke2",
              "Rd7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7",
              "Rf8",
              "Rf7",
              "Re8+",
              "Re7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 640,
            "total_tokens": 793,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 1920,
          "total_tokens": 2381
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 640,
            "total_tokens": 793,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bpp1/4pn1p/3p2B1/3P4/3BPN2/PPP2PPP/RN1Q1RK1 w - - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c4",
          "aggressive_uci": "c2c4",
          "aggressive_response": "8. c4 c5 9. Nc3 Bb7 10. Rc1 Nbd7 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Kf3 Qf5+ 39. Ke2 Qe4+ 40. Kf1 Qb1+ 41. Ke2 Qc2+ 42. Kf3 Qf5+ 43. Ke2 Qe4+ 44. Kf1 Qb1+ 45. Ke2 Qc2+ 46. Kf3 Qf5+ 47. Ke2 Qe4+ 48. Kf1 Qb1+ 49. Ke2 Qc2+ 50. Kf3 Qf5+ 51. Ke2 Qe4+ 52. Kf1 Qb1+ 53. Ke2 Qc2+ 54. Kf3 Qf5+ 55. Ke2 Qe4+ 56. Kf1 Qb1+ 57. Ke2 Qc2+ 58. Kf3 Qf5+ 59. Ke2 Qe4+ 60. Kf1 Qb1+ 61. Ke2 Qc2+ 62. Kf3 Qf5+ 63. Ke2 Qe4+ 64. Kf1 Qb1+ 65. Ke2 Qc2+ 66. Kf3 Qf5+ 67. Ke2 Qe4+ 68. Kf1 Qb1+ 69. Ke2 Qc2+ 70. Kf3 Qf5+ 71. Ke2 Qe4+ 72. Kf1 Qb1+ 73. Ke2 Qc2+ 74. Kf3 Qf5+ 75. Ke2 Qe4+ 76. Kf1 Qb1+ 77. Ke2",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "Nc3",
            "Bb7",
            "Rc1",
            "Nbd7",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Kf3",
            "Qf5+",
            "Ke2",
            "Qe4+",
            "Kf1",
            "Qb1+",
            "Ke2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c4",
          "positional_uci": "c2c4",
          "positional_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qe6+ Kh7 30. Qf5+ Kg8 31. Qe6+ Kh7 32. Qf5+ Kg8 33. Qe6+ Kh7 34. Qf5+ Kg8 35. Qe6+ Kh7 36. Qf5+ Kg8 37. Qe6+ Kh7 38. Qf5+ Kg8 39. Qe6+ Kh7 40. Qf5+ Kg8 41. Qe6+ Kh7 42. Qf5+ Kg8 43. Qe6+ Kh7 44. Qf5+ Kg8 45. Qe6+ Kh7 46. Qf5+ Kg8 47. Qe6+ Kh7 48. Qf5+ Kg8 49. Qe6+ Kh7 50. Qf5+ Kg8 51. Qe6+ Kh7 52. Qf5+ Kg8 53. Qe6+ Kh7 54. Qf5+ Kg8 55. Qe6+ Kh7 56. Qf5+ Kg8 57. Qe6+ Kh7 58. Qf5+ Kg8 59. Qe6+ Kh7 60. Qf5+ Kg8 61. Qe6+ Kh7 62. Qf5+ Kg8 63. Qe6+ Kh7 64. Qf5+ Kg8 65. Qe6+ Kh7 66. Qf5+ Kg8 67. Qe6+ Kh7 68. Qf5+ Kg8 69. Qe6+ Kh7 70. Qf5+ Kg8 71. Qe6+ Kh7 72. Qf5+ Kg8 73. Qe6+ Kh7 74. Qf5+ Kg8 75. Qe6+ Kh7 76. Qf5+ Kg8 77. Qe6+ Kh7 78. Qf5+ Kg8 79. Qe6+ Kh7 80.",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c4",
          "neutral_uci": "c2c4",
          "neutral_response": "8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qe6+ Kh7 30. Qf5+ Kg8 31. Qe6+ Kh7 32. Qf5+ Kg8 33. Qe6+ Kh7 34. Qf5+ Kg8 35. Qe6+ Kh7 36. Qf5+ Kg8 37. Qe6+ Kh7 38. Qf5+ Kg8 39. Qe6+ Kh7 40. Qf5+ Kg8 41. Qe6+ Kh7 42. Qf5+ Kg8 43. Qe6+ Kh7 44. Qf5+ Kg8 45. Qe6+ Kh7 46. Qf5+ Kg8 47. Qe6+ Kh7 48. Qf5+ Kg8 49. Qe6+ Kh7 50. Qf5+ Kg8 51. Qe6+ Kh7 52. Qf5+ Kg8 53. Qe6+ Kh7 54. Qf5+ Kg8 55. Qe6+ Kh7 56. Qf5+ Kg8 57. Qe6+ Kh7 58. Qf5+ Kg8 59. Qe6+ Kh7 60. Qf5+ Kg8 61. Qe6+ Kh7 62. Qf5+ Kg8 63. Qe6+ Kh7 64. Qf5+ Kg8 65. Qe6+ Kh7 66. Qf5+ Kg8 67. Qe6+ Kh7 68. Qf5+ Kg8 69. Qe6+ Kh7 70. Qf5+ Kg8 71. Qe6+ Kh7 72. Qf5+ Kg8 73. Qe6+ Kh7 74. Qf5+ Kg8 75. Qe6+ Kh7 76. Qf5+ Kg8 77. Qe6+ Kh7 78. Qf5+ Kg8 79. Qe6+ Kh7 80.",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c2c4",
          "positional_uci": "c2c4",
          "neutral_uci": "c2c4",
          "consensus_move": "c2c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c5",
              "Nc3",
              "Bb7",
              "Rc1",
              "Nbd7",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Kf3",
              "Qf5+",
              "Ke2",
              "Qe4+",
              "Kf1",
              "Qb1+",
              "Ke2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 1920,
          "total_tokens": 2402
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbq1rk1/p1p1bpp1/1p2pn1p/3p4/3P3B/3BPN2/PPP2PPP/RN1Q1RK1 w - - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc3",
          "aggressive_uci": "b1c3",
          "aggressive_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qe6+ Kh7 30. Qf5+ Kg8 31. Qe6+ Kh7 32. Qf5+ Kg8 33. Qe6+ Kh7 34. Qf5+ Kg8 35. Qe6+ Kh7 36. Qf5+ Kg8 37. Qe6+ Kh7 38. Qf5+ Kg8 39. Qe6+ Kh7 40. Qf5+ Kg8 41. Qe6+ Kh7 42. Qf5+ Kg8 43. Qe6+ Kh7 44. Qf5+ Kg8 45. Qe6+ Kh7 46. Qf5+ Kg8 47. Qe6+ Kh7 48. Qf5+ Kg8 49. Qe6+ Kh7 50. Qf5+ Kg8 51. Qe6+ Kh7 52. Qf5+ Kg8 53. Qe6+ Kh7 54. Qf5+ Kg8 55. Qe6+ Kh7 56. Qf5+ Kg8 57. Qe6+ Kh7 58. Qf5+ Kg8 59. Qe6+ Kh7 60. Qf5+ Kg8 61. Qe6+ Kh7 62. Qf5+ Kg8 63. Qe6+ Kh7 64. Qf5+ Kg8 65. Qe6+ Kh7 66. Qf5+ Kg8 67. Qe6+ Kh7 68. Qf5+ Kg8 69. Qe6+ Kh7 70. Qf5+ Kg8 71. Qe6+ Kh7 72. Qf5+ Kg8 73. Qe6+ Kh7 74. Qf5+ Kg8 75. Qe6+ Kh7 76. Qf5+ Kg8 77. Qe6+ Kh7 78. Qf5+ Kg8 79. Qe6+ Kh7 80. Qf5+ Kg8 81",
          "aggressive_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc3",
          "positional_uci": "b1c3",
          "positional_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. h4 Qf6 24. Rd1 Rd8 25. Rxd8+ Qxd8 26. Ba2 Qf6 27. Qd3 Kh7 28. Qd7 Bxe4 29. Nd6 Bg6 30. Nxf7 Bxf7 31. Bxf7 Nb8 32. Qe8 Nc6 33. Qg8# N/A",
          "positional_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 210,
            "total_tokens": 380,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "h4",
            "Qf6",
            "Rd1",
            "Rd8",
            "Rxd8+",
            "Qxd8",
            "Ba2",
            "Qf6",
            "Qd3",
            "Kh7",
            "Qd7",
            "Bxe4",
            "Nd6",
            "Bg6",
            "Nxf7",
            "Bxf7",
            "Bxf7",
            "Nb8",
            "Qe8",
            "Nc6",
            "Qg8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc3",
          "neutral_uci": "b1c3",
          "neutral_response": "9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qe6+ Kh7 30. Qf5+ Kg8 31. Qe6+ Kh7 32. Qf5+ Kg8 33. Qe6+ Kh7 34. Qf5+ Kg8 35. Qe6+ Kh7 36. Qf5+ Kg8 37. Qe6+ Kh7 38. Qf5+ Kg8 39. Qe6+ Kh7 40. Qf5+ Kg8 41. Qe6+ Kh7 42. Qf5+ Kg8 43. Qe6+ Kh7 44. Qf5+ Kg8 45. Qe6+ Kh7 46. Qf5+ Kg8 47. Qe6+ Kh7 48. Qf5+ Kg8 49. Qe6+ Kh7 50. Qf5+ Kg8 51. Qe6+ Kh7 52. Qf5+ Kg8 53. Qe6+ Kh7 54. Qf5+ Kg8 55. Qe6+ Kh7 56. Qf5+ Kg8 57. Qe6+ Kh7 58. Qf5+ Kg8 59. Qe6+ Kh7 60. Qf5+ Kg8 61. Qe6+ Kh7 62. Qf5+ Kg8 63. Qe6+ Kh7 64. Qf5+ Kg8 65. Qe6+ Kh7 66. Qf5+ Kg8 67. Qe6+ Kh7 68. Qf5+ Kg8 69. Qe6+ Kh7 70. Qf5+ Kg8 71. Qe6+ Kh7 72. Qf5+ Kg8 73. Qe6+ Kh7 74. Qf5+ Kg8 75. Qe6+ Kh7 76. Qf5+ Kg8 77. Qe6+ Kh7 78. Qf5+ Kg8 79. Qe6+ Kh7 80. Qf5+ Kg8 81",
          "neutral_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd7",
            "Rc1",
            "c5",
            "cxd5",
            "Nxd5",
            "Bxe7",
            "Qxe7",
            "Nxd5",
            "Bxd5",
            "e4",
            "Bb7",
            "Re1",
            "cxd4",
            "Nxd4",
            "Nc5",
            "Bb1",
            "Rfd8",
            "b4",
            "Na6",
            "a3",
            "e5",
            "Nf5",
            "Qg5",
            "Qf3",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Nd6",
            "Rc1",
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qf5+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b1c3",
          "positional_uci": "b1c3",
          "neutral_uci": "b1c3",
          "consensus_move": "b1c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "h4",
              "Qf6",
              "Rd1",
              "Rd8",
              "Rxd8+",
              "Qxd8",
              "Ba2",
              "Qf6",
              "Qd3",
              "Kh7",
              "Qd7",
              "Bxe4",
              "Nd6",
              "Bg6",
              "Nxf7",
              "Bxf7",
              "Bxf7",
              "Nb8",
              "Qe8",
              "Nc6",
              "Qg8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "Rc1",
              "c5",
              "cxd5",
              "Nxd5",
              "Bxe7",
              "Qxe7",
              "Nxd5",
              "Bxd5",
              "e4",
              "Bb7",
              "Re1",
              "cxd4",
              "Nxd4",
              "Nc5",
              "Bb1",
              "Rfd8",
              "b4",
              "Na6",
              "a3",
              "e5",
              "Nf5",
              "Qg5",
              "Qf3",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Nd6",
              "Rc1",
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qf5+",
              "Kg8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 170,
            "completion_tokens": 210,
            "total_tokens": 380,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 509,
          "total_completion_tokens": 1490,
          "total_tokens": 1999
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 170,
            "completion_tokens": 210,
            "total_tokens": 380,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 169,
            "completion_tokens": 640,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rn1q1rk1/pbp1bpp1/1p2pn1p/3p4/2PP3B/3BPN2/PP3PPP/RN1Q1RK1 w - - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rc1",
          "aggressive_uci": "a1c1",
          "aggressive_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kf3 Qf4+ 35. Ke2 Qxe4+ 36. Kf1 Qb1+ 37. Ke2 Qc2+ 38. Ke3 Qc3+ 39. Qd3+ Qxd3+ 40. Kxd3 Kg6 41. Ke4 Kf6 42. Kd5 Kf5 43. Kc6 Ke4 44. Kb7 Kd3 45. Kxa7 Ke2 46. Kxb6 Kxf2 47. a4 e4 48. a5 e3 49. a6 e2 50. a7 e1=Q 51. a8=Q Qxb4+ 52. Kc7 Qf4+ 53. Kd7 Qxh2 54. Qf3+ Kg1 55. Qd1+ Kxg2 56. Qe2+ Kg3 57. Qe5+ Kg2 58. Qe2+ Kg1 59. Qe1+ Kg2 60. Qe2+ Kg3 61. Qe5+ Kg2 62. Qe2+ Kg1 63. Qe1+ Kg2 64. Qe2+ Kg3 65. Qe5+ Kg2 66. Qe2+ Kg1 67. Qe1+ Kg2 68. Qe2+ Kg3 69. Qe5+ Kg2 70. Qe2+ Kg1 71. Qe1+ Kg2 72. Qe2+ Kg3 73. Qe5+ Kg2 74. Qe2+ Kg1 75. Qe1+ Kg2 76. Qe2+ Kg3 77. Qe5+ Kg2 78. Qe2+ Kg1 79. Qe1+ Kg2 80. Qe2+ Kg3 81. Qe5+ Kg2",
          "aggressive_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kf3",
            "Qf4+",
            "Ke2",
            "Qxe4+",
            "Kf1",
            "Qb1+",
            "Ke2",
            "Qc2+",
            "Ke3",
            "Qc3+",
            "Qd3+",
            "Qxd3+",
            "Kxd3",
            "Kg6",
            "Ke4",
            "Kf6",
            "Kd5",
            "Kf5",
            "Kc6",
            "Ke4",
            "Kb7",
            "Kd3",
            "Kxa7",
            "Ke2",
            "Kxb6",
            "Kxf2",
            "a4",
            "e4",
            "a5",
            "e3",
            "a6",
            "e2",
            "a7",
            "e1=Q",
            "a8=Q",
            "Qxb4+",
            "Kc7",
            "Qf4+",
            "Kd7",
            "Qxh2",
            "Qf3+",
            "Kg1",
            "Qd1+",
            "Kxg2",
            "Qe2+",
            "Kg3",
            "Qe5+",
            "Kg2",
            "Qe2+",
            "Kg1",
            "Qe1+",
            "Kg2",
            "Qe2+",
            "Kg3",
            "Qe5+",
            "Kg2",
            "Qe2+",
            "Kg1",
            "Qe1+",
            "Kg2",
            "Qe2+",
            "Kg3",
            "Qe5+",
            "Kg2",
            "Qe2+",
            "Kg1",
            "Qe1+",
            "Kg2",
            "Qe2+",
            "Kg3",
            "Qe5+",
            "Kg2",
            "Qe2+",
            "Kg1",
            "Qe1+",
            "Kg2",
            "Qe2+",
            "Kg3",
            "Qe5+",
            "Kg2",
            "Qe2+",
            "Kg1",
            "Qe1+",
            "Kg2",
            "Qe2+",
            "Kg3",
            "Qe5+",
            "Kg2",
            "Qe2+",
            "Kg1",
            "Qe1+",
            "Kg2",
            "Qe2+",
            "Kg3",
            "Qe5+",
            "Kg2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rc1",
          "positional_uci": "a1c1",
          "positional_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qf5+ Kg8 29. Qf7+ Kh7 30. Qf5+ Kg8 31. Qf7+ Kh7 32. Qf5+ Kg8 33. Qf7+ Kh7 34. Qf5+ Kg8 35. Qf7+ Kh7 36. Qf5+ Kg8 37. Qf7+ Kh7 38. Qf5+ Kg8 39. Qf7+ Kh7 40. Qf5+ Kg8 41. Qf7+ Kh7 42. Qf5+ Kg8 43. Qf7+ Kh7 44. Qf5+ Kg8 45. Qf7+ Kh7 46. Qf5+ Kg8 47. Qf7+ Kh7 48. Qf5+ Kg8 49. Qf7+ Kh7 50. Qf5+ Kg8 51. Qf7+ Kh7 52. Qf5+ Kg8 53. Qf7+ Kh7 54. Qf5+ Kg8 55. Qf7+ Kh7 56. Qf5+ Kg8 57. Qf7+ Kh7 58. Qf5+ Kg8 59. Qf7+ Kh7 60. Qf5+ Kg8 61. Qf7+ Kh7 62. Qf5+ Kg8 63. Qf7+ Kh7 64. Qf5+ Kg8 65. Qf7+ Kh7 66. Qf5+ Kg8 67. Qf7+ Kh7 68. Qf5+ Kg8 69. Qf7+ Kh7 70. Qf5+ Kg8 71. Qf7+ Kh7 72. Qf5+ Kg8 73. Qf7+ Kh7 74. Qf5+ Kg8 75. Qf7+ Kh7 76. Qf5+ Kg8 77. Qf7+ Kh7 78. Qf5+ Kg8 79. Qf7+ Kh7 80. Qf5+ Kg8 81. Qf7+ Kh7 82",
          "positional_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qf7+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rc1",
          "neutral_uci": "a1c1",
          "neutral_response": "10. Rc1 c5 11. cxd5 Nxd5 12. Bxe7 Qxe7 13. Nxd5 Bxd5 14. e4 Bb7 15. Re1 cxd4 16. Nxd4 Nc5 17. Bb1 Rfd8 18. b4 Na6 19. a3 e5 20. Nf5 Qg5 21. Qf3 Rac8 22. Rxc8 Rxc8 23. Nd6 Rc1 24. Qxf7+ Kh7 25. Rf1 Rxf1+ 26. Kxf1 Qc1+ 27. Ke2 Qxb1 28. Qxb7 Qc2+ 29. Kf3 Qd3+ 30. Kg4 Qxd6 31. Qxa6 Qg6+ 32. Kf3 Qh5+ 33. Ke3 Qg5+ 34. Kd3 Qxg2 35. Qxa7 Qxf2 36. Qd7 Qf3+ 37. Kc4 Qxe4+ 38. Kb5 Qd4 39. Qf5+ Kg8 40. Qe6+ Kf8 41. Qf5+ Ke7 42. Qg6 e4 43. Qxb6 Qxb6+ 44. Kxb6 e3 45. a4 e2 46. a5 e1=Q 47. a6 Qxb4+ 48. Ka7 Kd7 49. h4 Kc7 50. h5 Qb8# e4 d4 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 367,
            "total_tokens": 545,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf7+",
            "Kh7",
            "Rf1",
            "Rxf1+",
            "Kxf1",
            "Qc1+",
            "Ke2",
            "Qxb1",
            "Qxb7",
            "Qc2+",
            "Kf3",
            "Qd3+",
            "Kg4",
            "Qxd6",
            "Qxa6",
            "Qg6+",
            "Kf3",
            "Qh5+",
            "Ke3",
            "Qg5+",
            "Kd3",
            "Qxg2",
            "Qxa7",
            "Qxf2",
            "Qd7",
            "Qf3+",
            "Kc4",
            "Qxe4+",
            "Kb5",
            "Qd4",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kf8",
            "Qf5+",
            "Ke7",
            "Qg6",
            "e4",
            "Qxb6",
            "Qxb6+",
            "Kxb6",
            "e3",
            "a4",
            "e2",
            "a5",
            "e1=Q",
            "a6",
            "Qxb4+",
            "Ka7",
            "Kd7",
            "h4",
            "Kc7",
            "h5",
            "Qb8#",
            "e4",
            "d4",
            "Qe7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a1c1",
          "positional_uci": "a1c1",
          "neutral_uci": "a1c1",
          "consensus_move": "a1c1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kf3",
              "Qf4+",
              "Ke2",
              "Qxe4+",
              "Kf1",
              "Qb1+",
              "Ke2",
              "Qc2+",
              "Ke3",
              "Qc3+",
              "Qd3+",
              "Qxd3+",
              "Kxd3",
              "Kg6",
              "Ke4",
              "Kf6",
              "Kd5",
              "Kf5",
              "Kc6",
              "Ke4",
              "Kb7",
              "Kd3",
              "Kxa7",
              "Ke2",
              "Kxb6",
              "Kxf2",
              "a4",
              "e4",
              "a5",
              "e3",
              "a6",
              "e2",
              "a7",
              "e1=Q",
              "a8=Q",
              "Qxb4+",
              "Kc7",
              "Qf4+",
              "Kd7",
              "Qxh2",
              "Qf3+",
              "Kg1",
              "Qd1+",
              "Kxg2",
              "Qe2+",
              "Kg3",
              "Qe5+",
              "Kg2",
              "Qe2+",
              "Kg1",
              "Qe1+",
              "Kg2",
              "Qe2+",
              "Kg3",
              "Qe5+",
              "Kg2",
              "Qe2+",
              "Kg1",
              "Qe1+",
              "Kg2",
              "Qe2+",
              "Kg3",
              "Qe5+",
              "Kg2",
              "Qe2+",
              "Kg1",
              "Qe1+",
              "Kg2",
              "Qe2+",
              "Kg3",
              "Qe5+",
              "Kg2",
              "Qe2+",
              "Kg1",
              "Qe1+",
              "Kg2",
              "Qe2+",
              "Kg3",
              "Qe5+",
              "Kg2",
              "Qe2+",
              "Kg1",
              "Qe1+",
              "Kg2",
              "Qe2+",
              "Kg3",
              "Qe5+",
              "Kg2",
              "Qe2+",
              "Kg1",
              "Qe1+",
              "Kg2",
              "Qe2+",
              "Kg3",
              "Qe5+",
              "Kg2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qf7+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxf7+",
              "Kh7",
              "Rf1",
              "Rxf1+",
              "Kxf1",
              "Qc1+",
              "Ke2",
              "Qxb1",
              "Qxb7",
              "Qc2+",
              "Kf3",
              "Qd3+",
              "Kg4",
              "Qxd6",
              "Qxa6",
              "Qg6+",
              "Kf3",
              "Qh5+",
              "Ke3",
              "Qg5+",
              "Kd3",
              "Qxg2",
              "Qxa7",
              "Qxf2",
              "Qd7",
              "Qf3+",
              "Kc4",
              "Qxe4+",
              "Kb5",
              "Qd4",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kf8",
              "Qf5+",
              "Ke7",
              "Qg6",
              "e4",
              "Qxb6",
              "Qxb6+",
              "Kxb6",
              "e3",
              "a4",
              "e2",
              "a5",
              "e1=Q",
              "a6",
              "Qxb4+",
              "Ka7",
              "Kd7",
              "h4",
              "Kc7",
              "h5",
              "Qb8#",
              "e4",
              "d4",
              "Qe7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 178,
            "completion_tokens": 367,
            "total_tokens": 545,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 536,
          "total_completion_tokens": 1647,
          "total_tokens": 2183
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 178,
            "completion_tokens": 367,
            "total_tokens": 545,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pbpnbpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/R2Q1RK1 w - - 3 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd5",
          "aggressive_uci": "c4d5",
          "aggressive_response": "11. cxd5 exd5 12. Ne5 Re8 13. Bf5 Qd8 14. Nb5 c5 15. Bg3 a6 16. Nxd7 axb5 17.\nNxf6+ Bxf6 18. dxc5 bxc5 19. Rxc5 Rxa2 20. Rxb5 Ba6 21. Rxd5 Qb6 22. Bd3 Bxd3\n23. Qxd3 Rxb2 24. Rd6 Qb5 25. Qxb5 Rxb5 26. Rfd1 Kh7 27. h3 Rb2 28. Rd7 Kg6\n29. R1d6 Re6 30. Rxe6 fxe6 31. Rd6 Kf7 32. Rd7+ Kg6 33. Rd6 Kf7 34. Rd7+ Kg6\n35. Rd6 Kf7 36. Rd7+ Kg6 37. Rd6 Kf7 38. Rd7+ Kg6 39. Rd6 Kf7 40. Rd7+ Kg6\n41. Rd6 Kf7 42. Rd7+ Kg6 43. Rd6 Kf7 44. Rd7+ Kg6 45. Rd6 Kf7 46. Rd7+ Kg6\n47. Rd6 Kf7 48. Rd7+ Kg6 49. Rd6 Kf7 50. Rd7+ Kg6 51. Rd6 Kf7 52. Rd7+ Kg6\n53. Rd6 Kf7 54. Rd7+ Kg6 55. Rd6 Kf7 56. Rd7+ Kg6 57. Rd6 Kf7 58. Rd7+ Kg6\n59. Rd6 Kf7 60. Rd7+ Kg6 61. Rd6 Kf7 62. Rd7+ Kg6 63. Rd6 Kf7 64. Rd7+ Kg6\n65. Rd6 Kf7 66. Rd7+ Kg6 67. Rd6 Kf7 68. Rd7+ Kg6 69. Rd6 Kf7 70. Rd7+ Kg6\n71. Rd6 Kf7 72. Rd7+ Kg6 73. Rd6 Kf7 74. Rd7+ Kg6 75. Rd6 Kf7 76. Rd7+ Kg6\n77. Rd6 Kf7 78. Rd7+ Kg6 79. Rd6 Kf7 80. Rd7+ Kg6 81. Rd6 Kf7 82. Rd7+ Kg6\n83. Rd6 Kf7 84. Rd7+ Kg6 85. Rd6 Kf7 86. Rd7+ Kg6 87. Rd6 Kf7 88. Rd7+ Kg6\n89. Rd6 Kf",
          "aggressive_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 640,
            "total_tokens": 827,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "exd5",
            "Ne5",
            "Re8",
            "Bf5",
            "Qd8",
            "Nb5",
            "c5",
            "Bg3",
            "a6",
            "Nxd7",
            "axb5",
            "Nxf6+",
            "Bxf6",
            "dxc5",
            "bxc5",
            "Rxc5",
            "Rxa2",
            "Rxb5",
            "Ba6",
            "Rxd5",
            "Qb6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "Rxb2",
            "Rd6",
            "Qb5",
            "Qxb5",
            "Rxb5",
            "Rfd1",
            "Kh7",
            "h3",
            "Rb2",
            "Rd7",
            "Kg6",
            "R1d6",
            "Re6",
            "Rxe6",
            "fxe6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "cxd5",
          "positional_uci": "c4d5",
          "positional_response": "11. cxd5 exd5 12. Ne5 Re8 13. Bf5 Qd8 14. Nb5 c5 15. Bg3 a6 16. Nxd7 axb5 17.\nNxf6+ Bxf6 18. dxc5 bxc5 19. Rxc5 Rxa2 20. Rxb5 Ba6 21. Rxd5 Qb6 22. Bd3 Bxd3\n23. Qxd3 Rxb2 24. Rd6 Qb5 25. Qxb5 Rxb5 26. Rfd1 Kh7 27. h3 Ra8 28. Rd7 Kg6 29.\nRc7 Ra1 30. Rxa1 Bxa1 31. Rc6+ Kh7 32. Rc7 Kg6 33. Rc6+ Kh7 34. Rc7 Kg6 35. Rc6+\nKh7 36. Rc7 Kg6 37. Rc6+ Kh7 38. Rc7 Kg6 39. Rc6+ Kh7 40. Rc7 Kg6 41. Rc6+ Kh7\n42. Rc7 Kg6 43. Rc6+ Kh7 44. Rc7 Kg6 45. Rc6+ Kh7 46. Rc7 Kg6 47. Rc6+ Kh7 48.\nRc7 Kg6 49. Rc6+ Kh7 50. Rc7 Kg6 51. Rc6+ Kh7 52. Rc7 Kg6 53. Rc6+ Kh7 54. Rc7\nKg6 55. Rc6+ Kh7 56. Rc7 Kg6 57. Rc6+ Kh7 58. Rc7 Kg6 59. Rc6+ Kh7 60. Rc7 Kg6\n61. Rc6+ Kh7 62. Rc7 Kg6 63. Rc6+ Kh7 64. Rc7 Kg6 65. Rc6+ Kh7 66. Rc7 Kg6 67.\nRc6+ Kh7 68. Rc7 Kg6 69. Rc6+ Kh7 70. Rc7 Kg6 71. Rc6+ Kh7 72. Rc7 Kg6 73. Rc6+\nKh7 74. Rc7 Kg6 75. Rc6+ Kh7 76. Rc7 Kg6 77. Rc6+ Kh7 78. Rc7 Kg6 79. Rc6+ Kh7\n80. Rc7 Kg6 81. Rc6+ Kh7 82. Rc7 Kg6 83. Rc6+ Kh7 84. Rc7 Kg6 85. Rc6+ Kh7 86.\nRc7 Kg6 87. Rc6+ Kh7 88. Rc7 Kg6 89. Rc6+ Kh7 90. Rc7 Kg6 91. Rc6+ Kh7 92. Rc7\nKg6",
          "positional_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 640,
            "total_tokens": 827,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "exd5",
            "Ne5",
            "Re8",
            "Bf5",
            "Qd8",
            "Nb5",
            "c5",
            "Bg3",
            "a6",
            "Nxd7",
            "axb5",
            "Nxf6+",
            "Bxf6",
            "dxc5",
            "bxc5",
            "Rxc5",
            "Rxa2",
            "Rxb5",
            "Ba6",
            "Rxd5",
            "Qb6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "Rxb2",
            "Rd6",
            "Qb5",
            "Qxb5",
            "Rxb5",
            "Rfd1",
            "Kh7",
            "h3",
            "Ra8",
            "Rd7",
            "Kg6",
            "Rc7",
            "Ra1",
            "Rxa1",
            "Bxa1",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6",
            "Rc6+",
            "Kh7",
            "Rc7",
            "Kg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "cxd5",
          "neutral_uci": "c4d5",
          "neutral_response": "11. cxd5 exd5 12. Ne5 Re8 13. Bf5 Qd8 14. Nb5 c5 15. Bg3 Nxe5 16. dxe5 Ne4 17.\nBxe4 dxe4 18. Qg4 Qc8 19. Qh5 Qc6 20. Nd6 Bxd6 21. exd6 Rad8 22. Rfd1 Rd7 23.\nRd2 Re6 24. Rcd1 Ba6 25. Qd5 Qxd5 26. Rxd5 Bd3 27. f3 c4 28. Kf2 f6 29. Rd4\nexf3 30. gxf3 Kf7 31. e4 Re8 32. Ke3 Rc8 33. Rc1 b5 34. Rxd3 cxd3 35. Rxc8\nd2 36. Kxd2 Ke6 37. Rc7 Rxc7 38. dxc7 Kd7 39. Kc3 a5 40. Kd4 g5 41. Kc5 h5\n42. Kxb5 h4 43. Bd6 Kc8 44. Kc6 a4 45. b4 axb3 46. axb3 f5 47. exf5 g4 48.\nf6 gxf3 49. f7 f2 50. f8=Q# Qd8 Qd7# Qd8 Qd7#",
          "neutral_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 339,
            "total_tokens": 525,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exd5",
            "Ne5",
            "Re8",
            "Bf5",
            "Qd8",
            "Nb5",
            "c5",
            "Bg3",
            "Nxe5",
            "dxe5",
            "Ne4",
            "Bxe4",
            "dxe4",
            "Qg4",
            "Qc8",
            "Qh5",
            "Qc6",
            "Nd6",
            "Bxd6",
            "exd6",
            "Rad8",
            "Rfd1",
            "Rd7",
            "Rd2",
            "Re6",
            "Rcd1",
            "Ba6",
            "Qd5",
            "Qxd5",
            "Rxd5",
            "Bd3",
            "f3",
            "c4",
            "Kf2",
            "f6",
            "Rd4",
            "exf3",
            "gxf3",
            "Kf7",
            "e4",
            "Re8",
            "Ke3",
            "Rc8",
            "Rc1",
            "b5",
            "Rxd3",
            "cxd3",
            "Rxc8",
            "d2",
            "Kxd2",
            "Ke6",
            "Rc7",
            "Rxc7",
            "dxc7",
            "Kd7",
            "Kc3",
            "a5",
            "Kd4",
            "g5",
            "Kc5",
            "h5",
            "Kxb5",
            "h4",
            "Bd6",
            "Kc8",
            "Kc6",
            "a4",
            "b4",
            "axb3",
            "axb3",
            "f5",
            "exf5",
            "g4",
            "f6",
            "gxf3",
            "f7",
            "f2",
            "f8=Q#",
            "Qd8",
            "Qd7#",
            "Qd8",
            "Qd7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c4d5",
          "positional_uci": "c4d5",
          "neutral_uci": "c4d5",
          "consensus_move": "c4d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "exd5",
              "Ne5",
              "Re8",
              "Bf5",
              "Qd8",
              "Nb5",
              "c5",
              "Bg3",
              "a6",
              "Nxd7",
              "axb5",
              "Nxf6+",
              "Bxf6",
              "dxc5",
              "bxc5",
              "Rxc5",
              "Rxa2",
              "Rxb5",
              "Ba6",
              "Rxd5",
              "Qb6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "Rxb2",
              "Rd6",
              "Qb5",
              "Qxb5",
              "Rxb5",
              "Rfd1",
              "Kh7",
              "h3",
              "Rb2",
              "Rd7",
              "Kg6",
              "R1d6",
              "Re6",
              "Rxe6",
              "fxe6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "exd5",
              "Ne5",
              "Re8",
              "Bf5",
              "Qd8",
              "Nb5",
              "c5",
              "Bg3",
              "a6",
              "Nxd7",
              "axb5",
              "Nxf6+",
              "Bxf6",
              "dxc5",
              "bxc5",
              "Rxc5",
              "Rxa2",
              "Rxb5",
              "Ba6",
              "Rxd5",
              "Qb6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "Rxb2",
              "Rd6",
              "Qb5",
              "Qxb5",
              "Rxb5",
              "Rfd1",
              "Kh7",
              "h3",
              "Ra8",
              "Rd7",
              "Kg6",
              "Rc7",
              "Ra1",
              "Rxa1",
              "Bxa1",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6",
              "Rc6+",
              "Kh7",
              "Rc7",
              "Kg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "exd5",
              "Ne5",
              "Re8",
              "Bf5",
              "Qd8",
              "Nb5",
              "c5",
              "Bg3",
              "Nxe5",
              "dxe5",
              "Ne4",
              "Bxe4",
              "dxe4",
              "Qg4",
              "Qc8",
              "Qh5",
              "Qc6",
              "Nd6",
              "Bxd6",
              "exd6",
              "Rad8",
              "Rfd1",
              "Rd7",
              "Rd2",
              "Re6",
              "Rcd1",
              "Ba6",
              "Qd5",
              "Qxd5",
              "Rxd5",
              "Bd3",
              "f3",
              "c4",
              "Kf2",
              "f6",
              "Rd4",
              "exf3",
              "gxf3",
              "Kf7",
              "e4",
              "Re8",
              "Ke3",
              "Rc8",
              "Rc1",
              "b5",
              "Rxd3",
              "cxd3",
              "Rxc8",
              "d2",
              "Kxd2",
              "Ke6",
              "Rc7",
              "Rxc7",
              "dxc7",
              "Kd7",
              "Kc3",
              "a5",
              "Kd4",
              "g5",
              "Kc5",
              "h5",
              "Kxb5",
              "h4",
              "Bd6",
              "Kc8",
              "Kc6",
              "a4",
              "b4",
              "axb3",
              "axb3",
              "f5",
              "exf5",
              "g4",
              "f6",
              "gxf3",
              "f7",
              "f2",
              "f8=Q#",
              "Qd8",
              "Qd7#",
              "Qd8",
              "Qd7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 187,
            "completion_tokens": 640,
            "total_tokens": 827,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 187,
            "completion_tokens": 640,
            "total_tokens": 827,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 186,
            "completion_tokens": 339,
            "total_tokens": 525,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 560,
          "total_completion_tokens": 1619,
          "total_tokens": 2179
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 187,
            "completion_tokens": 640,
            "total_tokens": 827,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 187,
            "completion_tokens": 640,
            "total_tokens": 827,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 186,
            "completion_tokens": 339,
            "total_tokens": 525,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1q2rk1/pbpnbpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/2RQ1RK1 w - - 5 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne5",
          "aggressive_uci": "f3e5",
          "aggressive_response": "12. Ne5 Re8 13. Bf5 Qd8 14. Nb5 c5 15. Bg3 a6 16. Nxd7 axb5 17. Nxf6+ Bxf6 18.\ndxc5 bxc5 19. Rxc5 Rxa2 20. Rxb5 Ba6 21. Rxd5 Qb6 22. Bd3 Bxd3 23. Qxd3 Rxb2\n24. Rd6 Qb5 25. Qxb5 Rxb5 26. Rfd1 Kh7 27. h3 Rb2 28. Rd7 Kg6 29. R1d6 Re6\n30. Rxe6 fxe6 31. Rd6 Kf7 32. Rd7+ Kg6 33. Rd6 Kf7 34. Rd7+ Kg6 35. Rd6 Kf7\n36. Rd7+ Kg6 37. Rd6 Kf7 38. Rd7+ Kg6 39. Rd6 Kf7 40. Rd7+ Kg6 41. Rd6 Kf7\n42. Rd7+ Kg6 43. Rd6 Kf7 44. Rd7+ Kg6 45. Rd6 Kf7 46. Rd7+ Kg6 47. Rd6 Kf7\n48. Rd7+ Kg6 49. Rd6 Kf7 50. Rd7+ Kg6 51. Rd6 Kf7 52. Rd7+ Kg6 53. Rd6 Kf7\n54. Rd7+ Kg6 55. Rd6 Kf7 56. Rd7+ Kg6 57. Rd6 Kf7 58. Rd7+ Kg6 59. Rd6 Kf7\n60. Rd7+ Kg6 61. Rd6 Kf7 62. Rd7+ Kg6 63. Rd6 Kf7 64. Rd7+ Kg6 65. Rd6 Kf7\n66. Rd7+ Kg6 67. Rd6 Kf7 68. Rd7+ Kg6 69. Rd6 Kf7 70. Rd7+ Kg6 71. Rd6 Kf7\n72. Rd7+ Kg6 73. Rd6 Kf7 74. Rd7+ Kg6 75. Rd6 Kf7 76. Rd7+ Kg6 77. Rd6 Kf7\n78. Rd7+ Kg6 79. Rd6 Kf7 80. Rd7+ Kg6 81. Rd6 Kf7 82. Rd7+ Kg6 83. Rd6 Kf7\n84. Rd7+ Kg6 85. Rd6 Kf7 86. Rd7+ Kg6 87. Rd6 Kf7 88. Rd7+ Kg6 89. Rd6 Kf7\n90. Rd7+ Kg6",
          "aggressive_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re8",
            "Bf5",
            "Qd8",
            "Nb5",
            "c5",
            "Bg3",
            "a6",
            "Nxd7",
            "axb5",
            "Nxf6+",
            "Bxf6",
            "dxc5",
            "bxc5",
            "Rxc5",
            "Rxa2",
            "Rxb5",
            "Ba6",
            "Rxd5",
            "Qb6",
            "Bd3",
            "Bxd3",
            "Qxd3",
            "Rxb2",
            "Rd6",
            "Qb5",
            "Qxb5",
            "Rxb5",
            "Rfd1",
            "Kh7",
            "h3",
            "Rb2",
            "Rd7",
            "Kg6",
            "R1d6",
            "Re6",
            "Rxe6",
            "fxe6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rd6",
            "Kf7",
            "Rd7+",
            "Kg6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne5",
          "positional_uci": "f3e5",
          "positional_response": "12. Ne5 Re8 13. Bf5 Qd8 14. Nb5 c5 15. Bg3 Nxe5 16. dxe5 Ne4 17. Bxe4 dxe4 18.\nQg4 Qc8 19. Qh5 Qc6 20. Nd6 Bxd6 21. exd6 Rad8 22. Rfd1 Rd7 23. b4 c4 24. b5\nQc8 25. Rd4 c3 26. Qe2 Qc5 27. Rc4 Qxb5 28. R1xc3 Ba6 29. Qc2 Qd5 30. Rd4 Qb5\n31. h3 f5 32. Rc7 Red8 33. Rxd7 Rxd7 34. Rc4 Qd5 35. Rc7 Qb5 36. Kh2 Kh7 37.\nQc3 Kg6 38. Be5 Kh5 39. Bxg7 Rxd6 40. Be5 Rd7 41. Rc6 Rd3 42. Qc1 Qxe5+ 43.\ng3 Rd6 44. Rc7 Be2 45. Rxa7 Rd1 46. Qc8 Bf3 47. Qe8+ Qxe8 48. g4+ fxg4 49.\nhxg4+ Kxg4 50. Rg7+ Kh4 51. Rg1 Qe5+ 52. Rg3 Rh1# d4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Re8 Bf5 Qd8 Nb5 c5 Bg3 Nxe4 Bxe4 dxe4 Qg4 Qc8 Qh5 Qc6 Nd6 Bxd6 exd6 Qxd6 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5 Qc8 Qg4 Qc6 Qh5",
          "positional_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re8",
            "Bf5",
            "Qd8",
            "Nb5",
            "c5",
            "Bg3",
            "Nxe4",
            "Bxe4",
            "dxe4",
            "Qg4",
            "Qc8",
            "Qh5",
            "Qc6",
            "Nd6",
            "Bxd6",
            "exd6",
            "Qxd6",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5",
            "Qc8",
            "Qg4",
            "Qc6",
            "Qh5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne5",
          "neutral_uci": "f3e5",
          "neutral_response": "12. Ne5 Re8 13. Bf5 Qd8 14. Nb5 c5 15. Bg3 Nxe5 16. dxe5 Ne4 17. Bxe4 dxe4 18.\nQg4 Qc8 19. Qh5 Qc6 20. Nd6 Bxd6 21. exd6 Rad8 22. Rfd1 Rd7 23. b4 c4 24. b5\nQc8 25. Rd4 c3 26. Qe2 Qc5 27. Qc4 Rc8 28. Qxc5 Rxc5 29. a4 f5 30. Kf1 Kf7\n31. Ke2 Ke6 32. Kd1 Bd5 33. Kc2 g5 34. h4 f4 35. exf4 Rxd6 36. fxg5 Bb3+ 37.\nKxb3 Rxd4 38. gxh6 Kf7 39. Bf4 Kg6 40. Be3 Rd3 41. Bxc5 bxc5 42. Rxc3 Rd2 43.\nRxc5 Rxf2 44. Rc6+ Kh7 45. Rc7+ Kxh6 46. Rxa7 Rxg2 47. Re7 Rg4 48. b6 Rxh4\n49. b7 Rh1 50. Rxe4 Rb1+ 51. Kc4 Rxb7 52. a5 Kg6 53. a6 Ra7 54. Kb5 Kf6 55.\nKb6 Ra8 56. a7 Kf5 57. Re1 Kf6 58. Kb7 Rxa7+ 59. Kxa7 Kf5 60. Kb6 Kf4 61. Kc5\nKf3 62. Kd4 Kf2 63. Re3 Kg2 64. Ke4 Kf2 65. Kf4 Kg2 66. Rf3 Kh2 67. Rg3 Kh1\n68. Kf3 Kh2 69. Kf2 Kh1 70. Rh3# c3 c2 c1=Q",
          "neutral_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 493,
            "total_tokens": 688,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Bf5",
            "Qd8",
            "Nb5",
            "c5",
            "Bg3",
            "Nxe5",
            "dxe5",
            "Ne4",
            "Bxe4",
            "dxe4",
            "Qg4",
            "Qc8",
            "Qh5",
            "Qc6",
            "Nd6",
            "Bxd6",
            "exd6",
            "Rad8",
            "Rfd1",
            "Rd7",
            "b4",
            "c4",
            "b5",
            "Qc8",
            "Rd4",
            "c3",
            "Qe2",
            "Qc5",
            "Qc4",
            "Rc8",
            "Qxc5",
            "Rxc5",
            "a4",
            "f5",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Kd1",
            "Bd5",
            "Kc2",
            "g5",
            "h4",
            "f4",
            "exf4",
            "Rxd6",
            "fxg5",
            "Bb3+",
            "Kxb3",
            "Rxd4",
            "gxh6",
            "Kf7",
            "Bf4",
            "Kg6",
            "Be3",
            "Rd3",
            "Bxc5",
            "bxc5",
            "Rxc3",
            "Rd2",
            "Rxc5",
            "Rxf2",
            "Rc6+",
            "Kh7",
            "Rc7+",
            "Kxh6",
            "Rxa7",
            "Rxg2",
            "Re7",
            "Rg4",
            "b6",
            "Rxh4",
            "b7",
            "Rh1",
            "Rxe4",
            "Rb1+",
            "Kc4",
            "Rxb7",
            "a5",
            "Kg6",
            "a6",
            "Ra7",
            "Kb5",
            "Kf6",
            "Kb6",
            "Ra8",
            "a7",
            "Kf5",
            "Re1",
            "Kf6",
            "Kb7",
            "Rxa7+",
            "Kxa7",
            "Kf5",
            "Kb6",
            "Kf4",
            "Kc5",
            "Kf3",
            "Kd4",
            "Kf2",
            "Re3",
            "Kg2",
            "Ke4",
            "Kf2",
            "Kf4",
            "Kg2",
            "Rf3",
            "Kh2",
            "Rg3",
            "Kh1",
            "Kf3",
            "Kh2",
            "Kf2",
            "Kh1",
            "Rh3#",
            "c3",
            "c2",
            "c1=Q"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3e5",
          "positional_uci": "f3e5",
          "neutral_uci": "f3e5",
          "consensus_move": "f3e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re8",
              "Bf5",
              "Qd8",
              "Nb5",
              "c5",
              "Bg3",
              "a6",
              "Nxd7",
              "axb5",
              "Nxf6+",
              "Bxf6",
              "dxc5",
              "bxc5",
              "Rxc5",
              "Rxa2",
              "Rxb5",
              "Ba6",
              "Rxd5",
              "Qb6",
              "Bd3",
              "Bxd3",
              "Qxd3",
              "Rxb2",
              "Rd6",
              "Qb5",
              "Qxb5",
              "Rxb5",
              "Rfd1",
              "Kh7",
              "h3",
              "Rb2",
              "Rd7",
              "Kg6",
              "R1d6",
              "Re6",
              "Rxe6",
              "fxe6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rd6",
              "Kf7",
              "Rd7+",
              "Kg6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Bf5",
              "Qd8",
              "Nb5",
              "c5",
              "Bg3",
              "Nxe4",
              "Bxe4",
              "dxe4",
              "Qg4",
              "Qc8",
              "Qh5",
              "Qc6",
              "Nd6",
              "Bxd6",
              "exd6",
              "Qxd6",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5",
              "Qc8",
              "Qg4",
              "Qc6",
              "Qh5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re8",
              "Bf5",
              "Qd8",
              "Nb5",
              "c5",
              "Bg3",
              "Nxe5",
              "dxe5",
              "Ne4",
              "Bxe4",
              "dxe4",
              "Qg4",
              "Qc8",
              "Qh5",
              "Qc6",
              "Nd6",
              "Bxd6",
              "exd6",
              "Rad8",
              "Rfd1",
              "Rd7",
              "b4",
              "c4",
              "b5",
              "Qc8",
              "Rd4",
              "c3",
              "Qe2",
              "Qc5",
              "Qc4",
              "Rc8",
              "Qxc5",
              "Rxc5",
              "a4",
              "f5",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Kd1",
              "Bd5",
              "Kc2",
              "g5",
              "h4",
              "f4",
              "exf4",
              "Rxd6",
              "fxg5",
              "Bb3+",
              "Kxb3",
              "Rxd4",
              "gxh6",
              "Kf7",
              "Bf4",
              "Kg6",
              "Be3",
              "Rd3",
              "Bxc5",
              "bxc5",
              "Rxc3",
              "Rd2",
              "Rxc5",
              "Rxf2",
              "Rc6+",
              "Kh7",
              "Rc7+",
              "Kxh6",
              "Rxa7",
              "Rxg2",
              "Re7",
              "Rg4",
              "b6",
              "Rxh4",
              "b7",
              "Rh1",
              "Rxe4",
              "Rb1+",
              "Kc4",
              "Rxb7",
              "a5",
              "Kg6",
              "a6",
              "Ra7",
              "Kb5",
              "Kf6",
              "Kb6",
              "Ra8",
              "a7",
              "Kf5",
              "Re1",
              "Kf6",
              "Kb7",
              "Rxa7+",
              "Kxa7",
              "Kf5",
              "Kb6",
              "Kf4",
              "Kc5",
              "Kf3",
              "Kd4",
              "Kf2",
              "Re3",
              "Kg2",
              "Ke4",
              "Kf2",
              "Kf4",
              "Kg2",
              "Rf3",
              "Kh2",
              "Rg3",
              "Kh1",
              "Kf3",
              "Kh2",
              "Kf2",
              "Kh1",
              "Rh3#",
              "c3",
              "c2",
              "c1=Q"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 195,
            "completion_tokens": 493,
            "total_tokens": 688,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 587,
          "total_completion_tokens": 1773,
          "total_tokens": 2360
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 195,
            "completion_tokens": 493,
            "total_tokens": 688,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1q2rk1/pbpnbpp1/1p3n1p/3p4/3P3B/2NBPN2/PP3PPP/2RQ1RK1 w - - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxe5",
          "aggressive_uci": "d4e5",
          "aggressive_response": "13. dxe5 g5 14. exf6 Bxf6 15. Bg3 c5 16. Qh5 Kg7 17. f4 Qe6 18. Rce1 Rae8 19. fxg5 Bxg5 20. Bf4 Bxf4 21. Rxf4 d4 22. Rg4+ Kh8 23. Ne4 f5 24. Rg6 Qxg6 25. Qxg6 fxe4 26. Qxh6+ Kg8 27. Bc4+ Rf7 28. Qg6+ Kh8 29. Bxf7 Re6 30. Qg8# d4 e3 dxe3",
          "aggressive_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 163,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "exf6",
            "Bxf6",
            "Bg3",
            "c5",
            "Qh5",
            "Kg7",
            "f4",
            "Qe6",
            "Rce1",
            "Rae8",
            "fxg5",
            "Bxg5",
            "Bf4",
            "Bxf4",
            "Rxf4",
            "d4",
            "Rg4+",
            "Kh8",
            "Ne4",
            "f5",
            "Rg6",
            "Qxg6",
            "Qxg6",
            "fxe4",
            "Qxh6+",
            "Kg8",
            "Bc4+",
            "Rf7",
            "Qg6+",
            "Kh8",
            "Bxf7",
            "Re6",
            "Qg8#",
            "d4",
            "e3",
            "dxe3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxe5",
          "positional_uci": "d4e5",
          "positional_response": "13. dxe5 g5 14. exf6 Bxf6 15. Bg3 c5 16. Qh5 Kg7 17. f4 Qe6 18. Rce1 Rae8 19.\nfxg5 Bxg5 20. Bf4 Bxf4 21. Rxf4 d4 22. Rg4+ Kh8 23. Ne4 f5 24. Rg6 Qxg6 25.\nQxg6 fxe4 26. Qxh6+ Kg8 27. Bc4+ Rf7 28. Qg6+ Kh8 29. Bxf7 Re6 30. Qg8# d3\n31. Bxe6# d2 32. Qg8# dxe1=Q#",
          "positional_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 180,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "exf6",
            "Bxf6",
            "Bg3",
            "c5",
            "Qh5",
            "Kg7",
            "f4",
            "Qe6",
            "Rce1",
            "Rae8",
            "fxg5",
            "Bxg5",
            "Bf4",
            "Bxf4",
            "Rxf4",
            "d4",
            "Rg4+",
            "Kh8",
            "Ne4",
            "f5",
            "Rg6",
            "Qxg6",
            "Qxg6",
            "fxe4",
            "Qxh6+",
            "Kg8",
            "Bc4+",
            "Rf7",
            "Qg6+",
            "Kh8",
            "Bxf7",
            "Re6",
            "Qg8#",
            "d3",
            "Bxe6#",
            "d2",
            "Qg8#",
            "dxe1=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxe5",
          "neutral_uci": "d4e5",
          "neutral_response": "13. dxe5 g5 14. exf6 Bxf6 15. Bg3 c5 16. Qh5 Kg7 17. f4 Qe6 18. Rce1 Rae8 19. fxg5 Bxg5 20. Bf4 Bxf4 21. Rxf4 d4 22. Rg4+ Kh8 23. Ne4 f5 24. Rg6 Qxg6 25. Qxg6 fxe4 26. Qxh6+ Kg8 27. Bc4+ Rf7 28. Qg6+ Kh8 29. Bxf7 Re6 30. Qg8# d4 e3 Qg6",
          "neutral_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 163,
            "total_tokens": 366,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "exf6",
            "Bxf6",
            "Bg3",
            "c5",
            "Qh5",
            "Kg7",
            "f4",
            "Qe6",
            "Rce1",
            "Rae8",
            "fxg5",
            "Bxg5",
            "Bf4",
            "Bxf4",
            "Rxf4",
            "d4",
            "Rg4+",
            "Kh8",
            "Ne4",
            "f5",
            "Rg6",
            "Qxg6",
            "Qxg6",
            "fxe4",
            "Qxh6+",
            "Kg8",
            "Bc4+",
            "Rf7",
            "Qg6+",
            "Kh8",
            "Bxf7",
            "Re6",
            "Qg8#",
            "d4",
            "e3",
            "Qg6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4e5",
          "positional_uci": "d4e5",
          "neutral_uci": "d4e5",
          "consensus_move": "d4e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "g5",
              "exf6",
              "Bxf6",
              "Bg3",
              "c5",
              "Qh5",
              "Kg7",
              "f4",
              "Qe6",
              "Rce1",
              "Rae8",
              "fxg5",
              "Bxg5",
              "Bf4",
              "Bxf4",
              "Rxf4",
              "d4",
              "Rg4+",
              "Kh8",
              "Ne4",
              "f5",
              "Rg6",
              "Qxg6",
              "Qxg6",
              "fxe4",
              "Qxh6+",
              "Kg8",
              "Bc4+",
              "Rf7",
              "Qg6+",
              "Kh8",
              "Bxf7",
              "Re6",
              "Qg8#",
              "d4",
              "e3",
              "dxe3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "g5",
              "exf6",
              "Bxf6",
              "Bg3",
              "c5",
              "Qh5",
              "Kg7",
              "f4",
              "Qe6",
              "Rce1",
              "Rae8",
              "fxg5",
              "Bxg5",
              "Bf4",
              "Bxf4",
              "Rxf4",
              "d4",
              "Rg4+",
              "Kh8",
              "Ne4",
              "f5",
              "Rg6",
              "Qxg6",
              "Qxg6",
              "fxe4",
              "Qxh6+",
              "Kg8",
              "Bc4+",
              "Rf7",
              "Qg6+",
              "Kh8",
              "Bxf7",
              "Re6",
              "Qg8#",
              "d3",
              "Bxe6#",
              "d2",
              "Qg8#",
              "dxe1=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "g5",
              "exf6",
              "Bxf6",
              "Bg3",
              "c5",
              "Qh5",
              "Kg7",
              "f4",
              "Qe6",
              "Rce1",
              "Rae8",
              "fxg5",
              "Bxg5",
              "Bf4",
              "Bxf4",
              "Rxf4",
              "d4",
              "Rg4+",
              "Kh8",
              "Ne4",
              "f5",
              "Rg6",
              "Qxg6",
              "Qxg6",
              "fxe4",
              "Qxh6+",
              "Kg8",
              "Bc4+",
              "Rf7",
              "Qg6+",
              "Kh8",
              "Bxf7",
              "Re6",
              "Qg8#",
              "d4",
              "e3",
              "Qg6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 204,
            "completion_tokens": 163,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 204,
            "completion_tokens": 180,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 203,
            "completion_tokens": 163,
            "total_tokens": 366,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 611,
          "total_completion_tokens": 506,
          "total_tokens": 1117
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 204,
            "completion_tokens": 163,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 204,
            "completion_tokens": 180,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 203,
            "completion_tokens": 163,
            "total_tokens": 366,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1q2rk1/pbp1bpp1/1p3n1p/3pn3/3P3B/2NBP3/PP3PPP/2RQ1RK1 w - - 0 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "exf6",
          "aggressive_uci": "e5f6",
          "aggressive_response": "14. exf6 Bxf6 15. Bxf6 Qxf6 16. Qf3 Qxf3 17. gxf3 c5 18. Rfd1 Rfd8 19. Bf1 d4 20. exd4 cxd4 21. Ne4 f5 22. Nd2 Rac8 23. Rxc8 Rxc8 24. Bd3 g6 25. Nb3 Bxf3 26. Rc1 Rd8 27. Rc7 a5 28. Nd2 Bd5 29. Bc4 Bxc4 30. Rxc4 Kf7 31. Rc6 b5 32. Kf1 Rd5 33. Ke2 Re5+ 34. Kd3 Rd5 35. Nf3 g5 36. Rxh6 g4 37. Nxd4 Kg7 38. Ra6 a4 39. Rb6 Kf7 40. Rxb5 Rxb5 41. Nxb5 Ke6 42. Nc3 Ke5 43. Nxa4 Kf4 44. Ke2 Ke4 45. Nc3+ Kd4 46. a4 Kc4 47. Ke3 Kb4 48. Kf4 Kb3 49. a5 Kxb2 50. a6 Kxc3 51. a7 Kd2 52. a8=Q Ke2 53. Qa2+ Kf1 54. f3 gxf3 55. Kxf3 Ke1 56. Qe2# 1-0 1-0 1-0",
          "aggressive_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 361,
            "total_tokens": 574,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Qf3",
            "Qxf3",
            "gxf3",
            "c5",
            "Rfd1",
            "Rfd8",
            "Bf1",
            "d4",
            "exd4",
            "cxd4",
            "Ne4",
            "f5",
            "Nd2",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Bd3",
            "g6",
            "Nb3",
            "Bxf3",
            "Rc1",
            "Rd8",
            "Rc7",
            "a5",
            "Nd2",
            "Bd5",
            "Bc4",
            "Bxc4",
            "Rxc4",
            "Kf7",
            "Rc6",
            "b5",
            "Kf1",
            "Rd5",
            "Ke2",
            "Re5+",
            "Kd3",
            "Rd5",
            "Nf3",
            "g5",
            "Rxh6",
            "g4",
            "Nxd4",
            "Kg7",
            "Ra6",
            "a4",
            "Rb6",
            "Kf7",
            "Rxb5",
            "Rxb5",
            "Nxb5",
            "Ke6",
            "Nc3",
            "Ke5",
            "Nxa4",
            "Kf4",
            "Ke2",
            "Ke4",
            "Nc3+",
            "Kd4",
            "a4",
            "Kc4",
            "Ke3",
            "Kb4",
            "Kf4",
            "Kb3",
            "a5",
            "Kxb2",
            "a6",
            "Kxc3",
            "a7",
            "Kd2",
            "a8=Q",
            "Ke2",
            "Qa2+",
            "Kf1",
            "f3",
            "gxf3",
            "Kxf3",
            "Ke1",
            "Qe2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "exf6",
          "positional_uci": "e5f6",
          "positional_response": "14. exf6 Bxf6 15. Bxf6 Qxf6 16. Qf3 Qxf3 17. gxf3 c5 18. Rfd1 Rad8 19. Bf1 Rfe8 20. Bg2 Re6 21. f4 Rg6 22. Kf1 Ba6+ 23. Kg1 Bb7 24. Kh1 Rgd6 25. Rd2 Ba8 26. Rcd1 d4 27. Bxa8 Rxa8 28. exd4 cxd4 29. Rxd4 Rf6 30. Kg2 Kh7 31. Kf3 Re8 32. Rd7 a5 33. Rb7 Ree6 34. Rdd7 Kg6 35. Nd5 Rf5 36. Ne7+ Rxe7 37. Rxe7 Rb5 38. Rxf7 Rxb2 39. Rxg7+ Kh5 40. Rbf7 Rxa2 41. Rf5+ Kh4 42. Rg4+ Kh3 43. Rh5#",
          "positional_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 250,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Qf3",
            "Qxf3",
            "gxf3",
            "c5",
            "Rfd1",
            "Rad8",
            "Bf1",
            "Rfe8",
            "Bg2",
            "Re6",
            "f4",
            "Rg6",
            "Kf1",
            "Ba6+",
            "Kg1",
            "Bb7",
            "Kh1",
            "Rgd6",
            "Rd2",
            "Ba8",
            "Rcd1",
            "d4",
            "Bxa8",
            "Rxa8",
            "exd4",
            "cxd4",
            "Rxd4",
            "Rf6",
            "Kg2",
            "Kh7",
            "Kf3",
            "Re8",
            "Rd7",
            "a5",
            "Rb7",
            "Ree6",
            "Rdd7",
            "Kg6",
            "Nd5",
            "Rf5",
            "Ne7+",
            "Rxe7",
            "Rxe7",
            "Rb5",
            "Rxf7",
            "Rxb2",
            "Rxg7+",
            "Kh5",
            "Rbf7",
            "Rxa2",
            "Rf5+",
            "Kh4",
            "Rg4+",
            "Kh3",
            "Rh5#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "exf6",
          "neutral_uci": "e5f6",
          "neutral_response": "14. exf6 Bxf6 15. Bxf6 Qxf6 16. Qf3 Qe6 17. Qf5 Qxf5 18. Bxf5 c5 19. Rfd1 Rad8 20. Rd2 g6 21. Bg4 f5 22. Bf3 Rf7 23. Bxd5 Bxd5 24. Rxd5 Rxd5 25. Nxd5 Rd7 26. Rd1 Kf7 27. Kf1 Ke6 28. Nf4+ Ke7 29. Rxd7+ Kxd7 30. Nxg6 Ke6 31. Nf4+ Ke5 32. Ke2 Ke4 33. f3+ Ke5 34. Kd3 b5 35. b3 a5 36. a4 bxa4 37. bxa4 Kd6 38. Kc4 Kc6 39. Nd3 Kd6 40. Nxc5 Kc6 41. Nb3 Kb6 42. Kd5 Ka6 43. Kc6 Ka7 44. Nxa5 Ka6 45. Nc4 Ka7 46. a5 Ka6 47. Kd5 Kb5 48. Ke5 Kxc4 49. a6 Kd3 50. a7 Kxe3 51. a8=Q Kf2 52. Kxf5 Kxg2 53. Kg6 Kxh2 54. Kxh6 Kg3 55. Qe4 Kf2 56. f4 Kg3 57. f5 Kf2 58. f6 Kg3 59. f7 Kf2 60. f8=Q+ Kg3 61. Qg6+ Kh4 62. Qf4+ Kh3 63. Qgg3# Kc2 64. Qff2+ Kd1 65. Qgg1# Kc2 66. Qgg3 Kd1 67. Qgg1# Kc2 68. Qgg3 Kd1 69. Qgg1# Kc2 70. Qgg3 Kd1 71. Qgg1# Kc2 72. Qgg3 Kd1 73. Qgg1# Kc2 74. Qgg3 Kd1 75. Qgg1# Kc2 76. Qgg3 Kd1 77. Qgg1# Kc2 78. Qgg3 Kd1 79. Qgg1# Kc2 80. Qgg3 Kd1 81. Qgg1# Kc2 82. Qgg3 Kd1 83. Qgg1# Kc2 84. Qgg3 Kd1 85. Qgg1# Kc2 86. Qgg3 Kd1",
          "neutral_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Qf3",
            "Qe6",
            "Qf5",
            "Qxf5",
            "Bxf5",
            "c5",
            "Rfd1",
            "Rad8",
            "Rd2",
            "g6",
            "Bg4",
            "f5",
            "Bf3",
            "Rf7",
            "Bxd5",
            "Bxd5",
            "Rxd5",
            "Rxd5",
            "Nxd5",
            "Rd7",
            "Rd1",
            "Kf7",
            "Kf1",
            "Ke6",
            "Nf4+",
            "Ke7",
            "Rxd7+",
            "Kxd7",
            "Nxg6",
            "Ke6",
            "Nf4+",
            "Ke5",
            "Ke2",
            "Ke4",
            "f3+",
            "Ke5",
            "Kd3",
            "b5",
            "b3",
            "a5",
            "a4",
            "bxa4",
            "bxa4",
            "Kd6",
            "Kc4",
            "Kc6",
            "Nd3",
            "Kd6",
            "Nxc5",
            "Kc6",
            "Nb3",
            "Kb6",
            "Kd5",
            "Ka6",
            "Kc6",
            "Ka7",
            "Nxa5",
            "Ka6",
            "Nc4",
            "Ka7",
            "a5",
            "Ka6",
            "Kd5",
            "Kb5",
            "Ke5",
            "Kxc4",
            "a6",
            "Kd3",
            "a7",
            "Kxe3",
            "a8=Q",
            "Kf2",
            "Kxf5",
            "Kxg2",
            "Kg6",
            "Kxh2",
            "Kxh6",
            "Kg3",
            "Qe4",
            "Kf2",
            "f4",
            "Kg3",
            "f5",
            "Kf2",
            "f6",
            "Kg3",
            "f7",
            "Kf2",
            "f8=Q+",
            "Kg3",
            "Qg6+",
            "Kh4",
            "Qf4+",
            "Kh3",
            "Qgg3#",
            "Kc2",
            "Qff2+",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1",
            "Qgg1#",
            "Kc2",
            "Qgg3",
            "Kd1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5f6",
          "positional_uci": "e5f6",
          "neutral_uci": "e5f6",
          "consensus_move": "e5f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Qf3",
              "Qxf3",
              "gxf3",
              "c5",
              "Rfd1",
              "Rfd8",
              "Bf1",
              "d4",
              "exd4",
              "cxd4",
              "Ne4",
              "f5",
              "Nd2",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Bd3",
              "g6",
              "Nb3",
              "Bxf3",
              "Rc1",
              "Rd8",
              "Rc7",
              "a5",
              "Nd2",
              "Bd5",
              "Bc4",
              "Bxc4",
              "Rxc4",
              "Kf7",
              "Rc6",
              "b5",
              "Kf1",
              "Rd5",
              "Ke2",
              "Re5+",
              "Kd3",
              "Rd5",
              "Nf3",
              "g5",
              "Rxh6",
              "g4",
              "Nxd4",
              "Kg7",
              "Ra6",
              "a4",
              "Rb6",
              "Kf7",
              "Rxb5",
              "Rxb5",
              "Nxb5",
              "Ke6",
              "Nc3",
              "Ke5",
              "Nxa4",
              "Kf4",
              "Ke2",
              "Ke4",
              "Nc3+",
              "Kd4",
              "a4",
              "Kc4",
              "Ke3",
              "Kb4",
              "Kf4",
              "Kb3",
              "a5",
              "Kxb2",
              "a6",
              "Kxc3",
              "a7",
              "Kd2",
              "a8=Q",
              "Ke2",
              "Qa2+",
              "Kf1",
              "f3",
              "gxf3",
              "Kxf3",
              "Ke1",
              "Qe2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Qf3",
              "Qxf3",
              "gxf3",
              "c5",
              "Rfd1",
              "Rad8",
              "Bf1",
              "Rfe8",
              "Bg2",
              "Re6",
              "f4",
              "Rg6",
              "Kf1",
              "Ba6+",
              "Kg1",
              "Bb7",
              "Kh1",
              "Rgd6",
              "Rd2",
              "Ba8",
              "Rcd1",
              "d4",
              "Bxa8",
              "Rxa8",
              "exd4",
              "cxd4",
              "Rxd4",
              "Rf6",
              "Kg2",
              "Kh7",
              "Kf3",
              "Re8",
              "Rd7",
              "a5",
              "Rb7",
              "Ree6",
              "Rdd7",
              "Kg6",
              "Nd5",
              "Rf5",
              "Ne7+",
              "Rxe7",
              "Rxe7",
              "Rb5",
              "Rxf7",
              "Rxb2",
              "Rxg7+",
              "Kh5",
              "Rbf7",
              "Rxa2",
              "Rf5+",
              "Kh4",
              "Rg4+",
              "Kh3",
              "Rh5#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Qf3",
              "Qe6",
              "Qf5",
              "Qxf5",
              "Bxf5",
              "c5",
              "Rfd1",
              "Rad8",
              "Rd2",
              "g6",
              "Bg4",
              "f5",
              "Bf3",
              "Rf7",
              "Bxd5",
              "Bxd5",
              "Rxd5",
              "Rxd5",
              "Nxd5",
              "Rd7",
              "Rd1",
              "Kf7",
              "Kf1",
              "Ke6",
              "Nf4+",
              "Ke7",
              "Rxd7+",
              "Kxd7",
              "Nxg6",
              "Ke6",
              "Nf4+",
              "Ke5",
              "Ke2",
              "Ke4",
              "f3+",
              "Ke5",
              "Kd3",
              "b5",
              "b3",
              "a5",
              "a4",
              "bxa4",
              "bxa4",
              "Kd6",
              "Kc4",
              "Kc6",
              "Nd3",
              "Kd6",
              "Nxc5",
              "Kc6",
              "Nb3",
              "Kb6",
              "Kd5",
              "Ka6",
              "Kc6",
              "Ka7",
              "Nxa5",
              "Ka6",
              "Nc4",
              "Ka7",
              "a5",
              "Ka6",
              "Kd5",
              "Kb5",
              "Ke5",
              "Kxc4",
              "a6",
              "Kd3",
              "a7",
              "Kxe3",
              "a8=Q",
              "Kf2",
              "Kxf5",
              "Kxg2",
              "Kg6",
              "Kxh2",
              "Kxh6",
              "Kg3",
              "Qe4",
              "Kf2",
              "f4",
              "Kg3",
              "f5",
              "Kf2",
              "f6",
              "Kg3",
              "f7",
              "Kf2",
              "f8=Q+",
              "Kg3",
              "Qg6+",
              "Kh4",
              "Qf4+",
              "Kh3",
              "Qgg3#",
              "Kc2",
              "Qff2+",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1",
              "Qgg1#",
              "Kc2",
              "Qgg3",
              "Kd1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 213,
            "completion_tokens": 361,
            "total_tokens": 574,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 213,
            "completion_tokens": 250,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 638,
          "total_completion_tokens": 1251,
          "total_tokens": 1889
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 213,
            "completion_tokens": 361,
            "total_tokens": 574,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 213,
            "completion_tokens": 250,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 212,
            "completion_tokens": 640,
            "total_tokens": 852,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r4rk1/pbp1bpp1/1p2qn1p/3pP3/7B/2NBP3/PP3PPP/2RQ1RK1 w - - 1 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": "h4f6",
          "aggressive_response": "15. Bxf6 Qxf6 16. Qf3 Qxf3 17. gxf3 c5 18. Rfd1 Rad8 19. Bf1 Rfe8 20. Bg2 d4\n21. exd4 cxd4 22. Ne4 f5 23. Ng3 g6 24. Rc7 Ba6 25. Rxa7 Bc4 26. b3 Bf7 27. f4\nd3 28. Nf1 Re2 29. Bf3 Rc2 30. Ne3 Rb2 31. Nc4 Bxc4 32. bxc4 d2 33. Bd5+ Kh8\n34. Kf1 Re8 35. Ra8 Rxa8 36. Bxa8 Rxa2 37. Bd5 Kg7 38. Ke2 Kf6 39. Rxd2 Ra3\n40. Rb2 Rh3 41. Rxb6+ Kg7 42. c5 Rxh2 43. c6 Rh4 44. c7 Rxf4 45. c8=Q h5\n46. Qg8+ Kh6 47. Qxg6# Qd4 Qe5+ Qe6",
          "aggressive_tokens": {
            "prompt_tokens": 223,
            "completion_tokens": 279,
            "total_tokens": 502,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf6",
            "Qf3",
            "Qxf3",
            "gxf3",
            "c5",
            "Rfd1",
            "Rad8",
            "Bf1",
            "Rfe8",
            "Bg2",
            "d4",
            "exd4",
            "cxd4",
            "Ne4",
            "f5",
            "Ng3",
            "g6",
            "Rc7",
            "Ba6",
            "Rxa7",
            "Bc4",
            "b3",
            "Bf7",
            "f4",
            "d3",
            "Nf1",
            "Re2",
            "Bf3",
            "Rc2",
            "Ne3",
            "Rb2",
            "Nc4",
            "Bxc4",
            "bxc4",
            "d2",
            "Bd5+",
            "Kh8",
            "Kf1",
            "Re8",
            "Ra8",
            "Rxa8",
            "Bxa8",
            "Rxa2",
            "Bd5",
            "Kg7",
            "Ke2",
            "Kf6",
            "Rxd2",
            "Ra3",
            "Rb2",
            "Rh3",
            "Rxb6+",
            "Kg7",
            "c5",
            "Rxh2",
            "c6",
            "Rh4",
            "c7",
            "Rxf4",
            "c8=Q",
            "h5",
            "Qg8+",
            "Kh6",
            "Qxg6#",
            "Qd4",
            "Qe5+",
            "Qe6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf6",
          "positional_uci": "h4f6",
          "positional_response": "15. Bxf6 Qxf6 16. Qf3 Qxf3 17. gxf3 c5 18. Rfd1 Rad8 19. Bf1 Rfe8 20. Bg2 Re6\n21. f4 Rg6 22. Kf1 Ba6+ 23. Kg1 Bb7 24. Kh1 Rgd6 25. Rd2 Bc6 26. Rcd1 d4 27.\nBxc6 Rxc6 28. exd4 cxd4 29. Rxd4 Rxd4 30. Rxd4 Rf6 31. Kg2 Kh7 32. Kf3 Kg6 33.\nNe4 Rc6 34. Rd6+ Rxd6 35. Nxd6 Kf6 36. Nc8 Ke6 37. Nxa7 Kd5 38. Ke3 Kc4 39. Nc6\nb5 40. Ne5+ Kd5 41. Nxf7 Ke6 42. Ne5 Kf5 43. b3 g5 44. Nd3 gxf4+ 45. Nxf4 Kg4\n46. a4 bxa4 47. bxa4 h5 48. a5 h4 49. a6 h3 50. a7 Kh4 51. a8=Q Kg4 52. Qf3+\nKh4 53. Qg3# Qe6+ Kh5 Qg5#",
          "positional_tokens": {
            "prompt_tokens": 223,
            "completion_tokens": 331,
            "total_tokens": 554,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf6",
            "Qf3",
            "Qxf3",
            "gxf3",
            "c5",
            "Rfd1",
            "Rad8",
            "Bf1",
            "Rfe8",
            "Bg2",
            "Re6",
            "f4",
            "Rg6",
            "Kf1",
            "Ba6+",
            "Kg1",
            "Bb7",
            "Kh1",
            "Rgd6",
            "Rd2",
            "Bc6",
            "Rcd1",
            "d4",
            "Bxc6",
            "Rxc6",
            "exd4",
            "cxd4",
            "Rxd4",
            "Rxd4",
            "Rxd4",
            "Rf6",
            "Kg2",
            "Kh7",
            "Kf3",
            "Kg6",
            "Ne4",
            "Rc6",
            "Rd6+",
            "Rxd6",
            "Nxd6",
            "Kf6",
            "Nc8",
            "Ke6",
            "Nxa7",
            "Kd5",
            "Ke3",
            "Kc4",
            "Nc6",
            "b5",
            "Ne5+",
            "Kd5",
            "Nxf7",
            "Ke6",
            "Ne5",
            "Kf5",
            "b3",
            "g5",
            "Nd3",
            "gxf4+",
            "Nxf4",
            "Kg4",
            "a4",
            "bxa4",
            "bxa4",
            "h5",
            "a5",
            "h4",
            "a6",
            "h3",
            "a7",
            "Kh4",
            "a8=Q",
            "Kg4",
            "Qf3+",
            "Kh4",
            "Qg3#",
            "Qe6+",
            "Kh5",
            "Qg5#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "h4f6",
          "neutral_response": "15. Bxf6 Qxf6 16. Qf3 Qxf3 17. gxf3 c5 18. Rfd1 Rfd8 19. Bf1 Rd6 20. Bg2 Rad8\n21. f4 Rg6 22. Kf1 Ba6+ 23. Kg1 Bb7 24. Kh1 Rgd6 25. Rd2 Bc6 26. Rcd1 d4 27.\nBxc6 Rxc6 28. exd4 cxd4 29. Rxd4 Rxd4 30. Rxd4 Rf6 31. Kg2 Kh7 32. Kf3 Kg6 33.\nNe4 Rc6 34. Rd6+ Rxd6 35. Nxd6 Kf6 36. Nc8 Ke6 37. Nxa7 Kd6 38. Nb5+ Kc5 39.\nNc3 Kc4 40. Ke4 b5 41. Nd5 b4 42. Ne3+ Kc5 43. b3 g6 44. f5 g5 45. Ng4 h5\n46. Ne5 f6 47. Nd7+ Kd6 48. Nxf6 Ke7 49. Nxh5 Kf7 50. Ke5 Ke7 51. f6+ Kf7 52.\nKf5 Kf8 53. Ke6 Ke8 54. f7+ Kf8 55. Nf6 Kg7 56. Nd7 Kg6 57. f8=Q Kh5 58. Qf5\nKh4 59. Nf6 g4 60. Qxg4# Qd4 Qe5 Qg4",
          "neutral_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 387,
            "total_tokens": 609,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf6",
            "Qf3",
            "Qxf3",
            "gxf3",
            "c5",
            "Rfd1",
            "Rfd8",
            "Bf1",
            "Rd6",
            "Bg2",
            "Rad8",
            "f4",
            "Rg6",
            "Kf1",
            "Ba6+",
            "Kg1",
            "Bb7",
            "Kh1",
            "Rgd6",
            "Rd2",
            "Bc6",
            "Rcd1",
            "d4",
            "Bxc6",
            "Rxc6",
            "exd4",
            "cxd4",
            "Rxd4",
            "Rxd4",
            "Rxd4",
            "Rf6",
            "Kg2",
            "Kh7",
            "Kf3",
            "Kg6",
            "Ne4",
            "Rc6",
            "Rd6+",
            "Rxd6",
            "Nxd6",
            "Kf6",
            "Nc8",
            "Ke6",
            "Nxa7",
            "Kd6",
            "Nb5+",
            "Kc5",
            "Nc3",
            "Kc4",
            "Ke4",
            "b5",
            "Nd5",
            "b4",
            "Ne3+",
            "Kc5",
            "b3",
            "g6",
            "f5",
            "g5",
            "Ng4",
            "h5",
            "Ne5",
            "f6",
            "Nd7+",
            "Kd6",
            "Nxf6",
            "Ke7",
            "Nxh5",
            "Kf7",
            "Ke5",
            "Ke7",
            "f6+",
            "Kf7",
            "Kf5",
            "Kf8",
            "Ke6",
            "Ke8",
            "f7+",
            "Kf8",
            "Nf6",
            "Kg7",
            "Nd7",
            "Kg6",
            "f8=Q",
            "Kh5",
            "Qf5",
            "Kh4",
            "Nf6",
            "g4",
            "Qxg4#",
            "Qd4",
            "Qe5",
            "Qg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4f6",
          "positional_uci": "h4f6",
          "neutral_uci": "h4f6",
          "consensus_move": "h4f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxf6",
              "Qf3",
              "Qxf3",
              "gxf3",
              "c5",
              "Rfd1",
              "Rad8",
              "Bf1",
              "Rfe8",
              "Bg2",
              "d4",
              "exd4",
              "cxd4",
              "Ne4",
              "f5",
              "Ng3",
              "g6",
              "Rc7",
              "Ba6",
              "Rxa7",
              "Bc4",
              "b3",
              "Bf7",
              "f4",
              "d3",
              "Nf1",
              "Re2",
              "Bf3",
              "Rc2",
              "Ne3",
              "Rb2",
              "Nc4",
              "Bxc4",
              "bxc4",
              "d2",
              "Bd5+",
              "Kh8",
              "Kf1",
              "Re8",
              "Ra8",
              "Rxa8",
              "Bxa8",
              "Rxa2",
              "Bd5",
              "Kg7",
              "Ke2",
              "Kf6",
              "Rxd2",
              "Ra3",
              "Rb2",
              "Rh3",
              "Rxb6+",
              "Kg7",
              "c5",
              "Rxh2",
              "c6",
              "Rh4",
              "c7",
              "Rxf4",
              "c8=Q",
              "h5",
              "Qg8+",
              "Kh6",
              "Qxg6#",
              "Qd4",
              "Qe5+",
              "Qe6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxf6",
              "Qf3",
              "Qxf3",
              "gxf3",
              "c5",
              "Rfd1",
              "Rad8",
              "Bf1",
              "Rfe8",
              "Bg2",
              "Re6",
              "f4",
              "Rg6",
              "Kf1",
              "Ba6+",
              "Kg1",
              "Bb7",
              "Kh1",
              "Rgd6",
              "Rd2",
              "Bc6",
              "Rcd1",
              "d4",
              "Bxc6",
              "Rxc6",
              "exd4",
              "cxd4",
              "Rxd4",
              "Rxd4",
              "Rxd4",
              "Rf6",
              "Kg2",
              "Kh7",
              "Kf3",
              "Kg6",
              "Ne4",
              "Rc6",
              "Rd6+",
              "Rxd6",
              "Nxd6",
              "Kf6",
              "Nc8",
              "Ke6",
              "Nxa7",
              "Kd5",
              "Ke3",
              "Kc4",
              "Nc6",
              "b5",
              "Ne5+",
              "Kd5",
              "Nxf7",
              "Ke6",
              "Ne5",
              "Kf5",
              "b3",
              "g5",
              "Nd3",
              "gxf4+",
              "Nxf4",
              "Kg4",
              "a4",
              "bxa4",
              "bxa4",
              "h5",
              "a5",
              "h4",
              "a6",
              "h3",
              "a7",
              "Kh4",
              "a8=Q",
              "Kg4",
              "Qf3+",
              "Kh4",
              "Qg3#",
              "Qe6+",
              "Kh5",
              "Qg5#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxf6",
              "Qf3",
              "Qxf3",
              "gxf3",
              "c5",
              "Rfd1",
              "Rfd8",
              "Bf1",
              "Rd6",
              "Bg2",
              "Rad8",
              "f4",
              "Rg6",
              "Kf1",
              "Ba6+",
              "Kg1",
              "Bb7",
              "Kh1",
              "Rgd6",
              "Rd2",
              "Bc6",
              "Rcd1",
              "d4",
              "Bxc6",
              "Rxc6",
              "exd4",
              "cxd4",
              "Rxd4",
              "Rxd4",
              "Rxd4",
              "Rf6",
              "Kg2",
              "Kh7",
              "Kf3",
              "Kg6",
              "Ne4",
              "Rc6",
              "Rd6+",
              "Rxd6",
              "Nxd6",
              "Kf6",
              "Nc8",
              "Ke6",
              "Nxa7",
              "Kd6",
              "Nb5+",
              "Kc5",
              "Nc3",
              "Kc4",
              "Ke4",
              "b5",
              "Nd5",
              "b4",
              "Ne3+",
              "Kc5",
              "b3",
              "g6",
              "f5",
              "g5",
              "Ng4",
              "h5",
              "Ne5",
              "f6",
              "Nd7+",
              "Kd6",
              "Nxf6",
              "Ke7",
              "Nxh5",
              "Kf7",
              "Ke5",
              "Ke7",
              "f6+",
              "Kf7",
              "Kf5",
              "Kf8",
              "Ke6",
              "Ke8",
              "f7+",
              "Kf8",
              "Nf6",
              "Kg7",
              "Nd7",
              "Kg6",
              "f8=Q",
              "Kh5",
              "Qf5",
              "Kh4",
              "Nf6",
              "g4",
              "Qxg4#",
              "Qd4",
              "Qe5",
              "Qg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 223,
            "completion_tokens": 279,
            "total_tokens": 502,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 223,
            "completion_tokens": 331,
            "total_tokens": 554,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 222,
            "completion_tokens": 387,
            "total_tokens": 609,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 668,
          "total_completion_tokens": 997,
          "total_tokens": 1665
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 223,
            "completion_tokens": 279,
            "total_tokens": 502,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 223,
            "completion_tokens": 331,
            "total_tokens": 554,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 222,
            "completion_tokens": 387,
            "total_tokens": 609,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/pbp2pp1/1p2qb1p/3p4/7B/2NBP3/PP3PPP/2RQ1RK1 w - - 0 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxd5",
          "aggressive_uci": "c3d5",
          "aggressive_response": "16. Nxd5 Bxd5 17. Bh7+ Kxh7 18. Qxd5 Qxb2 19. Rxc7 Kg8 20. Rxf7 Rxf7 21. Qxa8+ Kh7 22. Qd5 Rf6 23. Qe4+ Kg8 24. Qc4+ Kh7 25. Qb3 Qe5 26. Rd1 Qf5 27. Qd3 Qxd3 28. Rxd3 Rc6 29. g3 Rc2 30. Ra3 a5 31. Rb3 Rxa2 32. Rxb6 a4 33. Ra6 a3 34. Kg2 Ra1 35. Kf3 a2 36. h4 Kg8 37. Ra7 Kh7 38. h5 Kg8 39. g4 Kh7 40. Kf4 Kg8 41. Kf5 Kh7 42. f4 Kg8 43. Kg6 Kf8 44. Ra8+ Ke7 45. Kxg7 Rg1 46. Rxa2 Rxg4+ 47. Kxh6 Kf6 48. Ra6+ Kf5 49. Rg6 Rh4 50. Rg5+ Kf6 51. Kh7 Rh3 52. h6 Rxe3 53. Kg8 Re8+ 54. Kh7 Re7+ 55. Rg7 Re4 56. Kg8 Re8+ 57. Kh7 Re4 58. Rg6+ Kf7 59. Rg4 Kf6 60. Kg8 Re8+ 61. Kh7 Re7+ 62. Rg7 Re4 63. Kg8 Re8+ 64. Kh7 Re4 65. Rg6+ Kf7 66. Rg4 Kf6 67. Kg8 Re8+ 68. Kh7 Re7+ 69. Rg7 Re4 70. Kg8 Re8+ 71. Kh7 Re4 72. Rg6+ Kf7 73. Rg4 Kf6 74. Kg8 Re8+ 75. Kh7 Re7+ 76. Rg7 Re4 77. Kg8 Re8+ 78. Kh7 Re4 79. Rg6+ Kf7 80. Rg4 Kf6 81. Kg8 Re8+ 82. Kh7 Re7+ 83. Rg7 Re4 84. Kg8 Re8+ 85. Kh7 Re4 86. Rg6+ Kf7 87. Rg4 Kf6 88. Kg8 Re8+ 89. Kh7 Re7+ 90. Rg7 Re4 91. Kg8 Re8+ 92. Kh7 Re4 93. R",
          "aggressive_tokens": {
            "prompt_tokens": 232,
            "completion_tokens": 640,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxd5",
            "Bh7+",
            "Kxh7",
            "Qxd5",
            "Qxb2",
            "Rxc7",
            "Kg8",
            "Rxf7",
            "Rxf7",
            "Qxa8+",
            "Kh7",
            "Qd5",
            "Rf6",
            "Qe4+",
            "Kg8",
            "Qc4+",
            "Kh7",
            "Qb3",
            "Qe5",
            "Rd1",
            "Qf5",
            "Qd3",
            "Qxd3",
            "Rxd3",
            "Rc6",
            "g3",
            "Rc2",
            "Ra3",
            "a5",
            "Rb3",
            "Rxa2",
            "Rxb6",
            "a4",
            "Ra6",
            "a3",
            "Kg2",
            "Ra1",
            "Kf3",
            "a2",
            "h4",
            "Kg8",
            "Ra7",
            "Kh7",
            "h5",
            "Kg8",
            "g4",
            "Kh7",
            "Kf4",
            "Kg8",
            "Kf5",
            "Kh7",
            "f4",
            "Kg8",
            "Kg6",
            "Kf8",
            "Ra8+",
            "Ke7",
            "Kxg7",
            "Rg1",
            "Rxa2",
            "Rxg4+",
            "Kxh6",
            "Kf6",
            "Ra6+",
            "Kf5",
            "Rg6",
            "Rh4",
            "Rg5+",
            "Kf6",
            "Kh7",
            "Rh3",
            "h6",
            "Rxe3",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re7+",
            "Rg7",
            "Re4",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re4",
            "Rg6+",
            "Kf7",
            "Rg4",
            "Kf6",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re7+",
            "Rg7",
            "Re4",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re4",
            "Rg6+",
            "Kf7",
            "Rg4",
            "Kf6",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re7+",
            "Rg7",
            "Re4",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re4",
            "Rg6+",
            "Kf7",
            "Rg4",
            "Kf6",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re7+",
            "Rg7",
            "Re4",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re4",
            "Rg6+",
            "Kf7",
            "Rg4",
            "Kf6",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re7+",
            "Rg7",
            "Re4",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re4",
            "Rg6+",
            "Kf7",
            "Rg4",
            "Kf6",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re7+",
            "Rg7",
            "Re4",
            "Kg8",
            "Re8+",
            "Kh7",
            "Re4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxd5",
          "positional_uci": "c3d5",
          "positional_response": "16. Nxd5 Bxd5 17. Bh7+ Kxh7 18. Qxd5 Qxb2 19. Rxc7 Kg8 20. Rxf7 Rxf7 21. Qxa8+ Kh7 22. Qd5 Rc7 23. Qf5+ Kg8 24. Qd5+ Kh7 25. Qf5+ Kg8 26. Qd5+ Kh7 27. Qf5+ Kg8 28. Qd5+ Kh7 29. Qf5+ Kg8 30. Qd5+ Kh7 31. Qf5+ Kg8 32. Qd5+ Kh7 33. Qf5+ Kg8 34. Qd5+ Kh7 35. Qf5+ Kg8 36. Qd5+ Kh7 37. Qf5+ Kg8 38. Qd5+ Kh7 39. Qf5+ Kg8 40. Qd5+ Kh7 41. Qf5+ Kg8 42. Qd5+ Kh7 43. Qf5+ Kg8 44. Qd5+ Kh7 45. Qf5+ Kg8 46. Qd5+ Kh7 47. Qf5+ Kg8 48. Qd5+ Kh7 49. Qf5+ Kg8 50. Qd5+ Kh7 51. Qf5+ Kg8 52. Qd5+ Kh7 53. Qf5+ Kg8 54. Qd5+ Kh7 55. Qf5+ Kg8 56. Qd5+ Kh7 57. Qf5+ Kg8 58. Qd5+ Kh7 59. Qf5+ Kg8 60. Qd5+ Kh7 61. Qf5+ Kg8 62. Qd5+ Kh7 63. Qf5+ Kg8 64. Qd5+ Kh7 65. Qf5+ Kg8 66. Qd5+ Kh7 67. Qf5+ Kg8 68. Qd5+ Kh7 69. Qf5+ Kg8 70. Qd5+ Kh7 71. Qf5+ Kg8 72. Qd5+ Kh7 73. Qf5+ Kg8 74. Qd5+ Kh7 75. Qf5+ Kg8 76. Qd5+ Kh7 77. Qf5+ Kg8 78. Qd5+ Kh7 79. Qf5+ Kg8 80. Qd5+ Kh7 81. Qf5+ Kg8 82. Qd5+ Kh7 83. Qf5+ Kg8 84. Qd5+ Kh7 85. Qf5+ Kg8 86. Qd5+ Kh7 87",
          "positional_tokens": {
            "prompt_tokens": 232,
            "completion_tokens": 640,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxd5",
            "Bh7+",
            "Kxh7",
            "Qxd5",
            "Qxb2",
            "Rxc7",
            "Kg8",
            "Rxf7",
            "Rxf7",
            "Qxa8+",
            "Kh7",
            "Qd5",
            "Rc7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qf5+",
            "Kg8",
            "Qd5+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxd5",
          "neutral_uci": "c3d5",
          "neutral_response": "16. Nxd5 Bxd5 17. Bh7+ Kxh7 18. Qxd5 Qxb2 19. Rxc7 Kg8 20. Rxf7 Rxf7 21. Qxa8+ Kh7 22. Qd5 Rc7 23. Qf5+ Kg8 24. Qe6+ Kh7 25. Qe4+ Kg8 26. Qd5+ Kh7 27. Qd3+ Kg8 28. Qd8+ Kh7 29. Qxc7 Qxa2 30. Rd1 Qe2 31. Qd7 a5 32. Qd3+ Qxd3 33. Rxd3 b5 34. Rd5 b4 35. Rxa5 b3 36. Rb5 b2 37. Rxb2 Kg6 38. Rb5 Kf6 39. f4 Ke6 40. e4 Kf6 41. g4 Ke6 42. h4 Kf6 43. h5 Ke6 44. g5 hxg5 45. fxg5 Kf7 46. Rb6 Ke7 47. e5 Kf7 48. h6 gxh6 49. gxh6 Kg8 50. Rb7 Kh8 51. e6 Kg8 52. Rf7 Kh8 53. e7 Kg8 54. e8=Q# Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe7 Qd8 Qe",
          "neutral_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxd5",
            "Bh7+",
            "Kxh7",
            "Qxd5",
            "Qxb2",
            "Rxc7",
            "Kg8",
            "Rxf7",
            "Rxf7",
            "Qxa8+",
            "Kh7",
            "Qd5",
            "Rc7",
            "Qf5+",
            "Kg8",
            "Qe6+",
            "Kh7",
            "Qe4+",
            "Kg8",
            "Qd5+",
            "Kh7",
            "Qd3+",
            "Kg8",
            "Qd8+",
            "Kh7",
            "Qxc7",
            "Qxa2",
            "Rd1",
            "Qe2",
            "Qd7",
            "a5",
            "Qd3+",
            "Qxd3",
            "Rxd3",
            "b5",
            "Rd5",
            "b4",
            "Rxa5",
            "b3",
            "Rb5",
            "b2",
            "Rxb2",
            "Kg6",
            "Rb5",
            "Kf6",
            "f4",
            "Ke6",
            "e4",
            "Kf6",
            "g4",
            "Ke6",
            "h4",
            "Kf6",
            "h5",
            "Ke6",
            "g5",
            "hxg5",
            "fxg5",
            "Kf7",
            "Rb6",
            "Ke7",
            "e5",
            "Kf7",
            "h6",
            "gxh6",
            "gxh6",
            "Kg8",
            "Rb7",
            "Kh8",
            "e6",
            "Kg8",
            "Rf7",
            "Kh8",
            "e7",
            "Kg8",
            "e8=Q#",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8",
            "Qe7",
            "Qd8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c3d5",
          "positional_uci": "c3d5",
          "neutral_uci": "c3d5",
          "consensus_move": "c3d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxd5",
              "Bh7+",
              "Kxh7",
              "Qxd5",
              "Qxb2",
              "Rxc7",
              "Kg8",
              "Rxf7",
              "Rxf7",
              "Qxa8+",
              "Kh7",
              "Qd5",
              "Rf6",
              "Qe4+",
              "Kg8",
              "Qc4+",
              "Kh7",
              "Qb3",
              "Qe5",
              "Rd1",
              "Qf5",
              "Qd3",
              "Qxd3",
              "Rxd3",
              "Rc6",
              "g3",
              "Rc2",
              "Ra3",
              "a5",
              "Rb3",
              "Rxa2",
              "Rxb6",
              "a4",
              "Ra6",
              "a3",
              "Kg2",
              "Ra1",
              "Kf3",
              "a2",
              "h4",
              "Kg8",
              "Ra7",
              "Kh7",
              "h5",
              "Kg8",
              "g4",
              "Kh7",
              "Kf4",
              "Kg8",
              "Kf5",
              "Kh7",
              "f4",
              "Kg8",
              "Kg6",
              "Kf8",
              "Ra8+",
              "Ke7",
              "Kxg7",
              "Rg1",
              "Rxa2",
              "Rxg4+",
              "Kxh6",
              "Kf6",
              "Ra6+",
              "Kf5",
              "Rg6",
              "Rh4",
              "Rg5+",
              "Kf6",
              "Kh7",
              "Rh3",
              "h6",
              "Rxe3",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re7+",
              "Rg7",
              "Re4",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re4",
              "Rg6+",
              "Kf7",
              "Rg4",
              "Kf6",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re7+",
              "Rg7",
              "Re4",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re4",
              "Rg6+",
              "Kf7",
              "Rg4",
              "Kf6",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re7+",
              "Rg7",
              "Re4",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re4",
              "Rg6+",
              "Kf7",
              "Rg4",
              "Kf6",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re7+",
              "Rg7",
              "Re4",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re4",
              "Rg6+",
              "Kf7",
              "Rg4",
              "Kf6",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re7+",
              "Rg7",
              "Re4",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re4",
              "Rg6+",
              "Kf7",
              "Rg4",
              "Kf6",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re7+",
              "Rg7",
              "Re4",
              "Kg8",
              "Re8+",
              "Kh7",
              "Re4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxd5",
              "Bh7+",
              "Kxh7",
              "Qxd5",
              "Qxb2",
              "Rxc7",
              "Kg8",
              "Rxf7",
              "Rxf7",
              "Qxa8+",
              "Kh7",
              "Qd5",
              "Rc7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qf5+",
              "Kg8",
              "Qd5+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxd5",
              "Bh7+",
              "Kxh7",
              "Qxd5",
              "Qxb2",
              "Rxc7",
              "Kg8",
              "Rxf7",
              "Rxf7",
              "Qxa8+",
              "Kh7",
              "Qd5",
              "Rc7",
              "Qf5+",
              "Kg8",
              "Qe6+",
              "Kh7",
              "Qe4+",
              "Kg8",
              "Qd5+",
              "Kh7",
              "Qd3+",
              "Kg8",
              "Qd8+",
              "Kh7",
              "Qxc7",
              "Qxa2",
              "Rd1",
              "Qe2",
              "Qd7",
              "a5",
              "Qd3+",
              "Qxd3",
              "Rxd3",
              "b5",
              "Rd5",
              "b4",
              "Rxa5",
              "b3",
              "Rb5",
              "b2",
              "Rxb2",
              "Kg6",
              "Rb5",
              "Kf6",
              "f4",
              "Ke6",
              "e4",
              "Kf6",
              "g4",
              "Ke6",
              "h4",
              "Kf6",
              "h5",
              "Ke6",
              "g5",
              "hxg5",
              "fxg5",
              "Kf7",
              "Rb6",
              "Ke7",
              "e5",
              "Kf7",
              "h6",
              "gxh6",
              "gxh6",
              "Kg8",
              "Rb7",
              "Kh8",
              "e6",
              "Kg8",
              "Rf7",
              "Kh8",
              "e7",
              "Kg8",
              "e8=Q#",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8",
              "Qe7",
              "Qd8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 232,
            "completion_tokens": 640,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 232,
            "completion_tokens": 640,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 695,
          "total_completion_tokens": 1920,
          "total_tokens": 2615
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 232,
            "completion_tokens": 640,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 232,
            "completion_tokens": 640,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r4rk1/pbp2pp1/1p3q1p/3p4/8/2NBP3/PP3PPP/2RQ1RK1 w - - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxg6",
          "aggressive_uci": "d3g6",
          "aggressive_response": "17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kh7 20. Nxf8+ Rxf8 21. Rxc7 Ba6 22. Qd7 Rg8 23. Qf5+ Kh8 24. Rd1 Be2 25. Rdd7 Bb5 26. Qxb5 a6 27. Qxb6 a5 28. Qxh6+ gxh6 29. Rh7# Qg6 Qxg6",
          "aggressive_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 119,
            "total_tokens": 360,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "fxg6",
            "Ne7+",
            "Kh8",
            "Nxg6+",
            "Kh7",
            "Nxf8+",
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Rg8",
            "Qf5+",
            "Kh8",
            "Rd1",
            "Be2",
            "Rdd7",
            "Bb5",
            "Qxb5",
            "a6",
            "Qxb6",
            "a5",
            "Qxh6+",
            "gxh6",
            "Rh7#",
            "Qg6",
            "Qxg6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxg6",
          "positional_uci": "d3g6",
          "positional_response": "17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kh7 20. Nxf8+ Rxf8 21. Rxc7 Ba6 22. Qd7\nRg8 23. Qf5+ Kh8 24. Rd1 Be2 25. Rdd7 Bb5 26. Rxg7 Rxg7 27. Qf8+ Rg8 28. Qxh6# Qd8 Qh7#",
          "positional_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 114,
            "total_tokens": 355,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "fxg6",
            "Ne7+",
            "Kh8",
            "Nxg6+",
            "Kh7",
            "Nxf8+",
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Rg8",
            "Qf5+",
            "Kh8",
            "Rd1",
            "Be2",
            "Rdd7",
            "Bb5",
            "Rxg7",
            "Rxg7",
            "Qf8+",
            "Rg8",
            "Qxh6#",
            "Qd8",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxg6",
          "neutral_uci": "d3g6",
          "neutral_response": "17. Bxg6 fxg6 18. Ne7+ Kh7 19. Qd3 Rf6 20. Rxc7 Rb8 21. Rxb7 Rxb7 22. Qd8 Rxe7\n23. Qxe7 a5 24. Rd1 g5 25. Rd7 Kg6 26. Qxg7+ Kf5 27. Rd5+ Ke6 28. Qd7# Qxd7\n29. Rxd7 Kxd7 30. Kf1 Kc6 31. Ke2 Kc5 32. Kd3 b5 33. f3 Rd6+ 34. Kc3 b4+ 35.\nKc2 Kc4 36. b3+ Kc5 37. g3 Rf6 38. f4 gxf4 39. exf4 Re6 40. Kd3 Rd6+ 41. Ke3\nRd1 42. f5 Ra1 43. f6 Rxa2 44. f7 Ra3 45. f8=Q+ Kb5 46. Qb8+ Kc5 47. Qc7+ Kb5\n48. Qc4+ Kb6 49. Kd4 Ra2 50. Qc5+ Kb7 51. Qb5+ Kc7 52. Kc5 Rc2+ 53. Kd5 Rd2+\n54. Ke5 Rxh2 55. Qxa5+ Kd7 56. Qxb4 Rh5+ 57. Kf6 Rh3 58. Qg4+ Kd6 59. Qxh3\nKd5 60. Qxh6 Kd4 61. Qf4+ Kc3 62. Qc4+ Kb2 63. b4 Ka3 64. b5 Kb2 65. b6 Ka3\n66. b7 Kb2 67. b8=Q+ Ka3 68. Qa6# Qxa6 69. Qb3# Qxb3 70. axb3 Kxb3 71. g4\nKc4 72. g5 Kd5 73. g6 Kd6 74. g7 Kd7 75. g8=Q Kd6 76. Qe6+ Kc5 77. Qd7\nKc4 78. Ke5 Kc5 79. Qd5+ Kb4 80. Qc6 Kb3 81. Kd4 Kb4 82. Qc4+ Ka5 83. Qb3\nKa6 84. Kc5 Ka7 85. Kc6 Ka8 86. Qb7# Qxd7 87. Kxd7 Kb7 88. g4 Kb6 89. g5\nKc5 90. g",
          "neutral_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxg6",
            "Ne7+",
            "Kh7",
            "Qd3",
            "Rf6",
            "Rxc7",
            "Rb8",
            "Rxb7",
            "Rxb7",
            "Qd8",
            "Rxe7",
            "Qxe7",
            "a5",
            "Rd1",
            "g5",
            "Rd7",
            "Kg6",
            "Qxg7+",
            "Kf5",
            "Rd5+",
            "Ke6",
            "Qd7#",
            "Qxd7",
            "Rxd7",
            "Kxd7",
            "Kf1",
            "Kc6",
            "Ke2",
            "Kc5",
            "Kd3",
            "b5",
            "f3",
            "Rd6+",
            "Kc3",
            "b4+",
            "Kc2",
            "Kc4",
            "b3+",
            "Kc5",
            "g3",
            "Rf6",
            "f4",
            "gxf4",
            "exf4",
            "Re6",
            "Kd3",
            "Rd6+",
            "Ke3",
            "Rd1",
            "f5",
            "Ra1",
            "f6",
            "Rxa2",
            "f7",
            "Ra3",
            "f8=Q+",
            "Kb5",
            "Qb8+",
            "Kc5",
            "Qc7+",
            "Kb5",
            "Qc4+",
            "Kb6",
            "Kd4",
            "Ra2",
            "Qc5+",
            "Kb7",
            "Qb5+",
            "Kc7",
            "Kc5",
            "Rc2+",
            "Kd5",
            "Rd2+",
            "Ke5",
            "Rxh2",
            "Qxa5+",
            "Kd7",
            "Qxb4",
            "Rh5+",
            "Kf6",
            "Rh3",
            "Qg4+",
            "Kd6",
            "Qxh3",
            "Kd5",
            "Qxh6",
            "Kd4",
            "Qf4+",
            "Kc3",
            "Qc4+",
            "Kb2",
            "b4",
            "Ka3",
            "b5",
            "Kb2",
            "b6",
            "Ka3",
            "b7",
            "Kb2",
            "b8=Q+",
            "Ka3",
            "Qa6#",
            "Qxa6",
            "Qb3#",
            "Qxb3",
            "axb3",
            "Kxb3",
            "g4",
            "Kc4",
            "g5",
            "Kd5",
            "g6",
            "Kd6",
            "g7",
            "Kd7",
            "g8=Q",
            "Kd6",
            "Qe6+",
            "Kc5",
            "Qd7",
            "Kc4",
            "Ke5",
            "Kc5",
            "Qd5+",
            "Kb4",
            "Qc6",
            "Kb3",
            "Kd4",
            "Kb4",
            "Qc4+",
            "Ka5",
            "Qb3",
            "Ka6",
            "Kc5",
            "Ka7",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Qxd7",
            "Kxd7",
            "Kb7",
            "g4",
            "Kb6",
            "g5",
            "Kc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3g6",
          "positional_uci": "d3g6",
          "neutral_uci": "d3g6",
          "consensus_move": "d3g6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "fxg6",
              "Ne7+",
              "Kh8",
              "Nxg6+",
              "Kh7",
              "Nxf8+",
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Rg8",
              "Qf5+",
              "Kh8",
              "Rd1",
              "Be2",
              "Rdd7",
              "Bb5",
              "Qxb5",
              "a6",
              "Qxb6",
              "a5",
              "Qxh6+",
              "gxh6",
              "Rh7#",
              "Qg6",
              "Qxg6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "fxg6",
              "Ne7+",
              "Kh8",
              "Nxg6+",
              "Kh7",
              "Nxf8+",
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Rg8",
              "Qf5+",
              "Kh8",
              "Rd1",
              "Be2",
              "Rdd7",
              "Bb5",
              "Rxg7",
              "Rxg7",
              "Qf8+",
              "Rg8",
              "Qxh6#",
              "Qd8",
              "Qh7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "fxg6",
              "Ne7+",
              "Kh7",
              "Qd3",
              "Rf6",
              "Rxc7",
              "Rb8",
              "Rxb7",
              "Rxb7",
              "Qd8",
              "Rxe7",
              "Qxe7",
              "a5",
              "Rd1",
              "g5",
              "Rd7",
              "Kg6",
              "Qxg7+",
              "Kf5",
              "Rd5+",
              "Ke6",
              "Qd7#",
              "Qxd7",
              "Rxd7",
              "Kxd7",
              "Kf1",
              "Kc6",
              "Ke2",
              "Kc5",
              "Kd3",
              "b5",
              "f3",
              "Rd6+",
              "Kc3",
              "b4+",
              "Kc2",
              "Kc4",
              "b3+",
              "Kc5",
              "g3",
              "Rf6",
              "f4",
              "gxf4",
              "exf4",
              "Re6",
              "Kd3",
              "Rd6+",
              "Ke3",
              "Rd1",
              "f5",
              "Ra1",
              "f6",
              "Rxa2",
              "f7",
              "Ra3",
              "f8=Q+",
              "Kb5",
              "Qb8+",
              "Kc5",
              "Qc7+",
              "Kb5",
              "Qc4+",
              "Kb6",
              "Kd4",
              "Ra2",
              "Qc5+",
              "Kb7",
              "Qb5+",
              "Kc7",
              "Kc5",
              "Rc2+",
              "Kd5",
              "Rd2+",
              "Ke5",
              "Rxh2",
              "Qxa5+",
              "Kd7",
              "Qxb4",
              "Rh5+",
              "Kf6",
              "Rh3",
              "Qg4+",
              "Kd6",
              "Qxh3",
              "Kd5",
              "Qxh6",
              "Kd4",
              "Qf4+",
              "Kc3",
              "Qc4+",
              "Kb2",
              "b4",
              "Ka3",
              "b5",
              "Kb2",
              "b6",
              "Ka3",
              "b7",
              "Kb2",
              "b8=Q+",
              "Ka3",
              "Qa6#",
              "Qxa6",
              "Qb3#",
              "Qxb3",
              "axb3",
              "Kxb3",
              "g4",
              "Kc4",
              "g5",
              "Kd5",
              "g6",
              "Kd6",
              "g7",
              "Kd7",
              "g8=Q",
              "Kd6",
              "Qe6+",
              "Kc5",
              "Qd7",
              "Kc4",
              "Ke5",
              "Kc5",
              "Qd5+",
              "Kb4",
              "Qc6",
              "Kb3",
              "Kd4",
              "Kb4",
              "Qc4+",
              "Ka5",
              "Qb3",
              "Ka6",
              "Kc5",
              "Ka7",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Qxd7",
              "Kxd7",
              "Kb7",
              "g4",
              "Kb6",
              "g5",
              "Kc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 241,
            "completion_tokens": 119,
            "total_tokens": 360,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 241,
            "completion_tokens": 114,
            "total_tokens": 355,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 722,
          "total_completion_tokens": 873,
          "total_tokens": 1595
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 241,
            "completion_tokens": 119,
            "total_tokens": 360,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 241,
            "completion_tokens": 114,
            "total_tokens": 355,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r4rk1/pbp2pp1/1p4qp/3N4/8/3BP3/PP3PPP/2RQ1RK1 w - - 1 17"
    },
    {
      "turn": 35,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne7+",
          "aggressive_uci": "d5e7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6\nBxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kh7 20. Nxf8+ Rxf8 21. Rxc7 Ba6 22. Qd7 Rg8 23. Qf5+ Kh8 24. Rd1 Be2 25. Rdd7 Bg4 26. Qxg4 h5 27. Qxh5#",
          "aggressive_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 228,
            "total_tokens": 479,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kh8",
            "Nxg6+",
            "Kh7",
            "Nxf8+",
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Rg8",
            "Qf5+",
            "Kh8",
            "Rd1",
            "Be2",
            "Rdd7",
            "Bg4",
            "Qxg4",
            "h5",
            "Qxh5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne7+",
          "positional_uci": "d5e7",
          "positional_response": "18. Ne7+ Kh7 19. Qd3 Rf6 20. Rxc7 Bxg2 21. Kxg2 Raf8 22. f4 h5 23. Rf3 Kh6 24.\nRg3 g5 25. fxg5# d4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7\nRc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf6 Qxf6 Nxd5 Qg6 Bxg6 fxg6 Ne7+ Kh7 Qd3 Rf6 Rxc7 Bxg2 Kxg2 Raf8 f4 h5 Rg3 g5 fxg5# d4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf6 Qxf6 Nxd5 Qg6 Bxg6 fxg6 Ne7+ Kh7 Qd3 Rf6 Rxc7 Bxg2 Kxg2 Raf8 f4 h5 Rg3 g5 fxg5# d4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf6 Qxf6 Nxd5 Qg6 Bxg6 fxg6 Ne7+ Kh7 Qd3 Rf6 Rxc7 Bxg2 Kxg2 Raf8 f4 h5 Rg3 g5 fxg5# d4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf6 Qxf6 Nxd5 Qg6 Bxg6 fxg6 Ne7+ Kh7 Qd3 Rf6 Rxc7 Bxg2 Kxg2 Raf8 f4 h5 Rg3 g5 fxg5# d4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf6 Qxf6 Nxd5 Qg6 Bxg6 fxg",
          "positional_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 640,
            "total_tokens": 891,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh7",
            "Qd3",
            "Rf6",
            "Rxc7",
            "Bxg2",
            "Kxg2",
            "Raf8",
            "f4",
            "h5",
            "Rg3",
            "g5",
            "fxg5#",
            "d4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4",
            "b6",
            "c4",
            "Bb7",
            "Nc3",
            "Nbd7",
            "Rc1",
            "Qc8",
            "cxd5",
            "exd5",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Qe6",
            "exf6",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nxd5",
            "Qg6",
            "Bxg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne7+",
          "neutral_uci": "d5e7",
          "neutral_response": "18. Ne7+ Kh8 19. Nxg6+ Kh7 20. Nxf8+ Rxf8 21. Rxc7 Ba6 22. Qd7 Rg8 23. Qf5+ Kh8 24. Rd1 Be2 25. Rdd7 Bb5 26. Qxb5 a6 27. Qxb6 a5 28. Qxh6+ gxh6 29. Rh7# d4 d3 d2",
          "neutral_tokens": {
            "prompt_tokens": 250,
            "completion_tokens": 108,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kh8",
            "Nxg6+",
            "Kh7",
            "Nxf8+",
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Rg8",
            "Qf5+",
            "Kh8",
            "Rd1",
            "Be2",
            "Rdd7",
            "Bb5",
            "Qxb5",
            "a6",
            "Qxb6",
            "a5",
            "Qxh6+",
            "gxh6",
            "Rh7#",
            "d4",
            "d3",
            "d2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d5e7",
          "positional_uci": "d5e7",
          "neutral_uci": "d5e7",
          "consensus_move": "d5e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kh8",
              "Nxg6+",
              "Kh7",
              "Nxf8+",
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Rg8",
              "Qf5+",
              "Kh8",
              "Rd1",
              "Be2",
              "Rdd7",
              "Bg4",
              "Qxg4",
              "h5",
              "Qxh5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kh7",
              "Qd3",
              "Rf6",
              "Rxc7",
              "Bxg2",
              "Kxg2",
              "Raf8",
              "f4",
              "h5",
              "Rg3",
              "g5",
              "fxg5#",
              "d4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4",
              "b6",
              "c4",
              "Bb7",
              "Nc3",
              "Nbd7",
              "Rc1",
              "Qc8",
              "cxd5",
              "exd5",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Qe6",
              "exf6",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nxd5",
              "Qg6",
              "Bxg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kh8",
              "Nxg6+",
              "Kh7",
              "Nxf8+",
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Rg8",
              "Qf5+",
              "Kh8",
              "Rd1",
              "Be2",
              "Rdd7",
              "Bb5",
              "Qxb5",
              "a6",
              "Qxb6",
              "a5",
              "Qxh6+",
              "gxh6",
              "Rh7#",
              "d4",
              "d3",
              "d2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 251,
            "completion_tokens": 228,
            "total_tokens": 479,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 251,
            "completion_tokens": 640,
            "total_tokens": 891,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 250,
            "completion_tokens": 108,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 752,
          "total_completion_tokens": 976,
          "total_tokens": 1728
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 251,
            "completion_tokens": 228,
            "total_tokens": 479,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 251,
            "completion_tokens": 640,
            "total_tokens": 891,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 250,
            "completion_tokens": 108,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/pbp3p1/1p4pp/3N4/8/4P3/PP3PPP/2RQ1RK1 w - - 0 18"
    },
    {
      "turn": 37,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxg6+",
          "aggressive_uci": "e7g6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6\nBxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kh7 20. Nxf8+ Rxf8 21. Rxc7 Ba6 22. Qd7 Rg8 23. Qf5+ Kh8",
          "aggressive_tokens": {
            "prompt_tokens": 259,
            "completion_tokens": 195,
            "total_tokens": 454,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kh7",
            "Nxf8+",
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Rg8",
            "Qf5+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxg6+",
          "positional_uci": "e7g6",
          "positional_response": "19. Nxg6+ Kh7 20. Nxf8+ Rxf8 21. Rxc7 Ba6 22. Qd7 Rg8 23. Qf5+ Kh8 24. Rd1 Be2 25. Rdd7 Bb5 26. Qxb5 a6 27. Qxb6 a5 28. Qxh6+ gxh6 29. Rh7# Bb5 30. Rxh6# Rg7 31. Rc8+ Rg8 32. Rxg8+ Kxg8 33. Rh5 Be8 34. Rxa5 Bf7 35. Ra7 Kg7 36. Rxf7+ Kxf7 37. a4 Ke6 38. b4 Kd6 39. h4 Kc6 40. h5 Kd6 41. h6 Ke6 42. h7 Kf7 43. h8=Q Ke6 44. Qh5 Kd6 45. Qc5+ Ke6 46. a5 Kd7 47. a6 Ke6 48. a7 Kd7 49. a8=Q Ke6 50. Qa6+ Kd7 51. Qca7+ Kd8 52. Q6b7 Ke8 53. Qbb8# Kd7 54. Qbb6 Ke8 55. Qbb7 Kd8 56. Qbb8# Kd7 57. Qbb7+ Ke8 58. Qbb8# Kd7 59. Qbb7+ Ke8 60. Qbb8# Kd7 61. Qbb7+ Ke8 62. Qbb8# Kd7 63. Qbb7+ Ke8 64. Qbb8# Kd7 65. Qbb7+ Ke8 66. Qbb8# Kd7 67. Qbb7+ Ke8 68. Qbb8# Kd7 69. Qbb7+ Ke8 70. Qbb8# Kd7 71. Qbb7+ Ke8 72. Qbb8# Kd7 73. Qbb7+ Ke8 74. Qbb8# Kd7 75. Qbb7+ Ke8 76. Qbb8# Kd7 77. Qbb7+ Ke8 78. Qbb8# Kd7 79. Qbb7+ Ke8 80. Qbb8# Kd7 81. Qbb7+ Ke8 82. Qbb8# Kd7 83. Qbb7+ Ke8 84. Qbb8# Kd7 85. Qbb7+ Ke8 86. Qbb8# Kd7 87. Qbb7+ Ke8 88. Qbb8# Kd7 89. Qbb",
          "positional_tokens": {
            "prompt_tokens": 259,
            "completion_tokens": 640,
            "total_tokens": 899,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh7",
            "Nxf8+",
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Rg8",
            "Qf5+",
            "Kh8",
            "Rd1",
            "Be2",
            "Rdd7",
            "Bb5",
            "Qxb5",
            "a6",
            "Qxb6",
            "a5",
            "Qxh6+",
            "gxh6",
            "Rh7#",
            "Bb5",
            "Rxh6#",
            "Rg7",
            "Rc8+",
            "Rg8",
            "Rxg8+",
            "Kxg8",
            "Rh5",
            "Be8",
            "Rxa5",
            "Bf7",
            "Ra7",
            "Kg7",
            "Rxf7+",
            "Kxf7",
            "a4",
            "Ke6",
            "b4",
            "Kd6",
            "h4",
            "Kc6",
            "h5",
            "Kd6",
            "h6",
            "Ke6",
            "h7",
            "Kf7",
            "h8=Q",
            "Ke6",
            "Qh5",
            "Kd6",
            "Qc5+",
            "Ke6",
            "a5",
            "Kd7",
            "a6",
            "Ke6",
            "a7",
            "Kd7",
            "a8=Q",
            "Ke6",
            "Qa6+",
            "Kd7",
            "Qca7+",
            "Kd8",
            "Q6b7",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb6",
            "Ke8",
            "Qbb7",
            "Kd8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7",
            "Qbb7+",
            "Ke8",
            "Qbb8#",
            "Kd7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxg6+",
          "neutral_uci": "e7g6",
          "neutral_response": "19. Nxg6+ Kh7 20. Nxf8+ Rxf8 21. Rxc7 Ba6 22. Qd7 Rg8 23. Qf5+ Kh8 24. Rd1 Be2 25. Rdd7 Bb5 26. Qxb5 a6 27. Qxb6 a5 28. Qxh6+ gxh6 29. Rh7# Bb5 30. Rxh6# Rg7 31. Rxg7 Kxg7 32. Rh5 Be8 33. Rxa5 Bf7 34. Ra7 Kf6 35. Rxf7+ Kxf7 36. a4 Ke6 37. b4 Kd6 38. h4 Kc6 39. h5 Kd6 40. h6 Ke6 41. h7 Kf7 42. h8=Q Ke6 43. Qh5 Kd6 44. Qc5+ Ke6 45. a5 Kf6 46. a6 Ke6 47. a7 Kf6 48. a8=Q Ke6 49. Qa6+ Kd7 50. Qca7+ Kd8 51. Qd6+ Kc8 52. Qdc7# Bb5 53. Qab8# Rxb8 54. Qxb8# Kxb8 55. g4 Kc7 56. g5 Kd7 57. g6 Ke7 58. b5 Kf6 59. b6 Kxg6 60. b7 Kf6 61. b8=Q Ke6 62. Qxb5 Kd6 63. f4 Ke6 64. Qe5+ Kd7 65. f5 Kc6 66. f6 Kd7 67. f7 Kc6 68. f8=Q Kd7 69. Qff6 Kc8 70. Qee7 Kb8 71. Qff8# Kc8 72. Qc5+ Kb8 73. Qb6+ Kc8 74. Qc6+ Kb8 75. Qb6+ Kc8 76. Qc6+ Kb8 77. Qb6+ Kc8 78. Qc6+ Kb8 79. Qb6+ Kc8 80. Qc6+ Kb8 81. Qb6+ Kc8 82. Qc6+ Kb8 83. Qb6+ Kc8 84. Qc6+ Kb8 85. Qb6+ Kc8 86. Qc6+ Kb8 87. Qb6+ Kc8 88. Qc6+ Kb8 89. Qb6+ Kc8 90. Qc6+ Kb8",
          "neutral_tokens": {
            "prompt_tokens": 258,
            "completion_tokens": 640,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh7",
            "Nxf8+",
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Rg8",
            "Qf5+",
            "Kh8",
            "Rd1",
            "Be2",
            "Rdd7",
            "Bb5",
            "Qxb5",
            "a6",
            "Qxb6",
            "a5",
            "Qxh6+",
            "gxh6",
            "Rh7#",
            "Bb5",
            "Rxh6#",
            "Rg7",
            "Rxg7",
            "Kxg7",
            "Rh5",
            "Be8",
            "Rxa5",
            "Bf7",
            "Ra7",
            "Kf6",
            "Rxf7+",
            "Kxf7",
            "a4",
            "Ke6",
            "b4",
            "Kd6",
            "h4",
            "Kc6",
            "h5",
            "Kd6",
            "h6",
            "Ke6",
            "h7",
            "Kf7",
            "h8=Q",
            "Ke6",
            "Qh5",
            "Kd6",
            "Qc5+",
            "Ke6",
            "a5",
            "Kf6",
            "a6",
            "Ke6",
            "a7",
            "Kf6",
            "a8=Q",
            "Ke6",
            "Qa6+",
            "Kd7",
            "Qca7+",
            "Kd8",
            "Qd6+",
            "Kc8",
            "Qdc7#",
            "Bb5",
            "Qab8#",
            "Rxb8",
            "Qxb8#",
            "Kxb8",
            "g4",
            "Kc7",
            "g5",
            "Kd7",
            "g6",
            "Ke7",
            "b5",
            "Kf6",
            "b6",
            "Kxg6",
            "b7",
            "Kf6",
            "b8=Q",
            "Ke6",
            "Qxb5",
            "Kd6",
            "f4",
            "Ke6",
            "Qe5+",
            "Kd7",
            "f5",
            "Kc6",
            "f6",
            "Kd7",
            "f7",
            "Kc6",
            "f8=Q",
            "Kd7",
            "Qff6",
            "Kc8",
            "Qee7",
            "Kb8",
            "Qff8#",
            "Kc8",
            "Qc5+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Qc6+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Qc6+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Qc6+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Qc6+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Qc6+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Qc6+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Qc6+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Qc6+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Qc6+",
            "Kb8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7g6",
          "positional_uci": "e7g6",
          "neutral_uci": "e7g6",
          "consensus_move": "e7g6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kh7",
              "Nxf8+",
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Rg8",
              "Qf5+",
              "Kh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kh7",
              "Nxf8+",
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Rg8",
              "Qf5+",
              "Kh8",
              "Rd1",
              "Be2",
              "Rdd7",
              "Bb5",
              "Qxb5",
              "a6",
              "Qxb6",
              "a5",
              "Qxh6+",
              "gxh6",
              "Rh7#",
              "Bb5",
              "Rxh6#",
              "Rg7",
              "Rc8+",
              "Rg8",
              "Rxg8+",
              "Kxg8",
              "Rh5",
              "Be8",
              "Rxa5",
              "Bf7",
              "Ra7",
              "Kg7",
              "Rxf7+",
              "Kxf7",
              "a4",
              "Ke6",
              "b4",
              "Kd6",
              "h4",
              "Kc6",
              "h5",
              "Kd6",
              "h6",
              "Ke6",
              "h7",
              "Kf7",
              "h8=Q",
              "Ke6",
              "Qh5",
              "Kd6",
              "Qc5+",
              "Ke6",
              "a5",
              "Kd7",
              "a6",
              "Ke6",
              "a7",
              "Kd7",
              "a8=Q",
              "Ke6",
              "Qa6+",
              "Kd7",
              "Qca7+",
              "Kd8",
              "Q6b7",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb6",
              "Ke8",
              "Qbb7",
              "Kd8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7",
              "Qbb7+",
              "Ke8",
              "Qbb8#",
              "Kd7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kh7",
              "Nxf8+",
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Rg8",
              "Qf5+",
              "Kh8",
              "Rd1",
              "Be2",
              "Rdd7",
              "Bb5",
              "Qxb5",
              "a6",
              "Qxb6",
              "a5",
              "Qxh6+",
              "gxh6",
              "Rh7#",
              "Bb5",
              "Rxh6#",
              "Rg7",
              "Rxg7",
              "Kxg7",
              "Rh5",
              "Be8",
              "Rxa5",
              "Bf7",
              "Ra7",
              "Kf6",
              "Rxf7+",
              "Kxf7",
              "a4",
              "Ke6",
              "b4",
              "Kd6",
              "h4",
              "Kc6",
              "h5",
              "Kd6",
              "h6",
              "Ke6",
              "h7",
              "Kf7",
              "h8=Q",
              "Ke6",
              "Qh5",
              "Kd6",
              "Qc5+",
              "Ke6",
              "a5",
              "Kf6",
              "a6",
              "Ke6",
              "a7",
              "Kf6",
              "a8=Q",
              "Ke6",
              "Qa6+",
              "Kd7",
              "Qca7+",
              "Kd8",
              "Qd6+",
              "Kc8",
              "Qdc7#",
              "Bb5",
              "Qab8#",
              "Rxb8",
              "Qxb8#",
              "Kxb8",
              "g4",
              "Kc7",
              "g5",
              "Kd7",
              "g6",
              "Ke7",
              "b5",
              "Kf6",
              "b6",
              "Kxg6",
              "b7",
              "Kf6",
              "b8=Q",
              "Ke6",
              "Qxb5",
              "Kd6",
              "f4",
              "Ke6",
              "Qe5+",
              "Kd7",
              "f5",
              "Kc6",
              "f6",
              "Kd7",
              "f7",
              "Kc6",
              "f8=Q",
              "Kd7",
              "Qff6",
              "Kc8",
              "Qee7",
              "Kb8",
              "Qff8#",
              "Kc8",
              "Qc5+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Qc6+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Qc6+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Qc6+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Qc6+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Qc6+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Qc6+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Qc6+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Qc6+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Qc6+",
              "Kb8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 259,
            "completion_tokens": 195,
            "total_tokens": 454,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 259,
            "completion_tokens": 640,
            "total_tokens": 899,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 258,
            "completion_tokens": 640,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 776,
          "total_completion_tokens": 1475,
          "total_tokens": 2251
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 259,
            "completion_tokens": 195,
            "total_tokens": 454,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 259,
            "completion_tokens": 640,
            "total_tokens": 899,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 258,
            "completion_tokens": 640,
            "total_tokens": 898,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r4r1k/pbp1N1p1/1p4pp/8/8/4P3/PP3PPP/2RQ1RK1 w - - 2 19"
    },
    {
      "turn": 39,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxf8",
          "aggressive_uci": "g6f8",
          "aggressive_response": "20. Nxf8 Rxf8 21. Rxc7 Ba6 22. Qd7 Bxf1 23. Qxg7# 1-0\n20... Kh8 21. Qd7 Bxf1 22. Qxg7# 1-0",
          "aggressive_tokens": {
            "prompt_tokens": 268,
            "completion_tokens": 64,
            "total_tokens": 332,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Bxf1",
            "Qxg7#",
            "Kh8",
            "Qd7",
            "Bxf1",
            "Qxg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxf8",
          "positional_uci": "g6f8",
          "positional_response": "20. Nxf8 Rxf8 21. Rxc7 Ba6 22. Qd7 Bxf1 23. Qxg7# 1-0\n1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6\nBxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8\n20. Nxf8 Rxf8 21. Rxc7 Ba6 22. Qd7 Bxf1 23. Qxg7# 1-0 20. Nxf8 Rxf8 21. Rxc7 Ba6 22. Qd7 Bxf1 23. Qxg7# 1-0",
          "positional_tokens": {
            "prompt_tokens": 268,
            "completion_tokens": 273,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Bxf1",
            "Qxg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxf8",
          "neutral_uci": "g6f8",
          "neutral_response": "20. Nxf8 Rxf8 21. Rxc7 Ba6 22. Qd7 Bxf1 23. Qxg7# 1-0\n20. Nxf8 Rxf8 21. Rxc7 Ba6 22. Qd7 Bxf1 23. Qxg7# 1-0",
          "neutral_tokens": {
            "prompt_tokens": 267,
            "completion_tokens": 76,
            "total_tokens": 343,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf8",
            "Rxc7",
            "Ba6",
            "Qd7",
            "Bxf1",
            "Qxg7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g6f8",
          "positional_uci": "g6f8",
          "neutral_uci": "g6f8",
          "consensus_move": "g6f8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Bxf1",
              "Qxg7#",
              "Kh8",
              "Qd7",
              "Bxf1",
              "Qxg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Bxf1",
              "Qxg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxf8",
              "Rxc7",
              "Ba6",
              "Qd7",
              "Bxf1",
              "Qxg7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 268,
            "completion_tokens": 64,
            "total_tokens": 332,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 268,
            "completion_tokens": 273,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 267,
            "completion_tokens": 76,
            "total_tokens": 343,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 803,
          "total_completion_tokens": 413,
          "total_tokens": 1216
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 268,
            "completion_tokens": 64,
            "total_tokens": 332,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 268,
            "completion_tokens": 273,
            "total_tokens": 541,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 267,
            "completion_tokens": 76,
            "total_tokens": 343,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/pbp3p1/1p4Np/8/8/4P3/PP3PPP/2RQ1RK1 w - - 1 20"
    },
    {
      "turn": 41,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc7",
          "aggressive_uci": "c1c7",
          "aggressive_response": "21. Rxc7 Ba6 22. Qd7 Bxf1 23. Qf7# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf8 Qxf6 Nxd5 Qg6 Bxg6 fxg6 Ne7+ Kh8 Nxg6+ Kg8 Nxf8 Kxf8 Rxc7 Ba6 Qd7 Bxf1 Qf7# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf6 Qxf6 Nxd5 Qg6 Bxg6 fxg6 Ne7+ Kh8 Nxg6+ Kg8 Nxf8 Kxf8 Rxc7 Ba6 Qd7 Bxf1 Qf7# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf6 Qxf6 Nxd5 Qg6 Bxg6 fxg6 Ne7+ Kh8 Nxg6+ Kg8 Nxf8 Kxf8 Rxc7 Ba6 Qd7 Bxf1 Qf7# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf6 Qxf6 Nxd5 Qg6 Bxg6 fxg6 Ne7+ Kh8 Nxg6+ Kg8 Nxf8 Kxf8 Rxc7 Ba6 Qd7 Bxf1 Qf7# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb7 Nc3 Nbd7 Rc1 Qc8 cxd5 exd5 Ne5 Nxe5 dxe5 Qe6 exf6 Bxf6 Bxf6 Qxf6 Nxd5 Qg6 Bxg6 fxg6 Ne7+ Kh8 Nxg6+ Kg8 Nxf8 Kxf8 Rxc7 Ba6 Qd7 Bxf1 Qf7# e4 d5 Nf3 Nf6 Bg5 e6 Bd3 O-O O-O h6 Bh4 b6 c4 Bb",
          "aggressive_tokens": {
            "prompt_tokens": 277,
            "completion_tokens": 640,
            "total_tokens": 917,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ba6",
            "Qd7",
            "Bxf1",
            "Qf7#",
            "e4",
            "d5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4",
            "b6",
            "c4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxc7",
          "positional_uci": "c1c7",
          "positional_response": "21. Rxc7 Ba6 22. Qd7 Bxf1 23. Qf7# d4 e4 dxe3 fxe3 Bc8 Qf8#",
          "positional_tokens": {
            "prompt_tokens": 277,
            "completion_tokens": 41,
            "total_tokens": 318,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba6",
            "Qd7",
            "Bxf1",
            "Qf7#",
            "d4",
            "e4",
            "dxe3",
            "fxe3",
            "Bc8",
            "Qf8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxc7",
          "neutral_uci": "c1c7",
          "neutral_response": "21. Rxc7 Ba6 22. Qd7 Bxf1 23. Qf7# e4 Nf3+ Kh1",
          "neutral_tokens": {
            "prompt_tokens": 276,
            "completion_tokens": 32,
            "total_tokens": 308,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba6",
            "Qd7",
            "Bxf1",
            "Qf7#",
            "e4",
            "Nf3+",
            "Kh1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1c7",
          "positional_uci": "c1c7",
          "neutral_uci": "c1c7",
          "consensus_move": "c1c7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba6",
              "Qd7",
              "Bxf1",
              "Qf7#",
              "e4",
              "d5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4",
              "b6",
              "c4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ba6",
              "Qd7",
              "Bxf1",
              "Qf7#",
              "d4",
              "e4",
              "dxe3",
              "fxe3",
              "Bc8",
              "Qf8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ba6",
              "Qd7",
              "Bxf1",
              "Qf7#",
              "e4",
              "Nf3+",
              "Kh1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 277,
            "completion_tokens": 640,
            "total_tokens": 917,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 277,
            "completion_tokens": 41,
            "total_tokens": 318,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 276,
            "completion_tokens": 32,
            "total_tokens": 308,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 830,
          "total_completion_tokens": 713,
          "total_tokens": 1543
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 277,
            "completion_tokens": 640,
            "total_tokens": 917,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 277,
            "completion_tokens": 41,
            "total_tokens": 318,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 276,
            "completion_tokens": 32,
            "total_tokens": 308,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4k2/pbp3p1/1p5p/8/8/4P3/PP3PPP/2RQ1RK1 w - - 0 21"
    },
    {
      "turn": 43,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxb7",
          "aggressive_uci": "c7b7",
          "aggressive_response": "22. Rxb7 Rc7 23. Qd8+ Kf7 24. Rxc7+ Kg6 25. Qd6+ Kh7 26. Qe7 Kg6 27. Qxg7+ Kf5\n28. Rc6 Ke4 29. Qd4+ Kf5 30. Rf6+ Kg5 31. Qf4+ Kh5 32. Rxh6# Qc8 33. Rxh6# Qg8\n34. Qh4# Qh7 35. Rxh7# Qxh7 36. Qxh7# Qxh7 37. Rxh7# Qxh7 38. Qxh7# Qxh7\n39. Rxh7# Qxh7 40. Qxh7# Qxh7 41. Rxh7# Qxh7 42. Qxh7# Qxh7 43. Rxh7# Qxh7\n44. Qxh7# Qxh7 45. Rxh7# Qxh7 46. Qxh7# Qxh7 47. Rxh7# Qxh7 48. Qxh7# Qxh7\n49. Rxh7# Qxh7 50. Qxh7# Qxh7 51. Rxh7# Qxh7 52. Qxh7# Qxh7 53. Rxh7# Qxh7\n54. Qxh7# Qxh7 55. Rxh7# Qxh7 56. Qxh7# Qxh7 57. Rxh7# Qxh7 58. Qxh7# Qxh7\n59. Rxh7# Qxh7 60. Qxh7# Qxh7 61. Rxh7# Qxh7 62. Qxh7# Qxh7 63. Rxh7# Qxh7\n64. Qxh7# Qxh7 65. Rxh7# Qxh7 66. Qxh7# Qxh7 67. Rxh7# Qxh7 68. Qxh7# Qxh7\n69. Rxh7# Qxh7 70. Qxh7# Qxh7 71. Rxh7# Qxh7 72. Qxh7# Qxh7 73. Rxh7# Qxh7\n74. Qxh7# Qxh7 75. Rxh7# Qxh7 76. Qxh7# Qxh7 77. Rxh7# Qxh7 78. Qxh7# Qxh7\n79. Rxh7# Qxh7 80.",
          "aggressive_tokens": {
            "prompt_tokens": 285,
            "completion_tokens": 640,
            "total_tokens": 925,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rc7",
            "Qd8+",
            "Kf7",
            "Rxc7+",
            "Kg6",
            "Qd6+",
            "Kh7",
            "Qe7",
            "Kg6",
            "Qxg7+",
            "Kf5",
            "Rc6",
            "Ke4",
            "Qd4+",
            "Kf5",
            "Rf6+",
            "Kg5",
            "Qf4+",
            "Kh5",
            "Rxh6#",
            "Qc8",
            "Rxh6#",
            "Qg8",
            "Qh4#",
            "Qh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7",
            "Qxh7#",
            "Qxh7",
            "Rxh7#",
            "Qxh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd7",
          "positional_uci": "d1d7",
          "positional_response": "22. Qd7 Rxc7 23. Qxc7 Kg8 24. Qxb7 Kh7 25. Qxa7 Kg6 26. Qxb6+ Kh7 27. Qc7 Kg6\n28. Rd1 Kh7 29. Rd7 Kg6 30. Rxg7+ Kh5 31. Qe5+ Kh4 32. Qf4+ Kh5 33. Qg4# Qg6\n34. Qxg6+ Kh4 35. Qg4# Kh5 36. Qh3# Kh4 37. Qxh6# Kh5 38. Qg5# Kh4 39. Qg4# Kh5\n40. Qg5# Kh4 41. Qg4# Kh5 42. Qg5# Kh4 43. Qg4# Kh5 44. Qg5# Kh4 45. Qg4# Kh5\n46. Qg5# Kh4 47. Qg4# Kh5 48. Qg5# Kh4 49. Qg4# Kh5 50. Qg5# Kh4 51. Qg4# Kh5\n52. Qg5# Kh4 53. Qg4# Kh5 54. Qg5# Kh4 55. Qg4# Kh5 56. Qg5# Kh4 57. Qg4# Kh5\n58. Qg5# Kh4 59. Qg4# Kh5 60. Qg5# Kh4 61. Qg4# Kh5 62. Qg5# Kh4 63. Qg4# Kh5\n64. Qg5# Kh4 65. Qg4# Kh5 66. Qg5# Kh4 67. Qg4# Kh5 68. Qg5# Kh4 69. Qg4# Kh5\n70. Qg5# Kh4 71. Qg4# Kh5 72. Qg5# Kh4 73. Qg4# Kh5 74. Qg5# Kh4 75. Qg4# Kh5\n76. Qg5# Kh4 77. Qg4# Kh5 78. Qg5# Kh4 79. Qg4# Kh5 80. Qg5# Kh4 81. Qg4# Kh5\n82. Qg5# Kh4 83. Qg4# Kh5 84. Qg5# Kh4 85. Qg4# Kh5 86. Qg5# Kh4 87. Qg4# Kh5\n88. Qg5# Kh4 89. Qg4# Kh5 90. Qg5# Kh4 91. Qg4# Kh5 92. Qg5# Kh4 93. Qg4",
          "positional_tokens": {
            "prompt_tokens": 285,
            "completion_tokens": 640,
            "total_tokens": 925,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxc7",
            "Qxc7",
            "Kg8",
            "Qxb7",
            "Kh7",
            "Qxa7",
            "Kg6",
            "Qxb6+",
            "Kh7",
            "Qc7",
            "Kg6",
            "Rd1",
            "Kh7",
            "Rd7",
            "Kg6",
            "Rxg7+",
            "Kh5",
            "Qe5+",
            "Kh4",
            "Qf4+",
            "Kh5",
            "Qg4#",
            "Qg6",
            "Qxg6+",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qh3#",
            "Kh4",
            "Qxh6#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4#",
            "Kh5",
            "Qg5#",
            "Kh4",
            "Qg4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qd7",
          "neutral_uci": "d1d7",
          "neutral_response": "22. Qd7 Rxc7 23. Qxc7 Kg8 24. Qxb7 Kh7 25. Qxa7 Kg6 26. Qxb6+ Kh7 27. Qe6 Kh8\n28. Qf7 Kh7 29. Rd1 Kh8 30. Rd7 Kh7 31. Qxg7# d4 dxe3 Qd8#",
          "neutral_tokens": {
            "prompt_tokens": 284,
            "completion_tokens": 89,
            "total_tokens": 373,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxc7",
            "Qxc7",
            "Kg8",
            "Qxb7",
            "Kh7",
            "Qxa7",
            "Kg6",
            "Qxb6+",
            "Kh7",
            "Qe6",
            "Kh8",
            "Qf7",
            "Kh7",
            "Rd1",
            "Kh8",
            "Rd7",
            "Kh7",
            "Qxg7#",
            "d4",
            "dxe3",
            "Qd8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c7b7",
          "positional_uci": "d1d7",
          "neutral_uci": "d1d7",
          "consensus_move": "d1d7",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rc7",
              "Qd8+",
              "Kf7",
              "Rxc7+",
              "Kg6",
              "Qd6+",
              "Kh7",
              "Qe7",
              "Kg6",
              "Qxg7+",
              "Kf5",
              "Rc6",
              "Ke4",
              "Qd4+",
              "Kf5",
              "Rf6+",
              "Kg5",
              "Qf4+",
              "Kh5",
              "Rxh6#",
              "Qc8",
              "Rxh6#",
              "Qg8",
              "Qh4#",
              "Qh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7",
              "Qxh7#",
              "Qxh7",
              "Rxh7#",
              "Qxh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxc7",
              "Qxc7",
              "Kg8",
              "Qxb7",
              "Kh7",
              "Qxa7",
              "Kg6",
              "Qxb6+",
              "Kh7",
              "Qc7",
              "Kg6",
              "Rd1",
              "Kh7",
              "Rd7",
              "Kg6",
              "Rxg7+",
              "Kh5",
              "Qe5+",
              "Kh4",
              "Qf4+",
              "Kh5",
              "Qg4#",
              "Qg6",
              "Qxg6+",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qh3#",
              "Kh4",
              "Qxh6#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4#",
              "Kh5",
              "Qg5#",
              "Kh4",
              "Qg4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxc7",
              "Qxc7",
              "Kg8",
              "Qxb7",
              "Kh7",
              "Qxa7",
              "Kg6",
              "Qxb6+",
              "Kh7",
              "Qe6",
              "Kh8",
              "Qf7",
              "Kh7",
              "Rd1",
              "Kh8",
              "Rd7",
              "Kh7",
              "Qxg7#",
              "d4",
              "dxe3",
              "Qd8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 285,
            "completion_tokens": 640,
            "total_tokens": 925,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 285,
            "completion_tokens": 640,
            "total_tokens": 925,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 284,
            "completion_tokens": 89,
            "total_tokens": 373,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 854,
          "total_completion_tokens": 1369,
          "total_tokens": 2223
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 285,
            "completion_tokens": 640,
            "total_tokens": 925,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 285,
            "completion_tokens": 640,
            "total_tokens": 925,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 284,
            "completion_tokens": 89,
            "total_tokens": 373,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2k2/pbR3p1/1p5p/8/8/4P3/PP3PPP/3Q1RK1 w - - 1 22"
    },
    {
      "turn": 45,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxc7",
          "aggressive_uci": "d7c7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4\nBb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6\nBxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20.\nNxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Bxg2 24. Kxg2 Kg8 25. Rd1 Kh7 26.\nQc2+ Kg8 27. Rd8+ Kf7 28. Qf5+ Ke7 29. Rd7+ Ke8 30. Qf7# Qd7 Qxd7 31. Qxd7+\nKxd7 32. Kf3 Ke6 33. Ke4 g6 34. f4 a6 35. h4 h5 36. b4 b5 37. a3 Kd6 38. f5\ngxf5+ 39. Kxf5 Kd5 40. e4+ Kc4 41. e5 Kb3 42. e6 Kxa3 43. e7 Kxb4 44. e8=Q\na5 45. Qe4+ Kb3 46. Qd3+ Kb4 47. Qd2+ Ka4 48. Qa2+ Kb4 49. Ke4 a4 50. Kd4\nKa5 51. Kc5 b4 52. Qc4 b3 53. Qb5# Qd7 Qxd7 54. Qxd7 b2 55. Qb5# Qd7 Qxd7 56.\nQxd7 b2 57. Qb5# Qd7 Qxd7 58. Qxd7 b2 59. Qb5# Qd7 Qxd7 60. Qxd7 b2 61.\nQb5# Qd7 Qxd7 62. Qxd7 b2 63. Qb5# Qd7 Qxd7 64. Qxd7 b2 65. Qb5# Qd7 Qxd7 66.\nQxd7 b2 67. Qb5# Qd7 Qxd7 68. Qxd7 b2 69. Qb5# Qd7 Qxd7 70. Qxd7 b2 71.\nQb5# Q",
          "aggressive_tokens": {
            "prompt_tokens": 294,
            "completion_tokens": 640,
            "total_tokens": 934,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxg2",
            "Kxg2",
            "Kg8",
            "Rd1",
            "Kh7",
            "Qc2+",
            "Kg8",
            "Rd8+",
            "Kf7",
            "Qf5+",
            "Ke7",
            "Rd7+",
            "Ke8",
            "Qf7#",
            "Qd7",
            "Qxd7",
            "Qxd7+",
            "Kxd7",
            "Kf3",
            "Ke6",
            "Ke4",
            "g6",
            "f4",
            "a6",
            "h4",
            "h5",
            "b4",
            "b5",
            "a3",
            "Kd6",
            "f5",
            "gxf5+",
            "Kxf5",
            "Kd5",
            "e4+",
            "Kc4",
            "e5",
            "Kb3",
            "e6",
            "Kxa3",
            "e7",
            "Kxb4",
            "e8=Q",
            "a5",
            "Qe4+",
            "Kb3",
            "Qd3+",
            "Kb4",
            "Qd2+",
            "Ka4",
            "Qa2+",
            "Kb4",
            "Ke4",
            "a4",
            "Kd4",
            "Ka5",
            "Kc5",
            "b4",
            "Qc4",
            "b3",
            "Qb5#",
            "Qd7",
            "Qxd7",
            "Qxd7",
            "b2",
            "Qb5#",
            "Qd7",
            "Qxd7",
            "Qxd7",
            "b2",
            "Qb5#",
            "Qd7",
            "Qxd7",
            "Qxd7",
            "b2",
            "Qb5#",
            "Qd7",
            "Qxd7",
            "Qxd7",
            "b2",
            "Qb5#",
            "Qd7",
            "Qxd7",
            "Qxd7",
            "b2",
            "Qb5#",
            "Qd7",
            "Qxd7",
            "Qxd7",
            "b2",
            "Qb5#",
            "Qd7",
            "Qxd7",
            "Qxd7",
            "b2",
            "Qb5#",
            "Qd7",
            "Qxd7",
            "Qxd7",
            "b2",
            "Qb5#",
            "Qd7",
            "Qxd7",
            "Qxd7",
            "b2",
            "Qb5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxc7",
          "positional_uci": "d7c7",
          "positional_response": "23. Qxc7 Bxg2 24. Kxg2 Kg8 25. Rd1 Kh7 26. Rd7 Kg6 27. Rxg7+ Kf5 28. Qf7+ Ke4\n29. Qf4+ Kd3 30. Rd7+ Ke2 31. Qf3+ Ke1 32. Rd1# Bb7 Qxb7 Qxb7",
          "positional_tokens": {
            "prompt_tokens": 294,
            "completion_tokens": 94,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg2",
            "Kxg2",
            "Kg8",
            "Rd1",
            "Kh7",
            "Rd7",
            "Kg6",
            "Rxg7+",
            "Kf5",
            "Qf7+",
            "Ke4",
            "Qf4+",
            "Kd3",
            "Rd7+",
            "Ke2",
            "Qf3+",
            "Ke1",
            "Rd1#",
            "Bb7",
            "Qxb7",
            "Qxb7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxc7",
          "neutral_uci": "d7c7",
          "neutral_response": "23. Qxc7 Bxg2 24. Kxg2 Kg8 25. Rd1 Kh7 26. Rd7 Kg6 27. Rxg7+ Kf5 28. Qf4+ Ke6\n29. Rg6+ Kd5 30. Qd4# Kg5 31. Qf4+ Kxg6 32. e4 Kg7 33. e5 Kg6 34. e6 Kg7\n35. e7 Kg6 36. e8=Q+ Kg7 37. Qef7+ Kh8 38. Q4f6# Kg8 39. Q6g7# Kg8 40. Qfg6#\nBb7 41. Qg8# Bc8 42. Q6g7# Bb7+ 43. Kg3 Bc8 44. Q7f7# Bb7 45. Qgf8# Bc8 46.\nQ7g8# Bb7+ 47. Kg4 Bc8+ 48. Kh5 Bb7+ 49. Kg6 Bc8+ 50. Kf6 Bb7+ 51. Ke7 Bc8+\n52. Kd8 Bb7+ 53. Kc7 Bc8+ 54. Kb8 Bb7+ 55. Kxb7 Bb7+ 56. Kc7 Bc8+ 57. Kd8\nBb7+ 58. Ke7 Bc8+ 59. Kf6 Bb7+ 60. Ke5 Bc8+ 61. Kd4 Bb7+ 62. Kc3 Bc8+ 63.\nKb4 Bb7+ 64. Ka3 Bc8+ 65. Kb3 Bb7+ 66. Kc2 Bc8+ 67. Kd1 Bb7+ 68. Ke1 Bc8+\n69. Kf1 Bb7+ 70. Kg1 Bc8+ 71. Kh1 Bb7+ 72. Kg1 Bc8+ 73. Kf1 Bb7+ 74. Ke1\nBc8+ 75. Kd1 Bb7+ 76. Kc1 Bc8+ 77. Kb1 Bb7+ 78. Ka1 Bc8+ 79. Kb1 Bb7+ 80.\nKc1 Bc8+ 81. Kd1 Bb7+ 82. Ke1 Bc8+ 83. Kf1 Bb7+ 84. Kg1 Bc8+ 85. Kh1 Bb7+ 86.\nKg1 Bc8+ 87. Kf1 Bb7+ 88. Ke1 Bc8+ 89. Kd1 Bb7+ 90. Kc1 Bc",
          "neutral_tokens": {
            "prompt_tokens": 293,
            "completion_tokens": 640,
            "total_tokens": 933,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxg2",
            "Kxg2",
            "Kg8",
            "Rd1",
            "Kh7",
            "Rd7",
            "Kg6",
            "Rxg7+",
            "Kf5",
            "Qf4+",
            "Ke6",
            "Rg6+",
            "Kd5",
            "Qd4#",
            "Kg5",
            "Qf4+",
            "Kxg6",
            "e4",
            "Kg7",
            "e5",
            "Kg6",
            "e6",
            "Kg7",
            "e7",
            "Kg6",
            "e8=Q+",
            "Kg7",
            "Qef7+",
            "Kh8",
            "Q4f6#",
            "Kg8",
            "Q6g7#",
            "Kg8",
            "Qfg6#",
            "Bb7",
            "Qg8#",
            "Bc8",
            "Q6g7#",
            "Bb7+",
            "Kg3",
            "Bc8",
            "Q7f7#",
            "Bb7",
            "Qgf8#",
            "Bc8",
            "Q7g8#",
            "Bb7+",
            "Kg4",
            "Bc8+",
            "Kh5",
            "Bb7+",
            "Kg6",
            "Bc8+",
            "Kf6",
            "Bb7+",
            "Ke7",
            "Bc8+",
            "Kd8",
            "Bb7+",
            "Kc7",
            "Bc8+",
            "Kb8",
            "Bb7+",
            "Kxb7",
            "Bb7+",
            "Kc7",
            "Bc8+",
            "Kd8",
            "Bb7+",
            "Ke7",
            "Bc8+",
            "Kf6",
            "Bb7+",
            "Ke5",
            "Bc8+",
            "Kd4",
            "Bb7+",
            "Kc3",
            "Bc8+",
            "Kb4",
            "Bb7+",
            "Ka3",
            "Bc8+",
            "Kb3",
            "Bb7+",
            "Kc2",
            "Bc8+",
            "Kd1",
            "Bb7+",
            "Ke1",
            "Bc8+",
            "Kf1",
            "Bb7+",
            "Kg1",
            "Bc8+",
            "Kh1",
            "Bb7+",
            "Kg1",
            "Bc8+",
            "Kf1",
            "Bb7+",
            "Ke1",
            "Bc8+",
            "Kd1",
            "Bb7+",
            "Kc1",
            "Bc8+",
            "Kb1",
            "Bb7+",
            "Ka1",
            "Bc8+",
            "Kb1",
            "Bb7+",
            "Kc1",
            "Bc8+",
            "Kd1",
            "Bb7+",
            "Ke1",
            "Bc8+",
            "Kf1",
            "Bb7+",
            "Kg1",
            "Bc8+",
            "Kh1",
            "Bb7+",
            "Kg1",
            "Bc8+",
            "Kf1",
            "Bb7+",
            "Ke1",
            "Bc8+",
            "Kd1",
            "Bb7+",
            "Kc1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7c7",
          "positional_uci": "d7c7",
          "neutral_uci": "d7c7",
          "consensus_move": "d7c7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxg2",
              "Kxg2",
              "Kg8",
              "Rd1",
              "Kh7",
              "Qc2+",
              "Kg8",
              "Rd8+",
              "Kf7",
              "Qf5+",
              "Ke7",
              "Rd7+",
              "Ke8",
              "Qf7#",
              "Qd7",
              "Qxd7",
              "Qxd7+",
              "Kxd7",
              "Kf3",
              "Ke6",
              "Ke4",
              "g6",
              "f4",
              "a6",
              "h4",
              "h5",
              "b4",
              "b5",
              "a3",
              "Kd6",
              "f5",
              "gxf5+",
              "Kxf5",
              "Kd5",
              "e4+",
              "Kc4",
              "e5",
              "Kb3",
              "e6",
              "Kxa3",
              "e7",
              "Kxb4",
              "e8=Q",
              "a5",
              "Qe4+",
              "Kb3",
              "Qd3+",
              "Kb4",
              "Qd2+",
              "Ka4",
              "Qa2+",
              "Kb4",
              "Ke4",
              "a4",
              "Kd4",
              "Ka5",
              "Kc5",
              "b4",
              "Qc4",
              "b3",
              "Qb5#",
              "Qd7",
              "Qxd7",
              "Qxd7",
              "b2",
              "Qb5#",
              "Qd7",
              "Qxd7",
              "Qxd7",
              "b2",
              "Qb5#",
              "Qd7",
              "Qxd7",
              "Qxd7",
              "b2",
              "Qb5#",
              "Qd7",
              "Qxd7",
              "Qxd7",
              "b2",
              "Qb5#",
              "Qd7",
              "Qxd7",
              "Qxd7",
              "b2",
              "Qb5#",
              "Qd7",
              "Qxd7",
              "Qxd7",
              "b2",
              "Qb5#",
              "Qd7",
              "Qxd7",
              "Qxd7",
              "b2",
              "Qb5#",
              "Qd7",
              "Qxd7",
              "Qxd7",
              "b2",
              "Qb5#",
              "Qd7",
              "Qxd7",
              "Qxd7",
              "b2",
              "Qb5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxg2",
              "Kxg2",
              "Kg8",
              "Rd1",
              "Kh7",
              "Rd7",
              "Kg6",
              "Rxg7+",
              "Kf5",
              "Qf7+",
              "Ke4",
              "Qf4+",
              "Kd3",
              "Rd7+",
              "Ke2",
              "Qf3+",
              "Ke1",
              "Rd1#",
              "Bb7",
              "Qxb7",
              "Qxb7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxg2",
              "Kxg2",
              "Kg8",
              "Rd1",
              "Kh7",
              "Rd7",
              "Kg6",
              "Rxg7+",
              "Kf5",
              "Qf4+",
              "Ke6",
              "Rg6+",
              "Kd5",
              "Qd4#",
              "Kg5",
              "Qf4+",
              "Kxg6",
              "e4",
              "Kg7",
              "e5",
              "Kg6",
              "e6",
              "Kg7",
              "e7",
              "Kg6",
              "e8=Q+",
              "Kg7",
              "Qef7+",
              "Kh8",
              "Q4f6#",
              "Kg8",
              "Q6g7#",
              "Kg8",
              "Qfg6#",
              "Bb7",
              "Qg8#",
              "Bc8",
              "Q6g7#",
              "Bb7+",
              "Kg3",
              "Bc8",
              "Q7f7#",
              "Bb7",
              "Qgf8#",
              "Bc8",
              "Q7g8#",
              "Bb7+",
              "Kg4",
              "Bc8+",
              "Kh5",
              "Bb7+",
              "Kg6",
              "Bc8+",
              "Kf6",
              "Bb7+",
              "Ke7",
              "Bc8+",
              "Kd8",
              "Bb7+",
              "Kc7",
              "Bc8+",
              "Kb8",
              "Bb7+",
              "Kxb7",
              "Bb7+",
              "Kc7",
              "Bc8+",
              "Kd8",
              "Bb7+",
              "Ke7",
              "Bc8+",
              "Kf6",
              "Bb7+",
              "Ke5",
              "Bc8+",
              "Kd4",
              "Bb7+",
              "Kc3",
              "Bc8+",
              "Kb4",
              "Bb7+",
              "Ka3",
              "Bc8+",
              "Kb3",
              "Bb7+",
              "Kc2",
              "Bc8+",
              "Kd1",
              "Bb7+",
              "Ke1",
              "Bc8+",
              "Kf1",
              "Bb7+",
              "Kg1",
              "Bc8+",
              "Kh1",
              "Bb7+",
              "Kg1",
              "Bc8+",
              "Kf1",
              "Bb7+",
              "Ke1",
              "Bc8+",
              "Kd1",
              "Bb7+",
              "Kc1",
              "Bc8+",
              "Kb1",
              "Bb7+",
              "Ka1",
              "Bc8+",
              "Kb1",
              "Bb7+",
              "Kc1",
              "Bc8+",
              "Kd1",
              "Bb7+",
              "Ke1",
              "Bc8+",
              "Kf1",
              "Bb7+",
              "Kg1",
              "Bc8+",
              "Kh1",
              "Bb7+",
              "Kg1",
              "Bc8+",
              "Kf1",
              "Bb7+",
              "Ke1",
              "Bc8+",
              "Kd1",
              "Bb7+",
              "Kc1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 294,
            "completion_tokens": 640,
            "total_tokens": 934,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 294,
            "completion_tokens": 94,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 293,
            "completion_tokens": 640,
            "total_tokens": 933,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 881,
          "total_completion_tokens": 1374,
          "total_tokens": 2255
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 294,
            "completion_tokens": 640,
            "total_tokens": 934,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 294,
            "completion_tokens": 94,
            "total_tokens": 388,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 293,
            "completion_tokens": 640,
            "total_tokens": 933,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "5k2/pbrQ2p1/1p5p/8/8/4P3/PP3PPP/5RK1 w - - 0 23"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rad8 25. Bg5 Ne7 26. Bxf6 gxf6\n27. Qh6 Ng6 28. Nh5 Re6 29. Qg7# d5 e5 Nxe5",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 234,
            "total_tokens": 348,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Kf7\n39. Bxb5 Bxb5 40. Rxb5 Rc8 41. Rb4 Rc1+ 42. Kh2 Rc2\n43. Kg3 Nc6 44. Rxa4 Rxb2 45. Ra6 Nb4 46. Ra7+ Kg6\n47. Nh4+ Kh6 48. Nf5+ Kg6 49. Rg7+ Kh5 50. Rxh7+ Kg6\n51. Rg7+ Kh5 52. Kf3 Nd3 53. g4# Nxf2 54. Rh7+ Kg6\n55. Rh6+ Kf7 56. Rh7+ Kg6 57. Rg7# Nxe4 58. Kxe4 Re2+\n59. Kf3 Rf2+ 60. Kxf2 e4 61. h4 e3+ 62. Kf3 e2\n63. h5# Nxe4 64. Kxe2 Ng3+ 65. Kf3 Nxf5 66. gxf5# Nxe4\n67. Kxe4 Kxg7 68. a4 Kh6 69. a5 Kxh5 70. a6 Kg5\n71. a7 Kg4 72. a8=Q Kg5 73. Qg8+ Kh4 74. Kf4 Kh3\n75. Qg3# Kh5 76. Qh3# Kh6 77. Qh4# Kh7",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Kf7",
            "Bxb5",
            "Bxb5",
            "Rxb5",
            "Rc8",
            "Rb4",
            "Rc1+",
            "Kh2",
            "Rc2",
            "Kg3",
            "Nc6",
            "Rxa4",
            "Rxb2",
            "Ra6",
            "Nb4",
            "Ra7+",
            "Kg6",
            "Nh4+",
            "Kh6",
            "Nf5+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Rxh7+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Kf3",
            "Nd3",
            "g4#",
            "Nxf2",
            "Rh7+",
            "Kg6",
            "Rh6+",
            "Kf7",
            "Rh7+",
            "Kg6",
            "Rg7#",
            "Nxe4",
            "Kxe4",
            "Re2+",
            "Kf3",
            "Rf2+",
            "Kxf2",
            "e4",
            "h4",
            "e3+",
            "Kf3",
            "e2",
            "h5#",
            "Nxe4",
            "Kxe2",
            "Ng3+",
            "Kf3",
            "Nxf5",
            "gxf5#",
            "Nxe4",
            "Kxe4",
            "Kxg7",
            "a4",
            "Kh6",
            "a5",
            "Kxh5",
            "a6",
            "Kg5",
            "a7",
            "Kg4",
            "a8=Q",
            "Kg5",
            "Qg8+",
            "Kh4",
            "Kf4",
            "Kh3",
            "Qg3#",
            "Kh5",
            "Qh3#",
            "Kh6",
            "Qh4#",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Kf7\n39. Bxb5 Bxb5 40. Rxb5 Rc8 41. Rb4 Rc1+ 42. Kh2 Rc2\n43. Kg3 Ng6 44. Ne1 Re2 45. Nd3 Rd2 46. Nc5 Nf4\n47. Nxa4 Nd3 48. Rb7+ Kg6 49. f3 Nf4 50. Kh2 Rxg2+\n51. Kh1 Rf2 52. Nc3 Rxf3 53. a4 Rxh3+ 54. Kg1 Rg3+\n55. Kf2 Rg2+ 56. Kf3 h5 57. Nd5 Rg4 58. Ne7+ Kg5\n59. Nf5 Ne6 60. a5 Rf4+ 61. Ke3 Rf1 62. a6 Ra1\n63. a7 h4 64. Rh7 h3 65. Rxh3 Rxa7 66. Rg3+ Kh5\n67. Rg8 Rb7 68. Ng3+ Kh6 69. Nf5+ Kh7 70. Rg2 Rb3+\n71. Kf2 Rxb2+ 72. Kg3 Rxg2+ 73. Kxg2 Kg6 74. Kf3 Ng5+\n75. Ke3 Kh5 76. Ng7+ Kg4 77. Ne8 Nh7 78. Nd6 Ng5\n79. Ne8 Nh",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Kf7",
            "Bxb5",
            "Bxb5",
            "Rxb5",
            "Rc8",
            "Rb4",
            "Rc1+",
            "Kh2",
            "Rc2",
            "Kg3",
            "Ng6",
            "Ne1",
            "Re2",
            "Nd3",
            "Rd2",
            "Nc5",
            "Nf4",
            "Nxa4",
            "Nd3",
            "Rb7+",
            "Kg6",
            "f3",
            "Nf4",
            "Kh2",
            "Rxg2+",
            "Kh1",
            "Rf2",
            "Nc3",
            "Rxf3",
            "a4",
            "Rxh3+",
            "Kg1",
            "Rg3+",
            "Kf2",
            "Rg2+",
            "Kf3",
            "h5",
            "Nd5",
            "Rg4",
            "Ne7+",
            "Kg5",
            "Nf5",
            "Ne6",
            "a5",
            "Rf4+",
            "Ke3",
            "Rf1",
            "a6",
            "Ra1",
            "a7",
            "h4",
            "Rh7",
            "h3",
            "Rxh3",
            "Rxa7",
            "Rg3+",
            "Kh5",
            "Rg8",
            "Rb7",
            "Ng3+",
            "Kh6",
            "Nf5+",
            "Kh7",
            "Rg2",
            "Rb3+",
            "Kf2",
            "Rxb2+",
            "Kg3",
            "Rxg2+",
            "Kxg2",
            "Kg6",
            "Kf3",
            "Ng5+",
            "Ke3",
            "Kh5",
            "Ng7+",
            "Kg4",
            "Ne8",
            "Nh7",
            "Nd6",
            "Ng5",
            "Ne8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxe5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Kf7",
              "Bxb5",
              "Bxb5",
              "Rxb5",
              "Rc8",
              "Rb4",
              "Rc1+",
              "Kh2",
              "Rc2",
              "Kg3",
              "Nc6",
              "Rxa4",
              "Rxb2",
              "Ra6",
              "Nb4",
              "Ra7+",
              "Kg6",
              "Nh4+",
              "Kh6",
              "Nf5+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Rxh7+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Kf3",
              "Nd3",
              "g4#",
              "Nxf2",
              "Rh7+",
              "Kg6",
              "Rh6+",
              "Kf7",
              "Rh7+",
              "Kg6",
              "Rg7#",
              "Nxe4",
              "Kxe4",
              "Re2+",
              "Kf3",
              "Rf2+",
              "Kxf2",
              "e4",
              "h4",
              "e3+",
              "Kf3",
              "e2",
              "h5#",
              "Nxe4",
              "Kxe2",
              "Ng3+",
              "Kf3",
              "Nxf5",
              "gxf5#",
              "Nxe4",
              "Kxe4",
              "Kxg7",
              "a4",
              "Kh6",
              "a5",
              "Kxh5",
              "a6",
              "Kg5",
              "a7",
              "Kg4",
              "a8=Q",
              "Kg5",
              "Qg8+",
              "Kh4",
              "Kf4",
              "Kh3",
              "Qg3#",
              "Kh5",
              "Qh3#",
              "Kh6",
              "Qh4#",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Kf7",
              "Bxb5",
              "Bxb5",
              "Rxb5",
              "Rc8",
              "Rb4",
              "Rc1+",
              "Kh2",
              "Rc2",
              "Kg3",
              "Ng6",
              "Ne1",
              "Re2",
              "Nd3",
              "Rd2",
              "Nc5",
              "Nf4",
              "Nxa4",
              "Nd3",
              "Rb7+",
              "Kg6",
              "f3",
              "Nf4",
              "Kh2",
              "Rxg2+",
              "Kh1",
              "Rf2",
              "Nc3",
              "Rxf3",
              "a4",
              "Rxh3+",
              "Kg1",
              "Rg3+",
              "Kf2",
              "Rg2+",
              "Kf3",
              "h5",
              "Nd5",
              "Rg4",
              "Ne7+",
              "Kg5",
              "Nf5",
              "Ne6",
              "a5",
              "Rf4+",
              "Ke3",
              "Rf1",
              "a6",
              "Ra1",
              "a7",
              "h4",
              "Rh7",
              "h3",
              "Rxh3",
              "Rxa7",
              "Rg3+",
              "Kh5",
              "Rg8",
              "Rb7",
              "Ng3+",
              "Kh6",
              "Nf5+",
              "Kh7",
              "Rg2",
              "Rb3+",
              "Kf2",
              "Rxb2+",
              "Kg3",
              "Rxg2+",
              "Kxg2",
              "Kg6",
              "Kf3",
              "Ng5+",
              "Ke3",
              "Kh5",
              "Ng7+",
              "Kg4",
              "Ne8",
              "Nh7",
              "Nd6",
              "Ng5",
              "Ne8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 234,
            "total_tokens": 348,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1514,
          "total_tokens": 1855
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 234,
            "total_tokens": 348,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6\n\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6\n13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8\n17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Ra6 Bf8 24. Rxc6 Bh3\n25. Qf3 Bg4 26. Qg2 Bh3 27. Qf3 Bg4 28. Qg2 Bh3\n29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3\n33. Qf3 Bg4 34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3\n37. Qf3 Bg4 38. Qg2 Bh3 39. Qf3 Bg4 40. Qg2 Bh3\n41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4 44. Qg2 Bh3\n45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3\n49. Qf3 Bg4 50. Qg2 Bh3 51. Qf3 Bg4 52. Qg2 Bh3\n53. Qf3 Bg4 54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3\n57. Qf3 Bg4 58. Qg2 Bh3 59. Qf3 Bg4 60. Qg2 Bh3\n61. Qf3 Bg4 62. Qg2 Bh3 63. Qf3 Bg4 64. Qg2 Bh3\n65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3\n69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3\n73. Qf3 Bg4 74. Qg2 Bh3 75. Qf3 Bg4 76. Qg2 Bh3\n77. Q",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Ra6",
            "Bf8",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Qxf8+ Qxf8 12. Bxf8 Kxf8 13. Nc3 d6 14. Nd5 Be6 15. Nxc7 Rc8 16. Nxe6+ fxe6 17. Rad1 Ke7 18. c3 Ne5 19. f4 Nc4 20. Rf2 Ne3 21. Rd3 Nc4 22. b3 Nb6 23. c4 Nd7 24. Rfd2 Nc5 25. Rxd6 Nxe4 26. Rd7+ Kf6 27. R2d4 Nc5 28. Rxh7 Kg6 29. Re7 Kf6 30. Rh7 Kg6 31. Rh3 Kf5 32. Rh5+ Kg4 33. Rg5+ Kh4 34. g3+ Kh3 35. f5 Rh8 36. fxe6 Nxe6 37. Rdd5 Nxg5 38. Rxg5 Rh7 39. Rg6 Rh8 40. Rg7 Rh6 41. Rxb7 Ra6 42. a4 Kg4 43. c5 Kf5 44. c6 Rxc6 45. Rxa7 Rb6 46. Ra5+ Ke4 47. Rb5 Ra6 48. a5 Kd4 49. b4 Kc4 50. Rb6 Ra7 51. a6 Kd5 52. b5 Kc5 53. Rb7 Ra8 54. a7 Kd6 55. b6 Kc6 56. Rb8 Rxa7 57. bxa7 Kc7 58. a8=Q Kd6 59. Qa5 Kc6 60. Rb6+ Kc7 61. Qa7+ Kc8 62. Rb8# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Qxf8+ Qxf8 Bxf8 Kxf8 Nc3 d6 Nd5 Be6 Nxc7 Rc8 Nxe6+ fxe6 Rad1 Ke7 c3 Ne5 f4 Nc4 Rf2 Ne3 Rd3 Nc4 b3 Nb6 c4",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Qxf8+",
            "Qxf8",
            "Bxf8",
            "Kxf8",
            "Nc3",
            "d6",
            "Nd5",
            "Be6",
            "Nxc7",
            "Rc8",
            "Nxe6+",
            "fxe6",
            "Rad1",
            "Ke7",
            "c3",
            "Ne5",
            "f4",
            "Nc4",
            "Rf2",
            "Ne3",
            "Rd3",
            "Nc4",
            "b3",
            "Nb6",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 Nf6\nd4 Nf6 Nc3 d5 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Re1 Qd6 Re3 Bf5 Re8+ Rxe8 Bxf5 Qxd1+ Rxd1 Rad8 Rxd8 Rxd8 Kf1 Rd2 b4 Rxa2 Be4 c6 b5 cxb5 Bxb7 Rc2 Ba6 Rxc3 Bxb5 Rc2 Ke2 a5 Kd2 Rc5 Kd3 a4 Kd4 Rc7 Bb5 a3 Ba4 a2 Bb3 a1=Q+ Kd5 Qd4#\nd4 Nf6 Nc3 d5 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Re1 Qd6 Re3 Bf5 Re8+ Rxe8 Bxf5 Qxd1+ Rxd1 Rad8 Rxd8 Rxd8 Kf1 Rd2 b4 Rxa2 Be4 c6 b5 cxb5 Bxb5 Rc2 Ba6 Rxc3 Bxb7 Rc2 Ke1 a5 Kd1 Rc5 Kd2 a4 Kd3 Rc7 Bc6 a3 Bd5 Rd7 Kc4 Rxd5+ Kxd5 a2 Ke5 a1=Q+ Kf5 Qf6+ Kg5 Qg6#",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 382,
            "total_tokens": 491,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Nc3",
            "d5",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "O-O",
            "Rd8",
            "c3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "Re1",
            "Qd6",
            "Re3",
            "Bf5",
            "Re8+",
            "Rxe8",
            "Bxf5",
            "Qxd1+",
            "Rxd1",
            "Rad8",
            "Rxd8",
            "Rxd8",
            "Kf1",
            "Rd2",
            "b4",
            "Rxa2",
            "Be4",
            "c6",
            "b5",
            "cxb5",
            "Bxb5",
            "Rc2",
            "Ba6",
            "Rxc3",
            "Bxb7",
            "Rc2",
            "Ke1",
            "a5",
            "Kd1",
            "Rc5",
            "Kd2",
            "a4",
            "Kd3",
            "Rc7",
            "Bc6",
            "a3",
            "Bd5",
            "Rd7",
            "Kc4",
            "Rxd5+",
            "Kxd5",
            "a2",
            "Ke5",
            "a1=Q+",
            "Kf5",
            "Qf6+",
            "Kg5",
            "Qg6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Ra6",
              "Bf8",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Qxf8+",
              "Qxf8",
              "Bxf8",
              "Kxf8",
              "Nc3",
              "d6",
              "Nd5",
              "Be6",
              "Nxc7",
              "Rc8",
              "Nxe6+",
              "fxe6",
              "Rad1",
              "Ke7",
              "c3",
              "Ne5",
              "f4",
              "Nc4",
              "Rf2",
              "Ne3",
              "Rd3",
              "Nc4",
              "b3",
              "Nb6",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Nc3",
              "d5",
              "Bg5",
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nxf6+",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nf3",
              "O-O",
              "Bd3",
              "Nc6",
              "O-O",
              "Rd8",
              "c3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "Re1",
              "Qd6",
              "Re3",
              "Bf5",
              "Re8+",
              "Rxe8",
              "Bxf5",
              "Qxd1+",
              "Rxd1",
              "Rad8",
              "Rxd8",
              "Rxd8",
              "Kf1",
              "Rd2",
              "b4",
              "Rxa2",
              "Be4",
              "c6",
              "b5",
              "cxb5",
              "Bxb5",
              "Rc2",
              "Ba6",
              "Rxc3",
              "Bxb7",
              "Rc2",
              "Ke1",
              "a5",
              "Kd1",
              "Rc5",
              "Kd2",
              "a4",
              "Kd3",
              "Rc7",
              "Bc6",
              "a3",
              "Bd5",
              "Rd7",
              "Kc4",
              "Rxd5+",
              "Kxd5",
              "a2",
              "Ke5",
              "a1=Q+",
              "Kf5",
              "Qf6+",
              "Kg5",
              "Qg6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 382,
            "total_tokens": 491,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1662,
          "total_tokens": 1991
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 382,
            "total_tokens": 491,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nc6 *\n3. Bb5 a6 *\n4. Ba4 Nf6 *\n5. O-O Be7 *\n6. Re1 b5 *\n7. Bb3 d6 *\n8. c3 O-O *\n9. h3 Na5 *\n10. Bc2 c5 *\n11. d4 Qc7 *\n12. Nbd2 cxd4 *\n13. cxd4 Nc6 *\n14. Nb3 a5 *\n15. Be3 a4 *\n16. Nbd2 Bd7 *\n17. Rc1 Qb7 *\n18. Bb1 Rfc8 *\n19. Nf1 Bd8 *\n20. Ng3 Bb6 *\n21. Qd2 Ba5 *\n22. Qe2 Bxe1 *\n23. Rxe1 Re8 *\n24. Qd2 Rac8 *\n25. Bg5 Kh8 *\n26. Bxf6 gxf6 *\n27. Qh6 Rg8 *\n28. Qxf6+ Rg7 *\n29. Nh5 Rg8 *\n30. Ng5 Be8 *\n31. Nxg7 Rxg7 *\n32. dxe5 dxe5 *\n33. Rd1 Qe7 *\n34. Qxe7 Nxe7 *\n35. Rd8 Rg8 *\n36. Nf3 f6 *\n37. Bd3 Kg7 *\n38. Rb8 Bc6 *\n39. Rxg8+ Kxg8 *\n40. Kf1 Kf7 *\n41. Ke2 Ke6 *\n42. Ke3 Kd6 *\n43. Nh4 Kc5 *\n44. a3 Bd7 *\n45. Nf3 Nc6 *\n46. Nd2 Nd4 *\n47. f4 Be6 *\n48. fxe5 fxe5 *\n49. Nf3 Nxf3 *\n50. Kxf3 Kd4 *\n51. Bxb5 Bb3 *\n52. g4 Bc2 *\n53. Kg3 Kxe4 *\n54. h4 Kd4 *\n55. g5 e4 *\n56. h5 e3 *\n57. Kf3 Bd1+ *\n58. Be2 Bc2 *\n59. Kf4 Bd3 *\n60. Kf3 Be4+ *\n61. Kf4 Bd3 *\n62. Kf3 Be4+ *\n63. Kf4 Bd3 *\n64. Kf3 Be4+ *\n65. Kf4 Bd3 *\n66. Kf3 Be4+ *\n67. Kf4 Bd3 *\n68. Kf3 Be4+ *\n69. Kf4 Bd3 *\n70. Kf3 Be4+ *\n71. K",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxf3",
            "Kxf3",
            "Kd4",
            "Bxb5",
            "Bb3",
            "g4",
            "Bc2",
            "Kg3",
            "Kxe4",
            "h4",
            "Kd4",
            "g5",
            "e4",
            "h5",
            "e3",
            "Kf3",
            "Bd1+",
            "Be2",
            "Bc2",
            "Kf4",
            "Bd3",
            "Kf3",
            "Be4+",
            "Kf4",
            "Bd3",
            "Kf3",
            "Be4+",
            "Kf4",
            "Bd3",
            "Kf3",
            "Be4+",
            "Kf4",
            "Bd3",
            "Kf3",
            "Be4+",
            "Kf4",
            "Bd3",
            "Kf3",
            "Be4+",
            "Kf4",
            "Bd3",
            "Kf3",
            "Be4+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nc6 *\n3. Bb5 a6 *\n4. Ba4 Nf6 *\n5. O-O Be7 *\n6. Re1 b5 *\n7. Bb3 d6 *\n8. c3 O-O *\n9. h3 Na5 *\n10. Bc2 c5 *\n11. d4 Qc7 *\n12. Nbd2 cxd4 *\n13. cxd4 Nc6 *\n14. Nb3 a5 *\n15. Be3 a4 *\n16. Nbd2 Bd7 *\n17. Rc1 Rfc8 *\n18. Bb1 Qb8 *\n19. Nf1 Bd8 *\n20. Ng3 Bb6 *\n21. Qd2 Ba5 *\n22. Qe2 Bxe1 *\n23. Rxe1 Ne7 *\n24. Bg5 Ng6 *\n25. Bxf6 gxf6 *\n26. Nh5 Kh8 *\n27. Nxf6 Be6 *\n28. Ng5 Kg7 *\n29. Nh5+ Kh6 *\n30. Nxe6 fxe6 *\n31. Qg4 Rf8 *\n32. h4 Qd8 *\n33. g3 Qe7 *\n34. Bd3 Rab8 *\n35. Be2 Rg8 *\n36. Qh3 Nf4 *\n37. Nxf4 exf4 *\n38. g4 Kg7 *\n39. g5 Kh8 *\n40. Bg4 e5 *\n41. d5 Rb7 *\n42. Rc1 Rc7 *\n43. Rc6 Rxc6 *\n44. dxc6 Qc7 *\n45. Bd7 Rg7 *\n46. Qe6 Rg8 *\n47. Qf6+ Rg7 *\n48. h5 Kg8 *\n49. Be6+ Rf7 *\n50. g6 hxg6 *\n51. hxg6 Kf8 *\n52. Bxf7 Qe7 *\n53. g7#",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 469,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Rfc8",
            "Bb1",
            "Qb8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Ne7",
            "Bg5",
            "Ng6",
            "Bxf6",
            "gxf6",
            "Nh5",
            "Kh8",
            "Nxf6",
            "Be6",
            "Ng5",
            "Kg7",
            "Nh5+",
            "Kh6",
            "Nxe6",
            "fxe6",
            "Qg4",
            "Rf8",
            "h4",
            "Qd8",
            "g3",
            "Qe7",
            "Bd3",
            "Rab8",
            "Be2",
            "Rg8",
            "Qh3",
            "Nf4",
            "Nxf4",
            "exf4",
            "g4",
            "Kg7",
            "g5",
            "Kh8",
            "Bg4",
            "e5",
            "d5",
            "Rb7",
            "Rc1",
            "Rc7",
            "Rc6",
            "Rxc6",
            "dxc6",
            "Qc7",
            "Bd7",
            "Rg7",
            "Qe6",
            "Rg8",
            "Qf6+",
            "Rg7",
            "h5",
            "Kg8",
            "Be6+",
            "Rf7",
            "g6",
            "hxg6",
            "hxg6",
            "Kf8",
            "Bxf7",
            "Qe7",
            "g7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nc6 *\n3. Bb5 a6 *\n4. Ba4 Nf6 *\n5. O-O Be7 *\n6. Re1 b5 *\n7. Bb3 d6 *\n8. c3 O-O *\n9. h3 Na5 *\n10. Bc2 c5 *\n11. d4 Qc7 *\n12. Nbd2 cxd4 *\n13. cxd4 Nc6 *\n14. Nb3 a5 *\n15. Be3 a4 *\n16. Nbd2 Bd7 *\n17. Rc1 Qb7 *\n18. Bb1 Rfc8 *\n19. Nf1 Bd8 *\n20. Ng3 Bb6 *\n21. Qd2 Ba5 *\n22. Qe2 Bxe1 *\n23. Rxe1 Re8 *\n24. Qd2 Rac8 *\n25. Bg5 Kh8 *\n26. Bxf6 gxf6 *\n27. Qh6 Rg8 *\n28. Qxf6+ Rg7 *\n29. Nh5 Rg8 *\n30. Ng5 Be8 *\n31. Nxg7 Rxg7 *\n32. dxe5 dxe5 *\n33. Rd1 Qe7 *\n34. Qxe7 Nxe7 *\n35. Rd8 Rg8 *\n36. Nf3 f6 *\n37. Bd3 Kg7 *\n38. Rb8 Bc6 *\n39. Rxg8+ Kxg8 *\n40. Kf1 Kf7 *\n41. Ke2 Ke6 *\n42. Ke3 Kd6 *\n43. Nh4 Kc5 *\n44. a3 b4 *\n45. g3 bxa3 *\n46. bxa3 Bd7 *\n47. g4 Nc6 *\n48. Nf5 Bxf5 *\n49. exf5 Nd4 *\n50. h4 h6 *\n51. f4 exf4+ *\n52. Kxf4 Kd5 *\n53. g5 hxg5+ *\n54. hxg5 fxg5+ *\n55. Kxg5 Ke5 *\n56. f6 Ne6+ *\n57. Kg6 Nf4+ *\n58. Kg7 Nh5+ *\n59. Kg6 Nxf6 *\n60. Bb5 Nd5 *\n61. Bxa4 Nc3 *\n62. Bb3 Kd4 *\n63. Kf5 Kc5 *\n64. Ke5 Nb5 *\n65. a4 Nd4 *\n66. Bd1 Nc6+ *\n67. Ke4 Kb4 *\n68. Kd5 Na5 *\n69. Kd4 Nb3+ *\n70. Bxb3 Kxb3 *\n71",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nh4",
            "Kc5",
            "a3",
            "b4",
            "g3",
            "bxa3",
            "bxa3",
            "Bd7",
            "g4",
            "Nc6",
            "Nf5",
            "Bxf5",
            "exf5",
            "Nd4",
            "h4",
            "h6",
            "f4",
            "exf4+",
            "Kxf4",
            "Kd5",
            "g5",
            "hxg5+",
            "hxg5",
            "fxg5+",
            "Kxg5",
            "Ke5",
            "f6",
            "Ne6+",
            "Kg6",
            "Nf4+",
            "Kg7",
            "Nh5+",
            "Kg6",
            "Nxf6",
            "Bb5",
            "Nd5",
            "Bxa4",
            "Nc3",
            "Bb3",
            "Kd4",
            "Kf5",
            "Kc5",
            "Ke5",
            "Nb5",
            "a4",
            "Nd4",
            "Bd1",
            "Nc6+",
            "Ke4",
            "Kb4",
            "Kd5",
            "Na5",
            "Kd4",
            "Nb3+",
            "Bxb3",
            "Kxb3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxf3",
              "Kxf3",
              "Kd4",
              "Bxb5",
              "Bb3",
              "g4",
              "Bc2",
              "Kg3",
              "Kxe4",
              "h4",
              "Kd4",
              "g5",
              "e4",
              "h5",
              "e3",
              "Kf3",
              "Bd1+",
              "Be2",
              "Bc2",
              "Kf4",
              "Bd3",
              "Kf3",
              "Be4+",
              "Kf4",
              "Bd3",
              "Kf3",
              "Be4+",
              "Kf4",
              "Bd3",
              "Kf3",
              "Be4+",
              "Kf4",
              "Bd3",
              "Kf3",
              "Be4+",
              "Kf4",
              "Bd3",
              "Kf3",
              "Be4+",
              "Kf4",
              "Bd3",
              "Kf3",
              "Be4+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Rfc8",
              "Bb1",
              "Qb8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Ne7",
              "Bg5",
              "Ng6",
              "Bxf6",
              "gxf6",
              "Nh5",
              "Kh8",
              "Nxf6",
              "Be6",
              "Ng5",
              "Kg7",
              "Nh5+",
              "Kh6",
              "Nxe6",
              "fxe6",
              "Qg4",
              "Rf8",
              "h4",
              "Qd8",
              "g3",
              "Qe7",
              "Bd3",
              "Rab8",
              "Be2",
              "Rg8",
              "Qh3",
              "Nf4",
              "Nxf4",
              "exf4",
              "g4",
              "Kg7",
              "g5",
              "Kh8",
              "Bg4",
              "e5",
              "d5",
              "Rb7",
              "Rc1",
              "Rc7",
              "Rc6",
              "Rxc6",
              "dxc6",
              "Qc7",
              "Bd7",
              "Rg7",
              "Qe6",
              "Rg8",
              "Qf6+",
              "Rg7",
              "h5",
              "Kg8",
              "Be6+",
              "Rf7",
              "g6",
              "hxg6",
              "hxg6",
              "Kf8",
              "Bxf7",
              "Qe7",
              "g7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nh4",
              "Kc5",
              "a3",
              "b4",
              "g3",
              "bxa3",
              "bxa3",
              "Bd7",
              "g4",
              "Nc6",
              "Nf5",
              "Bxf5",
              "exf5",
              "Nd4",
              "h4",
              "h6",
              "f4",
              "exf4+",
              "Kxf4",
              "Kd5",
              "g5",
              "hxg5+",
              "hxg5",
              "fxg5+",
              "Kxg5",
              "Ke5",
              "f6",
              "Ne6+",
              "Kg6",
              "Nf4+",
              "Kg7",
              "Nh5+",
              "Kg6",
              "Nxf6",
              "Bb5",
              "Nd5",
              "Bxa4",
              "Nc3",
              "Bb3",
              "Kd4",
              "Kf5",
              "Kc5",
              "Ke5",
              "Nb5",
              "a4",
              "Nd4",
              "Bd1",
              "Nc6+",
              "Ke4",
              "Kb4",
              "Kd5",
              "Na5",
              "Kd4",
              "Nb3+",
              "Bxb3",
              "Kxb3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 469,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1749,
          "total_tokens": 2096
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 469,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb5",
          "aggressive_uci": "f1b5",
          "aggressive_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Bf3 29. Rxb8+ Re8 30. Rxe8# g8=Q e4 Qxg6",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 241,
            "total_tokens": 366,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "g8=Q",
            "e4",
            "Qxg6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb5",
          "positional_uci": "f1b5",
          "positional_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Ra6 Bf8 24. Rxc6 Bh3 25. Qh1 Rxc6 26. Qxc6 Re6 27. Qf3 Bg4 28. Qg2 Bh3 29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3 33. Qf3 Bg4 34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3 37. Qf3 Bg4 38. Qg2 Bh3 39. Qf3 Bg4 40. Qg2 Bh3 41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4 44. Qg2 Bh3 45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3 49. Qf3 Bg4 50. Qg2 Bh3 51. Qf3 Bg4 52. Qg2 Bh3 53. Qf3 Bg4 54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3 57. Qf3 Bg4 58. Qg2 Bh3 59. Qf3 Bg4 60. Qg2 Bh3 61. Qf3 Bg4 62. Qg2 Bh3 63. Qf3 Bg4 64. Qg2 Bh3 65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3 69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3 73. Qf3 Bg4 74. Qg2 Bh3 75. Qf3 Bg4 76. Qg2 Bh3 77. Qf3 Bg4 78. Qg2 Bh3 79. Q",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Ra6",
            "Bf8",
            "Rxc6",
            "Bh3",
            "Qh1",
            "Rxc6",
            "Qxc6",
            "Re6",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb5",
          "neutral_uci": "f1b5",
          "neutral_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5 22. f3 Bxf3 23. Nxf3 Qxf3 24. Qe2 Qe4 25. Qg2 Qd3 26. Qe2 Qe4 27. Qg2 Qd3 28. Qe2 Qe4 29. Qg2 Qd3 30. Qe2 Qe4 31. Qg2 Qd3 32. Qe2 Qe4 33. Qg2 Qd3 34. Qe2 Qe4 35. Qg2 Qd3 36. Qe2 Qe4 37. Qg2 Qd3 38. Qe2 Qe4 39. Qg2 Qd3 40. Qe2 Qe4 41. Qg2 Qd3 42. Qe2 Qe4 43. Qg2 Qd3 44. Qe2 Qe4 45. Qg2 Qd3 46. Qe2 Qe4 47. Qg2 Qd3 48. Qe2 Qe4 49. Qg2 Qd3 50. Qe2 Qe4 51. Qg2 Qd3 52. Qe2 Qe4 53. Qg2 Qd3 54. Qe2 Qe4 55. Qg2 Qd3 56. Qe2 Qe4 57. Qg2 Qd3 58. Qe2 Qe4 59. Qg2 Qd3 60. Qe2 Qe4 61. Qg2 Qd3 62. Qe2 Qe4 63. Qg2 Qd3 64. Qe2 Qe4 65. Qg2 Qd3 66. Qe2 Qe4 67. Qg2 Qd3 68. Qe2 Qe4 69. Qg2 Qd3 70. Qe2 Qe4 71. Qg2 Qd3 72. Qe2 Qe4 73. Qg2 Qd3 74. Qe2 Qe4 75. Qg2 Qd3 76. Q",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bxd5",
            "Qxd5",
            "f3",
            "Bxf3",
            "Nxf3",
            "Qxf3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3",
            "Qe2",
            "Qe4",
            "Qg2",
            "Qd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1b5",
          "positional_uci": "f1b5",
          "neutral_uci": "f1b5",
          "consensus_move": "f1b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "g8=Q",
              "e4",
              "Qxg6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Ra6",
              "Bf8",
              "Rxc6",
              "Bh3",
              "Qh1",
              "Rxc6",
              "Qxc6",
              "Re6",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bxd5",
              "Qxd5",
              "f3",
              "Bxf3",
              "Nxf3",
              "Qxf3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3",
              "Qe2",
              "Qe4",
              "Qg2",
              "Qd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 241,
            "total_tokens": 366,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1521,
          "total_tokens": 1895
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 241,
            "total_tokens": 366,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxc6",
          "aggressive_uci": "b5c6",
          "aggressive_response": "4. Bxc6 dxc6 5. O-O Bg4 6. h3 h5 7. d3 Qf6 8. Nbd2 Ne7 9. Re1 Ng6 10. d4 Bd6 11. hxg4 hxg4 12. Nh2 Rxh2 13. Kxh2 Qxf2 14. Nf1 O-O-O 15. Kh1 Rh8+ 16. Nh2 Rxh2+ 17. Kxh2 Nh4 18. Qxg4+ f5 19. Qh3 Nf3+ 20. Qxf3 Qh4+ 21. Qh3 Qxe1 22. Qxf5+ Kb8 23. dxe5 Qh4+ 24. Qh3 Bxe5+ 25. g3 Qxe4 26. Qg2 Qh4+ 27. Kg1 Bxg3 28. Be3 Be5 29. c3 Qh5 30. Rf1 b6 31. Rf8+ Kb7 32. Qg5 Qh2+ 33. Kf1 Qh1+ 34. Ke2 Qh2+ 35. Rf2 Qg3 36. Qxg3 Bxg3 37. Rg2 Be5 38. Bd4 Bxd4 39. cxd4 c5 40. dxc5 bxc5 41. Rxg7 Kb6 42. Kd3 c6 43. Kc4 a5 44. a4 Ka6 45. Kxc5 * e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 O-O Bg4 h5 d3 Qf6 Nbd2 Ne7 Re1 Ng6 d4 Bd6 hxg4 hxg4 Nh2 Rxh2 Kxh2 Qxf2 Nf1 O-O-O Kh1 Rh8 Nh2 Rxh2 Kxh2 Nh4 Qxg4+ f5 Qh3 Nf3 Qxf3 Qh4+ Qh3 Qxe1 Qxf5+ f5 Qh3 Nf3+ Qxf3 Qh4+ Kg1 Qxe1 Qxf5+ Kb8 dxe5 Qh4+ Qh3 Qxe4 Qh8+ Kc7 Qg7+ Kb6 Qg3 Qh7+ Kg1 Qb1+ Kh2 Qxb2 Qe3+ Kb7 Qe7+ Kb6 Qd8+ Kb7 Qd7+ Kb6 Qd8+ Kb7 Qd7+ Kb6 Qd8+ Kb7 Qd7+ Kb6 Qd8+ Kb7 Qd7+ Kb6 Qd8+ Kb7 Qd7+ Kb6 Qd8+ Kb7 Qd7+ Kb6 Qd8+ Kb7 Q",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc6",
            "O-O",
            "Bg4",
            "h5",
            "d3",
            "Qf6",
            "Nbd2",
            "Ne7",
            "Re1",
            "Ng6",
            "d4",
            "Bd6",
            "hxg4",
            "hxg4",
            "Nh2",
            "Rxh2",
            "Kxh2",
            "Qxf2",
            "Nf1",
            "O-O-O",
            "Kh1",
            "Rh8",
            "Nh2",
            "Rxh2",
            "Kxh2",
            "Nh4",
            "Qxg4+",
            "f5",
            "Qh3",
            "Nf3",
            "Qxf3",
            "Qh4+",
            "Qh3",
            "Qxe1",
            "Qxf5+",
            "f5",
            "Qh3",
            "Nf3+",
            "Qxf3",
            "Qh4+",
            "Kg1",
            "Qxe1",
            "Qxf5+",
            "Kb8",
            "dxe5",
            "Qh4+",
            "Qh3",
            "Qxe4",
            "Qh8+",
            "Kc7",
            "Qg7+",
            "Kb6",
            "Qg3",
            "Qh7+",
            "Kg1",
            "Qb1+",
            "Kh2",
            "Qxb2",
            "Qe3+",
            "Kb7",
            "Qe7+",
            "Kb6",
            "Qd8+",
            "Kb7",
            "Qd7+",
            "Kb6",
            "Qd8+",
            "Kb7",
            "Qd7+",
            "Kb6",
            "Qd8+",
            "Kb7",
            "Qd7+",
            "Kb6",
            "Qd8+",
            "Kb7",
            "Qd7+",
            "Kb6",
            "Qd8+",
            "Kb7",
            "Qd7+",
            "Kb6",
            "Qd8+",
            "Kb7",
            "Qd7+",
            "Kb6",
            "Qd8+",
            "Kb7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxc6",
          "positional_uci": "b5c6",
          "positional_response": "4. Bxc6 dxc6 5. O-O Bg4 6. h3 h5 7. d3 Qf6 8. Nbd2 Ne7 9. Re1 Ng6 10. d4 Bd6 11. hxg4 hxg4 12. Nh2 Rxh2 13. Kxh2 Qxf2 14. Nf1 O-O-O 15. Qxg4+ Kb8 16. Bg5 Rh8+ 17. Qh3 Rxh3+ 18. Kxh3 exd4 19. Rad1 f6 20. Bc1 Qh4# 21. Kg4 Ne5+ 22. Kf5 Qg4# 23. Kf6 Qg6# 24. Ke7 Qf7# 25. Kd8 Qd7# 26. Ke8 Qe8# 27. Kf7 Qf8# 28. Ke6 Qf7# 29. Kf5 Qg6# 30. Ke6 Qg4# 31. Kf5 Qf3# 32. Ke6 Qg4# 33. Kf5 Qf3# 34. Ke6 Qg4# 35. Kf5 Qf3# 36. Ke6 Qg4# 37. Kf5 Qf3# 38. Ke6 Qg4# 39. Kf5 Qf3# 40. Ke6 Qg4# 41. Kf5 Qf3# 42. Ke6 Qg4# 43. Kf5 Qf3# 44. Ke6 Qg4# 45. Kf5 Qf3# 46. Ke6 Qg4# 47. Kf5 Qf3# 48. Ke6 Qg4# 49. Kf5 Qf3# 50. Ke6 Qg4# 51. Kf5 Qf3# 52. Ke6 Qg4# 53. Kf5 Qf3# 54. Ke6 Qg4# 55. Kf5 Qf3# 56. Ke6 Qg4# 57. Kf5 Qf3# 58. Ke6 Qg4# 59. Kf5 Qf3# 60. Ke6 Qg4# 61. Kf5 Qf3# 62. Ke6 Qg4# 63. Kf5 Qf3# 64. Ke6 Qg4# 65. Kf5 Qf3# 66. Ke6 Qg4# 67. Kf5 Qf3# 68. Ke6 Qg4# 69. Kf5 Qf3# 70. Ke6 Qg4# 71. Kf5 Qf3# 72. Ke6 Qg4#",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc6",
            "O-O",
            "Bg4",
            "h3",
            "h5",
            "d3",
            "Qf6",
            "Nbd2",
            "Ne7",
            "Re1",
            "Ng6",
            "d4",
            "Bd6",
            "hxg4",
            "hxg4",
            "Nh2",
            "Rxh2",
            "Kxh2",
            "Qxf2",
            "Nf1",
            "O-O-O",
            "Qxg4+",
            "Kb8",
            "Bg5",
            "Rh8+",
            "Qh3",
            "Rxh3+",
            "Kxh3",
            "exd4",
            "Rad1",
            "f6",
            "Bc1",
            "Qh4#",
            "Kg4",
            "Ne5+",
            "Kf5",
            "Qg4#",
            "Kf6",
            "Qg6#",
            "Ke7",
            "Qf7#",
            "Kd8",
            "Qd7#",
            "Ke8",
            "Qe8#",
            "Kf7",
            "Qf8#",
            "Ke6",
            "Qf7#",
            "Kf5",
            "Qg6#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#",
            "Kf5",
            "Qf3#",
            "Ke6",
            "Qg4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxc6",
          "neutral_uci": "b5c6",
          "neutral_response": "4. Bxc6 dxc6 5. O-O Bg4 6. h3 h5 7. d3 Qf6 8. Nbd2 Ne7 9. Re1 Ng6 10. d4 Bd6 11. hxg4 hxg4 12. Nh2 Rxh2 13. Kxh2 Qxf2 14. Nf1 O-O-O 15. Kh1 Rh8+ 16. Nh2 Rxh2+ 17. Kxh2 Nh4 18. Qxg4+ f5 19. Qh3 Nf3+ 20. Qxf3 Qh4+ 21. Qh3 Qxe1 22. Qxf5+ Kb8 23. dxe5 Qh4+ 24. Qh3 Bxe5+ 25. g3 Qxe4 26. Qg2 Qh4+ 27. Kg1 Bxg3 28. Be3 Be5 29. c3 Qh5 30. Rf1 b6 31. Rf8+ Kb7 32. Qf3 Qh2+ 33. Kf1 Qxb2 34. Qf5 Qa1+ 35. Kg2 Qxa2+ 36. Kf3 Qd5+ 37. Kg4 Qg2+ 38. Kh5 Qh2+ 39. Kg6 Qg3+ 40. Bg5 a5 41. Qc8+ Ka7 42. Qa8# e4 d5 Qh7#",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 350,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc6",
            "O-O",
            "Bg4",
            "h3",
            "h5",
            "d3",
            "Qf6",
            "Nbd2",
            "Ne7",
            "Re1",
            "Ng6",
            "d4",
            "Bd6",
            "hxg4",
            "hxg4",
            "Nh2",
            "Rxh2",
            "Kxh2",
            "Qxf2",
            "Nf1",
            "O-O-O",
            "Kh1",
            "Rh8+",
            "Nh2",
            "Rxh2+",
            "Kxh2",
            "Nh4",
            "Qxg4+",
            "f5",
            "Qh3",
            "Nf3+",
            "Qxf3",
            "Qh4+",
            "Qh3",
            "Qxe1",
            "Qxf5+",
            "Kb8",
            "dxe5",
            "Qh4+",
            "Qh3",
            "Bxe5+",
            "g3",
            "Qxe4",
            "Qg2",
            "Qh4+",
            "Kg1",
            "Bxg3",
            "Be3",
            "Be5",
            "c3",
            "Qh5",
            "Rf1",
            "b6",
            "Rf8+",
            "Kb7",
            "Qf3",
            "Qh2+",
            "Kf1",
            "Qxb2",
            "Qf5",
            "Qa1+",
            "Kg2",
            "Qxa2+",
            "Kf3",
            "Qd5+",
            "Kg4",
            "Qg2+",
            "Kh5",
            "Qh2+",
            "Kg6",
            "Qg3+",
            "Bg5",
            "a5",
            "Qc8+",
            "Ka7",
            "Qa8#",
            "e4",
            "d5",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b5c6",
          "positional_uci": "b5c6",
          "neutral_uci": "b5c6",
          "consensus_move": "b5c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc6",
              "O-O",
              "Bg4",
              "h5",
              "d3",
              "Qf6",
              "Nbd2",
              "Ne7",
              "Re1",
              "Ng6",
              "d4",
              "Bd6",
              "hxg4",
              "hxg4",
              "Nh2",
              "Rxh2",
              "Kxh2",
              "Qxf2",
              "Nf1",
              "O-O-O",
              "Kh1",
              "Rh8",
              "Nh2",
              "Rxh2",
              "Kxh2",
              "Nh4",
              "Qxg4+",
              "f5",
              "Qh3",
              "Nf3",
              "Qxf3",
              "Qh4+",
              "Qh3",
              "Qxe1",
              "Qxf5+",
              "f5",
              "Qh3",
              "Nf3+",
              "Qxf3",
              "Qh4+",
              "Kg1",
              "Qxe1",
              "Qxf5+",
              "Kb8",
              "dxe5",
              "Qh4+",
              "Qh3",
              "Qxe4",
              "Qh8+",
              "Kc7",
              "Qg7+",
              "Kb6",
              "Qg3",
              "Qh7+",
              "Kg1",
              "Qb1+",
              "Kh2",
              "Qxb2",
              "Qe3+",
              "Kb7",
              "Qe7+",
              "Kb6",
              "Qd8+",
              "Kb7",
              "Qd7+",
              "Kb6",
              "Qd8+",
              "Kb7",
              "Qd7+",
              "Kb6",
              "Qd8+",
              "Kb7",
              "Qd7+",
              "Kb6",
              "Qd8+",
              "Kb7",
              "Qd7+",
              "Kb6",
              "Qd8+",
              "Kb7",
              "Qd7+",
              "Kb6",
              "Qd8+",
              "Kb7",
              "Qd7+",
              "Kb6",
              "Qd8+",
              "Kb7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc6",
              "O-O",
              "Bg4",
              "h3",
              "h5",
              "d3",
              "Qf6",
              "Nbd2",
              "Ne7",
              "Re1",
              "Ng6",
              "d4",
              "Bd6",
              "hxg4",
              "hxg4",
              "Nh2",
              "Rxh2",
              "Kxh2",
              "Qxf2",
              "Nf1",
              "O-O-O",
              "Qxg4+",
              "Kb8",
              "Bg5",
              "Rh8+",
              "Qh3",
              "Rxh3+",
              "Kxh3",
              "exd4",
              "Rad1",
              "f6",
              "Bc1",
              "Qh4#",
              "Kg4",
              "Ne5+",
              "Kf5",
              "Qg4#",
              "Kf6",
              "Qg6#",
              "Ke7",
              "Qf7#",
              "Kd8",
              "Qd7#",
              "Ke8",
              "Qe8#",
              "Kf7",
              "Qf8#",
              "Ke6",
              "Qf7#",
              "Kf5",
              "Qg6#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#",
              "Kf5",
              "Qf3#",
              "Ke6",
              "Qg4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc6",
              "O-O",
              "Bg4",
              "h3",
              "h5",
              "d3",
              "Qf6",
              "Nbd2",
              "Ne7",
              "Re1",
              "Ng6",
              "d4",
              "Bd6",
              "hxg4",
              "hxg4",
              "Nh2",
              "Rxh2",
              "Kxh2",
              "Qxf2",
              "Nf1",
              "O-O-O",
              "Kh1",
              "Rh8+",
              "Nh2",
              "Rxh2+",
              "Kxh2",
              "Nh4",
              "Qxg4+",
              "f5",
              "Qh3",
              "Nf3+",
              "Qxf3",
              "Qh4+",
              "Qh3",
              "Qxe1",
              "Qxf5+",
              "Kb8",
              "dxe5",
              "Qh4+",
              "Qh3",
              "Bxe5+",
              "g3",
              "Qxe4",
              "Qg2",
              "Qh4+",
              "Kg1",
              "Bxg3",
              "Be3",
              "Be5",
              "c3",
              "Qh5",
              "Rf1",
              "b6",
              "Rf8+",
              "Kb7",
              "Qf3",
              "Qh2+",
              "Kf1",
              "Qxb2",
              "Qf5",
              "Qa1+",
              "Kg2",
              "Qxa2+",
              "Kf3",
              "Qd5+",
              "Kg4",
              "Qg2+",
              "Kh5",
              "Qh2+",
              "Kg6",
              "Qg3+",
              "Bg5",
              "a5",
              "Qc8+",
              "Ka7",
              "Qa8#",
              "e4",
              "d5",
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 350,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1630,
          "total_tokens": 2028
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 350,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": "f3e5",
          "aggressive_response": "5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. f4 Ke6 22. Kf3 f5 23. h4 g6 24. Nc4 Bf6 25. Kg3 Kd5 26. Ne3+ Kd4 27. Nd1 b5 28. a3 c5 29. f3 c4 30. dxc4 bxc4 31. b4 c3 32. a4 Kc4 33. b5 axb5 34. axb5 Kxb5 35. Ne3 c6 36. h5 Bd4 37. hxg6 hxg6 38. Ng2 Kc4 39. Nh4 Be3 40. Nxg6 Kb4 41. Ne7 Ka3 42. Nxf5 Bd2 43. Nd4 Kb2 44. f5 c5 45. Nb3 Kxc2 46. Nxc5 Kd1 47. Nb3 c2 48. f4 Bc3 49. Kg4 Bf6 50. Kh5 Ke2 51. Kg6 Bb2 52. f6 Bxf6 53. Kxf6 Kd3 54. Ke5 Kc3 55. Nc1 Kd2 56. Na2 Kd3 57. f5 Kc4 58. f6 Kb3 59. Nc1+ Kb2 60. Ne2 Kb3 61. f7 Kc4 62. f8=Q Kd3 63. Nc1+ Kd2 64. Qf4+ Kd1 65. Kd4 Ke1 66. Kd3 Kd1 67. Qd2# e5 e6 d5",
          "aggressive_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 517,
            "total_tokens": 659,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd4",
            "Nf3",
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "f4",
            "Ke6",
            "Kf3",
            "f5",
            "h4",
            "g6",
            "Nc4",
            "Bf6",
            "Kg3",
            "Kd5",
            "Ne3+",
            "Kd4",
            "Nd1",
            "b5",
            "a3",
            "c5",
            "f3",
            "c4",
            "dxc4",
            "bxc4",
            "b4",
            "c3",
            "a4",
            "Kc4",
            "b5",
            "axb5",
            "axb5",
            "Kxb5",
            "Ne3",
            "c6",
            "h5",
            "Bd4",
            "hxg6",
            "hxg6",
            "Ng2",
            "Kc4",
            "Nh4",
            "Be3",
            "Nxg6",
            "Kb4",
            "Ne7",
            "Ka3",
            "Nxf5",
            "Bd2",
            "Nd4",
            "Kb2",
            "f5",
            "c5",
            "Nb3",
            "Kxc2",
            "Nxc5",
            "Kd1",
            "Nb3",
            "c2",
            "f4",
            "Bc3",
            "Kg4",
            "Bf6",
            "Kh5",
            "Ke2",
            "Kg6",
            "Bb2",
            "f6",
            "Bxf6",
            "Kxf6",
            "Kd3",
            "Ke5",
            "Kc3",
            "Nc1",
            "Kd2",
            "Na2",
            "Kd3",
            "f5",
            "Kc4",
            "f6",
            "Kb3",
            "Nc1+",
            "Kb2",
            "Ne2",
            "Kb3",
            "f7",
            "Kc4",
            "f8=Q",
            "Kd3",
            "Nc1+",
            "Kd2",
            "Qf4+",
            "Kd1",
            "Kd4",
            "Ke1",
            "Kd3",
            "Kd1",
            "Qd2#",
            "e5",
            "e6",
            "d5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe5",
          "positional_uci": "f3e5",
          "positional_response": "5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Bd6 27. Kg4 Bc5 28. Kf4 Bxe3+ 29. fxe3 f6 30. gxf6 Kxf6 31. e4 h5 32. d4 b6 33. c4 b5 34. c5 a5 35. a3 b4 36. a4 Kg6 37. e5 h4 38. Kg4 h3 39. Kxh3 Kf5 40. Kg3 Ke6 41. Kf4 Kd5 42. Kf5 Kxd4 43. e6 Kxc5 44. e7 Kd4 45. e8=Q Kc3 46. Qe3+ Kb2 47. Ke4 c5 48. Kd3 Kxb3 49. Kd2+ Kxa4 50. Qxc5 b3 51. Kc3 b2 52. Qc4+ Ka3 53. Qb3# e4 Nf6 Qxf6+ Kd7",
          "positional_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 415,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd4",
            "Nf3",
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "Kg3",
            "Ke6",
            "Kf4",
            "Be5+",
            "Ke4",
            "Bxh2",
            "f4",
            "g6",
            "Kf3",
            "g5",
            "fxg5",
            "Bd6",
            "Kg4",
            "Bc5",
            "Kf4",
            "Bxe3+",
            "fxe3",
            "f6",
            "gxf6",
            "Kxf6",
            "e4",
            "h5",
            "d4",
            "b6",
            "c4",
            "b5",
            "c5",
            "a5",
            "a3",
            "b4",
            "a4",
            "Kg6",
            "e5",
            "h4",
            "Kg4",
            "h3",
            "Kxh3",
            "Kf5",
            "Kg3",
            "Ke6",
            "Kf4",
            "Kd5",
            "Kf5",
            "Kxd4",
            "e6",
            "Kxc5",
            "e7",
            "Kd4",
            "e8=Q",
            "Kc3",
            "Qe3+",
            "Kb2",
            "Ke4",
            "c5",
            "Kd3",
            "Kxb3",
            "Kd2+",
            "Kxa4",
            "Qxc5",
            "b3",
            "Kc3",
            "b2",
            "Qc4+",
            "Ka3",
            "Qb3#",
            "e4",
            "Nf6",
            "Qxf6+",
            "Kd7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe5",
          "neutral_uci": "f3e5",
          "neutral_response": "5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Be5 27. Ke4 Bg7 28. f4 f6 29. f5+ Kd6 30. g6 hxg6 31. fxg6 Ke6 32. Nf5 Bf8 33. g7 Bxg7 34. Nxg7+ Kd6 35. Kf5 Kc5 36. c3 b5 37. Kxf6 b4 38. Ne6+ Kb5 39. c4+ Kb6 40. Ke5 c5 41. Kd5 c6+ 42. Kd6 a5 43. Nxc5 Ka7 44. Kxc6 Kb8 45. d4 Kc8 46. d5 Kd8 47. d6 Kc8 48. d7+ Kd8 49. Nb7+ Ke7 50. d8=Q+ Ke6 51. Qd5+ Kf6 52. Kd6 Kg6 53. Qe5 Kf7 54. Qe6+ Kg7 55. Ke7 Kh7 56. Qg4 Kh6 57. Kf6 Kh7 58. Qg7# Qd4+ Kg1 Qd8+ Kh2 Qd7+ Kh3 Qd6+ Kh4 Qd7+ Kh5 Qd8+ Kh6 Qd7+ Kh7 Qd8+ Kh8 Qd7+ Kh7 Qd8+ Kh6 Qd7+ Kh5 Qd8+ Kh4 Qd7+ Kh3 Qd6+ Kh2 Qd7+ Kh1 Qd8+ Kh2 Qd7+ Kh3 Qd6+ Kh4 Qd8+ Kh5 Qd7+ Kh6 Qd7+ Kh7 Qd8+ Kh8 Qd7+ Kh7 Qd8+ Kh6 Qd7+ Kh5 Qd8+ Kh4 Qd7+ Kh3 Qd6+ Kh2 Qd7+ Kh1 Qd8+ Kh2 Qd7+ Kh3 Qd6+ Kh",
          "neutral_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qd4",
            "Nf3",
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "Kg3",
            "Ke6",
            "Kf4",
            "Be5+",
            "Ke4",
            "Bxh2",
            "f4",
            "g6",
            "Kf3",
            "g5",
            "fxg5",
            "Be5",
            "Ke4",
            "Bg7",
            "f4",
            "f6",
            "f5+",
            "Kd6",
            "g6",
            "hxg6",
            "fxg6",
            "Ke6",
            "Nf5",
            "Bf8",
            "g7",
            "Bxg7",
            "Nxg7+",
            "Kd6",
            "Kf5",
            "Kc5",
            "c3",
            "b5",
            "Kxf6",
            "b4",
            "Ne6+",
            "Kb5",
            "c4+",
            "Kb6",
            "Ke5",
            "c5",
            "Kd5",
            "c6+",
            "Kd6",
            "a5",
            "Nxc5",
            "Ka7",
            "Kxc6",
            "Kb8",
            "d4",
            "Kc8",
            "d5",
            "Kd8",
            "d6",
            "Kc8",
            "d7+",
            "Kd8",
            "Nb7+",
            "Ke7",
            "d8=Q+",
            "Ke6",
            "Qd5+",
            "Kf6",
            "Kd6",
            "Kg6",
            "Qe5",
            "Kf7",
            "Qe6+",
            "Kg7",
            "Ke7",
            "Kh7",
            "Qg4",
            "Kh6",
            "Kf6",
            "Kh7",
            "Qg7#",
            "Qd4+",
            "Kg1",
            "Qd8+",
            "Kh2",
            "Qd7+",
            "Kh3",
            "Qd6+",
            "Kh4",
            "Qd7+",
            "Kh5",
            "Qd8+",
            "Kh6",
            "Qd7+",
            "Kh7",
            "Qd8+",
            "Kh8",
            "Qd7+",
            "Kh7",
            "Qd8+",
            "Kh6",
            "Qd7+",
            "Kh5",
            "Qd8+",
            "Kh4",
            "Qd7+",
            "Kh3",
            "Qd6+",
            "Kh2",
            "Qd7+",
            "Kh1",
            "Qd8+",
            "Kh2",
            "Qd7+",
            "Kh3",
            "Qd6+",
            "Kh4",
            "Qd8+",
            "Kh5",
            "Qd7+",
            "Kh6",
            "Qd7+",
            "Kh7",
            "Qd8+",
            "Kh8",
            "Qd7+",
            "Kh7",
            "Qd8+",
            "Kh6",
            "Qd7+",
            "Kh5",
            "Qd8+",
            "Kh4",
            "Qd7+",
            "Kh3",
            "Qd6+",
            "Kh2",
            "Qd7+",
            "Kh1",
            "Qd8+",
            "Kh2",
            "Qd7+",
            "Kh3",
            "Qd6+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3e5",
          "positional_uci": "f3e5",
          "neutral_uci": "f3e5",
          "consensus_move": "f3e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd4",
              "Nf3",
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "f4",
              "Ke6",
              "Kf3",
              "f5",
              "h4",
              "g6",
              "Nc4",
              "Bf6",
              "Kg3",
              "Kd5",
              "Ne3+",
              "Kd4",
              "Nd1",
              "b5",
              "a3",
              "c5",
              "f3",
              "c4",
              "dxc4",
              "bxc4",
              "b4",
              "c3",
              "a4",
              "Kc4",
              "b5",
              "axb5",
              "axb5",
              "Kxb5",
              "Ne3",
              "c6",
              "h5",
              "Bd4",
              "hxg6",
              "hxg6",
              "Ng2",
              "Kc4",
              "Nh4",
              "Be3",
              "Nxg6",
              "Kb4",
              "Ne7",
              "Ka3",
              "Nxf5",
              "Bd2",
              "Nd4",
              "Kb2",
              "f5",
              "c5",
              "Nb3",
              "Kxc2",
              "Nxc5",
              "Kd1",
              "Nb3",
              "c2",
              "f4",
              "Bc3",
              "Kg4",
              "Bf6",
              "Kh5",
              "Ke2",
              "Kg6",
              "Bb2",
              "f6",
              "Bxf6",
              "Kxf6",
              "Kd3",
              "Ke5",
              "Kc3",
              "Nc1",
              "Kd2",
              "Na2",
              "Kd3",
              "f5",
              "Kc4",
              "f6",
              "Kb3",
              "Nc1+",
              "Kb2",
              "Ne2",
              "Kb3",
              "f7",
              "Kc4",
              "f8=Q",
              "Kd3",
              "Nc1+",
              "Kd2",
              "Qf4+",
              "Kd1",
              "Kd4",
              "Ke1",
              "Kd3",
              "Kd1",
              "Qd2#",
              "e5",
              "e6",
              "d5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd4",
              "Nf3",
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "Kg3",
              "Ke6",
              "Kf4",
              "Be5+",
              "Ke4",
              "Bxh2",
              "f4",
              "g6",
              "Kf3",
              "g5",
              "fxg5",
              "Bd6",
              "Kg4",
              "Bc5",
              "Kf4",
              "Bxe3+",
              "fxe3",
              "f6",
              "gxf6",
              "Kxf6",
              "e4",
              "h5",
              "d4",
              "b6",
              "c4",
              "b5",
              "c5",
              "a5",
              "a3",
              "b4",
              "a4",
              "Kg6",
              "e5",
              "h4",
              "Kg4",
              "h3",
              "Kxh3",
              "Kf5",
              "Kg3",
              "Ke6",
              "Kf4",
              "Kd5",
              "Kf5",
              "Kxd4",
              "e6",
              "Kxc5",
              "e7",
              "Kd4",
              "e8=Q",
              "Kc3",
              "Qe3+",
              "Kb2",
              "Ke4",
              "c5",
              "Kd3",
              "Kxb3",
              "Kd2+",
              "Kxa4",
              "Qxc5",
              "b3",
              "Kc3",
              "b2",
              "Qc4+",
              "Ka3",
              "Qb3#",
              "e4",
              "Nf6",
              "Qxf6+",
              "Kd7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd4",
              "Nf3",
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "Kg3",
              "Ke6",
              "Kf4",
              "Be5+",
              "Ke4",
              "Bxh2",
              "f4",
              "g6",
              "Kf3",
              "g5",
              "fxg5",
              "Be5",
              "Ke4",
              "Bg7",
              "f4",
              "f6",
              "f5+",
              "Kd6",
              "g6",
              "hxg6",
              "fxg6",
              "Ke6",
              "Nf5",
              "Bf8",
              "g7",
              "Bxg7",
              "Nxg7+",
              "Kd6",
              "Kf5",
              "Kc5",
              "c3",
              "b5",
              "Kxf6",
              "b4",
              "Ne6+",
              "Kb5",
              "c4+",
              "Kb6",
              "Ke5",
              "c5",
              "Kd5",
              "c6+",
              "Kd6",
              "a5",
              "Nxc5",
              "Ka7",
              "Kxc6",
              "Kb8",
              "d4",
              "Kc8",
              "d5",
              "Kd8",
              "d6",
              "Kc8",
              "d7+",
              "Kd8",
              "Nb7+",
              "Ke7",
              "d8=Q+",
              "Ke6",
              "Qd5+",
              "Kf6",
              "Kd6",
              "Kg6",
              "Qe5",
              "Kf7",
              "Qe6+",
              "Kg7",
              "Ke7",
              "Kh7",
              "Qg4",
              "Kh6",
              "Kf6",
              "Kh7",
              "Qg7#",
              "Qd4+",
              "Kg1",
              "Qd8+",
              "Kh2",
              "Qd7+",
              "Kh3",
              "Qd6+",
              "Kh4",
              "Qd7+",
              "Kh5",
              "Qd8+",
              "Kh6",
              "Qd7+",
              "Kh7",
              "Qd8+",
              "Kh8",
              "Qd7+",
              "Kh7",
              "Qd8+",
              "Kh6",
              "Qd7+",
              "Kh5",
              "Qd8+",
              "Kh4",
              "Qd7+",
              "Kh3",
              "Qd6+",
              "Kh2",
              "Qd7+",
              "Kh1",
              "Qd8+",
              "Kh2",
              "Qd7+",
              "Kh3",
              "Qd6+",
              "Kh4",
              "Qd8+",
              "Kh5",
              "Qd7+",
              "Kh6",
              "Qd7+",
              "Kh7",
              "Qd8+",
              "Kh8",
              "Qd7+",
              "Kh7",
              "Qd8+",
              "Kh6",
              "Qd7+",
              "Kh5",
              "Qd8+",
              "Kh4",
              "Qd7+",
              "Kh3",
              "Qd6+",
              "Kh2",
              "Qd7+",
              "Kh1",
              "Qd8+",
              "Kh2",
              "Qd7+",
              "Kh3",
              "Qd6+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 142,
            "completion_tokens": 517,
            "total_tokens": 659,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 142,
            "completion_tokens": 415,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 425,
          "total_completion_tokens": 1572,
          "total_tokens": 1997
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 142,
            "completion_tokens": 517,
            "total_tokens": 659,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 142,
            "completion_tokens": 415,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1pp2ppp/p1p5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "e5f3",
          "aggressive_response": "repeat entire game* 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Bd6 27. Kg4 Bc5 28. Kf4 Bxe3+ 29. fxe3 f6 30. gxf6 Kxf6 31. e4 h5 32. d4 b6 33. c4 c5 34. d5 h4 35. e5+ Ke7 36. Kg4 b5 37. Kxh4 bxc4 38. bxc4 a5 39. Kg5 a4 40. Kf5 a3 41. e6 Kd6 42. Kf6 c6 43. e7 cxd5 44. e8=Q dxc4 45. Qe6+ Kc7 46. Qxc4 Kc6 47. Ke5 Kb6 48. Kd5 Ka5 49. Qxc5+ Ka4 50. Qc4+ Ka5 51. Qb3 Ka6 52. Kc6 Ka5 53. Qb5# e4 d5 d4",
          "aggressive_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 405,
            "total_tokens": 556,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "Kg3",
            "Ke6",
            "Kf4",
            "Be5+",
            "Ke4",
            "Bxh2",
            "f4",
            "g6",
            "Kf3",
            "g5",
            "fxg5",
            "Bd6",
            "Kg4",
            "Bc5",
            "Kf4",
            "Bxe3+",
            "fxe3",
            "f6",
            "gxf6",
            "Kxf6",
            "e4",
            "h5",
            "d4",
            "b6",
            "c4",
            "c5",
            "d5",
            "h4",
            "e5+",
            "Ke7",
            "Kg4",
            "b5",
            "Kxh4",
            "bxc4",
            "bxc4",
            "a5",
            "Kg5",
            "a4",
            "Kf5",
            "a3",
            "e6",
            "Kd6",
            "Kf6",
            "c6",
            "e7",
            "cxd5",
            "e8=Q",
            "dxc4",
            "Qe6+",
            "Kc7",
            "Qxc4",
            "Kc6",
            "Ke5",
            "Kb6",
            "Kd5",
            "Ka5",
            "Qxc5+",
            "Ka4",
            "Qc4+",
            "Ka5",
            "Qb3",
            "Ka6",
            "Kc6",
            "Ka5",
            "Qb5#",
            "e4",
            "d5",
            "d4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "e5f3",
          "positional_response": "6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Kf3 g5 26. fxg5 Bd6 27. Kg4 Bc5 28. Kf4 Bxe3+ 29. fxe3 f6 30. gxf6 Kxf6 31. e4 h5 32. d4 b6 33. c4 c5 34. d5 h4 35. e5+ Ke7 36. Kg4 b5 37. Kxh4 bxc4 38. bxc4 a5 39. Kg5 a4 40. Kf5 a3 41. e6 Kd6 42. Kf6 c6 43. e7 cxd5 44. e8=Q dxc4 45. Qe6+ Kc7 46. Qxc4 Kc6 47. Ke6 Kb6 48. Kd6 Ka5 49. Qxc5+ Ka4 50. Qc4+ Ka5 51. Qb3 Ka6 52. Kc6 Ka5 53. Qb5# e5 d5 Qd8",
          "positional_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 402,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "Kg3",
            "Ke6",
            "Kf4",
            "Be5+",
            "Ke4",
            "Bxh2",
            "f4",
            "g6",
            "Kf3",
            "g5",
            "fxg5",
            "Bd6",
            "Kg4",
            "Bc5",
            "Kf4",
            "Bxe3+",
            "fxe3",
            "f6",
            "gxf6",
            "Kxf6",
            "e4",
            "h5",
            "d4",
            "b6",
            "c4",
            "c5",
            "d5",
            "h4",
            "e5+",
            "Ke7",
            "Kg4",
            "b5",
            "Kxh4",
            "bxc4",
            "bxc4",
            "a5",
            "Kg5",
            "a4",
            "Kf5",
            "a3",
            "e6",
            "Kd6",
            "Kf6",
            "c6",
            "e7",
            "cxd5",
            "e8=Q",
            "dxc4",
            "Qe6+",
            "Kc7",
            "Qxc4",
            "Kc6",
            "Ke6",
            "Kb6",
            "Kd6",
            "Ka5",
            "Qxc5+",
            "Ka4",
            "Qc4+",
            "Ka5",
            "Qb3",
            "Ka6",
            "Kc6",
            "Ka5",
            "Qb5#",
            "e5",
            "d5",
            "Qd8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "e5f3",
          "neutral_response": "6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. Kg3 Ke6 22. Kf4 Be5+ 23. Ke4 Bxh2 24. f4 g6 25. Ng4 f5+ 26. Kf3 fxg4+ 27. Kxg4 Kf6 28. Kh3 Bxf4 29. Kg4 Bd6 30. f4 h5+ 31. Kf3 Kf5 32. c4 Bxf4 33. d4 g5 34. d5 cxd5 35. cxd5 g4+ 36. Kg2 h4 37. a4 h3+ 38. Kh1 g3 39. b4 g2+ 40. Kg1 Be3+ 41. Kh2 g1=Q+ 42. Kxh3 Kf4 43. d6 Qg3# Qg3#",
          "neutral_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 322,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe4+",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "Kg3",
            "Ke6",
            "Kf4",
            "Be5+",
            "Ke4",
            "Bxh2",
            "f4",
            "g6",
            "Ng4",
            "f5+",
            "Kf3",
            "fxg4+",
            "Kxg4",
            "Kf6",
            "Kh3",
            "Bxf4",
            "Kg4",
            "Bd6",
            "f4",
            "h5+",
            "Kf3",
            "Kf5",
            "c4",
            "Bxf4",
            "d4",
            "g5",
            "d5",
            "cxd5",
            "cxd5",
            "g4+",
            "Kg2",
            "h4",
            "a4",
            "h3+",
            "Kh1",
            "g3",
            "b4",
            "g2+",
            "Kg1",
            "Be3+",
            "Kh2",
            "g1=Q+",
            "Kxh3",
            "Kf4",
            "d6",
            "Qg3#",
            "Qg3#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5f3",
          "positional_uci": "e5f3",
          "neutral_uci": "e5f3",
          "consensus_move": "e5f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "Kg3",
              "Ke6",
              "Kf4",
              "Be5+",
              "Ke4",
              "Bxh2",
              "f4",
              "g6",
              "Kf3",
              "g5",
              "fxg5",
              "Bd6",
              "Kg4",
              "Bc5",
              "Kf4",
              "Bxe3+",
              "fxe3",
              "f6",
              "gxf6",
              "Kxf6",
              "e4",
              "h5",
              "d4",
              "b6",
              "c4",
              "c5",
              "d5",
              "h4",
              "e5+",
              "Ke7",
              "Kg4",
              "b5",
              "Kxh4",
              "bxc4",
              "bxc4",
              "a5",
              "Kg5",
              "a4",
              "Kf5",
              "a3",
              "e6",
              "Kd6",
              "Kf6",
              "c6",
              "e7",
              "cxd5",
              "e8=Q",
              "dxc4",
              "Qe6+",
              "Kc7",
              "Qxc4",
              "Kc6",
              "Ke5",
              "Kb6",
              "Kd5",
              "Ka5",
              "Qxc5+",
              "Ka4",
              "Qc4+",
              "Ka5",
              "Qb3",
              "Ka6",
              "Kc6",
              "Ka5",
              "Qb5#",
              "e4",
              "d5",
              "d4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "Kg3",
              "Ke6",
              "Kf4",
              "Be5+",
              "Ke4",
              "Bxh2",
              "f4",
              "g6",
              "Kf3",
              "g5",
              "fxg5",
              "Bd6",
              "Kg4",
              "Bc5",
              "Kf4",
              "Bxe3+",
              "fxe3",
              "f6",
              "gxf6",
              "Kxf6",
              "e4",
              "h5",
              "d4",
              "b6",
              "c4",
              "c5",
              "d5",
              "h4",
              "e5+",
              "Ke7",
              "Kg4",
              "b5",
              "Kxh4",
              "bxc4",
              "bxc4",
              "a5",
              "Kg5",
              "a4",
              "Kf5",
              "a3",
              "e6",
              "Kd6",
              "Kf6",
              "c6",
              "e7",
              "cxd5",
              "e8=Q",
              "dxc4",
              "Qe6+",
              "Kc7",
              "Qxc4",
              "Kc6",
              "Ke6",
              "Kb6",
              "Kd6",
              "Ka5",
              "Qxc5+",
              "Ka4",
              "Qc4+",
              "Ka5",
              "Qb3",
              "Ka6",
              "Kc6",
              "Ka5",
              "Qb5#",
              "e5",
              "d5",
              "Qd8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxe4+",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "Kg3",
              "Ke6",
              "Kf4",
              "Be5+",
              "Ke4",
              "Bxh2",
              "f4",
              "g6",
              "Ng4",
              "f5+",
              "Kf3",
              "fxg4+",
              "Kxg4",
              "Kf6",
              "Kh3",
              "Bxf4",
              "Kg4",
              "Bd6",
              "f4",
              "h5+",
              "Kf3",
              "Kf5",
              "c4",
              "Bxf4",
              "d4",
              "g5",
              "d5",
              "cxd5",
              "cxd5",
              "g4+",
              "Kg2",
              "h4",
              "a4",
              "h3+",
              "Kh1",
              "g3",
              "b4",
              "g2+",
              "Kg1",
              "Be3+",
              "Kh2",
              "g1=Q+",
              "Kxh3",
              "Kf4",
              "d6",
              "Qg3#",
              "Qg3#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 151,
            "completion_tokens": 405,
            "total_tokens": 556,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 151,
            "completion_tokens": 402,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 150,
            "completion_tokens": 322,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 452,
          "total_completion_tokens": 1129,
          "total_tokens": 1581
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 151,
            "completion_tokens": 405,
            "total_tokens": 556,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 151,
            "completion_tokens": 402,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 150,
            "completion_tokens": 322,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/4N3/3qP3/8/PPPP1PPP/RNBQK2R w KQkq - 1 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf1",
          "aggressive_uci": "e1f1",
          "aggressive_response": "7. Kf1 Bg4 8. d3 Bxf3 9. Qxf3 Qxf3 10. gxf3 O-O-O 11. Be3 Nf6 12. Nc3 Nd5 13. Nxd5 cxd5 14. d4 Bd6 15. f4 Rhe8 16. Rg1 g6 17. Rg4 Re4 18. Ke2 Rde8 19. Kd3 f5 20. Rh4 R8e7 21. Rg1 c5 22. c3 c4+ 23. Kd2 b5 24. a3 a5 25. Rg3 b4 26. axb4 axb4 27. Rgh3 bxc3+ 28. bxc3 h5 29. Rg3 R7e6 30. Rg1 Be7 31. Rh3 Ra6 32. Rc1 Ra2+ 33. Rc2 Ra1 34. Rg3 Re6 35. Rc1 Ra2+ 36. Rc2 Ra1 37. Rc1 Ra2+ 38. Rc2 Ra1 39. Rc1 Ra2+ 40. Rc2 Ra1 41. Rc1 Ra2+ 42. Rc2 Ra1 43. Rc1 Ra2+ 44. Rc2 Ra1 45. Rc1 Ra2+ 46. Rc2 Ra1 47. Rc1 Ra2+ 48. Rc2 Ra1 49. Rc1 Ra2+ 50. Rc2 Ra1 51. Rc1 Ra2+ 52. Rc2 Ra1 53. Rc1 Ra2+ 54. Rc2 Ra1 55. Rc1 Ra2+ 56. Rc2 Ra1 57. Rc1 Ra2+ 58. Rc2 Ra1 59. Rc1 Ra2+ 60. Rc2 Ra1 61. Rc1 Ra2+ 62. Rc2 Ra1 63. Rc1 Ra2+ 64. Rc2 Ra1 65. Rc1 Ra2+ 66. Rc2 Ra1 67. Rc1 Ra2+ 68. Rc2 Ra1 69. Rc1 Ra2+ 70. Rc2 Ra1 71. Rc1 Ra2+ 72. Rc2 Ra1 73. Rc1 Ra2+ 74. Rc2 Ra1 75. Rc1 Ra2+ 76. Rc2 Ra1 77. Rc1 Ra2+ 78. Rc2 Ra1 79. Rc1 Ra2+ 80. Rc2 Ra1 81. Rc1 Ra2+ 82. Rc2 Ra1 83. Rc1 Ra2+ 84. Rc2 Ra1 85. Rc1 Ra2+ 86. Rc2 Ra1 87. Rc1 Ra2+ 88. Rc2 Ra1 89. Rc1 Ra",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bg4",
            "d3",
            "Bxf3",
            "Qxf3",
            "Qxf3",
            "gxf3",
            "O-O-O",
            "Be3",
            "Nf6",
            "Nc3",
            "Nd5",
            "Nxd5",
            "cxd5",
            "d4",
            "Bd6",
            "f4",
            "Rhe8",
            "Rg1",
            "g6",
            "Rg4",
            "Re4",
            "Ke2",
            "Rde8",
            "Kd3",
            "f5",
            "Rh4",
            "R8e7",
            "Rg1",
            "c5",
            "c3",
            "c4+",
            "Kd2",
            "b5",
            "a3",
            "a5",
            "Rg3",
            "b4",
            "axb4",
            "axb4",
            "Rgh3",
            "bxc3+",
            "bxc3",
            "h5",
            "Rg3",
            "R7e6",
            "Rg1",
            "Be7",
            "Rh3",
            "Ra6",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rg3",
            "Re6",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1",
            "Ra2+",
            "Rc2",
            "Ra1",
            "Rc1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kf1",
          "positional_uci": "e1f1",
          "positional_response": "7. Kf1 Bg4 8. d3 Bxf3 9. Qxf3 Qxf3 10. gxf3 O-O-O 11. Nc3 Nf6 12. Bg5 Be7 13. Re1 Rhe8 14. Kg2 h6 15. Bh4 g5 16. Bg3 Nd5 17. Nxd5 cxd5 18. Re2 Bf6 19. Rhe1 Rxe2 20. Rxe2 Bxb2 21. Re7 Rd7 22. Re8+ Rd8 23. Re7 Rd7 24. Re8+ Rd8 25. Re7 Rd7 26. Re8+ Rd8 27. Re7 Rd7 28. Re8+ Rd8 29. Re7 Rd7 30. Re8+ Rd8 31. Re7 Rd7 32. Re8+ Rd8 33. Re7 Rd7 34. Re8+ Rd8 35. Re7 Rd7 36. Re8+ Rd8 37. Re7 Rd7 38. Re8+ Rd8 39. Re7 Rd7 40. Re8+ Rd8 41. Re7 Rd7 42. Re8+ Rd8 43. Re7 Rd7 44. Re8+ Rd8 45. Re7 Rd7 46. Re8+ Rd8 47. Re7 Rd7 48. Re8+ Rd8 49. Re7 Rd7 50. Re8+ Rd8 51. Re7 Rd7 52. Re8+ Rd8 53. Re7 Rd7 54. Re8+ Rd8 55. Re7 Rd7 56. Re8+ Rd8 57. Re7 Rd7 58. Re8+ Rd8 59. Re7 Rd7 60. Re8+ Rd8 61. Re7 Rd7 62. Re8+ Rd8 63. Re7 Rd7 64. Re8+ Rd8 65. Re7 Rd7 66. Re8+ Rd8 67. Re7 Rd7 68. Re8+ Rd8 69. Re7 Rd7 70. Re8+ Rd8 71. Re7 Rd7 72. Re8+ Rd8 73. Re7 Rd7 74. Re8+ Rd8 75. Re7 Rd7 76. Re8+ Rd8 77. Re7 Rd7 78. Re8+ Rd8 79. Re7 Rd7 80. Re8+ Rd8 81. Re7 Rd7 82. Re8+ Rd8 83. Re7 Rd7 84. Re8+ Rd8 85. Re7 Rd7 86. Re8+ Rd8 87. Re7 Rd7 88. Re8+ Rd8 89. Re7 Rd7 90. Re8+ Rd8",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bg4",
            "d3",
            "Bxf3",
            "Qxf3",
            "Qxf3",
            "gxf3",
            "O-O-O",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "Re1",
            "Rhe8",
            "Kg2",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Nd5",
            "Nxd5",
            "cxd5",
            "Re2",
            "Bf6",
            "Rhe1",
            "Rxe2",
            "Rxe2",
            "Bxb2",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8",
            "Re7",
            "Rd7",
            "Re8+",
            "Rd8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe2",
          "neutral_uci": "d1e2",
          "neutral_response": "7. Qe2 Qxe2+ 8. Kxe2 Bg4 9. Re1 O-O-O 10. Kf1 Bxf3 11. gxf3 Nf6 12. d3 Bd6 13. Kg2 Rhe8 14. Rxe8 Rxe8 15. Nc3 Re1 16. b3 Be5 17. Bb2 Rxa1 18. Bxa1 Nd5 19. Nxd5 Bxa1 20. Ne3 Kd7 21. f4 Ke6 22. Kf3 f5 23. h4 g6 24. Nc4 Bf6 25. Kg3 Kd5 26. Ne3+ Kd4 27. Nd1 b5 28. h5 c5 29. hxg6 hxg6 30. Kf3 c4 31. dxc4 bxc4 32. Ke2 cxb3 33. axb3 Ke4 34. Ne3 Kxf4 35. Nd5+ Ke5 36. Nxc7 a5 37. Nb5 Kd5 38. Kd3 Kc5 39. Na3 Kb4 40. Nc4 a4 41. bxa4 Kxa4 42. Nd6 Kb4 43. Ne8 Be5 44. c4 Kc5 45. f3 g5 46. Ke3 Kxc4 47. f4 Bxf4+ 48. Kf3 Kd5 49. Ng7 Ke5 50. Nh5 g4+ 51. Kg2 Bg5 52. Ng3 f4 53. Nf1 Ke4 54. Nh2 Kf5 55. Nf1 Bh4 56. Nd2 Be1 57. Nf1 f3+ 58. Kh2 Kf4 59. Kg1 g3 60. Kh1 g2+ 61. Kg1 gxf1=Q+ 62. Kxf1 f2 63. Kg2 Ke3 64. Kf1 Kd2 65. Kg2 Ke2 66. Kh2 f1=Q 67. Kh1 Bf2+ 68. Kh2 Qg1+ 69. Kh3 Qg3# e4 e5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 Nxe5 Qd4 Nf6 Qxe4 Qxe4+ Kxe4 Bg4 Ke3 O-O-O Kf1 Bxf3 gxf3 Nf6 d3 Bd6 Kg2 Rhe8 Rxe8 Rxe8 Nc3 Re1 b3 Be5 Bb2 Bxc3 Bxc3 Nd5 c4 Nf4+ Kg3 Ne2+ Kg2 Rg1+ Kh2 Rg6 d4 Nxd4 f4 Nxb3 f5",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe2+",
            "Kxe2",
            "Bg4",
            "Re1",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Rxa1",
            "Bxa1",
            "Nd5",
            "Nxd5",
            "Bxa1",
            "Ne3",
            "Kd7",
            "f4",
            "Ke6",
            "Kf3",
            "f5",
            "h4",
            "g6",
            "Nc4",
            "Bf6",
            "Kg3",
            "Kd5",
            "Ne3+",
            "Kd4",
            "Nd1",
            "b5",
            "h5",
            "c5",
            "hxg6",
            "hxg6",
            "Kf3",
            "c4",
            "dxc4",
            "bxc4",
            "Ke2",
            "cxb3",
            "axb3",
            "Ke4",
            "Ne3",
            "Kxf4",
            "Nd5+",
            "Ke5",
            "Nxc7",
            "a5",
            "Nb5",
            "Kd5",
            "Kd3",
            "Kc5",
            "Na3",
            "Kb4",
            "Nc4",
            "a4",
            "bxa4",
            "Kxa4",
            "Nd6",
            "Kb4",
            "Ne8",
            "Be5",
            "c4",
            "Kc5",
            "f3",
            "g5",
            "Ke3",
            "Kxc4",
            "f4",
            "Bxf4+",
            "Kf3",
            "Kd5",
            "Ng7",
            "Ke5",
            "Nh5",
            "g4+",
            "Kg2",
            "Bg5",
            "Ng3",
            "f4",
            "Nf1",
            "Ke4",
            "Nh2",
            "Kf5",
            "Nf1",
            "Bh4",
            "Nd2",
            "Be1",
            "Nf1",
            "f3+",
            "Kh2",
            "Kf4",
            "Kg1",
            "g3",
            "Kh1",
            "g2+",
            "Kg1",
            "gxf1=Q+",
            "Kxf1",
            "f2",
            "Kg2",
            "Ke3",
            "Kf1",
            "Kd2",
            "Kg2",
            "Ke2",
            "Kh2",
            "f1=Q",
            "Kh1",
            "Bf2+",
            "Kh2",
            "Qg1+",
            "Kh3",
            "Qg3#",
            "e4",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Bxc6",
            "dxc6",
            "Nxe5",
            "Qd4",
            "Nf6",
            "Qxe4",
            "Qxe4+",
            "Kxe4",
            "Bg4",
            "Ke3",
            "O-O-O",
            "Kf1",
            "Bxf3",
            "gxf3",
            "Nf6",
            "d3",
            "Bd6",
            "Kg2",
            "Rhe8",
            "Rxe8",
            "Rxe8",
            "Nc3",
            "Re1",
            "b3",
            "Be5",
            "Bb2",
            "Bxc3",
            "Bxc3",
            "Nd5",
            "c4",
            "Nf4+",
            "Kg3",
            "Ne2+",
            "Kg2",
            "Rg1+",
            "Kh2",
            "Rg6",
            "d4",
            "Nxd4",
            "f4",
            "Nxb3",
            "f5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1f1",
          "positional_uci": "e1f1",
          "neutral_uci": "d1e2",
          "consensus_move": "e1f1",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg4",
              "d3",
              "Bxf3",
              "Qxf3",
              "Qxf3",
              "gxf3",
              "O-O-O",
              "Be3",
              "Nf6",
              "Nc3",
              "Nd5",
              "Nxd5",
              "cxd5",
              "d4",
              "Bd6",
              "f4",
              "Rhe8",
              "Rg1",
              "g6",
              "Rg4",
              "Re4",
              "Ke2",
              "Rde8",
              "Kd3",
              "f5",
              "Rh4",
              "R8e7",
              "Rg1",
              "c5",
              "c3",
              "c4+",
              "Kd2",
              "b5",
              "a3",
              "a5",
              "Rg3",
              "b4",
              "axb4",
              "axb4",
              "Rgh3",
              "bxc3+",
              "bxc3",
              "h5",
              "Rg3",
              "R7e6",
              "Rg1",
              "Be7",
              "Rh3",
              "Ra6",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rg3",
              "Re6",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1",
              "Ra2+",
              "Rc2",
              "Ra1",
              "Rc1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bg4",
              "d3",
              "Bxf3",
              "Qxf3",
              "Qxf3",
              "gxf3",
              "O-O-O",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "Re1",
              "Rhe8",
              "Kg2",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Nd5",
              "Nxd5",
              "cxd5",
              "Re2",
              "Bf6",
              "Rhe1",
              "Rxe2",
              "Rxe2",
              "Bxb2",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8",
              "Re7",
              "Rd7",
              "Re8+",
              "Rd8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxe2+",
              "Kxe2",
              "Bg4",
              "Re1",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Rxa1",
              "Bxa1",
              "Nd5",
              "Nxd5",
              "Bxa1",
              "Ne3",
              "Kd7",
              "f4",
              "Ke6",
              "Kf3",
              "f5",
              "h4",
              "g6",
              "Nc4",
              "Bf6",
              "Kg3",
              "Kd5",
              "Ne3+",
              "Kd4",
              "Nd1",
              "b5",
              "h5",
              "c5",
              "hxg6",
              "hxg6",
              "Kf3",
              "c4",
              "dxc4",
              "bxc4",
              "Ke2",
              "cxb3",
              "axb3",
              "Ke4",
              "Ne3",
              "Kxf4",
              "Nd5+",
              "Ke5",
              "Nxc7",
              "a5",
              "Nb5",
              "Kd5",
              "Kd3",
              "Kc5",
              "Na3",
              "Kb4",
              "Nc4",
              "a4",
              "bxa4",
              "Kxa4",
              "Nd6",
              "Kb4",
              "Ne8",
              "Be5",
              "c4",
              "Kc5",
              "f3",
              "g5",
              "Ke3",
              "Kxc4",
              "f4",
              "Bxf4+",
              "Kf3",
              "Kd5",
              "Ng7",
              "Ke5",
              "Nh5",
              "g4+",
              "Kg2",
              "Bg5",
              "Ng3",
              "f4",
              "Nf1",
              "Ke4",
              "Nh2",
              "Kf5",
              "Nf1",
              "Bh4",
              "Nd2",
              "Be1",
              "Nf1",
              "f3+",
              "Kh2",
              "Kf4",
              "Kg1",
              "g3",
              "Kh1",
              "g2+",
              "Kg1",
              "gxf1=Q+",
              "Kxf1",
              "f2",
              "Kg2",
              "Ke3",
              "Kf1",
              "Kd2",
              "Kg2",
              "Ke2",
              "Kh2",
              "f1=Q",
              "Kh1",
              "Bf2+",
              "Kh2",
              "Qg1+",
              "Kh3",
              "Qg3#",
              "e4",
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Bxc6",
              "dxc6",
              "Nxe5",
              "Qd4",
              "Nf6",
              "Qxe4",
              "Qxe4+",
              "Kxe4",
              "Bg4",
              "Ke3",
              "O-O-O",
              "Kf1",
              "Bxf3",
              "gxf3",
              "Nf6",
              "d3",
              "Bd6",
              "Kg2",
              "Rhe8",
              "Rxe8",
              "Rxe8",
              "Nc3",
              "Re1",
              "b3",
              "Be5",
              "Bb2",
              "Bxc3",
              "Bxc3",
              "Nd5",
              "c4",
              "Nf4+",
              "Kg3",
              "Ne2+",
              "Kg2",
              "Rg1+",
              "Kh2",
              "Rg6",
              "d4",
              "Nxd4",
              "f4",
              "Nxb3",
              "f5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 1920,
          "total_tokens": 2402
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 640,
            "total_tokens": 801,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 640,
            "total_tokens": 800,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d3",
          "aggressive_uci": "d2d3",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Nf6 9. Nc3 Bd6 10. Qe2+ Be6 11. Nd4 Qe5 12. Nxe6 fxe6 13. Qxe5 Bxe5 14. Bd2 O-O 15. Re1 Ng4 16. f3 Rae8 17. h3 Bxc3 18. Bxc3 Nf6 19. Kf2 Nd5 20. Be5 Rf5 21. Re4 Nf6 22. Bxf6 Rxf6 23. Rhe1 Kf7 24. g4 g5 25. Kg3 h6 26. f4 gxf4+ 27. Rxf4 Rxf4 28. Kxf4 Kf6 29. Re5 Rd8 30. Rh5 Kg6 31. Ke5 Rd5+ 32. Kxe6 Rxh5 33. gxh5+ Kxh5 34. Kd7 Kh4 35. Kxc7 Kxh3 36. Kxb7 Kg4 37. Kxc6 h5 38. d4 h4 39. d5 h3 40. d6 h2 41. d7 h1=Q+ 42. Kc7 Qh2+ 43. Kc8 Qxc2+ 44. Kb7 Qxb2+ 45. Kc8 Qc3+ 46. Kb7 Qb4+ 47. Kc8 Qc5+ 48. Kb7 Qd6 49. Kc8 Qc6+ 50. Kd8 Kf5 51. Ke7 Qe6+ 52. Kd8 Kf6 53. Kc7 Qc4+ 54. Kb7 Qb5+ 55. Kc7 Qc5+ 56. Kb7 Qd6 57. Kc8 Qc6+ 58. Kd8 Ke6 59. Ke8 Qxd7+ 60. Kf8 Qf7#\n*1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Nf6 9. Nc3 Bd6 10. Qe2+ Be6 11. Nd4 Qe5 12. Nxe6 fxe6 13. Qxe5 Bxe5 14. Bd2 O-O 15. Re1",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Nc3",
            "Bd6",
            "Qe2+",
            "Be6",
            "Nd4",
            "Qe5",
            "Nxe6",
            "fxe6",
            "Qxe5",
            "Bxe5",
            "Bd2",
            "O-O",
            "Re1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d3",
          "positional_uci": "d2d3",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Nf6 9. Nc3 Bd6 10. Qe2+ Be6 11. Nd4 Qe5 12. Qxe5 Bxe5 13. Nxe6 fxe6 14. Bd2 O-O 15. Re1 Ng4 16. f3 Rae8 17. h3 Bxc3 18. Bxc3 Nf6 19. Kf2 Nd5 20. Be5 Rf5 21. Re4 Nf6 22. Bxf6 gxf6 23. Rhe1 Kf7 24. g4 Rb5 25. b3 Rc5 26. c4 Ra5 27. a4 b5 28. cxb5 cxb5 29. Rc1 Re7 30. Rc5 e5 31. f4 exf4 32. Rxe7+ Kxe7 33. Rxc7+ Kd6 34. Rxh7 bxa4 35. bxa4 Rxa4 36. Kf3 Ke5 37. Re7+ Kd6 38. Re4 Ra3 39. Rd4+ Ke5 40. Re4+ Kd5 41. Kxf4 Rxd3 42. h4 Rh3 43. h5 a5 44. Ra4 Ke6 45. Rxa5 Kf7 46. Ra7+ Kg8 47. Kf5 Rf3+ 48. Kg6 Kf8 49. h6 Rg3 50. Kxf6 Rf3+ 51. Kg6 Rg3 52. g5 Re3 53. h7 Re6+ 54. Kh5 Re7 55. h8=Q+ Kf7 56. Qh7+ Ke6 57. Qxe7+ Kd5 58. Rd7+ Kc4 59. Qe4+ Kc5 60. Qd5+ Kb4 61. Rb7+ Kc3 62. Rb3+ Kc2 63. Qd3+ Kc1 64. Rb1# Qf5 g3 Qf5 g4 Qf5",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 550,
            "total_tokens": 721,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Nc3",
            "Bd6",
            "Qe2+",
            "Be6",
            "Nd4",
            "Qe5",
            "Qxe5",
            "Bxe5",
            "Nxe6",
            "fxe6",
            "Bd2",
            "O-O",
            "Re1",
            "Ng4",
            "f3",
            "Rae8",
            "h3",
            "Bxc3",
            "Bxc3",
            "Nf6",
            "Kf2",
            "Nd5",
            "Be5",
            "Rf5",
            "Re4",
            "Nf6",
            "Bxf6",
            "gxf6",
            "Rhe1",
            "Kf7",
            "g4",
            "Rb5",
            "b3",
            "Rc5",
            "c4",
            "Ra5",
            "a4",
            "b5",
            "cxb5",
            "cxb5",
            "Rc1",
            "Re7",
            "Rc5",
            "e5",
            "f4",
            "exf4",
            "Rxe7+",
            "Kxe7",
            "Rxc7+",
            "Kd6",
            "Rxh7",
            "bxa4",
            "bxa4",
            "Rxa4",
            "Kf3",
            "Ke5",
            "Re7+",
            "Kd6",
            "Re4",
            "Ra3",
            "Rd4+",
            "Ke5",
            "Re4+",
            "Kd5",
            "Kxf4",
            "Rxd3",
            "h4",
            "Rh3",
            "h5",
            "a5",
            "Ra4",
            "Ke6",
            "Rxa5",
            "Kf7",
            "Ra7+",
            "Kg8",
            "Kf5",
            "Rf3+",
            "Kg6",
            "Kf8",
            "h6",
            "Rg3",
            "Kxf6",
            "Rf3+",
            "Kg6",
            "Rg3",
            "g5",
            "Re3",
            "h7",
            "Re6+",
            "Kh5",
            "Re7",
            "h8=Q+",
            "Kf7",
            "Qh7+",
            "Ke6",
            "Qxe7+",
            "Kd5",
            "Rd7+",
            "Kc4",
            "Qe4+",
            "Kc5",
            "Qd5+",
            "Kb4",
            "Rb7+",
            "Kc3",
            "Rb3+",
            "Kc2",
            "Qd3+",
            "Kc1",
            "Rb1#",
            "Qf5",
            "g3",
            "Qf5",
            "g4",
            "Qf5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d3",
          "neutral_uci": "d2d3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Be6 9. Nc3 O-O-O 10. Be3 Nf6 11. Nd4 Qe5 12. Nxe6 Qxe6 13. Qf3 Bb4 14. Re1 Rhe8\n*8. d3 Be6 9. Nc3 O-O-O 10. Be3 Nf6 11. Nd4 Qe5 12. Nxe6 Qxe6 13. Qf3 Bb4 14. Re1 Rhe8\n15. a3 Bxc3 16. bxc3 Nd5 17. Bd2 Qd6 18. Rxe8 Rxe8 19. Qxf7 Rf8 20. Qxg7 Qxa3 21. c4 Nb4\n*15. a3 Bxc3 16. bxc3 Nd5 17. Bd2 Qd6 18. Rxe8 Rxe8 19. Qxf7 Rf8 20. Qxg7 Qxa3 21. c4 Nb4\n22. Qxf8+ Kd7 23. Qxb4 Qa1+ 24. Be1 Qd1\n*22. Qxf8+ Kd7 23. Qxb4 Qa1+ 24. Be1 Qd1\n25. Qd2 Qa1 26. Qc3 Qd1 27. Qd4+ Kc8 28. Qh8+ Kd7 29. Qxh7+ Kd6 30. Qg6+ Kc5 31. Qg5+ Kb6\n*25. Qd2 Qa1 26. Qc3 Qd1 27. Qd4+ Kc8 28. Qh8+ Kd7 29. Qxh7+ Kd6 30. Qg6+ Kc5 31. Qg5+ Kb6\n32. Qe3+ Ka5 33. Qd2+ Kb6\n*32. Qe3+ Ka5 33. Qd2+ Kb6 34. Qxd1",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 531,
            "total_tokens": 701,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be6",
            "Nc3",
            "O-O-O",
            "Be3",
            "Nf6",
            "Nd4",
            "Qe5",
            "Nxe6",
            "Qxe6",
            "Qf3",
            "Bb4",
            "Re1",
            "Rhe8",
            "a3",
            "Bxc3",
            "bxc3",
            "Nd5",
            "Bd2",
            "Qd6",
            "Rxe8",
            "Rxe8",
            "Qxf7",
            "Rf8",
            "Qxg7",
            "Qxa3",
            "c4",
            "Nb4",
            "a3",
            "Bxc3",
            "bxc3",
            "Nd5",
            "Bd2",
            "Qd6",
            "Rxe8",
            "Rxe8",
            "Qxf7",
            "Rf8",
            "Qxg7",
            "Qxa3",
            "c4",
            "Nb4",
            "Qxf8+",
            "Kd7",
            "Qxb4",
            "Qa1+",
            "Be1",
            "Qd1",
            "Qxf8+",
            "Kd7",
            "Qxb4",
            "Qa1+",
            "Be1",
            "Qd1",
            "Qd2",
            "Qa1",
            "Qc3",
            "Qd1",
            "Qd4+",
            "Kc8",
            "Qh8+",
            "Kd7",
            "Qxh7+",
            "Kd6",
            "Qg6+",
            "Kc5",
            "Qg5+",
            "Kb6",
            "Qd2",
            "Qa1",
            "Qc3",
            "Qd1",
            "Qd4+",
            "Kc8",
            "Qh8+",
            "Kd7",
            "Qxh7+",
            "Kd6",
            "Qg6+",
            "Kc5",
            "Qg5+",
            "Kb6",
            "Qe3+",
            "Ka5",
            "Qd2+",
            "Kb6",
            "Qe3+",
            "Ka5",
            "Qd2+",
            "Kb6",
            "Qxd1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d3",
          "positional_uci": "d2d3",
          "neutral_uci": "d2d3",
          "consensus_move": "d2d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Nc3",
              "Bd6",
              "Qe2+",
              "Be6",
              "Nd4",
              "Qe5",
              "Nxe6",
              "fxe6",
              "Qxe5",
              "Bxe5",
              "Bd2",
              "O-O",
              "Re1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Nc3",
              "Bd6",
              "Qe2+",
              "Be6",
              "Nd4",
              "Qe5",
              "Qxe5",
              "Bxe5",
              "Nxe6",
              "fxe6",
              "Bd2",
              "O-O",
              "Re1",
              "Ng4",
              "f3",
              "Rae8",
              "h3",
              "Bxc3",
              "Bxc3",
              "Nf6",
              "Kf2",
              "Nd5",
              "Be5",
              "Rf5",
              "Re4",
              "Nf6",
              "Bxf6",
              "gxf6",
              "Rhe1",
              "Kf7",
              "g4",
              "Rb5",
              "b3",
              "Rc5",
              "c4",
              "Ra5",
              "a4",
              "b5",
              "cxb5",
              "cxb5",
              "Rc1",
              "Re7",
              "Rc5",
              "e5",
              "f4",
              "exf4",
              "Rxe7+",
              "Kxe7",
              "Rxc7+",
              "Kd6",
              "Rxh7",
              "bxa4",
              "bxa4",
              "Rxa4",
              "Kf3",
              "Ke5",
              "Re7+",
              "Kd6",
              "Re4",
              "Ra3",
              "Rd4+",
              "Ke5",
              "Re4+",
              "Kd5",
              "Kxf4",
              "Rxd3",
              "h4",
              "Rh3",
              "h5",
              "a5",
              "Ra4",
              "Ke6",
              "Rxa5",
              "Kf7",
              "Ra7+",
              "Kg8",
              "Kf5",
              "Rf3+",
              "Kg6",
              "Kf8",
              "h6",
              "Rg3",
              "Kxf6",
              "Rf3+",
              "Kg6",
              "Rg3",
              "g5",
              "Re3",
              "h7",
              "Re6+",
              "Kh5",
              "Re7",
              "h8=Q+",
              "Kf7",
              "Qh7+",
              "Ke6",
              "Qxe7+",
              "Kd5",
              "Rd7+",
              "Kc4",
              "Qe4+",
              "Kc5",
              "Qd5+",
              "Kb4",
              "Rb7+",
              "Kc3",
              "Rb3+",
              "Kc2",
              "Qd3+",
              "Kc1",
              "Rb1#",
              "Qf5",
              "g3",
              "Qf5",
              "g4",
              "Qf5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be6",
              "Nc3",
              "O-O-O",
              "Be3",
              "Nf6",
              "Nd4",
              "Qe5",
              "Nxe6",
              "Qxe6",
              "Qf3",
              "Bb4",
              "Re1",
              "Rhe8",
              "a3",
              "Bxc3",
              "bxc3",
              "Nd5",
              "Bd2",
              "Qd6",
              "Rxe8",
              "Rxe8",
              "Qxf7",
              "Rf8",
              "Qxg7",
              "Qxa3",
              "c4",
              "Nb4",
              "a3",
              "Bxc3",
              "bxc3",
              "Nd5",
              "Bd2",
              "Qd6",
              "Rxe8",
              "Rxe8",
              "Qxf7",
              "Rf8",
              "Qxg7",
              "Qxa3",
              "c4",
              "Nb4",
              "Qxf8+",
              "Kd7",
              "Qxb4",
              "Qa1+",
              "Be1",
              "Qd1",
              "Qxf8+",
              "Kd7",
              "Qxb4",
              "Qa1+",
              "Be1",
              "Qd1",
              "Qd2",
              "Qa1",
              "Qc3",
              "Qd1",
              "Qd4+",
              "Kc8",
              "Qh8+",
              "Kd7",
              "Qxh7+",
              "Kd6",
              "Qg6+",
              "Kc5",
              "Qg5+",
              "Kb6",
              "Qd2",
              "Qa1",
              "Qc3",
              "Qd1",
              "Qd4+",
              "Kc8",
              "Qh8+",
              "Kd7",
              "Qxh7+",
              "Kd6",
              "Qg6+",
              "Kc5",
              "Qg5+",
              "Kb6",
              "Qe3+",
              "Ka5",
              "Qd2+",
              "Kb6",
              "Qe3+",
              "Ka5",
              "Qd2+",
              "Kb6",
              "Qxd1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 550,
            "total_tokens": 721,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 531,
            "total_tokens": 701,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1721,
          "total_tokens": 2233
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 550,
            "total_tokens": 721,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 531,
            "total_tokens": 701,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/5q2/8/5N2/PPPP1PPP/RNBQ1K1R w kq - 2 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxf3",
          "aggressive_uci": "d1f3",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Nf6 10. Bg5 Be7 11. Nc3 O-O 12. Re1 Be6 13. Ne4 Nxe4 14. Bxe7 Nd2+ 15. Ke2 Nxf3 16. Kxf3 Rfe8 17. Bb4 Bd5+ 18. Kg3 b6 19. Rxe8+ Rxe8 20. Re1 Rxe1 21. Bxe1 Bxa2 22. b3 Bb1 23. c3 Bxd3 24. Kf4 f6 25. Ke3 Bc2 26. b4 Kf7 27. Kd4 Ke6 28. Bd2 g5 29. f4 h6 30. fxg5 hxg5 31. g3 Kf5 32. h4 gxh4 33. gxh4 Kg4 34. Be1 f5 35. Ke5 f4 36. Ke6 f3 37. Kd7 Be4 38. Kxc7 b5 39. Kb6 Kh3 40. Kxa6 Kg2 41. Kb6 f2 42. Bxf2 Kxf2 43. Kc5 Ke3 44. c4 bxc4 45. Kxc4 Kf4 46. Kc5 Kg4 47. b5 cxb5 48. Kxb5 Kxh4 49. Kc5 Kg4 50. Kd4 Kf4 51. Kc5 Ke5 52. Kc4 Bd5+ 53. Kc5 Be6 54. Kc6 Kd4 55. Kd6 Bf5 56. Kc6 Be4+ 57. Kd6 Bd5 58. Ke7 Ke5 59. Kd7 Be6+ 60. Kc6 Kd4 61. Kd6 Bf5 62. Kc6 Be4+ 63. Kd6 Bf3 64. Ke6 Ke4 65. Kd6 Kf5 66. Kc5 Ke5 67. Kc4 Be4 68. Kc5 Bd5 69. Kb4 Kd4 70. Kb5 Bc4+ 71. Kc6 Bd5+ 72. Kd6 Be4 73. Ke6 Kc5 74. Ke5 Bd5 75. Kf4 Kd4 76. Kf5 Be4+ 77. Kf4 Kd3 78.",
          "aggressive_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Bg5",
            "Be7",
            "Nc3",
            "O-O",
            "Re1",
            "Be6",
            "Ne4",
            "Nxe4",
            "Bxe7",
            "Nd2+",
            "Ke2",
            "Nxf3",
            "Kxf3",
            "Rfe8",
            "Bb4",
            "Bd5+",
            "Kg3",
            "b6",
            "Rxe8+",
            "Rxe8",
            "Re1",
            "Rxe1",
            "Bxe1",
            "Bxa2",
            "b3",
            "Bb1",
            "c3",
            "Bxd3",
            "Kf4",
            "f6",
            "Ke3",
            "Bc2",
            "b4",
            "Kf7",
            "Kd4",
            "Ke6",
            "Bd2",
            "g5",
            "f4",
            "h6",
            "fxg5",
            "hxg5",
            "g3",
            "Kf5",
            "h4",
            "gxh4",
            "gxh4",
            "Kg4",
            "Be1",
            "f5",
            "Ke5",
            "f4",
            "Ke6",
            "f3",
            "Kd7",
            "Be4",
            "Kxc7",
            "b5",
            "Kb6",
            "Kh3",
            "Kxa6",
            "Kg2",
            "Kb6",
            "f2",
            "Bxf2",
            "Kxf2",
            "Kc5",
            "Ke3",
            "c4",
            "bxc4",
            "Kxc4",
            "Kf4",
            "Kc5",
            "Kg4",
            "b5",
            "cxb5",
            "Kxb5",
            "Kxh4",
            "Kc5",
            "Kg4",
            "Kd4",
            "Kf4",
            "Kc5",
            "Ke5",
            "Kc4",
            "Bd5+",
            "Kc5",
            "Be6",
            "Kc6",
            "Kd4",
            "Kd6",
            "Bf5",
            "Kc6",
            "Be4+",
            "Kd6",
            "Bd5",
            "Ke7",
            "Ke5",
            "Kd7",
            "Be6+",
            "Kc6",
            "Kd4",
            "Kd6",
            "Bf5",
            "Kc6",
            "Be4+",
            "Kd6",
            "Bf3",
            "Ke6",
            "Ke4",
            "Kd6",
            "Kf5",
            "Kc5",
            "Ke5",
            "Kc4",
            "Be4",
            "Kc5",
            "Bd5",
            "Kb4",
            "Kd4",
            "Kb5",
            "Bc4+",
            "Kc6",
            "Bd5+",
            "Kd6",
            "Be4",
            "Ke6",
            "Kc5",
            "Ke5",
            "Bd5",
            "Kf4",
            "Kd4",
            "Kf5",
            "Be4+",
            "Kf4",
            "Kd3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxf3",
          "positional_uci": "d1f3",
          "positional_response": "9. Qxf3 Bg4 10. Qxg4 Nf6 11. Qe2+ Be7 12. Bg5 O-O-O 13. Qxe7 Rhe8 14. Qxf7 Rd7\n15. Qb3 Rde7 16. Nc3 Re5 17. Bxf6 gxf6 18. Ne4 f5 19. Nf6 R8e6 20. Nxh7 Rb5 21. Qxe6+ Kb8 22. b3 Ka7 23. c4 Rb6 24. Qxf5 c5 25. Qxc5 a5 26. Qxa5+ Ra6 27. Qxc7 Rc6 28. Qa5+ Ra6 29. Qc5+ Rb6 30. Re1 Ka6 31. Qa3# Qxa3 32. Re8 Qc1+ 33. Ke2 Qxh1 34. Ra8# Qxg2 35. Nf8 Qg4+ 36. f3 Qg2+ 37. Ke3 Qg1+ 38. Ke4 Qe1+ 39. Kd4 Qf2+ 40. Kc3 Qe1+ 41. Kd4 Qf2+ 42. Kc3 Qe1+ 43. Kd4 Qf2+ 44. Kc3 Qe1+ 45. Kd4 Qf2+ 46. Kc3 Qe1+ 47. Kd4 Qf2+ 48. Kc3 Qe1+ 49. Kd4 Qf2+ 50. Kc3 Qe1+ 51. Kd4 Qf2+ 52. Kc3 Qe1+ 53. Kd4 Qf2+ 54. Kc3 Qe1+ 55. Kd4 Qf2+ 56. Kc3 Qe1+ 57. Kd4 Qf2+ 58. Kc3 Qe1+ 59. Kd4 Qf2+ 60. Kc3 Qe1+ 61. Kd4 Qf2+ 62. Kc3 Qe1+ 63. Kd4 Qf2+ 64. Kc3 Qe1+ 65. Kd4 Qf2+ 66. Kc3 Qe1+ 67. Kd4 Qf2+ 68. Kc3 Qe1+ 69. Kd4 Qf2+ 70. Kc3 Qe1+ 71. Kd4 Qf2+ 72. Kc3 Qe1+ 73. Kd4 Qf2+ 74. Kc3 Qe1+ 75. Kd4 Qf2+ 76. Kc3 Q",
          "positional_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bg4",
            "Qxg4",
            "Nf6",
            "Qe2+",
            "Be7",
            "Bg5",
            "O-O-O",
            "Qxe7",
            "Rhe8",
            "Qxf7",
            "Rd7",
            "Qb3",
            "Rde7",
            "Nc3",
            "Re5",
            "Bxf6",
            "gxf6",
            "Ne4",
            "f5",
            "Nf6",
            "R8e6",
            "Nxh7",
            "Rb5",
            "Qxe6+",
            "Kb8",
            "b3",
            "Ka7",
            "c4",
            "Rb6",
            "Qxf5",
            "c5",
            "Qxc5",
            "a5",
            "Qxa5+",
            "Ra6",
            "Qxc7",
            "Rc6",
            "Qa5+",
            "Ra6",
            "Qc5+",
            "Rb6",
            "Re1",
            "Ka6",
            "Qa3#",
            "Qxa3",
            "Re8",
            "Qc1+",
            "Ke2",
            "Qxh1",
            "Ra8#",
            "Qxg2",
            "Nf8",
            "Qg4+",
            "f3",
            "Qg2+",
            "Ke3",
            "Qg1+",
            "Ke4",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3",
            "Qe1+",
            "Kd4",
            "Qf2+",
            "Kc3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxf3",
          "neutral_uci": "d1f3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Nf6 10. Bg5 Be7 11. Nc3 O-O 12. Re1 Be6 13. Ne4 Nxe4 14. Bxe7 Nd2+ 15. Ke2 Nxf3 16. Kxf3 Rfe8 17. Bb4 Bd5+ 18. Kg3 b6 19. Rxe8+ Rxe8 20. Re1 Rxe1 21. Bxe1 Bxa2 22. b3 Bb1 23. c3 Bxd3 24. Kf4 f6 25. Ke3 Bf5 26. Kd4 Kf7 27. Bd2 Ke6 28. Bf4 Kd7 29. h3 Be6 30. b4 Bd5 31. g3 g5 32. Be3 Kd6 33. h4 c5+ 34. bxc5+ bxc5+ 35. Kd3 gxh4 36. gxh4 c4+ 37. Kd4 c5# 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Nf6 10. Bg5 Be7 11. Nc3 O-O 12. Re1 Be6 13. Ne4 Nxe4 14. Bxe7 Nd2+ 15. Ke2 Nxf3 16. Kxf3 Rfe8 17. Bb4 Bd5+ 18. Kg3 b6 19. Rxe8+ Rxe8 20. Re1 Rxe1 21. Bxe1 Bxa2 22. b3 Bb1 23. c3 Bxd3 24. Kf4 f6 25. Ke3 Bf5 26. Kd4 Kf7 27. Bd2 Ke6 28. Bf4 Kd7 29. h3 Be6 30. b4 Bd5 31. g3 g5 32. Be3 Kd6 33. h4 c5+ 34. bxc5+ bxc5+ 35. Kd3 gxh4 36. gxh4 c4+ 37. Kd4 c5# 1-0 1-0 1-0 1-0",
          "neutral_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Bg5",
            "Be7",
            "Nc3",
            "O-O",
            "Re1",
            "Be6",
            "Ne4",
            "Nxe4",
            "Bxe7",
            "Nd2+",
            "Ke2",
            "Nxf3",
            "Kxf3",
            "Rfe8",
            "Bb4",
            "Bd5+",
            "Kg3",
            "b6",
            "Rxe8+",
            "Rxe8",
            "Re1",
            "Rxe1",
            "Bxe1",
            "Bxa2",
            "b3",
            "Bb1",
            "c3",
            "Bxd3",
            "Kf4",
            "f6",
            "Ke3",
            "Bf5",
            "Kd4",
            "Kf7",
            "Bd2",
            "Ke6",
            "Bf4",
            "Kd7",
            "h3",
            "Be6",
            "b4",
            "Bd5",
            "g3",
            "g5",
            "Be3",
            "Kd6",
            "h4",
            "c5+",
            "bxc5+",
            "bxc5+",
            "Kd3",
            "gxh4",
            "gxh4",
            "c4+",
            "Kd4",
            "c5#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1f3",
          "positional_uci": "d1f3",
          "neutral_uci": "d1f3",
          "consensus_move": "d1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Bg5",
              "Be7",
              "Nc3",
              "O-O",
              "Re1",
              "Be6",
              "Ne4",
              "Nxe4",
              "Bxe7",
              "Nd2+",
              "Ke2",
              "Nxf3",
              "Kxf3",
              "Rfe8",
              "Bb4",
              "Bd5+",
              "Kg3",
              "b6",
              "Rxe8+",
              "Rxe8",
              "Re1",
              "Rxe1",
              "Bxe1",
              "Bxa2",
              "b3",
              "Bb1",
              "c3",
              "Bxd3",
              "Kf4",
              "f6",
              "Ke3",
              "Bc2",
              "b4",
              "Kf7",
              "Kd4",
              "Ke6",
              "Bd2",
              "g5",
              "f4",
              "h6",
              "fxg5",
              "hxg5",
              "g3",
              "Kf5",
              "h4",
              "gxh4",
              "gxh4",
              "Kg4",
              "Be1",
              "f5",
              "Ke5",
              "f4",
              "Ke6",
              "f3",
              "Kd7",
              "Be4",
              "Kxc7",
              "b5",
              "Kb6",
              "Kh3",
              "Kxa6",
              "Kg2",
              "Kb6",
              "f2",
              "Bxf2",
              "Kxf2",
              "Kc5",
              "Ke3",
              "c4",
              "bxc4",
              "Kxc4",
              "Kf4",
              "Kc5",
              "Kg4",
              "b5",
              "cxb5",
              "Kxb5",
              "Kxh4",
              "Kc5",
              "Kg4",
              "Kd4",
              "Kf4",
              "Kc5",
              "Ke5",
              "Kc4",
              "Bd5+",
              "Kc5",
              "Be6",
              "Kc6",
              "Kd4",
              "Kd6",
              "Bf5",
              "Kc6",
              "Be4+",
              "Kd6",
              "Bd5",
              "Ke7",
              "Ke5",
              "Kd7",
              "Be6+",
              "Kc6",
              "Kd4",
              "Kd6",
              "Bf5",
              "Kc6",
              "Be4+",
              "Kd6",
              "Bf3",
              "Ke6",
              "Ke4",
              "Kd6",
              "Kf5",
              "Kc5",
              "Ke5",
              "Kc4",
              "Be4",
              "Kc5",
              "Bd5",
              "Kb4",
              "Kd4",
              "Kb5",
              "Bc4+",
              "Kc6",
              "Bd5+",
              "Kd6",
              "Be4",
              "Ke6",
              "Kc5",
              "Ke5",
              "Bd5",
              "Kf4",
              "Kd4",
              "Kf5",
              "Be4+",
              "Kf4",
              "Kd3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bg4",
              "Qxg4",
              "Nf6",
              "Qe2+",
              "Be7",
              "Bg5",
              "O-O-O",
              "Qxe7",
              "Rhe8",
              "Qxf7",
              "Rd7",
              "Qb3",
              "Rde7",
              "Nc3",
              "Re5",
              "Bxf6",
              "gxf6",
              "Ne4",
              "f5",
              "Nf6",
              "R8e6",
              "Nxh7",
              "Rb5",
              "Qxe6+",
              "Kb8",
              "b3",
              "Ka7",
              "c4",
              "Rb6",
              "Qxf5",
              "c5",
              "Qxc5",
              "a5",
              "Qxa5+",
              "Ra6",
              "Qxc7",
              "Rc6",
              "Qa5+",
              "Ra6",
              "Qc5+",
              "Rb6",
              "Re1",
              "Ka6",
              "Qa3#",
              "Qxa3",
              "Re8",
              "Qc1+",
              "Ke2",
              "Qxh1",
              "Ra8#",
              "Qxg2",
              "Nf8",
              "Qg4+",
              "f3",
              "Qg2+",
              "Ke3",
              "Qg1+",
              "Ke4",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3",
              "Qe1+",
              "Kd4",
              "Qf2+",
              "Kc3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Bg5",
              "Be7",
              "Nc3",
              "O-O",
              "Re1",
              "Be6",
              "Ne4",
              "Nxe4",
              "Bxe7",
              "Nd2+",
              "Ke2",
              "Nxf3",
              "Kxf3",
              "Rfe8",
              "Bb4",
              "Bd5+",
              "Kg3",
              "b6",
              "Rxe8+",
              "Rxe8",
              "Re1",
              "Rxe1",
              "Bxe1",
              "Bxa2",
              "b3",
              "Bb1",
              "c3",
              "Bxd3",
              "Kf4",
              "f6",
              "Ke3",
              "Bf5",
              "Kd4",
              "Kf7",
              "Bd2",
              "Ke6",
              "Bf4",
              "Kd7",
              "h3",
              "Be6",
              "b4",
              "Bd5",
              "g3",
              "g5",
              "Be3",
              "Kd6",
              "h4",
              "c5+",
              "bxc5+",
              "bxc5+",
              "Kd3",
              "gxh4",
              "gxh4",
              "c4+",
              "Kd4",
              "c5#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 533,
          "total_completion_tokens": 1920,
          "total_tokens": 2453
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/8/3P1q2/PPP2PPP/RNBQ1K1R w kq - 0 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc3",
          "aggressive_uci": "b1c3",
          "aggressive_response": "10. Nc3 O-O-O 11. Bf4 Nf6 12. Re1 Bb4 13. a3 Bxc3 14. bxc3 Bd5 15. Qg3 Nh5\n16. Qg4+ Be6 17. Qxh5 g6 18. Qe5 Rd7 19. Qxh8+ Rd8 20. Qe5 Rd7 21. Qh8+ Rd8\n22. Qe5 Rd7 23. Qh8+ Rd8 24. Qe5 Rd7 25. Qh8+ Rd8 26. Qe5 Rd7 27. Qh8+ Rd8\n28. Qe5 Rd7 29. Qh8+ Rd8 30. Qe5 Rd7 31. Qh8+ Rd8 32. Qe5 Rd7 33. Qh8+ Rd8\n34. Qe5 Rd7 35. Qh8+ Rd8 36. Qe5 Rd7 37. Qh8+ Rd8 38. Qe5 Rd7 39. Qh8+ Rd8\n40. Qe5 Rd7 41. Qh8+ Rd8 42. Qe5 Rd7 43. Qh8+ Rd8 44. Qe5 Rd7 45. Qh8+ Rd8\n46. Qe5 Rd7 47. Qh8+ Rd8 48. Qe5 Rd7 49. Qh8+ Rd8 50. Qe5 Rd7 51. Qh8+ Rd8\n52. Qe5 Rd7 53. Qh8+ Rd8 54. Qe5 Rd7 55. Qh8+ Rd8 56. Qe5 Rd7 57. Qh8+ Rd8\n58. Qe5 Rd7 59. Qh8+ Rd8 60. Qe5 Rd7 61. Qh8+ Rd8 62. Qe5 Rd7 63. Qh8+ Rd8\n64. Qe5 Rd7 65. Qh8+ Rd8 66. Qe5 Rd7 67. Qh8+ Rd8 68. Qe5 Rd7 69. Qh8+ Rd8\n70. Qe5 Rd7 71. Qh8+ Rd8 72. Qe5 Rd7 73. Qh8+ Rd8 74. Qe5 Rd7 75. Qh8+ Rd8\n76. Qe5 Rd7 77. Qh8+ Rd8 78. Qe5 Rd7 79. Qh8+ Rd8 80. Qe5 Rd7 81. Qh8+ Rd8\n82. Qe5 Rd7 83. Qh8+ Rd8 84. Qe5 Rd7 85",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O-O",
            "Bf4",
            "Nf6",
            "Re1",
            "Bb4",
            "a3",
            "Bxc3",
            "bxc3",
            "Bd5",
            "Qg3",
            "Nh5",
            "Qg4+",
            "Be6",
            "Qxh5",
            "g6",
            "Qe5",
            "Rd7",
            "Qxh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7",
            "Qh8+",
            "Rd8",
            "Qe5",
            "Rd7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc3",
          "positional_uci": "b1c3",
          "positional_response": "10. Nc3 O-O-O 11. Bf4 Nf6 12. Re1 Bb4 13. a3 Bxc3 14. bxc3 Bd5 15. Qg3 Nh5\n16. Qg4+ Kb8 17. Qxh5 g6 18. Qe5 Rhe8 19. Qxc7+ Ka8 20. Rxe8 Rxe8 21. f3 f6\n22. Kf2 g5 23. Be3 f5 24. Qb6 Kb8 25. Qa7+ Kc8 26. Bb6 Kd7 27. Qxb7+ Ke6\n28. Re1+ Kf6 29. Rxe8 Kg6 30. Qe7 Kh5 31. Qxh7# e4 dxe4 Qd4+ Kg5 Qf5# e4 dxe4 Qd4+ Kg5 Qf5# e4 dxe4 Qd4+ Kg5 Qf5#",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 230,
            "total_tokens": 416,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O-O",
            "Bf4",
            "Nf6",
            "Re1",
            "Bb4",
            "a3",
            "Bxc3",
            "bxc3",
            "Bd5",
            "Qg3",
            "Nh5",
            "Qg4+",
            "Kb8",
            "Qxh5",
            "g6",
            "Qe5",
            "Rhe8",
            "Qxc7+",
            "Ka8",
            "Rxe8",
            "Rxe8",
            "f3",
            "f6",
            "Kf2",
            "g5",
            "Be3",
            "f5",
            "Qb6",
            "Kb8",
            "Qa7+",
            "Kc8",
            "Bb6",
            "Kd7",
            "Qxb7+",
            "Ke6",
            "Re1+",
            "Kf6",
            "Rxe8",
            "Kg6",
            "Qe7",
            "Kh5",
            "Qxh7#",
            "e4",
            "dxe4",
            "Qd4+",
            "Kg5",
            "Qf5#",
            "e4",
            "dxe4",
            "Qd4+",
            "Kg5",
            "Qf5#",
            "e4",
            "dxe4",
            "Qd4+",
            "Kg5",
            "Qf5#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc3",
          "neutral_uci": "b1c3",
          "neutral_response": "10. Nc3 O-O-O 11. Bf4 Nf6 12. Re1 Bb4 13. a3 Bxc3 14. bxc3 Nd5 15. c4 Nxf4 16. Qxf4 Rhe8\n17. g3 Bh3+ 18. Kg1 Rxe1# 19. Qf1 Rxf1# 20. Kxf1 Re8 21. f3 Re3 22. Kf2 Re6 23. g4 h5\n24. Kg3 hxg4 25. fxg4 Re3+ 26. Kf4 Re2 27. Kg3 Bg2 28. Rg1 Rxc2 29. Rxg2 Rxg2+ 30. Kxg2 Kd7\n31. Kf3 Ke6 32. Ke4 c5 33. h4 b5 34. cxb5 axb5 35. d4 cxd4 36. Kxd4 Kd6 37. h5 c5+ 38. Kc3 Ke5\n39. g5 Kf5 40. h6 gxh6 41. gxh6 Kg6 42. Kd3 Kxh6 43. Ke4 Kg5 44. Kd5 c4 45. Kd4 f5 46. Kc3 f4\n47. Kb4 f3 48. Kxb5 c3 49. a4 c2 50. a5 c1=Q 51. a6 f2 52. a7 f1=Q+ 53. Kb6 Qf6+ 54. Kb7 Qcc6+ 55. Kb8 Qd8# 56. a8=Q Qdc7# 57. Qxc6 Qxc6 58. Ka7 Kf6 59. Kb8 Ke7 60. Ka7 Kd7 61. Kb8 Qb6+ 62. Ka8 Qb5 63. Ka7 Kc7 64. Ka8 Qb7# 65. Ka2 Kc6 66. Ka3 Kc5 67. Ka4 Qb4# 68. Ka3 Kc4# 69. Ka2 Kc3 70. Ka1 Qb2# 71. Ka2 Qb3+ 72. Ka1 Qb2# 73. Ka2 Qb3+ 74. Ka1 Qb2# 75. Ka2 Qb3+ 76. Ka1 Qb2# 77. Ka2 Qb3+ 78. Ka1 Qb2# 79. Ka2 Qb3+ 80. Ka1 Qb2# 81. Ka2 Qb3+ 82. Ka1 Qb2# 83. Ka2 Qb3+ 84. Ka1 Qb2# 85. Ka2",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O-O",
            "Bf4",
            "Nf6",
            "Re1",
            "Bb4",
            "a3",
            "Bxc3",
            "bxc3",
            "Nd5",
            "c4",
            "Nxf4",
            "Qxf4",
            "Rhe8",
            "g3",
            "Bh3+",
            "Kg1",
            "Rxe1#",
            "Qf1",
            "Rxf1#",
            "Kxf1",
            "Re8",
            "f3",
            "Re3",
            "Kf2",
            "Re6",
            "g4",
            "h5",
            "Kg3",
            "hxg4",
            "fxg4",
            "Re3+",
            "Kf4",
            "Re2",
            "Kg3",
            "Bg2",
            "Rg1",
            "Rxc2",
            "Rxg2",
            "Rxg2+",
            "Kxg2",
            "Kd7",
            "Kf3",
            "Ke6",
            "Ke4",
            "c5",
            "h4",
            "b5",
            "cxb5",
            "axb5",
            "d4",
            "cxd4",
            "Kxd4",
            "Kd6",
            "h5",
            "c5+",
            "Kc3",
            "Ke5",
            "g5",
            "Kf5",
            "h6",
            "gxh6",
            "gxh6",
            "Kg6",
            "Kd3",
            "Kxh6",
            "Ke4",
            "Kg5",
            "Kd5",
            "c4",
            "Kd4",
            "f5",
            "Kc3",
            "f4",
            "Kb4",
            "f3",
            "Kxb5",
            "c3",
            "a4",
            "c2",
            "a5",
            "c1=Q",
            "a6",
            "f2",
            "a7",
            "f1=Q+",
            "Kb6",
            "Qf6+",
            "Kb7",
            "Qcc6+",
            "Kb8",
            "Qd8#",
            "a8=Q",
            "Qdc7#",
            "Qxc6",
            "Qxc6",
            "Ka7",
            "Kf6",
            "Kb8",
            "Ke7",
            "Ka7",
            "Kd7",
            "Kb8",
            "Qb6+",
            "Ka8",
            "Qb5",
            "Ka7",
            "Kc7",
            "Ka8",
            "Qb7#",
            "Ka2",
            "Kc6",
            "Ka3",
            "Kc5",
            "Ka4",
            "Qb4#",
            "Ka3",
            "Kc4#",
            "Ka2",
            "Kc3",
            "Ka1",
            "Qb2#",
            "Ka2",
            "Qb3+",
            "Ka1",
            "Qb2#",
            "Ka2",
            "Qb3+",
            "Ka1",
            "Qb2#",
            "Ka2",
            "Qb3+",
            "Ka1",
            "Qb2#",
            "Ka2",
            "Qb3+",
            "Ka1",
            "Qb2#",
            "Ka2",
            "Qb3+",
            "Ka1",
            "Qb2#",
            "Ka2",
            "Qb3+",
            "Ka1",
            "Qb2#",
            "Ka2",
            "Qb3+",
            "Ka1",
            "Qb2#",
            "Ka2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b1c3",
          "positional_uci": "b1c3",
          "neutral_uci": "b1c3",
          "consensus_move": "b1c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O-O",
              "Bf4",
              "Nf6",
              "Re1",
              "Bb4",
              "a3",
              "Bxc3",
              "bxc3",
              "Bd5",
              "Qg3",
              "Nh5",
              "Qg4+",
              "Be6",
              "Qxh5",
              "g6",
              "Qe5",
              "Rd7",
              "Qxh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7",
              "Qh8+",
              "Rd8",
              "Qe5",
              "Rd7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O-O",
              "Bf4",
              "Nf6",
              "Re1",
              "Bb4",
              "a3",
              "Bxc3",
              "bxc3",
              "Bd5",
              "Qg3",
              "Nh5",
              "Qg4+",
              "Kb8",
              "Qxh5",
              "g6",
              "Qe5",
              "Rhe8",
              "Qxc7+",
              "Ka8",
              "Rxe8",
              "Rxe8",
              "f3",
              "f6",
              "Kf2",
              "g5",
              "Be3",
              "f5",
              "Qb6",
              "Kb8",
              "Qa7+",
              "Kc8",
              "Bb6",
              "Kd7",
              "Qxb7+",
              "Ke6",
              "Re1+",
              "Kf6",
              "Rxe8",
              "Kg6",
              "Qe7",
              "Kh5",
              "Qxh7#",
              "e4",
              "dxe4",
              "Qd4+",
              "Kg5",
              "Qf5#",
              "e4",
              "dxe4",
              "Qd4+",
              "Kg5",
              "Qf5#",
              "e4",
              "dxe4",
              "Qd4+",
              "Kg5",
              "Qf5#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O-O",
              "Bf4",
              "Nf6",
              "Re1",
              "Bb4",
              "a3",
              "Bxc3",
              "bxc3",
              "Nd5",
              "c4",
              "Nxf4",
              "Qxf4",
              "Rhe8",
              "g3",
              "Bh3+",
              "Kg1",
              "Rxe1#",
              "Qf1",
              "Rxf1#",
              "Kxf1",
              "Re8",
              "f3",
              "Re3",
              "Kf2",
              "Re6",
              "g4",
              "h5",
              "Kg3",
              "hxg4",
              "fxg4",
              "Re3+",
              "Kf4",
              "Re2",
              "Kg3",
              "Bg2",
              "Rg1",
              "Rxc2",
              "Rxg2",
              "Rxg2+",
              "Kxg2",
              "Kd7",
              "Kf3",
              "Ke6",
              "Ke4",
              "c5",
              "h4",
              "b5",
              "cxb5",
              "axb5",
              "d4",
              "cxd4",
              "Kxd4",
              "Kd6",
              "h5",
              "c5+",
              "Kc3",
              "Ke5",
              "g5",
              "Kf5",
              "h6",
              "gxh6",
              "gxh6",
              "Kg6",
              "Kd3",
              "Kxh6",
              "Ke4",
              "Kg5",
              "Kd5",
              "c4",
              "Kd4",
              "f5",
              "Kc3",
              "f4",
              "Kb4",
              "f3",
              "Kxb5",
              "c3",
              "a4",
              "c2",
              "a5",
              "c1=Q",
              "a6",
              "f2",
              "a7",
              "f1=Q+",
              "Kb6",
              "Qf6+",
              "Kb7",
              "Qcc6+",
              "Kb8",
              "Qd8#",
              "a8=Q",
              "Qdc7#",
              "Qxc6",
              "Qxc6",
              "Ka7",
              "Kf6",
              "Kb8",
              "Ke7",
              "Ka7",
              "Kd7",
              "Kb8",
              "Qb6+",
              "Ka8",
              "Qb5",
              "Ka7",
              "Kc7",
              "Ka8",
              "Qb7#",
              "Ka2",
              "Kc6",
              "Ka3",
              "Kc5",
              "Ka4",
              "Qb4#",
              "Ka3",
              "Kc4#",
              "Ka2",
              "Kc3",
              "Ka1",
              "Qb2#",
              "Ka2",
              "Qb3+",
              "Ka1",
              "Qb2#",
              "Ka2",
              "Qb3+",
              "Ka1",
              "Qb2#",
              "Ka2",
              "Qb3+",
              "Ka1",
              "Qb2#",
              "Ka2",
              "Qb3+",
              "Ka1",
              "Qb2#",
              "Ka2",
              "Qb3+",
              "Ka1",
              "Qb2#",
              "Ka2",
              "Qb3+",
              "Ka1",
              "Qb2#",
              "Ka2",
              "Qb3+",
              "Ka1",
              "Qb2#",
              "Ka2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 230,
            "total_tokens": 416,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 1510,
          "total_tokens": 2067
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 640,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 230,
            "total_tokens": 416,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 640,
            "total_tokens": 825,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r3kbnr/1pp2ppp/p1p1b3/8/8/3P1Q2/PPP2PPP/RNB2K1R w kq - 1 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": "c1g5",
          "aggressive_response": "11. Bg5 f6 12. Bf4 g5 13. Bg3 h5 14. h3 g4 15. hxg4 hxg4 16. Qe4 Rxh1+ 17. Ke2 Rxa1\n18. Qxe6+ Kb8 19. Qxg4 Re8+ 20. Kd2 Bh6+ 21. f4 Rg1 22. Qf3 Ne7 23. Ne2 Ra1 24. a3 Nd5\n25. c4 Ne3 26. Kc3 f5 27. Kb3 Bg7 28. Bf2 Rb1 29. Nc3 Bxc3 30. Kxc3 Nd1+ 31. Kc2 Rxb2+\n32. Kxd1 Ree2 33. Qxe2 Rxe2 34. Kxe2 b5 35. cxb5 cxb5 36. Kd2 Kb7 37. Kc3 Kc6 38. Kb4 Kd5\n39. Ka5 c5 40. Kxa6 b4 41. axb4 cxb4 42. Be1 b3 43. Bc3 Kc5 44. Ka5 Kd5 45. Kb4 b2\n46. Bxb2 Kc6 47. Kc4 Kd6 48. Be5+ Ke6 49. Kc5 Kd7 50. Kd5 Ke7 51. Bd6+ Kf6 52. d4 Kf7\n53. Ke5 Kg6 54. Be7 Kf7 55. Bg5 Kg6 56. d5 Kf7 57. Kxf5 Ke8 58. Ke6 Kf8 59. d6 Ke8\n60. d7+ Kf8 61. d8=Q+ Kg7 62. Qf6+ Kh7 63. Qh6+ Kg8 64. Qg6+ Kh8 65. Bf6# e4 Nf3 Nxf3",
          "aggressive_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 465,
            "total_tokens": 660,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg6",
            "d5",
            "Kf7",
            "Kxf5",
            "Ke8",
            "Ke6",
            "Kf8",
            "d6",
            "Ke8",
            "d7+",
            "Kf8",
            "d8=Q+",
            "Kg7",
            "Qf6+",
            "Kh7",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Bf6#",
            "e4",
            "Nf3",
            "Nxf3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "11. Bg5 f6 12. Bf4 g5 13. Bg3 h5 14. h3 g4 15. hxg4 hxg4 16. Qe4 Rxh1+ 17. Ke2 Rxa1\n18. Qxe6+ Kb8 19. Qxg8 Re8+ 20. Kd2 Bh6+ 21. f4 gxf3+ 22. Bf4 Bxf4# Bb4+ c6",
          "positional_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 111,
            "total_tokens": 306,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "f6",
            "Bf4",
            "g5",
            "Bg3",
            "h5",
            "h3",
            "g4",
            "hxg4",
            "hxg4",
            "Qe4",
            "Rxh1+",
            "Ke2",
            "Rxa1",
            "Qxe6+",
            "Kb8",
            "Qxg8",
            "Re8+",
            "Kd2",
            "Bh6+",
            "f4",
            "gxf3+",
            "Bf4",
            "Bxf4#",
            "Bb4+",
            "c6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bf4",
          "neutral_uci": "c1f4",
          "neutral_response": "11. Bf4 Nf6 12. Re1 Bb4 13. a3 Bxc3 14. bxc3 Nd5 15. c4 Nxf4 16. Qxf4 Rhe8\n17. f3 h6 18. Kf2 g5 19. Qf6 Rd6 20. Qxh6 g4 21. Qf4 gxf3 22. gxf3 Red8\n23. Rhg1 Rd4 24. Qf6 R4d6 25. Rg7 Bxc4 26. Qf5+ Be6 27. Qf4 Rd4 28. Qe3 Rh4\n29. Kg3 Rh3+ 30. Kg2 Rdh8 31. Rh1 Bd5 32. Rg3 R3h6 33. c4 Be6 34. Qe5 Rd8\n35. Rd1 Bxc4 36. dxc4 Rxd1 37. Rg8+ Rd8 38. Qf5+ Re6 39. Rxd8+ Kxd8 40. Qxf7 Re7\n41. Qf8+ Kd7 42. Qf5+ Kd8 43. h4 b5 44. cxb5 cxb5 45. h5 c5 46. Qxc5 Rg7+\n47. Kh3 Rc7 48. Qd6+ Rd7 49. Qxa6 Ke7 50. Qxb5 Rd6 51. Qc5 Ke6 52. Qxd6+ Kxd6\n53. h6 Ke6 54. h7 Kf7 55. h8=Q Ke6 56. Qh5 Kd6 57. Qf5 Kc6 58. Qe5 Kb6\n59. Qd5 Ka6 60. Qc5 Kb7 61. Qd6 Ka7 62. Qc6 Kb8 63. Qd7 Ka8 64. Kg4 Kb8\n65. Kf5 Ka8 66. Ke6 Kb8 67. Kd6 Ka8 68. Kc6 Kb8 69. Qb7# e4 d4 Qh5",
          "neutral_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 496,
            "total_tokens": 690,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Re1",
            "Bb4",
            "a3",
            "Bxc3",
            "bxc3",
            "Nd5",
            "c4",
            "Nxf4",
            "Qxf4",
            "Rhe8",
            "f3",
            "h6",
            "Kf2",
            "g5",
            "Qf6",
            "Rd6",
            "Qxh6",
            "g4",
            "Qf4",
            "gxf3",
            "gxf3",
            "Red8",
            "Rhg1",
            "Rd4",
            "Qf6",
            "R4d6",
            "Rg7",
            "Bxc4",
            "Qf5+",
            "Be6",
            "Qf4",
            "Rd4",
            "Qe3",
            "Rh4",
            "Kg3",
            "Rh3+",
            "Kg2",
            "Rdh8",
            "Rh1",
            "Bd5",
            "Rg3",
            "R3h6",
            "c4",
            "Be6",
            "Qe5",
            "Rd8",
            "Rd1",
            "Bxc4",
            "dxc4",
            "Rxd1",
            "Rg8+",
            "Rd8",
            "Qf5+",
            "Re6",
            "Rxd8+",
            "Kxd8",
            "Qxf7",
            "Re7",
            "Qf8+",
            "Kd7",
            "Qf5+",
            "Kd8",
            "h4",
            "b5",
            "cxb5",
            "cxb5",
            "h5",
            "c5",
            "Qxc5",
            "Rg7+",
            "Kh3",
            "Rc7",
            "Qd6+",
            "Rd7",
            "Qxa6",
            "Ke7",
            "Qxb5",
            "Rd6",
            "Qc5",
            "Ke6",
            "Qxd6+",
            "Kxd6",
            "h6",
            "Ke6",
            "h7",
            "Kf7",
            "h8=Q",
            "Ke6",
            "Qh5",
            "Kd6",
            "Qf5",
            "Kc6",
            "Qe5",
            "Kb6",
            "Qd5",
            "Ka6",
            "Qc5",
            "Kb7",
            "Qd6",
            "Ka7",
            "Qc6",
            "Kb8",
            "Qd7",
            "Ka8",
            "Kg4",
            "Kb8",
            "Kf5",
            "Ka8",
            "Ke6",
            "Kb8",
            "Kd6",
            "Ka8",
            "Kc6",
            "Kb8",
            "Qb7#",
            "e4",
            "d4",
            "Qh5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1g5",
          "positional_uci": "c1g5",
          "neutral_uci": "c1f4",
          "consensus_move": "c1g5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg6",
              "d5",
              "Kf7",
              "Kxf5",
              "Ke8",
              "Ke6",
              "Kf8",
              "d6",
              "Ke8",
              "d7+",
              "Kf8",
              "d8=Q+",
              "Kg7",
              "Qf6+",
              "Kh7",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Bf6#",
              "e4",
              "Nf3",
              "Nxf3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "f6",
              "Bf4",
              "g5",
              "Bg3",
              "h5",
              "h3",
              "g4",
              "hxg4",
              "hxg4",
              "Qe4",
              "Rxh1+",
              "Ke2",
              "Rxa1",
              "Qxe6+",
              "Kb8",
              "Qxg8",
              "Re8+",
              "Kd2",
              "Bh6+",
              "f4",
              "gxf3+",
              "Bf4",
              "Bxf4#",
              "Bb4+",
              "c6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Re1",
              "Bb4",
              "a3",
              "Bxc3",
              "bxc3",
              "Nd5",
              "c4",
              "Nxf4",
              "Qxf4",
              "Rhe8",
              "f3",
              "h6",
              "Kf2",
              "g5",
              "Qf6",
              "Rd6",
              "Qxh6",
              "g4",
              "Qf4",
              "gxf3",
              "gxf3",
              "Red8",
              "Rhg1",
              "Rd4",
              "Qf6",
              "R4d6",
              "Rg7",
              "Bxc4",
              "Qf5+",
              "Be6",
              "Qf4",
              "Rd4",
              "Qe3",
              "Rh4",
              "Kg3",
              "Rh3+",
              "Kg2",
              "Rdh8",
              "Rh1",
              "Bd5",
              "Rg3",
              "R3h6",
              "c4",
              "Be6",
              "Qe5",
              "Rd8",
              "Rd1",
              "Bxc4",
              "dxc4",
              "Rxd1",
              "Rg8+",
              "Rd8",
              "Qf5+",
              "Re6",
              "Rxd8+",
              "Kxd8",
              "Qxf7",
              "Re7",
              "Qf8+",
              "Kd7",
              "Qf5+",
              "Kd8",
              "h4",
              "b5",
              "cxb5",
              "cxb5",
              "h5",
              "c5",
              "Qxc5",
              "Rg7+",
              "Kh3",
              "Rc7",
              "Qd6+",
              "Rd7",
              "Qxa6",
              "Ke7",
              "Qxb5",
              "Rd6",
              "Qc5",
              "Ke6",
              "Qxd6+",
              "Kxd6",
              "h6",
              "Ke6",
              "h7",
              "Kf7",
              "h8=Q",
              "Ke6",
              "Qh5",
              "Kd6",
              "Qf5",
              "Kc6",
              "Qe5",
              "Kb6",
              "Qd5",
              "Ka6",
              "Qc5",
              "Kb7",
              "Qd6",
              "Ka7",
              "Qc6",
              "Kb8",
              "Qd7",
              "Ka8",
              "Kg4",
              "Kb8",
              "Kf5",
              "Ka8",
              "Ke6",
              "Kb8",
              "Kd6",
              "Ka8",
              "Kc6",
              "Kb8",
              "Qb7#",
              "e4",
              "d4",
              "Qh5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 195,
            "completion_tokens": 465,
            "total_tokens": 660,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 195,
            "completion_tokens": 111,
            "total_tokens": 306,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 194,
            "completion_tokens": 496,
            "total_tokens": 690,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 584,
          "total_completion_tokens": 1072,
          "total_tokens": 1656
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 195,
            "completion_tokens": 465,
            "total_tokens": 660,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 195,
            "completion_tokens": 111,
            "total_tokens": 306,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 194,
            "completion_tokens": 496,
            "total_tokens": 690,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2kr1bnr/1pp2ppp/p1p1b3/8/8/2NP1Q2/PPP2PPP/R1B2K1R w - - 3 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re1",
          "aggressive_uci": "a1e1",
          "aggressive_response": "12. Re1 Bd7 13. Bf4 g5 14. Bg3 h5 15. h4 g4 16. Qf4 Bd6 17. Qd4 Bxg3 18. fxg3 Nh6\n19. Qa7 Bf5 20. Re7 Bxd3+ 21. cxd3 Rxd3 22. Qa8# Bxa8 Nf5",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 96,
            "total_tokens": 299,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd7",
            "Bf4",
            "g5",
            "Bg3",
            "h5",
            "h4",
            "g4",
            "Qf4",
            "Bd6",
            "Qd4",
            "Bxg3",
            "fxg3",
            "Nh6",
            "Qa7",
            "Bf5",
            "Re7",
            "Bxd3+",
            "cxd3",
            "Rxd3",
            "Qa8#",
            "Bxa8",
            "Nf5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re1",
          "positional_uci": "a1e1",
          "positional_response": "12. Re1 Bd7 13. Bf4 g5 14. Bg3 h5 15. h4 g4 16. Qf4 Bd6 17. Qd4 Bxg3 18. fxg3 Kb8 19. Ne4 Rh6 20. Nc5 Kc8 21. Nxd7 Rxd7 22. Re8+ Rd8 23. Qxd8# Bb5 Nf6 Bxd6#",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 106,
            "total_tokens": 309,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd7",
            "Bf4",
            "g5",
            "Bg3",
            "h5",
            "h4",
            "g4",
            "Qf4",
            "Bd6",
            "Qd4",
            "Bxg3",
            "fxg3",
            "Kb8",
            "Ne4",
            "Rh6",
            "Nc5",
            "Kc8",
            "Nxd7",
            "Rxd7",
            "Re8+",
            "Rd8",
            "Qxd8#",
            "Bb5",
            "Nf6",
            "Bxd6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bf4",
          "neutral_uci": "g5f4",
          "neutral_response": "12. Bf4 g5 13. Bg3 h5 14. h4 g4 15. Qe3 Re8 16. Qa7 Bd6 17. Bxd6 cxd6 18. Ne4 Kc7\n19. Re1 Nh6 20. Nxf6 Re7 21. Qd4 Nf5 22. Qc3 Rf8 23. Nd5+ Bxd5 24. Rxe7+ Nxe7 25. Qg7 Rf7\n26. Qg5 Nf5 27. Qxh5 Ng3+ 28. Kg1 Nxh5 29. Kh2 Rxf2 30. Rg1 g3+ 31. Kh3 Be6# g4 Nf4#",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 175,
            "total_tokens": 377,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Bg3",
            "h5",
            "h4",
            "g4",
            "Qe3",
            "Re8",
            "Qa7",
            "Bd6",
            "Bxd6",
            "cxd6",
            "Ne4",
            "Kc7",
            "Re1",
            "Nh6",
            "Nxf6",
            "Re7",
            "Qd4",
            "Nf5",
            "Qc3",
            "Rf8",
            "Nd5+",
            "Bxd5",
            "Rxe7+",
            "Nxe7",
            "Qg7",
            "Rf7",
            "Qg5",
            "Nf5",
            "Qxh5",
            "Ng3+",
            "Kg1",
            "Nxh5",
            "Kh2",
            "Rxf2",
            "Rg1",
            "g3+",
            "Kh3",
            "Be6#",
            "g4",
            "Nf4#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a1e1",
          "positional_uci": "a1e1",
          "neutral_uci": "g5f4",
          "consensus_move": "a1e1",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd7",
              "Bf4",
              "g5",
              "Bg3",
              "h5",
              "h4",
              "g4",
              "Qf4",
              "Bd6",
              "Qd4",
              "Bxg3",
              "fxg3",
              "Nh6",
              "Qa7",
              "Bf5",
              "Re7",
              "Bxd3+",
              "cxd3",
              "Rxd3",
              "Qa8#",
              "Bxa8",
              "Nf5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd7",
              "Bf4",
              "g5",
              "Bg3",
              "h5",
              "h4",
              "g4",
              "Qf4",
              "Bd6",
              "Qd4",
              "Bxg3",
              "fxg3",
              "Kb8",
              "Ne4",
              "Rh6",
              "Nc5",
              "Kc8",
              "Nxd7",
              "Rxd7",
              "Re8+",
              "Rd8",
              "Qxd8#",
              "Bb5",
              "Nf6",
              "Bxd6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "g5",
              "Bg3",
              "h5",
              "h4",
              "g4",
              "Qe3",
              "Re8",
              "Qa7",
              "Bd6",
              "Bxd6",
              "cxd6",
              "Ne4",
              "Kc7",
              "Re1",
              "Nh6",
              "Nxf6",
              "Re7",
              "Qd4",
              "Nf5",
              "Qc3",
              "Rf8",
              "Nd5+",
              "Bxd5",
              "Rxe7+",
              "Nxe7",
              "Qg7",
              "Rf7",
              "Qg5",
              "Nf5",
              "Qxh5",
              "Ng3+",
              "Kg1",
              "Nxh5",
              "Kh2",
              "Rxf2",
              "Rg1",
              "g3+",
              "Kh3",
              "Be6#",
              "g4",
              "Nf4#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 96,
            "total_tokens": 299,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 106,
            "total_tokens": 309,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 175,
            "total_tokens": 377,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 377,
          "total_tokens": 985
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 96,
            "total_tokens": 299,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 106,
            "total_tokens": 309,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 175,
            "total_tokens": 377,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2kr1bnr/1pp3pp/p1p1bp2/6B1/8/2NP1Q2/PPP2PPP/R4K1R w - - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxg4+",
          "aggressive_uci": "f3g4",
          "aggressive_response": "13. Qxg4+ Kb8 14. Bf4 Bd6 15. Bxd6 Rxd6 16. Qxg7 Ne7 17. Qxh8+ Ka7 18. Rxe7 Rd8 19. Qxd8 Kb6 20. Qxc7+ Kc5 21. Qxb7 Kd4 22. Qxc6 f5 23. Qd5# Qxd5 24. Nxd5 Kxd5 25. Rxh7 Ke5 26. Ra7 Kf6 27. Rxa6+ Kg5 28. Ra5 Kf4 29. Rxf5+ Kxf5 30. h4 Kg4 31. h5 Kg5 32. h6 Kg6 33. h7 Kg7 34. h8=Q+ Kg6 35. Rh5 Kf7 36. Qh6 Ke7 37. Rg5 Kf7 38. Rg7+ Kf8 39. Qh8# Qxh8 40. Rxh8+ Kg7 41. Rh5 Kg6 42. g4 Kf6 43. a4 Kg6 44. a5 Kf6 45. a6 Kg6 46. a7 Kf6 47. a8=Q Kg6 48. Qa6+ Kf7 49. Rh7+ Kg8 50. Rb7 Kf8 51. Qa8# Qxa8 52. Rb8+ Qxb8 53. Nxb8 Ke7 54. g5 Kd6 55. g6 Ke6 56. g7 Kf7 57. g8=Q+ Kxg8 58. c4 Kf7 59. c5 Ke7 60. c6 Kd8 61. f4 Kc7 62. f5 Kxb8 63. f6 Kc7 64. f7 Kxc6 65. f8=Q Kd5 66. Qf4 Kc5 67. Qe4 Kd6 68. Qf5 Kc6 69. Qe5 Kd7 70. Qf6 Kc7 71. Qe6 Kb7 72. Qd6 Ka7 73. Qc6 Kb8 74. Qd7 Ka8 75. Ke2 Kb8 76. Kd3 Ka8 77. Kc4 Kb8 78. Kb5 Ka8 79. Kb6 Kb8 80. Qb7# Qxb7+ 81. Kc5 Qxb2 82. d4 Qxf2 83. Kd5 Qxd4+ 84. Kxd4 *",
          "aggressive_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 613,
            "total_tokens": 824,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kb8",
            "Bf4",
            "Bd6",
            "Bxd6",
            "Rxd6",
            "Qxg7",
            "Ne7",
            "Qxh8+",
            "Ka7",
            "Rxe7",
            "Rd8",
            "Qxd8",
            "Kb6",
            "Qxc7+",
            "Kc5",
            "Qxb7",
            "Kd4",
            "Qxc6",
            "f5",
            "Qd5#",
            "Qxd5",
            "Nxd5",
            "Kxd5",
            "Rxh7",
            "Ke5",
            "Ra7",
            "Kf6",
            "Rxa6+",
            "Kg5",
            "Ra5",
            "Kf4",
            "Rxf5+",
            "Kxf5",
            "h4",
            "Kg4",
            "h5",
            "Kg5",
            "h6",
            "Kg6",
            "h7",
            "Kg7",
            "h8=Q+",
            "Kg6",
            "Rh5",
            "Kf7",
            "Qh6",
            "Ke7",
            "Rg5",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Qh8#",
            "Qxh8",
            "Rxh8+",
            "Kg7",
            "Rh5",
            "Kg6",
            "g4",
            "Kf6",
            "a4",
            "Kg6",
            "a5",
            "Kf6",
            "a6",
            "Kg6",
            "a7",
            "Kf6",
            "a8=Q",
            "Kg6",
            "Qa6+",
            "Kf7",
            "Rh7+",
            "Kg8",
            "Rb7",
            "Kf8",
            "Qa8#",
            "Qxa8",
            "Rb8+",
            "Qxb8",
            "Nxb8",
            "Ke7",
            "g5",
            "Kd6",
            "g6",
            "Ke6",
            "g7",
            "Kf7",
            "g8=Q+",
            "Kxg8",
            "c4",
            "Kf7",
            "c5",
            "Ke7",
            "c6",
            "Kd8",
            "f4",
            "Kc7",
            "f5",
            "Kxb8",
            "f6",
            "Kc7",
            "f7",
            "Kxc6",
            "f8=Q",
            "Kd5",
            "Qf4",
            "Kc5",
            "Qe4",
            "Kd6",
            "Qf5",
            "Kc6",
            "Qe5",
            "Kd7",
            "Qf6",
            "Kc7",
            "Qe6",
            "Kb7",
            "Qd6",
            "Ka7",
            "Qc6",
            "Kb8",
            "Qd7",
            "Ka8",
            "Ke2",
            "Kb8",
            "Kd3",
            "Ka8",
            "Kc4",
            "Kb8",
            "Kb5",
            "Ka8",
            "Kb6",
            "Kb8",
            "Qb7#",
            "Qxb7+",
            "Kc5",
            "Qxb2",
            "d4",
            "Qxf2",
            "Kd5",
            "Qxd4+",
            "Kxd4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxg4+",
          "positional_uci": "f3g4",
          "positional_response": "13. Qxg4+ Kb8 14. Be3 h5 15. Qg6 Ne7 16. Qf7 Nf5 17. Bf4 Bd6 18. Bxd6 Nxd6 19. Qxg7 Rhg8 20. Qxf6 Rdf8 21. Qh4 Nf5 22. Qxh5 Rh8 23. Qg4 Rhg8 24. Qe4 Nd6 25. Qe7 Re8 26. Qh4 Ref8 27. Re7 Nf5 28. Qh7 Nxe7 29. Qxe7 Re8 30. Qh4 Rh8 31. Qg3 Rhg8 32. Qf3 Rgf8 33. Qd1 Re7 34. h4 Ref7 35. Ne4 Rf4 36. h5 Rh8 37. h6 Rf7 38. Qh5 Rfh7 39. Qg6 Ka7 40. Nf6 Re7 41. h7 Re6 42. Qg7 Rd8 43. h8=Q Rxh8 44. Rxh8 Rd6 45. Qxc7 Rxf6 46. Rh7 Rxf2+ 47. Kxf2 a5 48. Qxb7# e4 Nf3 gxf3",
          "positional_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 310,
            "total_tokens": 521,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kb8",
            "Be3",
            "h5",
            "Qg6",
            "Ne7",
            "Qf7",
            "Nf5",
            "Bf4",
            "Bd6",
            "Bxd6",
            "Nxd6",
            "Qxg7",
            "Rhg8",
            "Qxf6",
            "Rdf8",
            "Qh4",
            "Nf5",
            "Qxh5",
            "Rh8",
            "Qg4",
            "Rhg8",
            "Qe4",
            "Nd6",
            "Qe7",
            "Re8",
            "Qh4",
            "Ref8",
            "Re7",
            "Nf5",
            "Qh7",
            "Nxe7",
            "Qxe7",
            "Re8",
            "Qh4",
            "Rh8",
            "Qg3",
            "Rhg8",
            "Qf3",
            "Rgf8",
            "Qd1",
            "Re7",
            "h4",
            "Ref7",
            "Ne4",
            "Rf4",
            "h5",
            "Rh8",
            "h6",
            "Rf7",
            "Qh5",
            "Rfh7",
            "Qg6",
            "Ka7",
            "Nf6",
            "Re7",
            "h7",
            "Re6",
            "Qg7",
            "Rd8",
            "h8=Q",
            "Rxh8",
            "Rxh8",
            "Rd6",
            "Qxc7",
            "Rxf6",
            "Rh7",
            "Rxf2+",
            "Kxf2",
            "a5",
            "Qxb7#",
            "e4",
            "Nf3",
            "gxf3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxg4+",
          "neutral_uci": "f3g4",
          "neutral_response": "13. Qxg4+ Kb8 14. Bf4 g5 15. Bg3 h5 16. Qe6 h4 17. Qf7 hxg3 18. Re8 Rxe8\n19. Qxe8+ Ka7 20. Qxf8 gxf2 21. Qg7 Rh4 22. Qxg8 Rf4 23. Qf7 Kb6 24. Ne4 c5\n25. Nxf6 c6 26. Nd7+ Kb5 27. Qb3+ Ka5 28. Qb6+ Ka4 29. Nxc5# 1-0\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Bf4 g5 15. Bg3 h5 16. Qe6 h4 17. Qf7 hxg3 18. Re8 Rxe8 19. Qxe8+ Ka7 20. Qxf8 gxf2 21. Qg7 Rh4 22. Qxg8 Rf4 23. Qf7 Kb6 24. Ne4 c5 25. Nxf6 c6 26. Nd7+ Kb5 27. Qb3+ Ka5 28. Qb6+ Ka4 29. Nxc5# 1-0",
          "neutral_tokens": {
            "prompt_tokens": 210,
            "completion_tokens": 335,
            "total_tokens": 545,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kb8",
            "Bf4",
            "g5",
            "Bg3",
            "h5",
            "Qe6",
            "h4",
            "Qf7",
            "hxg3",
            "Re8",
            "Rxe8",
            "Qxe8+",
            "Ka7",
            "Qxf8",
            "gxf2",
            "Qg7",
            "Rh4",
            "Qxg8",
            "Rf4",
            "Qf7",
            "Kb6",
            "Ne4",
            "c5",
            "Nxf6",
            "c6",
            "Nd7+",
            "Kb5",
            "Qb3+",
            "Ka5",
            "Qb6+",
            "Ka4",
            "Nxc5#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3g4",
          "positional_uci": "f3g4",
          "neutral_uci": "f3g4",
          "consensus_move": "f3g4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kb8",
              "Bf4",
              "Bd6",
              "Bxd6",
              "Rxd6",
              "Qxg7",
              "Ne7",
              "Qxh8+",
              "Ka7",
              "Rxe7",
              "Rd8",
              "Qxd8",
              "Kb6",
              "Qxc7+",
              "Kc5",
              "Qxb7",
              "Kd4",
              "Qxc6",
              "f5",
              "Qd5#",
              "Qxd5",
              "Nxd5",
              "Kxd5",
              "Rxh7",
              "Ke5",
              "Ra7",
              "Kf6",
              "Rxa6+",
              "Kg5",
              "Ra5",
              "Kf4",
              "Rxf5+",
              "Kxf5",
              "h4",
              "Kg4",
              "h5",
              "Kg5",
              "h6",
              "Kg6",
              "h7",
              "Kg7",
              "h8=Q+",
              "Kg6",
              "Rh5",
              "Kf7",
              "Qh6",
              "Ke7",
              "Rg5",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Qh8#",
              "Qxh8",
              "Rxh8+",
              "Kg7",
              "Rh5",
              "Kg6",
              "g4",
              "Kf6",
              "a4",
              "Kg6",
              "a5",
              "Kf6",
              "a6",
              "Kg6",
              "a7",
              "Kf6",
              "a8=Q",
              "Kg6",
              "Qa6+",
              "Kf7",
              "Rh7+",
              "Kg8",
              "Rb7",
              "Kf8",
              "Qa8#",
              "Qxa8",
              "Rb8+",
              "Qxb8",
              "Nxb8",
              "Ke7",
              "g5",
              "Kd6",
              "g6",
              "Ke6",
              "g7",
              "Kf7",
              "g8=Q+",
              "Kxg8",
              "c4",
              "Kf7",
              "c5",
              "Ke7",
              "c6",
              "Kd8",
              "f4",
              "Kc7",
              "f5",
              "Kxb8",
              "f6",
              "Kc7",
              "f7",
              "Kxc6",
              "f8=Q",
              "Kd5",
              "Qf4",
              "Kc5",
              "Qe4",
              "Kd6",
              "Qf5",
              "Kc6",
              "Qe5",
              "Kd7",
              "Qf6",
              "Kc7",
              "Qe6",
              "Kb7",
              "Qd6",
              "Ka7",
              "Qc6",
              "Kb8",
              "Qd7",
              "Ka8",
              "Ke2",
              "Kb8",
              "Kd3",
              "Ka8",
              "Kc4",
              "Kb8",
              "Kb5",
              "Ka8",
              "Kb6",
              "Kb8",
              "Qb7#",
              "Qxb7+",
              "Kc5",
              "Qxb2",
              "d4",
              "Qxf2",
              "Kd5",
              "Qxd4+",
              "Kxd4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kb8",
              "Be3",
              "h5",
              "Qg6",
              "Ne7",
              "Qf7",
              "Nf5",
              "Bf4",
              "Bd6",
              "Bxd6",
              "Nxd6",
              "Qxg7",
              "Rhg8",
              "Qxf6",
              "Rdf8",
              "Qh4",
              "Nf5",
              "Qxh5",
              "Rh8",
              "Qg4",
              "Rhg8",
              "Qe4",
              "Nd6",
              "Qe7",
              "Re8",
              "Qh4",
              "Ref8",
              "Re7",
              "Nf5",
              "Qh7",
              "Nxe7",
              "Qxe7",
              "Re8",
              "Qh4",
              "Rh8",
              "Qg3",
              "Rhg8",
              "Qf3",
              "Rgf8",
              "Qd1",
              "Re7",
              "h4",
              "Ref7",
              "Ne4",
              "Rf4",
              "h5",
              "Rh8",
              "h6",
              "Rf7",
              "Qh5",
              "Rfh7",
              "Qg6",
              "Ka7",
              "Nf6",
              "Re7",
              "h7",
              "Re6",
              "Qg7",
              "Rd8",
              "h8=Q",
              "Rxh8",
              "Rxh8",
              "Rd6",
              "Qxc7",
              "Rxf6",
              "Rh7",
              "Rxf2+",
              "Kxf2",
              "a5",
              "Qxb7#",
              "e4",
              "Nf3",
              "gxf3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kb8",
              "Bf4",
              "g5",
              "Bg3",
              "h5",
              "Qe6",
              "h4",
              "Qf7",
              "hxg3",
              "Re8",
              "Rxe8",
              "Qxe8+",
              "Ka7",
              "Qxf8",
              "gxf2",
              "Qg7",
              "Rh4",
              "Qxg8",
              "Rf4",
              "Qf7",
              "Kb6",
              "Ne4",
              "c5",
              "Nxf6",
              "c6",
              "Nd7+",
              "Kb5",
              "Qb3+",
              "Ka5",
              "Qb6+",
              "Ka4",
              "Nxc5#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 211,
            "completion_tokens": 613,
            "total_tokens": 824,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 211,
            "completion_tokens": 310,
            "total_tokens": 521,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 210,
            "completion_tokens": 335,
            "total_tokens": 545,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 632,
          "total_completion_tokens": 1258,
          "total_tokens": 1890
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 211,
            "completion_tokens": 613,
            "total_tokens": 824,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 211,
            "completion_tokens": 310,
            "total_tokens": 521,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 210,
            "completion_tokens": 335,
            "total_tokens": 545,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2kr1bnr/1pp3pp/p1p2p2/6B1/6b1/2NP1Q2/PPP2PPP/4RK1R w - - 2 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe6",
          "aggressive_uci": "g4e6",
          "aggressive_response": "14. Qe6 fxg5 15. Qf7 Nf6 16. Ne4 Nxe4 17. Rxe4 Bd6 18. Qxg7 Rhg8 19. Qxh7 Rh8\n20. Qg6 Rhg8 21. Qf7 Rgf8 22. Qg7 Rg8 23. Qf7 Rgf8 24. Qg7 Rg8 25. Qf7 Rgf8\n26. Qg7 Rg8 27. Qf7 Rgf8 28. Qg7 Rg8 29. Qf7 Rgf8 30. Qg7 Rg8 31. Qf7 Rgf8\n32. Qg7 Rg8 33. Qf7 Rgf8 34. Qg7 Rg8 35. Qf7 Rgf8 36. Qg7 Rg8 37. Qf7 Rgf8\n38. Qg7 Rg8 39. Qf7 Rgf8 40. Qg7 Rg8 41. Qf7 Rgf8 42. Qg7 Rg8 43. Qf7 Rgf8\n44. Qg7 Rg8 45. Qf7 Rgf8 46. Qg7 Rg8 47. Qf7 Rgf8 48. Qg7 Rg8 49. Qf7 Rgf8\n50. Qg7 Rg8 51. Qf7 Rgf8 52. Qg7 Rg8 53. Qf7 Rgf8 54. Qg7 Rg8 55. Qf7 Rgf8\n56. Qg7 Rg8 57. Qf7 Rgf8 58. Qg7 Rg8 59. Qf7 Rgf8 60. Qg7 Rg8 61. Qf7 Rgf8\n62. Qg7 Rg8 63. Qf7 Rgf8 64. Qg7 Rg8 65. Qf7 Rgf8 66. Qg7 Rg8 67. Qf7 Rgf8\n68. Qg7 Rg8 69. Qf7 Rgf8 70. Qg7 Rg8 71. Qf7 Rgf8 72. Qg7 Rg8 73. Qf7 Rgf8\n74. Qg7 Rg8 75. Qf7 Rgf8 76. Qg7 Rg8 77. Qf7 Rgf8 78. Qg7 Rg8 79. Qf7 Rgf8\n80. Qg7 Rg8 81. Qf7 Rgf8 82. Qg7 Rg8 83. Qf7 Rgf8 84. Qg7 Rg8 85",
          "aggressive_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxg5",
            "Qf7",
            "Nf6",
            "Ne4",
            "Nxe4",
            "Rxe4",
            "Bd6",
            "Qxg7",
            "Rhg8",
            "Qxh7",
            "Rh8",
            "Qg6",
            "Rhg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8",
            "Qf7",
            "Rgf8",
            "Qg7",
            "Rg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe6",
          "positional_uci": "g4e6",
          "positional_response": "14. Qe6 Bd6 15. Ne4 Ne7 16. Nxd6 cxd6 17. Qxe7 Rhe8 18. Qxe8 Rxe8 19. Rxe8+ Kc7\n20. Re7+ Kb6 21. Rxg7 Kc5 22. Rxh7 Kd4 23. Rxb7 Ke5 24. Rb6 Kf5 25. Rxc6 Kxg5\n26. Rxd6 Kf5 27. Rxa6 Ke5 28. Rxf6 Kxf6 29. Ke2 Ke5 30. Ke3 Kd5 31. h4 Ke5\n32. h5 Kf5 33. h6 Kg6 34. h7 Kf6 35. h8=Q+ Ke6 36. Rh5 Kd6 37. Qf6+ Kd7\n38. Rh7+ Ke8 39. Qh8# e4 Nf6+ Kd8",
          "positional_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 227,
            "total_tokens": 448,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd6",
            "Ne4",
            "Ne7",
            "Nxd6",
            "cxd6",
            "Qxe7",
            "Rhe8",
            "Qxe8",
            "Rxe8",
            "Rxe8+",
            "Kc7",
            "Re7+",
            "Kb6",
            "Rxg7",
            "Kc5",
            "Rxh7",
            "Kd4",
            "Rxb7",
            "Ke5",
            "Rb6",
            "Kf5",
            "Rxc6",
            "Kxg5",
            "Rxd6",
            "Kf5",
            "Rxa6",
            "Ke5",
            "Rxf6",
            "Kxf6",
            "Ke2",
            "Ke5",
            "Ke3",
            "Kd5",
            "h4",
            "Ke5",
            "h5",
            "Kf5",
            "h6",
            "Kg6",
            "h7",
            "Kf6",
            "h8=Q+",
            "Ke6",
            "Rh5",
            "Kd6",
            "Qf6+",
            "Kd7",
            "Rh7+",
            "Ke8",
            "Qh8#",
            "e4",
            "Nf6+",
            "Kd8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe6",
          "neutral_uci": "g4e6",
          "neutral_response": "14. Qe6 Bd6 15. Qf7 Nh6 16. Qxg7 Nf5 17. Qxf6 Rhf8 18. Qe6 Rde8 19. Qxe8+ Rxe8\n20. Rxe8+ Ka7 21. Be3+ b6 22. Ne4 Kb7 23. Nxd6+ Nxd6 24. Re7 Nf5 25. Rxh7 Nd6\n26. Bf4 Nb5 27. a4 Nd4 28. Rxc7+ Kb8 29. Rxc6+ Kb7 30. Rc7+ Kb8 31. Rc4+ Kb7\n32. Rxd4 Kc6 33. Rd6+ Kc5 34. d4+ Kc4 35. Ke2 b5 36. b3+ Kc3 37. Rc6+ Kb2\n38. Bc1+ Ka2 39. axb5 axb5 40. Ra6+ Kb1 41. Kd2 b4 42. Bb2+ Kxb2 43. Rha1 *\n43. ... Nxe8 44. Ra2+ Kxa2 45. Kc1 Ka1",
          "neutral_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 279,
            "total_tokens": 499,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rde8",
            "Qxe8+",
            "Rxe8",
            "Rxe8+",
            "Ka7",
            "Be3+",
            "b6",
            "Ne4",
            "Kb7",
            "Nxd6+",
            "Nxd6",
            "Re7",
            "Nf5",
            "Rxh7",
            "Nd6",
            "Bf4",
            "Nb5",
            "a4",
            "Nd4",
            "Rxc7+",
            "Kb8",
            "Rxc6+",
            "Kb7",
            "Rc7+",
            "Kb8",
            "Rc4+",
            "Kb7",
            "Rxd4",
            "Kc6",
            "Rd6+",
            "Kc5",
            "d4+",
            "Kc4",
            "Ke2",
            "b5",
            "b3+",
            "Kc3",
            "Rc6+",
            "Kb2",
            "Bc1+",
            "Ka2",
            "axb5",
            "axb5",
            "Ra6+",
            "Kb1",
            "Kd2",
            "b4",
            "Bb2+",
            "Kxb2",
            "Rha1",
            "Nxe8",
            "Ra2+",
            "Kxa2",
            "Kc1",
            "Ka1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4e6",
          "positional_uci": "g4e6",
          "neutral_uci": "g4e6",
          "consensus_move": "g4e6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "fxg5",
              "Qf7",
              "Nf6",
              "Ne4",
              "Nxe4",
              "Rxe4",
              "Bd6",
              "Qxg7",
              "Rhg8",
              "Qxh7",
              "Rh8",
              "Qg6",
              "Rhg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8",
              "Qf7",
              "Rgf8",
              "Qg7",
              "Rg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd6",
              "Ne4",
              "Ne7",
              "Nxd6",
              "cxd6",
              "Qxe7",
              "Rhe8",
              "Qxe8",
              "Rxe8",
              "Rxe8+",
              "Kc7",
              "Re7+",
              "Kb6",
              "Rxg7",
              "Kc5",
              "Rxh7",
              "Kd4",
              "Rxb7",
              "Ke5",
              "Rb6",
              "Kf5",
              "Rxc6",
              "Kxg5",
              "Rxd6",
              "Kf5",
              "Rxa6",
              "Ke5",
              "Rxf6",
              "Kxf6",
              "Ke2",
              "Ke5",
              "Ke3",
              "Kd5",
              "h4",
              "Ke5",
              "h5",
              "Kf5",
              "h6",
              "Kg6",
              "h7",
              "Kf6",
              "h8=Q+",
              "Ke6",
              "Rh5",
              "Kd6",
              "Qf6+",
              "Kd7",
              "Rh7+",
              "Ke8",
              "Qh8#",
              "e4",
              "Nf6+",
              "Kd8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rde8",
              "Qxe8+",
              "Rxe8",
              "Rxe8+",
              "Ka7",
              "Be3+",
              "b6",
              "Ne4",
              "Kb7",
              "Nxd6+",
              "Nxd6",
              "Re7",
              "Nf5",
              "Rxh7",
              "Nd6",
              "Bf4",
              "Nb5",
              "a4",
              "Nd4",
              "Rxc7+",
              "Kb8",
              "Rxc6+",
              "Kb7",
              "Rc7+",
              "Kb8",
              "Rc4+",
              "Kb7",
              "Rxd4",
              "Kc6",
              "Rd6+",
              "Kc5",
              "d4+",
              "Kc4",
              "Ke2",
              "b5",
              "b3+",
              "Kc3",
              "Rc6+",
              "Kb2",
              "Bc1+",
              "Ka2",
              "axb5",
              "axb5",
              "Ra6+",
              "Kb1",
              "Kd2",
              "b4",
              "Bb2+",
              "Kxb2",
              "Rha1",
              "Nxe8",
              "Ra2+",
              "Kxa2",
              "Kc1",
              "Ka1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 221,
            "completion_tokens": 227,
            "total_tokens": 448,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 220,
            "completion_tokens": 279,
            "total_tokens": 499,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 662,
          "total_completion_tokens": 1146,
          "total_tokens": 1808
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 221,
            "completion_tokens": 227,
            "total_tokens": 448,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 220,
            "completion_tokens": 279,
            "total_tokens": 499,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1k1r1bnr/1pp3pp/p1p2p2/6B1/6Q1/2NP4/PPP2PPP/4RK1R w - - 1 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd3",
          "aggressive_uci": "c2d3",
          "aggressive_response": "15. cxd3 Bb4 16. Qe8+ Ka7 17. Be3+ b6 18. Qxc6 Ne7 19. Qxc7+ Ka8 20. Bxb6\nNc8 21. Nd5 Bxe1 22. Qc6+ Kb8 23. Bc7+ Ka7 24. Qc5+ Kb7 25. Kxe1 Re8+ 26. Kd2\nRe6 27. Rc1 g5 28. Ba5 Re8 29. Qc7+ Ka8 30. Nb6+ Nxb6 31. Bxb6 Re2+ 32. Kxe2\na5 33. Qa7# e4 Nf6+ Ke7",
          "aggressive_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 171,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb4",
            "Qe8+",
            "Ka7",
            "Be3+",
            "b6",
            "Qxc6",
            "Ne7",
            "Qxc7+",
            "Ka8",
            "Bxb6",
            "Nc8",
            "Nd5",
            "Bxe1",
            "Qc6+",
            "Kb8",
            "Bc7+",
            "Ka7",
            "Qc5+",
            "Kb7",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Re6",
            "Rc1",
            "g5",
            "Ba5",
            "Re8",
            "Qc7+",
            "Ka8",
            "Nb6+",
            "Nxb6",
            "Bxb6",
            "Re2+",
            "Kxe2",
            "a5",
            "Qa7#",
            "e4",
            "Nf6+",
            "Ke7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe8+",
          "positional_uci": "e6e8",
          "positional_response": "Re8 15. Qxe8+ Rd8 16. Qxd8# Bb4 17. Re8+ Ka7 18. Be3+ Bc5 19. Bxc5+ b6\n20. Qxc7# Qxc7 21. Re7 Qxe7 22. Bxe7 Nxe7 23. Ke2 Nd5 24. Nxd5 cxd5 25. Re1 Kb7\n26. Kd2 Kc6 27. Re7 Rd7 28. Rxd7 Kxd7 29. Ke3 Kd6 30. Kd4 c5+ 31. Ke3 Ke5 32. f4+\nKf5 33. Kf3 h5 34. h3 g5 35. g4+ hxg4+ 36. hxg4+ Ke6 37. fxg5 fxg5 38. Ke3 Ke5\n39. c3 d4+ 40. cxd4+ cxd4+ 41. Kf3 Kd5 42. b3 b5 43. a3 a5 44. a4 bxa4 45.\nbxa4 Kc5 46. Ke4 Kb4 47. Kxd4 Kxa4 48. Kc4 Ka3 49. d4 a4 50. d5 Kb2 51. d6 a3\n52. d7 a2 53. d8=Q a1=Q 54. Qd4+ Ka2 55. Qxa1+ Kxa1 56. Kd5 Kb2 57. Ke5 Kc3\n58. Kf5 Kd4 59. Kxg5 Ke5 60. Kh6 Kf6 61. g5+ Kf7 62. Kh7 Kf8 63. g6 Ke7 64.\ng7 Kf6 65. g8=Q Kf5 66. Qg6+ Kf4 67. Kh6 Ke5 68. Kg5 Kd4 69. Qf5 Ke3 70. Qf4+ Kd3\n71. Kf5 Kc3 72. Qe4 Kd2 73. Qf3 Kc2 74. Qe3 Kb2 75. Qd3 Ka2 76. Qc3 Kb1 77.\nQd2 Ka1 78. Ke4 Kb1 79. Kd3 Ka1 80. Kc3 Kb1 81. Qb2# Kd1 82. Qd2# Kxd2 83.\nKxd2 1/2-1/2 84. Ke3 Ke1 85. Kf3 Kf1 86. Kg3 Kg1",
          "positional_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 612,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd8",
            "Qxd8#",
            "Bb4",
            "Re8+",
            "Ka7",
            "Be3+",
            "Bc5",
            "Bxc5+",
            "b6",
            "Qxc7#",
            "Qxc7",
            "Re7",
            "Qxe7",
            "Bxe7",
            "Nxe7",
            "Ke2",
            "Nd5",
            "Nxd5",
            "cxd5",
            "Re1",
            "Kb7",
            "Kd2",
            "Kc6",
            "Re7",
            "Rd7",
            "Rxd7",
            "Kxd7",
            "Ke3",
            "Kd6",
            "Kd4",
            "c5+",
            "Ke3",
            "Ke5",
            "f4+",
            "Kf5",
            "Kf3",
            "h5",
            "h3",
            "g5",
            "g4+",
            "hxg4+",
            "hxg4+",
            "Ke6",
            "fxg5",
            "fxg5",
            "Ke3",
            "Ke5",
            "c3",
            "d4+",
            "cxd4+",
            "cxd4+",
            "Kf3",
            "Kd5",
            "b3",
            "b5",
            "a3",
            "a5",
            "a4",
            "bxa4",
            "bxa4",
            "Kc5",
            "Ke4",
            "Kb4",
            "Kxd4",
            "Kxa4",
            "Kc4",
            "Ka3",
            "d4",
            "a4",
            "d5",
            "Kb2",
            "d6",
            "a3",
            "d7",
            "a2",
            "d8=Q",
            "a1=Q",
            "Qd4+",
            "Ka2",
            "Qxa1+",
            "Kxa1",
            "Kd5",
            "Kb2",
            "Ke5",
            "Kc3",
            "Kf5",
            "Kd4",
            "Kxg5",
            "Ke5",
            "Kh6",
            "Kf6",
            "g5+",
            "Kf7",
            "Kh7",
            "Kf8",
            "g6",
            "Ke7",
            "g7",
            "Kf6",
            "g8=Q",
            "Kf5",
            "Qg6+",
            "Kf4",
            "Kh6",
            "Ke5",
            "Kg5",
            "Kd4",
            "Qf5",
            "Ke3",
            "Qf4+",
            "Kd3",
            "Kf5",
            "Kc3",
            "Qe4",
            "Kd2",
            "Qf3",
            "Kc2",
            "Qe3",
            "Kb2",
            "Qd3",
            "Ka2",
            "Qc3",
            "Kb1",
            "Qd2",
            "Ka1",
            "Ke4",
            "Kb1",
            "Kd3",
            "Ka1",
            "Kc3",
            "Kb1",
            "Qb2#",
            "Kd1",
            "Qd2#",
            "Kxd2",
            "Kxd2",
            "Ke3",
            "Ke1",
            "Kf3",
            "Kf1",
            "Kg3",
            "Kg1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "cxd3",
          "neutral_uci": "c2d3",
          "neutral_response": "15. cxd3 Bb4 16. Qe8+ Ka7 17. Be3+ b6 18. Qxc6 Ne7 19. Qxc7+ Ka8 20. Bxb6\nNc6 21. Qxc6+ Kb8 22. Qc7+ Ka8 23. Qa7# e4 Nf6 d4 d5 dxe5 Nxe5 Nxe5 Qd4 Nxd4\nBd6 Nxf6+ gxf6 Qxf6 Rg8 Qxf7 Rg6 Qxh7 Rg5 Qh8+ Ka7 Qxf6 Rg4 Qf7+ Kb8 Qe8+ Ka7 Qd7+ Kb8 Qxg4 Ka7 Qd7+ Kb8 Qd8+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc7+ Ka8 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc7+ Ka8 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc7+ Ka8 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc7+ Ka8 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc7+ Ka8 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6+ Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka7 Qc6 Ka7 Qc7+ Ka8 Qc8+ Ka",
          "neutral_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 640,
            "total_tokens": 869,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb4",
            "Qe8+",
            "Ka7",
            "Be3+",
            "b6",
            "Qxc6",
            "Ne7",
            "Qxc7+",
            "Ka8",
            "Bxb6",
            "Nc6",
            "Qxc6+",
            "Kb8",
            "Qc7+",
            "Ka8",
            "Qa7#",
            "e4",
            "Nf6",
            "d4",
            "d5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qd4",
            "Nxd4",
            "Bd6",
            "Nxf6+",
            "gxf6",
            "Qxf6",
            "Rg8",
            "Qxf7",
            "Rg6",
            "Qxh7",
            "Rg5",
            "Qh8+",
            "Ka7",
            "Qxf6",
            "Rg4",
            "Qf7+",
            "Kb8",
            "Qe8+",
            "Ka7",
            "Qd7+",
            "Kb8",
            "Qxg4",
            "Ka7",
            "Qd7+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+",
            "Ka7",
            "Qc6",
            "Ka7",
            "Qc7+",
            "Ka8",
            "Qc8+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c2d3",
          "positional_uci": "e6e8",
          "neutral_uci": "c2d3",
          "consensus_move": "c2d3",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb4",
              "Qe8+",
              "Ka7",
              "Be3+",
              "b6",
              "Qxc6",
              "Ne7",
              "Qxc7+",
              "Ka8",
              "Bxb6",
              "Nc8",
              "Nd5",
              "Bxe1",
              "Qc6+",
              "Kb8",
              "Bc7+",
              "Ka7",
              "Qc5+",
              "Kb7",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Re6",
              "Rc1",
              "g5",
              "Ba5",
              "Re8",
              "Qc7+",
              "Ka8",
              "Nb6+",
              "Nxb6",
              "Bxb6",
              "Re2+",
              "Kxe2",
              "a5",
              "Qa7#",
              "e4",
              "Nf6+",
              "Ke7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rd8",
              "Qxd8#",
              "Bb4",
              "Re8+",
              "Ka7",
              "Be3+",
              "Bc5",
              "Bxc5+",
              "b6",
              "Qxc7#",
              "Qxc7",
              "Re7",
              "Qxe7",
              "Bxe7",
              "Nxe7",
              "Ke2",
              "Nd5",
              "Nxd5",
              "cxd5",
              "Re1",
              "Kb7",
              "Kd2",
              "Kc6",
              "Re7",
              "Rd7",
              "Rxd7",
              "Kxd7",
              "Ke3",
              "Kd6",
              "Kd4",
              "c5+",
              "Ke3",
              "Ke5",
              "f4+",
              "Kf5",
              "Kf3",
              "h5",
              "h3",
              "g5",
              "g4+",
              "hxg4+",
              "hxg4+",
              "Ke6",
              "fxg5",
              "fxg5",
              "Ke3",
              "Ke5",
              "c3",
              "d4+",
              "cxd4+",
              "cxd4+",
              "Kf3",
              "Kd5",
              "b3",
              "b5",
              "a3",
              "a5",
              "a4",
              "bxa4",
              "bxa4",
              "Kc5",
              "Ke4",
              "Kb4",
              "Kxd4",
              "Kxa4",
              "Kc4",
              "Ka3",
              "d4",
              "a4",
              "d5",
              "Kb2",
              "d6",
              "a3",
              "d7",
              "a2",
              "d8=Q",
              "a1=Q",
              "Qd4+",
              "Ka2",
              "Qxa1+",
              "Kxa1",
              "Kd5",
              "Kb2",
              "Ke5",
              "Kc3",
              "Kf5",
              "Kd4",
              "Kxg5",
              "Ke5",
              "Kh6",
              "Kf6",
              "g5+",
              "Kf7",
              "Kh7",
              "Kf8",
              "g6",
              "Ke7",
              "g7",
              "Kf6",
              "g8=Q",
              "Kf5",
              "Qg6+",
              "Kf4",
              "Kh6",
              "Ke5",
              "Kg5",
              "Kd4",
              "Qf5",
              "Ke3",
              "Qf4+",
              "Kd3",
              "Kf5",
              "Kc3",
              "Qe4",
              "Kd2",
              "Qf3",
              "Kc2",
              "Qe3",
              "Kb2",
              "Qd3",
              "Ka2",
              "Qc3",
              "Kb1",
              "Qd2",
              "Ka1",
              "Ke4",
              "Kb1",
              "Kd3",
              "Ka1",
              "Kc3",
              "Kb1",
              "Qb2#",
              "Kd1",
              "Qd2#",
              "Kxd2",
              "Kxd2",
              "Ke3",
              "Ke1",
              "Kf3",
              "Kf1",
              "Kg3",
              "Kg1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb4",
              "Qe8+",
              "Ka7",
              "Be3+",
              "b6",
              "Qxc6",
              "Ne7",
              "Qxc7+",
              "Ka8",
              "Bxb6",
              "Nc6",
              "Qxc6+",
              "Kb8",
              "Qc7+",
              "Ka8",
              "Qa7#",
              "e4",
              "Nf6",
              "d4",
              "d5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qd4",
              "Nxd4",
              "Bd6",
              "Nxf6+",
              "gxf6",
              "Qxf6",
              "Rg8",
              "Qxf7",
              "Rg6",
              "Qxh7",
              "Rg5",
              "Qh8+",
              "Ka7",
              "Qxf6",
              "Rg4",
              "Qf7+",
              "Kb8",
              "Qe8+",
              "Ka7",
              "Qd7+",
              "Kb8",
              "Qxg4",
              "Ka7",
              "Qd7+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+",
              "Ka7",
              "Qc6",
              "Ka7",
              "Qc7+",
              "Ka8",
              "Qc8+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 230,
            "completion_tokens": 171,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 230,
            "completion_tokens": 612,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 229,
            "completion_tokens": 640,
            "total_tokens": 869,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 689,
          "total_completion_tokens": 1423,
          "total_tokens": 2112
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 230,
            "completion_tokens": 171,
            "total_tokens": 401,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 230,
            "completion_tokens": 612,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 229,
            "completion_tokens": 640,
            "total_tokens": 869,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "1k3bnr/1pp3pp/p1p1Qp2/6B1/8/2Nr4/PPP2PPP/4RK1R w - - 0 15"
    }
  ],
  "black_responses": [
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "1. d4 * d5 Nf3 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 14,
            "total_tokens": 130,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": null,
          "positional_response": "1. d4\nd4 e5",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 10,
            "total_tokens": 126,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": null,
          "neutral_response": "1. d4 *\nd4",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 14,
            "total_tokens": 130,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 10,
            "total_tokens": 126,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 32,
          "total_tokens": 379
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 14,
            "total_tokens": 130,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 10,
            "total_tokens": 126,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6\nBlack Nf6 c4 e6",
          "aggressive_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c4",
            "e6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6\nNf6 e6 c4",
          "positional_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e6",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6 4. Nc3 Be7 5. Bf4 O-O 6. e3 c5 7. dxc5 Bxc5 8. Qc2 Nc6 9. Rd1 Qe7 10. Be2 Rd8 11. O-O Ne5 12. Nxe5 dxe5 13. Bg3 Bf5 14. Qb3 b6 15. cxb6 axb6 16. Rc1 Rac8 17. Rxc8 Rxc8 18. Bxb6 Bxb6 19. Qxb6 Qxb6 20. Rxd8+ Nf8 21. Rd7 Qb1+ 22. Kf2 Qxb2 23. Rxg7+ Kh8 24. Rh7+ Kg8 25. Rxh6 Qxc3 26. Rh8+ Kf7 27. Rh7+ Ke8 28. Rh8+ Kd7 29. Rh7+ Kc6 30. Rh6+ Kb5 31. Rh5+ Ka4 32. Rh4+ Ka3 33. Rh3+ Ka2 34. Rh2+ Ka1 35. Rh1+ Ka2 36. Rh2+ Ka3 37. Rh3+ Ka4 38. Rh4+ Ka5 39. Rh5+ Ka6 40. Rh6+ Ka7 41. Rh7+ Ka8 42. Rh8+ Ka7 43. Rh7+ Ka6 44. Rh6+ Ka5 45. Rh5+ Ka4 46. Rh4+ Ka3 47. Rh3+ Ka2 48. Rh2+ Ka1 49. Rh1+ Ka2 50. Rh2+ Ka3 51. Rh3+ Ka4 52. Rh4+ Ka5 53. Rh5+ Ka6 54. Rh6+ Ka7 55. Rh7+ Ka8 56. Rh8+ Ka7 57. Rh7+ Ka6 58. Rh6+ Ka5 59. Rh5+ Ka4 60. Rh4+ Ka3 61. Rh3+ Ka2 62. Rh2+ Ka1 63. Rh1+ Ka2 64. Rh2+ Ka3 65. Rh3+ Ka4 66. Rh4+ Ka5 67. Rh5+ Ka6 68. Rh6+ Ka7 69. Rh7+ Ka8 70. Rh8+ Ka7 71. Rh7+ Ka6 72. Rh6+ Ka5 73. Rh5+ Ka4 74. Rh4+ Ka3 75. Rh3+ Ka2 76. Rh2+ Ka1 77. Rh1+ Ka2 78. Rh2+ Ka3 79",
          "neutral_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "c4",
            "e6",
            "Nc3",
            "Be7",
            "Bf4",
            "O-O",
            "e3",
            "c5",
            "dxc5",
            "Bxc5",
            "Qc2",
            "Nc6",
            "Rd1",
            "Qe7",
            "Be2",
            "Rd8",
            "O-O",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Bg3",
            "Bf5",
            "Qb3",
            "b6",
            "cxb6",
            "axb6",
            "Rc1",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Bxb6",
            "Bxb6",
            "Qxb6",
            "Qxb6",
            "Rxd8+",
            "Nf8",
            "Rd7",
            "Qb1+",
            "Kf2",
            "Qxb2",
            "Rxg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rxh6",
            "Qxc3",
            "Rh8+",
            "Kf7",
            "Rh7+",
            "Ke8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kc6",
            "Rh6+",
            "Kb5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3",
            "Rh3+",
            "Ka4",
            "Rh4+",
            "Ka5",
            "Rh5+",
            "Ka6",
            "Rh6+",
            "Ka7",
            "Rh7+",
            "Ka8",
            "Rh8+",
            "Ka7",
            "Rh7+",
            "Ka6",
            "Rh6+",
            "Ka5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3",
            "Rh3+",
            "Ka4",
            "Rh4+",
            "Ka5",
            "Rh5+",
            "Ka6",
            "Rh6+",
            "Ka7",
            "Rh7+",
            "Ka8",
            "Rh8+",
            "Ka7",
            "Rh7+",
            "Ka6",
            "Rh6+",
            "Ka5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3",
            "Rh3+",
            "Ka4",
            "Rh4+",
            "Ka5",
            "Rh5+",
            "Ka6",
            "Rh6+",
            "Ka7",
            "Rh7+",
            "Ka8",
            "Rh8+",
            "Ka7",
            "Rh7+",
            "Ka6",
            "Rh6+",
            "Ka5",
            "Rh5+",
            "Ka4",
            "Rh4+",
            "Ka3",
            "Rh3+",
            "Ka2",
            "Rh2+",
            "Ka1",
            "Rh1+",
            "Ka2",
            "Rh2+",
            "Ka3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c4",
              "e6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c4",
              "e6",
              "Nc3",
              "Be7",
              "Bf4",
              "O-O",
              "e3",
              "c5",
              "dxc5",
              "Bxc5",
              "Qc2",
              "Nc6",
              "Rd1",
              "Qe7",
              "Be2",
              "Rd8",
              "O-O",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Bg3",
              "Bf5",
              "Qb3",
              "b6",
              "cxb6",
              "axb6",
              "Rc1",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Bxb6",
              "Bxb6",
              "Qxb6",
              "Qxb6",
              "Rxd8+",
              "Nf8",
              "Rd7",
              "Qb1+",
              "Kf2",
              "Qxb2",
              "Rxg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rxh6",
              "Qxc3",
              "Rh8+",
              "Kf7",
              "Rh7+",
              "Ke8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kc6",
              "Rh6+",
              "Kb5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3",
              "Rh3+",
              "Ka4",
              "Rh4+",
              "Ka5",
              "Rh5+",
              "Ka6",
              "Rh6+",
              "Ka7",
              "Rh7+",
              "Ka8",
              "Rh8+",
              "Ka7",
              "Rh7+",
              "Ka6",
              "Rh6+",
              "Ka5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3",
              "Rh3+",
              "Ka4",
              "Rh4+",
              "Ka5",
              "Rh5+",
              "Ka6",
              "Rh6+",
              "Ka7",
              "Rh7+",
              "Ka8",
              "Rh8+",
              "Ka7",
              "Rh7+",
              "Ka6",
              "Rh6+",
              "Ka5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3",
              "Rh3+",
              "Ka4",
              "Rh4+",
              "Ka5",
              "Rh5+",
              "Ka6",
              "Rh6+",
              "Ka7",
              "Rh7+",
              "Ka8",
              "Rh8+",
              "Ka7",
              "Rh7+",
              "Ka6",
              "Rh6+",
              "Ka5",
              "Rh5+",
              "Ka4",
              "Rh4+",
              "Ka3",
              "Rh3+",
              "Ka2",
              "Rh2+",
              "Ka1",
              "Rh1+",
              "Ka2",
              "Rh2+",
              "Ka3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 371,
          "total_completion_tokens": 705,
          "total_tokens": 1076
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 123,
            "completion_tokens": 640,
            "total_tokens": 763,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e6",
          "aggressive_uci": "e7e6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 *\nBlack e6 Bb4+",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 30,
            "total_tokens": 163,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb4+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e3",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 * e3 Bg4 4. Bxf6",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 34,
            "total_tokens": 167,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e6",
          "neutral_uci": "e7e6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Nbd2 O-O\nBlack e6 Be7 O-O",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e6",
          "positional_uci": null,
          "neutral_uci": "e7e6",
          "consensus_move": "e7e6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb4+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bg4",
              "Bxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 30,
            "total_tokens": 163,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 34,
            "total_tokens": 167,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 111,
          "total_tokens": 509
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 30,
            "total_tokens": 163,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 34,
            "total_tokens": 167,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p2B1/3P4/5N2/PPP1PPPP/RN1QKB1R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. c4 c5 10. Qc2 Nc6 11. Rac1 Rc8 12. Rfd1 Qd7 13. dxc5 bxc5 14. Nb3 Qe7 15. Nxc5 Nxc5 16. Qxc5 Rfd8 17. Qc2 d4 18. exd4 Bxd4 19. Ne5 Bxe5 20. Bxe5 Qxe5 21. Bxf6 gxf6 22. Qxf6 Qxf6 23. Rxd8+ Rxd8 24. Rxd8+ Kg7 25. Rd7+ Kg6 26. Rxh7 Kxh7 27. h3 Kg7 28. g4 Kf6 29. Kg2 Ke5 30. Kg3 Kd5 31. f4 Kc4 32. Kf3 Kb3 33. Ke3 Kxa2 34. Kd3 Kb3 35. Kd4 a5 36. Kc5 a4 37. Kb4 a3 38. Kxa3 Kc4 39. Ka4 Kc5 40. Ka5 Kc6 41. Ka6 Kc7 42. Ka7 Kc8 43. Ka8 Kc7 44. Ka7 Kc8 45. Ka8 Kc7 46. Ka7 Kc8 47. Ka8 Kc7 48. Ka7 Kc8 49. Ka8 Kc7 50. Ka7 Kc8 51. Ka8 Kc7 52. Ka7 Kc8 53. Ka8 Kc7 54. Ka7 Kc8 55. Ka8 Kc7 56. Ka7 Kc8 57. Ka8 Kc7 58. Ka7 Kc8 59. Ka8 Kc7 60. Ka7 Kc8 61. Ka8 Kc7 62. Ka7 Kc8 63. Ka8 Kc7 64. Ka7 Kc8 65. Ka8 Kc7 66. Ka7 Kc8 67. Ka8 Kc7 68. Ka7 Kc8 69. Ka8 Kc7 70. Ka7 Kc8 71. Ka8 Kc7 72. Ka7 Kc8 73. Ka8 Kc7 74. Ka7 Kc8 75. Ka8 Kc7 76. Ka7 Kc8 77. Ka8 Kc7 78. Ka7 Kc8 79. Ka8 Kc",
          "aggressive_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd3",
            "O-O",
            "O-O",
            "h6",
            "Bh4",
            "b6",
            "Nbd2",
            "Bb7",
            "c4",
            "c5",
            "Qc2",
            "Nc6",
            "Rac1",
            "Rc8",
            "Rfd1",
            "Qd7",
            "dxc5",
            "bxc5",
            "Nb3",
            "Qe7",
            "Nxc5",
            "Nxc5",
            "Qxc5",
            "Rfd8",
            "Qc2",
            "d4",
            "exd4",
            "Bxd4",
            "Ne5",
            "Bxe5",
            "Bxe5",
            "Qxe5",
            "Bxf6",
            "gxf6",
            "Qxf6",
            "Qxf6",
            "Rxd8+",
            "Rxd8",
            "Rxd8+",
            "Kg7",
            "Rd7+",
            "Kg6",
            "Rxh7",
            "Kxh7",
            "h3",
            "Kg7",
            "g4",
            "Kf6",
            "Kg2",
            "Ke5",
            "Kg3",
            "Kd5",
            "f4",
            "Kc4",
            "Kf3",
            "Kb3",
            "Ke3",
            "Kxa2",
            "Kd3",
            "Kb3",
            "Kd4",
            "a5",
            "Kc5",
            "a4",
            "Kb4",
            "a3",
            "Kxa3",
            "Kc4",
            "Ka4",
            "Kc5",
            "Ka5",
            "Kc6",
            "Ka6",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 * Be7 h3 Bd6",
          "positional_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Bd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O",
          "neutral_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 43,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3",
            "O-O",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd3",
              "O-O",
              "O-O",
              "h6",
              "Bh4",
              "b6",
              "Nbd2",
              "Bb7",
              "c4",
              "c5",
              "Qc2",
              "Nc6",
              "Rac1",
              "Rc8",
              "Rfd1",
              "Qd7",
              "dxc5",
              "bxc5",
              "Nb3",
              "Qe7",
              "Nxc5",
              "Nxc5",
              "Qxc5",
              "Rfd8",
              "Qc2",
              "d4",
              "exd4",
              "Bxd4",
              "Ne5",
              "Bxe5",
              "Bxe5",
              "Qxe5",
              "Bxf6",
              "gxf6",
              "Qxf6",
              "Qxf6",
              "Rxd8+",
              "Rxd8",
              "Rxd8+",
              "Kg7",
              "Rd7+",
              "Kg6",
              "Rxh7",
              "Kxh7",
              "h3",
              "Kg7",
              "g4",
              "Kf6",
              "Kg2",
              "Ke5",
              "Kg3",
              "Kd5",
              "f4",
              "Kc4",
              "Kf3",
              "Kb3",
              "Ke3",
              "Kxa2",
              "Kd3",
              "Kb3",
              "Kd4",
              "a5",
              "Kc5",
              "a4",
              "Kb4",
              "a3",
              "Kxa3",
              "Kc4",
              "Ka4",
              "Kc5",
              "Ka5",
              "Kc6",
              "Ka6",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h3",
              "Bd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bd3",
              "O-O",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 139,
            "completion_tokens": 43,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 419,
          "total_completion_tokens": 721,
          "total_tokens": 1140
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 139,
            "completion_tokens": 43,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p2B1/3P4/4PN2/PPP2PPP/RN1QKB1R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd7",
          "aggressive_uci": "b8d7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 *\nBlack Nbd7 O-O c6",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "c6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e8g8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 * O-O Nbd7 h6",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 44,
            "total_tokens": 190,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "h6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8d7",
          "positional_uci": "e8g8",
          "neutral_uci": "e8g8",
          "consensus_move": "e8g8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "c6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h6",
              "Bh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "h6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 44,
            "total_tokens": 190,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 139,
          "total_tokens": 579
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 44,
            "total_tokens": 190,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1QK2R b KQkq - 2 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "h6",
          "aggressive_uci": "h7h6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h6",
          "positional_uci": "h7h6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "h6",
          "neutral_uci": "h7h6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 58,
            "total_tokens": 211,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h7h6",
          "positional_uci": "h7h6",
          "neutral_uci": "h7h6",
          "consensus_move": "h7h6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 58,
            "total_tokens": 211,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 174,
          "total_tokens": 635
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 58,
            "total_tokens": 211,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1Q1RK1 b - - 4 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b6",
          "aggressive_uci": "b7b6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. Ne5\nBlack Ne4 Bxe4 Qc8",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Bb7",
            "Ne5",
            "Ne4",
            "Bxe4",
            "Qc8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b6",
          "positional_uci": "b7b6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. c4\nb6 Bb7 c4",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 74,
            "total_tokens": 235,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb7",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "b6",
          "neutral_uci": "b7b6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. c4",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 66,
            "total_tokens": 226,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Bb7",
            "c4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b7b6",
          "positional_uci": "b7b6",
          "neutral_uci": "b7b6",
          "consensus_move": "b7b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd2",
              "Bb7",
              "Ne5",
              "Ne4",
              "Bxe4",
              "Qc8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd2",
              "Bb7",
              "c4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 74,
            "total_tokens": 235,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 66,
            "total_tokens": 226,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 216,
          "total_tokens": 698
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 74,
            "total_tokens": 235,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 66,
            "total_tokens": 226,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bpp1/4pn1p/3p4/3P3B/3BPN2/PPP2PPP/RN1Q1RK1 b - - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb7",
          "aggressive_uci": "c8b7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2",
          "aggressive_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Qc2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb7",
          "positional_uci": "c8b7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1\nBb7 Nc3 Rc1",
          "positional_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 84,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Rc1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb7",
          "neutral_uci": "c8b7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2",
          "neutral_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Qc2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8b7",
          "positional_uci": "c8b7",
          "neutral_uci": "c8b7",
          "consensus_move": "c8b7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Nbd7",
              "Qc2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Rc1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc3",
              "Nbd7",
              "Qc2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 168,
            "completion_tokens": 84,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 503,
          "total_completion_tokens": 234,
          "total_tokens": 737
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 168,
            "completion_tokens": 84,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/p1p1bpp1/1p2pn1p/3p4/2PP3B/3BPN2/PP3PPP/RN1Q1RK1 b - - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd7",
          "aggressive_uci": "b8d7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2 c5 11. Rfd1",
          "aggressive_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc2",
            "c5",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nbd7",
          "positional_uci": "b8d7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. dxc5 bxc5",
          "positional_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 86,
            "total_tokens": 263,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rc1",
            "c5",
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nbd7",
          "neutral_uci": "b8d7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. dxc5 bxc5",
          "neutral_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 86,
            "total_tokens": 262,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rc1",
            "c5",
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8d7",
          "positional_uci": "b8d7",
          "neutral_uci": "b8d7",
          "consensus_move": "b8d7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qc2",
              "c5",
              "Rfd1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rc1",
              "c5",
              "dxc5",
              "bxc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rc1",
              "c5",
              "dxc5",
              "bxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 177,
            "completion_tokens": 86,
            "total_tokens": 263,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 176,
            "completion_tokens": 86,
            "total_tokens": 262,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 530,
          "total_completion_tokens": 255,
          "total_tokens": 785
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 177,
            "completion_tokens": 86,
            "total_tokens": 263,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 176,
            "completion_tokens": 86,
            "total_tokens": 262,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rn1q1rk1/pbp1bpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/R2Q1RK1 b - - 2 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxd5",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 * cxd5 Nxd5 11. Bxe7 Qxe7",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c5",
          "positional_uci": "c7c5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. dxc5 bxc5",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c5",
          "neutral_uci": "c7c5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 95,
            "total_tokens": 280,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "cxd5",
            "exd5",
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "c7c5",
          "neutral_uci": "c7c5",
          "consensus_move": "c7c5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "cxd5",
              "exd5",
              "dxc5",
              "bxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 95,
            "total_tokens": 280,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 272,
          "total_tokens": 829
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 95,
            "total_tokens": 280,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pbpnbpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/2RQ1RK1 b - - 4 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "exd5",
          "aggressive_uci": "e6d5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5 13. Qa4",
          "aggressive_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qa4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "exd5",
          "positional_uci": "e6d5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5 13. Qe2\nBlack Qe2 Rfc8 Bf5",
          "positional_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 112,
            "total_tokens": 306,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qe2",
            "Qe2",
            "Rfc8",
            "Bf5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "exd5",
          "neutral_uci": "e6d5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. dxc5 bxc5 13. Bxf6 Nxf6\nBlack exd5 dxc5 bxc5",
          "neutral_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 115,
            "total_tokens": 308,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e6d5",
          "positional_uci": "e6d5",
          "neutral_uci": "e6d5",
          "consensus_move": "e6d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc5",
              "bxc5",
              "Qa4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5",
              "Qe2",
              "Qe2",
              "Rfc8",
              "Bf5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc5",
              "bxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 194,
            "completion_tokens": 112,
            "total_tokens": 306,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 193,
            "completion_tokens": 115,
            "total_tokens": 308,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 581,
          "total_completion_tokens": 328,
          "total_tokens": 909
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 194,
            "completion_tokens": 112,
            "total_tokens": 306,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 193,
            "completion_tokens": 115,
            "total_tokens": 308,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p2pn1p/2pP4/3P3B/2NBPN2/PP3PPP/2RQ1RK1 b - - 0 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rc8",
          "aggressive_uci": "a8c8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. dxc5 bxc5 14. Qd2",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 110,
            "total_tokens": 313,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rc8",
          "positional_uci": "a8c8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. dxc5 bxc5 14. Qd2 *",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 111,
            "total_tokens": 314,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rc8",
          "neutral_uci": "a8c8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. dxc5 bxc5 14. Qd2\nBb7 Rc8 dxc5 bxc5 Qd2",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 125,
            "total_tokens": 327,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Qd2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a8c8",
          "positional_uci": "a8c8",
          "neutral_uci": "a8c8",
          "consensus_move": "a8c8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc5",
              "bxc5",
              "Qd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5",
              "Qd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc5",
              "bxc5",
              "Qd2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 110,
            "total_tokens": 313,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 111,
            "total_tokens": 314,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 125,
            "total_tokens": 327,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 346,
          "total_tokens": 954
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 110,
            "total_tokens": 313,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 111,
            "total_tokens": 314,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 125,
            "total_tokens": 327,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2N1PN2/PP3PPP/1BRQ1RK1 b - - 1 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qc7",
          "aggressive_uci": "d8c7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. dxc5 bxc5 15. Bxf6 Nxf6",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 122,
            "total_tokens": 334,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Bxf6",
            "Nxf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe8",
          "positional_uci": "d8e8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qe8 14. dxc5 bxc5 15. Bxf6\nQe8 dxc5 bxc5 Bxf6",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 132,
            "total_tokens": 344,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxc5",
            "bxc5",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qa5",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qa5 14. Ne2 Rfd8 15. Ng3\nQa5 Rfd8 Ng3",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 126,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rfd8",
            "Ng3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8c7",
          "positional_uci": "d8e8",
          "neutral_uci": null,
          "consensus_move": "d8c7",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxc5",
              "bxc5",
              "Bxf6",
              "Nxf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxc5",
              "bxc5",
              "Bxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rfd8",
              "Ng3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 122,
            "total_tokens": 334,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 132,
            "total_tokens": 344,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 126,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 380,
          "total_tokens": 1015
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 122,
            "total_tokens": 334,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 132,
            "total_tokens": 344,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 126,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2rq1rk1/pb1nbpp1/1p3n1p/2pp4/3P3B/2NQPN2/PP3PPP/1BR2RK1 b - - 3 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": "d7e5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Nd7 16. f4",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 125,
            "total_tokens": 345,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Nd7",
            "f4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe5",
          "positional_uci": "d7e5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Ng4 16. Bg3\nNg4 Bg3 Qe7",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 135,
            "total_tokens": 355,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Ng4",
            "Bg3",
            "Ng4",
            "Bg3",
            "Qe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe5",
          "neutral_uci": "d7e5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6\nBlack Nxe5 dxe5 Qxe5 Bxf6",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 141,
            "total_tokens": 360,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Qxe5",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7e5",
          "positional_uci": "d7e5",
          "neutral_uci": "d7e5",
          "consensus_move": "d7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxe5",
              "Nd7",
              "f4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxe5",
              "Ng4",
              "Bg3",
              "Ng4",
              "Bg3",
              "Qe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxe5",
              "Qxe5",
              "Bxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 125,
            "total_tokens": 345,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 135,
            "total_tokens": 355,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 141,
            "total_tokens": 360,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 401,
          "total_tokens": 1060
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 125,
            "total_tokens": 345,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 135,
            "total_tokens": 355,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 141,
            "total_tokens": 360,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pbqnbpp1/1p3n1p/2ppN3/3P3B/2NQP3/PP3PPP/1BR2RK1 b - - 5 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe5",
          "aggressive_uci": "c7e5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 * Qxe5 Qxe5 Bxe5",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne4",
          "positional_uci": "f6e4",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Ne4 16. Bxe7 Qxe7 17. f3\nNe4 f3 Bxe7 Qxe7",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 145,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "f3",
            "Bxe7",
            "Qxe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe5",
          "neutral_uci": "c7e5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qxd5\nQxe5 Qxd5 Bxf6",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxd5",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c7e5",
          "positional_uci": "f6e4",
          "neutral_uci": "c7e5",
          "consensus_move": "c7e5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxe5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "f3",
              "Bxe7",
              "Qxe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxd5",
              "Bxf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 145,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 419,
          "total_tokens": 1105
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 145,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pbq1bpp1/1p3n1p/2ppP3/7B/2NQP3/PP3PPP/1BR2RK1 b - - 0 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "gxf6",
          "aggressive_uci": "g7f6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 gxf6 17. Qg3+ Kh8 18. Qh4\nQg3+ Kh8 Qh4",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 154,
            "total_tokens": 392,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg3+",
            "Kh8",
            "Qh4",
            "Qg3+",
            "Kh8",
            "Qh4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "gxf6",
          "positional_uci": "g7f6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 gxf6 17. Qg3+ Kh8 18. Qh4",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 145,
            "total_tokens": 383,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg3+",
            "Kh8",
            "Qh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "e7f6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 c5 11. cxd5 exd5 12. Bb1 Rc8 13. Qd3 Qc7 14. Ne5 Nxe5 15. dxe5 Qxe5 16. Bxf6 Bxf6 17. Qxh6 Qg5 18. Qxg5\nBg5 Qxg5",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 151,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh6",
            "Qg5",
            "Qxg5",
            "Bg5",
            "Qxg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g7f6",
          "positional_uci": "g7f6",
          "neutral_uci": "e7f6",
          "consensus_move": "g7f6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qg3+",
              "Kh8",
              "Qh4",
              "Qg3+",
              "Kh8",
              "Qh4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qg3+",
              "Kh8",
              "Qh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxh6",
              "Qg5",
              "Qxg5",
              "Bg5",
              "Qxg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 154,
            "total_tokens": 392,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 145,
            "total_tokens": 383,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 151,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 450,
          "total_tokens": 1163
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 154,
            "total_tokens": 392,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 145,
            "total_tokens": 383,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 151,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2rk1/pb2bpp1/1p3B1p/2ppq3/8/2NQP3/PP3PPP/1BR2RK1 b - - 0 16"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d6 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Nb4 15. Bb1 Bb7 16. Nbd2 Rac8 17. Nb1 Rfd8 18. Nbd2 Qb8 19. Nb1 Qb7 20. Nbd2 Qb8 21. Nb1 Qb7 22. Nbd2 Qb8 23. Nb1 Qb7 24. Nbd2 Qb8 25. Nb1 Qb7 26. Nbd2 Qb8 27. Nb1 Qb7 28. Nbd2 Qb8 29. Nb1 Qb7 30. Nbd2 Qb8 31. Nb1 Qb7 32. Nbd2 Qb8 33. Nb1 Qb7 34. Nbd2 Qb8 35. Nb1 Qb7 36. Nbd2 Qb8 37. Nb1 Qb7 38. Nbd2 Qb8 39. Nb1 Qb7 40. Nbd2 Qb8 41. Nb1 Qb7 42. Nbd2 Qb8 43. Nb1 Qb7 44. Nbd2 Qb8 45. Nb1 Qb7 46. Nbd2 Qb8 47. Nb1 Qb7 48. Nbd2 Qb8 49. Nb1 Qb7 50. Nbd2 Qb8 51. Nb1 Qb7 52. Nbd2 Qb8 53. Nb1 Qb7 54. Nbd2 Qb8 55. Nb1 Qb7 56. Nbd2 Qb8 57. Nb1 Qb7 58. Nbd2 Qb8 59. Nb1 Qb7 60. Nbd2 Qb8 61. Nb1 Qb7 62. Nbd2 Qb8 63. Nb1 Qb7 64. Nbd2 Qb8 65. Nb1 Qb7 66. Nbd2 Qb8 67. Nb1 Qb7 68. Nbd2 Qb8 69. Nb1 Qb7 70. Nbd2 Qb8 71. Nb1 Qb7 72. Nbd2 Qb8 73. Nb1 Qb7 74. Nbd2 Qb8 75. Nb1 Qb7 76. Nbd2 Qb8 77. Nb1",
          "aggressive_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Nb4",
            "Bb1",
            "Bb7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Rfd8",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1",
            "Qb7",
            "Nbd2",
            "Qb8",
            "Nb1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Bb7 15. Be3 Rac8 16. Rc1 Qb8 17. dxe5 dxe5 18. Qxd8 Rfxd8 19. Nxe5 Nxe5 20. Bxe5 Rxc1 21. Rxc1 Bxe4 22. Bxf6 Bxf6 23. Rc7 Bxb2 24. Rb7 Bc3 25. Rxb5 Bxa1 26. Rxa5 Bc3 27. Ra7 Bb4 28. Rb7 Bc5 29. Rb5 Bb6 30. Rb7 Bc5 31. Rb5 Bb6 32. Rb7 Bc5 33. Rb5 Bb6 34. Rb7 Bc5 35. Rb5 Bb6 36. Rb7 Bc5 37. Rb5 Bb6 38. Rb7 Bc5 39. Rb5 Bb6 40. Rb7 Bc5 41. Rb5 Bb6 42. Rb7 Bc5 43. Rb5 Bb6 44. Rb7 Bc5 45. Rb5 Bb6 46. Rb7 Bc5 47. Rb5 Bb6 48. Rb7 Bc5 49. Rb5 Bb6 50. Rb7 Bc5 51. Rb5 Bb6 52. Rb7 Bc5 53. Rb5 Bb6 54. Rb7 Bc5 55. Rb5 Bb6 56. Rb7 Bc5 57. Rb5 Bb6 58. Rb7 Bc5 59. Rb5 Bb6 60. Rb7 Bc5 61. Rb5 Bb6 62. Rb7 Bc5 63. Rb5 Bb6 64. Rb7 Bc5 65. Rb5 Bb6 66. Rb7 Bc5 67. Rb5 Bb6 68. Rb7 Bc5 69. Rb5 Bb6 70. Rb7 Bc5 71. Rb5 Bb6 72. Rb7 Bc5 73. Rb5 Bb6 74. Rb7 Bc5 75. Rb5 Bb6 76. Rb7 Bc5 77. Rb5 Bb6 78. Rb7 Bc5 79. Rb5 Bb6",
          "positional_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Be3",
            "Rac8",
            "Rc1",
            "Qb8",
            "dxe5",
            "dxe5",
            "Qxd8",
            "Rfxd8",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "Rxc1",
            "Rxc1",
            "Bxe4",
            "Bxf6",
            "Bxf6",
            "Rc7",
            "Bxb2",
            "Rb7",
            "Bc3",
            "Rxb5",
            "Bxa1",
            "Rxa5",
            "Bc3",
            "Ra7",
            "Bb4",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6",
            "Rb7",
            "Bc5",
            "Rb5",
            "Bb6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Nb4 15. Bb1 Bb7 16. a3 Nc6 17. d5 Nb8 18. Be3 Qd7 19. Qd2 Rc8 20. Rac1 Rxc1 21. Rxc1 Rc8 22. Rxc8+ Qxc8 23. Qc3 Qxc3 24. bxc3 Na6 25. c4 bxc4 26. Nxc4 Nb4 27. Nd2 Bc8 28. Nb3 Bd7 29. Nc5 Bc8 30. Nb7 Bxb7 31. Bxb7 Nc2 32. Bxa6 Nxa3 33. Bb5 Nb1 34. Bc6 Nc3 35. Bxd6 Nxd5 36. exd5 exd5 37. Bxf8 Kxf8 38. Nc5 Ke7 39. Nxd7 Kxd7 40. Kf1 Ke6 41. Ke2 Kd5 42. Kd3 f5 43. f3 g5 44. g3 h5 45. h4 g4 46. fxg4 fxg4 47. Kc3 Kc5 48. Kb3 Kb5 49. Ka3 Ka5 50. Kb3 Kb5 51. Ka3 Ka5 52. Kb3 Kb5 53. Ka3 Ka5 54. Kb3 Kb5 55. Ka3 Ka5 56. Kb3 Kb5 57. Ka3 Ka5 58. Kb3 Kb5 59. Ka3 Ka5 60. Kb3 Kb5 61. Ka3 Ka5 62. Kb3 Kb5 63. Ka3 Ka5 64. Kb3 Kb5 65. Ka3 Ka5 66. Kb3 Kb5 67. Ka3 Ka5 68. Kb3 Kb5 69. Ka3 Ka5 70. Kb3 Kb5 71. Ka3 Ka5 72. Kb3 Kb5 73. Ka3 Ka5 74. Kb3 Kb5 75. Ka3 Ka5 76. Kb3 Kb5 77. Ka3 Ka5 78. Kb3 Kb5 79. Ka3 Ka5",
          "neutral_tokens": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Nb4",
            "Bb1",
            "Bb7",
            "a3",
            "Nc6",
            "d5",
            "Nb8",
            "Be3",
            "Qd7",
            "Qd2",
            "Rc8",
            "Rac1",
            "Rxc1",
            "Rxc1",
            "Rc8",
            "Rxc8+",
            "Qxc8",
            "Qc3",
            "Qxc3",
            "bxc3",
            "Na6",
            "c4",
            "bxc4",
            "Nxc4",
            "Nb4",
            "Nd2",
            "Bc8",
            "Nb3",
            "Bd7",
            "Nc5",
            "Bc8",
            "Nb7",
            "Bxb7",
            "Bxb7",
            "Nc2",
            "Bxa6",
            "Nxa3",
            "Bb5",
            "Nb1",
            "Bc6",
            "Nc3",
            "Bxd6",
            "Nxd5",
            "exd5",
            "exd5",
            "Bxf8",
            "Kxf8",
            "Nc5",
            "Ke7",
            "Nxd7",
            "Kxd7",
            "Kf1",
            "Ke6",
            "Ke2",
            "Kd5",
            "Kd3",
            "f5",
            "f3",
            "g5",
            "g3",
            "h5",
            "h4",
            "g4",
            "fxg4",
            "fxg4",
            "Kc3",
            "Kc5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5",
            "Kb3",
            "Kb5",
            "Ka3",
            "Ka5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Nb4",
              "Bb1",
              "Bb7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Rfd8",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1",
              "Qb7",
              "Nbd2",
              "Qb8",
              "Nb1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Be3",
              "Rac8",
              "Rc1",
              "Qb8",
              "dxe5",
              "dxe5",
              "Qxd8",
              "Rfxd8",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "Rxc1",
              "Rxc1",
              "Bxe4",
              "Bxf6",
              "Bxf6",
              "Rc7",
              "Bxb2",
              "Rb7",
              "Bc3",
              "Rxb5",
              "Bxa1",
              "Rxa5",
              "Bc3",
              "Ra7",
              "Bb4",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6",
              "Rb7",
              "Bc5",
              "Rb5",
              "Bb6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Nb4",
              "Bb1",
              "Bb7",
              "a3",
              "Nc6",
              "d5",
              "Nb8",
              "Be3",
              "Qd7",
              "Qd2",
              "Rc8",
              "Rac1",
              "Rxc1",
              "Rxc1",
              "Rc8",
              "Rxc8+",
              "Qxc8",
              "Qc3",
              "Qxc3",
              "bxc3",
              "Na6",
              "c4",
              "bxc4",
              "Nxc4",
              "Nb4",
              "Nd2",
              "Bc8",
              "Nb3",
              "Bd7",
              "Nc5",
              "Bc8",
              "Nb7",
              "Bxb7",
              "Bxb7",
              "Nc2",
              "Bxa6",
              "Nxa3",
              "Bb5",
              "Nb1",
              "Bc6",
              "Nc3",
              "Bxd6",
              "Nxd5",
              "exd5",
              "exd5",
              "Bxf8",
              "Kxf8",
              "Nc5",
              "Ke7",
              "Nxd7",
              "Kxd7",
              "Kf1",
              "Ke6",
              "Ke2",
              "Kd5",
              "Kd3",
              "f5",
              "f3",
              "g5",
              "g3",
              "h5",
              "h4",
              "g4",
              "fxg4",
              "fxg4",
              "Kc3",
              "Kc5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5",
              "Kb3",
              "Kb5",
              "Ka3",
              "Ka5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 335,
          "total_completion_tokens": 1920,
          "total_tokens": 2255
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Ng5 cxd4 cxd4 Nc6 Nxc6 Qxc6 Qf3 Be6 Rad1 Rfd8 Qg3 Rac8 Bb3 h6 Nf3 Qb6 Be3 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8 Qf4 Qb6 Qh4 Bg7 Qf4 Qb7 Qh4 Bf8",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Ng5",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nxc6",
            "Qxc6",
            "Qf3",
            "Be6",
            "Rad1",
            "Rfd8",
            "Qg3",
            "Rac8",
            "Bb3",
            "h6",
            "Nf3",
            "Qb6",
            "Be3",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8",
            "Qf4",
            "Qb6",
            "Qh4",
            "Bg7",
            "Qf4",
            "Qb7",
            "Qh4",
            "Bf8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4 e5 e5 e4 e4",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nb6 Nb3 Bg4 Be3 Rfc8 Rc1 Qb7 Qd3 Rac8 Rg1 Qa8 Qf1 Bxf3 Qxf3 Qb7 Qg3 Qxg3 fxg3 Nd7 Rcf1 Nf8 Bb1 Ne6 Bxe6 fxe6 Rxf8+ Kxf8 Rf1+ Ke8 Kg2 Kd7 Kf3 Kc6 Ke4 Kb6 Kd3 Kc6 Kc3 Kb6 Kb3 Kc6 a3 Kb6 a4 Kc6 a5 Kb5 axb6 Kxb6 b4 Kc6 Kc4 Kb6 c5+ dxc5 bxc5+ Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 Kxc5 K",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nb6",
            "Nb3",
            "Bg4",
            "Be3",
            "Rfc8",
            "Rc1",
            "Qb7",
            "Qd3",
            "Rac8",
            "Rg1",
            "Qa8",
            "Qf1",
            "Bxf3",
            "Qxf3",
            "Qb7",
            "Qg3",
            "Qxg3",
            "fxg3",
            "Nd7",
            "Rcf1",
            "Nf8",
            "Bb1",
            "Ne6",
            "Bxe6",
            "fxe6",
            "Rxf8+",
            "Kxf8",
            "Rf1+",
            "Ke8",
            "Kg2",
            "Kd7",
            "Kf3",
            "Kc6",
            "Ke4",
            "Kb6",
            "Kd3",
            "Kc6",
            "Kc3",
            "Kb6",
            "Kb3",
            "Kc6",
            "a3",
            "Kb6",
            "a4",
            "Kc6",
            "a5",
            "Kb5",
            "axb6",
            "Kxb6",
            "b4",
            "Kc6",
            "Kc4",
            "Kb6",
            "c5+",
            "dxc5",
            "bxc5+",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5",
            "Kxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Ng5",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nxc6",
              "Qxc6",
              "Qf3",
              "Be6",
              "Rad1",
              "Rfd8",
              "Qg3",
              "Rac8",
              "Bb3",
              "h6",
              "Nf3",
              "Qb6",
              "Be3",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8",
              "Qf4",
              "Qb6",
              "Qh4",
              "Bg7",
              "Qf4",
              "Qb7",
              "Qh4",
              "Bf8"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nb6",
              "Nb3",
              "Bg4",
              "Be3",
              "Rfc8",
              "Rc1",
              "Qb7",
              "Qd3",
              "Rac8",
              "Rg1",
              "Qa8",
              "Qf1",
              "Bxf3",
              "Qxf3",
              "Qb7",
              "Qg3",
              "Qxg3",
              "fxg3",
              "Nd7",
              "Rcf1",
              "Nf8",
              "Bb1",
              "Ne6",
              "Bxe6",
              "fxe6",
              "Rxf8+",
              "Kxf8",
              "Rf1+",
              "Ke8",
              "Kg2",
              "Kd7",
              "Kf3",
              "Kc6",
              "Ke4",
              "Kb6",
              "Kd3",
              "Kc6",
              "Kc3",
              "Kb6",
              "Kb3",
              "Kc6",
              "a3",
              "Kb6",
              "a4",
              "Kc6",
              "a5",
              "Kb5",
              "axb6",
              "Kxb6",
              "b4",
              "Kc6",
              "Kc4",
              "Kb6",
              "c5+",
              "dxc5",
              "bxc5+",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5",
              "Kxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 1920,
          "total_tokens": 2273
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 *\ne4 e5 Nf3 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Nbd2 Rac8 Nb1 Rfe8 Nc3 Bf8 Nb5 Qb8 Be3 Nb4 Bxb4 Qxb4 a3 Qb6 Qd3 g6 Rac1 Qd8 Rxc8 Qxc8 Qc2 Qxc2 Bxc2 Rc8 Bb3 Rc3 Bd1 Kf8 f3 Ke8 Kf2 Kd7 Ke2 Kc7 Kd2 Kb6 Kc2 Ka5 Kb2 Kb4 a4 Kc4 Bc2 Kd4 Bb3 Ke3 Bc2 Kf4 Bb3 Kg3 Bc2 Kh4 Bb3 Kh5 Bc2 Kh6 Bb3 Kg7 Bc2 Kf8 Bb3 Ke8 Bc2 Kd7 Bb3 Kc7 Bc2 Kb6 Bb3 Ka5 Bc2 Kb4 a5 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 a6 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 a7 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 a8=Q Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf4 Bc2 Kg3 Bb3 Kh4 Bc2 Kh5 Bb3 Kh6 Bc2 Kg7 Bb3 Kf8 Bc2 Ke8 Bb3 Kd7 Bc2 Kc7 Bb3 Kb6 Bc2 Ka5 Bb3 Kb4 Qa7 Kc4 Bb3 Kd4 Bc2 Ke3 Bb3 Kf",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Rfe8",
            "Nc3",
            "Bf8",
            "Nb5",
            "Qb8",
            "Be3",
            "Nb4",
            "Bxb4",
            "Qxb4",
            "a3",
            "Qb6",
            "Qd3",
            "g6",
            "Rac1",
            "Qd8",
            "Rxc8",
            "Qxc8",
            "Qc2",
            "Qxc2",
            "Bxc2",
            "Rc8",
            "Bb3",
            "Rc3",
            "Bd1",
            "Kf8",
            "f3",
            "Ke8",
            "Kf2",
            "Kd7",
            "Ke2",
            "Kc7",
            "Kd2",
            "Kb6",
            "Kc2",
            "Ka5",
            "Kb2",
            "Kb4",
            "a4",
            "Kc4",
            "Bc2",
            "Kd4",
            "Bb3",
            "Ke3",
            "Bc2",
            "Kf4",
            "Bb3",
            "Kg3",
            "Bc2",
            "Kh4",
            "Bb3",
            "Kh5",
            "Bc2",
            "Kh6",
            "Bb3",
            "Kg7",
            "Bc2",
            "Kf8",
            "Bb3",
            "Ke8",
            "Bc2",
            "Kd7",
            "Bb3",
            "Kc7",
            "Bc2",
            "Kb6",
            "Bb3",
            "Ka5",
            "Bc2",
            "Kb4",
            "a5",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "a6",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "a7",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "a8=Q",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3",
            "Kf4",
            "Bc2",
            "Kg3",
            "Bb3",
            "Kh4",
            "Bc2",
            "Kh5",
            "Bb3",
            "Kh6",
            "Bc2",
            "Kg7",
            "Bb3",
            "Kf8",
            "Bc2",
            "Ke8",
            "Bb3",
            "Kd7",
            "Bc2",
            "Kc7",
            "Bb3",
            "Kb6",
            "Bc2",
            "Ka5",
            "Bb3",
            "Kb4",
            "Qa7",
            "Kc4",
            "Bb3",
            "Kd4",
            "Bc2",
            "Ke3",
            "Bb3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 exd4 Nb3 Nxb3 axb3 Bb7 Nxd4 Rfe8 Nf5 Bf8 Bd3 g6 Nh6+ Kg7 Qf3 Bg7 Qg3 Qf4 Qxf4 Bxf4 Bxf4 Nxe4 Bxe4 Rxe4 Rxe4 Bxe4 Re1 Bf5 Re7+ Kg8 Rxh7 Be6 Rh8+ Kxh8 Bg5 Kg7 Bf6+ Kg8 Be7 Kf7 Bxd6 Ke6 Bc5 Kd5 Bxb7 Kc4 Bxa6 Kb3 Bxb5 Ka3 Bc4 Kb2 Bd3 Kc3 Be4 Kd2 Bf5 Ke3 Bg6 Kf4 Bh5 Kg5 Bg6 Kh6 Bf7+ Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh7 Bg8# Kh8 Bf7# Kh",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "exd4",
            "Nb3",
            "Nxb3",
            "axb3",
            "Bb7",
            "Nxd4",
            "Rfe8",
            "Nf5",
            "Bf8",
            "Bd3",
            "g6",
            "Nh6+",
            "Kg7",
            "Qf3",
            "Bg7",
            "Qg3",
            "Qf4",
            "Qxf4",
            "Bxf4",
            "Bxf4",
            "Nxe4",
            "Bxe4",
            "Rxe4",
            "Rxe4",
            "Bxe4",
            "Re1",
            "Bf5",
            "Re7+",
            "Kg8",
            "Rxh7",
            "Be6",
            "Rh8+",
            "Kxh8",
            "Bg5",
            "Kg7",
            "Bf6+",
            "Kg8",
            "Be7",
            "Kf7",
            "Bxd6",
            "Ke6",
            "Bc5",
            "Kd5",
            "Bxb7",
            "Kc4",
            "Bxa6",
            "Kb3",
            "Bxb5",
            "Ka3",
            "Bc4",
            "Kb2",
            "Bd3",
            "Kc3",
            "Be4",
            "Kd2",
            "Bf5",
            "Ke3",
            "Bg6",
            "Kf4",
            "Bh5",
            "Kg5",
            "Bg6",
            "Kh6",
            "Bf7+",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#",
            "Kh7",
            "Bg8#",
            "Kh8",
            "Bf7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Rfe8",
              "Nc3",
              "Bf8",
              "Nb5",
              "Qb8",
              "Be3",
              "Nb4",
              "Bxb4",
              "Qxb4",
              "a3",
              "Qb6",
              "Qd3",
              "g6",
              "Rac1",
              "Qd8",
              "Rxc8",
              "Qxc8",
              "Qc2",
              "Qxc2",
              "Bxc2",
              "Rc8",
              "Bb3",
              "Rc3",
              "Bd1",
              "Kf8",
              "f3",
              "Ke8",
              "Kf2",
              "Kd7",
              "Ke2",
              "Kc7",
              "Kd2",
              "Kb6",
              "Kc2",
              "Ka5",
              "Kb2",
              "Kb4",
              "a4",
              "Kc4",
              "Bc2",
              "Kd4",
              "Bb3",
              "Ke3",
              "Bc2",
              "Kf4",
              "Bb3",
              "Kg3",
              "Bc2",
              "Kh4",
              "Bb3",
              "Kh5",
              "Bc2",
              "Kh6",
              "Bb3",
              "Kg7",
              "Bc2",
              "Kf8",
              "Bb3",
              "Ke8",
              "Bc2",
              "Kd7",
              "Bb3",
              "Kc7",
              "Bc2",
              "Kb6",
              "Bb3",
              "Ka5",
              "Bc2",
              "Kb4",
              "a5",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "a6",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "a7",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "a8=Q",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3",
              "Kf4",
              "Bc2",
              "Kg3",
              "Bb3",
              "Kh4",
              "Bc2",
              "Kh5",
              "Bb3",
              "Kh6",
              "Bc2",
              "Kg7",
              "Bb3",
              "Kf8",
              "Bc2",
              "Ke8",
              "Bb3",
              "Kd7",
              "Bc2",
              "Kc7",
              "Bb3",
              "Kb6",
              "Bc2",
              "Ka5",
              "Bb3",
              "Kb4",
              "Qa7",
              "Kc4",
              "Bb3",
              "Kd4",
              "Bc2",
              "Ke3",
              "Bb3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "exd4",
              "Nb3",
              "Nxb3",
              "axb3",
              "Bb7",
              "Nxd4",
              "Rfe8",
              "Nf5",
              "Bf8",
              "Bd3",
              "g6",
              "Nh6+",
              "Kg7",
              "Qf3",
              "Bg7",
              "Qg3",
              "Qf4",
              "Qxf4",
              "Bxf4",
              "Bxf4",
              "Nxe4",
              "Bxe4",
              "Rxe4",
              "Rxe4",
              "Bxe4",
              "Re1",
              "Bf5",
              "Re7+",
              "Kg8",
              "Rxh7",
              "Be6",
              "Rh8+",
              "Kxh8",
              "Bg5",
              "Kg7",
              "Bf6+",
              "Kg8",
              "Be7",
              "Kf7",
              "Bxd6",
              "Ke6",
              "Bc5",
              "Kd5",
              "Bxb7",
              "Kc4",
              "Bxa6",
              "Kb3",
              "Bxb5",
              "Ka3",
              "Bc4",
              "Kb2",
              "Bd3",
              "Kc3",
              "Be4",
              "Kd2",
              "Bf5",
              "Ke3",
              "Bg6",
              "Kf4",
              "Bh5",
              "Kg5",
              "Bg6",
              "Kh6",
              "Bf7+",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#",
              "Kh7",
              "Bg8#",
              "Kh8",
              "Bf7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 1298,
          "total_tokens": 1651
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 640,
            "total_tokens": 757,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Nbd2 Rac8 Nb1 Nb4 Bb1 Rfe8 Nbd2 Bf8 Nb1 g6 Nbd2 Bg7 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc7 Nbd2 Rac8 Nb1 Qb6 Nbd2 Rac8 Nb1 Qc",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Nb4",
            "Bb1",
            "Rfe8",
            "Nbd2",
            "Bf8",
            "Nb1",
            "g6",
            "Nbd2",
            "Bg7",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qc7",
            "Nbd2",
            "Rac8",
            "Nb1",
            "Qb6",
            "Nbd2",
            "Rac8",
            "Nb1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 d6 c3 O-O h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Bd3 exd4 Nfxd4 Nxd4 Nxd4 Qb6 Be3 Rfe8 Qf3 Bf8 Rac1 Rac8 Rxc8 Rxc8 Rc1 Rxc1 Qxc1 Qc7 Qxc7 Bxc7 Kf1 Kf8 Ke2 Ke7 Kd3 Kd7 Kc4 Bb6 f3 f6 g4 g5 Kb5 Bc7 Ka6 Kc6 Ka7 Bb6+ Ka6 Bc7\nKa6 Bc7 Ka7 Bb6+ Ka6 Bc7",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 202,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Bd3",
            "exd4",
            "Nfxd4",
            "Nxd4",
            "Nxd4",
            "Qb6",
            "Be3",
            "Rfe8",
            "Qf3",
            "Bf8",
            "Rac1",
            "Rac8",
            "Rxc8",
            "Rxc8",
            "Rc1",
            "Rxc1",
            "Qxc1",
            "Qc7",
            "Qxc7",
            "Bxc7",
            "Kf1",
            "Kf8",
            "Ke2",
            "Ke7",
            "Kd3",
            "Kd7",
            "Kc4",
            "Bb6",
            "f3",
            "f6",
            "g4",
            "g5",
            "Kb5",
            "Bc7",
            "Ka6",
            "Kc6",
            "Ka7",
            "Bb6+",
            "Ka6",
            "Bc7",
            "Ka6",
            "Bc7",
            "Ka7",
            "Bb6+",
            "Ka6",
            "Bc7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Nb4",
              "Bb1",
              "Rfe8",
              "Nbd2",
              "Bf8",
              "Nb1",
              "g6",
              "Nbd2",
              "Bg7",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qc7",
              "Nbd2",
              "Rac8",
              "Nb1",
              "Qb6",
              "Nbd2",
              "Rac8",
              "Nb1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Bd3",
              "exd4",
              "Nfxd4",
              "Nxd4",
              "Nxd4",
              "Qb6",
              "Be3",
              "Rfe8",
              "Qf3",
              "Bf8",
              "Rac1",
              "Rac8",
              "Rxc8",
              "Rxc8",
              "Rc1",
              "Rxc1",
              "Qxc1",
              "Qc7",
              "Qxc7",
              "Bxc7",
              "Kf1",
              "Kf8",
              "Ke2",
              "Ke7",
              "Kd3",
              "Kd7",
              "Kc4",
              "Bb6",
              "f3",
              "f6",
              "g4",
              "g5",
              "Kb5",
              "Bc7",
              "Ka6",
              "Kc6",
              "Ka7",
              "Bb6+",
              "Ka6",
              "Bc7",
              "Ka6",
              "Bc7",
              "Ka7",
              "Bb6+",
              "Ka6",
              "Bc7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 202,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 860,
          "total_tokens": 1213
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 202,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 *\ne4 e5 Nf3",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 13,
            "total_tokens": 129,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 * e5 Nf3 Nc6\ne5 Nf3 Nc6",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 23,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1. e4 * e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Bb7 Bd3 Rac8 Qe2 exd4 Nfxd4 Nxd4 Nxd4 Bxd4 Qxe7 Qxe7 Rxe7 Bxc3 bxc3 Rxc3 Bb2 Rfc8 Rac1 Rxc1 Rxc1 Rxc1+ Bxc1 Kf8 f3 Ke7 Kf2 Kd7 Ke3 Kc6 Kd4 Kb5 Kc3 Ka4 Kb2 Kb4 Ka2 Kc3 Ka3 Kb1 Kb3 Kc1 Kc3 Kd1 Kd3 Ke1 Ke3 Kf1 Kf3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh1 Kh3 Kg1 Kg3 Kh",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Bd3",
            "Rac8",
            "Qe2",
            "exd4",
            "Nfxd4",
            "Nxd4",
            "Nxd4",
            "Bxd4",
            "Qxe7",
            "Qxe7",
            "Rxe7",
            "Bxc3",
            "bxc3",
            "Rxc3",
            "Bb2",
            "Rfc8",
            "Rac1",
            "Rxc1",
            "Rxc1",
            "Rxc1+",
            "Bxc1",
            "Kf8",
            "f3",
            "Ke7",
            "Kf2",
            "Kd7",
            "Ke3",
            "Kc6",
            "Kd4",
            "Kb5",
            "Kc3",
            "Ka4",
            "Kb2",
            "Kb4",
            "Ka2",
            "Kc3",
            "Ka3",
            "Kb1",
            "Kb3",
            "Kc1",
            "Kc3",
            "Kd1",
            "Kd3",
            "Ke1",
            "Ke3",
            "Kf1",
            "Kf3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3",
            "Kh1",
            "Kh3",
            "Kg1",
            "Kg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Bd3",
              "Rac8",
              "Qe2",
              "exd4",
              "Nfxd4",
              "Nxd4",
              "Nxd4",
              "Bxd4",
              "Qxe7",
              "Qxe7",
              "Rxe7",
              "Bxc3",
              "bxc3",
              "Rxc3",
              "Bb2",
              "Rfc8",
              "Rac1",
              "Rxc1",
              "Rxc1",
              "Rxc1+",
              "Bxc1",
              "Kf8",
              "f3",
              "Ke7",
              "Kf2",
              "Kd7",
              "Ke3",
              "Kc6",
              "Kd4",
              "Kb5",
              "Kc3",
              "Ka4",
              "Kb2",
              "Kb4",
              "Ka2",
              "Kc3",
              "Ka3",
              "Kb1",
              "Kb3",
              "Kc1",
              "Kc3",
              "Kd1",
              "Kd3",
              "Ke1",
              "Ke3",
              "Kf1",
              "Kf3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3",
              "Kh1",
              "Kh3",
              "Kg1",
              "Kg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 13,
            "total_tokens": 129,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 23,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 676,
          "total_tokens": 1023
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 13,
            "total_tokens": 129,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 23,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "1. e4 e5 2. Nf3 * Nc6 3. Bb5\nNc6 Bb5",
          "aggressive_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "1. e4 e5 2. Nf3 * Nc6 3. Bb5\nNc6 Bb5",
          "positional_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "1. e4 e5 2. Nf3 * Nc6 Nf6 d4",
          "neutral_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 22,
            "total_tokens": 145,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "d4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 123,
            "completion_tokens": 22,
            "total_tokens": 145,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 371,
          "total_completion_tokens": 82,
          "total_tokens": 453
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 123,
            "completion_tokens": 22,
            "total_tokens": 145,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5\nWhite a6",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 26,
            "total_tokens": 159,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\nBa4 Nf6 O-O Be7",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 49,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a7a6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O\nWhite Black White Black White",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 43,
            "total_tokens": 175,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "a7a6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 26,
            "total_tokens": 159,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 49,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 43,
            "total_tokens": 175,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 118,
          "total_tokens": 516
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 26,
            "total_tokens": 159,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 49,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 43,
            "total_tokens": 175,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxc6",
          "aggressive_uci": "d7c6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. O-O f6 6. d4 *",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 46,
            "total_tokens": 187,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "f6",
            "d4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxc6",
          "positional_uci": "d7c6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. O-O f6 6. d4 Bg4",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 48,
            "total_tokens": 189,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "f6",
            "d4",
            "Bg4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxc6",
          "neutral_uci": "d7c6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. O-O f6 6. d4",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "f6",
            "d4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7c6",
          "positional_uci": "d7c6",
          "neutral_uci": "d7c6",
          "consensus_move": "d7c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "f6",
              "d4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "f6",
              "d4",
              "Bg4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "f6",
              "d4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 46,
            "total_tokens": 187,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 48,
            "total_tokens": 189,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 139,
          "total_tokens": 561
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 46,
            "total_tokens": 187,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 48,
            "total_tokens": 189,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1B5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qd4",
          "aggressive_uci": "d8d4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be2",
          "aggressive_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qxe4+",
            "Be2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd4",
          "positional_uci": "d8d4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2",
          "positional_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 58,
            "total_tokens": 208,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qxe4+",
            "Qe2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qd4",
          "neutral_uci": "d8d4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be3",
          "neutral_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 57,
            "total_tokens": 206,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qxe4+",
            "Be3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8d4",
          "positional_uci": "d8d4",
          "neutral_uci": "d8d4",
          "consensus_move": "d8d4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Qxe4+",
              "Be2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Qxe4+",
              "Qe2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf3",
              "Qxe4+",
              "Be3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 150,
            "completion_tokens": 58,
            "total_tokens": 208,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 149,
            "completion_tokens": 57,
            "total_tokens": 206,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 449,
          "total_completion_tokens": 172,
          "total_tokens": 621
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 150,
            "completion_tokens": 58,
            "total_tokens": 208,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 149,
            "completion_tokens": 57,
            "total_tokens": 206,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1pp2ppp/p1p5/4N3/4P3/8/PPPP1PPP/RNBQK2R b KQkq - 0 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe4+",
          "aggressive_uci": "d4e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be2 Bg4 8. O-O",
          "aggressive_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Bg4",
            "O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe4+",
          "positional_uci": "d4e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be3 Bg4 8. O-O",
          "positional_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be3",
            "Bg4",
            "O-O"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe4+",
          "neutral_uci": "d4e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2 * Qxe2+ Kxe2 Bg4",
          "neutral_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 79,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Qxe2+",
            "Kxe2",
            "Bg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4e4",
          "positional_uci": "d4e4",
          "neutral_uci": "d4e4",
          "consensus_move": "d4e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be2",
              "Bg4",
              "O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be3",
              "Bg4",
              "O-O"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Qxe2+",
              "Kxe2",
              "Bg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 158,
            "completion_tokens": 79,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 476,
          "total_completion_tokens": 209,
          "total_tokens": 685
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 159,
            "completion_tokens": 65,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 158,
            "completion_tokens": 79,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/3qP3/5N2/PPPP1PPP/RNBQK2R b KQkq - 2 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be6",
          "aggressive_uci": "c8e6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Be6 8. d3 Qf5 9. Be3\nBe6 d3 Be3",
          "aggressive_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 80,
            "total_tokens": 249,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Be3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qf5",
          "positional_uci": "e4f5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Be6 9. Be3\nQf5 d3 Be6 Be3",
          "positional_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 83,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Be6",
            "Be3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxf3+",
          "neutral_uci": "e4f3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 * Qxf3+ gxf3 Be6",
          "neutral_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 68,
            "total_tokens": 236,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf3",
            "Be6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8e6",
          "positional_uci": "e4f5",
          "neutral_uci": "e4f3",
          "consensus_move": "e4f3",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d3",
              "Be3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d3",
              "Be6",
              "Be3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf3",
              "Be6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 169,
            "completion_tokens": 80,
            "total_tokens": 249,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 169,
            "completion_tokens": 83,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 168,
            "completion_tokens": 68,
            "total_tokens": 236,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 506,
          "total_completion_tokens": 231,
          "total_tokens": 737
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 169,
            "completion_tokens": 80,
            "total_tokens": 249,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 169,
            "completion_tokens": 83,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 168,
            "completion_tokens": 68,
            "total_tokens": 236,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQ1K1R b kq - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g3",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 * g3 Bg4 9. h3 Bh5",
          "aggressive_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 80,
            "total_tokens": 258,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "h3",
            "Bh5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg4",
          "positional_uci": "c8g4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qg3 Bh5 10. d3\nBg4 Qg3 Bh5 d3",
          "positional_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 93,
            "total_tokens": 271,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg3",
            "Bh5",
            "d3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g3",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 * g3 Bg4 Kg2",
          "neutral_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 75,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "Kg2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "c8g4",
          "neutral_uci": null,
          "consensus_move": "c8g4",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg4",
              "h3",
              "Bh5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qg3",
              "Bh5",
              "d3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bg4",
              "Kg2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 178,
            "completion_tokens": 80,
            "total_tokens": 258,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 178,
            "completion_tokens": 93,
            "total_tokens": 271,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 177,
            "completion_tokens": 75,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 533,
          "total_completion_tokens": 248,
          "total_tokens": 781
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 178,
            "completion_tokens": 80,
            "total_tokens": 258,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 178,
            "completion_tokens": 93,
            "total_tokens": 271,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 177,
            "completion_tokens": 75,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/8/5Q2/PPPP1PPP/RNB2K1R b kq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxg4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 * Qxg4 10. h3 h5 11. d3",
          "aggressive_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 92,
            "total_tokens": 279,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "h5",
            "d3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qf3 O-O 11. d3\n10. Qf3 O-O 11. d3",
          "positional_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 105,
            "total_tokens": 292,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "O-O",
            "d3",
            "Qf3",
            "O-O",
            "d3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 *\nBlack Nf6 h5 Qf6",
          "neutral_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h5",
            "Qf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h3",
              "h5",
              "d3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf3",
              "O-O",
              "d3",
              "Qf3",
              "O-O",
              "d3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h5",
              "Qf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 187,
            "completion_tokens": 92,
            "total_tokens": 279,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 187,
            "completion_tokens": 105,
            "total_tokens": 292,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 560,
          "total_completion_tokens": 283,
          "total_tokens": 843
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 187,
            "completion_tokens": 92,
            "total_tokens": 279,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 187,
            "completion_tokens": 105,
            "total_tokens": 292,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3kbnr/1pp2ppp/p1p5/8/6Q1/8/PPPP1PPP/RNB2K1R b kq - 0 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. Qxe7+ Kxe7 12. Re1+",
          "aggressive_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7+",
            "Kxe7",
            "Re1+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. Qxe7+ Kxe7 12. Re1+",
          "positional_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7+",
            "Kxe7",
            "Re1+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. Qxe7+ Kxe7 12. d3\nBe7 Kxe7 d3",
          "neutral_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 111,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxe7",
            "d3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe7+",
              "Kxe7",
              "Re1+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxe7+",
              "Kxe7",
              "Re1+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxe7",
              "d3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 196,
            "completion_tokens": 111,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 590,
          "total_completion_tokens": 319,
          "total_tokens": 909
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 197,
            "completion_tokens": 104,
            "total_tokens": 301,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 196,
            "completion_tokens": 111,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3kb1r/1pp2ppp/p1p2n2/8/8/8/PPPPQPPP/RNB2K1R b kq - 2 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 * \nBe7 Qe2+ Be7",
          "aggressive_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 103,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Be3 Rfe8 13. Nd2\nO-O Rfe8 Nd2",
          "positional_tokens": {
            "prompt_tokens": 204,
            "completion_tokens": 116,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rfe8",
            "Nd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 *\nBe7 O-O Bg5",
          "neutral_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 101,
            "total_tokens": 304,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e8g8",
          "neutral_uci": null,
          "consensus_move": "e8g8",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Rfe8",
              "Nd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Bg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 204,
            "completion_tokens": 103,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 204,
            "completion_tokens": 116,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 203,
            "completion_tokens": 101,
            "total_tokens": 304,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 611,
          "total_completion_tokens": 320,
          "total_tokens": 931
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 204,
            "completion_tokens": 103,
            "total_tokens": 307,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 204,
            "completion_tokens": 116,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 203,
            "completion_tokens": 101,
            "total_tokens": 304,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3k2r/1pp1bppp/p1p2n2/8/8/3P4/PPP1QPPP/RNB2K1R b kq - 0 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 *\n* Qe7 Qxe7 13. Bg5 Qd7 14. Nc3",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 124,
            "total_tokens": 336,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7",
            "Bg5",
            "Qd7",
            "Nc3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe7",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 *\nQxe7 Qd7 Qe8",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 111,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd7",
            "Qe8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qd8",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 *\nBlack Qd8 Qd7 Qxd3",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 112,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd7",
            "Qxd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe7",
              "Bg5",
              "Qd7",
              "Nc3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd7",
              "Qe8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd7",
              "Qxd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 124,
            "total_tokens": 336,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 111,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 112,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 347,
          "total_tokens": 982
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 124,
            "total_tokens": 336,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 111,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 112,
            "total_tokens": 323,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp1Qppp/p1p2n2/8/8/3P4/PPP2PPP/RNB2K1R b - - 0 12"
    },
    {
      "turn": 24,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 * Qxe7 13. Bg5 Rfe8 14. Bxf6",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 120,
            "total_tokens": 332,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg5",
            "Rfe8",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe7",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 * Qe7 Re8 Qxe7\nWhite Re8 Qxe7",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 117,
            "total_tokens": 329,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Qxe7",
            "Re8",
            "Qxe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nd5",
          "neutral_uci": "f6d5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qd7 Rfe8 14. Qxc7\nNd5 Qd7 Rfe8 Qxc7",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 130,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd7",
            "Rfe8",
            "Qxc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": "f6d5",
          "consensus_move": "f6d5",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg5",
              "Rfe8",
              "Bxf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Qxe7",
              "Re8",
              "Qxe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd7",
              "Rfe8",
              "Qxc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 120,
            "total_tokens": 332,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 117,
            "total_tokens": 329,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 130,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 367,
          "total_tokens": 1002
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 120,
            "total_tokens": 332,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 117,
            "total_tokens": 329,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 130,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp1Qppp/p1p2n2/8/8/3P4/PPP2PPP/RNB2K1R b - - 0 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe2",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 * \nWhite Qe2 Qd2 Qxd5",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 121,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd2",
            "Qxd5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf4",
          "positional_uci": "d5f4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Qf3 Rae8 15. Qxf4\n13. Qe2 Nf4 14. Qf3 Rae8 15. Qxf4",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 149,
            "total_tokens": 369,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rae8",
            "Qxf4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe2",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 *\nWhite: Qe2 Nd5 14. Qe4",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 123,
            "total_tokens": 342,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd5",
            "Qe4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "d5f4",
          "neutral_uci": null,
          "consensus_move": "d5f4",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd2",
              "Qxd5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf3",
              "Rae8",
              "Qxf4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nd5",
              "Qe4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 121,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 149,
            "total_tokens": 369,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 123,
            "total_tokens": 342,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 393,
          "total_tokens": 1052
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 121,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 149,
            "total_tokens": 369,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 123,
            "total_tokens": 342,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp2ppp/p1p5/3n4/8/3P4/PPP1QPPP/RNB2K1R b - - 2 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rfe8",
          "aggressive_uci": "f8e8",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Bg3 f5 16. h3",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 134,
            "total_tokens": 363,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg3",
            "f5",
            "h3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxf4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rxf4 15. Qe3 Rf5 16. g3\nRf5 g3 Qe3",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 144,
            "total_tokens": 373,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe3",
            "Rf5",
            "g3",
            "Rf5",
            "g3",
            "Qe3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxf4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rxf4 15. Qe3 Rf6 16. Qd2\nRf6 Qe3 Qd2",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe3",
            "Rf6",
            "Qd2",
            "Rf6",
            "Qe3",
            "Qd2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8e8",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "f8e8",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg3",
              "f5",
              "h3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe3",
              "Rf5",
              "g3",
              "Rf5",
              "g3",
              "Qe3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe3",
              "Rf6",
              "Qd2",
              "Rf6",
              "Qe3",
              "Qd2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 134,
            "total_tokens": 363,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 144,
            "total_tokens": 373,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 424,
          "total_tokens": 1110
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 134,
            "total_tokens": 363,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 144,
            "total_tokens": 373,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/1pp2ppp/p1p5/8/5B2/3P4/PPP1QPPP/RN3K1R b - - 0 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rae8",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 Rae8 16. Qh5 g6 17. Qh6\nBlack Rae8 Qh5 g6 Qh6",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 155,
            "total_tokens": 393,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh5",
            "g6",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rae8",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 Rae8 16. Qf3 Rxe4 17. Qxf6\nQg4 Rae8 Qf3 Rxe4 Qxf6",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 158,
            "total_tokens": 396,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rxe4",
            "Qxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxg4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 Qxg4 16. h3 Qh5 17. g4",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Qh5",
            "g4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh5",
              "g6",
              "Qh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf3",
              "Rxe4",
              "Qxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h3",
              "Qh5",
              "g4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 155,
            "total_tokens": 393,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 158,
            "total_tokens": 396,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 456,
          "total_tokens": 1169
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 155,
            "total_tokens": 393,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 158,
            "total_tokens": 396,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2ppp/p1p5/8/5BQ1/3P4/PPP2PPP/RN3K1R b - - 2 15"
    },
    {
      "turn": 30,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rae8",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 Rae8 16. Qh5 g6 17. Qh6",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 143,
            "total_tokens": 381,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh5",
            "g6",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h5",
          "positional_uci": "h7h5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qh3 h4 17. g3\nh5 Qh3 g3",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 150,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh3",
            "g3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxg4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 Qxg4 16. h3 Qh5 17. g4",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Qh5",
            "g4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "h7h5",
          "neutral_uci": null,
          "consensus_move": "h7h5",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh5",
              "g6",
              "Qh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qh3",
              "g3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h3",
              "Qh5",
              "g4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 143,
            "total_tokens": 381,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 150,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 436,
          "total_tokens": 1149
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 143,
            "total_tokens": 381,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 150,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 143,
            "total_tokens": 380,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2ppp/p1p5/8/5BQ1/3P4/PPP2PPP/RN3K1R b - - 2 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g6",
          "aggressive_uci": "g7g6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qg5 f6 18. Qh6",
          "aggressive_tokens": {
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg5",
            "f6",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g6",
          "positional_uci": "g7g6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qg5 f6 18. Qh6",
          "positional_tokens": {
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg5",
            "f6",
            "Qh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g6",
          "neutral_uci": "g7g6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 Qg5 Rae8",
          "neutral_tokens": {
            "prompt_tokens": 245,
            "completion_tokens": 142,
            "total_tokens": 387,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg5",
            "Rae8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g7g6",
          "positional_uci": "g7g6",
          "neutral_uci": "g7g6",
          "consensus_move": "g7g6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qg5",
              "f6",
              "Qh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qg5",
              "f6",
              "Qh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qg5",
              "Rae8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 245,
            "completion_tokens": 142,
            "total_tokens": 387,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 737,
          "total_completion_tokens": 444,
          "total_tokens": 1181
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 246,
            "completion_tokens": 151,
            "total_tokens": 397,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 245,
            "completion_tokens": 142,
            "total_tokens": 387,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2pp1/p1p5/7Q/5B2/3P4/PPP2PPP/RN3K1R b - - 0 16"
    },
    {
      "turn": 34,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh8",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh8 Qxh8 Rxh8",
          "aggressive_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh8",
            "Rxh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qh8",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh8 18. Qxh8 Rxh8 19. g3\nQh8 Rxh8 g3",
          "positional_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 169,
            "total_tokens": 423,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxh8",
            "g3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh6 Qg7 Qh7",
          "neutral_tokens": {
            "prompt_tokens": 253,
            "completion_tokens": 152,
            "total_tokens": 405,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg7",
            "Qh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxh8",
              "Rxh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxh8",
              "g3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qg7",
              "Qh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 254,
            "completion_tokens": 169,
            "total_tokens": 423,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 253,
            "completion_tokens": 152,
            "total_tokens": 405,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 761,
          "total_completion_tokens": 473,
          "total_tokens": 1234
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 254,
            "completion_tokens": 169,
            "total_tokens": 423,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 253,
            "completion_tokens": 152,
            "total_tokens": 405,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2p2/p1p3pQ/8/5B2/3P4/PPP2PPP/RN3K1R b - - 1 17"
    },
    {
      "turn": 34,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh6",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh6 18. Bg5 Qg7 19. Bh6",
          "aggressive_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg5",
            "Qg7",
            "Bh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qh6",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh6 18. Bg5 Qg7 19. h4",
          "positional_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg5",
            "Qg7",
            "h4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 * Qh6 Qxh6 gxh5",
          "neutral_tokens": {
            "prompt_tokens": 253,
            "completion_tokens": 153,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh6",
            "gxh5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg5",
              "Qg7",
              "Bh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bg5",
              "Qg7",
              "h4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxh6",
              "gxh5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 253,
            "completion_tokens": 153,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 761,
          "total_completion_tokens": 473,
          "total_tokens": 1234
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 253,
            "completion_tokens": 153,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2p2/p1p3pQ/8/5B2/3P4/PPP2PPP/RN3K1R b - - 1 17"
    },
    {
      "turn": 34,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qf6",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qf6 18. Qxf6 Bxf6 19. g3",
          "aggressive_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf6",
            "Bxf6",
            "g3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qh8",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3 8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14. Bxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh8 18. Qxh8+ Kxh8 19. g3\nQh8 Qxh8+ Kxh8 g3",
          "positional_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 174,
            "total_tokens": 428,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh8+",
            "Kxh8",
            "g3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qxf3\n8. Qxf3 Bg4 9. Qxg4 Nf6 10. Qe2+ Be7 11. d3 O-O 12. Qxe7 Nd5 13. Qe2 Nf4 14.\nBxf4 Rfe8 15. Qg4 h5 16. Qxh5 g6 17. Qh6 Qh6 18. Bxh6 Re1+ 19. Kg2",
          "neutral_tokens": {
            "prompt_tokens": 253,
            "completion_tokens": 160,
            "total_tokens": 413,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxh6",
            "Re1+",
            "Kg2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxf6",
              "Bxf6",
              "g3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxh8+",
              "Kxh8",
              "g3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxh6",
              "Re1+",
              "Kg2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 254,
            "completion_tokens": 174,
            "total_tokens": 428,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 253,
            "completion_tokens": 160,
            "total_tokens": 413,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 761,
          "total_completion_tokens": 494,
          "total_tokens": 1255
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 254,
            "completion_tokens": 160,
            "total_tokens": 414,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 254,
            "completion_tokens": 174,
            "total_tokens": 428,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 253,
            "completion_tokens": 160,
            "total_tokens": 413,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3r1k1/1pp2p2/p1p3pQ/8/5B2/3P4/PPP2PPP/RN3K1R b - - 1 17"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d6 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Bb7 15. Be3 Rac8 16. Rc1 Nb4 17. Bb1 Rfd8 18. a3 Nc6 19. dxe5 dxe5 20. Qxd8+ Rxd8 21. Nxe5 Bxe4 22. Nxc6 Bxc6 23. Rxc6 Rxd1+ 24. Bxd1 Nd5 25. Rc7 Bf6 26. f3 g6 27. Kf2 Kg7 28. Ke2 Ne3 29. Bxe3 Bxe3 30. Kxe3 Kf6 31. Rc5 Ke6 32. Kd4 f6 33. b4 Kd6 34. Rc8 Kd7 35. Rc5 Kd6 36. Rc8 Kd7 37. Rc5 Kd6 38. Rc8 Kd7 39. Rc5 Kd6 40. Rc8 Kd7 41. Rc5 Kd6 42. Rc8 Kd7 43. Rc5 Kd6 44. Rc8 Kd7 45. Rc5 Kd6 46. Rc8 Kd7 47. Rc5 Kd6 48. Rc8 Kd7 49. Rc5 Kd6 50. Rc8 Kd7 51. Rc5 Kd6 52. Rc8 Kd7 53. Rc5 Kd6 54. Rc8 Kd7 55. Rc5 Kd6 56. Rc8 Kd7 57. Rc5 Kd6 58. Rc8 Kd7 59. Rc5 Kd6 60. Rc8 Kd7 61. Rc5 Kd6 62. Rc8 Kd7 63. Rc5 Kd6 64. Rc8 Kd7 65. Rc5 Kd6 66. Rc8 Kd7 67. Rc5 Kd6 68. Rc8 Kd7 69. Rc5 Kd6 70. Rc8 Kd7 71. Rc5 Kd6 72. Rc8 Kd7 73. Rc5 Kd6 74. Rc8 Kd7 75",
          "aggressive_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Be3",
            "Rac8",
            "Rc1",
            "Nb4",
            "Bb1",
            "Rfd8",
            "a3",
            "Nc6",
            "dxe5",
            "dxe5",
            "Qxd8+",
            "Rxd8",
            "Nxe5",
            "Bxe4",
            "Nxc6",
            "Bxc6",
            "Rxc6",
            "Rxd1+",
            "Bxd1",
            "Nd5",
            "Rc7",
            "Bf6",
            "f3",
            "g6",
            "Kf2",
            "Kg7",
            "Ke2",
            "Ne3",
            "Bxe3",
            "Bxe3",
            "Kxe3",
            "Kf6",
            "Rc5",
            "Ke6",
            "Kd4",
            "f6",
            "b4",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7",
            "Rc5",
            "Kd6",
            "Rc8",
            "Kd7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Bb7 15. Be3 Rfe8 16. Rc1 Qb8 17. Qd2 Rac8 18. Bb1 Nb4 19. a3 Nc6 20. dxe5 dxe5 21. Qxd8 Rxd8 22. Nxe5 Bxe4 23. Nxc6 Bxc6 24. Bxc6 Rxc6 25. Rxc6 Bf8 26. Rc7 Rd7 27. Rxd7 Bxd7 28. Rd1 Be6 29. Rd8+ Kg7 30. Rd6 Bc4 31. b3 Bb5 32. Nd4 Bxd4 33. Bxd4+ f6 34. Kf1 Kf7 35. Ke2 Ke7 36. Kd3 Kd7 37. Kc3 Kc7 38. Kb4 Kb6 39. a4 Ka5 40. a5 Kb6 41. Kc4 Kc7 42. Kd5 Kd7 43. Ke4 Ke7 44. Kf5 Kf7 45. Kg4 Kg6 46. Kh4 Kh6 47. g3 Kh7 48. Kg5 Kg7 49. h4 Kh7 50. Kh5 Kg7 51. g4 Kh7 52. Kg5 Kg7 53. h5 Kh7 54. Kh4 Kg7 55. Kg3 Kh7 56. Kf3 Kg7 57. Ke3 Kh7 58. Kd3 Kg7 59. Kc3 Kh7 60. Kb4 Kg7 61. Ka5 Kh7 62. Kb6 Kg7 63. Kc7 Kh7 64. Kd7 Kg7 65. Ke7 Kh7 66. Kf7 Kh8 67. Kg6 Kg8 68. Kh6 Kh8 69. g5 Kg8 70. Kg6 Kh8 71. h6 Kg8 72. h7+ Kh8 73. g6 Kg7 74. h8=Q+ Kxh8 75. Kf7 Kh7 76. g7 Kh8 77. g8=Q+ Kh7 78. Qg7#",
          "positional_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 617,
            "total_tokens": 729,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Be3",
            "Rfe8",
            "Rc1",
            "Qb8",
            "Qd2",
            "Rac8",
            "Bb1",
            "Nb4",
            "a3",
            "Nc6",
            "dxe5",
            "dxe5",
            "Qxd8",
            "Rxd8",
            "Nxe5",
            "Bxe4",
            "Nxc6",
            "Bxc6",
            "Bxc6",
            "Rxc6",
            "Rxc6",
            "Bf8",
            "Rc7",
            "Rd7",
            "Rxd7",
            "Bxd7",
            "Rd1",
            "Be6",
            "Rd8+",
            "Kg7",
            "Rd6",
            "Bc4",
            "b3",
            "Bb5",
            "Nd4",
            "Bxd4",
            "Bxd4+",
            "f6",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke7",
            "Kd3",
            "Kd7",
            "Kc3",
            "Kc7",
            "Kb4",
            "Kb6",
            "a4",
            "Ka5",
            "a5",
            "Kb6",
            "Kc4",
            "Kc7",
            "Kd5",
            "Kd7",
            "Ke4",
            "Ke7",
            "Kf5",
            "Kf7",
            "Kg4",
            "Kg6",
            "Kh4",
            "Kh6",
            "g3",
            "Kh7",
            "Kg5",
            "Kg7",
            "h4",
            "Kh7",
            "Kh5",
            "Kg7",
            "g4",
            "Kh7",
            "Kg5",
            "Kg7",
            "h5",
            "Kh7",
            "Kh4",
            "Kg7",
            "Kg3",
            "Kh7",
            "Kf3",
            "Kg7",
            "Ke3",
            "Kh7",
            "Kd3",
            "Kg7",
            "Kc3",
            "Kh7",
            "Kb4",
            "Kg7",
            "Ka5",
            "Kh7",
            "Kb6",
            "Kg7",
            "Kc7",
            "Kh7",
            "Kd7",
            "Kg7",
            "Ke7",
            "Kh7",
            "Kf7",
            "Kh8",
            "Kg6",
            "Kg8",
            "Kh6",
            "Kh8",
            "g5",
            "Kg8",
            "Kg6",
            "Kh8",
            "h6",
            "Kg8",
            "h7+",
            "Kh8",
            "g6",
            "Kg7",
            "h8=Q+",
            "Kxh8",
            "Kf7",
            "Kh7",
            "g7",
            "Kh8",
            "g8=Q+",
            "Kh7",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d6 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Bb7 15. Be3 Rac8 16. Rc1 Qb8 17. d5 Nb4 18. Bb1 a5 19. a3 Na6 20. Qd3 g6 21. Bh6 Rfe8 22. Rxc8 Bxc8 23. Qc3 Bb7 24. Qc7 Qxc7 25. dxc7 Bc6 26. Nd2 Rc8 27. Nc4 Bxc4 28. Bxc4 Nxc7 29. Bxf7+ Kxf7 30. Rxe5 Nxe5 31. Nxe5+ Ke6 32. Nxg6 Kf6 33. Nf4 Bf8 34. g4 h6 35. Kg2 Kg5 36. h4+ Kf6 37. Kh3 Kg7 38. g5 hxg5 39. hxg5 Be7 40. Kg4 Bf8 41. Nh5+ Kg6 42. Nf4+ Kf7 43. Kh5 Kg7 44. Kg4 Kf7 45. Kh5 Kg7 46. Kg4 Kf7 47. Kh5 Kg7 48. Kg4 Kf7 49. Kh5 Kg7 50. Kg4 Kf7 51. Kh5 Kg7 52. Kg4 Kf7 53. Kh5 Kg7 54. Kg4 Kf7 55. Kh5 Kg7 56. Kg4 Kf7 57. Kh5 Kg7 58. Kg4 Kf7 59. Kh5 Kg7 60. Kg4 Kf7 61. Kh5 Kg7 62. Kg4 Kf7 63. Kh5 Kg7 64. Kg4 Kf7 65. Kh5 Kg7 66. Kg4 Kf7 67. Kh5 Kg7 68. Kg4 Kf7 69. Kh5 Kg7 70. Kg4 Kf7 71. Kh5 Kg7 72. Kg4 Kf7 73. Kh5 Kg7 74. Kg4 Kf7 75. Kh5 Kg7 76. Kg4 Kf7 77. Kh5 Kg7 78. Kg4 Kf7 79. Kh5 Kg7 80. Kg4 Kf7 81. Kh5 Kg7 82. Kg4",
          "neutral_tokens": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Be3",
            "Rac8",
            "Rc1",
            "Qb8",
            "d5",
            "Nb4",
            "Bb1",
            "a5",
            "a3",
            "Na6",
            "Qd3",
            "g6",
            "Bh6",
            "Rfe8",
            "Rxc8",
            "Bxc8",
            "Qc3",
            "Bb7",
            "Qc7",
            "Qxc7",
            "dxc7",
            "Bc6",
            "Nd2",
            "Rc8",
            "Nc4",
            "Bxc4",
            "Bxc4",
            "Nxc7",
            "Bxf7+",
            "Kxf7",
            "Rxe5",
            "Nxe5",
            "Nxe5+",
            "Ke6",
            "Nxg6",
            "Kf6",
            "Nf4",
            "Bf8",
            "g4",
            "h6",
            "Kg2",
            "Kg5",
            "h4+",
            "Kf6",
            "Kh3",
            "Kg7",
            "g5",
            "hxg5",
            "hxg5",
            "Be7",
            "Kg4",
            "Bf8",
            "Nh5+",
            "Kg6",
            "Nf4+",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4",
            "Kf7",
            "Kh5",
            "Kg7",
            "Kg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Be3",
              "Rac8",
              "Rc1",
              "Nb4",
              "Bb1",
              "Rfd8",
              "a3",
              "Nc6",
              "dxe5",
              "dxe5",
              "Qxd8+",
              "Rxd8",
              "Nxe5",
              "Bxe4",
              "Nxc6",
              "Bxc6",
              "Rxc6",
              "Rxd1+",
              "Bxd1",
              "Nd5",
              "Rc7",
              "Bf6",
              "f3",
              "g6",
              "Kf2",
              "Kg7",
              "Ke2",
              "Ne3",
              "Bxe3",
              "Bxe3",
              "Kxe3",
              "Kf6",
              "Rc5",
              "Ke6",
              "Kd4",
              "f6",
              "b4",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7",
              "Rc5",
              "Kd6",
              "Rc8",
              "Kd7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Be3",
              "Rfe8",
              "Rc1",
              "Qb8",
              "Qd2",
              "Rac8",
              "Bb1",
              "Nb4",
              "a3",
              "Nc6",
              "dxe5",
              "dxe5",
              "Qxd8",
              "Rxd8",
              "Nxe5",
              "Bxe4",
              "Nxc6",
              "Bxc6",
              "Bxc6",
              "Rxc6",
              "Rxc6",
              "Bf8",
              "Rc7",
              "Rd7",
              "Rxd7",
              "Bxd7",
              "Rd1",
              "Be6",
              "Rd8+",
              "Kg7",
              "Rd6",
              "Bc4",
              "b3",
              "Bb5",
              "Nd4",
              "Bxd4",
              "Bxd4+",
              "f6",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke7",
              "Kd3",
              "Kd7",
              "Kc3",
              "Kc7",
              "Kb4",
              "Kb6",
              "a4",
              "Ka5",
              "a5",
              "Kb6",
              "Kc4",
              "Kc7",
              "Kd5",
              "Kd7",
              "Ke4",
              "Ke7",
              "Kf5",
              "Kf7",
              "Kg4",
              "Kg6",
              "Kh4",
              "Kh6",
              "g3",
              "Kh7",
              "Kg5",
              "Kg7",
              "h4",
              "Kh7",
              "Kh5",
              "Kg7",
              "g4",
              "Kh7",
              "Kg5",
              "Kg7",
              "h5",
              "Kh7",
              "Kh4",
              "Kg7",
              "Kg3",
              "Kh7",
              "Kf3",
              "Kg7",
              "Ke3",
              "Kh7",
              "Kd3",
              "Kg7",
              "Kc3",
              "Kh7",
              "Kb4",
              "Kg7",
              "Ka5",
              "Kh7",
              "Kb6",
              "Kg7",
              "Kc7",
              "Kh7",
              "Kd7",
              "Kg7",
              "Ke7",
              "Kh7",
              "Kf7",
              "Kh8",
              "Kg6",
              "Kg8",
              "Kh6",
              "Kh8",
              "g5",
              "Kg8",
              "Kg6",
              "Kh8",
              "h6",
              "Kg8",
              "h7+",
              "Kh8",
              "g6",
              "Kg7",
              "h8=Q+",
              "Kxh8",
              "Kf7",
              "Kh7",
              "g7",
              "Kh8",
              "g8=Q+",
              "Kh7",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Be3",
              "Rac8",
              "Rc1",
              "Qb8",
              "d5",
              "Nb4",
              "Bb1",
              "a5",
              "a3",
              "Na6",
              "Qd3",
              "g6",
              "Bh6",
              "Rfe8",
              "Rxc8",
              "Bxc8",
              "Qc3",
              "Bb7",
              "Qc7",
              "Qxc7",
              "dxc7",
              "Bc6",
              "Nd2",
              "Rc8",
              "Nc4",
              "Bxc4",
              "Bxc4",
              "Nxc7",
              "Bxf7+",
              "Kxf7",
              "Rxe5",
              "Nxe5",
              "Nxe5+",
              "Ke6",
              "Nxg6",
              "Kf6",
              "Nf4",
              "Bf8",
              "g4",
              "h6",
              "Kg2",
              "Kg5",
              "h4+",
              "Kf6",
              "Kh3",
              "Kg7",
              "g5",
              "hxg5",
              "hxg5",
              "Be7",
              "Kg4",
              "Bf8",
              "Nh5+",
              "Kg6",
              "Nf4+",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4",
              "Kf7",
              "Kh5",
              "Kg7",
              "Kg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 112,
            "completion_tokens": 617,
            "total_tokens": 729,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 335,
          "total_completion_tokens": 1897,
          "total_tokens": 2232
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 112,
            "completion_tokens": 617,
            "total_tokens": 729,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Nc6 Nb3 Nb4 Bb1 Bb7 Nfd2 Rac8 a3 Nc6 d5 Nb8 Qe2 exd4 Nxd4 Nxd4 Qxd4 c5 Qd3 Rfe8 f3 Qc7 e5 dxe5 Qxe5 Qxe5 Rxe5 f6 Re6 Kf7 Rae1 Bc8 R6e3 Bf5 g4 Bc8 f4 g5 fxg5 fxg5 Bxg5 Bxg5 Rxg5 Rd2 Rg7+ Ke8 Rg8+ Kd7 Rf7+ Kc6 Rf6+ Kb7 Rxb6+ Ka7 Rxa6#",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 219,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Nb4",
            "Bb1",
            "Bb7",
            "Nfd2",
            "Rac8",
            "a3",
            "Nc6",
            "d5",
            "Nb8",
            "Qe2",
            "exd4",
            "Nxd4",
            "Nxd4",
            "Qxd4",
            "c5",
            "Qd3",
            "Rfe8",
            "f3",
            "Qc7",
            "e5",
            "dxe5",
            "Qxe5",
            "Qxe5",
            "Rxe5",
            "f6",
            "Re6",
            "Kf7",
            "Rae1",
            "Bc8",
            "R6e3",
            "Bf5",
            "g4",
            "Bc8",
            "f4",
            "g5",
            "fxg5",
            "fxg5",
            "Bxg5",
            "Bxg5",
            "Rxg5",
            "Rd2",
            "Rg7+",
            "Ke8",
            "Rg8+",
            "Kd7",
            "Rf7+",
            "Kc6",
            "Rf6+",
            "Kb7",
            "Rxb6+",
            "Ka7",
            "Rxa6#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 Bb7 Nb3 Nxb3 axb3 Rac8 Nbd2 Rfd8 Qe2 Qb8 Rad1 Qb7 Rc1 Rxc1 Rxc1 Rc8 Rxc8+ Qxc8 Qc2 Qxc2 Bxc2 Kf8 f3 Ke8 Kf2 Kd7 Ke3 Kc6 Bd3 Kb6 Kd2 Ka5 Kc3 Kb6 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 Kb7 Kb4 Kc6 Ka5 K",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Bb7",
            "Nb3",
            "Nxb3",
            "axb3",
            "Rac8",
            "Nbd2",
            "Rfd8",
            "Qe2",
            "Qb8",
            "Rad1",
            "Qb7",
            "Rc1",
            "Rxc1",
            "Rxc1",
            "Rc8",
            "Rxc8+",
            "Qxc8",
            "Qc2",
            "Qxc2",
            "Bxc2",
            "Kf8",
            "f3",
            "Ke8",
            "Kf2",
            "Kd7",
            "Ke3",
            "Kc6",
            "Bd3",
            "Kb6",
            "Kd2",
            "Ka5",
            "Kc3",
            "Kb6",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5",
            "Kb7",
            "Kb4",
            "Kc6",
            "Ka5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Nb4",
              "Bb1",
              "Bb7",
              "Nfd2",
              "Rac8",
              "a3",
              "Nc6",
              "d5",
              "Nb8",
              "Qe2",
              "exd4",
              "Nxd4",
              "Nxd4",
              "Qxd4",
              "c5",
              "Qd3",
              "Rfe8",
              "f3",
              "Qc7",
              "e5",
              "dxe5",
              "Qxe5",
              "Qxe5",
              "Rxe5",
              "f6",
              "Re6",
              "Kf7",
              "Rae1",
              "Bc8",
              "R6e3",
              "Bf5",
              "g4",
              "Bc8",
              "f4",
              "g5",
              "fxg5",
              "fxg5",
              "Bxg5",
              "Bxg5",
              "Rxg5",
              "Rd2",
              "Rg7+",
              "Ke8",
              "Rg8+",
              "Kd7",
              "Rf7+",
              "Kc6",
              "Rf6+",
              "Kb7",
              "Rxb6+",
              "Ka7",
              "Rxa6#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Bb7",
              "Nb3",
              "Nxb3",
              "axb3",
              "Rac8",
              "Nbd2",
              "Rfd8",
              "Qe2",
              "Qb8",
              "Rad1",
              "Qb7",
              "Rc1",
              "Rxc1",
              "Rxc1",
              "Rc8",
              "Rxc8+",
              "Qxc8",
              "Qc2",
              "Qxc2",
              "Bxc2",
              "Kf8",
              "f3",
              "Ke8",
              "Kf2",
              "Kd7",
              "Ke3",
              "Kc6",
              "Bd3",
              "Kb6",
              "Kd2",
              "Ka5",
              "Kc3",
              "Kb6",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5",
              "Kb7",
              "Kb4",
              "Kc6",
              "Ka5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 219,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 877,
          "total_tokens": 1230
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 219,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "1. e4 e5 * Nf3 Nc6 Bb5\nNf3 Nc6 Bb5",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 27,
            "total_tokens": 145,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc6",
            "Bb5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5\ne4 e5 Nf3 Nc6",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc6",
              "Bb5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 27,
            "total_tokens": 145,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 63,
          "total_tokens": 416
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 27,
            "total_tokens": 145,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": "f3e5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 * Nxe5 Nxe5 d4",
          "aggressive_tokens": {
            "prompt_tokens": 127,
            "completion_tokens": 25,
            "total_tokens": 152,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe5",
          "positional_uci": "f3e5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 * Nxe5 Nxe5",
          "positional_tokens": {
            "prompt_tokens": 127,
            "completion_tokens": 23,
            "total_tokens": 150,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe5",
          "neutral_uci": "f3e5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 * Nxe5 Nxe5 d4 Nf6",
          "neutral_tokens": {
            "prompt_tokens": 126,
            "completion_tokens": 28,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4",
            "Nf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3e5",
          "positional_uci": "f3e5",
          "neutral_uci": "f3e5",
          "consensus_move": "f3e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d4"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "d4",
              "Nf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 127,
            "completion_tokens": 25,
            "total_tokens": 152,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 127,
            "completion_tokens": 23,
            "total_tokens": 150,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 126,
            "completion_tokens": 28,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 380,
          "total_completion_tokens": 76,
          "total_tokens": 456
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 127,
            "completion_tokens": 25,
            "total_tokens": 152,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 127,
            "completion_tokens": 23,
            "total_tokens": 150,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 126,
            "completion_tokens": 28,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 * d4 Nf6 Qd5",
          "aggressive_tokens": {
            "prompt_tokens": 136,
            "completion_tokens": 34,
            "total_tokens": 170,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Qd5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": "d2d4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 * d4 Nf6 Bf4",
          "positional_tokens": {
            "prompt_tokens": 136,
            "completion_tokens": 34,
            "total_tokens": 170,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bf4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 * d4 Nf6 Bf4",
          "neutral_tokens": {
            "prompt_tokens": 135,
            "completion_tokens": 34,
            "total_tokens": 169,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bf4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "d2d4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Qd5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Bf4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Bf4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 136,
            "completion_tokens": 34,
            "total_tokens": 170,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 136,
            "completion_tokens": 34,
            "total_tokens": 170,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 135,
            "completion_tokens": 34,
            "total_tokens": 169,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 407,
          "total_completion_tokens": 102,
          "total_tokens": 509
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 136,
            "completion_tokens": 34,
            "total_tokens": 170,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 136,
            "completion_tokens": 34,
            "total_tokens": 170,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 135,
            "completion_tokens": 34,
            "total_tokens": 169,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/8/4n3/4P3/8/PPPP1PPP/RNBQKB1R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d4d5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 * d5 Bb4+ c3",
          "aggressive_tokens": {
            "prompt_tokens": 144,
            "completion_tokens": 42,
            "total_tokens": 186,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb4+",
            "c3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d5",
          "positional_uci": "d4d5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 * d5 Bb4+ c3",
          "positional_tokens": {
            "prompt_tokens": 144,
            "completion_tokens": 42,
            "total_tokens": 186,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb4+",
            "c3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 * Nc6 d5 exd5",
          "neutral_tokens": {
            "prompt_tokens": 143,
            "completion_tokens": 42,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "exd5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4d5",
          "positional_uci": "d4d5",
          "neutral_uci": null,
          "consensus_move": "d4d5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb4+",
              "c3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb4+",
              "c3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "exd5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 144,
            "completion_tokens": 42,
            "total_tokens": 186,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 144,
            "completion_tokens": 42,
            "total_tokens": 186,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 143,
            "completion_tokens": 42,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 431,
          "total_completion_tokens": 126,
          "total_tokens": 557
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 144,
            "completion_tokens": 42,
            "total_tokens": 186,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 144,
            "completion_tokens": 42,
            "total_tokens": 186,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 143,
            "completion_tokens": 42,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/8/3PP3/8/PPP2PPP/RNBQKB1R w KQkq - 1 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "f4",
          "aggressive_uci": "f2f4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 * f4 Nf6 f5",
          "aggressive_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 48,
            "total_tokens": 199,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "f5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "f4",
          "positional_uci": "f2f4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 * f4 Nf7 Qd4",
          "positional_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 49,
            "total_tokens": 200,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf7",
            "Qd4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "f4",
          "neutral_uci": "f2f4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 * f4 Nf6 f5",
          "neutral_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 48,
            "total_tokens": 198,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "f5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f2f4",
          "positional_uci": "f2f4",
          "neutral_uci": "f2f4",
          "consensus_move": "f2f4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "f5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf7",
              "Qd4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "f5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 151,
            "completion_tokens": 48,
            "total_tokens": 199,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 151,
            "completion_tokens": 49,
            "total_tokens": 200,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 150,
            "completion_tokens": 48,
            "total_tokens": 198,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 452,
          "total_completion_tokens": 145,
          "total_tokens": 597
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 151,
            "completion_tokens": 48,
            "total_tokens": 199,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 151,
            "completion_tokens": 49,
            "total_tokens": 200,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 150,
            "completion_tokens": 48,
            "total_tokens": 198,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/8/3Pn3/4P3/8/PPP2PPP/RNBQKB1R w KQkq - 1 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g4",
          "aggressive_uci": "g2g4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 * g4 Bc5 g5",
          "aggressive_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 55,
            "total_tokens": 213,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc5",
            "g5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 * e4 e5 Nf3 Nc6 Nxe5 Nxe5 d4 Nc6 d5 Ne5 f4 Ng6 * Bb5 c6 dxc6",
          "positional_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 86,
            "total_tokens": 244,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Nxe5",
            "Nxe5",
            "d4",
            "Nc6",
            "d5",
            "Ne5",
            "f4",
            "Ng6",
            "Bb5",
            "c6",
            "dxc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qd4",
          "neutral_uci": "d1d4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 * e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 * Qd4 Bc5 Qxg7",
          "neutral_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 102,
            "total_tokens": 259,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc5",
            "Qxg7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g2g4",
          "positional_uci": null,
          "neutral_uci": "d1d4",
          "consensus_move": "d1d4",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc5",
              "g5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Nxe5",
              "Nxe5",
              "d4",
              "Nc6",
              "d5",
              "Ne5",
              "f4",
              "Ng6",
              "Bb5",
              "c6",
              "dxc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bc5",
              "Qxg7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 158,
            "completion_tokens": 55,
            "total_tokens": 213,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 158,
            "completion_tokens": 86,
            "total_tokens": 244,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 157,
            "completion_tokens": 102,
            "total_tokens": 259,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 473,
          "total_completion_tokens": 243,
          "total_tokens": 716
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 158,
            "completion_tokens": 55,
            "total_tokens": 213,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 158,
            "completion_tokens": 86,
            "total_tokens": 244,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 157,
            "completion_tokens": 102,
            "total_tokens": 259,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/6n1/3P4/4PP2/8/PPP3PP/RNBQKB1R w KQkq - 1 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxg7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 * Qxg7 Qxg7",
          "aggressive_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 63,
            "total_tokens": 230,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "f5",
          "positional_uci": "f4f5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 * Qxf6 gxf6 8. f5 Ne5",
          "positional_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 70,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ne5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e4e5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 * Qxf6 Nxf6 8. e5 Nd7",
          "neutral_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 70,
            "total_tokens": 236,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "f4f5",
          "neutral_uci": "e4e5",
          "consensus_move": "e4e5",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Ne5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nd7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 167,
            "completion_tokens": 63,
            "total_tokens": 230,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 167,
            "completion_tokens": 70,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 166,
            "completion_tokens": 70,
            "total_tokens": 236,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 500,
          "total_completion_tokens": 203,
          "total_tokens": 703
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 167,
            "completion_tokens": 63,
            "total_tokens": 230,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 167,
            "completion_tokens": 70,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 166,
            "completion_tokens": 70,
            "total_tokens": 236,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/pppp1ppp/5qn1/3P4/3QPP2/8/PPP3PP/RNB1KB1R w KQkq - 3 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxb6",
          "aggressive_uci": "d4b6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 * Qxb6 Nb4",
          "aggressive_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 70,
            "total_tokens": 246,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nb4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxb6",
          "positional_uci": "d4b6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 * Qxb6 Nxb6",
          "positional_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 71,
            "total_tokens": 247,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxb6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxb6",
          "neutral_uci": "d4b6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 * Qxb6 Nxb6",
          "neutral_tokens": {
            "prompt_tokens": 175,
            "completion_tokens": 71,
            "total_tokens": 246,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxb6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4b6",
          "positional_uci": "d4b6",
          "neutral_uci": "d4b6",
          "consensus_move": "d4b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nb4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxb6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxb6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 176,
            "completion_tokens": 70,
            "total_tokens": 246,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 176,
            "completion_tokens": 71,
            "total_tokens": 247,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 175,
            "completion_tokens": 71,
            "total_tokens": 246,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 527,
          "total_completion_tokens": 212,
          "total_tokens": 739
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 176,
            "completion_tokens": 70,
            "total_tokens": 246,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 176,
            "completion_tokens": 71,
            "total_tokens": 247,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 175,
            "completion_tokens": 71,
            "total_tokens": 246,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/pppp1ppp/1q4n1/3PP3/3Q1P2/8/PPP3PP/RNB1KB1R w KQkq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 * Bc4 Nf6 10. O-O Bd6",
          "aggressive_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 87,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "f5",
          "positional_uci": "f4f5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 * \nf5 Bb4+ c3",
          "positional_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 83,
            "total_tokens": 268,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb4+",
            "c3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb5",
          "neutral_uci": "f1b5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 * Bb5 Nf6 Bd3",
          "neutral_tokens": {
            "prompt_tokens": 184,
            "completion_tokens": 82,
            "total_tokens": 266,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "f4f5",
          "neutral_uci": "f1b5",
          "consensus_move": "f1b5",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb4+",
              "c3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Bd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 185,
            "completion_tokens": 87,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 185,
            "completion_tokens": 83,
            "total_tokens": 268,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 184,
            "completion_tokens": 82,
            "total_tokens": 266,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 554,
          "total_completion_tokens": 252,
          "total_tokens": 806
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 185,
            "completion_tokens": 87,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 185,
            "completion_tokens": 83,
            "total_tokens": 268,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 184,
            "completion_tokens": 82,
            "total_tokens": 266,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1ppp1ppp/1p4n1/3PP3/5P2/8/PPP3PP/RNB1KB1R w KQkq - 0 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxc6",
          "aggressive_uci": "d5c6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 * dxc6 Bxc6 Nc3",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 91,
            "total_tokens": 284,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxc6",
            "Nc3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxc6",
          "positional_uci": "d5c6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 * dxc6 Nxf4 cxb5",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 91,
            "total_tokens": 284,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxf4",
            "cxb5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxc6",
          "neutral_uci": "d5c6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 * dxc6 Nf6 Bxc6",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 91,
            "total_tokens": 283,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bxc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d5c6",
          "positional_uci": "d5c6",
          "neutral_uci": "d5c6",
          "consensus_move": "d5c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxc6",
              "Nc3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxf4",
              "cxb5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Bxc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 91,
            "total_tokens": 284,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 91,
            "total_tokens": 284,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 91,
            "total_tokens": 283,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 273,
          "total_tokens": 851
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 91,
            "total_tokens": 284,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 91,
            "total_tokens": 284,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 91,
            "total_tokens": 283,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1p1p1ppp/1pp3n1/1B1PP3/5P2/8/PPP3PP/RNB1K2R w KQkq - 0 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxc6",
          "aggressive_uci": "b5c6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 * Bxc6 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 97,
            "total_tokens": 299,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxc6",
          "positional_uci": "b5c6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 * Bxc6 Bd7 Bxd7+",
          "positional_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 100,
            "total_tokens": 302,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd7",
            "Bxd7+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxc6",
          "neutral_uci": "b5c6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 * Bxc6 Bd6 O-O",
          "neutral_tokens": {
            "prompt_tokens": 201,
            "completion_tokens": 98,
            "total_tokens": 299,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd6",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b5c6",
          "positional_uci": "b5c6",
          "neutral_uci": "b5c6",
          "consensus_move": "b5c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd7",
              "Bxd7+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bd6",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 202,
            "completion_tokens": 97,
            "total_tokens": 299,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 202,
            "completion_tokens": 100,
            "total_tokens": 302,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 201,
            "completion_tokens": 98,
            "total_tokens": 299,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 605,
          "total_completion_tokens": 295,
          "total_tokens": 900
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 202,
            "completion_tokens": 97,
            "total_tokens": 299,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 202,
            "completion_tokens": 100,
            "total_tokens": 302,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 201,
            "completion_tokens": 98,
            "total_tokens": 299,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1p3ppp/1pp3n1/1B2P3/5P2/8/PPP3PP/RNB1K2R w KQkq - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 * Nf3 Nf6 O-O",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 109,
            "total_tokens": 321,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "O-O"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bd6 14. f5 Ne7\n13. O-O Bd6 14. f5 Ne7",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 128,
            "total_tokens": 340,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd6",
            "f5",
            "Ne7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O-O",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 * O-O-O O-O-O Rd1+",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 110,
            "total_tokens": 321,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd1+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e1g1",
          "neutral_uci": null,
          "consensus_move": "e1g1",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "O-O"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd6",
              "f5",
              "Ne7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rd1+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 109,
            "total_tokens": 321,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 128,
            "total_tokens": 340,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 110,
            "total_tokens": 321,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 347,
          "total_tokens": 982
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 109,
            "total_tokens": 321,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 128,
            "total_tokens": 340,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 110,
            "total_tokens": 321,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/5ppp/1pp3n1/4P3/5P2/8/PPP3PP/RNB1K2R w KQkq - 0 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kh1",
          "aggressive_uci": "g1h1",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ * Kh1 Bd6 Nc3",
          "aggressive_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 117,
            "total_tokens": 338,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd6",
            "Nc3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kh1",
          "positional_uci": "g1h1",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ * Kh1 Bd6 Be3",
          "positional_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 116,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd6",
            "Be3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kh1",
          "neutral_uci": "g1h1",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ * Kh1 Rd8 Rd1",
          "neutral_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 116,
            "total_tokens": 336,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd8",
            "Rd1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1h1",
          "positional_uci": "g1h1",
          "neutral_uci": "g1h1",
          "consensus_move": "g1h1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd6",
              "Nc3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd6",
              "Be3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rd8",
              "Rd1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 221,
            "completion_tokens": 117,
            "total_tokens": 338,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 221,
            "completion_tokens": 116,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 220,
            "completion_tokens": 116,
            "total_tokens": 336,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 662,
          "total_completion_tokens": 349,
          "total_tokens": 1011
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 221,
            "completion_tokens": 117,
            "total_tokens": 338,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 221,
            "completion_tokens": 116,
            "total_tokens": 337,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 220,
            "completion_tokens": 116,
            "total_tokens": 336,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k1nr/5ppp/1pp3n1/2b1P3/5P2/8/PPP3PP/RNB2RK1 w kq - 2 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 * Nxe7 Nxe7 Bd6",
          "aggressive_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 127,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 * Nf3 Bd6 Nxg6",
          "positional_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 127,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd6",
            "Nxg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 * Nxe7 Bxe7 Rf3",
          "neutral_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 128,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe7",
            "Rf3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd6",
              "Nxg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxe7",
              "Rf3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 231,
            "completion_tokens": 127,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 231,
            "completion_tokens": 127,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 230,
            "completion_tokens": 128,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 692,
          "total_completion_tokens": 382,
          "total_tokens": 1074
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 231,
            "completion_tokens": 127,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 231,
            "completion_tokens": 127,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 230,
            "completion_tokens": 128,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/4nppp/1pp3n1/2b1P3/5P2/8/PPP3PP/RNB2R1K w kq - 4 15"
    },
    {
      "turn": 29,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 * Nf3 Nf5 Nxf5",
          "aggressive_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 128,
            "total_tokens": 359,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf5",
            "Nxf5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe7",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 * Nxe7 Bxe7 Rf1",
          "positional_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 128,
            "total_tokens": 359,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe7",
            "Rf1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "f5",
          "neutral_uci": "f4f5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nh4 16. Nc3 O-O",
          "neutral_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 133,
            "total_tokens": 363,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nh4",
            "Nc3",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": "f4f5",
          "consensus_move": "f4f5",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf5",
              "Nxf5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxe7",
              "Rf1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nh4",
              "Nc3",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 231,
            "completion_tokens": 128,
            "total_tokens": 359,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 231,
            "completion_tokens": 128,
            "total_tokens": 359,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 230,
            "completion_tokens": 133,
            "total_tokens": 363,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 692,
          "total_completion_tokens": 389,
          "total_tokens": 1081
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 231,
            "completion_tokens": 128,
            "total_tokens": 359,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 231,
            "completion_tokens": 128,
            "total_tokens": 359,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 230,
            "completion_tokens": 133,
            "total_tokens": 363,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/4nppp/1pp3n1/2b1P3/5P2/8/PPP3PP/RNB2R1K w kq - 4 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g4",
          "aggressive_uci": "g2g4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 * g4 Nxh4 g5",
          "aggressive_tokens": {
            "prompt_tokens": 239,
            "completion_tokens": 134,
            "total_tokens": 373,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxh4",
            "g5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxf5",
          "positional_uci": "f1f5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 * Rxf5 gxf5 Bxf5",
          "positional_tokens": {
            "prompt_tokens": 239,
            "completion_tokens": 136,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf5",
            "Bxf5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g4",
          "neutral_uci": "g2g4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 * g4 Nh4 g5",
          "neutral_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 133,
            "total_tokens": 371,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nh4",
            "g5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g2g4",
          "positional_uci": "f1f5",
          "neutral_uci": "g2g4",
          "consensus_move": "g2g4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxh4",
              "g5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "gxf5",
              "Bxf5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nh4",
              "g5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 239,
            "completion_tokens": 134,
            "total_tokens": 373,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 239,
            "completion_tokens": 136,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 238,
            "completion_tokens": 133,
            "total_tokens": 371,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 716,
          "total_completion_tokens": 403,
          "total_tokens": 1119
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 239,
            "completion_tokens": 134,
            "total_tokens": 373,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 239,
            "completion_tokens": 136,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 238,
            "completion_tokens": 133,
            "total_tokens": 371,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/5ppp/1pp3n1/2b1Pn2/8/8/PPP3PP/RNB2R1K w kq - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxc6",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 * Nxc6 Nxc6 Rxf5",
          "aggressive_tokens": {
            "prompt_tokens": 246,
            "completion_tokens": 143,
            "total_tokens": 389,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc3",
          "positional_uci": "b1c3",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 O-O 18. Rxf5\nWhite Rxf5 Nc3 O-O",
          "positional_tokens": {
            "prompt_tokens": 246,
            "completion_tokens": 157,
            "total_tokens": 403,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxf5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 * Nxf5 gxf5 Rxf5",
          "neutral_tokens": {
            "prompt_tokens": 245,
            "completion_tokens": 143,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf5",
            "Rxf5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "b1c3",
          "neutral_uci": null,
          "consensus_move": "b1c3",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxf5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf5",
              "Rxf5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 246,
            "completion_tokens": 143,
            "total_tokens": 389,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 246,
            "completion_tokens": 157,
            "total_tokens": 403,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 245,
            "completion_tokens": 143,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 737,
          "total_completion_tokens": 443,
          "total_tokens": 1180
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 246,
            "completion_tokens": 143,
            "total_tokens": 389,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 246,
            "completion_tokens": 157,
            "total_tokens": 403,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 245,
            "completion_tokens": 143,
            "total_tokens": 388,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/5ppp/1pp3n1/2b1P3/3n2P1/8/PPP4P/RNB2R1K w kq - 1 17"
    },
    {
      "turn": 35,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc2",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 Nxc2 * Rxc2 Bxf2 Rf1",
          "aggressive_tokens": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf2",
            "Rf1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxc2",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 Nxc2 * Rxc2 Bxf5 gxf5",
          "positional_tokens": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf5",
            "gxf5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxc2",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 Nxc2 * Rxc2 Bxf2 Rf2",
          "neutral_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf2",
            "Rf2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf2",
              "Rf1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf5",
              "gxf5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxf2",
              "Rf2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 764,
          "total_completion_tokens": 456,
          "total_tokens": 1220
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/5ppp/1pp3n1/2b1P3/6P1/2N5/PPn4P/R1B2R1K w kq - 0 18"
    },
    {
      "turn": 35,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc2",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 Nxc2 * Rxc2 Bxf2 Rxf2",
          "aggressive_tokens": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf2",
            "Rxf2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxc2",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 Nxc2 * Rxc2 Bxf5 gxf5",
          "positional_tokens": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf5",
            "gxf5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxc2",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 Nxc2 * Rxc2 Rxa1 Rxa1",
          "neutral_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxa1",
            "Rxa1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf2",
              "Rxf2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf5",
              "gxf5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxa1",
              "Rxa1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 764,
          "total_completion_tokens": 456,
          "total_tokens": 1220
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/5ppp/1pp3n1/2b1P3/6P1/2N5/PPn4P/R1B2R1K w kq - 0 18"
    },
    {
      "turn": 35,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxa8",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 Nxc2 * Rxa8 Rxa8 Rf3",
          "aggressive_tokens": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rf3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxc2",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 Nxc2 * Rxc2 Rxa2",
          "positional_tokens": {
            "prompt_tokens": 255,
            "completion_tokens": 149,
            "total_tokens": 404,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxa2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxc2",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Nxe5 Nxe5 4. d4 Nc6 5. d5 Ne5 6. f4 Ng6 7. Qd4 Qf6 8. e5 Qb6 9. Qxb6 axb6 10. Bb5 c6 11. dxc6 dxc6 12. Bxc6+ bxc6 13. O-O Bc5+ 14. Kh1 N8e7 15. f5 Nxf5 16. g4 Nd4 17. Nc3 Nxc2 * Rxc2 Bxf2 Rf1",
          "neutral_tokens": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf2",
            "Rf1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rf3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxa2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxf2",
              "Rf1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 255,
            "completion_tokens": 149,
            "total_tokens": 404,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 764,
          "total_completion_tokens": 453,
          "total_tokens": 1217
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 255,
            "completion_tokens": 152,
            "total_tokens": 407,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 255,
            "completion_tokens": 149,
            "total_tokens": 404,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 254,
            "completion_tokens": 152,
            "total_tokens": 406,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/5ppp/1pp3n1/2b1P3/6P1/2N5/PPn4P/R1B2R1K w kq - 0 18"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "1. d4 * d5 Nf3 Nc6\nBlack d5 Nf3 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 24,
            "total_tokens": 140,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": null,
          "positional_response": "1. d4 * d4 Nf6 Nf6 c4 c4 e6 e6 Nc3 Nc3 Bb4 Bb4 Qc2 Qc2 O-O O-O e3 e3 d5 d5 Bd3 Bd3 Nf3 Nf3 c5 c5 O-O O-O dxc5 dxc5 Qa5 Qa5 Bd2 Bd2 Qxc5 Qxc5 Rac1 Rac1 Qa5 Qa5 Rfd1 Rfd1 b6 b6 Bb5 Bb5 Bxc6 Bxc6 Qb4 Qb4 Rxc6 Rxc6 Qxb4 Qxb4 axb4 axb4 Rc2 Rc2 Rxc2 Rxc2 Bc1 Bc1 Kf1 Kf1 Ke2 Ke2 Kd3 Kd3 Kc4 Kc4 Kb5 Kb5 a3 a3 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb5 Kc4 Kc4 Kb5 Kb",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Nf6",
            "c4",
            "c4",
            "e6",
            "e6",
            "Nc3",
            "Nc3",
            "Bb4",
            "Bb4",
            "Qc2",
            "Qc2",
            "O-O",
            "O-O",
            "e3",
            "e3",
            "d5",
            "d5",
            "Bd3",
            "Bd3",
            "Nf3",
            "Nf3",
            "c5",
            "c5",
            "O-O",
            "O-O",
            "dxc5",
            "dxc5",
            "Qa5",
            "Qa5",
            "Bd2",
            "Bd2",
            "Qxc5",
            "Qxc5",
            "Rac1",
            "Rac1",
            "Qa5",
            "Qa5",
            "Rfd1",
            "Rfd1",
            "b6",
            "b6",
            "Bb5",
            "Bb5",
            "Bxc6",
            "Bxc6",
            "Qb4",
            "Qb4",
            "Rxc6",
            "Rxc6",
            "Qxb4",
            "Qxb4",
            "axb4",
            "axb4",
            "Rc2",
            "Rc2",
            "Rxc2",
            "Rxc2",
            "Bc1",
            "Bc1",
            "Kf1",
            "Kf1",
            "Ke2",
            "Ke2",
            "Kd3",
            "Kd3",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "a3",
            "a3",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5",
            "Kb5",
            "Kc4",
            "Kc4",
            "Kb5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": null,
          "neutral_response": "1. d4 *\nd4",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Nf6",
              "c4",
              "c4",
              "e6",
              "e6",
              "Nc3",
              "Nc3",
              "Bb4",
              "Bb4",
              "Qc2",
              "Qc2",
              "O-O",
              "O-O",
              "e3",
              "e3",
              "d5",
              "d5",
              "Bd3",
              "Bd3",
              "Nf3",
              "Nf3",
              "c5",
              "c5",
              "O-O",
              "O-O",
              "dxc5",
              "dxc5",
              "Qa5",
              "Qa5",
              "Bd2",
              "Bd2",
              "Qxc5",
              "Qxc5",
              "Rac1",
              "Rac1",
              "Qa5",
              "Qa5",
              "Rfd1",
              "Rfd1",
              "b6",
              "b6",
              "Bb5",
              "Bb5",
              "Bxc6",
              "Bxc6",
              "Qb4",
              "Qb4",
              "Rxc6",
              "Rxc6",
              "Qxb4",
              "Qxb4",
              "axb4",
              "axb4",
              "Rc2",
              "Rc2",
              "Rxc2",
              "Rxc2",
              "Bc1",
              "Bc1",
              "Kf1",
              "Kf1",
              "Ke2",
              "Ke2",
              "Kd3",
              "Kd3",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "a3",
              "a3",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5",
              "Kb5",
              "Kc4",
              "Kc4",
              "Kb5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 24,
            "total_tokens": 140,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 672,
          "total_tokens": 1019
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 24,
            "total_tokens": 140,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6\nBlack Nf6 c4 e6",
          "aggressive_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c4",
            "e6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6\nNf6 c4 e6",
          "positional_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c4",
            "e6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. d4 d5 2. Nf3 * Nf6 3. c4 e6\nNf6 c4 e6",
          "neutral_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 32,
            "total_tokens": 155,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c4",
            "e6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c4",
              "e6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "c4",
              "e6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c4",
              "e6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 123,
            "completion_tokens": 32,
            "total_tokens": 155,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 371,
          "total_completion_tokens": 97,
          "total_tokens": 468
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 124,
            "completion_tokens": 33,
            "total_tokens": 157,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 124,
            "completion_tokens": 32,
            "total_tokens": 156,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 123,
            "completion_tokens": 32,
            "total_tokens": 155,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e3",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5\nWhite e3 Bxf6",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 29,
            "total_tokens": 162,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg4",
          "positional_uci": "c8g4",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 Bg4 4. Nbd2 Nc6 5. e3\nBg4 Nbd2 Nc6 e3",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 50,
            "total_tokens": 183,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Nc6",
            "e3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e6",
          "neutral_uci": "e7e6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Nbd2 O-O\nBlack e6 Be7 O-O",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "c8g4",
          "neutral_uci": "e7e6",
          "consensus_move": "e7e6",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd2",
              "Nc6",
              "e3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 29,
            "total_tokens": 162,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 50,
            "total_tokens": 183,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 126,
          "total_tokens": 524
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 29,
            "total_tokens": 162,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 50,
            "total_tokens": 183,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 47,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p2B1/3P4/5N2/PPP1PPPP/RN1QKB1R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 * Be7 Nbd7 Qc1",
          "aggressive_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "Qc1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. Nbd2 *",
          "positional_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3",
            "O-O",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 * Be7 Bd3 O-O",
          "neutral_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 36,
            "total_tokens": 175,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd7",
              "Qc1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd3",
              "O-O",
              "Nbd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bd3",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 139,
            "completion_tokens": 36,
            "total_tokens": 175,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 419,
          "total_completion_tokens": 119,
          "total_tokens": 538
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 140,
            "completion_tokens": 38,
            "total_tokens": 178,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 139,
            "completion_tokens": 36,
            "total_tokens": 175,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp2ppp/4pn2/3p2B1/3P4/4PN2/PPP2PPP/RN1QKB1R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd7",
          "aggressive_uci": "b8d7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 *\nBlack Nbd7 O-O c5",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "c5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "Bh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e8g8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 *\nBlack O-O Nbd7 h6",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 45,
            "total_tokens": 191,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd7",
            "h6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8d7",
          "positional_uci": "e8g8",
          "neutral_uci": "e8g8",
          "consensus_move": "e8g8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "c5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "h6",
              "Bh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd7",
              "h6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 45,
            "total_tokens": 191,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 140,
          "total_tokens": 580
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 45,
            "total_tokens": 192,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 50,
            "total_tokens": 197,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 45,
            "total_tokens": 191,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1QK2R b KQkq - 2 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "h6",
          "aggressive_uci": "h7h6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h6",
          "positional_uci": "h7h6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2\nh6 Bh4 b6 Nbd2",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 68,
            "total_tokens": 222,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "b6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nbd7",
          "neutral_uci": "b8d7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O * Nbd7 c5 dxc5",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 52,
            "total_tokens": 205,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c5",
            "dxc5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h7h6",
          "positional_uci": "h7h6",
          "neutral_uci": "b8d7",
          "consensus_move": "h7h6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bh4",
              "b6",
              "Nbd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c5",
              "dxc5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 68,
            "total_tokens": 222,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 52,
            "total_tokens": 205,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 178,
          "total_tokens": 639
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 58,
            "total_tokens": 212,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 68,
            "total_tokens": 222,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 52,
            "total_tokens": 205,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bppp/4pn2/3p2B1/3P4/3BPN2/PPP2PPP/RN1Q1RK1 b - - 4 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b6",
          "aggressive_uci": "b7b6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Nbd2 Bb7 9. Qe2\nBlack b6 Bb7 Qe2",
          "aggressive_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 77,
            "total_tokens": 238,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb7",
            "Qe2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b6",
          "positional_uci": "b7b6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. Bxf6 Bxf6 9. Nbd2\nb6 Bxf6 Nbd2",
          "positional_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf6",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 * Bxf6 Bxf6 Nc3",
          "neutral_tokens": {
            "prompt_tokens": 160,
            "completion_tokens": 60,
            "total_tokens": 220,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b7b6",
          "positional_uci": "b7b6",
          "neutral_uci": null,
          "consensus_move": "b7b6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb7",
              "Qe2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf6",
              "Nbd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 161,
            "completion_tokens": 77,
            "total_tokens": 238,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 160,
            "completion_tokens": 60,
            "total_tokens": 220,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 482,
          "total_completion_tokens": 213,
          "total_tokens": 695
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 161,
            "completion_tokens": 77,
            "total_tokens": 238,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 161,
            "completion_tokens": 76,
            "total_tokens": 237,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 160,
            "completion_tokens": 60,
            "total_tokens": 220,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/ppp1bpp1/4pn1p/3p4/3P3B/3BPN2/PPP2PPP/RN1Q1RK1 b - - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb7",
          "aggressive_uci": "c8b7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2",
          "aggressive_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Qc2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bb7",
          "positional_uci": "c8b7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2",
          "positional_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Qc2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bb7",
          "neutral_uci": "c8b7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2",
          "neutral_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc3",
            "Nbd7",
            "Qc2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8b7",
          "positional_uci": "c8b7",
          "neutral_uci": "c8b7",
          "consensus_move": "c8b7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc3",
              "Nbd7",
              "Qc2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc3",
              "Nbd7",
              "Qc2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc3",
              "Nbd7",
              "Qc2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 503,
          "total_completion_tokens": 225,
          "total_tokens": 728
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 168,
            "completion_tokens": 75,
            "total_tokens": 243,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 167,
            "completion_tokens": 75,
            "total_tokens": 242,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbq1rk1/p1p1bpp1/1p2pn1p/3p4/2PP3B/3BPN2/PP3PPP/RN1Q1RK1 b - - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd7",
          "aggressive_uci": "b8d7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2 c5 11. Rfd1",
          "aggressive_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc2",
            "c5",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nbd7",
          "positional_uci": "b8d7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Qc2 c5 11. Rfd1\nNbd7 c5 Rfd1",
          "positional_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 92,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c5",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxc4",
          "neutral_uci": "d5c4",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 dxc4 10. Bxc4 Nbd7 11. Qe2",
          "neutral_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 84,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxc4",
            "Nbd7",
            "Qe2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8d7",
          "positional_uci": "b8d7",
          "neutral_uci": "d5c4",
          "consensus_move": "b8d7",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qc2",
              "c5",
              "Rfd1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "c5",
              "Rfd1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxc4",
              "Nbd7",
              "Qe2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 177,
            "completion_tokens": 92,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 176,
            "completion_tokens": 84,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 530,
          "total_completion_tokens": 259,
          "total_tokens": 789
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 177,
            "completion_tokens": 83,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 177,
            "completion_tokens": 92,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 176,
            "completion_tokens": 84,
            "total_tokens": 260,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rn1q1rk1/pbp1bpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/R2Q1RK1 b - - 2 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qc8",
          "aggressive_uci": "d8c8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 * Qc8 Qb8 Qa8",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 85,
            "total_tokens": 271,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qb8",
            "Qa8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "cxd5",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 * cxd5 Nxd5 11. Bxe7 Qxe7",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxd5",
            "Bxe7",
            "Qxe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "cxd5",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 * cxd5 Nxd5 Bh7",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 84,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxd5",
            "Bh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8c8",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "d8c8",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qb8",
              "Qa8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxd5",
              "Bxe7",
              "Qxe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxd5",
              "Bh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 85,
            "total_tokens": 271,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 84,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 260,
          "total_tokens": 817
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 85,
            "total_tokens": 271,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 91,
            "total_tokens": 277,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 84,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/pbpnbpp1/1p2pn1p/3p4/2PP3B/2NBPN2/PP3PPP/2RQ1RK1 b - - 4 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "exd5",
          "aggressive_uci": "e6d5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Qc2 c5 13. dxc5",
          "aggressive_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 101,
            "total_tokens": 296,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc2",
            "c5",
            "dxc5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "exd5",
          "positional_uci": "e6d5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Qc2 c5 13. dxc5\nexd5 Qc2 c5",
          "positional_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 110,
            "total_tokens": 305,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc2",
            "c5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "exd5",
          "neutral_uci": "e6d5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Qc2 Qd8 13. Ne5",
          "neutral_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc2",
            "Qd8",
            "Ne5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e6d5",
          "positional_uci": "e6d5",
          "neutral_uci": "e6d5",
          "consensus_move": "e6d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qc2",
              "c5",
              "dxc5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qc2",
              "c5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qc2",
              "Qd8",
              "Ne5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 195,
            "completion_tokens": 101,
            "total_tokens": 296,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 195,
            "completion_tokens": 110,
            "total_tokens": 305,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 584,
          "total_completion_tokens": 312,
          "total_tokens": 896
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 195,
            "completion_tokens": 101,
            "total_tokens": 296,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 195,
            "completion_tokens": 110,
            "total_tokens": 305,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 194,
            "completion_tokens": 101,
            "total_tokens": 295,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1q2rk1/pbpnbpp1/1p2pn1p/3P4/3P3B/2NBPN2/PP3PPP/2RQ1RK1 b - - 0 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": "d7e5",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Nd7 14. Qg4",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 109,
            "total_tokens": 312,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Nd7",
            "Qg4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe5",
          "positional_uci": "d7e5",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Nd7 14. Qg4\nNe5 Qg4 Nxe5",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 118,
            "total_tokens": 321,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe5",
          "neutral_uci": "d7e5",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Nd7 14. Qg4\nBlack Nxe5 dxe5 Nd7 Qg4",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 122,
            "total_tokens": 324,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Nd7",
            "Qg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7e5",
          "positional_uci": "d7e5",
          "neutral_uci": "d7e5",
          "consensus_move": "d7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxe5",
              "Nd7",
              "Qg4"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxe5",
              "Nd7",
              "Qg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 109,
            "total_tokens": 312,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 118,
            "total_tokens": 321,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 122,
            "total_tokens": 324,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 349,
          "total_tokens": 957
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 109,
            "total_tokens": 312,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 118,
            "total_tokens": 321,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 122,
            "total_tokens": 324,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1q2rk1/pbpnbpp1/1p3n1p/3pN3/3P3B/2NBP3/PP3PPP/2RQ1RK1 b - - 1 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe6",
          "aggressive_uci": "c8e6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. Qf3 Rad8 15. Bg3",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 118,
            "total_tokens": 330,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rad8",
            "Bg3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe5",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qxe5 14. Bxf6 Bxf6 15. Qf3\nQxe5 Qf3 Bxf6",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 129,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe6",
          "neutral_uci": "c8e6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 * Qe6 Bg3 Qxe5",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 111,
            "total_tokens": 322,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg3",
            "Qxe5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8e6",
          "positional_uci": null,
          "neutral_uci": "c8e6",
          "consensus_move": "c8e6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qf3",
              "Rad8",
              "Bg3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf3",
              "Bxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bg3",
              "Qxe5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 118,
            "total_tokens": 330,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 129,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 111,
            "total_tokens": 322,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 358,
          "total_tokens": 993
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 118,
            "total_tokens": 330,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 129,
            "total_tokens": 341,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 111,
            "total_tokens": 322,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1q2rk1/pbp1bpp1/1p3n1p/3pP3/7B/2NBP3/PP3PPP/2RQ1RK1 b - - 0 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": "e7f6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Qf3 Rfe8 16. Bg3",
          "aggressive_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 128,
            "total_tokens": 349,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rfe8",
            "Bg3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf6",
          "positional_uci": "e7f6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Qf3 Rfe8 16. Rfd1\nBxf6 Rfe8 Rfd1",
          "positional_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 138,
            "total_tokens": 359,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rfe8",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "e7f6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Qf3 Rfe8 16. Bxf6\nBxf6 Qf3 Rfe8",
          "neutral_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 138,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rfe8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7f6",
          "positional_uci": "e7f6",
          "neutral_uci": "e7f6",
          "consensus_move": "e7f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qf3",
              "Rfe8",
              "Bg3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rfe8",
              "Rfd1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qf3",
              "Rfe8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 221,
            "completion_tokens": 128,
            "total_tokens": 349,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 221,
            "completion_tokens": 138,
            "total_tokens": 359,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 220,
            "completion_tokens": 138,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 662,
          "total_completion_tokens": 404,
          "total_tokens": 1066
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 221,
            "completion_tokens": 128,
            "total_tokens": 349,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 221,
            "completion_tokens": 138,
            "total_tokens": 359,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 220,
            "completion_tokens": 138,
            "total_tokens": 358,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/pbp1bpp1/1p2qP1p/3p4/7B/2NBP3/PP3PPP/2RQ1RK1 b - - 0 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxf6",
          "aggressive_uci": "e6f6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Qd2 Rfe8 17. Rfd1\nQxf6 Qd2 Rfe8",
          "aggressive_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 147,
            "total_tokens": 378,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd2",
            "Rfe8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxf6",
          "positional_uci": "e6f6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Qd2 Rfe8 17. Rfd1\nQxf6 Qd2 Rfe8",
          "positional_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 147,
            "total_tokens": 378,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd2",
            "Rfe8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxf6",
          "neutral_uci": "e6f6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Qd2 Rfe8 17. Rfd1",
          "neutral_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 137,
            "total_tokens": 367,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd2",
            "Rfe8",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e6f6",
          "positional_uci": "e6f6",
          "neutral_uci": "e6f6",
          "consensus_move": "e6f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd2",
              "Rfe8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd2",
              "Rfe8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd2",
              "Rfe8",
              "Rfd1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 231,
            "completion_tokens": 147,
            "total_tokens": 378,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 231,
            "completion_tokens": 147,
            "total_tokens": 378,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 230,
            "completion_tokens": 137,
            "total_tokens": 367,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 692,
          "total_completion_tokens": 431,
          "total_tokens": 1123
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 231,
            "completion_tokens": 147,
            "total_tokens": 378,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 231,
            "completion_tokens": 147,
            "total_tokens": 378,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 230,
            "completion_tokens": 137,
            "total_tokens": 367,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/pbp2pp1/1p2qB1p/3p4/8/2NBP3/PP3PPP/2RQ1RK1 b - - 0 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qg6",
          "aggressive_uci": "f6g6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Qf3 Rfe8 18. Rfd1",
          "aggressive_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 146,
            "total_tokens": 386,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rfe8",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qg6",
          "positional_uci": "f6g6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Qf3 Rfd8 18. Nf4\nQg6 Qf3 Rfd8 Nf4",
          "positional_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 158,
            "total_tokens": 398,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rfd8",
            "Nf4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qg6",
          "neutral_uci": "f6g6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Qf3 Rfe8 18. Rfd1",
          "neutral_tokens": {
            "prompt_tokens": 239,
            "completion_tokens": 146,
            "total_tokens": 385,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf3",
            "Rfe8",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f6g6",
          "positional_uci": "f6g6",
          "neutral_uci": "f6g6",
          "consensus_move": "f6g6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qf3",
              "Rfe8",
              "Rfd1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf3",
              "Rfd8",
              "Nf4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qf3",
              "Rfe8",
              "Rfd1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 240,
            "completion_tokens": 146,
            "total_tokens": 386,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 240,
            "completion_tokens": 158,
            "total_tokens": 398,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 239,
            "completion_tokens": 146,
            "total_tokens": 385,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 719,
          "total_completion_tokens": 450,
          "total_tokens": 1169
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 240,
            "completion_tokens": 146,
            "total_tokens": 386,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 240,
            "completion_tokens": 158,
            "total_tokens": 398,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 239,
            "completion_tokens": 146,
            "total_tokens": 385,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/pbp2pp1/1p3q1p/3N4/8/3BP3/PP3PPP/2RQ1RK1 b - - 0 16"
    },
    {
      "turn": 34,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "fxg6",
          "aggressive_uci": "f7g6",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Qd4 Rf7 19. Rfd1",
          "aggressive_tokens": {
            "prompt_tokens": 249,
            "completion_tokens": 155,
            "total_tokens": 404,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd4",
            "Rf7",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "fxg6",
          "positional_uci": "f7g6",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Qd4 Rf7 19. Rfd1\nfxg6 Qd4 Rf7 Rfd1",
          "positional_tokens": {
            "prompt_tokens": 249,
            "completion_tokens": 168,
            "total_tokens": 417,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd4",
            "Rf7",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "fxg6",
          "neutral_uci": "f7g6",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Qd3 Rf7 19. Rfd1",
          "neutral_tokens": {
            "prompt_tokens": 248,
            "completion_tokens": 155,
            "total_tokens": 403,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd3",
            "Rf7",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f7g6",
          "positional_uci": "f7g6",
          "neutral_uci": "f7g6",
          "consensus_move": "f7g6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd4",
              "Rf7",
              "Rfd1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd4",
              "Rf7",
              "Rfd1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd3",
              "Rf7",
              "Rfd1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 249,
            "completion_tokens": 155,
            "total_tokens": 404,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 249,
            "completion_tokens": 168,
            "total_tokens": 417,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 248,
            "completion_tokens": 155,
            "total_tokens": 403,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 746,
          "total_completion_tokens": 478,
          "total_tokens": 1224
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 249,
            "completion_tokens": 155,
            "total_tokens": 404,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 249,
            "completion_tokens": 168,
            "total_tokens": 417,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 248,
            "completion_tokens": 155,
            "total_tokens": 403,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/pbp2pp1/1p4Bp/3N4/8/4P3/PP3PPP/2RQ1RK1 b - - 0 17"
    },
    {
      "turn": 36,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kh8",
          "aggressive_uci": "g8h8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Qd3 Rf7 20. Qxg6\nKh8 Qd3 Rf7 Qxg6",
          "aggressive_tokens": {
            "prompt_tokens": 258,
            "completion_tokens": 175,
            "total_tokens": 433,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd3",
            "Rf7",
            "Qxg6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kh8",
          "positional_uci": "g8h8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Qd4\nKh8 Kg8 Qd4",
          "positional_tokens": {
            "prompt_tokens": 258,
            "completion_tokens": 171,
            "total_tokens": 429,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg8",
            "Qd4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kh8",
          "neutral_uci": "g8h8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Qd4\nKh8 Qd4 Qh4",
          "neutral_tokens": {
            "prompt_tokens": 257,
            "completion_tokens": 172,
            "total_tokens": 429,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd4",
            "Qh4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8h8",
          "positional_uci": "g8h8",
          "neutral_uci": "g8h8",
          "consensus_move": "g8h8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd3",
              "Rf7",
              "Qxg6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg8",
              "Qd4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd4",
              "Qh4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 258,
            "completion_tokens": 175,
            "total_tokens": 433,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 258,
            "completion_tokens": 171,
            "total_tokens": 429,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 257,
            "completion_tokens": 172,
            "total_tokens": 429,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 773,
          "total_completion_tokens": 518,
          "total_tokens": 1291
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 258,
            "completion_tokens": 175,
            "total_tokens": 433,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 258,
            "completion_tokens": 171,
            "total_tokens": 429,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 257,
            "completion_tokens": 172,
            "total_tokens": 429,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/pbp1N1p1/1p4pp/8/8/4P3/PP3PPP/2RQ1RK1 b - - 1 18"
    },
    {
      "turn": 38,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kg8",
          "aggressive_uci": "h8g8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Qd4 Rf7 21. Rc7\nKg8 Qd4 Rf7 Rc7",
          "aggressive_tokens": {
            "prompt_tokens": 267,
            "completion_tokens": 184,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd4",
            "Rf7",
            "Rc7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kg8",
          "positional_uci": "h8g8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Qd4 Rf7 21. Rc7\nKg8 Qd4 Rf7 Rc7",
          "positional_tokens": {
            "prompt_tokens": 267,
            "completion_tokens": 184,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd4",
            "Rf7",
            "Rc7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kh7",
          "neutral_uci": "h8h7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kh7 20. Qg4 Rf7 21. Qh5+\nKh7 Qg4 Rf7 Qh5+",
          "neutral_tokens": {
            "prompt_tokens": 266,
            "completion_tokens": 185,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg4",
            "Rf7",
            "Qh5+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h8g8",
          "positional_uci": "h8g8",
          "neutral_uci": "h8h7",
          "consensus_move": "h8g8",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd4",
              "Rf7",
              "Rc7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd4",
              "Rf7",
              "Rc7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qg4",
              "Rf7",
              "Qh5+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 267,
            "completion_tokens": 184,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 267,
            "completion_tokens": 184,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 266,
            "completion_tokens": 185,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 800,
          "total_completion_tokens": 553,
          "total_tokens": 1353
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 267,
            "completion_tokens": 184,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 267,
            "completion_tokens": 184,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 266,
            "completion_tokens": 185,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4r1k/pbp3p1/1p4Np/8/8/4P3/PP3PPP/2RQ1RK1 b - - 0 19"
    },
    {
      "turn": 40,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kxf8",
          "aggressive_uci": "g8f8",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 * Kxf8 Rxf8+ Kg7 Qf3",
          "aggressive_tokens": {
            "prompt_tokens": 275,
            "completion_tokens": 176,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf8+",
            "Kg7",
            "Qf3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kxf8",
          "positional_uci": "g8f8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Qd2 Ke7 22. Rfd1\nKxf8 Qd2 Ke7 Rfd1",
          "positional_tokens": {
            "prompt_tokens": 275,
            "completion_tokens": 192,
            "total_tokens": 467,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd2",
            "Ke7",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kxf8",
          "neutral_uci": "g8f8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Qd2 Ke7 22. Rfd1",
          "neutral_tokens": {
            "prompt_tokens": 274,
            "completion_tokens": 180,
            "total_tokens": 454,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd2",
            "Ke7",
            "Rfd1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f8",
          "positional_uci": "g8f8",
          "neutral_uci": "g8f8",
          "consensus_move": "g8f8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxf8+",
              "Kg7",
              "Qf3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd2",
              "Ke7",
              "Rfd1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd2",
              "Ke7",
              "Rfd1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 275,
            "completion_tokens": 176,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 275,
            "completion_tokens": 192,
            "total_tokens": 467,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 274,
            "completion_tokens": 180,
            "total_tokens": 454,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 824,
          "total_completion_tokens": 548,
          "total_tokens": 1372
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 275,
            "completion_tokens": 176,
            "total_tokens": 451,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 275,
            "completion_tokens": 192,
            "total_tokens": 467,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 274,
            "completion_tokens": 180,
            "total_tokens": 454,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4Nk1/pbp3p1/1p5p/8/8/4P3/PP3PPP/2RQ1RK1 b - - 0 20"
    },
    {
      "turn": 42,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc7",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 *\nBlack Rxc7 22. Qd2 Rxc7 23. Qd8+",
          "aggressive_tokens": {
            "prompt_tokens": 284,
            "completion_tokens": 193,
            "total_tokens": 477,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd8+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rc8",
          "positional_uci": "a8c8",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Rxc8+ Bxc8 23. Qd5\nRc8 Rxc8+ Qd5",
          "positional_tokens": {
            "prompt_tokens": 284,
            "completion_tokens": 202,
            "total_tokens": 486,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxc8+",
            "Qd5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rc8",
          "neutral_uci": "a8c8",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Rxc8+ Bxc8 23. Qc2",
          "neutral_tokens": {
            "prompt_tokens": 283,
            "completion_tokens": 191,
            "total_tokens": 474,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxc8+",
            "Bxc8",
            "Qc2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "a8c8",
          "neutral_uci": "a8c8",
          "consensus_move": "a8c8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd8+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxc8+",
              "Qd5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxc8+",
              "Bxc8",
              "Qc2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 284,
            "completion_tokens": 193,
            "total_tokens": 477,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 284,
            "completion_tokens": 202,
            "total_tokens": 486,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 283,
            "completion_tokens": 191,
            "total_tokens": 474,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 851,
          "total_completion_tokens": 586,
          "total_tokens": 1437
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 284,
            "completion_tokens": 193,
            "total_tokens": 477,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 284,
            "completion_tokens": 202,
            "total_tokens": 486,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 283,
            "completion_tokens": 191,
            "total_tokens": 474,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4k2/pbR3p1/1p5p/8/8/4P3/PP3PPP/3Q1RK1 b - - 0 21"
    },
    {
      "turn": 44,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc7",
          "aggressive_uci": "c8c7",
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Ke8 24. Qb7",
          "aggressive_tokens": {
            "prompt_tokens": 293,
            "completion_tokens": 198,
            "total_tokens": 491,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc7",
            "Ke8",
            "Qb7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxc7",
          "positional_uci": "c8c7",
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Ke8 24. Qb7",
          "positional_tokens": {
            "prompt_tokens": 293,
            "completion_tokens": 198,
            "total_tokens": 491,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc7",
            "Ke8",
            "Qb7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxc7",
          "neutral_uci": "c8c7",
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Ke8 24. Qxb7",
          "neutral_tokens": {
            "prompt_tokens": 292,
            "completion_tokens": 198,
            "total_tokens": 490,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc7",
            "Ke8",
            "Qxb7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8c7",
          "positional_uci": "c8c7",
          "neutral_uci": "c8c7",
          "consensus_move": "c8c7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxc7",
              "Ke8",
              "Qb7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxc7",
              "Ke8",
              "Qb7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxc7",
              "Ke8",
              "Qxb7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 293,
            "completion_tokens": 198,
            "total_tokens": 491,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 293,
            "completion_tokens": 198,
            "total_tokens": 491,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 292,
            "completion_tokens": 198,
            "total_tokens": 490,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 878,
          "total_completion_tokens": 594,
          "total_tokens": 1472
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 293,
            "completion_tokens": 198,
            "total_tokens": 491,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 293,
            "completion_tokens": 198,
            "total_tokens": 491,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 292,
            "completion_tokens": 198,
            "total_tokens": 490,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2r2k2/pbRQ2p1/1p5p/8/8/4P3/PP3PPP/5RK1 b - - 2 22"
    },
    {
      "turn": 46,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qf7",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Qf7 Qe8 Qd8",
          "aggressive_tokens": {
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe8",
            "Qd8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd6",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Qd6 Qe7 Qf6",
          "positional_tokens": {
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe7",
            "Qf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qf7",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Qf7 Qe8 Qd8",
          "neutral_tokens": {
            "prompt_tokens": 301,
            "completion_tokens": 199,
            "total_tokens": 500,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe8",
            "Qd8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qe8",
              "Qd8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe7",
              "Qf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe8",
              "Qd8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 301,
            "completion_tokens": 199,
            "total_tokens": 500,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 905,
          "total_completion_tokens": 597,
          "total_tokens": 1502
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 301,
            "completion_tokens": 199,
            "total_tokens": 500,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5k2/pbQ3p1/1p5p/8/8/4P3/PP3PPP/5RK1 b - - 0 23"
    },
    {
      "turn": 46,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe8",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Qe8 Qe6 Qf7",
          "aggressive_tokens": {
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe6",
            "Qf7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qf5",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Qf5 24. Qd8+ Kf7 25. Qxh6",
          "positional_tokens": {
            "prompt_tokens": 302,
            "completion_tokens": 209,
            "total_tokens": 511,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd8+",
            "Kf7",
            "Qxh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qf7",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Qf7 Qe8 Qd8",
          "neutral_tokens": {
            "prompt_tokens": 301,
            "completion_tokens": 199,
            "total_tokens": 500,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe8",
            "Qd8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qe6",
              "Qf7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd8+",
              "Kf7",
              "Qxh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe8",
              "Qd8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 302,
            "completion_tokens": 209,
            "total_tokens": 511,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 301,
            "completion_tokens": 199,
            "total_tokens": 500,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 905,
          "total_completion_tokens": 607,
          "total_tokens": 1512
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 302,
            "completion_tokens": 209,
            "total_tokens": 511,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 301,
            "completion_tokens": 199,
            "total_tokens": 500,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5k2/pbQ3p1/1p5p/8/8/4P3/PP3PPP/5RK1 b - - 0 23"
    },
    {
      "turn": 46,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qf6",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Qf6 Qe7 Qe8",
          "aggressive_tokens": {
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe7",
            "Qe8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe6",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 Qe6 24. Qd8+ Kg7 25. Qe7+ Kh8\nQe6 Qd8+ Qe7+",
          "positional_tokens": {
            "prompt_tokens": 302,
            "completion_tokens": 223,
            "total_tokens": 525,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd8+",
            "Qe7+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxc7",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nf3 Nf6 3. Bg5 e6 4. e3 Be7 5. Bd3 O-O 6. O-O h6 7. Bh4 b6 8. c4 Bb7 9. Nc3 Nbd7 10. Rc1 Qc8 11. cxd5 exd5 12. Ne5 Nxe5 13. dxe5 Qe6 14. exf6 Bxf6 15. Bxf6 Qxf6 16. Nxd5 Qg6 17. Bxg6 fxg6 18. Ne7+ Kh8 19. Nxg6+ Kg8 20. Nxf8 Kxf8 21. Rxc7 Rc8 22. Qd7 Rxc7 23. Qxc7 * Qxc7 Qd8 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 301,
            "completion_tokens": 200,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd8",
            "Qe7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qe7",
              "Qe8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qd8+",
              "Qe7+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd8",
              "Qe7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 302,
            "completion_tokens": 223,
            "total_tokens": 525,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 301,
            "completion_tokens": 200,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 905,
          "total_completion_tokens": 622,
          "total_tokens": 1527
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 302,
            "completion_tokens": 199,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 302,
            "completion_tokens": 223,
            "total_tokens": 525,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 301,
            "completion_tokens": 200,
            "total_tokens": 501,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5k2/pbQ3p1/1p5p/8/8/4P3/PP3PPP/5RK1 b - - 0 23"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d6 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Bb7 15. Be3 Rac8 16. Rc1 Qb8 17. d5 Nb4 18. Bb1 Rxc1 19. Qxc1 Rc8 20. Qd2 Nc2 21. Qe2 Nb4 22. Qd2 Nc2 23. Qe2 Nb4 24. Qd2 Nc2 25. Qe2 Nb4 26. Qd2 Nc2 27. Qe2 Nb4 28. Qd2 Nc2 29. Qe2 Nb4 30. Qd2 Nc2 31. Qe2 Nb4 32. Qd2 Nc2 33. Qe2 Nb4 34. Qd2 Nc2 35. Qe2 Nb4 36. Qd2 Nc2 37. Qe2 Nb4 38. Qd2 Nc2 39. Qe2 Nb4 40. Qd2 Nc2 41. Qe2 Nb4 42. Qd2 Nc2 43. Qe2 Nb4 44. Qd2 Nc2 45. Qe2 Nb4 46. Qd2 Nc2 47. Qe2 Nb4 48. Qd2 Nc2 49. Qe2 Nb4 50. Qd2 Nc2 51. Qe2 Nb4 52. Qd2 Nc2 53. Qe2 Nb4 54. Qd2 Nc2 55. Qe2 Nb4 56. Qd2 Nc2 57. Qe2 Nb4 58. Qd2 Nc2 59. Qe2 Nb4 60. Qd2 Nc2 61. Qe2 Nb4 62. Qd2 Nc2 63. Qe2 Nb4 64. Qd2 Nc2 65. Qe2 Nb4 66. Qd2 Nc2 67. Qe2 Nb4 68. Qd2 Nc2 69. Qe2 Nb4 70. Qd2 Nc2 71. Qe2 Nb4 72. Qd2 Nc2 73. Qe2 Nb4 74. Qd2 Nc2 75. Qe2 Nb4 76. Qd2 Nc2 77. Qe",
          "aggressive_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Be3",
            "Rac8",
            "Rc1",
            "Qb8",
            "d5",
            "Nb4",
            "Bb1",
            "Rxc1",
            "Qxc1",
            "Rc8",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2",
            "Qe2",
            "Nb4",
            "Qd2",
            "Nc2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d6 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Nb4 15. Bb1 Bb7 16. a3 Nc6 17. d5 Nb8 18. Bd3 g6 19. Be3 Nh5 20. Qd2 f5 21. exf5 gxf5 22. Rxe5 dxe5 23. Qxh5 Qf7 24. Qxf7+ Rxf7 25. Bxf5 Rxf5 26. Nxe5 Re8 27. Nxf7 Kxf7 28. Bxb4+ Ke7 29. Bc5+ Kf7 30. Bxe8+ Kxe8 31. Nc5 Bc8 32. Nxb7 Bxb7 33. Rc1 Bc8 34. Rc7 Kd8 35. Rxa7 Kc8 36. Ra8+ Kb7 37. Rxc8 Kxc8 38. a4 Kd7 39. a5 Ke7 40. a6 Kf7 41. a7 Kg7 42. a8=Q Kh7 43. Qg8# 1-0\nBlack Qg8#",
          "positional_tokens": {
            "prompt_tokens": 112,
            "completion_tokens": 366,
            "total_tokens": 478,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Nb4",
            "Bb1",
            "Bb7",
            "a3",
            "Nc6",
            "d5",
            "Nb8",
            "Bd3",
            "g6",
            "Be3",
            "Nh5",
            "Qd2",
            "f5",
            "exf5",
            "gxf5",
            "Rxe5",
            "dxe5",
            "Qxh5",
            "Qf7",
            "Qxf7+",
            "Rxf7",
            "Bxf5",
            "Rxf5",
            "Nxe5",
            "Re8",
            "Nxf7",
            "Kxf7",
            "Bxb4+",
            "Ke7",
            "Bc5+",
            "Kf7",
            "Bxe8+",
            "Kxe8",
            "Nc5",
            "Bc8",
            "Nxb7",
            "Bxb7",
            "Rc1",
            "Bc8",
            "Rc7",
            "Kd8",
            "Rxa7",
            "Kc8",
            "Ra8+",
            "Kb7",
            "Rxc8",
            "Kxc8",
            "a4",
            "Kd7",
            "a5",
            "Ke7",
            "a6",
            "Kf7",
            "a7",
            "Kg7",
            "a8=Q",
            "Kh7",
            "Qg8#",
            "Qg8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d6 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Bb7 15. Be3 Rac8 16. Rc1 Qb8 17. d5 Nb4 18. Bb1 Rxc1 19. Qxc1 Rc8 20. Qd2 Bc5 21. Nxc5 dxc5 22. Qg5 Qd6 23. Qxd6 cxd6 24. Bxb4 cxb4 25. Rc1 Rxc1+ 26. Bxc1 Kf8 27. Kf1 Ke7 28. Ke2 Kd7 29. Kd3 Kc7 30. Kc4 Kb6 31. Bb2 f6 32. a3 bxa3 33. Bxa3 Bxa3 34. Kb3 Bb4 35. Kc4 Bc5 36. b3 Kc7 37. Kb5 Kd7 38. Kc4 Kc7 39. Kb5 Kb7 40. Kc4 Kc7 41. Kb5 Kb7 42. Kc4 Kc7 43. Kb5 Kb7 44. Kc4 Kc7 45. Kb5 Kb7 46. Kc4 Kc7 47. Kb5 Kb7 48. Kc4 Kc7 49. Kb5 Kb7 50. Kc4 Kc7 51. Kb5 Kb7 52. Kc4 Kc7 53. Kb5 Kb7 54. Kc4 Kc7 55. Kb5 Kb7 56. Kc4 Kc7 57. Kb5 Kb7 58. Kc4 Kc7 59. Kb5 Kb7 60. Kc4 Kc7 61. Kb5 Kb7 62. Kc4 Kc7 63. Kb5 Kb7 64. Kc4 Kc7 65. Kb5 Kb7 66. Kc4 Kc7 67. Kb5 Kb7 68. Kc4 Kc7 69. Kb5 Kb7 70. Kc4 Kc7 71. Kb5 Kb7 72. Kc4 Kc7 73. Kb5 Kb7 74. Kc4 Kc",
          "neutral_tokens": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Be3",
            "Rac8",
            "Rc1",
            "Qb8",
            "d5",
            "Nb4",
            "Bb1",
            "Rxc1",
            "Qxc1",
            "Rc8",
            "Qd2",
            "Bc5",
            "Nxc5",
            "dxc5",
            "Qg5",
            "Qd6",
            "Qxd6",
            "cxd6",
            "Bxb4",
            "cxb4",
            "Rc1",
            "Rxc1+",
            "Bxc1",
            "Kf8",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd7",
            "Kd3",
            "Kc7",
            "Kc4",
            "Kb6",
            "Bb2",
            "f6",
            "a3",
            "bxa3",
            "Bxa3",
            "Bxa3",
            "Kb3",
            "Bb4",
            "Kc4",
            "Bc5",
            "b3",
            "Kc7",
            "Kb5",
            "Kd7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4",
            "Kc7",
            "Kb5",
            "Kb7",
            "Kc4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Be3",
              "Rac8",
              "Rc1",
              "Qb8",
              "d5",
              "Nb4",
              "Bb1",
              "Rxc1",
              "Qxc1",
              "Rc8",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2",
              "Qe2",
              "Nb4",
              "Qd2",
              "Nc2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Nb4",
              "Bb1",
              "Bb7",
              "a3",
              "Nc6",
              "d5",
              "Nb8",
              "Bd3",
              "g6",
              "Be3",
              "Nh5",
              "Qd2",
              "f5",
              "exf5",
              "gxf5",
              "Rxe5",
              "dxe5",
              "Qxh5",
              "Qf7",
              "Qxf7+",
              "Rxf7",
              "Bxf5",
              "Rxf5",
              "Nxe5",
              "Re8",
              "Nxf7",
              "Kxf7",
              "Bxb4+",
              "Ke7",
              "Bc5+",
              "Kf7",
              "Bxe8+",
              "Kxe8",
              "Nc5",
              "Bc8",
              "Nxb7",
              "Bxb7",
              "Rc1",
              "Bc8",
              "Rc7",
              "Kd8",
              "Rxa7",
              "Kc8",
              "Ra8+",
              "Kb7",
              "Rxc8",
              "Kxc8",
              "a4",
              "Kd7",
              "a5",
              "Ke7",
              "a6",
              "Kf7",
              "a7",
              "Kg7",
              "a8=Q",
              "Kh7",
              "Qg8#",
              "Qg8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Be3",
              "Rac8",
              "Rc1",
              "Qb8",
              "d5",
              "Nb4",
              "Bb1",
              "Rxc1",
              "Qxc1",
              "Rc8",
              "Qd2",
              "Bc5",
              "Nxc5",
              "dxc5",
              "Qg5",
              "Qd6",
              "Qxd6",
              "cxd6",
              "Bxb4",
              "cxb4",
              "Rc1",
              "Rxc1+",
              "Bxc1",
              "Kf8",
              "Kf1",
              "Ke7",
              "Ke2",
              "Kd7",
              "Kd3",
              "Kc7",
              "Kc4",
              "Kb6",
              "Bb2",
              "f6",
              "a3",
              "bxa3",
              "Bxa3",
              "Bxa3",
              "Kb3",
              "Bb4",
              "Kc4",
              "Bc5",
              "b3",
              "Kc7",
              "Kb5",
              "Kd7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4",
              "Kc7",
              "Kb5",
              "Kb7",
              "Kc4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 112,
            "completion_tokens": 366,
            "total_tokens": 478,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 335,
          "total_completion_tokens": 1646,
          "total_tokens": 1981
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 112,
            "completion_tokens": 640,
            "total_tokens": 752,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 112,
            "completion_tokens": 366,
            "total_tokens": 478,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 111,
            "completion_tokens": 640,
            "total_tokens": 751,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 * e4 e5 Nf3 Nc6",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5\ne4 e5 Nf3 Nc6 Bb5\nWhite Black Nf3 Nc6 Bb5",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 33,
            "total_tokens": 151,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Nf3",
            "Nc6",
            "Bb5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Nf3",
              "Nc6",
              "Bb5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 33,
            "total_tokens": 151,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 69,
          "total_tokens": 422
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 18,
            "total_tokens": 136,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 33,
            "total_tokens": 151,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 21,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5\ne4 e5 Nf3 Nc6 Bb5",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 21,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 21,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 21,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 60,
          "total_tokens": 413
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 21,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 21,
            "total_tokens": 139,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 18,
            "total_tokens": 135,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Ng5 cxd4 cxd4 Nc6 Nxc6 Qxc6 Qf3 Bb7 Qg3 g6 Nxe5 dxe5 Qxg6+ hxg6 Bxg6+ Kh8 Bh7#",
          "aggressive_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 109,
            "total_tokens": 227,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Ng5",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nxc6",
            "Qxc6",
            "Qf3",
            "Bb7",
            "Qg3",
            "g6",
            "Nxe5",
            "dxe5",
            "Qxg6+",
            "hxg6",
            "Bxg6+",
            "Kh8",
            "Bh7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 h3 Na5 Bc2 c5 d4 Qc7 Nbd2 cxd4 cxd4 exd4 Nb3 Nb7 Nfxd4 Nxd4 Nxd4 Bb7 Qf3 Rfe8 Bg5 Bf8 Rad1 Qb8 Qg3 g6 f4 Bg7 e5 dxe5 fxe5 Qxe5 Qxe5 Bxe5 Bxe5 Rxe5 Rxe5 Nc5 Re7 Bxf7+ Kxf7 Rxf7+ Kg8 Rd7 Ne6 Rxh7 Nf4 Rxa7 Nxh3+ Kg2 Nf4+ Kf3 Rd8 Ra6 Rd3+ Ke4 Rxh3 Kf5 Rf3+ Kg5 Rg3+ Kh6 Rg4 Kh5 Rf4 Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6 Rf6+ Kh5 Rf5+ Kh6",
          "positional_tokens": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "exd4",
            "Nb3",
            "Nb7",
            "Nfxd4",
            "Nxd4",
            "Nxd4",
            "Bb7",
            "Qf3",
            "Rfe8",
            "Bg5",
            "Bf8",
            "Rad1",
            "Qb8",
            "Qg3",
            "g6",
            "f4",
            "Bg7",
            "e5",
            "dxe5",
            "fxe5",
            "Qxe5",
            "Qxe5",
            "Bxe5",
            "Bxe5",
            "Rxe5",
            "Rxe5",
            "Nc5",
            "Re7",
            "Bxf7+",
            "Kxf7",
            "Rxf7+",
            "Kg8",
            "Rd7",
            "Ne6",
            "Rxh7",
            "Nf4",
            "Rxa7",
            "Nxh3+",
            "Kg2",
            "Nf4+",
            "Kf3",
            "Rd8",
            "Ra6",
            "Rd3+",
            "Ke4",
            "Rxh3",
            "Kf5",
            "Rf3+",
            "Kg5",
            "Rg3+",
            "Kh6",
            "Rg4",
            "Kh5",
            "Rf4",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6",
            "Rf6+",
            "Kh5",
            "Rf5+",
            "Kh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 * e4 e5 Nf3 Nc6 Bb5",
          "neutral_tokens": {
            "prompt_tokens": 117,
            "completion_tokens": 21,
            "total_tokens": 138,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Ng5",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nxc6",
              "Qxc6",
              "Qf3",
              "Bb7",
              "Qg3",
              "g6",
              "Nxe5",
              "dxe5",
              "Qxg6+",
              "hxg6",
              "Bxg6+",
              "Kh8",
              "Bh7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "exd4",
              "Nb3",
              "Nb7",
              "Nfxd4",
              "Nxd4",
              "Nxd4",
              "Bb7",
              "Qf3",
              "Rfe8",
              "Bg5",
              "Bf8",
              "Rad1",
              "Qb8",
              "Qg3",
              "g6",
              "f4",
              "Bg7",
              "e5",
              "dxe5",
              "fxe5",
              "Qxe5",
              "Qxe5",
              "Bxe5",
              "Bxe5",
              "Rxe5",
              "Rxe5",
              "Nc5",
              "Re7",
              "Bxf7+",
              "Kxf7",
              "Rxf7+",
              "Kg8",
              "Rd7",
              "Ne6",
              "Rxh7",
              "Nf4",
              "Rxa7",
              "Nxh3+",
              "Kg2",
              "Nf4+",
              "Kf3",
              "Rd8",
              "Ra6",
              "Rd3+",
              "Ke4",
              "Rxh3",
              "Kf5",
              "Rf3+",
              "Kg5",
              "Rg3+",
              "Kh6",
              "Rg4",
              "Kh5",
              "Rf4",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6",
              "Rf6+",
              "Kh5",
              "Rf5+",
              "Kh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 118,
            "completion_tokens": 109,
            "total_tokens": 227,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 117,
            "completion_tokens": 21,
            "total_tokens": 138,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 353,
          "total_completion_tokens": 770,
          "total_tokens": 1123
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 118,
            "completion_tokens": 109,
            "total_tokens": 227,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 118,
            "completion_tokens": 640,
            "total_tokens": 758,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 117,
            "completion_tokens": 21,
            "total_tokens": 138,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1. e4 e5\ne5 *",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 11,
            "total_tokens": 127,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d6 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 Bb7 15. Be3 Rac8 16. Rc1 Qb8 17. dxe5 dxe5 18. Qxd8 Rfxd8 19. Nxe5 Nxe5 20. Bxb7 Nxb7 21. Rxc8 Rxc8 22. Rc1 Rxc1+ 23. Bxc1 Nc5 24. Nd4 Nd3 25. Bxd3 Bc5 26. Nf5 Bxf2+ 27. Kh2 Bxe1 28. Nxg7 Kxg7 29. Bc4+ Kg6 30. Qxe1 Qxb2 31. Qe4+ Kh6 32. Qf4+ Kg7 33. Qg5+ Kh8 34. Qh6+ Kg8 35. Qg6+ Kh8 36. Qh6+ Kg8 37. Qg6+ Kh8 38. Qh6+ Kg8 39. Qg6+ Kh8 40. Qh6+ Kg8 41. Qg6+ Kh8 42. Qh6+ Kg8 43. Qg6+ Kh8 44. Qh6+ Kg8 45. Qg6+ Kh8 46. Qh6+ Kg8 47. Qg6+ Kh8 48. Qh6+ Kg8 49. Qg6+ Kh8 50. Qh6+ Kg8 51. Qg6+ Kh8 52. Qh6+ Kg8 53. Qg6+ Kh8 54. Qh6+ Kg8 55. Qg6+ Kh8 56. Qh6+ Kg8 57. Qg6+ Kh8 58. Qh6+ Kg8 59. Qg6+ Kh8 60. Qh6+ Kg8 61. Qg6+ Kh8 62. Qh6+ Kg8 63. Qg6+ Kh8 64. Qh6+ Kg8 65. Qg6+ Kh8 66. Qh6+ Kg8 67. Qg6+ Kh8 68. Qh6+ Kg8 69. Qg6+ Kh8 70. Qh6+ Kg8 71. Qg6+ Kh8 72. Qh6+ Kg8 73. Qg6+ Kh8 74",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "Bb7",
            "Be3",
            "Rac8",
            "Rc1",
            "Qb8",
            "dxe5",
            "dxe5",
            "Qxd8",
            "Rfxd8",
            "Nxe5",
            "Nxe5",
            "Bxb7",
            "Nxb7",
            "Rxc8",
            "Rxc8",
            "Rc1",
            "Rxc1+",
            "Bxc1",
            "Nc5",
            "Nd4",
            "Nd3",
            "Bxd3",
            "Bc5",
            "Nf5",
            "Bxf2+",
            "Kh2",
            "Bxe1",
            "Nxg7",
            "Kxg7",
            "Bc4+",
            "Kg6",
            "Qxe1",
            "Qxb2",
            "Qe4+",
            "Kh6",
            "Qf4+",
            "Kg7",
            "Qg5+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg6+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 *\ne4",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": null,
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "Bb7",
              "Be3",
              "Rac8",
              "Rc1",
              "Qb8",
              "dxe5",
              "dxe5",
              "Qxd8",
              "Rfxd8",
              "Nxe5",
              "Nxe5",
              "Bxb7",
              "Nxb7",
              "Rxc8",
              "Rxc8",
              "Rc1",
              "Rxc1+",
              "Bxc1",
              "Nc5",
              "Nd4",
              "Nd3",
              "Bxd3",
              "Bc5",
              "Nf5",
              "Bxf2+",
              "Kh2",
              "Bxe1",
              "Nxg7",
              "Kxg7",
              "Bc4+",
              "Kg6",
              "Qxe1",
              "Qxb2",
              "Qe4+",
              "Kh6",
              "Qf4+",
              "Kg7",
              "Qg5+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg6+",
              "Kh8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 11,
            "total_tokens": 127,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 659,
          "total_tokens": 1006
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 11,
            "total_tokens": 127,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 8,
            "total_tokens": 123,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "1. e4 e5 2. Nf3 *\nNc6 Bb5",
          "aggressive_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 20,
            "total_tokens": 144,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "1. e4 e5 2. Nf3 * Nc6 3. Bb5\nNc6 Bb5",
          "positional_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "1. e4 e5 2. Nf3 * Nc6 3. Bb5\nNc6 Bb5",
          "neutral_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 30,
            "total_tokens": 153,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 124,
            "completion_tokens": 20,
            "total_tokens": 144,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 123,
            "completion_tokens": 30,
            "total_tokens": 153,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 371,
          "total_completion_tokens": 80,
          "total_tokens": 451
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 124,
            "completion_tokens": 20,
            "total_tokens": 144,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 124,
            "completion_tokens": 30,
            "total_tokens": 154,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 123,
            "completion_tokens": 30,
            "total_tokens": 153,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O\nWhite O-O Be7 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 46,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "O-O",
            "Be7",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\nBb5 a6 Ba4 Nf6 O-O Be7",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 53,
            "total_tokens": 186,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a7a6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\nBa4 Nf6 O-O Be7",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 49,
            "total_tokens": 181,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "a7a6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "O-O",
              "Be7",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 46,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 53,
            "total_tokens": 186,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 49,
            "total_tokens": 181,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 148,
          "total_tokens": 546
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 46,
            "total_tokens": 179,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 53,
            "total_tokens": 186,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 49,
            "total_tokens": 181,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxc6",
          "aggressive_uci": "d7c6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. O-O Bg4 6. h3",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 46,
            "total_tokens": 187,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bg4",
            "h3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "dxc6",
          "positional_uci": "d7c6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 * dxc6 5. O-O f6",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 41,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "f6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "dxc6",
          "neutral_uci": "d7c6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. O-O f6 6. d4",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "f6",
            "d4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7c6",
          "positional_uci": "d7c6",
          "neutral_uci": "d7c6",
          "consensus_move": "d7c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Bg4",
              "h3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "f6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "f6",
              "d4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 46,
            "total_tokens": 187,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 41,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 132,
          "total_tokens": 554
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 46,
            "total_tokens": 187,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 41,
            "total_tokens": 182,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 45,
            "total_tokens": 185,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1B5/4p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qd4",
          "aggressive_uci": "d8d4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be2",
          "aggressive_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qxe4+",
            "Be2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd4",
          "positional_uci": "d8d4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be3",
          "positional_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qxe4+",
            "Be3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qd4",
          "neutral_uci": "d8d4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be3",
          "neutral_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 57,
            "total_tokens": 206,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qxe4+",
            "Be3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8d4",
          "positional_uci": "d8d4",
          "neutral_uci": "d8d4",
          "consensus_move": "d8d4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Qxe4+",
              "Be2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Qxe4+",
              "Be3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf3",
              "Qxe4+",
              "Be3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 149,
            "completion_tokens": 57,
            "total_tokens": 206,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 449,
          "total_completion_tokens": 171,
          "total_tokens": 620
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 150,
            "completion_tokens": 57,
            "total_tokens": 207,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 149,
            "completion_tokens": 57,
            "total_tokens": 206,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1pp2ppp/p1p5/4N3/4P3/8/PPPP1PPP/RNBQK2R b KQkq - 0 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe4+",
          "aggressive_uci": "d4e4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be2 Qxg2 8. Rg1 Qxh2",
          "aggressive_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 69,
            "total_tokens": 228,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Qxg2",
            "Rg1",
            "Qxh2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe4+",
          "positional_uci": "d4e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Qe2 Qxe2+ 8. Kxe2",
          "positional_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 68,
            "total_tokens": 227,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Qxe2+",
            "Kxe2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe4+",
          "neutral_uci": "d4e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Be3 Qg4 8. O-O",
          "neutral_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 65,
            "total_tokens": 223,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be3",
            "Qg4",
            "O-O"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d4e4",
          "positional_uci": "d4e4",
          "neutral_uci": "d4e4",
          "consensus_move": "d4e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be2",
              "Qxg2",
              "Rg1",
              "Qxh2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe2",
              "Qxe2+",
              "Kxe2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be3",
              "Qg4",
              "O-O"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 159,
            "completion_tokens": 69,
            "total_tokens": 228,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 159,
            "completion_tokens": 68,
            "total_tokens": 227,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 158,
            "completion_tokens": 65,
            "total_tokens": 223,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 476,
          "total_completion_tokens": 202,
          "total_tokens": 678
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 159,
            "completion_tokens": 69,
            "total_tokens": 228,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 159,
            "completion_tokens": 68,
            "total_tokens": 227,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 158,
            "completion_tokens": 65,
            "total_tokens": 223,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/3qP3/5N2/PPPP1PPP/RNBQK2R b KQkq - 2 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be6",
          "aggressive_uci": "c8e6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Be6 8. d3 Qf5 9. Be3\n* Be6 d3 Be3",
          "aggressive_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 81,
            "total_tokens": 250,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Be3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qf5",
          "positional_uci": "e4f5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Bg4 9. Qd2",
          "positional_tokens": {
            "prompt_tokens": 169,
            "completion_tokens": 75,
            "total_tokens": 244,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Bg4",
            "Qd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qf5",
          "neutral_uci": "e4f5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Be6 9. Be3",
          "neutral_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 73,
            "total_tokens": 241,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Be6",
            "Be3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8e6",
          "positional_uci": "e4f5",
          "neutral_uci": "e4f5",
          "consensus_move": "e4f5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d3",
              "Be3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d3",
              "Bg4",
              "Qd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d3",
              "Be6",
              "Be3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 169,
            "completion_tokens": 81,
            "total_tokens": 250,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 169,
            "completion_tokens": 75,
            "total_tokens": 244,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 168,
            "completion_tokens": 73,
            "total_tokens": 241,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 506,
          "total_completion_tokens": 229,
          "total_tokens": 735
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 169,
            "completion_tokens": 81,
            "total_tokens": 250,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 169,
            "completion_tokens": 75,
            "total_tokens": 244,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 168,
            "completion_tokens": 73,
            "total_tokens": 241,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/4q3/5N2/PPPP1PPP/RNBQ1K1R b kq - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 * \n8... Bg4 9. Qd2 O-O-O 10. h3",
          "aggressive_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 87,
            "total_tokens": 264,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd2",
            "O-O-O",
            "h3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be6",
          "positional_uci": "c8e6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Be6 9. Be3 O-O-O 10. Nbd2\nBe6 O-O-O Nbd2",
          "positional_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 91,
            "total_tokens": 268,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O-O",
            "Nbd2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxf3",
          "neutral_uci": "f5f3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 * Qxf3 gxf3 Bg4",
          "neutral_tokens": {
            "prompt_tokens": 176,
            "completion_tokens": 76,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf3",
            "Bg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "c8e6",
          "neutral_uci": "f5f3",
          "consensus_move": "f5f3",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qd2",
              "O-O-O",
              "h3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O-O",
              "Nbd2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf3",
              "Bg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 177,
            "completion_tokens": 87,
            "total_tokens": 264,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 177,
            "completion_tokens": 91,
            "total_tokens": 268,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 176,
            "completion_tokens": 76,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 530,
          "total_completion_tokens": 254,
          "total_tokens": 784
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 177,
            "completion_tokens": 87,
            "total_tokens": 264,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 177,
            "completion_tokens": 91,
            "total_tokens": 268,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 176,
            "completion_tokens": 76,
            "total_tokens": 252,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/5q2/8/3P1N2/PPP2PPP/RNBQ1K1R b kq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g3",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 * g3 Bg4 10. Be3",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "Be3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g3",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 * g3 Bg4 Be3",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 83,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "Be3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g3",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 * g3 Bg4 Kg2",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 83,
            "total_tokens": 268,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "Kg2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg4",
              "Be3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bg4",
              "Be3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bg4",
              "Kg2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 83,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 83,
            "total_tokens": 268,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 252,
          "total_tokens": 809
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 86,
            "total_tokens": 272,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 83,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 83,
            "total_tokens": 268,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/8/3P1Q2/PPP2PPP/RNB2K1R b kq - 0 9"
    },
    {
      "turn": 18,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "g3",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 * g3 Bg4 10. h3 Bh5",
          "aggressive_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 88,
            "total_tokens": 274,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "h3",
            "Bh5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g3",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 * g3 Bg4 h3",
          "positional_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 83,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg4",
            "h3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be6",
          "neutral_uci": "c8e6",
          "neutral_response": "8. d3 Qxf3 9. Qxf3 Be6 10. Be3 O-O-O 11. Nc3\nBe6 O-O-O Nc3",
          "neutral_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 39,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O-O",
            "Nc3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": "c8e6",
          "consensus_move": "c8e6",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg4",
              "h3",
              "Bh5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bg4",
              "h3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O-O",
              "Nc3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 186,
            "completion_tokens": 88,
            "total_tokens": 274,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 186,
            "completion_tokens": 83,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 185,
            "completion_tokens": 39,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 557,
          "total_completion_tokens": 210,
          "total_tokens": 767
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 186,
            "completion_tokens": 88,
            "total_tokens": 274,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 186,
            "completion_tokens": 83,
            "total_tokens": 269,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 185,
            "completion_tokens": 39,
            "total_tokens": 224,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1kbnr/1pp2ppp/p1p5/8/8/3P1Q2/PPP2PPP/RNB2K1R b kq - 0 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 *\nBlack O-O 11. Be3 Rd8 12. Rd1",
          "aggressive_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 99,
            "total_tokens": 293,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be3",
            "Rd8",
            "Rd1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O-O",
          "positional_uci": "e8c8",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Be3 Bg4 12. Qg3",
          "positional_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 100,
            "total_tokens": 294,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be3",
            "Bg4",
            "Qg3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O-O",
          "neutral_uci": "e8c8",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Be3 Bg4 12. Qg3",
          "neutral_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 100,
            "total_tokens": 293,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be3",
            "Bg4",
            "Qg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e8c8",
          "neutral_uci": "e8c8",
          "consensus_move": "e8c8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be3",
              "Rd8",
              "Rd1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be3",
              "Bg4",
              "Qg3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be3",
              "Bg4",
              "Qg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 194,
            "completion_tokens": 99,
            "total_tokens": 293,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 194,
            "completion_tokens": 100,
            "total_tokens": 294,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 193,
            "completion_tokens": 100,
            "total_tokens": 293,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 581,
          "total_completion_tokens": 299,
          "total_tokens": 880
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 194,
            "completion_tokens": 99,
            "total_tokens": 293,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 194,
            "completion_tokens": 100,
            "total_tokens": 294,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 193,
            "completion_tokens": 100,
            "total_tokens": 293,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3kbnr/1pp2ppp/p1p1b3/8/8/2NP1Q2/PPP2PPP/R1B2K1R b kq - 2 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 *\nBlack Bg5 h6 Bxe6",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 102,
            "total_tokens": 305,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "Bxe6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "f6",
          "positional_uci": "f7f6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Be3 Bg4 13. Qe2\nf6 Be3 Bg4 Qe2",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 119,
            "total_tokens": 322,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be3",
            "Bg4",
            "Qe2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "f6",
          "neutral_uci": "f7f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Bf4 g5 13. Bg3",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 108,
            "total_tokens": 310,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bf4",
            "g5",
            "Bg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "f7f6",
          "neutral_uci": "f7f6",
          "consensus_move": "f7f6",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h6",
              "Bxe6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be3",
              "Bg4",
              "Qe2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bf4",
              "g5",
              "Bg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 102,
            "total_tokens": 305,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 119,
            "total_tokens": 322,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 108,
            "total_tokens": 310,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 329,
          "total_tokens": 937
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 102,
            "total_tokens": 305,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 119,
            "total_tokens": 322,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 108,
            "total_tokens": 310,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2kr1bnr/1pp2ppp/p1p1b3/6B1/8/2NP1Q2/PPP2PPP/R4K1R b - - 4 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 * \n* Bxf6 gxf6 13. Qxf6",
          "aggressive_tokens": {
            "prompt_tokens": 210,
            "completion_tokens": 114,
            "total_tokens": 324,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf6",
            "Qxf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg4",
          "positional_uci": "e6g4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qe2 h6",
          "positional_tokens": {
            "prompt_tokens": 210,
            "completion_tokens": 110,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "h6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxg5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 * Bxg5 Qe2 Qxe1+",
          "neutral_tokens": {
            "prompt_tokens": 209,
            "completion_tokens": 110,
            "total_tokens": 319,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Qxe1+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e6g4",
          "neutral_uci": null,
          "consensus_move": "e6g4",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "gxf6",
              "Qxf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe2",
              "h6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe2",
              "Qxe1+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 210,
            "completion_tokens": 114,
            "total_tokens": 324,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 210,
            "completion_tokens": 110,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 209,
            "completion_tokens": 110,
            "total_tokens": 319,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 629,
          "total_completion_tokens": 334,
          "total_tokens": 963
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 210,
            "completion_tokens": 114,
            "total_tokens": 324,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 210,
            "completion_tokens": 110,
            "total_tokens": 320,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 209,
            "completion_tokens": 110,
            "total_tokens": 319,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2kr1bnr/1pp3pp/p1p1bp2/6B1/8/2NP1Q2/PPP2PPP/4RK1R b - - 1 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "hxg4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ hxg4 14. Bxf6 gxf6 15. Rxe6",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 127,
            "total_tokens": 347,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf6",
            "gxf6",
            "Rxe6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kb8",
          "positional_uci": "c8b8",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qf4 Rd7 15. Bf4",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 126,
            "total_tokens": 346,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf4",
            "Rd7",
            "Bf4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kb8",
          "neutral_uci": "c8b8",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ *\n* Kb8 Qe2 Rhe8",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 119,
            "total_tokens": 338,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Rhe8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "c8b8",
          "neutral_uci": "c8b8",
          "consensus_move": "c8b8",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf6",
              "gxf6",
              "Rxe6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf4",
              "Rd7",
              "Bf4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe2",
              "Rhe8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 127,
            "total_tokens": 347,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 126,
            "total_tokens": 346,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 119,
            "total_tokens": 338,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 372,
          "total_tokens": 1031
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 127,
            "total_tokens": 347,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 126,
            "total_tokens": 346,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 119,
            "total_tokens": 338,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "2kr1bnr/1pp3pp/p1p2p2/6B1/6Q1/2NP4/PPP2PPP/4RK1R b - - 0 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe6",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qe6 * Qe6 Bf7 Qxf7",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bf7",
            "Qxf7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rhe8",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14.\nQe6 Rhe8 15. Qxf6 Rxe1+ 16. Kxe1\nQxf6 Rxe1+ Kxe1",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 147,
            "total_tokens": 376,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf6",
            "Rxe1+",
            "Kxe1",
            "Qxf6",
            "Rxe1+",
            "Kxe1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe6",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14.\nQe6 * Qe6 Bxg5 Qxg5",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 128,
            "total_tokens": 356,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg5",
            "Qxg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bf7",
              "Qxf7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxf6",
              "Rxe1+",
              "Kxe1",
              "Qxf6",
              "Rxe1+",
              "Kxe1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxg5",
              "Qxg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 147,
            "total_tokens": 376,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 128,
            "total_tokens": 356,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 403,
          "total_tokens": 1089
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 147,
            "total_tokens": 376,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 128,
            "total_tokens": 356,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1k1r1bnr/1pp3pp/p1p1Qp2/6B1/8/2NP4/PPP2PPP/4RK1R b - - 2 14"
    },
    {
      "turn": 28,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe6",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qe6 * Qe6 Bf7 Qxf7",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bf7",
            "Qxf7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rhe8",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14.\nQe6 Rhe8 15. Qxf6 Rxe1+ 16. Kxe1\nQxf6 Rhe8 Rxe1+",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 146,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe1+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe6",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qe6 * Qe6 Qd7 Qxd7",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 128,
            "total_tokens": 356,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qd7",
            "Qxd7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bf7",
              "Qxf7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxe1+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qd7",
              "Qxd7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 146,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 128,
            "total_tokens": 356,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 402,
          "total_tokens": 1088
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 128,
            "total_tokens": 357,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 146,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 128,
            "total_tokens": 356,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1k1r1bnr/1pp3pp/p1p1Qp2/6B1/8/2NP4/PPP2PPP/4RK1R b - - 2 14"
    },
    {
      "turn": 28,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe6",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qe6 *\nQe6 Rhe8 Qxc6",
          "aggressive_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 127,
            "total_tokens": 356,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rhe8",
            "Qxc6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rhe8",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qe6 Rhe8 15. Qxc6 bxc6 16. Bf4\nRhe8 Qxc6 bxc6 Bf4",
          "positional_tokens": {
            "prompt_tokens": 229,
            "completion_tokens": 148,
            "total_tokens": 377,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc6",
            "bxc6",
            "Bf4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxd3",
          "neutral_uci": "d8d3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qe6 Rxd3 15. Qxf6 Rxc3 16. Qxc3\nRxd3 Qxf6 Rxc3",
          "neutral_tokens": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf6",
            "Rxc3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": "d8d3",
          "consensus_move": "d8d3",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rhe8",
              "Qxc6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxc6",
              "bxc6",
              "Bf4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxf6",
              "Rxc3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 229,
            "completion_tokens": 127,
            "total_tokens": 356,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 229,
            "completion_tokens": 148,
            "total_tokens": 377,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 686,
          "total_completion_tokens": 421,
          "total_tokens": 1107
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 229,
            "completion_tokens": 127,
            "total_tokens": 356,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 229,
            "completion_tokens": 148,
            "total_tokens": 377,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 228,
            "completion_tokens": 146,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1k1r1bnr/1pp3pp/p1p1Qp2/6B1/8/2NP4/PPP2PPP/4RK1R b - - 2 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bf7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qe6 Rxd3 15. cxd3 Bf7 16. Qxf7 Rd8 17. Qe7",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 144,
            "total_tokens": 382,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf7",
            "Rd8",
            "Qe7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bf7",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14.\nQe6 Rxd3 15. cxd3 Bf7 16. Qxf7 Rd8 17. Qxh7\nBf7 Qxf7 Rd8 Qxh7",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 156,
            "total_tokens": 394,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf7",
            "Rd8",
            "Qxh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14.\nQe6 Rxd3 15. cxd3 * Qe7 Qxe7 Bxe7",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 137,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7",
            "Bxe7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxf7",
              "Rd8",
              "Qe7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxf7",
              "Rd8",
              "Qxh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxe7",
              "Bxe7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 144,
            "total_tokens": 382,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 156,
            "total_tokens": 394,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 137,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 437,
          "total_tokens": 1150
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 144,
            "total_tokens": 382,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 156,
            "total_tokens": 394,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 137,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1k3bnr/1pp3pp/p1p1Qp2/6B1/8/2NP4/PP3PPP/4RK1R b - - 0 15"
    },
    {
      "turn": 30,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qe6 Rxd3 15. cxd3 * Qe7 Qxe7 Bxe7",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 137,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7",
            "Bxe7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bf7",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14.\nQe6 Rxd3 15. cxd3 Bf7 16. Qxf6 gxf6 17. Bxf6\nBf7 gxf6 Bxf6",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 155,
            "total_tokens": 393,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf6",
            "Bxf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14.\nQe6 Rxd3 15. cxd3 * Qe7 Qxe7 Bxe7",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 137,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7",
            "Bxe7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe7",
              "Bxe7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "gxf6",
              "Bxf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxe7",
              "Bxe7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 137,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 155,
            "total_tokens": 393,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 137,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 429,
          "total_tokens": 1142
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 137,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 155,
            "total_tokens": 393,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 137,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1k3bnr/1pp3pp/p1p1Qp2/6B1/8/2NP4/PP3PPP/4RK1R b - - 0 15"
    },
    {
      "turn": 30,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5 8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14. Qe6 Rxd3 15. cxd3 * Qe7 Qxe7 Bxe7",
          "aggressive_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 137,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7",
            "Bxe7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bf7",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14.\nQe6 Rxd3 15. cxd3 Bf7 16. Qxf7 Rd8 17. Qe7\nBf7 Qxf7 Rd8 Qe7",
          "positional_tokens": {
            "prompt_tokens": 238,
            "completion_tokens": 156,
            "total_tokens": 394,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxf7",
            "Rd8",
            "Qe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qd4 6. Nf3 Qxe4+ 7. Kf1 Qf5\n8. d3 Qxf3 9. Qxf3 Be6 10. Nc3 O-O-O 11. Bg5 f6 12. Re1 Bg4 13. Qxg4+ Kb8 14.\nQe6 Rxd3 15. cxd3 * Qe7 Qxe7 Bxe7",
          "neutral_tokens": {
            "prompt_tokens": 237,
            "completion_tokens": 137,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxe7",
            "Bxe7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxe7",
              "Bxe7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxf7",
              "Rd8",
              "Qe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxe7",
              "Bxe7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 238,
            "completion_tokens": 137,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 238,
            "completion_tokens": 156,
            "total_tokens": 394,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 237,
            "completion_tokens": 137,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 713,
          "total_completion_tokens": 430,
          "total_tokens": 1143
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 238,
            "completion_tokens": 137,
            "total_tokens": 375,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 238,
            "completion_tokens": 156,
            "total_tokens": 394,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 237,
            "completion_tokens": 137,
            "total_tokens": 374,
            "model": "deepseek-ai/deepseek-v3",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1k3bnr/1pp3pp/p1p1Qp2/6B1/8/2NP4/PP3PPP/4RK1R b - - 0 15"
    }
  ],
  "white_errors": [],
  "black_errors": [],
  "white_plan_log": [],
  "black_plan_log": [],
  "timestamp": "2025-11-29T23:28:17.287460",
  "game_id": "gpt-3.5-turbo-instruct_vs_deepseek-ai_deepseek-v3_SC_7",
  "configuration": "SC"
}