{
  "result": "gpt-3.5-turbo-instruct wins by disqualification (meta-llama/llama-3.3-70b-instruct failed to produce a legal move)",
  "white_player": "gpt-3.5-turbo-instruct",
  "black_player": "meta-llama/llama-3.3-70b-instruct",
  "white_score": 1.0,
  "black_score": 0.0,
  "total_moves": 25,
  "moves": [
    "e2e4",
    "e7e5",
    "g1f3",
    "b8c6",
    "f1b5",
    "a7a6",
    "b5a4",
    "g8f6",
    "e1g1",
    "f8e7",
    "f1e1",
    "b7b5",
    "a4b3",
    "d7d6",
    "c2c3",
    "c6a5",
    "b3c2",
    "a5c4",
    "d2d3",
    "c4b6",
    "b1d2",
    "b5b4",
    "c3b4",
    "a6a5",
    "b4a5"
  ],
  "game_history": [
    {
      "move_number": 1,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e4",
      "move_san": "e4",
      "fen_after": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "move_number": 2,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "e7e5",
      "move_san": "e5",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "move_number": 3,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1f3",
      "move_san": "Nf3",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "move_number": 4,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "b8c6",
      "move_san": "Nc6",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "move_number": 5,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1b5",
      "move_san": "Bb5",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "move_number": 6,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "a7a6",
      "move_san": "a6",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "move_number": 7,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b5a4",
      "move_san": "Ba4",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "move_number": 8,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "g8f6",
      "move_san": "Nf6",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "move_number": 9,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1g1",
      "move_san": "O-O",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 b kq - 3 5"
    },
    {
      "move_number": 10,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "f8e7",
      "move_san": "Be7",
      "fen_after": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 w kq - 4 6"
    },
    {
      "move_number": 11,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1e1",
      "move_san": "Re1",
      "fen_after": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQR1K1 b kq - 5 6"
    },
    {
      "move_number": 12,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "b7b5",
      "move_san": "b5",
      "fen_after": "r1bqk2r/2ppbppp/p1n2n2/1p2p3/B3P3/5N2/PPPP1PPP/RNBQR1K1 w kq - 0 7"
    },
    {
      "move_number": 13,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a4b3",
      "move_san": "Bb3",
      "fen_after": "r1bqk2r/2ppbppp/p1n2n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 b kq - 1 7"
    },
    {
      "move_number": 14,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "d7d6",
      "move_san": "d6",
      "fen_after": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 w kq - 0 8"
    },
    {
      "move_number": 15,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c2c3",
      "move_san": "c3",
      "fen_after": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 b kq - 0 8"
    },
    {
      "move_number": 16,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "c6a5",
      "move_san": "Na5",
      "fen_after": "r1bqk2r/2p1bppp/p2p1n2/np2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 w kq - 1 9"
    },
    {
      "move_number": 17,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b3c2",
      "move_san": "Bc2",
      "fen_after": "r1bqk2r/2p1bppp/p2p1n2/np2p3/4P3/2P2N2/PPBP1PPP/RNBQR1K1 b kq - 2 9"
    },
    {
      "move_number": 18,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "a5c4",
      "move_san": "Nc4",
      "fen_after": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2P2N2/PPBP1PPP/RNBQR1K1 w kq - 3 10"
    },
    {
      "move_number": 19,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2d3",
      "move_san": "d3",
      "fen_after": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2PP1N2/PPB2PPP/RNBQR1K1 b kq - 0 10"
    },
    {
      "move_number": 20,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "c4b6",
      "move_san": "Nb6",
      "fen_after": "r1bqk2r/2p1bppp/pn1p1n2/1p2p3/4P3/2PP1N2/PPB2PPP/RNBQR1K1 w kq - 1 11"
    },
    {
      "move_number": 21,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b1d2",
      "move_san": "Nbd2",
      "fen_after": "r1bqk2r/2p1bppp/pn1p1n2/1p2p3/4P3/2PP1N2/PPBN1PPP/R1BQR1K1 b kq - 2 11"
    },
    {
      "move_number": 22,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "b5b4",
      "move_san": "b4",
      "fen_after": "r1bqk2r/2p1bppp/pn1p1n2/4p3/1p2P3/2PP1N2/PPBN1PPP/R1BQR1K1 w kq - 0 12"
    },
    {
      "move_number": 23,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c3b4",
      "move_san": "cxb4",
      "fen_after": "r1bqk2r/2p1bppp/pn1p1n2/4p3/1P2P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 12"
    },
    {
      "move_number": 24,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "black",
      "move_uci": "a6a5",
      "move_san": "a5",
      "fen_after": "r1bqk2r/2p1bppp/1n1p1n2/p3p3/1P2P3/3P1N2/PPBN1PPP/R1BQR1K1 w kq - 0 13"
    },
    {
      "move_number": 25,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b4a5",
      "move_san": "bxa5",
      "fen_after": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    }
  ],
  "final_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13",
  "white_tokens": {
    "prompt_tokens": 23075,
    "completion_tokens": 81544,
    "total_tokens": 104619
  },
  "black_tokens": {
    "prompt_tokens": 27828,
    "completion_tokens": 8083,
    "total_tokens": 35911
  },
  "white_token_log": [
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 443,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1723,
        "total_tokens": 2052
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 443,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 269,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1549,
        "total_tokens": 1923
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 269,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 227,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 1507,
        "total_tokens": 1929
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 227,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 148,
          "completion_tokens": 247,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 148,
          "completion_tokens": 282,
          "total_tokens": 430,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 147,
          "completion_tokens": 216,
          "total_tokens": 363,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 443,
        "total_completion_tokens": 745,
        "total_tokens": 1188
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 148,
          "completion_tokens": 247,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 148,
          "completion_tokens": 282,
          "total_tokens": 430,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 147,
          "completion_tokens": 216,
          "total_tokens": 363,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 163,
          "completion_tokens": 198,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 163,
          "completion_tokens": 640,
          "total_tokens": 803,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 162,
          "completion_tokens": 580,
          "total_tokens": 742,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 488,
        "total_completion_tokens": 1418,
        "total_tokens": 1906
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 163,
          "completion_tokens": 198,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 163,
          "completion_tokens": 640,
          "total_tokens": 803,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 162,
          "completion_tokens": 580,
          "total_tokens": 742,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 372,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 493,
          "total_tokens": 663,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1505,
        "total_tokens": 2017
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 372,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 493,
          "total_tokens": 663,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 470,
          "total_tokens": 650,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 339,
          "total_tokens": 518,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 539,
        "total_completion_tokens": 1449,
        "total_tokens": 1988
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 470,
          "total_tokens": 650,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 339,
          "total_tokens": 518,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 175,
          "total_tokens": 370,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 502,
          "total_tokens": 697,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 640,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 584,
        "total_completion_tokens": 1317,
        "total_tokens": 1901
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 175,
          "total_tokens": 370,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 502,
          "total_tokens": 697,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 640,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 640,
          "total_tokens": 842,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 1920,
        "total_tokens": 2528
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 640,
          "total_tokens": 842,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 498,
          "total_tokens": 612,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 640,
          "total_tokens": 753,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1778,
        "total_tokens": 2119
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 498,
          "total_tokens": 612,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 640,
          "total_tokens": 753,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 328,
          "total_tokens": 450,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 609,
          "total_tokens": 730,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 365,
        "total_completion_tokens": 1577,
        "total_tokens": 1942
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 328,
          "total_tokens": 450,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 609,
          "total_tokens": 730,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 631,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 589,
          "total_tokens": 720,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 392,
        "total_completion_tokens": 1860,
        "total_tokens": 2252
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 631,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 589,
          "total_tokens": 720,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 139,
          "completion_tokens": 424,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 416,
        "total_completion_tokens": 1704,
        "total_tokens": 2120
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 139,
          "completion_tokens": 424,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 347,
          "total_tokens": 494,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 261,
          "total_tokens": 408,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 640,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 1248,
        "total_tokens": 1688
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 347,
          "total_tokens": 494,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 261,
          "total_tokens": 408,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 640,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 445,
          "total_tokens": 555,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1725,
        "total_tokens": 2054
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 445,
          "total_tokens": 555,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 299,
          "total_tokens": 424,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1579,
        "total_tokens": 1953
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 299,
          "total_tokens": 424,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 220,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 1500,
        "total_tokens": 1922
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 220,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 148,
          "completion_tokens": 640,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 148,
          "completion_tokens": 640,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 147,
          "completion_tokens": 581,
          "total_tokens": 728,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 443,
        "total_completion_tokens": 1861,
        "total_tokens": 2304
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 148,
          "completion_tokens": 640,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 148,
          "completion_tokens": 640,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 147,
          "completion_tokens": 581,
          "total_tokens": 728,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 155,
          "completion_tokens": 640,
          "total_tokens": 795,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 155,
          "completion_tokens": 640,
          "total_tokens": 795,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 464,
        "total_completion_tokens": 1920,
        "total_tokens": 2384
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 155,
          "completion_tokens": 640,
          "total_tokens": 795,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 155,
          "completion_tokens": 640,
          "total_tokens": 795,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 163,
          "completion_tokens": 202,
          "total_tokens": 365,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 163,
          "completion_tokens": 640,
          "total_tokens": 803,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 162,
          "completion_tokens": 640,
          "total_tokens": 802,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 488,
        "total_completion_tokens": 1482,
        "total_tokens": 1970
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 163,
          "completion_tokens": 202,
          "total_tokens": 365,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 163,
          "completion_tokens": 640,
          "total_tokens": 803,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 162,
          "completion_tokens": 640,
          "total_tokens": 802,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 617,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 466,
          "total_tokens": 636,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1723,
        "total_tokens": 2235
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 617,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 466,
          "total_tokens": 636,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 539,
        "total_completion_tokens": 1920,
        "total_tokens": 2459
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 553,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 640,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 584,
        "total_completion_tokens": 1833,
        "total_tokens": 2417
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 553,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 640,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 155,
          "total_tokens": 358,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 640,
          "total_tokens": 842,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 1435,
        "total_tokens": 2043
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 155,
          "total_tokens": 358,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 640,
          "total_tokens": 842,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 640,
          "total_tokens": 753,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1920,
        "total_tokens": 2261
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 640,
          "total_tokens": 753,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 619,
          "total_tokens": 740,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 365,
        "total_completion_tokens": 1899,
        "total_tokens": 2264
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 619,
          "total_tokens": 740,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 615,
          "total_tokens": 746,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 433,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 392,
        "total_completion_tokens": 1688,
        "total_tokens": 2080
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 615,
          "total_tokens": 746,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 433,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 139,
          "completion_tokens": 424,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 416,
        "total_completion_tokens": 1704,
        "total_tokens": 2120
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 139,
          "completion_tokens": 424,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 567,
          "total_tokens": 714,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 271,
          "total_tokens": 417,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 1478,
        "total_tokens": 1918
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 567,
          "total_tokens": 714,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 271,
          "total_tokens": 417,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 464,
          "total_tokens": 574,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 541,
          "total_tokens": 650,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1645,
        "total_tokens": 1974
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 464,
          "total_tokens": 574,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 541,
          "total_tokens": 650,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 495,
          "total_tokens": 620,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1775,
        "total_tokens": 2149
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 495,
          "total_tokens": 620,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 442,
          "total_tokens": 574,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1722,
        "total_tokens": 2120
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 442,
          "total_tokens": 574,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 305,
          "total_tokens": 447,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 396,
          "total_tokens": 537,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 425,
        "total_completion_tokens": 1341,
        "total_tokens": 1766
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 142,
          "completion_tokens": 640,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 142,
          "completion_tokens": 305,
          "total_tokens": 447,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 141,
          "completion_tokens": 396,
          "total_tokens": 537,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 159,
          "completion_tokens": 640,
          "total_tokens": 799,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 159,
          "completion_tokens": 188,
          "total_tokens": 347,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 158,
          "completion_tokens": 640,
          "total_tokens": 798,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 476,
        "total_completion_tokens": 1468,
        "total_tokens": 1944
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 159,
          "completion_tokens": 640,
          "total_tokens": 799,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 159,
          "completion_tokens": 188,
          "total_tokens": 347,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 158,
          "completion_tokens": 640,
          "total_tokens": 798,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 167,
          "completion_tokens": 110,
          "total_tokens": 277,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 167,
          "completion_tokens": 222,
          "total_tokens": 389,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 166,
          "completion_tokens": 123,
          "total_tokens": 289,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 500,
        "total_completion_tokens": 455,
        "total_tokens": 955
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 167,
          "completion_tokens": 110,
          "total_tokens": 277,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 167,
          "completion_tokens": 222,
          "total_tokens": 389,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 166,
          "completion_tokens": 123,
          "total_tokens": 289,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 115,
          "completion_tokens": 315,
          "total_tokens": 430,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 344,
        "total_completion_tokens": 1595,
        "total_tokens": 1939
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 115,
          "completion_tokens": 315,
          "total_tokens": 430,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 585,
          "total_tokens": 709,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 530,
          "total_tokens": 653,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 371,
        "total_completion_tokens": 1755,
        "total_tokens": 2126
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 124,
          "completion_tokens": 585,
          "total_tokens": 709,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 123,
          "completion_tokens": 530,
          "total_tokens": 653,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 520,
          "total_tokens": 652,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1800,
        "total_tokens": 2198
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 520,
          "total_tokens": 652,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 388,
          "total_tokens": 529,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 1668,
        "total_tokens": 2090
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 388,
          "total_tokens": 529,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 263,
          "total_tokens": 412,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 640,
          "total_tokens": 789,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 640,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 446,
        "total_completion_tokens": 1543,
        "total_tokens": 1989
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 263,
          "total_tokens": 412,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 640,
          "total_tokens": 789,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 640,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 640,
          "total_tokens": 806,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 640,
          "total_tokens": 806,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 470,
          "total_tokens": 635,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 497,
        "total_completion_tokens": 1750,
        "total_tokens": 2247
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 640,
          "total_tokens": 806,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 640,
          "total_tokens": 806,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 470,
          "total_tokens": 635,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 121,
          "completion_tokens": 230,
          "total_tokens": 351,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 121,
          "completion_tokens": 640,
          "total_tokens": 761,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 120,
          "completion_tokens": 640,
          "total_tokens": 760,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 362,
        "total_completion_tokens": 1510,
        "total_tokens": 1872
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 121,
          "completion_tokens": 230,
          "total_tokens": 351,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 121,
          "completion_tokens": 640,
          "total_tokens": 761,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 120,
          "completion_tokens": 640,
          "total_tokens": 760,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 315,
          "total_tokens": 425,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 639,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1594,
        "total_tokens": 1923
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 315,
          "total_tokens": 425,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 639,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 269,
          "total_tokens": 394,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 269,
          "total_tokens": 394,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 269,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 807,
        "total_tokens": 1181
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 269,
          "total_tokens": 394,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 269,
          "total_tokens": 394,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 269,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 598,
          "total_tokens": 739,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 1878,
        "total_tokens": 2300
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 598,
          "total_tokens": 739,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 640,
          "total_tokens": 780,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 148,
          "completion_tokens": 247,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 148,
          "completion_tokens": 640,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 443,
        "total_completion_tokens": 1527,
        "total_tokens": 1970
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 148,
          "completion_tokens": 247,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 148,
          "completion_tokens": 640,
          "total_tokens": 788,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 147,
          "completion_tokens": 640,
          "total_tokens": 787,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 155,
          "completion_tokens": 251,
          "total_tokens": 406,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 155,
          "completion_tokens": 236,
          "total_tokens": 391,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 154,
          "completion_tokens": 211,
          "total_tokens": 365,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 464,
        "total_completion_tokens": 698,
        "total_tokens": 1162
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 155,
          "completion_tokens": 251,
          "total_tokens": 406,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 155,
          "completion_tokens": 236,
          "total_tokens": 391,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 154,
          "completion_tokens": 211,
          "total_tokens": 365,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 163,
          "completion_tokens": 640,
          "total_tokens": 803,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 163,
          "completion_tokens": 541,
          "total_tokens": 704,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 162,
          "completion_tokens": 640,
          "total_tokens": 802,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 488,
        "total_completion_tokens": 1821,
        "total_tokens": 2309
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 163,
          "completion_tokens": 640,
          "total_tokens": 803,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 163,
          "completion_tokens": 541,
          "total_tokens": 704,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 162,
          "completion_tokens": 640,
          "total_tokens": 802,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 448,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1728,
        "total_tokens": 2240
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 448,
          "total_tokens": 619,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 640,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 539,
          "total_tokens": 719,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 539,
        "total_completion_tokens": 1819,
        "total_tokens": 2358
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 539,
          "total_tokens": 719,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 198,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 640,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 584,
        "total_completion_tokens": 1478,
        "total_tokens": 2062
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 198,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 640,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 250,
          "total_tokens": 453,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 310,
          "total_tokens": 512,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 1200,
        "total_tokens": 1808
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 250,
          "total_tokens": 453,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 310,
          "total_tokens": 512,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    }
  ],
  "black_token_log": [
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 24,
          "total_tokens": 173,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 30,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 24,
          "total_tokens": 172,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 446,
        "total_completion_tokens": 78,
        "total_tokens": 524
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 24,
          "total_tokens": 173,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 30,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 24,
          "total_tokens": 172,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 20,
          "total_tokens": 177,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 20,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 470,
        "total_completion_tokens": 84,
        "total_tokens": 554
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 20,
          "total_tokens": 177,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 20,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 52,
          "total_tokens": 218,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 49,
          "total_tokens": 215,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 29,
          "total_tokens": 194,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 497,
        "total_completion_tokens": 130,
        "total_tokens": 627
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 52,
          "total_tokens": 218,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 49,
          "total_tokens": 215,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 29,
          "total_tokens": 194,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 173,
          "completion_tokens": 34,
          "total_tokens": 207,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 173,
          "completion_tokens": 126,
          "total_tokens": 299,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 172,
          "completion_tokens": 37,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 518,
        "total_completion_tokens": 197,
        "total_tokens": 715
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 173,
          "completion_tokens": 34,
          "total_tokens": 207,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 173,
          "completion_tokens": 126,
          "total_tokens": 299,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 172,
          "completion_tokens": 37,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 47,
          "total_tokens": 228,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 46,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 47,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 542,
        "total_completion_tokens": 140,
        "total_tokens": 682
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 47,
          "total_tokens": 228,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 46,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 47,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 54,
          "total_tokens": 242,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 178,
          "total_tokens": 366,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 120,
          "total_tokens": 307,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 563,
        "total_completion_tokens": 352,
        "total_tokens": 915
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 54,
          "total_tokens": 242,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 178,
          "total_tokens": 366,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 120,
          "total_tokens": 307,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 56,
          "total_tokens": 251,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 587,
        "total_completion_tokens": 168,
        "total_tokens": 755
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 56,
          "total_tokens": 251,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 69,
          "total_tokens": 272,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 66,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 69,
          "total_tokens": 271,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 204,
        "total_tokens": 812
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 69,
          "total_tokens": 272,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 66,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 69,
          "total_tokens": 271,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 75,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 76,
          "total_tokens": 288,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 76,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 227,
        "total_tokens": 862
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 75,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 76,
          "total_tokens": 288,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 76,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 86,
          "total_tokens": 306,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 84,
          "total_tokens": 304,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 84,
          "total_tokens": 303,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 254,
        "total_tokens": 913
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 86,
          "total_tokens": 306,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 84,
          "total_tokens": 304,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 84,
          "total_tokens": 303,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 46,
          "total_tokens": 191,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 23,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 33,
          "total_tokens": 217,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 514,
        "total_completion_tokens": 102,
        "total_tokens": 616
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 46,
          "total_tokens": 191,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 23,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 33,
          "total_tokens": 217,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 9,
          "total_tokens": 160,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 63,
          "total_tokens": 214,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 9,
          "total_tokens": 159,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 452,
        "total_completion_tokens": 81,
        "total_tokens": 533
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 9,
          "total_tokens": 160,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 63,
          "total_tokens": 214,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 9,
          "total_tokens": 159,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 35,
          "total_tokens": 202,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 503,
        "total_completion_tokens": 105,
        "total_tokens": 608
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 35,
          "total_tokens": 202,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 55,
          "total_tokens": 240,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 52,
          "total_tokens": 237,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 47,
          "total_tokens": 231,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 554,
        "total_completion_tokens": 154,
        "total_tokens": 708
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 55,
          "total_tokens": 240,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 52,
          "total_tokens": 237,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 47,
          "total_tokens": 231,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 24,
          "total_tokens": 173,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 30,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 24,
          "total_tokens": 172,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 446,
        "total_completion_tokens": 78,
        "total_tokens": 524
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 24,
          "total_tokens": 173,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 30,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 24,
          "total_tokens": 172,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 20,
          "total_tokens": 177,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 20,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 470,
        "total_completion_tokens": 84,
        "total_tokens": 554
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 20,
          "total_tokens": 177,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 20,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 53,
          "total_tokens": 219,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 49,
          "total_tokens": 215,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 28,
          "total_tokens": 193,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 497,
        "total_completion_tokens": 130,
        "total_tokens": 627
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 53,
          "total_tokens": 219,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 49,
          "total_tokens": 215,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 28,
          "total_tokens": 193,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 173,
          "completion_tokens": 34,
          "total_tokens": 207,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 173,
          "completion_tokens": 76,
          "total_tokens": 249,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 172,
          "completion_tokens": 37,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 518,
        "total_completion_tokens": 147,
        "total_tokens": 665
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 173,
          "completion_tokens": 34,
          "total_tokens": 207,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 173,
          "completion_tokens": 76,
          "total_tokens": 249,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 172,
          "completion_tokens": 37,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 49,
          "total_tokens": 230,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 46,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 47,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 542,
        "total_completion_tokens": 142,
        "total_tokens": 684
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 49,
          "total_tokens": 230,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 46,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 47,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 54,
          "total_tokens": 242,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 178,
          "total_tokens": 366,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 120,
          "total_tokens": 307,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 563,
        "total_completion_tokens": 352,
        "total_tokens": 915
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 54,
          "total_tokens": 242,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 178,
          "total_tokens": 366,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 120,
          "total_tokens": 307,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 64,
          "total_tokens": 260,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 56,
          "total_tokens": 251,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 587,
        "total_completion_tokens": 176,
        "total_tokens": 763
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 64,
          "total_tokens": 260,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 56,
          "total_tokens": 251,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 69,
          "total_tokens": 272,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 66,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 67,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 202,
        "total_tokens": 810
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 69,
          "total_tokens": 272,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 66,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 67,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 171,
          "total_tokens": 391,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 84,
          "total_tokens": 304,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 84,
          "total_tokens": 303,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 339,
        "total_tokens": 998
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 171,
          "total_tokens": 391,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 84,
          "total_tokens": 304,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 84,
          "total_tokens": 303,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 46,
          "total_tokens": 191,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 23,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 33,
          "total_tokens": 217,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 514,
        "total_completion_tokens": 102,
        "total_tokens": 616
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 46,
          "total_tokens": 191,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 23,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 33,
          "total_tokens": 217,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 9,
          "total_tokens": 160,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 63,
          "total_tokens": 214,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 9,
          "total_tokens": 159,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 452,
        "total_completion_tokens": 81,
        "total_tokens": 533
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 9,
          "total_tokens": 160,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 63,
          "total_tokens": 214,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 9,
          "total_tokens": 159,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 35,
          "total_tokens": 202,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 503,
        "total_completion_tokens": 105,
        "total_tokens": 608
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 35,
          "total_tokens": 202,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 52,
          "total_tokens": 237,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 52,
          "total_tokens": 237,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 47,
          "total_tokens": 231,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 554,
        "total_completion_tokens": 151,
        "total_tokens": 705
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 52,
          "total_tokens": 237,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 52,
          "total_tokens": 237,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 47,
          "total_tokens": 231,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 8,
          "total_tokens": 157,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 8,
          "total_tokens": 157,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 8,
          "total_tokens": 156,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 446,
        "total_completion_tokens": 24,
        "total_tokens": 470
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 8,
          "total_tokens": 157,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 8,
          "total_tokens": 157,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 8,
          "total_tokens": 156,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 19,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 19,
          "total_tokens": 175,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 470,
        "total_completion_tokens": 82,
        "total_tokens": 552
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 19,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 19,
          "total_tokens": 175,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 47,
          "total_tokens": 213,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 37,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 44,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 497,
        "total_completion_tokens": 128,
        "total_tokens": 625
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 47,
          "total_tokens": 213,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 37,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 44,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 174,
          "completion_tokens": 34,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 174,
          "completion_tokens": 34,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 173,
          "completion_tokens": 41,
          "total_tokens": 214,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 521,
        "total_completion_tokens": 109,
        "total_tokens": 630
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 174,
          "completion_tokens": 34,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 174,
          "completion_tokens": 34,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 173,
          "completion_tokens": 41,
          "total_tokens": 214,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 182,
          "completion_tokens": 50,
          "total_tokens": 232,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 182,
          "completion_tokens": 64,
          "total_tokens": 246,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 181,
          "completion_tokens": 64,
          "total_tokens": 245,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 545,
        "total_completion_tokens": 178,
        "total_tokens": 723
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 182,
          "completion_tokens": 50,
          "total_tokens": 232,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 182,
          "completion_tokens": 64,
          "total_tokens": 246,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 181,
          "completion_tokens": 64,
          "total_tokens": 245,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 191,
          "completion_tokens": 63,
          "total_tokens": 254,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 191,
          "completion_tokens": 62,
          "total_tokens": 253,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 190,
          "completion_tokens": 63,
          "total_tokens": 253,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 572,
        "total_completion_tokens": 188,
        "total_tokens": 760
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 191,
          "completion_tokens": 63,
          "total_tokens": 254,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 191,
          "completion_tokens": 62,
          "total_tokens": 253,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 190,
          "completion_tokens": 63,
          "total_tokens": 253,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 200,
          "completion_tokens": 69,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 200,
          "completion_tokens": 67,
          "total_tokens": 267,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 199,
          "completion_tokens": 67,
          "total_tokens": 266,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 599,
        "total_completion_tokens": 203,
        "total_tokens": 802
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 200,
          "completion_tokens": 69,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 200,
          "completion_tokens": 67,
          "total_tokens": 267,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 199,
          "completion_tokens": 67,
          "total_tokens": 266,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 209,
          "completion_tokens": 74,
          "total_tokens": 283,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 209,
          "completion_tokens": 79,
          "total_tokens": 288,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 208,
          "completion_tokens": 78,
          "total_tokens": 286,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 626,
        "total_completion_tokens": 231,
        "total_tokens": 857
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 209,
          "completion_tokens": 74,
          "total_tokens": 283,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 209,
          "completion_tokens": 79,
          "total_tokens": 288,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 208,
          "completion_tokens": 78,
          "total_tokens": 286,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 8,
          "total_tokens": 157,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 8,
          "total_tokens": 157,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 8,
          "total_tokens": 156,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 446,
        "total_completion_tokens": 24,
        "total_tokens": 470
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 8,
          "total_tokens": 157,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 8,
          "total_tokens": 157,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 8,
          "total_tokens": 156,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 156,
          "completion_tokens": 24,
          "total_tokens": 180,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 156,
          "completion_tokens": 18,
          "total_tokens": 174,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 155,
          "completion_tokens": 24,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 467,
        "total_completion_tokens": 66,
        "total_tokens": 533
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 156,
          "completion_tokens": 24,
          "total_tokens": 180,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 156,
          "completion_tokens": 18,
          "total_tokens": 174,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 155,
          "completion_tokens": 24,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 165,
          "completion_tokens": 28,
          "total_tokens": 193,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 165,
          "completion_tokens": 27,
          "total_tokens": 192,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 164,
          "completion_tokens": 29,
          "total_tokens": 193,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 494,
        "total_completion_tokens": 84,
        "total_tokens": 578
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 165,
          "completion_tokens": 28,
          "total_tokens": 193,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 165,
          "completion_tokens": 27,
          "total_tokens": 192,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 164,
          "completion_tokens": 29,
          "total_tokens": 193,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 174,
          "completion_tokens": 38,
          "total_tokens": 212,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 174,
          "completion_tokens": 38,
          "total_tokens": 212,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 173,
          "completion_tokens": 36,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 521,
        "total_completion_tokens": 112,
        "total_tokens": 633
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 174,
          "completion_tokens": 38,
          "total_tokens": 212,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 174,
          "completion_tokens": 38,
          "total_tokens": 212,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 173,
          "completion_tokens": 36,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 190,
          "completion_tokens": 53,
          "total_tokens": 243,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 190,
          "completion_tokens": 53,
          "total_tokens": 243,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 189,
          "completion_tokens": 52,
          "total_tokens": 241,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 569,
        "total_completion_tokens": 158,
        "total_tokens": 727
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 190,
          "completion_tokens": 53,
          "total_tokens": 243,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 190,
          "completion_tokens": 53,
          "total_tokens": 243,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 189,
          "completion_tokens": 52,
          "total_tokens": 241,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 68,
          "total_tokens": 274,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 65,
          "total_tokens": 271,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 68,
          "total_tokens": 273,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 617,
        "total_completion_tokens": 201,
        "total_tokens": 818
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 68,
          "total_tokens": 274,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 65,
          "total_tokens": 271,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 68,
          "total_tokens": 273,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 17,
          "total_tokens": 168,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 9,
          "total_tokens": 160,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 17,
          "total_tokens": 167,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 452,
        "total_completion_tokens": 43,
        "total_tokens": 495
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 17,
          "total_tokens": 168,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 9,
          "total_tokens": 160,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 17,
          "total_tokens": 167,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 24,
          "total_tokens": 173,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 30,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 24,
          "total_tokens": 172,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 446,
        "total_completion_tokens": 78,
        "total_tokens": 524
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 24,
          "total_tokens": 173,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 30,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 24,
          "total_tokens": 172,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 20,
          "total_tokens": 177,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 20,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 470,
        "total_completion_tokens": 84,
        "total_tokens": 554
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 20,
          "total_tokens": 177,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 20,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 53,
          "total_tokens": 219,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 49,
          "total_tokens": 215,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 28,
          "total_tokens": 193,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 497,
        "total_completion_tokens": 130,
        "total_tokens": 627
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 53,
          "total_tokens": 219,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 49,
          "total_tokens": 215,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 28,
          "total_tokens": 193,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 173,
          "completion_tokens": 34,
          "total_tokens": 207,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 173,
          "completion_tokens": 76,
          "total_tokens": 249,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 172,
          "completion_tokens": 37,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 518,
        "total_completion_tokens": 147,
        "total_tokens": 665
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 173,
          "completion_tokens": 34,
          "total_tokens": 207,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 173,
          "completion_tokens": 76,
          "total_tokens": 249,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 172,
          "completion_tokens": 37,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 49,
          "total_tokens": 230,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 46,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 47,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 542,
        "total_completion_tokens": 142,
        "total_tokens": 684
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 49,
          "total_tokens": 230,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 46,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 47,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 54,
          "total_tokens": 242,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 128,
          "total_tokens": 316,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 178,
          "total_tokens": 365,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 563,
        "total_completion_tokens": 360,
        "total_tokens": 923
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 54,
          "total_tokens": 242,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 128,
          "total_tokens": 316,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 178,
          "total_tokens": 365,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 64,
          "total_tokens": 260,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 56,
          "total_tokens": 251,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 587,
        "total_completion_tokens": 176,
        "total_tokens": 763
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 64,
          "total_tokens": 260,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 56,
          "total_tokens": 251,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 69,
          "total_tokens": 272,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 66,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 69,
          "total_tokens": 271,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 204,
        "total_tokens": 812
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 69,
          "total_tokens": 272,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 66,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 69,
          "total_tokens": 271,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 75,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 76,
          "total_tokens": 288,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 76,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 227,
        "total_tokens": 862
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 75,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 76,
          "total_tokens": 288,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 76,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 171,
          "total_tokens": 391,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 84,
          "total_tokens": 304,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 84,
          "total_tokens": 303,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 339,
        "total_tokens": 998
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 171,
          "total_tokens": 391,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 84,
          "total_tokens": 304,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 84,
          "total_tokens": 303,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    }
  ],
  "white_responses": [
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 d5\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg6 Qh4+ Kg8 Re8#\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "O-O",
            "Rd8"
          ],
          "plan_execute": [
            "d5",
            "Nc3",
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6 19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8 22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8 25. Qe7+ Kg8 26. Qg7# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Bg7 Qe6 Nf6 Qxf6 Bxf6 Be6 Qxb7 Rc8 Rad1 Bd7 Rxd6 Nb8 Qxd7+ Nxd7 Rxd7+ Ke8 Rfd1 Kf8 R1d6 Kg8 Rg6+ Kh8 Rh6+ Kg8 Rg6+ Kh8 Rgg7 Rxc2 Rh7+ Kg8 Rdg7+ Kf8 Rf7+ Kg8 Rhg7+ Kh8 Rh7+ Kg8 Rfg7+ Kf8 Rf7+ Kg8 Rhg7+ Kh8 Rg6 Rc1#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 443,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Bg7",
            "Qe6",
            "Nf6",
            "Qxf6",
            "Bxf6",
            "Be6",
            "Qxb7",
            "Rc8",
            "Rad1",
            "Bd7",
            "Rxd6",
            "Nb8",
            "Qxd7+",
            "Nxd7",
            "Rxd7+",
            "Ke8",
            "Rfd1",
            "Kf8",
            "R1d6",
            "Kg8",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Kg8",
            "Rg6+",
            "Kh8",
            "Rgg7",
            "Rxc2",
            "Rh7+",
            "Kg8",
            "Rdg7+",
            "Kf8",
            "Rf7+",
            "Kg8",
            "Rhg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rfg7+",
            "Kf8",
            "Rf7+",
            "Kg8",
            "Rhg7+",
            "Kh8",
            "Rg6",
            "Rc1#"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "1. e4 e5\n2. Nf3 Nc6\n3. Bb5 a6\n4. Ba4 Nf6\n5. O-O Be7\n6. Re1 b5\n7. Bb3 O-O\n8. c3 d6\n9. d4 Bg4\n10. d5 Na5\n11. Bc2 c6\n12. dxc6 Nxc6\n13. Nbd2 d5\n14. h3 Bh5\n15. g4 Bg6\n16. exd5 Nxd5\n17. Nxe5 Nxe5\n18. Rxe5 Nf4\n19. Bxg6 fxg6\n20. Qf3 Nd3\n21. Qd5+ Qxd5\n22. Rxd5 Nxf2\n23. Kg2 Rae8\n24. Nf3 Nxh3\n25. Kxh3 Rxf3+\n26. Kg2 Ref8\n27. Rd2 Bh4\n28. Re2 Rg3+\n29. Kh2 Rxg4\n30. Be3 Re4\n31. Kg2 Rfe8\n32. Kf3 Bg5\n33. Rae1 Rxe3+\n34. Rxe3 Rxe3+\n35. Rxe3 Bxe3\n36. Kxe3 Kf7\n37. b3 Ke6\n38. c4 bxc4\n39. bxc4 Ke5\n40. a4 a5\n41. Kd3 h5\n42. Ke3 g5\n43. Kd3 h4\n44. Ke3 g4\n45. Kd3 h3\n46. Ke3 g5\n47. Kd3 h2\n48. Ke3 g3\n49. Kd3 h1=Q\n50. Ke3 Qe4+\n51. Kd2 Kd4\n52. Kc1 Kc3\n53. Kd1 Qe3\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 d4 Bg4 d5 Na5 Bc2 c6 dxc6 Nxc6 Nbd2 d5 h3 Bh5 g4 Bg6 exd5 Nxd5 Nxe5 Nxe5 Rxe5 Nf4 Bxg6 fxg6 Qf3 Nd3 Qd5+ Qxd5 Rxd5 Nxf2 Kg2 Rae8 Nf3 Nxh3 Kxh3 Rxf3 Kg2 Ref8 Rd2 Bh4 Re2 Rg3+ Kh2 Rxg4 Be3 Re4 Kg2 Rfe8 Kf3 Bg5 Rae1 Rxe3 Rxe3 Rxe3 Rxe3 Bxe3 Kxe3 Kf7 b3 Ke6 c4 bxc4 bxc4 Ke5 a4 a5 Kd",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "d4",
            "Bg4",
            "d5",
            "Na5",
            "Bc2",
            "c6",
            "dxc6",
            "Nxc6",
            "Nbd2",
            "d5",
            "h3",
            "Bh5",
            "g4",
            "Bg6",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Nf4",
            "Bxg6",
            "fxg6",
            "Qf3",
            "Nd3",
            "Qd5+",
            "Qxd5",
            "Rxd5",
            "Nxf2",
            "Kg2",
            "Rae8",
            "Nf3",
            "Nxh3",
            "Kxh3",
            "Rxf3",
            "Kg2",
            "Ref8",
            "Rd2",
            "Bh4",
            "Re2",
            "Rg3+",
            "Kh2",
            "Rxg4",
            "Be3",
            "Re4",
            "Kg2",
            "Rfe8",
            "Kf3",
            "Bg5",
            "Rae1",
            "Rxe3",
            "Rxe3",
            "Rxe3",
            "Rxe3",
            "Bxe3",
            "Kxe3",
            "Kf7",
            "b3",
            "Ke6",
            "c4",
            "bxc4",
            "bxc4",
            "Ke5",
            "a4",
            "a5"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nc3",
              "Nf6",
              "Bg5",
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nxf6+",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nf3",
              "O-O",
              "Bd3",
              "Nc6",
              "O-O",
              "Rd8"
            ],
            "execute": [
              "d5",
              "Nc3",
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Bg7",
              "Qe6",
              "Nf6",
              "Qxf6",
              "Bxf6",
              "Be6",
              "Qxb7",
              "Rc8",
              "Rad1",
              "Bd7",
              "Rxd6",
              "Nb8",
              "Qxd7+",
              "Nxd7",
              "Rxd7+",
              "Ke8",
              "Rfd1",
              "Kf8",
              "R1d6",
              "Kg8",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Kg8",
              "Rg6+",
              "Kh8",
              "Rgg7",
              "Rxc2",
              "Rh7+",
              "Kg8",
              "Rdg7+",
              "Kf8",
              "Rf7+",
              "Kg8",
              "Rhg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rfg7+",
              "Kf8",
              "Rf7+",
              "Kg8",
              "Rhg7+",
              "Kh8",
              "Rg6",
              "Rc1#"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "d4",
              "Bg4",
              "d5",
              "Na5",
              "Bc2",
              "c6",
              "dxc6",
              "Nxc6",
              "Nbd2",
              "d5",
              "h3",
              "Bh5",
              "g4",
              "Bg6",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Nf4",
              "Bxg6",
              "fxg6",
              "Qf3",
              "Nd3",
              "Qd5+",
              "Qxd5",
              "Rxd5",
              "Nxf2",
              "Kg2",
              "Rae8",
              "Nf3",
              "Nxh3",
              "Kxh3",
              "Rxf3",
              "Kg2",
              "Ref8",
              "Rd2",
              "Bh4",
              "Re2",
              "Rg3+",
              "Kh2",
              "Rxg4",
              "Be3",
              "Re4",
              "Kg2",
              "Rfe8",
              "Kf3",
              "Bg5",
              "Rae1",
              "Rxe3",
              "Rxe3",
              "Rxe3",
              "Rxe3",
              "Bxe3",
              "Kxe3",
              "Kf7",
              "b3",
              "Ke6",
              "c4",
              "bxc4",
              "bxc4",
              "Ke5",
              "a4",
              "a5"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "full_moves": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "d4",
            "Bg4",
            "d5",
            "Na5",
            "Bc2",
            "c6",
            "dxc6",
            "Nxc6",
            "Nbd2",
            "d5",
            "h3",
            "Bh5",
            "g4",
            "Bg6",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Nf4",
            "Bxg6",
            "fxg6",
            "Qf3",
            "Nd3",
            "Qd5+",
            "Qxd5",
            "Rxd5",
            "Nxf2",
            "Kg2",
            "Rae8",
            "Nf3",
            "Nxh3",
            "Kxh3",
            "Rxf3",
            "Kg2",
            "Ref8",
            "Rd2",
            "Bh4",
            "Re2",
            "Rg3+",
            "Kh2",
            "Rxg4",
            "Be3",
            "Re4",
            "Kg2",
            "Rfe8",
            "Kf3",
            "Bg5",
            "Rae1",
            "Rxe3",
            "Rxe3",
            "Rxe3",
            "Rxe3",
            "Bxe3",
            "Kxe3",
            "Kf7",
            "b3",
            "Ke6",
            "c4",
            "bxc4",
            "bxc4",
            "Ke5",
            "a4",
            "a5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 443,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1723,
          "total_tokens": 2052
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 443,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb5",
          "aggressive_uci": "f1b5",
          "aggressive_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Qh5 18. a4 Re6 19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5 22. f3 Bf5 23. Qf1 Rfe8 24. Qf2 h5 25. Nf1 Bd3 26. Raa1 Rf6 27. Nd2 Rfe6 28. Nf1 Rf6 29. Nd2 Rfe6 30. Nf1 Rf6 31. Nd2 Rfe6 32. Nf1 Rf6 33. Nd2 Rfe6 34. Nf1 Rf6 35. Nd2 Rfe6 36. Nf1 Rf6 37. Nd2 Rfe6 38. Nf1 Rf6 39. Nd2 Rfe6 40. Nf1 Rf6 41. Nd2 Rfe6 42. Nf1 Rf6 43. Nd2 Rfe6 44. Nf1 Rf6 45. Nd2 Rfe6 46. Nf1 Rf6 47. Nd2 Rfe6 48. Nf1 Rf6 49. Nd2 Rfe6 50. Nf1 Rf6 51. Nd2 Rfe6 52. Nf1 Rf6 53. Nd2 Rfe6 54. Nf1 Rf6 55. Nd2 Rfe6 56. Nf1 Rf6 57. Nd2 Rfe6 58. Nf1 Rf6 59. Nd2 Rfe6 60. Nf1 Rf6 61. Nd2 Rfe6 62. Nf1 Rf6 63. Nd2 Rfe6 64. Nf1 Rf6 65. Nd2 Rfe6 66. Nf1 Rf6 67. Nd2 Rfe6 68. Nf1 Rf6 69. Nd2 Rfe6 70. Nf1 Rf6 71. Nd2 Rfe6 72. Nf1 Rf6 73. Nd2 Rfe6 74. Nf1 Rf6 75. Nd2 Rfe6 76. Nf1 Rf6 77. Nd2 Rfe6 78. Nf1 Rf6 79. Nd2",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Qh5",
            "a4",
            "Re6",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bxd5",
            "Qxd5",
            "f3",
            "Bf5",
            "Qf1",
            "Rfe8",
            "Qf2",
            "h5",
            "Nf1",
            "Bd3",
            "Raa1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "Bb5",
          "positional_uci": "f1b5",
          "positional_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bb8 25. Ra8 Rg6 26. Bf4 Rxe1+ 27. Nf1 h6 28. Rxb8+ Kh7 29. Bg3 Bh3 30. Qa8 Rxf1# e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d5 exd5 Nxd5 Nxe5 Nxe5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Re6 Qf1 Qh5 a4 Rfe8 axb5 axb5 Bxd5 Qxd5 Qg2 Qh5 Qxc6 Bxg3 Qg2 Bb8 Bd4 Rg6 Bg3 Bh3 Qa8 Rge6 Rxe6 fxe6 Nf1 Bxg3 Nxg3 Qg6 Qe4 Qf7 Qe5 Rf8 Re2 Ra8 Qxe6 Ra1+ Kg2 Qxe6 Rxe6 Rb1 Re2 Kf7 Ne4 Ke6 Nc5+ Kd5 Nd3 Kc4 Ne5+ Kb3 Nd3+ Kxb2 Nxb4 Kc3 Nd5+ Kd4 Nf6 Re7 g5+ Ke5 Ng4+ Kf5 Nxh2 Rxh7 Nf3 Rh3 g4 Rg3 Kc4 Rxg4+ Kd3 Rg3 Ke5 Rg5+ Kf4 Rg4+ Kf5 Rg5+ Ke6 Rg6+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bb8",
            "Bd4",
            "Rg6",
            "Bg3",
            "Bh3",
            "Qa8",
            "Rge6",
            "Rxe6",
            "fxe6",
            "Nf1",
            "Bxg3",
            "Nxg3",
            "Qg6",
            "Qe4",
            "Qf7",
            "Qe5",
            "Rf8",
            "Re2",
            "Ra8",
            "Qxe6",
            "Ra1+",
            "Kg2",
            "Qxe6",
            "Rxe6",
            "Rb1",
            "Re2",
            "Kf7",
            "Ne4",
            "Ke6",
            "Nc5+",
            "Kd5",
            "Nd3",
            "Kc4",
            "Ne5+",
            "Kb3",
            "Nd3+",
            "Kxb2",
            "Nxb4",
            "Kc3",
            "Nd5+",
            "Kd4",
            "Nf6",
            "Re7",
            "g5+",
            "Ke5",
            "Ng4+",
            "Kf5",
            "Nxh2",
            "Rxh7",
            "Nf3",
            "Rh3",
            "g4",
            "Rg3",
            "Kc4",
            "Rxg4+",
            "Kd3",
            "Rg3",
            "Ke5",
            "Rg5+",
            "Kf4",
            "Rg4+",
            "Kf5",
            "Rg5+",
            "Ke6",
            "Rg6+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "Bb5",
          "neutral_uci": "f1b5",
          "neutral_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6 Bc5",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 269,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6",
            "Bc5"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1b5",
          "positional_uci": "f1b5",
          "neutral_uci": "f1b5",
          "consensus_move": "f1b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Qh5",
              "a4",
              "Re6",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bxd5",
              "Qxd5",
              "f3",
              "Bf5",
              "Qf1",
              "Rfe8",
              "Qf2",
              "h5",
              "Nf1",
              "Bd3",
              "Raa1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bb8",
              "Bd4",
              "Rg6",
              "Bg3",
              "Bh3",
              "Qa8",
              "Rge6",
              "Rxe6",
              "fxe6",
              "Nf1",
              "Bxg3",
              "Nxg3",
              "Qg6",
              "Qe4",
              "Qf7",
              "Qe5",
              "Rf8",
              "Re2",
              "Ra8",
              "Qxe6",
              "Ra1+",
              "Kg2",
              "Qxe6",
              "Rxe6",
              "Rb1",
              "Re2",
              "Kf7",
              "Ne4",
              "Ke6",
              "Nc5+",
              "Kd5",
              "Nd3",
              "Kc4",
              "Ne5+",
              "Kb3",
              "Nd3+",
              "Kxb2",
              "Nxb4",
              "Kc3",
              "Nd5+",
              "Kd4",
              "Nf6",
              "Re7",
              "g5+",
              "Ke5",
              "Ng4+",
              "Kf5",
              "Nxh2",
              "Rxh7",
              "Nf3",
              "Rh3",
              "g4",
              "Rg3",
              "Kc4",
              "Rxg4+",
              "Kd3",
              "Rg3",
              "Ke5",
              "Rg5+",
              "Kf4",
              "Rg4+",
              "Kf5",
              "Rg5+",
              "Ke6",
              "Rg6+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6",
              "Bc5"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "a6",
            "Ba4",
            "Nf6"
          ],
          "full_moves": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6",
            "Bc5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 269,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1549,
          "total_tokens": 1923
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 269,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7\n17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7\n29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8 40. Kf1 Kf7\n41. Ke2 Ke6 42. Ke3 Kd6 43. Nd2 Kc5 44. a3 Bd7 45. Nb1 Be6 46. Nc3 Bc4\n47. Bxc4 Kxc4 48. Kd2 Nc6 49. Nd5 Kb3 50. Kc1 Nd4 51. Nxf6 Ne2+ 52. Kb1 Nf4\n53. Nxh7 Nxg2 54. Nf6 Nf4 55. h4 Nd3 56. h5 Nxb2 57. h6 Nc4 58. h7 Nxa3+\n59. Kc1 Nc4 60. h8=Q a3 61. Qh3+ Ka4 62. Nd5 b4 63. Qd3 Nb2 64. Qa6+ Kb3\n65. Qb5 Ka2 66. Nxb4+ Ka1 67. Nc2+ Ka2 68. Qd5+ Nc4 69. Qxc4# Nf6 70. Qb4 Nxe4\n71. Qxa3# Nc3 72. Qb2# Nxb2 73. Nxa3 Nd3+ 74. Kd2 Nxf2 75. Ke3 Ng4+ 76. Ke4 Kxa3\n77. Kf5 Kb4 78. Kxg4 Kc4 79. Kf3 Kd3 80. Kf2 e4 81. Ke",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Be6",
            "Nc3",
            "Bc4",
            "Bxc4",
            "Kxc4",
            "Kd2",
            "Nc6",
            "Nd5",
            "Kb3",
            "Kc1",
            "Nd4",
            "Nxf6",
            "Ne2+",
            "Kb1",
            "Nf4",
            "Nxh7",
            "Nxg2",
            "Nf6",
            "Nf4",
            "h4",
            "Nd3",
            "h5",
            "Nxb2",
            "h6",
            "Nc4",
            "h7",
            "Nxa3+",
            "Kc1",
            "Nc4",
            "h8=Q",
            "a3",
            "Qh3+",
            "Ka4",
            "Nd5",
            "b4",
            "Qd3",
            "Nb2",
            "Qa6+",
            "Kb3",
            "Qb5",
            "Ka2",
            "Nxb4+",
            "Ka1",
            "Nc2+",
            "Ka2",
            "Qd5+",
            "Nc4",
            "Qxc4#",
            "Nf6",
            "Qb4",
            "Nxe4",
            "Qxa3#",
            "Nc3",
            "Qb2#",
            "Nxb2",
            "Nxa3",
            "Nd3+",
            "Kd2",
            "Nxf2",
            "Ke3",
            "Ng4+",
            "Ke4",
            "Kxa3",
            "Kf5",
            "Kb4",
            "Kxg4",
            "Kc4",
            "Kf3",
            "Kd3",
            "Kf2",
            "e4"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Nb4 17. Bb1 Bd7 18. a3 Nc6 19. Bd3 Qb7 20. Rc1 Rfc8 21. Qe2 Rab8 22. d5 Na5 23. Nh2 Bd8 24. f4 Bb6 25. fxe5 dxe5 26. Nhf3 Bxe3+ 27. Qxe3 Re8 28. Rc5 Qb6 29. Rec1 Nb7 30. R5c3 Qxe3+ 31. Kh1 Qb6 32. Rc7 Rbc8 33. Rxc8 Rxc8 34. Rxc8+ Bxc8 35. Nxe5 Qd4 36. Ndf3 Qxb2 37. Nc6 Kf8 38. Na7 Bd7 39. Nc6 Bxc6 40. dxc6 Nd6 41. e5 Qc1+ 42. Kh2 Qxc6 43. exd6 Qxd6+ 44. Kh1 Qxd3 45. Ne5 Qxa3 46. Nc6 Qc1+ 47. Kh2 Qxc6 48. Kg3 a3 49. Kf4 a2 50. Ke5 a1=Q+ 51. Kf4 Qd4+ 52. Kg3 Qcc3+ 53. Kh2 Qf4+ 54. Kg1 Qe1# e4 Nc6 d4 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 N",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Nb4",
            "Bb1",
            "Bd7",
            "a3",
            "Nc6",
            "Bd3",
            "Qb7",
            "Rc1",
            "Rfc8",
            "Qe2",
            "Rab8",
            "d5",
            "Na5",
            "Nh2",
            "Bd8",
            "f4",
            "Bb6",
            "fxe5",
            "dxe5",
            "Nhf3",
            "Bxe3+",
            "Qxe3",
            "Re8",
            "Rc5",
            "Qb6",
            "Rec1",
            "Nb7",
            "R5c3",
            "Qxe3+",
            "Kh1",
            "Qb6",
            "Rc7",
            "Rbc8",
            "Rxc8",
            "Rxc8",
            "Rxc8+",
            "Bxc8",
            "Nxe5",
            "Qd4",
            "Ndf3",
            "Qxb2",
            "Nc6",
            "Kf8",
            "Na7",
            "Bd7",
            "Nc6",
            "Bxc6",
            "dxc6",
            "Nd6",
            "e5",
            "Qc1+",
            "Kh2",
            "Qxc6",
            "exd6",
            "Qxd6+",
            "Kh1",
            "Qxd3",
            "Ne5",
            "Qxa3",
            "Nc6",
            "Qc1+",
            "Kh2",
            "Qxc6",
            "Kg3",
            "a3",
            "Kf4",
            "a2",
            "Ke5",
            "a1=Q+",
            "Kf4",
            "Qd4+",
            "Kg3",
            "Qcc3+",
            "Kh2",
            "Qf4+",
            "Kg1",
            "Qe1#",
            "e4",
            "Nc6",
            "d4",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. d5 Ne7 25. Nh4 Rac8 26. Bg5 Kh8 27. Bxf6 gxf6 28. Qf3 Ng8 29. Nhf5 Qc7 30. Qg4 Bxf5 31. Nxf5 *\n31... Qc1 32. Qg7#",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 227,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qf3",
            "Ng8",
            "Nhf5",
            "Qc7",
            "Qg4",
            "Bxf5",
            "Nxf5",
            "Qc1",
            "Qg7#"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Bd7",
              "Nb1",
              "Be6",
              "Nc3",
              "Bc4",
              "Bxc4",
              "Kxc4",
              "Kd2",
              "Nc6",
              "Nd5",
              "Kb3",
              "Kc1",
              "Nd4",
              "Nxf6",
              "Ne2+",
              "Kb1",
              "Nf4",
              "Nxh7",
              "Nxg2",
              "Nf6",
              "Nf4",
              "h4",
              "Nd3",
              "h5",
              "Nxb2",
              "h6",
              "Nc4",
              "h7",
              "Nxa3+",
              "Kc1",
              "Nc4",
              "h8=Q",
              "a3",
              "Qh3+",
              "Ka4",
              "Nd5",
              "b4",
              "Qd3",
              "Nb2",
              "Qa6+",
              "Kb3",
              "Qb5",
              "Ka2",
              "Nxb4+",
              "Ka1",
              "Nc2+",
              "Ka2",
              "Qd5+",
              "Nc4",
              "Qxc4#",
              "Nf6",
              "Qb4",
              "Nxe4",
              "Qxa3#",
              "Nc3",
              "Qb2#",
              "Nxb2",
              "Nxa3",
              "Nd3+",
              "Kd2",
              "Nxf2",
              "Ke3",
              "Ng4+",
              "Ke4",
              "Kxa3",
              "Kf5",
              "Kb4",
              "Kxg4",
              "Kc4",
              "Kf3",
              "Kd3",
              "Kf2",
              "e4"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          },
          "positional": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Nb4",
              "Bb1",
              "Bd7",
              "a3",
              "Nc6",
              "Bd3",
              "Qb7",
              "Rc1",
              "Rfc8",
              "Qe2",
              "Rab8",
              "d5",
              "Na5",
              "Nh2",
              "Bd8",
              "f4",
              "Bb6",
              "fxe5",
              "dxe5",
              "Nhf3",
              "Bxe3+",
              "Qxe3",
              "Re8",
              "Rc5",
              "Qb6",
              "Rec1",
              "Nb7",
              "R5c3",
              "Qxe3+",
              "Kh1",
              "Qb6",
              "Rc7",
              "Rbc8",
              "Rxc8",
              "Rxc8",
              "Rxc8+",
              "Bxc8",
              "Nxe5",
              "Qd4",
              "Ndf3",
              "Qxb2",
              "Nc6",
              "Kf8",
              "Na7",
              "Bd7",
              "Nc6",
              "Bxc6",
              "dxc6",
              "Nd6",
              "e5",
              "Qc1+",
              "Kh2",
              "Qxc6",
              "exd6",
              "Qxd6+",
              "Kh1",
              "Qxd3",
              "Ne5",
              "Qxa3",
              "Nc6",
              "Qc1+",
              "Kh2",
              "Qxc6",
              "Kg3",
              "a3",
              "Kf4",
              "a2",
              "Ke5",
              "a1=Q+",
              "Kf4",
              "Qd4+",
              "Kg3",
              "Qcc3+",
              "Kh2",
              "Qf4+",
              "Kg1",
              "Qe1#",
              "e4",
              "Nc6",
              "d4",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          },
          "neutral": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "d5",
              "Ne7",
              "Nh4",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qf3",
              "Ng8",
              "Nhf5",
              "Qc7",
              "Qg4",
              "Bxf5",
              "Nxf5",
              "Qc1",
              "Qg7#"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "h3",
            "Na5",
            "Bc2"
          ],
          "full_moves": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qf3",
            "Ng8",
            "Nhf5",
            "Qc7",
            "Qg4",
            "Bxf5",
            "Nxf5",
            "Qc1",
            "Qg7#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 227,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 1507,
          "total_tokens": 1929
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 227,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re1",
          "aggressive_uci": "f1e1",
          "aggressive_response": "6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6+ Bc7",
          "aggressive_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 247,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6+",
            "Bc7"
          ],
          "plan_execute": [
            "Qh4",
            "g3",
            "Qh3"
          ]
        },
        "query2": {
          "positional_move": "Re1",
          "positional_uci": "f1e1",
          "positional_response": "6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Nf1 Rfc8 19. Ng3 g6 20. Qd2 Bd8 21. Red1 Ba5 22. Qe2 Bb6 23. dxe5 dxe5 24. Bxb6 Qxb6 25. Rd6 Kg7 26. Qd2 Be8 27. Nf5+ gxf5 28. Qg5+ Kf8 29. Qxf6 Kg8 30. Qg5+ Kf8 31. Qh6+ Kg8 32. Ng5 Qc7 33. Nxh7 f6 34. Nxf6+ Kf7 35. Qh7+ Kf8 36. Qg8+ Ke7 37. Re6+ Kd8 38. Qxe8# e5 Nc6 Nxd4",
          "positional_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 282,
            "total_tokens": 430,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Nf1",
            "Rfc8",
            "Ng3",
            "g6",
            "Qd2",
            "Bd8",
            "Red1",
            "Ba5",
            "Qe2",
            "Bb6",
            "dxe5",
            "dxe5",
            "Bxb6",
            "Qxb6",
            "Rd6",
            "Kg7",
            "Qd2",
            "Be8",
            "Nf5+",
            "gxf5",
            "Qg5+",
            "Kf8",
            "Qxf6",
            "Kg8",
            "Qg5+",
            "Kf8",
            "Qh6+",
            "Kg8",
            "Ng5",
            "Qc7",
            "Nxh7",
            "f6",
            "Nxf6+",
            "Kf7",
            "Qh7+",
            "Kf8",
            "Qg8+",
            "Ke7",
            "Re6+",
            "Kd8",
            "Qxe8#",
            "e5",
            "Nc6",
            "Nxd4"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "d6"
          ]
        },
        "query3": {
          "neutral_move": "Re1",
          "neutral_uci": "f1e1",
          "neutral_response": "6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. d5 Ne7 25. Nh4 Rac8 26. Bg5 Kh8 27. Bxf6 gxf6 28. Qf3 Ng8 29. Nhf5 Qb6 30. Qg4 Bxf5 31. Nxf5 * Be2 32. Qg7#",
          "neutral_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 216,
            "total_tokens": 363,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qf3",
            "Ng8",
            "Nhf5",
            "Qb6",
            "Qg4",
            "Bxf5",
            "Nxf5",
            "Be2",
            "Qg7#"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "d6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1e1",
          "positional_uci": "f1e1",
          "neutral_uci": "f1e1",
          "consensus_move": "f1e1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6+",
              "Bc7"
            ],
            "execute": [
              "Qh4",
              "g3",
              "Qh3"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Nf1",
              "Rfc8",
              "Ng3",
              "g6",
              "Qd2",
              "Bd8",
              "Red1",
              "Ba5",
              "Qe2",
              "Bb6",
              "dxe5",
              "dxe5",
              "Bxb6",
              "Qxb6",
              "Rd6",
              "Kg7",
              "Qd2",
              "Be8",
              "Nf5+",
              "gxf5",
              "Qg5+",
              "Kf8",
              "Qxf6",
              "Kg8",
              "Qg5+",
              "Kf8",
              "Qh6+",
              "Kg8",
              "Ng5",
              "Qc7",
              "Nxh7",
              "f6",
              "Nxf6+",
              "Kf7",
              "Qh7+",
              "Kf8",
              "Qg8+",
              "Ke7",
              "Re6+",
              "Kd8",
              "Qxe8#",
              "e5",
              "Nc6",
              "Nxd4"
            ],
            "execute": [
              "b5",
              "Bb3",
              "d6"
            ]
          },
          "neutral": {
            "full": [
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "d5",
              "Ne7",
              "Nh4",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qf3",
              "Ng8",
              "Nhf5",
              "Qb6",
              "Qg4",
              "Bxf5",
              "Nxf5",
              "Be2",
              "Qg7#"
            ],
            "execute": [
              "b5",
              "Bb3",
              "d6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b5",
            "Bb3",
            "d6"
          ],
          "full_moves": [
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qf3",
            "Ng8",
            "Nhf5",
            "Qb6",
            "Qg4",
            "Bxf5",
            "Nxf5",
            "Be2",
            "Qg7#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 148,
            "completion_tokens": 247,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 148,
            "completion_tokens": 282,
            "total_tokens": 430,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 147,
            "completion_tokens": 216,
            "total_tokens": 363,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 443,
          "total_completion_tokens": 745,
          "total_tokens": 1188
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 148,
            "completion_tokens": 247,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 148,
            "completion_tokens": 282,
            "total_tokens": 430,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 147,
            "completion_tokens": 216,
            "total_tokens": 363,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 w kq - 4 6"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c3",
          "aggressive_uci": "c2c3",
          "aggressive_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rad8 25. Bg5 exd4 26. Bxf6 gxf6 27. Qh6 Ne7 28. Nh5 Nf5 29. Nxf6+ Kh8 30. Qxh7# e4 Nxe4 Qe7 Qe6",
          "aggressive_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 198,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rad8",
            "Bg5",
            "exd4",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Ne7",
            "Nh5",
            "Nf5",
            "Nxf6+",
            "Kh8",
            "Qxh7#",
            "e4",
            "Nxe4",
            "Qe7",
            "Qe6"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "query2": {
          "positional_move": "c3",
          "positional_uci": "c2c3",
          "positional_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6 43. Nd2 Kc5 44. a3 Ng6 45. g3 Bd7 46. h4 Nf8 47. Nb1 Ne6 48. Nc3 Nd4 49. Nd5 f5 50. Nf6 fxe4 51. Nxd7+ Kd6 52. Bxe4 Kxd7 53. Bxh7 Ke6 54. Bd3 Kf6 55. f4 Ne6 56. Bxb5 exf4+ 57. gxf4 Nc5 58. Kd4 Ne6+ 59. Ke3 Nc5 60. Bd3 Ke6 61. h5 Kf6 62. h6 Ne6 63. Bc2 Nc5 64. Kd4 Ne6+ 65. Kc4 Nxf4 66. Bxa4 Kg6 67. Bc6 Kxh6 68. a4 Kg6 69. a5 Kf6 70. a6 Ne6 71. a7 Nc7 72. a8=Q Nxa8 73. Bxa8 Ke7 74. Kc5 Kd7 75. Kb6 Kc8 76. b4 Kb8 77. Bc6 Kc8 78. b5 Kb8 79. Bd5 Kc8 80. Ka7 Kc7 81. b6+ Kd6 82. b7 Kxd5 83. b8=Q Kc6 84. Qb4 Kd5 85. Kb",
          "positional_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Ng6",
            "g3",
            "Bd7",
            "h4",
            "Nf8",
            "Nb1",
            "Ne6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "fxe4",
            "Nxd7+",
            "Kd6",
            "Bxe4",
            "Kxd7",
            "Bxh7",
            "Ke6",
            "Bd3",
            "Kf6",
            "f4",
            "Ne6",
            "Bxb5",
            "exf4+",
            "gxf4",
            "Nc5",
            "Kd4",
            "Ne6+",
            "Ke3",
            "Nc5",
            "Bd3",
            "Ke6",
            "h5",
            "Kf6",
            "h6",
            "Ne6",
            "Bc2",
            "Nc5",
            "Kd4",
            "Ne6+",
            "Kc4",
            "Nxf4",
            "Bxa4",
            "Kg6",
            "Bc6",
            "Kxh6",
            "a4",
            "Kg6",
            "a5",
            "Kf6",
            "a6",
            "Ne6",
            "a7",
            "Nc7",
            "a8=Q",
            "Nxa8",
            "Bxa8",
            "Ke7",
            "Kc5",
            "Kd7",
            "Kb6",
            "Kc8",
            "b4",
            "Kb8",
            "Bc6",
            "Kc8",
            "b5",
            "Kb8",
            "Bd5",
            "Kc8",
            "Ka7",
            "Kc7",
            "b6+",
            "Kd6",
            "b7",
            "Kxd5",
            "b8=Q",
            "Kc6",
            "Qb4",
            "Kd5"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "query3": {
          "neutral_move": "c3",
          "neutral_uci": "c2c3",
          "neutral_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6 43. Nd2 Kc5 44. a3 Ng6 45. g3 Bd7 46. h4 Nf8 47. Nb1 Ne6 48. Nc3 Nd4 49. Nd5 f5 50. Nf6 fxe4 51. Nxe4+ Kd5 52. Nf6+ Ke6 53. Nxd7 Kxd7 54. Bxh7 Ke6 55. Bd3 Kf6 56. f4 Nf5+ 57. Bxf5 Kxf5 58. fxe5 Kxe5 59. g4 Kf6 60. Kd4 Ke6 61. Kc5 Ke5 62. Kxb5 Kf4 63. g5 Kf5 64. Kxa4 Kg6 65. Kb5 Kh5 66. a4 Kg6 67. a5 Kh5 68. a6 Kg6 69. a7 Kh5 70. a8=Q Kg6 71. Qe4+ Kh5 72. Qf3+ Kg6 73. Qg4 Kg7 74. h5 Kh7 75. Qd7+ Kg8 76. g6 Kh8 77. Qh7# e4 d5 e5 dxe6",
          "neutral_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 580,
            "total_tokens": 742,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Ng6",
            "g3",
            "Bd7",
            "h4",
            "Nf8",
            "Nb1",
            "Ne6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "fxe4",
            "Nxe4+",
            "Kd5",
            "Nf6+",
            "Ke6",
            "Nxd7",
            "Kxd7",
            "Bxh7",
            "Ke6",
            "Bd3",
            "Kf6",
            "f4",
            "Nf5+",
            "Bxf5",
            "Kxf5",
            "fxe5",
            "Kxe5",
            "g4",
            "Kf6",
            "Kd4",
            "Ke6",
            "Kc5",
            "Ke5",
            "Kxb5",
            "Kf4",
            "g5",
            "Kf5",
            "Kxa4",
            "Kg6",
            "Kb5",
            "Kh5",
            "a4",
            "Kg6",
            "a5",
            "Kh5",
            "a6",
            "Kg6",
            "a7",
            "Kh5",
            "a8=Q",
            "Kg6",
            "Qe4+",
            "Kh5",
            "Qf3+",
            "Kg6",
            "Qg4",
            "Kg7",
            "h5",
            "Kh7",
            "Qd7+",
            "Kg8",
            "g6",
            "Kh8",
            "Qh7#",
            "e4",
            "d5",
            "e5",
            "dxe6"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c2c3",
          "positional_uci": "c2c3",
          "neutral_uci": "c2c3",
          "consensus_move": "c2c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rad8",
              "Bg5",
              "exd4",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Ne7",
              "Nh5",
              "Nf5",
              "Nxf6+",
              "Kh8",
              "Qxh7#",
              "e4",
              "Nxe4",
              "Qe7",
              "Qe6"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Ng6",
              "g3",
              "Bd7",
              "h4",
              "Nf8",
              "Nb1",
              "Ne6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "fxe4",
              "Nxd7+",
              "Kd6",
              "Bxe4",
              "Kxd7",
              "Bxh7",
              "Ke6",
              "Bd3",
              "Kf6",
              "f4",
              "Ne6",
              "Bxb5",
              "exf4+",
              "gxf4",
              "Nc5",
              "Kd4",
              "Ne6+",
              "Ke3",
              "Nc5",
              "Bd3",
              "Ke6",
              "h5",
              "Kf6",
              "h6",
              "Ne6",
              "Bc2",
              "Nc5",
              "Kd4",
              "Ne6+",
              "Kc4",
              "Nxf4",
              "Bxa4",
              "Kg6",
              "Bc6",
              "Kxh6",
              "a4",
              "Kg6",
              "a5",
              "Kf6",
              "a6",
              "Ne6",
              "a7",
              "Nc7",
              "a8=Q",
              "Nxa8",
              "Bxa8",
              "Ke7",
              "Kc5",
              "Kd7",
              "Kb6",
              "Kc8",
              "b4",
              "Kb8",
              "Bc6",
              "Kc8",
              "b5",
              "Kb8",
              "Bd5",
              "Kc8",
              "Ka7",
              "Kc7",
              "b6+",
              "Kd6",
              "b7",
              "Kxd5",
              "b8=Q",
              "Kc6",
              "Qb4",
              "Kd5"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Ng6",
              "g3",
              "Bd7",
              "h4",
              "Nf8",
              "Nb1",
              "Ne6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "fxe4",
              "Nxe4+",
              "Kd5",
              "Nf6+",
              "Ke6",
              "Nxd7",
              "Kxd7",
              "Bxh7",
              "Ke6",
              "Bd3",
              "Kf6",
              "f4",
              "Nf5+",
              "Bxf5",
              "Kxf5",
              "fxe5",
              "Kxe5",
              "g4",
              "Kf6",
              "Kd4",
              "Ke6",
              "Kc5",
              "Ke5",
              "Kxb5",
              "Kf4",
              "g5",
              "Kf5",
              "Kxa4",
              "Kg6",
              "Kb5",
              "Kh5",
              "a4",
              "Kg6",
              "a5",
              "Kh5",
              "a6",
              "Kg6",
              "a7",
              "Kh5",
              "a8=Q",
              "Kg6",
              "Qe4+",
              "Kh5",
              "Qf3+",
              "Kg6",
              "Qg4",
              "Kg7",
              "h5",
              "Kh7",
              "Qd7+",
              "Kg8",
              "g6",
              "Kh8",
              "Qh7#",
              "e4",
              "d5",
              "e5",
              "dxe6"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "h3",
            "Na5"
          ],
          "full_moves": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Ng6",
            "g3",
            "Bd7",
            "h4",
            "Nf8",
            "Nb1",
            "Ne6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "fxe4",
            "Nxe4+",
            "Kd5",
            "Nf6+",
            "Ke6",
            "Nxd7",
            "Kxd7",
            "Bxh7",
            "Ke6",
            "Bd3",
            "Kf6",
            "f4",
            "Nf5+",
            "Bxf5",
            "Kxf5",
            "fxe5",
            "Kxe5",
            "g4",
            "Kf6",
            "Kd4",
            "Ke6",
            "Kc5",
            "Ke5",
            "Kxb5",
            "Kf4",
            "g5",
            "Kf5",
            "Kxa4",
            "Kg6",
            "Kb5",
            "Kh5",
            "a4",
            "Kg6",
            "a5",
            "Kh5",
            "a6",
            "Kg6",
            "a7",
            "Kh5",
            "a8=Q",
            "Kg6",
            "Qe4+",
            "Kh5",
            "Qf3+",
            "Kg6",
            "Qg4",
            "Kg7",
            "h5",
            "Kh7",
            "Qd7+",
            "Kg8",
            "g6",
            "Kh8",
            "Qh7#",
            "e4",
            "d5",
            "e5",
            "dxe6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 163,
            "completion_tokens": 198,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 162,
            "completion_tokens": 580,
            "total_tokens": 742,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 488,
          "total_completion_tokens": 1418,
          "total_tokens": 1906
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 163,
            "completion_tokens": 198,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 162,
            "completion_tokens": 580,
            "total_tokens": 742,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 w kq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc2",
          "aggressive_uci": "b3c2",
          "aggressive_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. Ng3 g6 16. b3 Nb6 17. Bh6 Rfe8 18. Qd2 Bf8 19. Bxf8 Rxf8 20. Qh6 Kh8 21. Ng5 Be8 22. Re3 Rg8 23. Rf3 Qe7 24. Rxf6 Rg7 25. Nh5 gxh5 26. Nxh7 Rxh7 27. Qg5 Nd7 28. Rf5 Qxg5 29. Rxg5 f6 30. Rg3 Rg7 31. Rf3 Bg6 32. Re1 Rf8 33. Kh2 Bh7 34. Rfe3 f5 35. f3 f4 36. R3e2 Rfg8 37. Rf2 Nf6 38. Ree2 h4 39. Rd2 Nh5 40. Bd3 Ng3 41. Rc2 Rb8 42. Rb2 Rgb7 43. Rbc2 Bg6 44. Rb2 Be8 45. Rbc2 a5 46. Rb2 a4 47. Rbc2 axb3 48. axb3 Ra7 49. Rb2 Ra1 50. Rb1 Rba8 51. Rfb2 Rxb1 52. Rxb1 Ra2 53. Kg1 Kg7 54. Kh2 Kf6 55. Kg1 Ke7 56. Kh2 Kd8 57. Kg1 Kc7 58. Kh2 Kb6 59. Kg1 Ka5 60. Kh2 Kb6 61. Kg1 Bd7 62. Kh2 Bc8 63. Kg1 Ba6 64. Kh2 Ka5 65. Kg1 Kb6 66. Kh2 b4 67. c4 Rd2 68. Bf1 Nxf1+ 69. Rxf1 Rb2 70. Ra1 Rxb3 71. Ra2 Ra3 72. Rb2 Bxc4 73. Kg1 Ra1+ 74. Kh2 Ra2 75. Rb1 b3 76. Kg1 b2 77. Kh2 Bd3 78. Rd1 b1=Q 79. Rxb1+ Bxb1 80. Kg1 Bd3 81. Kh2 Bf1 82. Kg1 Bxg2 83. Kh2 Bxf3+ 84. Kg1 Bxe4 85. Kf1 Bxd5 86. Ke1 Bg2 87. Kd1 Bxh3 88.",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "Ng3",
            "g6",
            "b3",
            "Nb6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "Re3",
            "Rg8",
            "Rf3",
            "Qe7",
            "Rxf6",
            "Rg7",
            "Nh5",
            "gxh5",
            "Nxh7",
            "Rxh7",
            "Qg5",
            "Nd7",
            "Rf5",
            "Qxg5",
            "Rxg5",
            "f6",
            "Rg3",
            "Rg7",
            "Rf3",
            "Bg6",
            "Re1",
            "Rf8",
            "Kh2",
            "Bh7",
            "Rfe3",
            "f5",
            "f3",
            "f4",
            "R3e2",
            "Rfg8",
            "Rf2",
            "Nf6",
            "Ree2",
            "h4",
            "Rd2",
            "Nh5",
            "Bd3",
            "Ng3",
            "Rc2",
            "Rb8",
            "Rb2",
            "Rgb7",
            "Rbc2",
            "Bg6",
            "Rb2",
            "Be8",
            "Rbc2",
            "a5",
            "Rb2",
            "a4",
            "Rbc2",
            "axb3",
            "axb3",
            "Ra7",
            "Rb2",
            "Ra1",
            "Rb1",
            "Rba8",
            "Rfb2",
            "Rxb1",
            "Rxb1",
            "Ra2",
            "Kg1",
            "Kg7",
            "Kh2",
            "Kf6",
            "Kg1",
            "Ke7",
            "Kh2",
            "Kd8",
            "Kg1",
            "Kc7",
            "Kh2",
            "Kb6",
            "Kg1",
            "Ka5",
            "Kh2",
            "Kb6",
            "Kg1",
            "Bd7",
            "Kh2",
            "Bc8",
            "Kg1",
            "Ba6",
            "Kh2",
            "Ka5",
            "Kg1",
            "Kb6",
            "Kh2",
            "b4",
            "c4",
            "Rd2",
            "Bf1",
            "Nxf1+",
            "Rxf1",
            "Rb2",
            "Ra1",
            "Rxb3",
            "Ra2",
            "Ra3",
            "Rb2",
            "Bxc4",
            "Kg1",
            "Ra1+",
            "Kh2",
            "Ra2",
            "Rb1",
            "b3",
            "Kg1",
            "b2",
            "Kh2",
            "Bd3",
            "Rd1",
            "b1=Q",
            "Rxb1+",
            "Bxb1",
            "Kg1",
            "Bd3",
            "Kh2",
            "Bf1",
            "Kg1",
            "Bxg2",
            "Kh2",
            "Bxf3+",
            "Kg1",
            "Bxe4",
            "Kf1",
            "Bxd5",
            "Ke1",
            "Bg2",
            "Kd1",
            "Bxh3"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "query2": {
          "positional_move": "Bc2",
          "positional_uci": "b3c2",
          "positional_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. b3 Nb6 16. Ng3 g6 17. Bh6 Rfe8 18. Qd2 c4 19. b4 a5 20. a3 Ra7 21. Nh2 Rea8 22. Rac1 axb4 23. axb4 Ra2 24. f4 exf4 25. Qxf4 Be8 26. Rf1 Nbd7 27. Nf5 Ne5 28. Nxe7+ Qxe7 29. Qxf6 Qxf6 30. Rxf6 R8a6 31. Nf3 Nd7 32. Rf4 f6 33. Nd4 g5 34. Rf2 Rb6 35. h4 gxh4 36. Rcf1 Bg6 37. Bb1 Ra3 38. Rf3 Bh5 39. Rh3 Bg4 40. Rxh4 Ne5 41. Rxf6 Rb8 42. Nxb5 Ra1 43. Kh2 Rxb1 44. Nxd6 Bd7 45. Rhf4 Ng6 46. Rf7 Ba4 47. Rg7+ Kh8 48. Nf7# d3 Nf6+ Kh8 Nf7# d3 Nf6+ Kh8 Nf7# d3 Nf6+ Kh8 Nf7# d3 Nf6+ Kh8 Nf7#",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 372,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "c4",
            "b4",
            "a5",
            "a3",
            "Ra7",
            "Nh2",
            "Rea8",
            "Rac1",
            "axb4",
            "axb4",
            "Ra2",
            "f4",
            "exf4",
            "Qxf4",
            "Be8",
            "Rf1",
            "Nbd7",
            "Nf5",
            "Ne5",
            "Nxe7+",
            "Qxe7",
            "Qxf6",
            "Qxf6",
            "Rxf6",
            "R8a6",
            "Nf3",
            "Nd7",
            "Rf4",
            "f6",
            "Nd4",
            "g5",
            "Rf2",
            "Rb6",
            "h4",
            "gxh4",
            "Rcf1",
            "Bg6",
            "Bb1",
            "Ra3",
            "Rf3",
            "Bh5",
            "Rh3",
            "Bg4",
            "Rxh4",
            "Ne5",
            "Rxf6",
            "Rb8",
            "Nxb5",
            "Ra1",
            "Kh2",
            "Rxb1",
            "Nxd6",
            "Bd7",
            "Rhf4",
            "Ng6",
            "Rf7",
            "Ba4",
            "Rg7+",
            "Kh8",
            "Nf7#",
            "d3",
            "Nf6+",
            "Kh8",
            "Nf7#",
            "d3",
            "Nf6+",
            "Kh8",
            "Nf7#",
            "d3",
            "Nf6+",
            "Kh8",
            "Nf7#",
            "d3",
            "Nf6+",
            "Kh8",
            "Nf7#"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "query3": {
          "neutral_move": "Bc2",
          "neutral_uci": "b3c2",
          "neutral_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. b3 Nb6 16. Ng3 g6 17. Bh6 Rfe8 18. Qd2 Bf8 19. Bxf8 Rxf8 20. Qh6 Kh8 21. Ng5 Be8 22. f4 Rg8 23. fxe5 dxe5 24. Rf1 Qd6 25. Rxf6 Qxf6 26. Qxh7# 1-0\n\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3\nNa5 9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. b3 Nb6 16. Ng3 g6 17. Bh6 Rfe8 18. Qd2 Bf8 19. Bxf8 Rxf8 20. Qh6 Kh8 21. Ng5 Be8 22. f4 Rg8 23. fxe5 dxe5 24. Rf1 Qd6 25. Rxf6 Qxf6 26. Qxh7# 1-0 1-0 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 d6 c3 Na5 Bc2 c5 d4 Qc7 Nbd2 O-O Nf1 Bg4 d5 Nc4 h3 Bd7 b3 Nb6 Ng3 g6 Bh6 Rfe8 Qd2 Bf8 Bxf8 Rxf8 Qh6 Kh8 Ng5 Be8 f4 Rg8 fxe5 dxe5 Rf1 Qd6 Rxf6 Qxf6 Qxh7#",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 493,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "f4",
            "Rg8",
            "fxe5",
            "dxe5",
            "Rf1",
            "Qd6",
            "Rxf6",
            "Qxf6",
            "Qxh7#"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b3c2",
          "positional_uci": "b3c2",
          "neutral_uci": "b3c2",
          "consensus_move": "b3c2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "Ng3",
              "g6",
              "b3",
              "Nb6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "Bf8",
              "Bxf8",
              "Rxf8",
              "Qh6",
              "Kh8",
              "Ng5",
              "Be8",
              "Re3",
              "Rg8",
              "Rf3",
              "Qe7",
              "Rxf6",
              "Rg7",
              "Nh5",
              "gxh5",
              "Nxh7",
              "Rxh7",
              "Qg5",
              "Nd7",
              "Rf5",
              "Qxg5",
              "Rxg5",
              "f6",
              "Rg3",
              "Rg7",
              "Rf3",
              "Bg6",
              "Re1",
              "Rf8",
              "Kh2",
              "Bh7",
              "Rfe3",
              "f5",
              "f3",
              "f4",
              "R3e2",
              "Rfg8",
              "Rf2",
              "Nf6",
              "Ree2",
              "h4",
              "Rd2",
              "Nh5",
              "Bd3",
              "Ng3",
              "Rc2",
              "Rb8",
              "Rb2",
              "Rgb7",
              "Rbc2",
              "Bg6",
              "Rb2",
              "Be8",
              "Rbc2",
              "a5",
              "Rb2",
              "a4",
              "Rbc2",
              "axb3",
              "axb3",
              "Ra7",
              "Rb2",
              "Ra1",
              "Rb1",
              "Rba8",
              "Rfb2",
              "Rxb1",
              "Rxb1",
              "Ra2",
              "Kg1",
              "Kg7",
              "Kh2",
              "Kf6",
              "Kg1",
              "Ke7",
              "Kh2",
              "Kd8",
              "Kg1",
              "Kc7",
              "Kh2",
              "Kb6",
              "Kg1",
              "Ka5",
              "Kh2",
              "Kb6",
              "Kg1",
              "Bd7",
              "Kh2",
              "Bc8",
              "Kg1",
              "Ba6",
              "Kh2",
              "Ka5",
              "Kg1",
              "Kb6",
              "Kh2",
              "b4",
              "c4",
              "Rd2",
              "Bf1",
              "Nxf1+",
              "Rxf1",
              "Rb2",
              "Ra1",
              "Rxb3",
              "Ra2",
              "Ra3",
              "Rb2",
              "Bxc4",
              "Kg1",
              "Ra1+",
              "Kh2",
              "Ra2",
              "Rb1",
              "b3",
              "Kg1",
              "b2",
              "Kh2",
              "Bd3",
              "Rd1",
              "b1=Q",
              "Rxb1+",
              "Bxb1",
              "Kg1",
              "Bd3",
              "Kh2",
              "Bf1",
              "Kg1",
              "Bxg2",
              "Kh2",
              "Bxf3+",
              "Kg1",
              "Bxe4",
              "Kf1",
              "Bxd5",
              "Ke1",
              "Bg2",
              "Kd1",
              "Bxh3"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          },
          "positional": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "b3",
              "Nb6",
              "Ng3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "c4",
              "b4",
              "a5",
              "a3",
              "Ra7",
              "Nh2",
              "Rea8",
              "Rac1",
              "axb4",
              "axb4",
              "Ra2",
              "f4",
              "exf4",
              "Qxf4",
              "Be8",
              "Rf1",
              "Nbd7",
              "Nf5",
              "Ne5",
              "Nxe7+",
              "Qxe7",
              "Qxf6",
              "Qxf6",
              "Rxf6",
              "R8a6",
              "Nf3",
              "Nd7",
              "Rf4",
              "f6",
              "Nd4",
              "g5",
              "Rf2",
              "Rb6",
              "h4",
              "gxh4",
              "Rcf1",
              "Bg6",
              "Bb1",
              "Ra3",
              "Rf3",
              "Bh5",
              "Rh3",
              "Bg4",
              "Rxh4",
              "Ne5",
              "Rxf6",
              "Rb8",
              "Nxb5",
              "Ra1",
              "Kh2",
              "Rxb1",
              "Nxd6",
              "Bd7",
              "Rhf4",
              "Ng6",
              "Rf7",
              "Ba4",
              "Rg7+",
              "Kh8",
              "Nf7#",
              "d3",
              "Nf6+",
              "Kh8",
              "Nf7#",
              "d3",
              "Nf6+",
              "Kh8",
              "Nf7#",
              "d3",
              "Nf6+",
              "Kh8",
              "Nf7#",
              "d3",
              "Nf6+",
              "Kh8",
              "Nf7#"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          },
          "neutral": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "b3",
              "Nb6",
              "Ng3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "Bf8",
              "Bxf8",
              "Rxf8",
              "Qh6",
              "Kh8",
              "Ng5",
              "Be8",
              "f4",
              "Rg8",
              "fxe5",
              "dxe5",
              "Rf1",
              "Qd6",
              "Rxf6",
              "Qxf6",
              "Qxh7#"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "c5",
            "d4",
            "Qc7"
          ],
          "full_moves": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "f4",
            "Rg8",
            "fxe5",
            "dxe5",
            "Rf1",
            "Qd6",
            "Rxf6",
            "Qxf6",
            "Qxh7#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 372,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 493,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1505,
          "total_tokens": 2017
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 372,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 493,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/np2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 w kq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d3",
          "aggressive_uci": "d2d3",
          "aggressive_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 Bg4 13. h3 Bh5 14. Ng3 Bg6 15. Nh4 Nfd7 16. Nhf5 Bxf5 17. Nxf5 Bg5 18. Qg4 h6 19. h4 Nf6 20. Qg3 Nh5 21. Qg4 Nf6 22. Qh3 Bxc1 23. Raxc1 Kh7 24. d4 g6 25. Ng3 Qd7 26. Qh2 Ng4 27. Qh1 exd4 28. cxd4 Nc4 29. b3 Na3 30. Bd3 b4 31. h5 Nb5 32. hxg6+ fxg6 33. f3 Nf6 34. e5 dxe5 35. dxe5 Qxd3 36. exf6 Rxf6 37. Re7+ Kg8 38. Qxh6 Qd4+ 39. Kh1 Rf7 40. Qxg6+ Qg7 41. Qxg7+ Rxg7 42. Rxg7+ Kxg7 43. Ne4 Rh8+ 44. Kg1 Rd8 45. Rc6 a5 46. Rc5 Rb8 47. Kf2 Kf7 48. g4 Ke6 49. f4 Kd7 50. g5 c6 51. f5 Nd4 52. Rxa5 Rf8 53. f6 Ke6 54. g6 Nf5 55. g7 Rg8 56. Ra6 Kd5 57. f7 Rxg7 58. f8=Q Kxe4 59. Qxb4+ Nd4 60. Ra4 Rf7+ 61. Kg2 Rg7+ 62. Kh3 Rh7+ 63. Kg4 Rg7+ 64. Kh5 Rh7+ 65. Kg6 Rd7 66. Qe1+ Kd5 67. Ra5+ c5 68. b4 Rd6+ 69. Kf7 Rd7+ 70. Ke8 Rc7 71. Rxc5+ Rxc5 72. bxc5 Kxc5 73. Qc3+ Kd5 74. a4 Nc6 75. a5 Kd6 76. a6 Kc7 77. Qc5 Kb8 78. Qxc6 Ka7 79. Qb7# Nf6+ 80. Kf7 Nd7 81. Qxd7+ Kxa6 82. Qc6+ Ka5 83. Qb7 Ka4 84. Ke6 Ka3 85. Kd5 Ka2",
          "aggressive_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "Nfd7",
            "Nhf5",
            "Bxf5",
            "Nxf5",
            "Bg5",
            "Qg4",
            "h6",
            "h4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qh3",
            "Bxc1",
            "Raxc1",
            "Kh7",
            "d4",
            "g6",
            "Ng3",
            "Qd7",
            "Qh2",
            "Ng4",
            "Qh1",
            "exd4",
            "cxd4",
            "Nc4",
            "b3",
            "Na3",
            "Bd3",
            "b4",
            "h5",
            "Nb5",
            "hxg6+",
            "fxg6",
            "f3",
            "Nf6",
            "e5",
            "dxe5",
            "dxe5",
            "Qxd3",
            "exf6",
            "Rxf6",
            "Re7+",
            "Kg8",
            "Qxh6",
            "Qd4+",
            "Kh1",
            "Rf7",
            "Qxg6+",
            "Qg7",
            "Qxg7+",
            "Rxg7",
            "Rxg7+",
            "Kxg7",
            "Ne4",
            "Rh8+",
            "Kg1",
            "Rd8",
            "Rc6",
            "a5",
            "Rc5",
            "Rb8",
            "Kf2",
            "Kf7",
            "g4",
            "Ke6",
            "f4",
            "Kd7",
            "g5",
            "c6",
            "f5",
            "Nd4",
            "Rxa5",
            "Rf8",
            "f6",
            "Ke6",
            "g6",
            "Nf5",
            "g7",
            "Rg8",
            "Ra6",
            "Kd5",
            "f7",
            "Rxg7",
            "f8=Q",
            "Kxe4",
            "Qxb4+",
            "Nd4",
            "Ra4",
            "Rf7+",
            "Kg2",
            "Rg7+",
            "Kh3",
            "Rh7+",
            "Kg4",
            "Rg7+",
            "Kh5",
            "Rh7+",
            "Kg6",
            "Rd7",
            "Qe1+",
            "Kd5",
            "Ra5+",
            "c5",
            "b4",
            "Rd6+",
            "Kf7",
            "Rd7+",
            "Ke8",
            "Rc7",
            "Rxc5+",
            "Rxc5",
            "bxc5",
            "Kxc5",
            "Qc3+",
            "Kd5",
            "a4",
            "Nc6",
            "a5",
            "Kd6",
            "a6",
            "Kc7",
            "Qc5",
            "Kb8",
            "Qxc6",
            "Ka7",
            "Qb7#",
            "Nf6+",
            "Kf7",
            "Nd7",
            "Qxd7+",
            "Kxa6",
            "Qc6+",
            "Ka5",
            "Qb7",
            "Ka4",
            "Ke6",
            "Ka3",
            "Kd5",
            "Ka2"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "d3",
          "positional_uci": "d2d3",
          "positional_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 Bb7 13. Ng3 Re8 14. Nf5 Bf8 15. Bg5 h6 16. Bh4 g6 17. Ne3 Bg7 18. Qd2 Qd7 19. Rad1 d5 20. exd5 Nfxd5 21. Nxd5 Bxd5 22. Qe3 Qc6 23. Bg3 Bxf3 24. gxf3 Nd5 25. Qe4 f5 26. Qe2 f4 27. Bh4 g5 28. Qe4 gxh4 29. Bb3 Rad8 30. c4 bxc4 31. dxc4 Qf6 32. cxd5 Kh8 33. Bc2 Kg8 34. Kh1 Rd6 35. Rg1 Kf8 36. Rg6 Qf7 37. Rdg1 Rxg6 38. Rxg6 Rd8 39. Bb3 Rd6 40. Rxd6 cxd6 41. Qb4 Qc7 42. Bc4 a5 43. Qb5 Ke7 44. b4 axb4 45. Qxb4 Qa7 46. Kg2 Bf6 47. a4 Kd7 48. Bb5+ Ke7 49. a5 Kd8 50. Qxd6+ Kc8 51. Ba6+ Qxa6 52. Qxa6+ Kd7 53. Qxf6 Kc7 54. Qxe5+ Kb7 55. Qxf4 Ka6 56. Qxh4 Kxa5 57. Qxh6 Kb5 58. Qc6+ Kb4 59. d6 Kb3 60. d7 Kb2 61. d8=Q Kb1 62. Qb8+ Ka2 63. Qca8# d4 e5 d3 e4 d2 e3 d1=Q#",
          "positional_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 470,
            "total_tokens": 650,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e4",
            "d2",
            "e3",
            "d1=Q#"
          ],
          "plan_execute": [
            "e4",
            "d2",
            "e3"
          ]
        },
        "query3": {
          "neutral_move": "d3",
          "neutral_uci": "d2d3",
          "neutral_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 c5 13. Ng3 Qc7 14. h3 Re8 15. Be3 Bf8 16. Rc1 d5\n17. d4 exd4 18. cxd4 dxe4 19. Ng5 Bb7 20. dxc5 Nc4 21. Bd4 Rad8 22. N5xe4 Nxe4\n23. Nxe4 Bxc5 24. Nxc5 Rxe1+ 25. Qxe1 Bc6 26. Nb3 Qf4 27. Be3 Qf6 28. Rd1 Re8\n29. Nd4 Bb7 30. b3 Nxe3 31. fxe3 Qg5 32. Qf2 Rxe3 33. Nf5 Re8 34. Nd6 Re7\n35. Nxb7 Rxb7 36. Qf5 Qe3+ 37. Kh1 g6 38. Qc8+ Kg7 39. Qxb7 Qe2 40. Qe4 Qh5\n41. Qd4+ Kh6 42. Qf4+ Kg7 43. Rd7 g5 44. Qe5+ Kh6 45. Qf6+ Qg6 46. Bxg6 hxg6\n47. Qh8# Nf6 Qxf6 49. Qxf6 Kh5 50. Qh8#",
          "neutral_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 339,
            "total_tokens": 518,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "c5",
            "Ng3",
            "Qc7",
            "h3",
            "Re8",
            "Be3",
            "Bf8",
            "Rc1",
            "d5",
            "d4",
            "exd4",
            "cxd4",
            "dxe4",
            "Ng5",
            "Bb7",
            "dxc5",
            "Nc4",
            "Bd4",
            "Rad8",
            "N5xe4",
            "Nxe4",
            "Nxe4",
            "Bxc5",
            "Nxc5",
            "Rxe1+",
            "Qxe1",
            "Bc6",
            "Nb3",
            "Qf4",
            "Be3",
            "Qf6",
            "Rd1",
            "Re8",
            "Nd4",
            "Bb7",
            "b3",
            "Nxe3",
            "fxe3",
            "Qg5",
            "Qf2",
            "Rxe3",
            "Nf5",
            "Re8",
            "Nd6",
            "Re7",
            "Nxb7",
            "Rxb7",
            "Qf5",
            "Qe3+",
            "Kh1",
            "g6",
            "Qc8+",
            "Kg7",
            "Qxb7",
            "Qe2",
            "Qe4",
            "Qh5",
            "Qd4+",
            "Kh6",
            "Qf4+",
            "Kg7",
            "Rd7",
            "g5",
            "Qe5+",
            "Kh6",
            "Qf6+",
            "Qg6",
            "Bxg6",
            "hxg6",
            "Qh8#",
            "Nf6",
            "Qxf6",
            "Qxf6",
            "Kh5",
            "Qh8#"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d2d3",
          "positional_uci": "d2d3",
          "neutral_uci": "d2d3",
          "consensus_move": "d2d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "Nfd7",
              "Nhf5",
              "Bxf5",
              "Nxf5",
              "Bg5",
              "Qg4",
              "h6",
              "h4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qh3",
              "Bxc1",
              "Raxc1",
              "Kh7",
              "d4",
              "g6",
              "Ng3",
              "Qd7",
              "Qh2",
              "Ng4",
              "Qh1",
              "exd4",
              "cxd4",
              "Nc4",
              "b3",
              "Na3",
              "Bd3",
              "b4",
              "h5",
              "Nb5",
              "hxg6+",
              "fxg6",
              "f3",
              "Nf6",
              "e5",
              "dxe5",
              "dxe5",
              "Qxd3",
              "exf6",
              "Rxf6",
              "Re7+",
              "Kg8",
              "Qxh6",
              "Qd4+",
              "Kh1",
              "Rf7",
              "Qxg6+",
              "Qg7",
              "Qxg7+",
              "Rxg7",
              "Rxg7+",
              "Kxg7",
              "Ne4",
              "Rh8+",
              "Kg1",
              "Rd8",
              "Rc6",
              "a5",
              "Rc5",
              "Rb8",
              "Kf2",
              "Kf7",
              "g4",
              "Ke6",
              "f4",
              "Kd7",
              "g5",
              "c6",
              "f5",
              "Nd4",
              "Rxa5",
              "Rf8",
              "f6",
              "Ke6",
              "g6",
              "Nf5",
              "g7",
              "Rg8",
              "Ra6",
              "Kd5",
              "f7",
              "Rxg7",
              "f8=Q",
              "Kxe4",
              "Qxb4+",
              "Nd4",
              "Ra4",
              "Rf7+",
              "Kg2",
              "Rg7+",
              "Kh3",
              "Rh7+",
              "Kg4",
              "Rg7+",
              "Kh5",
              "Rh7+",
              "Kg6",
              "Rd7",
              "Qe1+",
              "Kd5",
              "Ra5+",
              "c5",
              "b4",
              "Rd6+",
              "Kf7",
              "Rd7+",
              "Ke8",
              "Rc7",
              "Rxc5+",
              "Rxc5",
              "bxc5",
              "Kxc5",
              "Qc3+",
              "Kd5",
              "a4",
              "Nc6",
              "a5",
              "Kd6",
              "a6",
              "Kc7",
              "Qc5",
              "Kb8",
              "Qxc6",
              "Ka7",
              "Qb7#",
              "Nf6+",
              "Kf7",
              "Nd7",
              "Qxd7+",
              "Kxa6",
              "Qc6+",
              "Ka5",
              "Qb7",
              "Ka4",
              "Ke6",
              "Ka3",
              "Kd5",
              "Ka2"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "e4",
              "d2",
              "e3",
              "d1=Q#"
            ],
            "execute": [
              "e4",
              "d2",
              "e3"
            ]
          },
          "neutral": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "c5",
              "Ng3",
              "Qc7",
              "h3",
              "Re8",
              "Be3",
              "Bf8",
              "Rc1",
              "d5",
              "d4",
              "exd4",
              "cxd4",
              "dxe4",
              "Ng5",
              "Bb7",
              "dxc5",
              "Nc4",
              "Bd4",
              "Rad8",
              "N5xe4",
              "Nxe4",
              "Nxe4",
              "Bxc5",
              "Nxc5",
              "Rxe1+",
              "Qxe1",
              "Bc6",
              "Nb3",
              "Qf4",
              "Be3",
              "Qf6",
              "Rd1",
              "Re8",
              "Nd4",
              "Bb7",
              "b3",
              "Nxe3",
              "fxe3",
              "Qg5",
              "Qf2",
              "Rxe3",
              "Nf5",
              "Re8",
              "Nd6",
              "Re7",
              "Nxb7",
              "Rxb7",
              "Qf5",
              "Qe3+",
              "Kh1",
              "g6",
              "Qc8+",
              "Kg7",
              "Qxb7",
              "Qe2",
              "Qe4",
              "Qh5",
              "Qd4+",
              "Kh6",
              "Qf4+",
              "Kg7",
              "Rd7",
              "g5",
              "Qe5+",
              "Kh6",
              "Qf6+",
              "Qg6",
              "Bxg6",
              "hxg6",
              "Qh8#",
              "Nf6",
              "Qxf6",
              "Qxf6",
              "Kh5",
              "Qh8#"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nb6",
            "Nbd2",
            "O-O"
          ],
          "full_moves": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "c5",
            "Ng3",
            "Qc7",
            "h3",
            "Re8",
            "Be3",
            "Bf8",
            "Rc1",
            "d5",
            "d4",
            "exd4",
            "cxd4",
            "dxe4",
            "Ng5",
            "Bb7",
            "dxc5",
            "Nc4",
            "Bd4",
            "Rad8",
            "N5xe4",
            "Nxe4",
            "Nxe4",
            "Bxc5",
            "Nxc5",
            "Rxe1+",
            "Qxe1",
            "Bc6",
            "Nb3",
            "Qf4",
            "Be3",
            "Qf6",
            "Rd1",
            "Re8",
            "Nd4",
            "Bb7",
            "b3",
            "Nxe3",
            "fxe3",
            "Qg5",
            "Qf2",
            "Rxe3",
            "Nf5",
            "Re8",
            "Nd6",
            "Re7",
            "Nxb7",
            "Rxb7",
            "Qf5",
            "Qe3+",
            "Kh1",
            "g6",
            "Qc8+",
            "Kg7",
            "Qxb7",
            "Qe2",
            "Qe4",
            "Qh5",
            "Qd4+",
            "Kh6",
            "Qf4+",
            "Kg7",
            "Rd7",
            "g5",
            "Qe5+",
            "Kh6",
            "Qf6+",
            "Qg6",
            "Bxg6",
            "hxg6",
            "Qh8#",
            "Nf6",
            "Qxf6",
            "Qxf6",
            "Kh5",
            "Qh8#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 180,
            "completion_tokens": 470,
            "total_tokens": 650,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 179,
            "completion_tokens": 339,
            "total_tokens": 518,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 539,
          "total_completion_tokens": 1449,
          "total_tokens": 1988
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 180,
            "completion_tokens": 470,
            "total_tokens": 650,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 179,
            "completion_tokens": 339,
            "total_tokens": 518,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2P2N2/PPBP1PPP/RNBQR1K1 w kq - 3 10"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxb4",
          "aggressive_uci": "c3b4",
          "aggressive_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Qxd5 19. Bb3 Nc4 20. Bxc4 Qxc4 21. dxc4 Bxb4 22. Rxe5 Rad8 23. Qb3 Bd6 24. c5+ Kh8 25. cxd6 cxd6 26. Re7 d5 27. Bg5 d4 28. Bxf6 gxf6 29. Qb7 d3 30. Rxh7+ Kg8 31. Qg7# e4 d3 Qxd3 Qxd3",
          "aggressive_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 175,
            "total_tokens": 370,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Qxd5",
            "Bb3",
            "Nc4",
            "Bxc4",
            "Qxc4",
            "dxc4",
            "Bxb4",
            "Rxe5",
            "Rad8",
            "Qb3",
            "Bd6",
            "c5+",
            "Kh8",
            "cxd6",
            "cxd6",
            "Re7",
            "d5",
            "Bg5",
            "d4",
            "Bxf6",
            "gxf6",
            "Qb7",
            "d3",
            "Rxh7+",
            "Kg8",
            "Qg7#",
            "e4",
            "d3",
            "Qxd3",
            "Qxd3"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "cxb4",
          "positional_uci": "c3b4",
          "positional_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Nfxd5 19. Rxe5 Nxb4 20. Bb3+ Kh8 21. Qe2 Bf6 22. Re4 Nxd3 23. Be3 Nxb2 24. Rb1 Nd3 25. Rd1 Re8 26. Rxd3 Qc8 27. Bxb6 cxb6 28. Rxe8+ Qxe8 29. Qxe8+ Rxe8 30. Rd6 Rb8 31. Ne4 Be5 32. Re6 Bd4 33. Nd6 h6 34. Re8+ Rxe8 35. Nxe8 Be5 36. g3 g5 37. Kg2 Kh7 38. Kf3 Kg6 39. Ke4 Bb8 40. Kd5 Kf7 41. Nd6+ Ke7 42. Nf5+ Kf6 43. Nd4 Be5 44. Nc6 Bc7 45. Nb4 a5 46. Na6 Bd8 47. Kc6 Ke5 48. Nc7 Kd4 49. Ne6+ Kc3 50. Nxd8 Kb4 51. Kxb6 a4 52. Bxa4 Kxa4 53. Ne6 Ka3 54. Nxg7 Kxa2 55. Nf5 Kb3 56. Nxh6 Kc4 57. Nf7 Kd5 58. Nxg5 Ke5 59. h4 Kf5 60. f3 Kg6 61. g4 Kh6 62. f4 Kg6 63. h5+ Kh6 64. Nf7+ Kg7 65. Ne5 Kh6 66. f5 Kg5 67. Kc6 Kf6 68. Kd6 Kg5 69. Ke6 Kh6 70. f6 Kh7 71. f7 Kg7 72. Ke7 Kh7 73. f8=Q *",
          "positional_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 502,
            "total_tokens": 697,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Re8",
            "Rxd3",
            "Qc8",
            "Bxb6",
            "cxb6",
            "Rxe8+",
            "Qxe8",
            "Qxe8+",
            "Rxe8",
            "Rd6",
            "Rb8",
            "Ne4",
            "Be5",
            "Re6",
            "Bd4",
            "Nd6",
            "h6",
            "Re8+",
            "Rxe8",
            "Nxe8",
            "Be5",
            "g3",
            "g5",
            "Kg2",
            "Kh7",
            "Kf3",
            "Kg6",
            "Ke4",
            "Bb8",
            "Kd5",
            "Kf7",
            "Nd6+",
            "Ke7",
            "Nf5+",
            "Kf6",
            "Nd4",
            "Be5",
            "Nc6",
            "Bc7",
            "Nb4",
            "a5",
            "Na6",
            "Bd8",
            "Kc6",
            "Ke5",
            "Nc7",
            "Kd4",
            "Ne6+",
            "Kc3",
            "Nxd8",
            "Kb4",
            "Kxb6",
            "a4",
            "Bxa4",
            "Kxa4",
            "Ne6",
            "Ka3",
            "Nxg7",
            "Kxa2",
            "Nf5",
            "Kb3",
            "Nxh6",
            "Kc4",
            "Nf7",
            "Kd5",
            "Nxg5",
            "Ke5",
            "h4",
            "Kf5",
            "f3",
            "Kg6",
            "g4",
            "Kh6",
            "f4",
            "Kg6",
            "h5+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Ne5",
            "Kh6",
            "f5",
            "Kg5",
            "Kc6",
            "Kf6",
            "Kd6",
            "Kg5",
            "Ke6",
            "Kh6",
            "f6",
            "Kh7",
            "f7",
            "Kg7",
            "Ke7",
            "Kh7",
            "f8=Q"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "query3": {
          "neutral_move": "cxb4",
          "neutral_uci": "c3b4",
          "neutral_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Nfxd5 19. Rxe5 Nxb4 20. Bb3+ Kh8 21. Qe2 Bf6 22. Re4 Nxd3 23. Be3 Nxb2 24. Rb1 Nd3 25. Rd1 Nc5 26. Rxd8 Raxd8 27. Bxc5 Nd7 28. Bxf8 Rxf8 29. Re8 h6 30. Rxf8+ Nxf8 31. Qe8 Kh7 32. Qxf8 g5 33. Bc2+ g6 34. Qf7+ Bg7 35. Bxg6+ Kh8 36. Qe8+ Bf8 37. Qxf8# e4 Nc6 Nc4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 N",
          "neutral_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Nc5",
            "Rxd8",
            "Raxd8",
            "Bxc5",
            "Nd7",
            "Bxf8",
            "Rxf8",
            "Re8",
            "h6",
            "Rxf8+",
            "Nxf8",
            "Qe8",
            "Kh7",
            "Qxf8",
            "g5",
            "Bc2+",
            "g6",
            "Qf7+",
            "Bg7",
            "Bxg6+",
            "Kh8",
            "Qe8+",
            "Bf8",
            "Qxf8#",
            "e4",
            "Nc6",
            "Nc4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c3b4",
          "positional_uci": "c3b4",
          "neutral_uci": "c3b4",
          "consensus_move": "c3b4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "exd5",
              "Qxd5",
              "Bb3",
              "Nc4",
              "Bxc4",
              "Qxc4",
              "dxc4",
              "Bxb4",
              "Rxe5",
              "Rad8",
              "Qb3",
              "Bd6",
              "c5+",
              "Kh8",
              "cxd6",
              "cxd6",
              "Re7",
              "d5",
              "Bg5",
              "d4",
              "Bxf6",
              "gxf6",
              "Qb7",
              "d3",
              "Rxh7+",
              "Kg8",
              "Qg7#",
              "e4",
              "d3",
              "Qxd3",
              "Qxd3"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "exd5",
              "Nfxd5",
              "Rxe5",
              "Nxb4",
              "Bb3+",
              "Kh8",
              "Qe2",
              "Bf6",
              "Re4",
              "Nxd3",
              "Be3",
              "Nxb2",
              "Rb1",
              "Nd3",
              "Rd1",
              "Re8",
              "Rxd3",
              "Qc8",
              "Bxb6",
              "cxb6",
              "Rxe8+",
              "Qxe8",
              "Qxe8+",
              "Rxe8",
              "Rd6",
              "Rb8",
              "Ne4",
              "Be5",
              "Re6",
              "Bd4",
              "Nd6",
              "h6",
              "Re8+",
              "Rxe8",
              "Nxe8",
              "Be5",
              "g3",
              "g5",
              "Kg2",
              "Kh7",
              "Kf3",
              "Kg6",
              "Ke4",
              "Bb8",
              "Kd5",
              "Kf7",
              "Nd6+",
              "Ke7",
              "Nf5+",
              "Kf6",
              "Nd4",
              "Be5",
              "Nc6",
              "Bc7",
              "Nb4",
              "a5",
              "Na6",
              "Bd8",
              "Kc6",
              "Ke5",
              "Nc7",
              "Kd4",
              "Ne6+",
              "Kc3",
              "Nxd8",
              "Kb4",
              "Kxb6",
              "a4",
              "Bxa4",
              "Kxa4",
              "Ne6",
              "Ka3",
              "Nxg7",
              "Kxa2",
              "Nf5",
              "Kb3",
              "Nxh6",
              "Kc4",
              "Nf7",
              "Kd5",
              "Nxg5",
              "Ke5",
              "h4",
              "Kf5",
              "f3",
              "Kg6",
              "g4",
              "Kh6",
              "f4",
              "Kg6",
              "h5+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Ne5",
              "Kh6",
              "f5",
              "Kg5",
              "Kc6",
              "Kf6",
              "Kd6",
              "Kg5",
              "Ke6",
              "Kh6",
              "f6",
              "Kh7",
              "f7",
              "Kg7",
              "Ke7",
              "Kh7",
              "f8=Q"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "exd5",
              "Nfxd5",
              "Rxe5",
              "Nxb4",
              "Bb3+",
              "Kh8",
              "Qe2",
              "Bf6",
              "Re4",
              "Nxd3",
              "Be3",
              "Nxb2",
              "Rb1",
              "Nd3",
              "Rd1",
              "Nc5",
              "Rxd8",
              "Raxd8",
              "Bxc5",
              "Nd7",
              "Bxf8",
              "Rxf8",
              "Re8",
              "h6",
              "Rxf8+",
              "Nxf8",
              "Qe8",
              "Kh7",
              "Qxf8",
              "g5",
              "Bc2+",
              "g6",
              "Qf7+",
              "Bg7",
              "Bxg6+",
              "Kh8",
              "Qe8+",
              "Bf8",
              "Qxf8#",
              "e4",
              "Nc6",
              "Nc4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "Nf1",
            "Bg4"
          ],
          "full_moves": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Nc5",
            "Rxd8",
            "Raxd8",
            "Bxc5",
            "Nd7",
            "Bxf8",
            "Rxf8",
            "Re8",
            "h6",
            "Rxf8+",
            "Nxf8",
            "Qe8",
            "Kh7",
            "Qxf8",
            "g5",
            "Bc2+",
            "g6",
            "Qf7+",
            "Bg7",
            "Bxg6+",
            "Kh8",
            "Qe8+",
            "Bf8",
            "Qxf8#",
            "e4",
            "Nc6",
            "Nc4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 195,
            "completion_tokens": 175,
            "total_tokens": 370,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 195,
            "completion_tokens": 502,
            "total_tokens": 697,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 584,
          "total_completion_tokens": 1317,
          "total_tokens": 1901
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 195,
            "completion_tokens": 175,
            "total_tokens": 370,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 195,
            "completion_tokens": 502,
            "total_tokens": 697,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/pn1p1n2/4p3/1p2P3/2PP1N2/PPBN1PPP/R1BQR1K1 w kq - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "bxa5",
          "aggressive_uci": "b4a5",
          "aggressive_response": "13. bxa5 Rxa5 14. b4 Ra8 15. a4 O-O 16. a5 Nbd7 17. d4 exd4 18. Nxd4 Bb7 19. Nf5 Re8 20. Nxe7+ Qxe7 21. Bb2 Ne5 22. f4 Nc6 23. Bc3 Ba6 24. Ba4 Bb7 25. b5 Nxa5 26. Bxa5 Rxa5 27. b6 c6 28. Nc4 Rc5 29. Nxd6 Rd8 30. e5 Nd5 31. Qd4 Ra5 32. Bxc6 Rxa1 33. Rxa1 Bxc6 34. Ra7 Qh4 35. g3 Qh3 36. b7 Ne3 37. Kf2 Ng4+ 38. Ke1 Nxh2 39. Qf2 Nf3+ 40. Ke2 Qh1 41. Ra8 Rxa8 42. bxa8=Q+ Bxa8 43. Qa7 Qe1+ 44. Kd3 Qd2+ 45. Kc4 Qd5+ 46. Kc3 h6 47. Qb8+ Kh7 48. Qb1+ g6 49. Qb8 Qd4+ 50. Kc2 Be4+ 51. Nxe4 Qxe4+ 52. Kc3 Qe3+ 53. Kc4 Qd4+ 54. Kb3 Nd2+ 55. Kc2 Ne4 56. Qc7 Qd2+ 57. Kb3 Qd5+ 58. Kb2 Nxg3 59. Qc3 Ne4 60. Qc7 Qd2+ 61. Kb3 Qd3+ 62. Kb2 Qb5+ 63. Kc2 Qc5+ 64. Qxc5 Nxc5 65. Kd2 h5 66. Ke3 Kh6 67. Kf3 g5 68. fxg5+ Kxg5 69. Kg3 Nd3 70. Kh3 Nxe5 71. Kg3 h4+ 72. Kh3 f5 73. Kg2 Kg4 74. Kh2 h3 75. Kg1 Kg3 76. Kh1 Ng4 77. Kg1 h2+ 78. Kh1 Nf2# 0-1 e4 Nf6 Bb5 a6 Ba4 Nc6 Nf3 Be7 Re1 b5 c3 Na5 Bc2 Nc4 d3 Nb6 Nbd2 b4 cxb4 a5 bxa5 Rxa5 b3 Ra8 a5 O-O a6 Nbd7 d4 exd4 Nxd4",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxa5",
            "b3",
            "Ra8",
            "a5",
            "O-O",
            "a6",
            "Nbd7",
            "d4",
            "exd4",
            "Nxd4"
          ],
          "plan_execute": [
            "Rxa5",
            "b3",
            "Ra8"
          ]
        },
        "query2": {
          "positional_move": "bxa5",
          "positional_uci": "b4a5",
          "positional_response": "13. bxa5 Rxa5 14. Nb3 Ra8 15. d4 exd4 16. Nbxd4 Bb7 17. Nf5 O-O 18. Bg5 h6 19. Bh4 g5 20. Nxh6+ Kg7 21. Bxg5 Nh7 22. Nf5+ Kg6 23. Bxe7 Qd7 24. N3h4# e4 Nxe7 Nxe7+ Kh8 Qd4+ Kg8 Qg5+ Kh8 Qg7# e5 Nxe5 Nxe5+ Kh8 Qg7# e6 Nxe6 Nxe6+ Kh8 Qg7# e7 Nxe7 Nxe7+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxh6+",
            "Kg7",
            "Bxg5",
            "Nh7",
            "Nf5+",
            "Kg6",
            "Bxe7",
            "Qd7",
            "N3h4#",
            "e4",
            "Nxe7",
            "Nxe7+",
            "Kh8",
            "Qd4+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qg7#",
            "e5",
            "Nxe5",
            "Nxe5+",
            "Kh8",
            "Qg7#",
            "e6",
            "Nxe6",
            "Nxe6+",
            "Kh8",
            "Qg7#",
            "e7",
            "Nxe7",
            "Nxe7+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8"
          ],
          "plan_execute": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ]
        },
        "query3": {
          "neutral_move": "bxa5",
          "neutral_uci": "b4a5",
          "neutral_response": "13. bxa5 Rxa5 14. Nb3 Ra8 15. d4 exd4 16. Nbxd4 Bb7 17. Nf5 O-O 18. Nxe7+ Qxe7 19. e5 dxe5 20. Nxe5 Qc5 21. Bg5 Nfd5 22. Qd3 g6 23. Bh6 Rfe8 24. Qf3 f5 25. Bxf5 gxf5 26. Qg3+ Kh8 27. Qg7# Nf6 28. Nf7# Kg8 29. Qxf6 Qf8 30. Bxf8 Rxf8 31. Nh6# Kh8 32. Qe5# Kh8 33. Qxc7# Kh8 34. Qxb7# Kh8 35. Qxb6# Kh8 36. Qd4# Kh8 37. Re7# Kh8 38. Qg7# Kh8 39. Qxh7# Kh8 40. Qg7# Kh8 41. Qxf8# Kh8 42. Qg7# Kh8 43. Qxf8# Kh8 44. Qg7# Kh8 45. Qxf8# Kh8 46. Qg7# Kh8 47. Qxf8# Kh8 48. Qg7# Kh8 49. Qxf8# Kh8 50. Qg7# Kh8 51. Qxf8# Kh8 52. Qg7# Kh8 53. Qxf8# Kh8 54. Qg7# Kh8 55. Qxf8# Kh8 56. Qg7# Kh8 57. Qxf8# Kh8 58. Qg7# Kh8 59. Qxf8# Kh8 60. Qg7# Kh8 61. Qxf8# Kh8 62. Qg7# Kh8 63. Qxf8# Kh8 64. Qg7# Kh8 65. Qxf8# Kh8 66. Qg7# Kh8 67. Qxf8# Kh8 68. Qg7# Kh8 69. Qxf8# Kh8 70. Qg7# Kh8 71. Qxf8# Kh8 72. Qg7# Kh8 73. Qxf8# Kh8 74. Qg7# Kh8 75. Qxf8# Kh8 76. Qg7# Kh8 77. Qxf8# Kh8 78. Qg7# Kh8 79. Qxf8# Kh8 80. Qg7# Kh8 81. Qxf8# Kh8 82. Qg7# Kh8 83. Qxf8# Kh8 84. Qg7# Kh",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 640,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Nxe7+",
            "Qxe7",
            "e5",
            "dxe5",
            "Nxe5",
            "Qc5",
            "Bg5",
            "Nfd5",
            "Qd3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qf3",
            "f5",
            "Bxf5",
            "gxf5",
            "Qg3+",
            "Kh8",
            "Qg7#",
            "Nf6",
            "Nf7#",
            "Kg8",
            "Qxf6",
            "Qf8",
            "Bxf8",
            "Rxf8",
            "Nh6#",
            "Kh8",
            "Qe5#",
            "Kh8",
            "Qxc7#",
            "Kh8",
            "Qxb7#",
            "Kh8",
            "Qxb6#",
            "Kh8",
            "Qd4#",
            "Kh8",
            "Re7#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxh7#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#"
          ],
          "plan_execute": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b4a5",
          "positional_uci": "b4a5",
          "neutral_uci": "b4a5",
          "consensus_move": "b4a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxa5",
              "b3",
              "Ra8",
              "a5",
              "O-O",
              "a6",
              "Nbd7",
              "d4",
              "exd4",
              "Nxd4"
            ],
            "execute": [
              "Rxa5",
              "b3",
              "Ra8"
            ]
          },
          "positional": {
            "full": [
              "Rxa5",
              "Nb3",
              "Ra8",
              "d4",
              "exd4",
              "Nbxd4",
              "Bb7",
              "Nf5",
              "O-O",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxh6+",
              "Kg7",
              "Bxg5",
              "Nh7",
              "Nf5+",
              "Kg6",
              "Bxe7",
              "Qd7",
              "N3h4#",
              "e4",
              "Nxe7",
              "Nxe7+",
              "Kh8",
              "Qd4+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qg7#",
              "e5",
              "Nxe5",
              "Nxe5+",
              "Kh8",
              "Qg7#",
              "e6",
              "Nxe6",
              "Nxe6+",
              "Kh8",
              "Qg7#",
              "e7",
              "Nxe7",
              "Nxe7+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8"
            ],
            "execute": [
              "Rxa5",
              "Nb3",
              "Ra8"
            ]
          },
          "neutral": {
            "full": [
              "Rxa5",
              "Nb3",
              "Ra8",
              "d4",
              "exd4",
              "Nbxd4",
              "Bb7",
              "Nf5",
              "O-O",
              "Nxe7+",
              "Qxe7",
              "e5",
              "dxe5",
              "Nxe5",
              "Qc5",
              "Bg5",
              "Nfd5",
              "Qd3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qf3",
              "f5",
              "Bxf5",
              "gxf5",
              "Qg3+",
              "Kh8",
              "Qg7#",
              "Nf6",
              "Nf7#",
              "Kg8",
              "Qxf6",
              "Qf8",
              "Bxf8",
              "Rxf8",
              "Nh6#",
              "Kh8",
              "Qe5#",
              "Kh8",
              "Qxc7#",
              "Kh8",
              "Qxb7#",
              "Kh8",
              "Qxb6#",
              "Kh8",
              "Qd4#",
              "Kh8",
              "Re7#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxh7#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#"
            ],
            "execute": [
              "Rxa5",
              "Nb3",
              "Ra8"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ],
          "full_moves": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Nxe7+",
            "Qxe7",
            "e5",
            "dxe5",
            "Nxe5",
            "Qc5",
            "Bg5",
            "Nfd5",
            "Qd3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qf3",
            "f5",
            "Bxf5",
            "gxf5",
            "Qg3+",
            "Kh8",
            "Qg7#",
            "Nf6",
            "Nf7#",
            "Kg8",
            "Qxf6",
            "Qf8",
            "Bxf8",
            "Rxf8",
            "Nh6#",
            "Kh8",
            "Qe5#",
            "Kh8",
            "Qxc7#",
            "Kh8",
            "Qxb7#",
            "Kh8",
            "Qxb6#",
            "Kh8",
            "Qd4#",
            "Kh8",
            "Re7#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxh7#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 640,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 1920,
          "total_tokens": 2528
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 640,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/p3p3/1P2P3/3P1N2/PPBN1PPP/R1BQR1K1 w kq - 0 13"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bf7\n39. Rxb5 Bxa2 40. Ra5 Bb3 41. Nd2 Nc6 42. Ra6 Nb4\n43. Ra7+ Kg6 44. Bc4 Bxc4 45. Nxc4 Nd3 46. Rxa4 Rc8\n47. b3 Nc5 48. Rb4 Nxe4 49. Nxe5+ Kf5 50. Nc4 Rd8\n51. Ne3+ Ke5 52. Rb5+ Ke6 53. Rb6+ Ke5 54. Ng4+ Kf5\n55. f3 Rd1+ 56. Kh2 Nd6 57. Ne3+ Ke5 58. Nxd1 1-0\n58... Kd5 59. Rxd6+ Kxd6 60. Kg3 Kc5",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 498,
            "total_tokens": 612,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bf7",
            "Rxb5",
            "Bxa2",
            "Ra5",
            "Bb3",
            "Nd2",
            "Nc6",
            "Ra6",
            "Nb4",
            "Ra7+",
            "Kg6",
            "Bc4",
            "Bxc4",
            "Nxc4",
            "Nd3",
            "Rxa4",
            "Rc8",
            "b3",
            "Nc5",
            "Rb4",
            "Nxe4",
            "Nxe5+",
            "Kf5",
            "Nc4",
            "Rd8",
            "Ne3+",
            "Ke5",
            "Rb5+",
            "Ke6",
            "Rb6+",
            "Ke5",
            "Ng4+",
            "Kf5",
            "f3",
            "Rd1+",
            "Kh2",
            "Nd6",
            "Ne3+",
            "Ke5",
            "Nxd1",
            "Kd5",
            "Rxd6+",
            "Kxd6",
            "Kg3",
            "Kc5"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bb5"
          ]
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6\n5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6\n13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8\n17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4\n25. Ra8 Bb8 26. Rea1 Rg6 27. R1a6 Be6 28. Qxg6 Qxg6+\n29. Kf1 Qd3+ 30. Ke1 Bg4 31. f3 Qxe3+ 32. Kd1 Bxf3+\n33. Nxf3 Qxf3+ 34. Kc2 Qe2+ 35. Kb3 Qc4+ 36. Ka3 b4+\n37. cxb4 Qxa6+ 38. Rxa6 Bxh2 39. b5 h5 40. b6 h4\n41. b7 h3 42. Ra8 Bb8 43. Ra5 h2 44. Rh5 g6\n45. Rh3 Kg7 46. Kb4 Rh8 47. Rxh8 Kxh8 48. Kc5 h1=Q\n49. d5 Qc1+ 50. Kb6 Qxb2+ 51. Kc6 Qc3+ 52. Kd7 Qc7+\n53. Ke8 Kg7 54. d6 Qxd6 55. b4 Qe6+ 56. Kd8 Qd6+ 57. Ke8 Qc6+ 58. Kd8 Qxb7 59. b5 Qc7+ 60. Ke8 Qc8+ 61. Ke7 Qe6+ 62. Kd8 Qd6+ 63. Ke8 Qe6+ 64. Kd8 Qd6+ 65. Ke8 Qe6+ 66. Kd8 Qd6+ 67. Ke8 Qe6+ 68. Kd8 Qd6+ 69. Ke8 Qe6+ 70. Kd8 Qd6+ 71. Ke8 Qe6+ 72. Kd8 Qd6+ 73. Ke8 Qe6+ 74. Kd8 Q",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Rea1",
            "Rg6",
            "R1a6",
            "Be6",
            "Qxg6",
            "Qxg6+",
            "Kf1",
            "Qd3+",
            "Ke1",
            "Bg4",
            "f3",
            "Qxe3+",
            "Kd1",
            "Bxf3+",
            "Nxf3",
            "Qxf3+",
            "Kc2",
            "Qe2+",
            "Kb3",
            "Qc4+",
            "Ka3",
            "b4+",
            "cxb4",
            "Qxa6+",
            "Rxa6",
            "Bxh2",
            "b5",
            "h5",
            "b6",
            "h4",
            "b7",
            "h3",
            "Ra8",
            "Bb8",
            "Ra5",
            "h2",
            "Rh5",
            "g6",
            "Rh3",
            "Kg7",
            "Kb4",
            "Rh8",
            "Rxh8",
            "Kxh8",
            "Kc5",
            "h1=Q",
            "d5",
            "Qc1+",
            "Kb6",
            "Qxb2+",
            "Kc6",
            "Qc3+",
            "Kd7",
            "Qc7+",
            "Ke8",
            "Kg7",
            "d6",
            "Qxd6",
            "b4",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qc6+",
            "Kd8",
            "Qxb7",
            "b5",
            "Qc7+",
            "Ke8",
            "Qc8+",
            "Ke7",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bb5"
          ]
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6\n39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6\n43. Nd2 Kc5 44. a3 Bd7 45. Nb1 Nc6 46. Nc3 Nd4\n47. Nd5 f5 48. Nf6 f4+ 49. Kd2 Be6 50. Nxh7 b4\n51. Ng5 Bg8 52. h4 bxa3 53. bxa3 Nb3+ 54. Kc3 Nd4\n55. h5 Nb5+ 56. Bxb5 Kxb5 57. h6 Kc5 58. h7 Bxh7\n59. Nxh7 Kd6 60. Ng5 Kc5 61. Nf3 Kd6 62. Kb4 Ke6\n63. Kxa4 Kd6 64. Kb5 Ke6 65. a4 Kd6 66. a5 Ke6\n67. a6 Kd6 68. a7 Ke6 69. a8=Q Kd6 70. Qd5+ Ke7\n71. Qxe5+ Kd7 72. Qxf4 Ke6 73. Qf5+ Kd6 74. Qd5+ Ke7\n75. Qc6 Kf7 76. Qd6 Kg7 77. Qe6 Kh7 78. Qf6 Kg8",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Nc6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "Kd2",
            "Be6",
            "Nxh7",
            "b4",
            "Ng5",
            "Bg8",
            "h4",
            "bxa3",
            "bxa3",
            "Nb3+",
            "Kc3",
            "Nd4",
            "h5",
            "Nb5+",
            "Bxb5",
            "Kxb5",
            "h6",
            "Kc5",
            "h7",
            "Bxh7",
            "Nxh7",
            "Kd6",
            "Ng5",
            "Kc5",
            "Nf3",
            "Kd6",
            "Kb4",
            "Ke6",
            "Kxa4",
            "Kd6",
            "Kb5",
            "Ke6",
            "a4",
            "Kd6",
            "a5",
            "Ke6",
            "a6",
            "Kd6",
            "a7",
            "Ke6",
            "a8=Q",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qxe5+",
            "Kd7",
            "Qxf4",
            "Ke6",
            "Qf5+",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qc6",
            "Kf7",
            "Qd6",
            "Kg7",
            "Qe6",
            "Kh7",
            "Qf6",
            "Kg8"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bb5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bf7",
              "Rxb5",
              "Bxa2",
              "Ra5",
              "Bb3",
              "Nd2",
              "Nc6",
              "Ra6",
              "Nb4",
              "Ra7+",
              "Kg6",
              "Bc4",
              "Bxc4",
              "Nxc4",
              "Nd3",
              "Rxa4",
              "Rc8",
              "b3",
              "Nc5",
              "Rb4",
              "Nxe4",
              "Nxe5+",
              "Kf5",
              "Nc4",
              "Rd8",
              "Ne3+",
              "Ke5",
              "Rb5+",
              "Ke6",
              "Rb6+",
              "Ke5",
              "Ng4+",
              "Kf5",
              "f3",
              "Rd1+",
              "Kh2",
              "Nd6",
              "Ne3+",
              "Ke5",
              "Nxd1",
              "Kd5",
              "Rxd6+",
              "Kxd6",
              "Kg3",
              "Kc5"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bb5"
            ]
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Rea1",
              "Rg6",
              "R1a6",
              "Be6",
              "Qxg6",
              "Qxg6+",
              "Kf1",
              "Qd3+",
              "Ke1",
              "Bg4",
              "f3",
              "Qxe3+",
              "Kd1",
              "Bxf3+",
              "Nxf3",
              "Qxf3+",
              "Kc2",
              "Qe2+",
              "Kb3",
              "Qc4+",
              "Ka3",
              "b4+",
              "cxb4",
              "Qxa6+",
              "Rxa6",
              "Bxh2",
              "b5",
              "h5",
              "b6",
              "h4",
              "b7",
              "h3",
              "Ra8",
              "Bb8",
              "Ra5",
              "h2",
              "Rh5",
              "g6",
              "Rh3",
              "Kg7",
              "Kb4",
              "Rh8",
              "Rxh8",
              "Kxh8",
              "Kc5",
              "h1=Q",
              "d5",
              "Qc1+",
              "Kb6",
              "Qxb2+",
              "Kc6",
              "Qc3+",
              "Kd7",
              "Qc7+",
              "Ke8",
              "Kg7",
              "d6",
              "Qxd6",
              "b4",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qc6+",
              "Kd8",
              "Qxb7",
              "b5",
              "Qc7+",
              "Ke8",
              "Qc8+",
              "Ke7",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bb5"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Bd7",
              "Nb1",
              "Nc6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "f4+",
              "Kd2",
              "Be6",
              "Nxh7",
              "b4",
              "Ng5",
              "Bg8",
              "h4",
              "bxa3",
              "bxa3",
              "Nb3+",
              "Kc3",
              "Nd4",
              "h5",
              "Nb5+",
              "Bxb5",
              "Kxb5",
              "h6",
              "Kc5",
              "h7",
              "Bxh7",
              "Nxh7",
              "Kd6",
              "Ng5",
              "Kc5",
              "Nf3",
              "Kd6",
              "Kb4",
              "Ke6",
              "Kxa4",
              "Kd6",
              "Kb5",
              "Ke6",
              "a4",
              "Kd6",
              "a5",
              "Ke6",
              "a6",
              "Kd6",
              "a7",
              "Ke6",
              "a8=Q",
              "Kd6",
              "Qd5+",
              "Ke7",
              "Qxe5+",
              "Kd7",
              "Qxf4",
              "Ke6",
              "Qf5+",
              "Kd6",
              "Qd5+",
              "Ke7",
              "Qc6",
              "Kf7",
              "Qd6",
              "Kg7",
              "Qe6",
              "Kh7",
              "Qf6",
              "Kg8"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bb5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf3",
            "Nc6",
            "Bb5"
          ],
          "full_moves": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Nc6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "Kd2",
            "Be6",
            "Nxh7",
            "b4",
            "Ng5",
            "Bg8",
            "h4",
            "bxa3",
            "bxa3",
            "Nb3+",
            "Kc3",
            "Nd4",
            "h5",
            "Nb5+",
            "Bxb5",
            "Kxb5",
            "h6",
            "Kc5",
            "h7",
            "Bxh7",
            "Nxh7",
            "Kd6",
            "Ng5",
            "Kc5",
            "Nf3",
            "Kd6",
            "Kb4",
            "Ke6",
            "Kxa4",
            "Kd6",
            "Kb5",
            "Ke6",
            "a4",
            "Kd6",
            "a5",
            "Ke6",
            "a6",
            "Kd6",
            "a7",
            "Ke6",
            "a8=Q",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qxe5+",
            "Kd7",
            "Qxf4",
            "Ke6",
            "Qf5+",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qc6",
            "Kf7",
            "Qd6",
            "Kg7",
            "Qe6",
            "Kh7",
            "Qf6",
            "Kg8"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 498,
            "total_tokens": 612,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1778,
          "total_tokens": 2119
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 498,
            "total_tokens": 612,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1\nRg6 27. Bf4 Rxe1+ 28. Nf1 Bf3 29. Rxb8+ Re8 30. Rxe8# e5 dxe5 Bxg2+ Kxg2\nQg4+ Ng3 exf4 Rxe8+ Kxe8 Nxf4 Qxf4 Kg1 Qc1+ Kg2 Qxb2 Kg3 Qxc3+ Kg2 Qxd4 Kg3 b4 Kg2 b3 Kg3 b2 Kg2 b1=Q Kg3 Qg6+ Kf3 Qde4#",
          "aggressive_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 328,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "e5",
            "dxe5",
            "Bxg2+",
            "Kxg2",
            "Qg4+",
            "Ng3",
            "exf4",
            "Rxe8+",
            "Kxe8",
            "Nxf4",
            "Qxf4",
            "Kg1",
            "Qc1+",
            "Kg2",
            "Qxb2",
            "Kg3",
            "Qxc3+",
            "Kg2",
            "Qxd4",
            "Kg3",
            "b4",
            "Kg2",
            "b3",
            "Kg3",
            "b2",
            "Kg2",
            "b1=Q",
            "Kg3",
            "Qg6+",
            "Kf3",
            "Qde4#"
          ],
          "plan_execute": [
            "Bb5",
            "a6",
            "Ba4"
          ]
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1\nRg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+\n32. Kf1 Qd1# e5 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d5 exd5 Nxd5 Nxe5 Nxe5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Re6 Qf1 Qh5 a4 Rfe8 axb5 axb5 Bxd5 Qxd5 Qg2 Qh5 Qxc6 Bxg3 Qg2 Bf4 Bxf4 Rxe1+ Nf1 Rxf1+ Qxf1 Bf3 Bg3 Bb7 Qd3 Qd5 f3 Qxf3 Qxf3 Bxf3 Kf2 Bd5 Bd6 f6 Bc5 Kf7 Bd6 Ke6 Bc5 Kf5 Bd6 Ke4 Bc5 g6 Bd6 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3",
          "positional_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Bxf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3",
            "Bg3",
            "Bb7",
            "Qd3",
            "Qd5",
            "f3",
            "Qxf3",
            "Qxf3",
            "Bxf3",
            "Kf2",
            "Bd5",
            "Bd6",
            "f6",
            "Bc5",
            "Kf7",
            "Bd6",
            "Ke6",
            "Bc5",
            "Kf5",
            "Bd6",
            "Ke4",
            "Bc5",
            "g6",
            "Bd6",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3"
          ],
          "plan_execute": [
            "Bb5",
            "a6",
            "Ba4"
          ]
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bc7 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qf3 Bg4 26. Qh1 Bb8 27. Rxe6 Rxe6 28. Qb7 Re8 29. Qc6 f6 30. f3 Bh3 31. Bf2 Rxe1+ 32. Bxe1 h6 33. g4 Bxg4 34. fxg4 Qxg4+ 35. Qg2 Qd1 36. Qd5+ Kh7 37. Qe4+ Kg8 38. Qe8+ Kh7 39. Qxb8 Qxe1+ 40. Nf1 Qe2 41. Qg3 Qxb2 42. Qd3+ Kg8 43. d5 b4 44. cxb4 Qxb4 45. d6 Qb6+ 46. Ne3 Kf7 47. Qd5+ Ke8 48. Qe6+ Kd8 49. Qe7+ Kc8 50. d7+ Kb7 51. d8=Q+ Ka6 52. Qa3+ Kb5 53. Qd5+ Qc5 54. Qdxc5# Qxc5 55. Qxc5+ Kxc5 56. Nf5 g6 57. Nxh6 Kd5 58. Kf2 Ke4 59. Kg3 f5 60. h4 Ke5 61. Kf3 Kf6 62. Kf4 Kg7 63. Kg5 Kh7 64. Nf7 Kg7 65. Ne5 Kh7 66. Nxg6 Kg7 67. Kxf5 Kh6 68. Kg4 Kxg6 69. h5+ Kh6 70. Kh4 Kg7 71. Kg5 Kh7 72. h6 Kg8 73. Kg6 Kh8 74. h7 *",
          "neutral_tokens": {
            "prompt_tokens": 121,
            "completion_tokens": 609,
            "total_tokens": 730,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qh1",
            "Bb8",
            "Rxe6",
            "Rxe6",
            "Qb7",
            "Re8",
            "Qc6",
            "f6",
            "f3",
            "Bh3",
            "Bf2",
            "Rxe1+",
            "Bxe1",
            "h6",
            "g4",
            "Bxg4",
            "fxg4",
            "Qxg4+",
            "Qg2",
            "Qd1",
            "Qd5+",
            "Kh7",
            "Qe4+",
            "Kg8",
            "Qe8+",
            "Kh7",
            "Qxb8",
            "Qxe1+",
            "Nf1",
            "Qe2",
            "Qg3",
            "Qxb2",
            "Qd3+",
            "Kg8",
            "d5",
            "b4",
            "cxb4",
            "Qxb4",
            "d6",
            "Qb6+",
            "Ne3",
            "Kf7",
            "Qd5+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qe7+",
            "Kc8",
            "d7+",
            "Kb7",
            "d8=Q+",
            "Ka6",
            "Qa3+",
            "Kb5",
            "Qd5+",
            "Qc5",
            "Qdxc5#",
            "Qxc5",
            "Qxc5+",
            "Kxc5",
            "Nf5",
            "g6",
            "Nxh6",
            "Kd5",
            "Kf2",
            "Ke4",
            "Kg3",
            "f5",
            "h4",
            "Ke5",
            "Kf3",
            "Kf6",
            "Kf4",
            "Kg7",
            "Kg5",
            "Kh7",
            "Nf7",
            "Kg7",
            "Ne5",
            "Kh7",
            "Nxg6",
            "Kg7",
            "Kxf5",
            "Kh6",
            "Kg4",
            "Kxg6",
            "h5+",
            "Kh6",
            "Kh4",
            "Kg7",
            "Kg5",
            "Kh7",
            "h6",
            "Kg8",
            "Kg6",
            "Kh8",
            "h7"
          ],
          "plan_execute": [
            "Bb5",
            "a6",
            "Ba4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "e5",
              "dxe5",
              "Bxg2+",
              "Kxg2",
              "Qg4+",
              "Ng3",
              "exf4",
              "Rxe8+",
              "Kxe8",
              "Nxf4",
              "Qxf4",
              "Kg1",
              "Qc1+",
              "Kg2",
              "Qxb2",
              "Kg3",
              "Qxc3+",
              "Kg2",
              "Qxd4",
              "Kg3",
              "b4",
              "Kg2",
              "b3",
              "Kg3",
              "b2",
              "Kg2",
              "b1=Q",
              "Kg3",
              "Qg6+",
              "Kf3",
              "Qde4#"
            ],
            "execute": [
              "Bb5",
              "a6",
              "Ba4"
            ]
          },
          "positional": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Bxf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3",
              "Bg3",
              "Bb7",
              "Qd3",
              "Qd5",
              "f3",
              "Qxf3",
              "Qxf3",
              "Bxf3",
              "Kf2",
              "Bd5",
              "Bd6",
              "f6",
              "Bc5",
              "Kf7",
              "Bd6",
              "Ke6",
              "Bc5",
              "Kf5",
              "Bd6",
              "Ke4",
              "Bc5",
              "g6",
              "Bd6",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3"
            ],
            "execute": [
              "Bb5",
              "a6",
              "Ba4"
            ]
          },
          "neutral": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qh1",
              "Bb8",
              "Rxe6",
              "Rxe6",
              "Qb7",
              "Re8",
              "Qc6",
              "f6",
              "f3",
              "Bh3",
              "Bf2",
              "Rxe1+",
              "Bxe1",
              "h6",
              "g4",
              "Bxg4",
              "fxg4",
              "Qxg4+",
              "Qg2",
              "Qd1",
              "Qd5+",
              "Kh7",
              "Qe4+",
              "Kg8",
              "Qe8+",
              "Kh7",
              "Qxb8",
              "Qxe1+",
              "Nf1",
              "Qe2",
              "Qg3",
              "Qxb2",
              "Qd3+",
              "Kg8",
              "d5",
              "b4",
              "cxb4",
              "Qxb4",
              "d6",
              "Qb6+",
              "Ne3",
              "Kf7",
              "Qd5+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qe7+",
              "Kc8",
              "d7+",
              "Kb7",
              "d8=Q+",
              "Ka6",
              "Qa3+",
              "Kb5",
              "Qd5+",
              "Qc5",
              "Qdxc5#",
              "Qxc5",
              "Qxc5+",
              "Kxc5",
              "Nf5",
              "g6",
              "Nxh6",
              "Kd5",
              "Kf2",
              "Ke4",
              "Kg3",
              "f5",
              "h4",
              "Ke5",
              "Kf3",
              "Kf6",
              "Kf4",
              "Kg7",
              "Kg5",
              "Kh7",
              "Nf7",
              "Kg7",
              "Ne5",
              "Kh7",
              "Nxg6",
              "Kg7",
              "Kxf5",
              "Kh6",
              "Kg4",
              "Kxg6",
              "h5+",
              "Kh6",
              "Kh4",
              "Kg7",
              "Kg5",
              "Kh7",
              "h6",
              "Kg8",
              "Kg6",
              "Kh8",
              "h7"
            ],
            "execute": [
              "Bb5",
              "a6",
              "Ba4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bb5",
            "a6",
            "Ba4"
          ],
          "full_moves": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qh1",
            "Bb8",
            "Rxe6",
            "Rxe6",
            "Qb7",
            "Re8",
            "Qc6",
            "f6",
            "f3",
            "Bh3",
            "Bf2",
            "Rxe1+",
            "Bxe1",
            "h6",
            "g4",
            "Bxg4",
            "fxg4",
            "Qxg4+",
            "Qg2",
            "Qd1",
            "Qd5+",
            "Kh7",
            "Qe4+",
            "Kg8",
            "Qe8+",
            "Kh7",
            "Qxb8",
            "Qxe1+",
            "Nf1",
            "Qe2",
            "Qg3",
            "Qxb2",
            "Qd3+",
            "Kg8",
            "d5",
            "b4",
            "cxb4",
            "Qxb4",
            "d6",
            "Qb6+",
            "Ne3",
            "Kf7",
            "Qd5+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qe7+",
            "Kc8",
            "d7+",
            "Kb7",
            "d8=Q+",
            "Ka6",
            "Qa3+",
            "Kb5",
            "Qd5+",
            "Qc5",
            "Qdxc5#",
            "Qxc5",
            "Qxc5+",
            "Kxc5",
            "Nf5",
            "g6",
            "Nxh6",
            "Kd5",
            "Kf2",
            "Ke4",
            "Kg3",
            "f5",
            "h4",
            "Ke5",
            "Kf3",
            "Kf6",
            "Kf4",
            "Kg7",
            "Kg5",
            "Kh7",
            "Nf7",
            "Kg7",
            "Ne5",
            "Kh7",
            "Nxg6",
            "Kg7",
            "Kxf5",
            "Kh6",
            "Kg4",
            "Kxg6",
            "h5+",
            "Kh6",
            "Kh4",
            "Kg7",
            "Kg5",
            "Kh7",
            "h6",
            "Kg8",
            "Kg6",
            "Kh8",
            "h7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 122,
            "completion_tokens": 328,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 121,
            "completion_tokens": 609,
            "total_tokens": 730,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 365,
          "total_completion_tokens": 1577,
          "total_tokens": 1942
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 122,
            "completion_tokens": 328,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 121,
            "completion_tokens": 609,
            "total_tokens": 730,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5 22. c4 bxc4 23. Qxc4 Qh5\n24. Rxc6 Ba5 25. Rxe6 Bxe6 26. Qc5 Qxc5 27. dxc5 Rb8 28. Ra1 Bxd2\n29. Bxd2 Rxb2 30. Ra8+ 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6\n12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8\n17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5\n22. c4 bxc4 23. Qxc4 Qh5 24. Rxc6 Ba5 25. Rxe6 Bxe6 26. Qc5 Qxc5\n27. dxc5 Rb8 28. Ra1 Bxd2 29. Bxd2 Rxb2 30. Ra8+ 1-0 e5 d5 Nf6 Nc6 Bb4 a6 Ba4 b5 Bb3 Na5 O-O Nxb3 cxb3 Be7 Re1 O-O Nxe5 Nxe5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Re6 a4 Qh5 axb5 axb5 Ra6 Bc7 Bxd5 Qxd5 Qc4 Qh5 Rxc6 Ba5 Rxe6 Bxe6 Qc5 Qxc5 Nxc5 Bxb2 Nxb2 Bxb3 Re5 Bc4 Nxc4 bxc4 Rxc5 Rc8 Rxc8# 1-0",
          "aggressive_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 631,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "b5",
            "Bb3",
            "Na5",
            "O-O",
            "Nxb3",
            "cxb3",
            "Be7",
            "Re1",
            "O-O",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bxd5",
            "Qxd5",
            "Qc4",
            "Qh5",
            "Rxc6",
            "Ba5",
            "Rxe6",
            "Bxe6",
            "Qc5",
            "Qxc5",
            "Nxc5",
            "Bxb2",
            "Nxb2",
            "Bxb3",
            "Re5",
            "Bc4",
            "Nxc4",
            "bxc4",
            "Rxc5",
            "Rc8",
            "Rxc8#"
          ],
          "plan_execute": [
            "Ba4",
            "b5",
            "Bb3"
          ]
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5 22. c4 bxc4 23. Qxc4 Qh5\n24. Rxc6 Ba5 25. Rxe6 Bxe6 26. Qc5 Qxc5 27. dxc5 Rb8 28. Ra1 Bxd2\n29. Bxd2 Rxb2 30. Ra8+ 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6\n12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8\n17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5\n22. c4 bxc4 23. Qxc4 Qh5 24. Rxc6 Ba5 25. Rxe6 Bxe6 26. Qc5 Qxc5\n27. dxc5 Rb8 28. Ra1 Bxd2 29. Bxd2 Rxb2 30. Ra8+ 1-0 e5 d5 Nc3 Nf6 Bg5 Be7 O-O Be6 Re1 Qd7 Nbd2 O-O-O b4 Na5 a4 Nc4 Nxc4 Bxc4 Bxc4 dxc4 Qe2 Qe6 a5 Rd7 b6 cxb6 axb6 axb6 Ra8+ Kb7 Ra7+ Kc8 Ra8+ Kb7 Ra7+ Kc8 Ra8+ Kb7 Ra7+ Kc8 Ra8+ 1/2-1/2",
          "positional_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 589,
            "total_tokens": 720,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bxd5",
            "Qxd5",
            "c4",
            "bxc4",
            "Qxc4",
            "Qh5",
            "Rxc6",
            "Ba5",
            "Rxe6",
            "Bxe6",
            "Qc5",
            "Qxc5",
            "dxc5",
            "Rb8",
            "Ra1",
            "Bxd2",
            "Bxd2",
            "Rxb2",
            "Ra8+",
            "e5",
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "O-O",
            "Be6",
            "Re1",
            "Qd7",
            "Nbd2",
            "O-O-O",
            "b4",
            "Na5",
            "a4",
            "Nc4",
            "Nxc4",
            "Bxc4",
            "Bxc4",
            "dxc4",
            "Qe2",
            "Qe6",
            "a5",
            "Rd7",
            "b6",
            "cxb6",
            "axb6",
            "axb6",
            "Ra8+",
            "Kb7",
            "Ra7+",
            "Kc8",
            "Ra8+",
            "Kb7",
            "Ra7+",
            "Kc8",
            "Ra8+",
            "Kb7",
            "Ra7+",
            "Kc8",
            "Ra8+"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a7a6",
          "neutral_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bb8 21. Bd1 Bxd1 22. Qf1 Bg4 23. c4 bxc4\n24. Nxc4 Bh3 25. Qe2 Qxe2 26. Rxe2 Nb4 27. Rb6 Nd5 28. Ra6 Rfe8\n29. Ra3 Bg4 30. Re1 Bf3 31. Nd2 Bg4 32. Kg2 Bd6 33. Rb3 Bb4\n34. h3 Bxd2 35. Bxd2 Rxe1 36. Bxe1 Be6 37. Ra3 h6 38. Bd2 Rb8\n39. Bc1 Rb4 40. Rd3 Bf5 41. Rd1 Bc2 42. Rd2 Be4+ 43. f3 Bg6\n44. Kf2 Rc4 45. Rd1 Rc2+ 46. Kg1 Nb4 47. b3 Nd3 48. Be3 Re2\n49. Bf4 Nxf4 50. gxf4 Bc2 51. Rc1 Bxb3 52. Rxc6 Bd5 53. Rc3 Rd2\n54. Rc8+ Kh7 55. Rd8 Rxd4 56. Kf2 Rd3 57. Ke2 Bc4 58. Rxd3 Bxd3+\n59. Kxd3 Kg6 60. Ke4 Kh5 61. Kf5 Kh4 62. Ke5 Kxh3 63. f5 Kg3\n64. f4 h5 65. f6 gxf6+ 66. Kxf6 Kxf4 67. Kxf7 h4 68. Kg6 h3\n69. Kh5 h2 70. Kh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d5 exd5 Nxd5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Qh5 c4 bxc4 Nxc4 Bh3 c3 Nxc3 Nxc6 Bd5 Qf",
          "neutral_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Qh5",
            "c4",
            "bxc4",
            "Nxc4",
            "Bh3",
            "c3",
            "Nxc3",
            "Nxc6",
            "Bd5"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "a7a6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "b5",
              "Bb3",
              "Na5",
              "O-O",
              "Nxb3",
              "cxb3",
              "Be7",
              "Re1",
              "O-O",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bxd5",
              "Qxd5",
              "Qc4",
              "Qh5",
              "Rxc6",
              "Ba5",
              "Rxe6",
              "Bxe6",
              "Qc5",
              "Qxc5",
              "Nxc5",
              "Bxb2",
              "Nxb2",
              "Bxb3",
              "Re5",
              "Bc4",
              "Nxc4",
              "bxc4",
              "Rxc5",
              "Rc8",
              "Rxc8#"
            ],
            "execute": [
              "Ba4",
              "b5",
              "Bb3"
            ]
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bxd5",
              "Qxd5",
              "c4",
              "bxc4",
              "Qxc4",
              "Qh5",
              "Rxc6",
              "Ba5",
              "Rxe6",
              "Bxe6",
              "Qc5",
              "Qxc5",
              "dxc5",
              "Rb8",
              "Ra1",
              "Bxd2",
              "Bxd2",
              "Rxb2",
              "Ra8+",
              "e5",
              "d5",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "O-O",
              "Be6",
              "Re1",
              "Qd7",
              "Nbd2",
              "O-O-O",
              "b4",
              "Na5",
              "a4",
              "Nc4",
              "Nxc4",
              "Bxc4",
              "Bxc4",
              "dxc4",
              "Qe2",
              "Qe6",
              "a5",
              "Rd7",
              "b6",
              "cxb6",
              "axb6",
              "axb6",
              "Ra8+",
              "Kb7",
              "Ra7+",
              "Kc8",
              "Ra8+",
              "Kb7",
              "Ra7+",
              "Kc8",
              "Ra8+",
              "Kb7",
              "Ra7+",
              "Kc8",
              "Ra8+"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Qh5",
              "c4",
              "bxc4",
              "Nxc4",
              "Bh3",
              "c3",
              "Nxc3",
              "Nxc6",
              "Bd5"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Ba4",
            "Nf6",
            "O-O"
          ],
          "full_moves": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Qh5",
            "c4",
            "bxc4",
            "Nxc4",
            "Bh3",
            "c3",
            "Nxc3",
            "Nxc6",
            "Bd5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 131,
            "completion_tokens": 631,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 131,
            "completion_tokens": 589,
            "total_tokens": 720,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 392,
          "total_completion_tokens": 1860,
          "total_tokens": 2252
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 131,
            "completion_tokens": 631,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 131,
            "completion_tokens": 589,
            "total_tokens": 720,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "4... Nf6 5. O-O Nxe4 6. Re1 d5 7. Bb3 Bc5 8. d4 Nxd4 9. Nxd4 Bxd4 10. Be3 Bxb2 11. Bxd5 Nf6 12. Bg5 Qxd5 13. Bxf6 Qxd1 14. Rxd1 gxf6 15. Nd2 Bxa1 16. Rxa1 Be6 17. Ne4 Ke7 18. Nc5 b6 19. Ne4 Rad8 20. h3 Rd4 21. f3 Rhd8 22. Kh2 Rd1 23. Rxd1 Rxd1 24. a3 Ra1 25. Nc3 Rxa3 26. Ne4 Ra2 27. c3 Bd5 28. Ng3 Bxf3 29. Nf5+ Ke6 30. Ng7+ Kd5 31. Kg3 Bxg2 32. Nf5 Be4 33. Ne3+ Kc5 34. Ng4 Rg2+ 35. Kh4 Rxg4+ 36. hxg4 a5 37. Kh5 a4 38. Kh6 a3 39. Kg7 a2 40. Kxf6 a1=Q 41. Kxe5 Qxc3+ 42. Kxe4 Qd4+ 43. Kf5 Kd5 44. g5 Qe4+ 45. Kf6 Qe6+ 46. Kg7 Qg6+ 47. Kf8 Ke6 48. Ke8 Qg8# e4 Nf6+ Bxf6 exf6 gxf6 Kxf6 Kd5 Kc5 Kd4 Kc4 Kd3 Kc3 Kc2 Kc1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2",
          "aggressive_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxf6",
            "exf6",
            "gxf6",
            "Kxf6",
            "Kd5",
            "Kc5",
            "Kd4",
            "Kc4",
            "Kd3",
            "Kc3",
            "Kc2",
            "Kc1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2"
          ],
          "plan_execute": [
            "Bxf6",
            "exf6",
            "gxf6"
          ]
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "4... Nf6 5. d3 Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qf3 Nd4 20. Bxd4 Bxd4 21. c3 Ba7 22. g4 c6 23. gxh5 cxd5 24. cxd5 Qg8+ 25. Kh1 Qg5 26. Rg1 Qxh5 27. Qg3 Rag8 28. Rg2 Rxg3 29. fxg3 Qf3 30. Re1 Bf2 31. Rf1 Rxh2+ 32. Kxh2 Qh5# 33.# e4 e5 Nf3 Nc6 Bb5 a6 Bc4 Nf6 d3 Bc5 O-O O-O Nc3 d6 Bg5 h6 Bh4 g5 Nxg5 hxg5 Bxg5 Be6 Qf3 Kg7 Qg3 Nh5 Qh4 f6 Be3 Bxc4 dxc4 Rh8 Qg4+ Kf7 Nd5 Qc8 Qf3 Nd4 Bxd4 Bxd4 c3 Ba7 g4 c6 gxh5 cxd5 cxd5 Qg8+ Kh1 Qg5 Rg1 Qxh5 Qg3 Rag8 Rg2 Rxg3 fxg3 Qf3 Re1 Bf2 Rf1 Rxh2+ Kxh2 Qh5# 33.#",
          "positional_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 424,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Bc5",
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qf3",
            "Nd4",
            "Bxd4",
            "Bxd4",
            "c3",
            "Ba7",
            "g4",
            "c6",
            "gxh5",
            "cxd5",
            "cxd5",
            "Qg8+",
            "Kh1",
            "Qg5",
            "Rg1",
            "Qxh5",
            "Qg3",
            "Rag8",
            "Rg2",
            "Rxg3",
            "fxg3",
            "Qf3",
            "Re1",
            "Bf2",
            "Rf1",
            "Rxh2+",
            "Kxh2",
            "Qh5#"
          ],
          "plan_execute": [
            "d3",
            "Bc5",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "4... Nf6 5. d3 Bc5 6. O-O d6 7. c3 O-O 8. Bg5 h6 9. Bh4 g5 10. Bg3 Ba7 11. Nbd2 Nh5 12. Nxe5 Nxg3 13. Nxc6 bxc6 14. hxg3 d5 15. Bb3 Be6 16. d4 c5 17. exd5 Bxd5 18. Bxd5 Qxd5 19. Qh5 Kg7 20. Nf3 cxd4 21. cxd4 Bxd4 22. Rad1 c5 23. b4 Qxa2 24. Nxd4 cxd4 25. Rxd4 Rad8 26. Rfd1 Rxd4 27. Rxd4 Qa1+ 28. Rd1 Qb2 29. Qg4 Rb8 30. Rd4 Re8 31. Qd1 Re2 32. Rd6 Rxf2 33. Qd4+ Qxd4 34. Rxd4 Rb2 35. g4 Kf6 36. Rd6+ Ke5 37. Rxa6 Rxb4 38. Rxh6 Rxg4 39. Kf2 f5 40. Rh8 Ra4 41. Re8+ Kf4 42. g3+ Kg4 43. Re2 Ra3 44. Rb2 Rf3+ 45. Kg2 Rxg3+ 46. Kh2 f4 47. Rb4 Ra3 48. Rb2 Kh4 49. Kg2 g4 50. Kh2 g3+ 51. Kg2 Kg4 52. Rb4 Ra2+ 53. Kg1 Kh3 54. Rb1 f3 55. Kh1 g2+ 56. Kg1 f2# 0-1\n4... Nf6 5. d3 Bc5 6. O-O d6 7. c3 O-O 8. Bg5 h6 9. Bh4 g5 10. Bg3 Ba7 11. Nbd2 Nh5 12. Nxe5 Nxg3 13. Nxc6 bxc6 14. hxg3 d5 15. Bb3 Be6 16. d4 c5 17. exd5 Bxd5 18. Bxd5 Qxd5 19. Qh5 Kg7 20. Nf3 cxd4 21. cxd4 Bxd4 22. Rad1 c5 23. b4 Qxa2 24. Nxd4 cxd4 25. Rxd4 Rad8 26. Rfd1 Rxd4 27. Rxd4 Qa1+ 28. Rd1 Qb2 29",
          "neutral_tokens": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d3",
            "Bc5",
            "O-O",
            "d6",
            "c3",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Ba7",
            "Nbd2",
            "Nh5",
            "Nxe5",
            "Nxg3",
            "Nxc6",
            "bxc6",
            "hxg3",
            "d5",
            "Bb3",
            "Be6",
            "d4",
            "c5",
            "exd5",
            "Bxd5",
            "Bxd5",
            "Qxd5",
            "Qh5",
            "Kg7",
            "Nf3",
            "cxd4",
            "cxd4",
            "Bxd4",
            "Rad1",
            "c5",
            "b4",
            "Qxa2",
            "Nxd4",
            "cxd4",
            "Rxd4",
            "Rad8",
            "Rfd1",
            "Rxd4",
            "Rxd4",
            "Qa1+",
            "Rd1",
            "Qb2"
          ],
          "plan_execute": [
            "d3",
            "Bc5",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf6",
              "exf6",
              "gxf6",
              "Kxf6",
              "Kd5",
              "Kc5",
              "Kd4",
              "Kc4",
              "Kd3",
              "Kc3",
              "Kc2",
              "Kc1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2"
            ],
            "execute": [
              "Bxf6",
              "exf6",
              "gxf6"
            ]
          },
          "positional": {
            "full": [
              "d3",
              "Bc5",
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qf3",
              "Nd4",
              "Bxd4",
              "Bxd4",
              "c3",
              "Ba7",
              "g4",
              "c6",
              "gxh5",
              "cxd5",
              "cxd5",
              "Qg8+",
              "Kh1",
              "Qg5",
              "Rg1",
              "Qxh5",
              "Qg3",
              "Rag8",
              "Rg2",
              "Rxg3",
              "fxg3",
              "Qf3",
              "Re1",
              "Bf2",
              "Rf1",
              "Rxh2+",
              "Kxh2",
              "Qh5#"
            ],
            "execute": [
              "d3",
              "Bc5",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "d3",
              "Bc5",
              "O-O",
              "d6",
              "c3",
              "O-O",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Ba7",
              "Nbd2",
              "Nh5",
              "Nxe5",
              "Nxg3",
              "Nxc6",
              "bxc6",
              "hxg3",
              "d5",
              "Bb3",
              "Be6",
              "d4",
              "c5",
              "exd5",
              "Bxd5",
              "Bxd5",
              "Qxd5",
              "Qh5",
              "Kg7",
              "Nf3",
              "cxd4",
              "cxd4",
              "Bxd4",
              "Rad1",
              "c5",
              "b4",
              "Qxa2",
              "Nxd4",
              "cxd4",
              "Rxd4",
              "Rad8",
              "Rfd1",
              "Rxd4",
              "Rxd4",
              "Qa1+",
              "Rd1",
              "Qb2"
            ],
            "execute": [
              "d3",
              "Bc5",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "d3",
            "Bc5",
            "O-O"
          ],
          "full_moves": [
            "d3",
            "Bc5",
            "O-O",
            "d6",
            "c3",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Ba7",
            "Nbd2",
            "Nh5",
            "Nxe5",
            "Nxg3",
            "Nxc6",
            "bxc6",
            "hxg3",
            "d5",
            "Bb3",
            "Be6",
            "d4",
            "c5",
            "exd5",
            "Bxd5",
            "Bxd5",
            "Qxd5",
            "Qh5",
            "Kg7",
            "Nf3",
            "cxd4",
            "cxd4",
            "Bxd4",
            "Rad1",
            "c5",
            "b4",
            "Qxa2",
            "Nxd4",
            "cxd4",
            "Rxd4",
            "Rad8",
            "Rfd1",
            "Rxd4",
            "Rxd4",
            "Qa1+",
            "Rd1",
            "Qb2"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 139,
            "completion_tokens": 424,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 416,
          "total_completion_tokens": 1704,
          "total_tokens": 2120
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 139,
            "completion_tokens": 424,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/4p3/2B1P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc5",
          "aggressive_uci": "f8c5",
          "aggressive_response": "5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qxc8 Raxc8 20. Bxc5 dxc5 21. c3 Ne7 22. Ne3 Nf4 23. Rfe1 Rcd8 24. Rad1 Nd3 25. Re2 Nf4 26. Red2 Rxd2 27. Rxd2 Ke6 28. g3 Nh3+ 29. Kg2 Ng5 30. f3 Nf7 31. h4 Nd6 32. b3 f5 33. exf5+ Nexf5 34. Nd5 c6 35. Nb6 Rg8 36. g4 Nxh4+ 37. Kg3 Nhf5+ 38. Kf2 Ne7 39. Na4 b6 40. Nxb6 e4 41. Na4 exf3 42. Nxc5+ Ke5 43. Kxf3 Rf8+ 44. Ke3 Rf4 45. Nd7+ Ke6 46. Kxf4 Kxd7 47. c5 *",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 347,
            "total_tokens": 494,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qxc8",
            "Raxc8",
            "Bxc5",
            "dxc5",
            "c3",
            "Ne7",
            "Ne3",
            "Nf4",
            "Rfe1",
            "Rcd8",
            "Rad1",
            "Nd3",
            "Re2",
            "Nf4",
            "Red2",
            "Rxd2",
            "Rxd2",
            "Ke6",
            "g3",
            "Nh3+",
            "Kg2",
            "Ng5",
            "f3",
            "Nf7",
            "h4",
            "Nd6",
            "b3",
            "f5",
            "exf5+",
            "Nexf5",
            "Nd5",
            "c6",
            "Nb6",
            "Rg8",
            "g4",
            "Nxh4+",
            "Kg3",
            "Nhf5+",
            "Kf2",
            "Ne7",
            "Na4",
            "b6",
            "Nxb6",
            "e4",
            "Na4",
            "exf3",
            "Nxc5+",
            "Ke5",
            "Kxf3",
            "Rf8+",
            "Ke3",
            "Rf4",
            "Nd7+",
            "Ke6",
            "Kxf4",
            "Kxd7",
            "c5"
          ],
          "plan_execute": [
            "O-O",
            "O-O",
            "Nc3"
          ]
        },
        "query2": {
          "positional_move": "Bc5",
          "positional_uci": "f8c5",
          "positional_response": "5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qf3 Nd4 20. Bxd4 Bxd4 21. c3 Ba7 22. g4 c6 23. gxh5 cxd5 24. cxd5 Qg8+ 25. Kh1 Qg5 26. Rg1 Qxh5 27. Qg3 Rag8 28. Rg2 Rxg3 29. fxg3 Qf3 30. Re1 Bf2 31. Rf1 Rxh2+ 32. Kxh2 Qh5# 0-1\n33. Rh2 Qf3 34. Rg2 Qh5# 0-1",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 261,
            "total_tokens": 408,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qf3",
            "Nd4",
            "Bxd4",
            "Bxd4",
            "c3",
            "Ba7",
            "g4",
            "c6",
            "gxh5",
            "cxd5",
            "cxd5",
            "Qg8+",
            "Kh1",
            "Qg5",
            "Rg1",
            "Qxh5",
            "Qg3",
            "Rag8",
            "Rg2",
            "Rxg3",
            "fxg3",
            "Qf3",
            "Re1",
            "Bf2",
            "Rf1",
            "Rxh2+",
            "Kxh2",
            "Qh5#",
            "Rh2",
            "Qf3",
            "Rg2",
            "Qh5#"
          ],
          "plan_execute": [
            "O-O",
            "O-O",
            "Nc3"
          ]
        },
        "query3": {
          "neutral_move": "Bc5",
          "neutral_uci": "f8c5",
          "neutral_response": "5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Bxe6 fxg5 16. Qxh5 Qf6 17. Bf5 Rh8 18. Qg4 Rh4 19. Qg3 Rah8 20. Nd5 Qh6 21. h3 Nd4 22. Rae1 Nxf5 23. exf5 g4 24. f6+ Kf7 25. Re4 gxh3 26. Rxh4 Qxh4 27. Qg7+ Ke6 28. Nxc7+ Kf5 29. f7 hxg2 30. f8=Q+ Rxf8 31. Qxf8+ Kg6 32. Qg8+ Kf6 33. Nd5+ Kf5 34. Qf7+ Kg5 35. Qf6+ Kh5 36. Qxh4+ Kxh4 37. Kxg2 Kg4 38. f3+ Kf5 39. Rh1 Ke6 40. c4 b5 41. Rh6+ Kd7 42. b4 Bd4 43. cxb5 axb5 44. Rh7+ Kc6 45. Ne7+ Kd7 46. Nf5+ Ke6 47. Nxd4+ exd4 48. Rh5 d5 49. Kg3 Kd6 50. Kf4 Ke6 51. Rh6+ Kd7 52. Ke5 Ke7 53. Rh7+ Kf8 54. Kf6 Kg8 55. Ra7 Kh8 56. Kg6 Kg8 57. Ra8# Bf8 58. Rxf8# Bf8 59. Rxf8# Kxf8 60. Kf6 Ke8 61. Ke6 Kd8 62. Kxd5 Kc7 63. Kc5 Kb7 64. Kxb5 Ka7 65. Kc6 Ka6 66. b5+ Ka7 67. b6+ Kb8 68. b7 Ka7 69. Kc7 Ka6 70. b8=Q Ka5 71. Qb3 Ka6 72. Qb6# Kd5 73. Qd6# Kc4 74. Qc5# Kd3 75. d5 Ke2 76. d6 Kxf3 77. d7 Ke4 78. d8=Q Kf4 79. Qce7 Kf5 80. Q",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Bxe6",
            "fxg5",
            "Qxh5",
            "Qf6",
            "Bf5",
            "Rh8",
            "Qg4",
            "Rh4",
            "Qg3",
            "Rah8",
            "Nd5",
            "Qh6",
            "h3",
            "Nd4",
            "Rae1",
            "Nxf5",
            "exf5",
            "g4",
            "f6+",
            "Kf7",
            "Re4",
            "gxh3",
            "Rxh4",
            "Qxh4",
            "Qg7+",
            "Ke6",
            "Nxc7+",
            "Kf5",
            "f7",
            "hxg2",
            "f8=Q+",
            "Rxf8",
            "Qxf8+",
            "Kg6",
            "Qg8+",
            "Kf6",
            "Nd5+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Qf6+",
            "Kh5",
            "Qxh4+",
            "Kxh4",
            "Kxg2",
            "Kg4",
            "f3+",
            "Kf5",
            "Rh1",
            "Ke6",
            "c4",
            "b5",
            "Rh6+",
            "Kd7",
            "b4",
            "Bd4",
            "cxb5",
            "axb5",
            "Rh7+",
            "Kc6",
            "Ne7+",
            "Kd7",
            "Nf5+",
            "Ke6",
            "Nxd4+",
            "exd4",
            "Rh5",
            "d5",
            "Kg3",
            "Kd6",
            "Kf4",
            "Ke6",
            "Rh6+",
            "Kd7",
            "Ke5",
            "Ke7",
            "Rh7+",
            "Kf8",
            "Kf6",
            "Kg8",
            "Ra7",
            "Kh8",
            "Kg6",
            "Kg8",
            "Ra8#",
            "Bf8",
            "Rxf8#",
            "Bf8",
            "Rxf8#",
            "Kxf8",
            "Kf6",
            "Ke8",
            "Ke6",
            "Kd8",
            "Kxd5",
            "Kc7",
            "Kc5",
            "Kb7",
            "Kxb5",
            "Ka7",
            "Kc6",
            "Ka6",
            "b5+",
            "Ka7",
            "b6+",
            "Kb8",
            "b7",
            "Ka7",
            "Kc7",
            "Ka6",
            "b8=Q",
            "Ka5",
            "Qb3",
            "Ka6",
            "Qb6#",
            "Kd5",
            "Qd6#",
            "Kc4",
            "Qc5#",
            "Kd3",
            "d5",
            "Ke2",
            "d6",
            "Kxf3",
            "d7",
            "Ke4",
            "d8=Q",
            "Kf4",
            "Qce7",
            "Kf5"
          ],
          "plan_execute": [
            "O-O",
            "O-O",
            "Nc3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f8c5",
          "positional_uci": "f8c5",
          "neutral_uci": "f8c5",
          "consensus_move": "f8c5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qxc8",
              "Raxc8",
              "Bxc5",
              "dxc5",
              "c3",
              "Ne7",
              "Ne3",
              "Nf4",
              "Rfe1",
              "Rcd8",
              "Rad1",
              "Nd3",
              "Re2",
              "Nf4",
              "Red2",
              "Rxd2",
              "Rxd2",
              "Ke6",
              "g3",
              "Nh3+",
              "Kg2",
              "Ng5",
              "f3",
              "Nf7",
              "h4",
              "Nd6",
              "b3",
              "f5",
              "exf5+",
              "Nexf5",
              "Nd5",
              "c6",
              "Nb6",
              "Rg8",
              "g4",
              "Nxh4+",
              "Kg3",
              "Nhf5+",
              "Kf2",
              "Ne7",
              "Na4",
              "b6",
              "Nxb6",
              "e4",
              "Na4",
              "exf3",
              "Nxc5+",
              "Ke5",
              "Kxf3",
              "Rf8+",
              "Ke3",
              "Rf4",
              "Nd7+",
              "Ke6",
              "Kxf4",
              "Kxd7",
              "c5"
            ],
            "execute": [
              "O-O",
              "O-O",
              "Nc3"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qf3",
              "Nd4",
              "Bxd4",
              "Bxd4",
              "c3",
              "Ba7",
              "g4",
              "c6",
              "gxh5",
              "cxd5",
              "cxd5",
              "Qg8+",
              "Kh1",
              "Qg5",
              "Rg1",
              "Qxh5",
              "Qg3",
              "Rag8",
              "Rg2",
              "Rxg3",
              "fxg3",
              "Qf3",
              "Re1",
              "Bf2",
              "Rf1",
              "Rxh2+",
              "Kxh2",
              "Qh5#",
              "Rh2",
              "Qf3",
              "Rg2",
              "Qh5#"
            ],
            "execute": [
              "O-O",
              "O-O",
              "Nc3"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Bxe6",
              "fxg5",
              "Qxh5",
              "Qf6",
              "Bf5",
              "Rh8",
              "Qg4",
              "Rh4",
              "Qg3",
              "Rah8",
              "Nd5",
              "Qh6",
              "h3",
              "Nd4",
              "Rae1",
              "Nxf5",
              "exf5",
              "g4",
              "f6+",
              "Kf7",
              "Re4",
              "gxh3",
              "Rxh4",
              "Qxh4",
              "Qg7+",
              "Ke6",
              "Nxc7+",
              "Kf5",
              "f7",
              "hxg2",
              "f8=Q+",
              "Rxf8",
              "Qxf8+",
              "Kg6",
              "Qg8+",
              "Kf6",
              "Nd5+",
              "Kf5",
              "Qf7+",
              "Kg5",
              "Qf6+",
              "Kh5",
              "Qxh4+",
              "Kxh4",
              "Kxg2",
              "Kg4",
              "f3+",
              "Kf5",
              "Rh1",
              "Ke6",
              "c4",
              "b5",
              "Rh6+",
              "Kd7",
              "b4",
              "Bd4",
              "cxb5",
              "axb5",
              "Rh7+",
              "Kc6",
              "Ne7+",
              "Kd7",
              "Nf5+",
              "Ke6",
              "Nxd4+",
              "exd4",
              "Rh5",
              "d5",
              "Kg3",
              "Kd6",
              "Kf4",
              "Ke6",
              "Rh6+",
              "Kd7",
              "Ke5",
              "Ke7",
              "Rh7+",
              "Kf8",
              "Kf6",
              "Kg8",
              "Ra7",
              "Kh8",
              "Kg6",
              "Kg8",
              "Ra8#",
              "Bf8",
              "Rxf8#",
              "Bf8",
              "Rxf8#",
              "Kxf8",
              "Kf6",
              "Ke8",
              "Ke6",
              "Kd8",
              "Kxd5",
              "Kc7",
              "Kc5",
              "Kb7",
              "Kxb5",
              "Ka7",
              "Kc6",
              "Ka6",
              "b5+",
              "Ka7",
              "b6+",
              "Kb8",
              "b7",
              "Ka7",
              "Kc7",
              "Ka6",
              "b8=Q",
              "Ka5",
              "Qb3",
              "Ka6",
              "Qb6#",
              "Kd5",
              "Qd6#",
              "Kc4",
              "Qc5#",
              "Kd3",
              "d5",
              "Ke2",
              "d6",
              "Kxf3",
              "d7",
              "Ke4",
              "d8=Q",
              "Kf4",
              "Qce7",
              "Kf5"
            ],
            "execute": [
              "O-O",
              "O-O",
              "Nc3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "O-O",
            "Nc3"
          ],
          "full_moves": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Bxe6",
            "fxg5",
            "Qxh5",
            "Qf6",
            "Bf5",
            "Rh8",
            "Qg4",
            "Rh4",
            "Qg3",
            "Rah8",
            "Nd5",
            "Qh6",
            "h3",
            "Nd4",
            "Rae1",
            "Nxf5",
            "exf5",
            "g4",
            "f6+",
            "Kf7",
            "Re4",
            "gxh3",
            "Rxh4",
            "Qxh4",
            "Qg7+",
            "Ke6",
            "Nxc7+",
            "Kf5",
            "f7",
            "hxg2",
            "f8=Q+",
            "Rxf8",
            "Qxf8+",
            "Kg6",
            "Qg8+",
            "Kf6",
            "Nd5+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Qf6+",
            "Kh5",
            "Qxh4+",
            "Kxh4",
            "Kxg2",
            "Kg4",
            "f3+",
            "Kf5",
            "Rh1",
            "Ke6",
            "c4",
            "b5",
            "Rh6+",
            "Kd7",
            "b4",
            "Bd4",
            "cxb5",
            "axb5",
            "Rh7+",
            "Kc6",
            "Ne7+",
            "Kd7",
            "Nf5+",
            "Ke6",
            "Nxd4+",
            "exd4",
            "Rh5",
            "d5",
            "Kg3",
            "Kd6",
            "Kf4",
            "Ke6",
            "Rh6+",
            "Kd7",
            "Ke5",
            "Ke7",
            "Rh7+",
            "Kf8",
            "Kf6",
            "Kg8",
            "Ra7",
            "Kh8",
            "Kg6",
            "Kg8",
            "Ra8#",
            "Bf8",
            "Rxf8#",
            "Bf8",
            "Rxf8#",
            "Kxf8",
            "Kf6",
            "Ke8",
            "Ke6",
            "Kd8",
            "Kxd5",
            "Kc7",
            "Kc5",
            "Kb7",
            "Kxb5",
            "Ka7",
            "Kc6",
            "Ka6",
            "b5+",
            "Ka7",
            "b6+",
            "Kb8",
            "b7",
            "Ka7",
            "Kc7",
            "Ka6",
            "b8=Q",
            "Ka5",
            "Qb3",
            "Ka6",
            "Qb6#",
            "Kd5",
            "Qd6#",
            "Kc4",
            "Qc5#",
            "Kd3",
            "d5",
            "Ke2",
            "d6",
            "Kxf3",
            "d7",
            "Ke4",
            "d8=Q",
            "Kf4",
            "Qce7",
            "Kf5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 347,
            "total_tokens": 494,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 261,
            "total_tokens": 408,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 1248,
          "total_tokens": 1688
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 347,
            "total_tokens": 494,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 261,
            "total_tokens": 408,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/2B1P3/3P1N2/PPP2PPP/RNBQK2R b KQkq - 0 5"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 d5\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qf5 Qh4+ Kg8 Re8#\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qf5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qf5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qf5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qf5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qf5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "O-O",
            "Rd8"
          ],
          "plan_execute": [
            "d5",
            "Nc3",
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Qxh7 Kd8 17. Qg8+ Kd7 18. Qf7+ Kd8 19. Bg7 Qe8 20. Bf6+ Ne7 21. Bxe7+ Kd7 22. Nf6+ Kc6 23. Qxe8+ Kb6 24. Nd5+ Ka6 25. Qa4# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Qxh7 Kd8 Qxg6 Kd7 Qf7+ Kd8 Qc7+ Ke8 Qxd6 Kf7 Nc7 Rb8 Qf4+ Ke7 Nd5+ Kd7 Qxb8 Nxb8 Rad1 Nc6 Nf6+ Ke6 Qxc8+ Kxf6 Qxb7 Ne5 Qxa7 Kf5 Rd5 Ke4 Rxe5+ Kxe5 Re1+ Kd5 Qd7+ Kc5 Re5+ Kb6 Qd6+ Kb7 Re7+ Kc8 Qc7#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 445,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Qxh7",
            "Kd8",
            "Qxg6",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qc7+",
            "Ke8",
            "Qxd6",
            "Kf7",
            "Nc7",
            "Rb8",
            "Qf4+",
            "Ke7",
            "Nd5+",
            "Kd7",
            "Qxb8",
            "Nxb8",
            "Rad1",
            "Nc6",
            "Nf6+",
            "Ke6",
            "Qxc8+",
            "Kxf6",
            "Qxb7",
            "Ne5",
            "Qxa7",
            "Kf5",
            "Rd5",
            "Ke4",
            "Rxe5+",
            "Kxe5",
            "Re1+",
            "Kd5",
            "Qd7+",
            "Kc5",
            "Re5+",
            "Kb6",
            "Qd6+",
            "Kb7",
            "Re7+",
            "Kc8",
            "Qc7#"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nf6 5. d3 O-O 6. Bg5 d6 7. Nc3 Bg4 8. Nd5 Nd4\n9. Bxf6 gxf6 10. Bc4 c6 11. Ne3 Bxf3 12. gxf3 Kh8 13. c3 Ne6 14. Nf5 Rg8+ 15. Kh1 d5\n16. Bb3 Nf4 17. d4 Bb6 18. Qd2 Rg5 19. Rg1 Qd7 20. Rxg5 fxg5 21. Rg1 f6 22. Rg3 Rd8\n23. h4 h6 24. hxg5 hxg5 25. Kg1 Qh7 26. Bc2 Rd7 27. Qe1 Kg8 28. Qf1 Kf8 29. a4 a5\n30. b4 axb4 31. cxb4 Bxd4 32. Nxd4 exd4 33. Qd1 d3 34. Bxd3 dxe4 35. fxe4 Qxe4\n36. Bxe4 Rxd1+ 37. Kh2 Rd4 38. Bf5 Rxb4 39. Ra3 Nd5 40. a5 Rf4 41. Bc8 Rxf2+\n42. Kg3 Rb2 43. a6 bxa6 44. Rxa6 Rb6 45. Ra8 Ke7 46. Bf5 Kd6 47. Rd8+ Ke5\n48. Bg6 Rb3+ 49. Kf2 Kf4 50. Rc8 Rb2+ 51. Ke1 Ne7 52. Rf8 Nxg6 53. Rxf6+ Ke3\n54. Re6+ Kd3 55. Rxg6 c5 56. Rxg5 c4 57. Rd5+ Kc2 58. Rd2+ Kc1 59. Rd1+ Kc2\n60. Rd2+ Kc3 61. Rd1 Rh2 62. Rd8 Kc2 63. Rc8 c3 64. Rc7 Kb2 65. Rb7+ Kc1\n66. Rc7 c2 67. Rc8 Rh5 68. Rc7 Re5+ 69. Kf2 Kd2 70. Rd7+ Kc3 71. Rc7+ Kd3\n72. Rd7+ Kc4 73. Rc7+ Rc5 74. Rxc5+ Kxc5 75. Ke2 c1=Q 76. Kd3 Qc4+ 77. Ke",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nf6",
            "d3",
            "O-O",
            "Bg5",
            "d6",
            "Nc3",
            "Bg4",
            "Nd5",
            "Nd4",
            "Bxf6",
            "gxf6",
            "Bc4",
            "c6",
            "Ne3",
            "Bxf3",
            "gxf3",
            "Kh8",
            "c3",
            "Ne6",
            "Nf5",
            "Rg8+",
            "Kh1",
            "d5",
            "Bb3",
            "Nf4",
            "d4",
            "Bb6",
            "Qd2",
            "Rg5",
            "Rg1",
            "Qd7",
            "Rxg5",
            "fxg5",
            "Rg1",
            "f6",
            "Rg3",
            "Rd8",
            "h4",
            "h6",
            "hxg5",
            "hxg5",
            "Kg1",
            "Qh7",
            "Bc2",
            "Rd7",
            "Qe1",
            "Kg8",
            "Qf1",
            "Kf8",
            "a4",
            "a5",
            "b4",
            "axb4",
            "cxb4",
            "Bxd4",
            "Nxd4",
            "exd4",
            "Qd1",
            "d3",
            "Bxd3",
            "dxe4",
            "fxe4",
            "Qxe4",
            "Bxe4",
            "Rxd1+",
            "Kh2",
            "Rd4",
            "Bf5",
            "Rxb4",
            "Ra3",
            "Nd5",
            "a5",
            "Rf4",
            "Bc8",
            "Rxf2+",
            "Kg3",
            "Rb2",
            "a6",
            "bxa6",
            "Rxa6",
            "Rb6",
            "Ra8",
            "Ke7",
            "Bf5",
            "Kd6",
            "Rd8+",
            "Ke5",
            "Bg6",
            "Rb3+",
            "Kf2",
            "Kf4",
            "Rc8",
            "Rb2+",
            "Ke1",
            "Ne7",
            "Rf8",
            "Nxg6",
            "Rxf6+",
            "Ke3",
            "Re6+",
            "Kd3",
            "Rxg6",
            "c5",
            "Rxg5",
            "c4",
            "Rd5+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "Rd2+",
            "Kc3",
            "Rd1",
            "Rh2",
            "Rd8",
            "Kc2",
            "Rc8",
            "c3",
            "Rc7",
            "Kb2",
            "Rb7+",
            "Kc1",
            "Rc7",
            "c2",
            "Rc8",
            "Rh5",
            "Rc7",
            "Re5+",
            "Kf2",
            "Kd2",
            "Rd7+",
            "Kc3",
            "Rc7+",
            "Kd3",
            "Rd7+",
            "Kc4",
            "Rc7+",
            "Rc5",
            "Rxc5+",
            "Kxc5",
            "Ke2",
            "c1=Q",
            "Kd3",
            "Qc4+"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nc3",
              "Nf6",
              "Bg5",
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nxf6+",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nf3",
              "O-O",
              "Bd3",
              "Nc6",
              "O-O",
              "Rd8"
            ],
            "execute": [
              "d5",
              "Nc3",
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Qxh7",
              "Kd8",
              "Qxg6",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qc7+",
              "Ke8",
              "Qxd6",
              "Kf7",
              "Nc7",
              "Rb8",
              "Qf4+",
              "Ke7",
              "Nd5+",
              "Kd7",
              "Qxb8",
              "Nxb8",
              "Rad1",
              "Nc6",
              "Nf6+",
              "Ke6",
              "Qxc8+",
              "Kxf6",
              "Qxb7",
              "Ne5",
              "Qxa7",
              "Kf5",
              "Rd5",
              "Ke4",
              "Rxe5+",
              "Kxe5",
              "Re1+",
              "Kd5",
              "Qd7+",
              "Kc5",
              "Re5+",
              "Kb6",
              "Qd6+",
              "Kb7",
              "Re7+",
              "Kc8",
              "Qc7#"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nf6",
              "d3",
              "O-O",
              "Bg5",
              "d6",
              "Nc3",
              "Bg4",
              "Nd5",
              "Nd4",
              "Bxf6",
              "gxf6",
              "Bc4",
              "c6",
              "Ne3",
              "Bxf3",
              "gxf3",
              "Kh8",
              "c3",
              "Ne6",
              "Nf5",
              "Rg8+",
              "Kh1",
              "d5",
              "Bb3",
              "Nf4",
              "d4",
              "Bb6",
              "Qd2",
              "Rg5",
              "Rg1",
              "Qd7",
              "Rxg5",
              "fxg5",
              "Rg1",
              "f6",
              "Rg3",
              "Rd8",
              "h4",
              "h6",
              "hxg5",
              "hxg5",
              "Kg1",
              "Qh7",
              "Bc2",
              "Rd7",
              "Qe1",
              "Kg8",
              "Qf1",
              "Kf8",
              "a4",
              "a5",
              "b4",
              "axb4",
              "cxb4",
              "Bxd4",
              "Nxd4",
              "exd4",
              "Qd1",
              "d3",
              "Bxd3",
              "dxe4",
              "fxe4",
              "Qxe4",
              "Bxe4",
              "Rxd1+",
              "Kh2",
              "Rd4",
              "Bf5",
              "Rxb4",
              "Ra3",
              "Nd5",
              "a5",
              "Rf4",
              "Bc8",
              "Rxf2+",
              "Kg3",
              "Rb2",
              "a6",
              "bxa6",
              "Rxa6",
              "Rb6",
              "Ra8",
              "Ke7",
              "Bf5",
              "Kd6",
              "Rd8+",
              "Ke5",
              "Bg6",
              "Rb3+",
              "Kf2",
              "Kf4",
              "Rc8",
              "Rb2+",
              "Ke1",
              "Ne7",
              "Rf8",
              "Nxg6",
              "Rxf6+",
              "Ke3",
              "Re6+",
              "Kd3",
              "Rxg6",
              "c5",
              "Rxg5",
              "c4",
              "Rd5+",
              "Kc2",
              "Rd2+",
              "Kc1",
              "Rd1+",
              "Kc2",
              "Rd2+",
              "Kc3",
              "Rd1",
              "Rh2",
              "Rd8",
              "Kc2",
              "Rc8",
              "c3",
              "Rc7",
              "Kb2",
              "Rb7+",
              "Kc1",
              "Rc7",
              "c2",
              "Rc8",
              "Rh5",
              "Rc7",
              "Re5+",
              "Kf2",
              "Kd2",
              "Rd7+",
              "Kc3",
              "Rc7+",
              "Kd3",
              "Rd7+",
              "Kc4",
              "Rc7+",
              "Rc5",
              "Rxc5+",
              "Kxc5",
              "Ke2",
              "c1=Q",
              "Kd3",
              "Qc4+"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "full_moves": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nf6",
            "d3",
            "O-O",
            "Bg5",
            "d6",
            "Nc3",
            "Bg4",
            "Nd5",
            "Nd4",
            "Bxf6",
            "gxf6",
            "Bc4",
            "c6",
            "Ne3",
            "Bxf3",
            "gxf3",
            "Kh8",
            "c3",
            "Ne6",
            "Nf5",
            "Rg8+",
            "Kh1",
            "d5",
            "Bb3",
            "Nf4",
            "d4",
            "Bb6",
            "Qd2",
            "Rg5",
            "Rg1",
            "Qd7",
            "Rxg5",
            "fxg5",
            "Rg1",
            "f6",
            "Rg3",
            "Rd8",
            "h4",
            "h6",
            "hxg5",
            "hxg5",
            "Kg1",
            "Qh7",
            "Bc2",
            "Rd7",
            "Qe1",
            "Kg8",
            "Qf1",
            "Kf8",
            "a4",
            "a5",
            "b4",
            "axb4",
            "cxb4",
            "Bxd4",
            "Nxd4",
            "exd4",
            "Qd1",
            "d3",
            "Bxd3",
            "dxe4",
            "fxe4",
            "Qxe4",
            "Bxe4",
            "Rxd1+",
            "Kh2",
            "Rd4",
            "Bf5",
            "Rxb4",
            "Ra3",
            "Nd5",
            "a5",
            "Rf4",
            "Bc8",
            "Rxf2+",
            "Kg3",
            "Rb2",
            "a6",
            "bxa6",
            "Rxa6",
            "Rb6",
            "Ra8",
            "Ke7",
            "Bf5",
            "Kd6",
            "Rd8+",
            "Ke5",
            "Bg6",
            "Rb3+",
            "Kf2",
            "Kf4",
            "Rc8",
            "Rb2+",
            "Ke1",
            "Ne7",
            "Rf8",
            "Nxg6",
            "Rxf6+",
            "Ke3",
            "Re6+",
            "Kd3",
            "Rxg6",
            "c5",
            "Rxg5",
            "c4",
            "Rd5+",
            "Kc2",
            "Rd2+",
            "Kc1",
            "Rd1+",
            "Kc2",
            "Rd2+",
            "Kc3",
            "Rd1",
            "Rh2",
            "Rd8",
            "Kc2",
            "Rc8",
            "c3",
            "Rc7",
            "Kb2",
            "Rb7+",
            "Kc1",
            "Rc7",
            "c2",
            "Rc8",
            "Rh5",
            "Rc7",
            "Re5+",
            "Kf2",
            "Kd2",
            "Rd7+",
            "Kc3",
            "Rc7+",
            "Kd3",
            "Rd7+",
            "Kc4",
            "Rc7+",
            "Rc5",
            "Rxc5+",
            "Kxc5",
            "Ke2",
            "c1=Q",
            "Kd3",
            "Qc4+"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 445,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1725,
          "total_tokens": 2054
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 445,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb5",
          "aggressive_uci": "f1b5",
          "aggressive_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf4+ Bxf4# Bb8+ Bc7 Bf",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7",
            "Bf4+",
            "Bxf4#",
            "Bb8+",
            "Bc7"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "Bb5",
          "positional_uci": "f1b5",
          "positional_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. d5 Rg6 27. Bf4 Rxe1+ 28. Nf1 h6 29. Rxb8+ Kh7 30. Bg3 Bh3 31. d6 Bxg2 32. Kxg2 Qd5+ 33. Kg1 Qd3 34. Kg2 Qxf1+ 35. Kf3 Qh1+ 36. Kf4 Qe4# d4 Nc3 Bb4 Nxd5",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 299,
            "total_tokens": 424,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "d5",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "h6",
            "Rxb8+",
            "Kh7",
            "Bg3",
            "Bh3",
            "d6",
            "Bxg2",
            "Kxg2",
            "Qd5+",
            "Kg1",
            "Qd3",
            "Kg2",
            "Qxf1+",
            "Kf3",
            "Qh1+",
            "Kf4",
            "Qe4#",
            "d4",
            "Nc3",
            "Bb4",
            "Nxd5"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "Bb5",
          "neutral_uci": "f1b5",
          "neutral_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bb8 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qf3 Bg4 26. Qg2 Bh3 27. Qf3 Bg4 28. Qg2 Bh3 29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3 33. Qf3 Bg4 34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3 37. Qf3 Bg4 38. Qg2 Bh3 39. Qf3 Bg4 40. Qg2 Bh3 41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4 44. Qg2 Bh3 45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3 49. Qf3 Bg4 50. Qg2 Bh3 51. Qf3 Bg4 52. Qg2 Bh3 53. Qf3 Bg4 54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3 57. Qf3 Bg4 58. Qg2 Bh3 59. Qf3 Bg4 60. Qg2 Bh3 61. Qf3 Bg4 62. Qg2 Bh3 63. Qf3 Bg4 64. Qg2 Bh3 65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3 69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3 73. Qf3 Bg4 74. Qg2 Bh3 75. Qf3 Bg4 76. Qg2 Bh3 77. Qf3 Bg4 78. Qg2 Bh3 79. Q",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1b5",
          "positional_uci": "f1b5",
          "neutral_uci": "f1b5",
          "consensus_move": "f1b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7",
              "Bf4+",
              "Bxf4#",
              "Bb8+",
              "Bc7"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "d5",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "h6",
              "Rxb8+",
              "Kh7",
              "Bg3",
              "Bh3",
              "d6",
              "Bxg2",
              "Kxg2",
              "Qd5+",
              "Kg1",
              "Qd3",
              "Kg2",
              "Qxf1+",
              "Kf3",
              "Qh1+",
              "Kf4",
              "Qe4#",
              "d4",
              "Nc3",
              "Bb4",
              "Nxd5"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "a6",
            "Ba4",
            "Nf6"
          ],
          "full_moves": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 299,
            "total_tokens": 424,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1579,
          "total_tokens": 1953
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 299,
            "total_tokens": 424,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Qe2 h6 20. Red1 Bf8 21. Nf1 exd4 22. Nxd4 Nxd4 23. Bxd4 Rxc1 24. Rxc1 Re8 25. Ng3 Nh7 26. Qd3 g6 27. f4 Bg7 28. Bxg7 Kxg7 29. Qxd6 Nf6 30. Qd4 Qb8 31. e5 Ng8 32. Qxd7 Rd8 33. Qc6 Rd2 34. Qc3 Qb6+ 35. Kh2 Qf2 36. e6+ Kh7 37. Be4 fxe6 38. Qc7+ Kh8 39. Qe5+ Kh7 40. Rc7+ Ne7 41. Rxe7+ Kg8 42. Qg7# Nf6 43. Qg7# Nf6 44. Qg7# Nf6 45. Qg7# Nf6 46. Qg7# Nf6 47. Qg7# Nf6 48. Qg7# Nf6 49. Qg7# Nf6 50. Qg7# Nf6 51. Qg7# Nf6 52. Qg7# Nf6 53. Qg7# Nf6 54. Qg7# Nf6 55. Qg7# Nf6 56. Qg7# Nf6 57. Qg7# Nf6 58. Qg7# Nf6 59. Qg7# Nf6 60. Qg7# Nf6 61. Qg7# Nf6 62. Qg7# Nf6 63. Qg7# Nf6 64. Qg7# Nf6 65. Qg7# Nf6 66. Qg7# Nf6 67. Qg7# Nf6 68. Qg7# Nf6 69. Qg7# Nf6 70. Qg7# Nf6 71. Qg7# Nf6 72. Qg7# Nf6 73. Qg7# Nf6 74. Qg7# Nf6 75. Qg7",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Qe2",
            "h6",
            "Red1",
            "Bf8",
            "Nf1",
            "exd4",
            "Nxd4",
            "Nxd4",
            "Bxd4",
            "Rxc1",
            "Rxc1",
            "Re8",
            "Ng3",
            "Nh7",
            "Qd3",
            "g6",
            "f4",
            "Bg7",
            "Bxg7",
            "Kxg7",
            "Qxd6",
            "Nf6",
            "Qd4",
            "Qb8",
            "e5",
            "Ng8",
            "Qxd7",
            "Rd8",
            "Qc6",
            "Rd2",
            "Qc3",
            "Qb6+",
            "Kh2",
            "Qf2",
            "e6+",
            "Kh7",
            "Be4",
            "fxe6",
            "Qc7+",
            "Kh8",
            "Qe5+",
            "Kh7",
            "Rc7+",
            "Ne7",
            "Rxe7+",
            "Kg8",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rad8 25. Bg5 exd4 26. Bxf6 gxf6 27. Qh6 Ne7 28. Nh5 Nf5 29. Nxf6+ Kh8 30. Qxh7# e4 Nxe4 Nxe4 Qe7",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 220,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rad8",
            "Bg5",
            "exd4",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Ne7",
            "Nh5",
            "Nf5",
            "Nxf6+",
            "Kh8",
            "Qxh7#",
            "e4",
            "Nxe4",
            "Nxe4",
            "Qe7"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Qa6 25. Bg5 Qa5 26. Qd1 Nxd4 27. Nxd4 exd4 28. Bxf6 gxf6 29. Nh5 Re6 30. Rf1 b4 31. f4 Kh8 32. f5 Re5 33. Nxf6 Qd8 34. Ng4 Bb5 35. Rf2 Qb6 36. Qd2 Rg8 37. Qh6 Qd8 38. Nf6 Rg7 39. Rf4 d3 40. Rh4 Qb6+ 41. Kh2 Rxg2+ 42. Kxg2 1-0 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Qa6 25. Bg5 Qa5 26. Qd1 Nxd4 27. Nxd4 exd4 28. Bxf6 gxf6 29. Nh5 Re6 30. Rf1 b4 31. f4 Kh8 32. f5 Re5 33. Nxf6 Qd8 34. Ng4 Bb5 35. Rf2 Qb6 36. Qd2 Rg8 37. Qh6 Qd8 38. Nf6 Rg7 39. Rf4 d3 40. Rh4 Qb6+ 41. Kh2 Rxg2+ 42. Kxg2 1-0 5. O-O Be7 6. Re1",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Re1"
          ],
          "plan_execute": [
            "Be7",
            "Re1"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Qe2",
              "h6",
              "Red1",
              "Bf8",
              "Nf1",
              "exd4",
              "Nxd4",
              "Nxd4",
              "Bxd4",
              "Rxc1",
              "Rxc1",
              "Re8",
              "Ng3",
              "Nh7",
              "Qd3",
              "g6",
              "f4",
              "Bg7",
              "Bxg7",
              "Kxg7",
              "Qxd6",
              "Nf6",
              "Qd4",
              "Qb8",
              "e5",
              "Ng8",
              "Qxd7",
              "Rd8",
              "Qc6",
              "Rd2",
              "Qc3",
              "Qb6+",
              "Kh2",
              "Qf2",
              "e6+",
              "Kh7",
              "Be4",
              "fxe6",
              "Qc7+",
              "Kh8",
              "Qe5+",
              "Kh7",
              "Rc7+",
              "Ne7",
              "Rxe7+",
              "Kg8",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7#",
              "Nf6",
              "Qg7"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          },
          "positional": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rad8",
              "Bg5",
              "exd4",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Ne7",
              "Nh5",
              "Nf5",
              "Nxf6+",
              "Kh8",
              "Qxh7#",
              "e4",
              "Nxe4",
              "Nxe4",
              "Qe7"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          },
          "neutral": {
            "full": [
              "Be7",
              "Re1"
            ],
            "execute": [
              "Be7",
              "Re1"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "h3",
            "Na5",
            "Bc2"
          ],
          "full_moves": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Qe2",
            "h6",
            "Red1",
            "Bf8",
            "Nf1",
            "exd4",
            "Nxd4",
            "Nxd4",
            "Bxd4",
            "Rxc1",
            "Rxc1",
            "Re8",
            "Ng3",
            "Nh7",
            "Qd3",
            "g6",
            "f4",
            "Bg7",
            "Bxg7",
            "Kxg7",
            "Qxd6",
            "Nf6",
            "Qd4",
            "Qb8",
            "e5",
            "Ng8",
            "Qxd7",
            "Rd8",
            "Qc6",
            "Rd2",
            "Qc3",
            "Qb6+",
            "Kh2",
            "Qf2",
            "e6+",
            "Kh7",
            "Be4",
            "fxe6",
            "Qc7+",
            "Kh8",
            "Qe5+",
            "Kh7",
            "Rc7+",
            "Ne7",
            "Rxe7+",
            "Kg8",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7#",
            "Nf6",
            "Qg7"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 220,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 1500,
          "total_tokens": 1922
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 220,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re1",
          "aggressive_uci": "f1e1",
          "aggressive_response": "6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bc8+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+ Ke7 Bg5+ Kf8 Bf4+",
          "aggressive_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bc8+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+"
          ],
          "plan_execute": [
            "Qh4",
            "g3",
            "Qh3"
          ]
        },
        "query2": {
          "positional_move": "Re1",
          "positional_uci": "f1e1",
          "positional_response": "6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Bf3 29. Rxb8+ Re8 30. Rxe8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8# e5 dxe5 Qd8+ Bf8 Qxd8#",
          "positional_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#",
            "e5",
            "dxe5",
            "Qd8+",
            "Bf8",
            "Qxd8#"
          ],
          "plan_execute": [
            "Qh4",
            "g3",
            "Qh3"
          ]
        },
        "query3": {
          "neutral_move": "Re1",
          "neutral_uci": "f1e1",
          "neutral_response": "6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Qa6 25. Bg5 Qa5 26. Qd1 Nxd4 27. Nxd4 exd4 28. Bxf6 gxf6 29. Nh5 Re6 30. Rf1 Kh8 31. Qxd4 b4 32. Nxf6 Qe5 33. Qxe5 dxe5 34. Nxd7 Rd8 35. Nc5 Rc6 36. Nxa4 Rd2 37. b3 Kg7 38. g3 Kf6 39. Kg2 Ke7 40. Kf3 Rf6+ 41. Ke3 Rfd6 42. Rc1 Rd1 43. Rxd1 Rxd1 44. Bd3 Ra1 45. Nb6 Rxa2 46. Nd5+ Kd6 47. Nxb4 Rb2 48. Bc4 f6 49. Nd3 Rb1 50. h4 h6 51. Kf3 h5 52. Ke3 Kc6 53. f4 Kd6 54. fxe5+ fxe5 55. Kf3 Rf1+ 56. Nf2 Rb1 57. g4 hxg4+ 58. Nxg4 Rh1 59. Kg3 Rg1+ 60. Kh3 Rh1+ 61. Nh2 Re1 62. Bd5 Re3+ 63. Kg4 Re2 64. Nf3 Rg2+ 65. Kf5 Rf2 66. Kg4 Rg2+ 67. Kh3 Rf2 68. Kg3 Rf1 69. h5 Rh1 70. Kg4 Rf1 71. h6 Rh1 72. Kg5 Rh3 73. Nh4 Rg3+ 74. Kf6 Rg4 75. Nf5+ Kc5 76. h7 *",
          "neutral_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 581,
            "total_tokens": 728,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd5",
            "Re3+",
            "Kg4",
            "Re2",
            "Nf3",
            "Rg2+",
            "Kf5",
            "Rf2",
            "Kg4",
            "Rg2+",
            "Kh3",
            "Rf2",
            "Kg3",
            "Rf1",
            "h5",
            "Rh1",
            "Kg4",
            "Rf1",
            "h6",
            "Rh1",
            "Kg5",
            "Rh3",
            "Nh4",
            "Rg3+",
            "Kf6",
            "Rg4",
            "Nf5+",
            "Kc5",
            "h7"
          ],
          "plan_execute": [
            "Bd5",
            "Re3+",
            "Kg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1e1",
          "positional_uci": "f1e1",
          "neutral_uci": "f1e1",
          "consensus_move": "f1e1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bc8+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+",
              "Ke7",
              "Bg5+",
              "Kf8",
              "Bf4+"
            ],
            "execute": [
              "Qh4",
              "g3",
              "Qh3"
            ]
          },
          "positional": {
            "full": [
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#",
              "e5",
              "dxe5",
              "Qd8+",
              "Bf8",
              "Qxd8#"
            ],
            "execute": [
              "Qh4",
              "g3",
              "Qh3"
            ]
          },
          "neutral": {
            "full": [
              "Bd5",
              "Re3+",
              "Kg4",
              "Re2",
              "Nf3",
              "Rg2+",
              "Kf5",
              "Rf2",
              "Kg4",
              "Rg2+",
              "Kh3",
              "Rf2",
              "Kg3",
              "Rf1",
              "h5",
              "Rh1",
              "Kg4",
              "Rf1",
              "h6",
              "Rh1",
              "Kg5",
              "Rh3",
              "Nh4",
              "Rg3+",
              "Kf6",
              "Rg4",
              "Nf5+",
              "Kc5",
              "h7"
            ],
            "execute": [
              "Bd5",
              "Re3+",
              "Kg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Qh4",
            "g3",
            "Qh3"
          ],
          "full_moves": [
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bc8+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+",
            "Ke7",
            "Bg5+",
            "Kf8",
            "Bf4+"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 147,
            "completion_tokens": 581,
            "total_tokens": 728,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 443,
          "total_completion_tokens": 1861,
          "total_tokens": 2304
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 147,
            "completion_tokens": 581,
            "total_tokens": 728,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 w kq - 4 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb3",
          "aggressive_uci": "a4b3",
          "aggressive_response": "7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Qh5 18. a4 Re6 19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5 22. c4 bxc4 23. Qxc4 Qh5 24. Rxc6 Rxc6 25. Qxc6 Ba5 26. Ra1 Bxd2 27. Bxd2 Bf3 28. Qc4 Bd5 29. Qd3 Re8 30. Re1 Rxe1+ 31. Bxe1 Qh3 32. Qf1 Qg4 33. Bc3 Qf3 34. Qh3 Qh1# e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d5 exd5 Nxd5 Nxe5 Nxe5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Qh5 a4 Re6 axb5 axb5 Ra6 Bc7 Bxd5 Qxd5 Qxc6 Ba5 Ra8 Bxd2 Bxd2 Bf3 Qc4 Bd5 Qd3 Qh5 Rxc6 Bxc6 Qxc6 Qd1+ Kg2 Qxd2 Qxb5 Qd4 b4 Qe4 Qc5 Qc6 Qxc6 bxc6 Rc8 Kf1 Rxc6 Ke2 Rc3 Kd2 Ra3 Ke2 f5 Kf1 Kf7 Kg2 Ke6 h3 Ke5 h4 Ke4 Kh3 Kf3 h5 Ra1 Kh4 Rh1# e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d5 exd5 Nxd5 Nxe5 Nxe5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Qh5 a4 Re6 axb5 axb5 Ra6 Bc7 Bxd5 Qxd5 Qxc6 Ba5 Ra8 Bxd2 Bxd2 Bf3 Qc4 Bd5 Qd3 Qh5 Rxc6 Bxc6 Qxc6 Qd1+ Kg2 Qxd2 Qxb5 Qd4 b4 Qe4 Qc5 Qc6 Qxc6 bxc6 Rc8 Kf1 Rxc6 Ke",
          "aggressive_tokens": {
            "prompt_tokens": 155,
            "completion_tokens": 640,
            "total_tokens": 795,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Qh5",
            "a4",
            "Re6",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bxd5",
            "Qxd5",
            "Qxc6",
            "Ba5",
            "Ra8",
            "Bxd2",
            "Bxd2",
            "Bf3",
            "Qc4",
            "Bd5",
            "Qd3",
            "Qh5",
            "Rxc6",
            "Bxc6",
            "Qxc6",
            "Qd1+",
            "Kg2",
            "Qxd2",
            "Qxb5",
            "Qd4",
            "b4",
            "Qe4",
            "Qc5",
            "Qc6",
            "Qxc6",
            "bxc6",
            "Rc8",
            "Kf1",
            "Rxc6"
          ],
          "plan_execute": [
            "O-O",
            "c3",
            "d5"
          ]
        },
        "query2": {
          "positional_move": "Bb3",
          "positional_uci": "a4b3",
          "positional_response": "7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ 33. Qe1 Qd3+ 34. Qe2 Bg2+ 35. Ke1 Qb1+ 36. Qd1 Re6+ 37. Be3 Qxb2 38. Qd2 Qb1+ 39. Qd1 Qe4 40. Qd2 Bf4 41. Kd1 Bxe3 42. fxe3 Qb1+ 43. Qc1 Bf3+ 44. Kd2 Qa2+ 45. Qc2 Qc4 46. Qd3 Qa2+ 47. Qc2 Qa1 48. Qc1 Qa4 49. Qc2 Qc4 50. Qd3 Qa2+ 51. Qc2 Qa1 52. Qc1 Qa4 53. Qc2 Qa3 54. Qc1 Qa2+ 55. Qc2 Qa1 56. Qc1 Qa4 57. Qc2 Qa3 58. Qc1 Qa2+ 59. Qc2 Qa1 60. Qc1 Qa4 61. Qc2 Qa3 62. Qc1 Qa2+ 63. Qc2 Qa1 64. Qc1 Qa4 65. Qc2 Qa3 66. Qc1 Qa2+ 67. Qc2 Qa1 68. Qc1 Qa4 69. Qc2 Qa3 70. Qc1 Qa2+ 71. Qc2 Qa1 72. Qc1 Qa4 73. Qc2 Qa3 74. Qc1 Qa2+ 75. Qc2 Qa1 76. Qc1 Qa4",
          "positional_tokens": {
            "prompt_tokens": 155,
            "completion_tokens": 640,
            "total_tokens": 795,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Qe1",
            "Qd3+",
            "Qe2",
            "Bg2+",
            "Ke1",
            "Qb1+",
            "Qd1",
            "Re6+",
            "Be3",
            "Qxb2",
            "Qd2",
            "Qb1+",
            "Qd1",
            "Qe4",
            "Qd2",
            "Bf4",
            "Kd1",
            "Bxe3",
            "fxe3",
            "Qb1+",
            "Qc1",
            "Bf3+",
            "Kd2",
            "Qa2+",
            "Qc2",
            "Qc4",
            "Qd3",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qc4",
            "Qd3",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4"
          ],
          "plan_execute": [
            "O-O",
            "c3",
            "d5"
          ]
        },
        "query3": {
          "neutral_move": "Bb3",
          "neutral_uci": "a4b3",
          "neutral_response": "7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Bf3 29. Rxb8+ Re8 30. Rxe8# Bf8 31. Ng3 Bxg2+ 32. Kxg2 Qd5+ 33. f3 Re6 34. Rb8 h6 35. Ne4 Rxe4 36. fxe4 Qxe4+ 37. Kg3+ Kh7 38. Rxb5 g5 39. Be5 f5 40. Rb8 f4+ 41. Kf2 Qe3+ 42. Kf1 f3 43. Rb7+ Kg6 44. Rg7+ Kh5 45. Bg3 Qe2+ 46. Kg1 Qg2# e4 d5 Nc3 Nf6 Bg5 O-O Nxe5 Nxe5 Rxe5 c6 Bd6 Qh4 g3 Qh3 Be3 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd3 Bf5 Qe2 Bg4 Qd",
          "neutral_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "Bf8",
            "Ng3",
            "Bxg2+",
            "Kxg2",
            "Qd5+",
            "f3",
            "Re6",
            "Rb8",
            "h6",
            "Ne4",
            "Rxe4",
            "fxe4",
            "Qxe4+",
            "Kg3+",
            "Kh7",
            "Rxb5",
            "g5",
            "Be5",
            "f5",
            "Rb8",
            "f4+",
            "Kf2",
            "Qe3+",
            "Kf1",
            "f3",
            "Rb7+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Bg3",
            "Qe2+",
            "Kg1",
            "Qg2#",
            "e4",
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "O-O",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "Bd6",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4"
          ],
          "plan_execute": [
            "O-O",
            "c3",
            "d5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a4b3",
          "positional_uci": "a4b3",
          "neutral_uci": "a4b3",
          "consensus_move": "a4b3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Qh5",
              "a4",
              "Re6",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bxd5",
              "Qxd5",
              "Qxc6",
              "Ba5",
              "Ra8",
              "Bxd2",
              "Bxd2",
              "Bf3",
              "Qc4",
              "Bd5",
              "Qd3",
              "Qh5",
              "Rxc6",
              "Bxc6",
              "Qxc6",
              "Qd1+",
              "Kg2",
              "Qxd2",
              "Qxb5",
              "Qd4",
              "b4",
              "Qe4",
              "Qc5",
              "Qc6",
              "Qxc6",
              "bxc6",
              "Rc8",
              "Kf1",
              "Rxc6"
            ],
            "execute": [
              "O-O",
              "c3",
              "d5"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Qe1",
              "Qd3+",
              "Qe2",
              "Bg2+",
              "Ke1",
              "Qb1+",
              "Qd1",
              "Re6+",
              "Be3",
              "Qxb2",
              "Qd2",
              "Qb1+",
              "Qd1",
              "Qe4",
              "Qd2",
              "Bf4",
              "Kd1",
              "Bxe3",
              "fxe3",
              "Qb1+",
              "Qc1",
              "Bf3+",
              "Kd2",
              "Qa2+",
              "Qc2",
              "Qc4",
              "Qd3",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qc4",
              "Qd3",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4"
            ],
            "execute": [
              "O-O",
              "c3",
              "d5"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "Bf8",
              "Ng3",
              "Bxg2+",
              "Kxg2",
              "Qd5+",
              "f3",
              "Re6",
              "Rb8",
              "h6",
              "Ne4",
              "Rxe4",
              "fxe4",
              "Qxe4+",
              "Kg3+",
              "Kh7",
              "Rxb5",
              "g5",
              "Be5",
              "f5",
              "Rb8",
              "f4+",
              "Kf2",
              "Qe3+",
              "Kf1",
              "f3",
              "Rb7+",
              "Kg6",
              "Rg7+",
              "Kh5",
              "Bg3",
              "Qe2+",
              "Kg1",
              "Qg2#",
              "e4",
              "d5",
              "Nc3",
              "Nf6",
              "Bg5",
              "O-O",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "Bd6",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4",
              "Qd3",
              "Bf5",
              "Qe2",
              "Bg4"
            ],
            "execute": [
              "O-O",
              "c3",
              "d5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "c3",
            "d5"
          ],
          "full_moves": [
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "Bf8",
            "Ng3",
            "Bxg2+",
            "Kxg2",
            "Qd5+",
            "f3",
            "Re6",
            "Rb8",
            "h6",
            "Ne4",
            "Rxe4",
            "fxe4",
            "Qxe4+",
            "Kg3+",
            "Kh7",
            "Rxb5",
            "g5",
            "Be5",
            "f5",
            "Rb8",
            "f4+",
            "Kf2",
            "Qe3+",
            "Kf1",
            "f3",
            "Rb7+",
            "Kg6",
            "Rg7+",
            "Kh5",
            "Bg3",
            "Qe2+",
            "Kg1",
            "Qg2#",
            "e4",
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "O-O",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "Bd6",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4",
            "Qd3",
            "Bf5",
            "Qe2",
            "Bg4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 155,
            "completion_tokens": 640,
            "total_tokens": 795,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 155,
            "completion_tokens": 640,
            "total_tokens": 795,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 464,
          "total_completion_tokens": 1920,
          "total_tokens": 2384
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 155,
            "completion_tokens": 640,
            "total_tokens": 795,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 155,
            "completion_tokens": 640,
            "total_tokens": 795,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2ppbppp/p1n2n2/1p2p3/B3P3/5N2/PPPP1PPP/RNBQR1K1 w kq - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c3",
          "aggressive_uci": "c2c3",
          "aggressive_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. d5 Ne7 25. Nh4 Rac8 26. Bg5 Kh8 27. Bxf6 gxf6 28. Qf3 Ng8 29. Nhf5 Qc7 30. Qg4 Bxf5 31. Nxf5 *\nBe7 32. Qg7#",
          "aggressive_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 202,
            "total_tokens": 365,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qf3",
            "Ng8",
            "Nhf5",
            "Qc7",
            "Qg4",
            "Bxf5",
            "Nxf5",
            "Be7",
            "Qg7#"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "query2": {
          "positional_move": "c3",
          "positional_uci": "c2c3",
          "positional_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Qa6 25. Bg5 Qa5 26. Qd1 Nxd4 27. Nxd4 exd4 28. Bxf6 gxf6 29. Nh5 Re6 30. Rf1 b4 31. f4 Kh8 32. f5 Re5 33. Nxf6 Qd8 34. Ng4 Bb5 35. Rf2 Qb6 36. Qd2 Rg8 37. Qh6 Rg7 38. Nxe5 Qc5 39. Nd3 Bxd3 40. Bxd3 b3 41. axb3 axb3 42. f6 Rg6 43. Qf8+ Rg8 44. Qxf7 Qc1+ 45. Kh2 Qe3 46. Qxg8+ Kxg8 47. Bc4+ Kf8 48. Rf3 Qxe4 49. f7 Qe5+ 50. Rg3 d5 51. Bxb3 Kxf7 52. Bc2 h5 53. h4 Qf4 54. Kh3 Ke6 55. Bd3 Kd6 56. b4 Kc6 57. Rg6+ Kb7 58. Rg3 Kb6 59. Rg6+ Kc7 60. Rg3 Kd6 61. Rg6+ Ke5 62. Rg5+ Ke6 63. Rg3 Qd2 64. b5 Ke5 65. Rg5+ Kf4 66. Rf5+ Ke3 67. Rf3# d6 e5 dxe5 dxe5 Qxe5+ g3 Qe6+ Kg2 Qxf3+ Kh2 Qf2+ Kh1 Qxg3 Bf1 Qxh3+ Kg1 Qg3+ Kh1 Qf3+ Kg1 Qg3+ Kh1 Qf3+ Kg1 Qg3+ Kh1 Qf3+ Kg1 Qg3+ Kh1 Qf3+ Kg1 Qg3+ Kh1 Qf3+ Kg1 Qg3+ Kh1 Qf3+ Kg1 Qg3+ Kh1 Qf3+ Kg1",
          "positional_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Qa6",
            "Bg5",
            "Qa5",
            "Qd1",
            "Nxd4",
            "Nxd4",
            "exd4",
            "Bxf6",
            "gxf6",
            "Nh5",
            "Re6",
            "Rf1",
            "b4",
            "f4",
            "Kh8",
            "f5",
            "Re5",
            "Nxf6",
            "Qd8",
            "Ng4",
            "Bb5",
            "Rf2",
            "Qb6",
            "Qd2",
            "Rg8",
            "Qh6",
            "Rg7",
            "Nxe5",
            "Qc5",
            "Nd3",
            "Bxd3",
            "Bxd3",
            "b3",
            "axb3",
            "axb3",
            "f6",
            "Rg6",
            "Qf8+",
            "Rg8",
            "Qxf7",
            "Qc1+",
            "Kh2",
            "Qe3",
            "Qxg8+",
            "Kxg8",
            "Bc4+",
            "Kf8",
            "Rf3",
            "Qxe4",
            "f7",
            "Qe5+",
            "Rg3",
            "d5",
            "Bxb3",
            "Kxf7",
            "Bc2",
            "h5",
            "h4",
            "Qf4",
            "Kh3",
            "Ke6",
            "Bd3",
            "Kd6",
            "b4",
            "Kc6",
            "Rg6+",
            "Kb7",
            "Rg3",
            "Kb6",
            "Rg6+",
            "Kc7",
            "Rg3",
            "Kd6",
            "Rg6+",
            "Ke5",
            "Rg5+",
            "Ke6",
            "Rg3",
            "Qd2",
            "b5",
            "Ke5",
            "Rg5+",
            "Kf4",
            "Rf5+",
            "Ke3",
            "Rf3#",
            "d6",
            "e5",
            "dxe5",
            "dxe5",
            "Qxe5+",
            "g3",
            "Qe6+",
            "Kg2",
            "Qxf3+",
            "Kh2",
            "Qf2+",
            "Kh1",
            "Qxg3",
            "Bf1",
            "Qxh3+",
            "Kg1",
            "Qg3+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qg3+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qg3+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qg3+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qg3+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qg3+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qg3+",
            "Kh1",
            "Qf3+",
            "Kg1"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "query3": {
          "neutral_move": "c3",
          "neutral_uci": "c2c3",
          "neutral_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6 43. Nd2 Kc5 44. a3 Ng6 45. g3 Bd7 46. h4 Nf8 47. Nb1 Ne6 48. Nc3 Nd4 49. Nd5 f5 50. Nf6 f4+ 51. gxf4 exf4+ 52. Kxf4 Be6 53. Nxh7 Bc4 54. Bxc4 Kxc4 55. Nf6 Kb3 56. h5 Kxb2 57. h6 Kxa3 58. h7 b4 59. h8=Q b3 60. Nd5 b2 61. Qxd4 b1=Q 62. Qc3+ Qb3 63. Qxb3+ axb3 64. e5 b2 65. Nc3 Kb3 66. Nb1 Kc2 67. e6 Kxb1 68. e7 Ka2 69. e8=Q b1=Q 70. Qa4+ Kb2 71. Qb4+ Kc2 72. Qxb1+ Kxb1 73. Ke5 Kc2 74. f4 Kd3 75. f5 Ke3 76. f6 Kf3 77. f7 Ke3 78. f8=Q Kd3 79. Qf4 Kc3 80. Qd4+ Kb3 81. Kd5 Kc2 82. Qe3 Kb2 83. Kc4 Kc2 84. Qe2+",
          "neutral_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 640,
            "total_tokens": 802,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Ng6",
            "g3",
            "Bd7",
            "h4",
            "Nf8",
            "Nb1",
            "Ne6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "gxf4",
            "exf4+",
            "Kxf4",
            "Be6",
            "Nxh7",
            "Bc4",
            "Bxc4",
            "Kxc4",
            "Nf6",
            "Kb3",
            "h5",
            "Kxb2",
            "h6",
            "Kxa3",
            "h7",
            "b4",
            "h8=Q",
            "b3",
            "Nd5",
            "b2",
            "Qxd4",
            "b1=Q",
            "Qc3+",
            "Qb3",
            "Qxb3+",
            "axb3",
            "e5",
            "b2",
            "Nc3",
            "Kb3",
            "Nb1",
            "Kc2",
            "e6",
            "Kxb1",
            "e7",
            "Ka2",
            "e8=Q",
            "b1=Q",
            "Qa4+",
            "Kb2",
            "Qb4+",
            "Kc2",
            "Qxb1+",
            "Kxb1",
            "Ke5",
            "Kc2",
            "f4",
            "Kd3",
            "f5",
            "Ke3",
            "f6",
            "Kf3",
            "f7",
            "Ke3",
            "f8=Q",
            "Kd3",
            "Qf4",
            "Kc3",
            "Qd4+",
            "Kb3",
            "Kd5",
            "Kc2",
            "Qe3",
            "Kb2",
            "Kc4",
            "Kc2",
            "Qe2+"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c2c3",
          "positional_uci": "c2c3",
          "neutral_uci": "c2c3",
          "consensus_move": "c2c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "d5",
              "Ne7",
              "Nh4",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qf3",
              "Ng8",
              "Nhf5",
              "Qc7",
              "Qg4",
              "Bxf5",
              "Nxf5",
              "Be7",
              "Qg7#"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Qa6",
              "Bg5",
              "Qa5",
              "Qd1",
              "Nxd4",
              "Nxd4",
              "exd4",
              "Bxf6",
              "gxf6",
              "Nh5",
              "Re6",
              "Rf1",
              "b4",
              "f4",
              "Kh8",
              "f5",
              "Re5",
              "Nxf6",
              "Qd8",
              "Ng4",
              "Bb5",
              "Rf2",
              "Qb6",
              "Qd2",
              "Rg8",
              "Qh6",
              "Rg7",
              "Nxe5",
              "Qc5",
              "Nd3",
              "Bxd3",
              "Bxd3",
              "b3",
              "axb3",
              "axb3",
              "f6",
              "Rg6",
              "Qf8+",
              "Rg8",
              "Qxf7",
              "Qc1+",
              "Kh2",
              "Qe3",
              "Qxg8+",
              "Kxg8",
              "Bc4+",
              "Kf8",
              "Rf3",
              "Qxe4",
              "f7",
              "Qe5+",
              "Rg3",
              "d5",
              "Bxb3",
              "Kxf7",
              "Bc2",
              "h5",
              "h4",
              "Qf4",
              "Kh3",
              "Ke6",
              "Bd3",
              "Kd6",
              "b4",
              "Kc6",
              "Rg6+",
              "Kb7",
              "Rg3",
              "Kb6",
              "Rg6+",
              "Kc7",
              "Rg3",
              "Kd6",
              "Rg6+",
              "Ke5",
              "Rg5+",
              "Ke6",
              "Rg3",
              "Qd2",
              "b5",
              "Ke5",
              "Rg5+",
              "Kf4",
              "Rf5+",
              "Ke3",
              "Rf3#",
              "d6",
              "e5",
              "dxe5",
              "dxe5",
              "Qxe5+",
              "g3",
              "Qe6+",
              "Kg2",
              "Qxf3+",
              "Kh2",
              "Qf2+",
              "Kh1",
              "Qxg3",
              "Bf1",
              "Qxh3+",
              "Kg1",
              "Qg3+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qg3+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qg3+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qg3+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qg3+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qg3+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qg3+",
              "Kh1",
              "Qf3+",
              "Kg1"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Ng6",
              "g3",
              "Bd7",
              "h4",
              "Nf8",
              "Nb1",
              "Ne6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "f4+",
              "gxf4",
              "exf4+",
              "Kxf4",
              "Be6",
              "Nxh7",
              "Bc4",
              "Bxc4",
              "Kxc4",
              "Nf6",
              "Kb3",
              "h5",
              "Kxb2",
              "h6",
              "Kxa3",
              "h7",
              "b4",
              "h8=Q",
              "b3",
              "Nd5",
              "b2",
              "Qxd4",
              "b1=Q",
              "Qc3+",
              "Qb3",
              "Qxb3+",
              "axb3",
              "e5",
              "b2",
              "Nc3",
              "Kb3",
              "Nb1",
              "Kc2",
              "e6",
              "Kxb1",
              "e7",
              "Ka2",
              "e8=Q",
              "b1=Q",
              "Qa4+",
              "Kb2",
              "Qb4+",
              "Kc2",
              "Qxb1+",
              "Kxb1",
              "Ke5",
              "Kc2",
              "f4",
              "Kd3",
              "f5",
              "Ke3",
              "f6",
              "Kf3",
              "f7",
              "Ke3",
              "f8=Q",
              "Kd3",
              "Qf4",
              "Kc3",
              "Qd4+",
              "Kb3",
              "Kd5",
              "Kc2",
              "Qe3",
              "Kb2",
              "Kc4",
              "Kc2",
              "Qe2+"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "h3",
            "Na5"
          ],
          "full_moves": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Ng6",
            "g3",
            "Bd7",
            "h4",
            "Nf8",
            "Nb1",
            "Ne6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "gxf4",
            "exf4+",
            "Kxf4",
            "Be6",
            "Nxh7",
            "Bc4",
            "Bxc4",
            "Kxc4",
            "Nf6",
            "Kb3",
            "h5",
            "Kxb2",
            "h6",
            "Kxa3",
            "h7",
            "b4",
            "h8=Q",
            "b3",
            "Nd5",
            "b2",
            "Qxd4",
            "b1=Q",
            "Qc3+",
            "Qb3",
            "Qxb3+",
            "axb3",
            "e5",
            "b2",
            "Nc3",
            "Kb3",
            "Nb1",
            "Kc2",
            "e6",
            "Kxb1",
            "e7",
            "Ka2",
            "e8=Q",
            "b1=Q",
            "Qa4+",
            "Kb2",
            "Qb4+",
            "Kc2",
            "Qxb1+",
            "Kxb1",
            "Ke5",
            "Kc2",
            "f4",
            "Kd3",
            "f5",
            "Ke3",
            "f6",
            "Kf3",
            "f7",
            "Ke3",
            "f8=Q",
            "Kd3",
            "Qf4",
            "Kc3",
            "Qd4+",
            "Kb3",
            "Kd5",
            "Kc2",
            "Qe3",
            "Kb2",
            "Kc4",
            "Kc2",
            "Qe2+"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 163,
            "completion_tokens": 202,
            "total_tokens": 365,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 162,
            "completion_tokens": 640,
            "total_tokens": 802,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 488,
          "total_completion_tokens": 1482,
          "total_tokens": 1970
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 163,
            "completion_tokens": 202,
            "total_tokens": 365,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 162,
            "completion_tokens": 640,
            "total_tokens": 802,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 w kq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc2",
          "aggressive_uci": "b3c2",
          "aggressive_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. Ng3 g6 16. b3 Nb6 17. Bh6 Rfe8 18. Qd2 c4 19. b4 a5 20. a3 Ra7 21. Nh2 Rea8 22. Rac1 axb4 23. axb4 Ra2 24. f4 exf4 25. Qxf4 Na4 26. Bb1 Ra3 27. Ne2 Nh5 28. Qf2 Bf6 29. Rf1 Be8 30. g4 Bxc3 31. gxh5 Bxb4 32. hxg6 hxg6 33. Qf6 Bc5+ 34. Kh1 Bd4 35. Nxd4 Rxh3 36. Qg7# e4 Nf6+ Kh8 Qxh7# e5 Nxe5 Qh7# e6 Nf6+ Kh8 Qxh7# e7 Nxe7 Qh7# e8=Q Nxe8 Qh7# e5 Nf6+ Kh8 Qxh7# e6 Nf6+ Kh8 Qxh7# e7 Nxe7 Qh7# e8=Q Nxe8 Qh7# e5 Nf6+ Kh8 Qxh7# e6 Nf6+ Kh8 Qxh7# e7 Nxe7 Qh7# e8=Q Nxe8 Qh7# e5 Nf6+ Kh8 Qxh7# e6 Nf6+ Kh8 Qxh7# e7 Nxe7 Qh7# e8=Q Nxe8 Qh7# e5 Nf6+ Kh8 Qxh7# e6 Nf6+ Kh8 Qxh7# e7 Nxe7 Qh7# e8=Q Nxe8 Qh7# e5 Nf6+ Kh8 Qxh7# e6 Nf6+ Kh8 Qxh7# e7 Nxe7 Qh7# e8=Q Nxe8 Qh7# e5 Nf6+ Kh8 Qxh7# e6 Nf6+ Kh8 Qxh7# e7 Nxe7 Qh7# e8=Q Nxe8 Qh7# e5 Nf6+ Kh8 Qxh7# e6 Nf6+ Kh8 Qxh7# e7 Nxe7 Qh7# e8=Q Nxe8 Qh7# e5 Nf6+ Kh8 Qxh7# e6 Nf6+ Kh8 Qxh7# e7 Nxe7 Qh7# e8=Q N",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "Ng3",
            "g6",
            "b3",
            "Nb6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "c4",
            "b4",
            "a5",
            "a3",
            "Ra7",
            "Nh2",
            "Rea8",
            "Rac1",
            "axb4",
            "axb4",
            "Ra2",
            "f4",
            "exf4",
            "Qxf4",
            "Na4",
            "Bb1",
            "Ra3",
            "Ne2",
            "Nh5",
            "Qf2",
            "Bf6",
            "Rf1",
            "Be8",
            "g4",
            "Bxc3",
            "gxh5",
            "Bxb4",
            "hxg6",
            "hxg6",
            "Qf6",
            "Bc5+",
            "Kh1",
            "Bd4",
            "Nxd4",
            "Rxh3",
            "Qg7#",
            "e4",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e5",
            "Nxe5",
            "Qh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "query2": {
          "positional_move": "Bc2",
          "positional_uci": "b3c2",
          "positional_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. b3 Nb6 16. Ng3 g6 17. Bh6 Rfe8 18. Qd2 Bf8 19. Bxf8 Rxf8 20. Qh6 Kh8 21. Ng5 Be8 22. Re3 Rg8 23. Rf3 Qe7 24. Rxf6 Rg7 25. Rf3 f6 26. Ne6 Rf7 27. h4 Bd7 28. h5 Bxe6 29. hxg6 Rg7 30. dxe6 Rxg6 31. Qh4 Qxe6 32. Nf5 Rag8 33. g3 d5 34. Kg2 d4 35. Rh1 Qd7 36. cxd4 cxd4 37. Bd3 Nc8 38. Nh6 Rf8 39. Rf5 Nd6 40. Rh5 Rg7 41. Nf5 Nxf5 42. Rxf5 Qe7 43. Rc1 Rg6 44. Rc6 Kg7 45. Rxa6 Rh6 46. Qg4+ Rg6 47. Qf3 Qb7 48. Re6 Qd7 49. Rb6 Qa7 50. Rxb5 Qxa2 51. Rb7+ Kh8 52. Rh5 Rg7 53. Rxg7 Kxg7 54. Qg4+ Kh8 55. Qd7 1-0\n\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 d6 c3 Na5 Bc2 c5 d4 Qc7 Nbd2 O-O Nf1 Bg4 d5 Nc4 h3 Bd7 b3 Nb6 Ng3 g6 Bh6 Rfe8 Qd2 Bf8 Bxf8 Rxf8 Qh6 Kh8 Ng5 Be8 Re3 Rg8 Rf3 Qe7 Rxf6 Rg7 Rf3 f6 Ne6 Rg8 h4 Bd7 h5 Bxe6 hxg6 Rg7 dxe6 Rxg6 Nf5 Qxe6 Rh3 Qg8 Ne7 Rxg2+ Qxg2 Qxg2+ Kxg2 Re8 Nf5 Rg8+ Rg3 Nd7 Rxg8+ Kxg8 Nxd6 Kf8 Rh1 Ke7 Nf5+ Ke6 Rxh7 Nf8 Re7#",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 617,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "Re3",
            "Rg8",
            "Rf3",
            "Qe7",
            "Rxf6",
            "Rg7",
            "Rf3",
            "f6",
            "Ne6",
            "Rg8",
            "h4",
            "Bd7",
            "h5",
            "Bxe6",
            "hxg6",
            "Rg7",
            "dxe6",
            "Rxg6",
            "Nf5",
            "Qxe6",
            "Rh3",
            "Qg8",
            "Ne7",
            "Rxg2+",
            "Qxg2",
            "Qxg2+",
            "Kxg2",
            "Re8",
            "Nf5",
            "Rg8+",
            "Rg3",
            "Nd7",
            "Rxg8+",
            "Kxg8",
            "Nxd6",
            "Kf8",
            "Rh1",
            "Ke7",
            "Nf5+",
            "Ke6",
            "Rxh7",
            "Nf8",
            "Re7#"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "query3": {
          "neutral_move": "Bc2",
          "neutral_uci": "b3c2",
          "neutral_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. Ng3 g6 16. b3 Nb6 17. Bh6 Rfe8 18. Qd2 c4 19. b4 a5 20. a3 Ra7 21. Nh2 Rea8 22. Rac1 axb4 23. axb4 Ra2 24. f4 exf4 25. Qxf4 Be8 26. Rf1 Nbd7 27. Nf5 Ne5 28. Nxe7+ Qxe7 29. Qxf6 Qxf6 30. Rxf6 R8a6 31. Nf3 Nd7 32. Rf4 f6 33. Nd4 g5 34. Rf2 Rb6 35. Rcf1 Bg6 36. Bb1 Rxf2 37. Rxf2 Kf7 38. Bxg5 Ra6 39. Bc2 Ra1+ 40. Kh2 Ra3 41. Bd2 Ra2 42. Bf4 Ne5 43. Bxe5 dxe5 44. Nxb5 Ke7 45. d6+ Kd7 46. Rd2 Bf7 47. Nc7 Ra3 48. Nd5 Bxd5 49. Rxd5 Rxc3 50. Ba4+ Kd8 51. d7 Rd3 52. Rc5 Rd4 53. Rc8+ Ke7 54. Re8+ Kf7 55. d8=Q Rxd8 56. Rxd8 c3 57. Rc8 c2 58. Rxc2 f5 59. exf5 Kf6 60. g4 h5 61. Kg3 hxg4 62. hxg4 Kg5 63. Rc6 e4 64. Rg6# c5 dxc6 dxc6 dxc6",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 466,
            "total_tokens": 636,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ra1+",
            "Kh2",
            "Ra3",
            "Bd2",
            "Ra2",
            "Bf4",
            "Ne5",
            "Bxe5",
            "dxe5",
            "Nxb5",
            "Ke7",
            "d6+",
            "Kd7",
            "Rd2",
            "Bf7",
            "Nc7",
            "Ra3",
            "Nd5",
            "Bxd5",
            "Rxd5",
            "Rxc3",
            "Ba4+",
            "Kd8",
            "d7",
            "Rd3",
            "Rc5",
            "Rd4",
            "Rc8+",
            "Ke7",
            "Re8+",
            "Kf7",
            "d8=Q",
            "Rxd8",
            "Rxd8",
            "c3",
            "Rc8",
            "c2",
            "Rxc2",
            "f5",
            "exf5",
            "Kf6",
            "g4",
            "h5",
            "Kg3",
            "hxg4",
            "hxg4",
            "Kg5",
            "Rc6",
            "e4",
            "Rg6#",
            "c5",
            "dxc6",
            "dxc6",
            "dxc6"
          ],
          "plan_execute": [
            "Ra1+",
            "Kh2",
            "Ra3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b3c2",
          "positional_uci": "b3c2",
          "neutral_uci": "b3c2",
          "consensus_move": "b3c2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "Ng3",
              "g6",
              "b3",
              "Nb6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "c4",
              "b4",
              "a5",
              "a3",
              "Ra7",
              "Nh2",
              "Rea8",
              "Rac1",
              "axb4",
              "axb4",
              "Ra2",
              "f4",
              "exf4",
              "Qxf4",
              "Na4",
              "Bb1",
              "Ra3",
              "Ne2",
              "Nh5",
              "Qf2",
              "Bf6",
              "Rf1",
              "Be8",
              "g4",
              "Bxc3",
              "gxh5",
              "Bxb4",
              "hxg6",
              "hxg6",
              "Qf6",
              "Bc5+",
              "Kh1",
              "Bd4",
              "Nxd4",
              "Rxh3",
              "Qg7#",
              "e4",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e5",
              "Nxe5",
              "Qh7#",
              "e6",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e7",
              "Nxe7",
              "Qh7#",
              "e8=Q",
              "Nxe8",
              "Qh7#",
              "e5",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e6",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e7",
              "Nxe7",
              "Qh7#",
              "e8=Q",
              "Nxe8",
              "Qh7#",
              "e5",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e6",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e7",
              "Nxe7",
              "Qh7#",
              "e8=Q",
              "Nxe8",
              "Qh7#",
              "e5",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e6",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e7",
              "Nxe7",
              "Qh7#",
              "e8=Q",
              "Nxe8",
              "Qh7#",
              "e5",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e6",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e7",
              "Nxe7",
              "Qh7#",
              "e8=Q",
              "Nxe8",
              "Qh7#",
              "e5",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e6",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e7",
              "Nxe7",
              "Qh7#",
              "e8=Q",
              "Nxe8",
              "Qh7#",
              "e5",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e6",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e7",
              "Nxe7",
              "Qh7#",
              "e8=Q",
              "Nxe8",
              "Qh7#",
              "e5",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e6",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e7",
              "Nxe7",
              "Qh7#",
              "e8=Q",
              "Nxe8",
              "Qh7#",
              "e5",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e6",
              "Nf6+",
              "Kh8",
              "Qxh7#",
              "e7",
              "Nxe7",
              "Qh7#",
              "e8=Q"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          },
          "positional": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "b3",
              "Nb6",
              "Ng3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "Bf8",
              "Bxf8",
              "Rxf8",
              "Qh6",
              "Kh8",
              "Ng5",
              "Be8",
              "Re3",
              "Rg8",
              "Rf3",
              "Qe7",
              "Rxf6",
              "Rg7",
              "Rf3",
              "f6",
              "Ne6",
              "Rg8",
              "h4",
              "Bd7",
              "h5",
              "Bxe6",
              "hxg6",
              "Rg7",
              "dxe6",
              "Rxg6",
              "Nf5",
              "Qxe6",
              "Rh3",
              "Qg8",
              "Ne7",
              "Rxg2+",
              "Qxg2",
              "Qxg2+",
              "Kxg2",
              "Re8",
              "Nf5",
              "Rg8+",
              "Rg3",
              "Nd7",
              "Rxg8+",
              "Kxg8",
              "Nxd6",
              "Kf8",
              "Rh1",
              "Ke7",
              "Nf5+",
              "Ke6",
              "Rxh7",
              "Nf8",
              "Re7#"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          },
          "neutral": {
            "full": [
              "Ra1+",
              "Kh2",
              "Ra3",
              "Bd2",
              "Ra2",
              "Bf4",
              "Ne5",
              "Bxe5",
              "dxe5",
              "Nxb5",
              "Ke7",
              "d6+",
              "Kd7",
              "Rd2",
              "Bf7",
              "Nc7",
              "Ra3",
              "Nd5",
              "Bxd5",
              "Rxd5",
              "Rxc3",
              "Ba4+",
              "Kd8",
              "d7",
              "Rd3",
              "Rc5",
              "Rd4",
              "Rc8+",
              "Ke7",
              "Re8+",
              "Kf7",
              "d8=Q",
              "Rxd8",
              "Rxd8",
              "c3",
              "Rc8",
              "c2",
              "Rxc2",
              "f5",
              "exf5",
              "Kf6",
              "g4",
              "h5",
              "Kg3",
              "hxg4",
              "hxg4",
              "Kg5",
              "Rc6",
              "e4",
              "Rg6#",
              "c5",
              "dxc6",
              "dxc6",
              "dxc6"
            ],
            "execute": [
              "Ra1+",
              "Kh2",
              "Ra3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "c5",
            "d4",
            "Qc7"
          ],
          "full_moves": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "Ng3",
            "g6",
            "b3",
            "Nb6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "c4",
            "b4",
            "a5",
            "a3",
            "Ra7",
            "Nh2",
            "Rea8",
            "Rac1",
            "axb4",
            "axb4",
            "Ra2",
            "f4",
            "exf4",
            "Qxf4",
            "Na4",
            "Bb1",
            "Ra3",
            "Ne2",
            "Nh5",
            "Qf2",
            "Bf6",
            "Rf1",
            "Be8",
            "g4",
            "Bxc3",
            "gxh5",
            "Bxb4",
            "hxg6",
            "hxg6",
            "Qf6",
            "Bc5+",
            "Kh1",
            "Bd4",
            "Nxd4",
            "Rxh3",
            "Qg7#",
            "e4",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e5",
            "Nxe5",
            "Qh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q",
            "Nxe8",
            "Qh7#",
            "e5",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e6",
            "Nf6+",
            "Kh8",
            "Qxh7#",
            "e7",
            "Nxe7",
            "Qh7#",
            "e8=Q"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 617,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 466,
            "total_tokens": 636,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1723,
          "total_tokens": 2235
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 617,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 466,
            "total_tokens": 636,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/np2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 w kq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d3",
          "aggressive_uci": "d2d3",
          "aggressive_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 Bg4 13. h3 Bh5 14. Ng3 Bg6 15. Nh4 Nfd7 16. Nhf5 Bxf5 17. Nxf5 Bg5 18. Qg4 h6 19. h4 Nf6 20. Qg3 Nh5 21. Qg4 Nf6 22. Qh3 Bxc1 23. Raxc1 Kh7 24. d4 g6 25. Ng3 Qd7 26. Qh2 Ng4 27. Qh1 exd4 28. cxd4 Nc4 29. b3 Na3 30. Bd3 b4 31. h5 Nb5 32. hxg6+ fxg6 33. f3 Nf6 34. e5 dxe5 35. dxe5 Qxd3 36. exf6 Rxf6 37. Re7+ Kg8 38. Qxh6 Qd4+ 39. Kh1 Rf7 40. Qxg6+ Qg7 41. Qxg7+ Kxg7 42. Rxf7+ Kxf7 43. Ne4 Rh8+ 44. Kg1 Ke6 45. Rc6+ Kd5 46. Rxa6 Nc3 47. Nxc3+ bxc3 48. Ra4 c2 49. Rc4 Ra8 50. Rxc2 c5 51. Kf2 Kd4 52. g4 Kd3 53. Rxc5 Rxa2+ 54. Kg3 Kd4 55. Rc4+ Kd5 56. g5 Ra1 57. Kf4 Rg1 58. Kf5 Rg3 59. f4 Rxb3 60. Re4 Rb8 61. Re5+ Kd6 62. g6 Rf8+ 63. Kg5 Rg8 64. Re1 Kd7 65. f5 Re8 66. Rxe8 Kxe8 67. f6 Kf8 68. Kh6 Kg8 69. f7+ Kf8 70. Kh7 Ke7 71. Kg8 Kf6 72. g7 Kg6 73. f8=Q Kh6 74. Kf7 Kh7 75. g8=Q# 1-0 10. d3 Nb6 11. Nbd2 O-O 12. Nf1 Bg4 13. h3 Bh5 14. Ng3 Bg6 15. Nh4 Nfd7 16. Nhf5 Bxf5 17. Nxf5 Bg5 18. Qg4 h6 19. h4 Nf6 20",
          "aggressive_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "Nfd7",
            "Nhf5",
            "Bxf5",
            "Nxf5",
            "Bg5",
            "Qg4",
            "h6",
            "h4",
            "Nf6"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "d3",
          "positional_uci": "d2d3",
          "positional_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 c5 13. Ng3 Bg4 14. h3 Bxf3 15. Qxf3 Qd7 16. Nf5 g6 17. Nxe7+ Qxe7 18. Bg5 Kg7 19. Qe3 Rfe8 20. f4 exf4 21. Qxf4 Qe5 22. Qh4 Nh5 23. Rf1 f6 24. Be3 Nd7 25. g4 Ng3 26. Rf2 g5 27. d4 cxd4 28. cxd4 Qe6 29. Qxg3 Rac8 30. Raf1 Rf8 31. h4 h6 32. hxg5 hxg5 33. Rh2 Rh8 34. Rxh8 Rxh8 35. Rf2 Rh4 36. Rg2 Nb6 37. b3 a5 38. d5 Nxd5 39. exd5 Qxd5 40. Bf5 Qd1+ 41. Kf2 Rh1 42. Rg1 Rxg1 43. Qxg1 Qd5 44. Qh2 Qg8 45. Qxd6 Qf7 46. Bd4 a4 47. Be6 Qf8 48. Qd7+ Kh6 49. Bf5 Qg7 50. Qxg7+ Kxg7 51. bxa4 bxa4 52. Bd7 a3 53. Bc5 Kf7 54. Bxa3 Kg6 55. Bf5+ Kf7 56. Bb2 Ke7 57. a4 Kd6 58. Bxf6 Kc5 59. Bxg5 Kb4 60. Bd7 Ka5 61. Bd2+ Kb6 62. a5+ Ka6 63. g5 Kb7 64. g6 Kc7 65. Bb5 Kd6 66. g7 Ke7 67. g8=Q Kd6 68. Bb4+ Ke5 69. Qg5+ Kd4 70. Qc5+ Ke4 71. Bc6+ Kf4 72. Bd2+ Kg4 73. Bd7+ Kh4 74. Qg5# e5 Nf6 Nc6 Bb4 d6 Na5 Nc4 d3 Nb6 Nbd2 O-O Nf1 c5 Ng3 Bg4 h3 Bxf3 Qxf3 Qd7 Nf5 g6 Nxe7+ Qxe7 Bg5 Kg7 Qe3 Rfe8 f4 exf4 Qxf4 Qe5 Qh4 Nh5 Rf1 f6 Be3",
          "positional_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "c5",
            "Ng3",
            "Bg4",
            "h3",
            "Bxf3",
            "Qxf3",
            "Qd7",
            "Nf5",
            "g6",
            "Nxe7+",
            "Qxe7",
            "Bg5",
            "Kg7",
            "Qe3",
            "Rfe8",
            "f4",
            "exf4",
            "Qxf4",
            "Qe5",
            "Qh4",
            "Nh5",
            "Rf1",
            "f6",
            "Be3"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "d3",
          "neutral_uci": "d2d3",
          "neutral_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 c5 13. Ng3 Qc7 14. h3 Be6 15. Be3 Rfd8 16. Qe2 d5 17. exd5 Nbxd5 18. Bd2 Bd6 19. Ng5 Re8 20. Nxe6 Rxe6 21. Ne4 Nxe4 22. dxe4 Nf4 23. Bxf4 exf4 24. Rad1 Rae8 25. Qd3 Be5 26. Qd7 Qb6 27. Rd5 c4 28. Red1 g6 29. Kf1 Kg7 30. f3 Qe3 31. Re1 Qb6 32. Red1 Qe3 33. Re1 Qb6 34. Red1 Qe3 35. Re1 Qb6 36. Red1 Qe3 37. Re1 Qb6 38. Red1 Qe3 39. Re1 Qb6 40. Red1 Qe3 41. Re1 Qb6 42. Red1 Qe3 43. Re1 Qb6 44. Red1 Qe3 45. Re1 Qb6 46. Red1 Qe3 47. Re1 Qb6 48. Red1 Qe3 49. Re1 Qb6 50. Red1 Qe3 51. Re1 Qb6 52. Red1 Qe3 53. Re1 Qb6 54. Red1 Qe3 55. Re1 Qb6 56. Red1 Qe3 57. Re1 Qb6 58. Red1 Qe3 59. Re1 Qb6 60. Red1 Qe3 61. Re1 Qb6 62. Red1 Qe3 63. Re1 Qb6 64. Red1 Qe3 65. Re1 Qb6 66. Red1 Qe3 67. Re1 Qb6 68. Red1 Qe3 69. Re1 Qb6 70. Red1 Qe3 71. Re1 Qb6 72. Red1 Qe3 73. Re1 Qb6 74. Red1 Qe3 75. Re1 Qb6 76. Red1 Qe3 77. Re1 Qb6 78. Red1 Qe3 79. Re1 Qb6 80. Red1 Qe3 81. Re1 Qb6 82. Red1 Qe3 83. Re1 Qb6 84. Red1 Qe3 85. Re1 Qb6 86. Red1 Qe3 87. Re1 Qb6 88. Red1 Qe3 89. Re1 Qb6 90",
          "neutral_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "c5",
            "Ng3",
            "Qc7",
            "h3",
            "Be6",
            "Be3",
            "Rfd8",
            "Qe2",
            "d5",
            "exd5",
            "Nbxd5",
            "Bd2",
            "Bd6",
            "Ng5",
            "Re8",
            "Nxe6",
            "Rxe6",
            "Ne4",
            "Nxe4",
            "dxe4",
            "Nf4",
            "Bxf4",
            "exf4",
            "Rad1",
            "Rae8",
            "Qd3",
            "Be5",
            "Qd7",
            "Qb6",
            "Rd5",
            "c4",
            "Red1",
            "g6",
            "Kf1",
            "Kg7",
            "f3",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d2d3",
          "positional_uci": "d2d3",
          "neutral_uci": "d2d3",
          "consensus_move": "d2d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "Nfd7",
              "Nhf5",
              "Bxf5",
              "Nxf5",
              "Bg5",
              "Qg4",
              "h6",
              "h4",
              "Nf6"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "c5",
              "Ng3",
              "Bg4",
              "h3",
              "Bxf3",
              "Qxf3",
              "Qd7",
              "Nf5",
              "g6",
              "Nxe7+",
              "Qxe7",
              "Bg5",
              "Kg7",
              "Qe3",
              "Rfe8",
              "f4",
              "exf4",
              "Qxf4",
              "Qe5",
              "Qh4",
              "Nh5",
              "Rf1",
              "f6",
              "Be3"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "c5",
              "Ng3",
              "Qc7",
              "h3",
              "Be6",
              "Be3",
              "Rfd8",
              "Qe2",
              "d5",
              "exd5",
              "Nbxd5",
              "Bd2",
              "Bd6",
              "Ng5",
              "Re8",
              "Nxe6",
              "Rxe6",
              "Ne4",
              "Nxe4",
              "dxe4",
              "Nf4",
              "Bxf4",
              "exf4",
              "Rad1",
              "Rae8",
              "Qd3",
              "Be5",
              "Qd7",
              "Qb6",
              "Rd5",
              "c4",
              "Red1",
              "g6",
              "Kf1",
              "Kg7",
              "f3",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6",
              "Red1",
              "Qe3",
              "Re1",
              "Qb6"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nb6",
            "Nbd2",
            "O-O"
          ],
          "full_moves": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "c5",
            "Ng3",
            "Qc7",
            "h3",
            "Be6",
            "Be3",
            "Rfd8",
            "Qe2",
            "d5",
            "exd5",
            "Nbxd5",
            "Bd2",
            "Bd6",
            "Ng5",
            "Re8",
            "Nxe6",
            "Rxe6",
            "Ne4",
            "Nxe4",
            "dxe4",
            "Nf4",
            "Bxf4",
            "exf4",
            "Rad1",
            "Rae8",
            "Qd3",
            "Be5",
            "Qd7",
            "Qb6",
            "Rd5",
            "c4",
            "Red1",
            "g6",
            "Kf1",
            "Kg7",
            "f3",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6",
            "Red1",
            "Qe3",
            "Re1",
            "Qb6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 539,
          "total_completion_tokens": 1920,
          "total_tokens": 2459
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2P2N2/PPBP1PPP/RNBQR1K1 w kq - 3 10"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxb4",
          "aggressive_uci": "c3b4",
          "aggressive_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Nfxd5 19. Rxe5 Nxb4 20. Bb3+ Kh8 21. Qe2 Bf6 22. Re4 Nxd3 23. Be3 Nxb2 24. Rb1 Nd3 25. Rd1 Qd6 26. Rxd3 Qc6 27. Re6 Qb5 28. Bxb6 cxb6 29. Rd5 Qb4 30. Ne4 Bd4 31. Red6 Bc5 32. Nxc5 bxc5 33. Qc4 Qe1+ 34. Kh2 Qxf2 35. Rxc5 Rae8 36. Rc7 Re2 37. Qd5 Qf4+ 38. Kg1 Re1# 0-1\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Nfxd5 19. Rxe5 Nxb4 20. Bb3+ Kh8 21. Qe2 Bf6 22. Re4 Nxd3 23. Be3 Nxb2 24. Rb1 Nd3 25. Rd1 Qd6 26. Rxd3 Qc6 27. Re6 Qb5 28. Bxb6 cxb6 29. Rd5 Qb4 30. Ne4 Bd4 31. Red6 Bc5 32. Nxc5 bxc5 33. Qc4 Qe1+ 34. Kh2 Qxf2 35. Rxc5 Rae8 36. Rc7 Re2 37. Qd5 Qf4+ 38. Kg1 Re1# 0-1 d5 cxd5 Qxd5",
          "aggressive_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 553,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Qd6",
            "Rxd3",
            "Qc6",
            "Re6",
            "Qb5",
            "Bxb6",
            "cxb6",
            "Rd5",
            "Qb4",
            "Ne4",
            "Bd4",
            "Red6",
            "Bc5",
            "Nxc5",
            "bxc5",
            "Qc4",
            "Qe1+",
            "Kh2",
            "Qxf2",
            "Rxc5",
            "Rae8",
            "Rc7",
            "Re2",
            "Qd5",
            "Qf4+",
            "Kg1",
            "Re1#",
            "d5",
            "cxd5",
            "Qxd5"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "cxb4",
          "positional_uci": "c3b4",
          "positional_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. Bb3 Bxb4 19. Bd2 Bxd2 20. Qxd2 Kh8 21. exd5 Nbxd5 22. Rxe5 c6 23. Rae1 Qb6 24. Ne4 Nxe4 25. R1xe4 Nf6 26. Re2 Rad8 27. Qc3 Nd5 28. Bxd5 cxd5 29. Re7 d4 30. Qc7 Qxc7 31. Rxc7 Rc8 32. Ree7 Rxc7 33. Rxc7 h5 34. Rd7 Rb8 35. b3 Rb4 36. Rd6 a5 37. Rxg6 a4 38. bxa4 Rxa4 39. Rd6 Kh7 40. Kh2 g6 41. Kg3 Kh6 42. Kf4 Rxa2 43. Kf3 Ra4 44. Ke4 Ra2 45. Rf6 Ra4 46. Rd6 Ra2 47. Kf3 Ra4 48. g4 hxg4+ 49. hxg4 Kg5 50. Kg3 Kh6 51. f4 Kg7 52. Kf3 Kf7 53. Ke4 Ra1 54. Rxd4 Re1+ 55. Kf3 Rf1+ 56. Kg2 Rd1 57. Rd6 Rd2+ 58. Kf3 Rd1 59. Ke4 Re1+ 60. Kd5 Rf1 61. Ke5 Re1+ 62. Kd5 Rf1 63. Rd7+ Kf6 64. g5+ Kf5 65. Rf7+ Kg4 66. Ke5 Re1+ 67. Kf6 Kxf4 68. Kxg6+ Kg4 69. Rf5 Re6+ 70. Rf6 Re5 71. Kf7 Rxg5 72. Rg6 Rxg6 73. Kxg6 Kf4 74. d4 Ke4 75. d5 Kxd5 76. 1/2-1/2 77. Kf4 Kd4 78. Kf3 Kd3 79. Kf2 Kd2 80. Kf1 Kd1 81. Kf2 Kd2 82. Kf1 Kd1 83. Kf2 Kd2 84. Kf1 Kd1 85. Kf2 Kd2 86. Kf1 Kd1 87. Kf2 Kd2 88. Kf",
          "positional_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "Bb3",
            "Bxb4",
            "Bd2",
            "Bxd2",
            "Qxd2",
            "Kh8",
            "exd5",
            "Nbxd5",
            "Rxe5",
            "c6",
            "Rae1",
            "Qb6",
            "Ne4",
            "Nxe4",
            "R1xe4",
            "Nf6",
            "Re2",
            "Rad8",
            "Qc3",
            "Nd5",
            "Bxd5",
            "cxd5",
            "Re7",
            "d4",
            "Qc7",
            "Qxc7",
            "Rxc7",
            "Rc8",
            "Ree7",
            "Rxc7",
            "Rxc7",
            "h5",
            "Rd7",
            "Rb8",
            "b3",
            "Rb4",
            "Rd6",
            "a5",
            "Rxg6",
            "a4",
            "bxa4",
            "Rxa4",
            "Rd6",
            "Kh7",
            "Kh2",
            "g6",
            "Kg3",
            "Kh6",
            "Kf4",
            "Rxa2",
            "Kf3",
            "Ra4",
            "Ke4",
            "Ra2",
            "Rf6",
            "Ra4",
            "Rd6",
            "Ra2",
            "Kf3",
            "Ra4",
            "g4",
            "hxg4+",
            "hxg4",
            "Kg5",
            "Kg3",
            "Kh6",
            "f4",
            "Kg7",
            "Kf3",
            "Kf7",
            "Ke4",
            "Ra1",
            "Rxd4",
            "Re1+",
            "Kf3",
            "Rf1+",
            "Kg2",
            "Rd1",
            "Rd6",
            "Rd2+",
            "Kf3",
            "Rd1",
            "Ke4",
            "Re1+",
            "Kd5",
            "Rf1",
            "Ke5",
            "Re1+",
            "Kd5",
            "Rf1",
            "Rd7+",
            "Kf6",
            "g5+",
            "Kf5",
            "Rf7+",
            "Kg4",
            "Ke5",
            "Re1+",
            "Kf6",
            "Kxf4",
            "Kxg6+",
            "Kg4",
            "Rf5",
            "Re6+",
            "Rf6",
            "Re5",
            "Kf7",
            "Rxg5",
            "Rg6",
            "Rxg6",
            "Kxg6",
            "Kf4",
            "d4",
            "Ke4",
            "d5",
            "Kxd5",
            "Kf4",
            "Kd4",
            "Kf3",
            "Kd3",
            "Kf2",
            "Kd2",
            "Kf1",
            "Kd1",
            "Kf2",
            "Kd2",
            "Kf1",
            "Kd1",
            "Kf2",
            "Kd2",
            "Kf1",
            "Kd1",
            "Kf2",
            "Kd2",
            "Kf1",
            "Kd1",
            "Kf2",
            "Kd2"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "query3": {
          "neutral_move": "cxb4",
          "neutral_uci": "c3b4",
          "neutral_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. Bb3 Bxb4 19. Bd2 Bxd2 20. Qxd2 Kh8 21. exd5 Nbxd5 22. Rxe5 c6 23. Rae1 Qb6 24. Ne4 Nxe4 25. R1xe4 Nf6 26. Re2 Rad8 27. Qc3 Nd5 28. Bxd5 cxd5 29. Re7 d4 30. Qc7 Qxc7 31. Rxc7 Rb8 32. Ree7 Rxb2 33. Rxg7 Rfxf2 34. Rxh7+ Kg8 35. Rhg7+ Kf8 36. Rxg6 Rxa2 37. h4 Rfd2 38. h5 Rxd3 39. h6 Rd1+ 40. Kh2 Raa1 41. h7 Rh1+ 42. Kg3 Ra3+ 43. Kf4 Rh4+ 44. Kg5 Rg3+ 45. Kxh4 Rxg6 46. h8=Q+ Rg8 47. Qf6+ Ke8 48. Qe7# e5 dxe5 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5+ Kh8 Qh5+ Kg8 Qg5",
          "neutral_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "Bb3",
            "Bxb4",
            "Bd2",
            "Bxd2",
            "Qxd2",
            "Kh8",
            "exd5",
            "Nbxd5",
            "Rxe5",
            "c6",
            "Rae1",
            "Qb6",
            "Ne4",
            "Nxe4",
            "R1xe4",
            "Nf6",
            "Re2",
            "Rad8",
            "Qc3",
            "Nd5",
            "Bxd5",
            "cxd5",
            "Re7",
            "d4",
            "Qc7",
            "Qxc7",
            "Rxc7",
            "Rb8",
            "Ree7",
            "Rxb2",
            "Rxg7",
            "Rfxf2",
            "Rxh7+",
            "Kg8",
            "Rhg7+",
            "Kf8",
            "Rxg6",
            "Rxa2",
            "h4",
            "Rfd2",
            "h5",
            "Rxd3",
            "h6",
            "Rd1+",
            "Kh2",
            "Raa1",
            "h7",
            "Rh1+",
            "Kg3",
            "Ra3+",
            "Kf4",
            "Rh4+",
            "Kg5",
            "Rg3+",
            "Kxh4",
            "Rxg6",
            "h8=Q+",
            "Rg8",
            "Qf6+",
            "Ke8",
            "Qe7#",
            "e5",
            "dxe5",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c3b4",
          "positional_uci": "c3b4",
          "neutral_uci": "c3b4",
          "consensus_move": "c3b4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "exd5",
              "Nfxd5",
              "Rxe5",
              "Nxb4",
              "Bb3+",
              "Kh8",
              "Qe2",
              "Bf6",
              "Re4",
              "Nxd3",
              "Be3",
              "Nxb2",
              "Rb1",
              "Nd3",
              "Rd1",
              "Qd6",
              "Rxd3",
              "Qc6",
              "Re6",
              "Qb5",
              "Bxb6",
              "cxb6",
              "Rd5",
              "Qb4",
              "Ne4",
              "Bd4",
              "Red6",
              "Bc5",
              "Nxc5",
              "bxc5",
              "Qc4",
              "Qe1+",
              "Kh2",
              "Qxf2",
              "Rxc5",
              "Rae8",
              "Rc7",
              "Re2",
              "Qd5",
              "Qf4+",
              "Kg1",
              "Re1#",
              "d5",
              "cxd5",
              "Qxd5"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "Bb3",
              "Bxb4",
              "Bd2",
              "Bxd2",
              "Qxd2",
              "Kh8",
              "exd5",
              "Nbxd5",
              "Rxe5",
              "c6",
              "Rae1",
              "Qb6",
              "Ne4",
              "Nxe4",
              "R1xe4",
              "Nf6",
              "Re2",
              "Rad8",
              "Qc3",
              "Nd5",
              "Bxd5",
              "cxd5",
              "Re7",
              "d4",
              "Qc7",
              "Qxc7",
              "Rxc7",
              "Rc8",
              "Ree7",
              "Rxc7",
              "Rxc7",
              "h5",
              "Rd7",
              "Rb8",
              "b3",
              "Rb4",
              "Rd6",
              "a5",
              "Rxg6",
              "a4",
              "bxa4",
              "Rxa4",
              "Rd6",
              "Kh7",
              "Kh2",
              "g6",
              "Kg3",
              "Kh6",
              "Kf4",
              "Rxa2",
              "Kf3",
              "Ra4",
              "Ke4",
              "Ra2",
              "Rf6",
              "Ra4",
              "Rd6",
              "Ra2",
              "Kf3",
              "Ra4",
              "g4",
              "hxg4+",
              "hxg4",
              "Kg5",
              "Kg3",
              "Kh6",
              "f4",
              "Kg7",
              "Kf3",
              "Kf7",
              "Ke4",
              "Ra1",
              "Rxd4",
              "Re1+",
              "Kf3",
              "Rf1+",
              "Kg2",
              "Rd1",
              "Rd6",
              "Rd2+",
              "Kf3",
              "Rd1",
              "Ke4",
              "Re1+",
              "Kd5",
              "Rf1",
              "Ke5",
              "Re1+",
              "Kd5",
              "Rf1",
              "Rd7+",
              "Kf6",
              "g5+",
              "Kf5",
              "Rf7+",
              "Kg4",
              "Ke5",
              "Re1+",
              "Kf6",
              "Kxf4",
              "Kxg6+",
              "Kg4",
              "Rf5",
              "Re6+",
              "Rf6",
              "Re5",
              "Kf7",
              "Rxg5",
              "Rg6",
              "Rxg6",
              "Kxg6",
              "Kf4",
              "d4",
              "Ke4",
              "d5",
              "Kxd5",
              "Kf4",
              "Kd4",
              "Kf3",
              "Kd3",
              "Kf2",
              "Kd2",
              "Kf1",
              "Kd1",
              "Kf2",
              "Kd2",
              "Kf1",
              "Kd1",
              "Kf2",
              "Kd2",
              "Kf1",
              "Kd1",
              "Kf2",
              "Kd2",
              "Kf1",
              "Kd1",
              "Kf2",
              "Kd2"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "Bb3",
              "Bxb4",
              "Bd2",
              "Bxd2",
              "Qxd2",
              "Kh8",
              "exd5",
              "Nbxd5",
              "Rxe5",
              "c6",
              "Rae1",
              "Qb6",
              "Ne4",
              "Nxe4",
              "R1xe4",
              "Nf6",
              "Re2",
              "Rad8",
              "Qc3",
              "Nd5",
              "Bxd5",
              "cxd5",
              "Re7",
              "d4",
              "Qc7",
              "Qxc7",
              "Rxc7",
              "Rb8",
              "Ree7",
              "Rxb2",
              "Rxg7",
              "Rfxf2",
              "Rxh7+",
              "Kg8",
              "Rhg7+",
              "Kf8",
              "Rxg6",
              "Rxa2",
              "h4",
              "Rfd2",
              "h5",
              "Rxd3",
              "h6",
              "Rd1+",
              "Kh2",
              "Raa1",
              "h7",
              "Rh1+",
              "Kg3",
              "Ra3+",
              "Kf4",
              "Rh4+",
              "Kg5",
              "Rg3+",
              "Kxh4",
              "Rxg6",
              "h8=Q+",
              "Rg8",
              "Qf6+",
              "Ke8",
              "Qe7#",
              "e5",
              "dxe5",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qh5+",
              "Kg8",
              "Qg5"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "Nf1",
            "Bg4"
          ],
          "full_moves": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "Bb3",
            "Bxb4",
            "Bd2",
            "Bxd2",
            "Qxd2",
            "Kh8",
            "exd5",
            "Nbxd5",
            "Rxe5",
            "c6",
            "Rae1",
            "Qb6",
            "Ne4",
            "Nxe4",
            "R1xe4",
            "Nf6",
            "Re2",
            "Rad8",
            "Qc3",
            "Nd5",
            "Bxd5",
            "cxd5",
            "Re7",
            "d4",
            "Qc7",
            "Qxc7",
            "Rxc7",
            "Rb8",
            "Ree7",
            "Rxb2",
            "Rxg7",
            "Rfxf2",
            "Rxh7+",
            "Kg8",
            "Rhg7+",
            "Kf8",
            "Rxg6",
            "Rxa2",
            "h4",
            "Rfd2",
            "h5",
            "Rxd3",
            "h6",
            "Rd1+",
            "Kh2",
            "Raa1",
            "h7",
            "Rh1+",
            "Kg3",
            "Ra3+",
            "Kf4",
            "Rh4+",
            "Kg5",
            "Rg3+",
            "Kxh4",
            "Rxg6",
            "h8=Q+",
            "Rg8",
            "Qf6+",
            "Ke8",
            "Qe7#",
            "e5",
            "dxe5",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qh5+",
            "Kg8",
            "Qg5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 195,
            "completion_tokens": 553,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 584,
          "total_completion_tokens": 1833,
          "total_tokens": 2417
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 195,
            "completion_tokens": 553,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/pn1p1n2/4p3/1p2P3/2PP1N2/PPBN1PPP/R1BQR1K1 w kq - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "bxa5",
          "aggressive_uci": "b4a5",
          "aggressive_response": "13. bxa5 Rxa5 14. b4 Ra8 15. a4 O-O 16. a5 Nbd7 17. d4 exd4 18. Nxd4 Bb7 19. Nf5 Re8 20. Nxe7+ Qxe7 21. Bb2 Ne5 22. f4 Nc6 23. Bc3 Ba6 24. Ba4 Bb7 25. b5 Nxa5 26. Bxa5 Rxa5 27. b6 c6 28. Nc4 Rc5 29. Nxd6 Rd8 30. e5 Nd5 31. Qd4 Ra5 32. Bxc6 Rxa1 33. Rxa1 Bxc6 34. Ra7 Qh4 35. g3 Qh3 36. b7 Nxf4 37. Qf2 Qg4 38. Qxf4 Qd1+ 39. Qf1 Qd4+ 40. Qf2 Qd1+ 41. Qf1 Qd4+ 42. Qf2 Qd1+ 43. Qf1 Qd4+ 44. Qf2 Qd1+ 45. Qf1 Qd4+ 46. Qf2 Qd1+ 47. Qf1 Qd4+ 48. Qf2 Qd1+ 49. Qf1 Qd4+ 50. Qf2 Qd1+ 51. Qf1 Qd4+ 52. Qf2 Qd1+ 53. Qf1 Qd4+ 54. Qf2 Qd1+ 55. Qf1 Qd4+ 56. Qf2 Qd1+ 57. Qf1 Qd4+ 58. Qf2 Qd1+ 59. Qf1 Qd4+ 60. Qf2 Qd1+ 61. Qf1 Qd4+ 62. Qf2 Qd1+ 63. Qf1 Qd4+ 64. Qf2 Qd1+ 65. Qf1 Qd4+ 66. Qf2 Qd1+ 67. Qf1 Qd4+ 68. Qf2 Qd1+ 69. Qf1 Qd4+ 70. Qf2 Qd1+ 71. Qf1 Qd4+ 72. Qf2 Qd1+ 73. Qf1 Qd4+ 74. Qf2 Qd1+ 75. Qf1 Qd4+ 76. Qf2 Qd1+ 77. Qf1 Qd4+ 78. Qf2 Qd1+ 79. Qf1 Qd4+ 80. Qf2 Qd1+ 81. Qf1",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxa5",
            "b4",
            "Ra8",
            "a4",
            "O-O",
            "a5",
            "Nbd7",
            "d4",
            "exd4",
            "Nxd4",
            "Bb7",
            "Nf5",
            "Re8",
            "Nxe7+",
            "Qxe7",
            "Bb2",
            "Ne5",
            "f4",
            "Nc6",
            "Bc3",
            "Ba6",
            "Ba4",
            "Bb7",
            "b5",
            "Nxa5",
            "Bxa5",
            "Rxa5",
            "b6",
            "c6",
            "Nc4",
            "Rc5",
            "Nxd6",
            "Rd8",
            "e5",
            "Nd5",
            "Qd4",
            "Ra5",
            "Bxc6",
            "Rxa1",
            "Rxa1",
            "Bxc6",
            "Ra7",
            "Qh4",
            "g3",
            "Qh3",
            "b7",
            "Nxf4",
            "Qf2",
            "Qg4",
            "Qxf4",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1",
            "Qd4+",
            "Qf2",
            "Qd1+",
            "Qf1"
          ],
          "plan_execute": [
            "Rxa5",
            "b4",
            "Ra8"
          ]
        },
        "query2": {
          "positional_move": "bxa5",
          "positional_uci": "b4a5",
          "positional_response": "13. bxa5 Rxa5 14. Nb3 Ra8 15. d4 exd4 16. Nbxd4 Bb7 17. Nf5 O-O 18. Bg5 h6 19. Bh4 g5 20. Nxh6+ Kg7 21. Bxg5 Nh7 22. Nf5+ Kg6 23. Bxe7 Qd7 24. N3h4# e5 Nf6 Bxf6+ Kxf6 Qh5+ Ke6 Qg4# e4 Nxe4 Bxe4 dxe4 Qxd8+ Kxd8 Rad1+ Ke8 Rxe4+ Kf8 Rd8#",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 155,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxh6+",
            "Kg7",
            "Bxg5",
            "Nh7",
            "Nf5+",
            "Kg6",
            "Bxe7",
            "Qd7",
            "N3h4#",
            "e5",
            "Nf6",
            "Bxf6+",
            "Kxf6",
            "Qh5+",
            "Ke6",
            "Qg4#",
            "e4",
            "Nxe4",
            "Bxe4",
            "dxe4",
            "Qxd8+",
            "Kxd8",
            "Rad1+",
            "Ke8",
            "Rxe4+",
            "Kf8",
            "Rd8#"
          ],
          "plan_execute": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ]
        },
        "query3": {
          "neutral_move": "bxa5",
          "neutral_uci": "b4a5",
          "neutral_response": "13. bxa5 Rxa5 14. Nb3 Ra8 15. d4 exd4 16. Nbxd4 Bb7 17. Nf5 O-O 18. Bg5 h6 19. Bh4 g5 20. Nxh6+ Kg7 21. Bxg5 Nh7 22. Nf5+ Kg6 23. Bxe7 Qd7 24. N3h4# e4 Nxe7 Nxe7+ Kh8 Qd4+ Kg8 Qg5+ Kh8 Qg7# e5 Nxe5 Nxe5+ Kh8 Qg7# e6 Nxe6 Nxe6+ Kh8 Qg7# e7 Nxe7 Nxe7+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 640,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxh6+",
            "Kg7",
            "Bxg5",
            "Nh7",
            "Nf5+",
            "Kg6",
            "Bxe7",
            "Qd7",
            "N3h4#",
            "e4",
            "Nxe7",
            "Nxe7+",
            "Kh8",
            "Qd4+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qg7#",
            "e5",
            "Nxe5",
            "Nxe5+",
            "Kh8",
            "Qg7#",
            "e6",
            "Nxe6",
            "Nxe6+",
            "Kh8",
            "Qg7#",
            "e7",
            "Nxe7",
            "Nxe7+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8"
          ],
          "plan_execute": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b4a5",
          "positional_uci": "b4a5",
          "neutral_uci": "b4a5",
          "consensus_move": "b4a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxa5",
              "b4",
              "Ra8",
              "a4",
              "O-O",
              "a5",
              "Nbd7",
              "d4",
              "exd4",
              "Nxd4",
              "Bb7",
              "Nf5",
              "Re8",
              "Nxe7+",
              "Qxe7",
              "Bb2",
              "Ne5",
              "f4",
              "Nc6",
              "Bc3",
              "Ba6",
              "Ba4",
              "Bb7",
              "b5",
              "Nxa5",
              "Bxa5",
              "Rxa5",
              "b6",
              "c6",
              "Nc4",
              "Rc5",
              "Nxd6",
              "Rd8",
              "e5",
              "Nd5",
              "Qd4",
              "Ra5",
              "Bxc6",
              "Rxa1",
              "Rxa1",
              "Bxc6",
              "Ra7",
              "Qh4",
              "g3",
              "Qh3",
              "b7",
              "Nxf4",
              "Qf2",
              "Qg4",
              "Qxf4",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1",
              "Qd4+",
              "Qf2",
              "Qd1+",
              "Qf1"
            ],
            "execute": [
              "Rxa5",
              "b4",
              "Ra8"
            ]
          },
          "positional": {
            "full": [
              "Rxa5",
              "Nb3",
              "Ra8",
              "d4",
              "exd4",
              "Nbxd4",
              "Bb7",
              "Nf5",
              "O-O",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxh6+",
              "Kg7",
              "Bxg5",
              "Nh7",
              "Nf5+",
              "Kg6",
              "Bxe7",
              "Qd7",
              "N3h4#",
              "e5",
              "Nf6",
              "Bxf6+",
              "Kxf6",
              "Qh5+",
              "Ke6",
              "Qg4#",
              "e4",
              "Nxe4",
              "Bxe4",
              "dxe4",
              "Qxd8+",
              "Kxd8",
              "Rad1+",
              "Ke8",
              "Rxe4+",
              "Kf8",
              "Rd8#"
            ],
            "execute": [
              "Rxa5",
              "Nb3",
              "Ra8"
            ]
          },
          "neutral": {
            "full": [
              "Rxa5",
              "Nb3",
              "Ra8",
              "d4",
              "exd4",
              "Nbxd4",
              "Bb7",
              "Nf5",
              "O-O",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxh6+",
              "Kg7",
              "Bxg5",
              "Nh7",
              "Nf5+",
              "Kg6",
              "Bxe7",
              "Qd7",
              "N3h4#",
              "e4",
              "Nxe7",
              "Nxe7+",
              "Kh8",
              "Qd4+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qg7#",
              "e5",
              "Nxe5",
              "Nxe5+",
              "Kh8",
              "Qg7#",
              "e6",
              "Nxe6",
              "Nxe6+",
              "Kh8",
              "Qg7#",
              "e7",
              "Nxe7",
              "Nxe7+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8"
            ],
            "execute": [
              "Rxa5",
              "Nb3",
              "Ra8"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ],
          "full_moves": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxh6+",
            "Kg7",
            "Bxg5",
            "Nh7",
            "Nf5+",
            "Kg6",
            "Bxe7",
            "Qd7",
            "N3h4#",
            "e4",
            "Nxe7",
            "Nxe7+",
            "Kh8",
            "Qd4+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qg7#",
            "e5",
            "Nxe5",
            "Nxe5+",
            "Kh8",
            "Qg7#",
            "e6",
            "Nxe6",
            "Nxe6+",
            "Kh8",
            "Qg7#",
            "e7",
            "Nxe7",
            "Nxe7+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 155,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 640,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 1435,
          "total_tokens": 2043
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 155,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 640,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/p3p3/1P2P3/3P1N2/PPBN1PPP/R1BQR1K1 w kq - 0 13"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6\n39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6\n43. Nh4 Kc5 44. a3 Bd7 45. Nf3 Nc6 46. Nd2 Nd4\n47. Nb1 Be6 48. Nc3 Bc4 49. Bxc4 Kxc4 50. Kd2 Kb3\n51. Kc1 b4 52. axb4 Kxb4 53. Nd5+ Kb3 54. Nxf6 Ne2+\n55. Kb1 Nf4 56. Nxh7 Nxg2 57. Nf6 Nf4 58. h4 Nd3\n59. h5 Nxb2 60. h6 a3 61. h7 a2+ 62. Ka1 Nd3\n63. h8=Q Nb4 64. Qg8+ Ka3 65. Qa8+ Kb3 66. Qb7 Ka3\n67. Qxb4+ Kxb4 68. Kxa2 Kc3 69. Ng4 Kd4 70. f3 Kd3\n71. Nxe5+ Ke3 72. Kb3 Kf4 73. Kc4 Kxe5 74. Kd3 Kf4\n75. Kd4 Kxf3 76. e5 Kf4 77. e6 Kf5 78. e7 Kf6",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf4",
            "e6",
            "Kf5",
            "e7",
            "Kf6"
          ],
          "plan_execute": [
            "Kf4",
            "e6",
            "Kf5"
          ]
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6\n5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O\n9. h3 Nb8 10. d4 Nbd7 11. Nbd2 Bb7 12. Bc2 Re8\n13. Nf1 Bf8 14. Ng3 g6 15. a4 c5 16. d5 c4\n17. Bg5 h6 18. Be3 Nc5 19. Qd2 h5 20. Bg5 Be7\n21. Ra3 Nfd7 22. Rea1 Bxg5 23. Nxg5 Qf6 24. Nf3 Nb6\n25. axb5 axb5 26. Rxa8 Rxa8 27. Rxa8+ Bxa8 28. Qh6 Qg7\n29. Qe3 Nbd7 30. Qg5 Qf6 31. Qh6 Qg7 32. Qe3 Qf6\n33. Qh6 Qg7 34. Qe3 Qf6 35. Qh6 Qg7 36. Qe3 Qf6\n37. Qh6 Qg7 38. Qe3 Qf6 39. Qh6 Qg7 40. Qe3 Qf6\n41. Qh6 Qg7 42. Qe3 Qf6 43. Qh6 Qg7 44. Qe3 Qf6\n45. Qh6 Qg7 46. Qe3 Qf6 47. Qh6 Qg7 48. Qe3 Qf6\n49. Qh6 Qg7 50. Qe3 Qf6 51. Qh6 Qg7 52. Qe3 Qf6\n53. Qh6 Qg7 54. Qe3 Qf6 55. Qh6 Qg7 56. Qe3 Qf6\n57. Qh6 Qg7 58. Qe3 Qf6 59. Qh6 Qg7 60. Qe3 Qf6\n61. Qh6 Qg7 62. Qe3 Qf6 63. Qh6 Qg7 64. Qe3 Qf6\n65. Qh6 Qg7 66. Qe3 Qf6 67. Qh6 Qg7 68. Qe3 Qf6\n69. Qh6 Qg7 70. Qe3 Qf6 71. Qh6 Qg7 72. Qe3 Qf6\n73. Qh6 Qg7 74. Qe3 Qf",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Nb8",
            "d4",
            "Nbd7",
            "Nbd2",
            "Bb7",
            "Bc2",
            "Re8",
            "Nf1",
            "Bf8",
            "Ng3",
            "g6",
            "a4",
            "c5",
            "d5",
            "c4",
            "Bg5",
            "h6",
            "Be3",
            "Nc5",
            "Qd2",
            "h5",
            "Bg5",
            "Be7",
            "Ra3",
            "Nfd7",
            "Rea1",
            "Bxg5",
            "Nxg5",
            "Qf6",
            "Nf3",
            "Nb6",
            "axb5",
            "axb5",
            "Rxa8",
            "Rxa8",
            "Rxa8+",
            "Bxa8",
            "Qh6",
            "Qg7",
            "Qe3",
            "Nbd7",
            "Qg5",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3",
            "Qf6",
            "Qh6",
            "Qg7",
            "Qe3"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bb5"
          ]
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bf7\n39. Rxb5 Bxa2 40. Ra5 Bb3 41. Nd2 Nc6 42. Ra6 Nb4\n43. Ra7+ Kg6 44. Bc4 Bxc4 45. Nxc4 Nd3 46. Rxa4 Rc8\n47. b3 Nc5 48. Rb4 Nxe4 49. Nxe5+ Kf5 50. Nc4 Rd8\n51. Ne3+ Ke5 52. Rb5+ Ke6 53. f3 Nc3 54. Rb6+ Kf7\n55. Ng4 Nd5 56. Rb7+ Kg6 57. Kf2 h5 58. Ne3 Nf4\n59. Kg3 Ne2+ 60. Kh4 Rd4+ 61. g4 hxg4 62. hxg4 Rd3\n63. Nf5 Rxf3 64. Rg7# Nf4 65. Rg8+ Kf7 66. Rg7+ Kf8\n67. g5 fxg5+ 68. Kxg5 Ne6+ 69. Kg4 Rf4+ 70. Kg3 Rxf5\n71. Rb7 Nd4 72. b4 Rb5 73. Rxb5 Nxb5 74. Kf4 Ke7\n75. Ke5 Kd7 76. Kd5 Kc7 77. Kc5 Nc3",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bf7",
            "Rxb5",
            "Bxa2",
            "Ra5",
            "Bb3",
            "Nd2",
            "Nc6",
            "Ra6",
            "Nb4",
            "Ra7+",
            "Kg6",
            "Bc4",
            "Bxc4",
            "Nxc4",
            "Nd3",
            "Rxa4",
            "Rc8",
            "b3",
            "Nc5",
            "Rb4",
            "Nxe4",
            "Nxe5+",
            "Kf5",
            "Nc4",
            "Rd8",
            "Ne3+",
            "Ke5",
            "Rb5+",
            "Ke6",
            "f3",
            "Nc3",
            "Rb6+",
            "Kf7",
            "Ng4",
            "Nd5",
            "Rb7+",
            "Kg6",
            "Kf2",
            "h5",
            "Ne3",
            "Nf4",
            "Kg3",
            "Ne2+",
            "Kh4",
            "Rd4+",
            "g4",
            "hxg4",
            "hxg4",
            "Rd3",
            "Nf5",
            "Rxf3",
            "Rg7#",
            "Nf4",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "g5",
            "fxg5+",
            "Kxg5",
            "Ne6+",
            "Kg4",
            "Rf4+",
            "Kg3",
            "Rxf5",
            "Rb7",
            "Nd4",
            "b4",
            "Rb5",
            "Rxb5",
            "Nxb5",
            "Kf4",
            "Ke7",
            "Ke5",
            "Kd7",
            "Kd5",
            "Kc7",
            "Kc5",
            "Nc3"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bb5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf4",
              "e6",
              "Kf5",
              "e7",
              "Kf6"
            ],
            "execute": [
              "Kf4",
              "e6",
              "Kf5"
            ]
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Nb8",
              "d4",
              "Nbd7",
              "Nbd2",
              "Bb7",
              "Bc2",
              "Re8",
              "Nf1",
              "Bf8",
              "Ng3",
              "g6",
              "a4",
              "c5",
              "d5",
              "c4",
              "Bg5",
              "h6",
              "Be3",
              "Nc5",
              "Qd2",
              "h5",
              "Bg5",
              "Be7",
              "Ra3",
              "Nfd7",
              "Rea1",
              "Bxg5",
              "Nxg5",
              "Qf6",
              "Nf3",
              "Nb6",
              "axb5",
              "axb5",
              "Rxa8",
              "Rxa8",
              "Rxa8+",
              "Bxa8",
              "Qh6",
              "Qg7",
              "Qe3",
              "Nbd7",
              "Qg5",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3",
              "Qf6",
              "Qh6",
              "Qg7",
              "Qe3"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bb5"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bf7",
              "Rxb5",
              "Bxa2",
              "Ra5",
              "Bb3",
              "Nd2",
              "Nc6",
              "Ra6",
              "Nb4",
              "Ra7+",
              "Kg6",
              "Bc4",
              "Bxc4",
              "Nxc4",
              "Nd3",
              "Rxa4",
              "Rc8",
              "b3",
              "Nc5",
              "Rb4",
              "Nxe4",
              "Nxe5+",
              "Kf5",
              "Nc4",
              "Rd8",
              "Ne3+",
              "Ke5",
              "Rb5+",
              "Ke6",
              "f3",
              "Nc3",
              "Rb6+",
              "Kf7",
              "Ng4",
              "Nd5",
              "Rb7+",
              "Kg6",
              "Kf2",
              "h5",
              "Ne3",
              "Nf4",
              "Kg3",
              "Ne2+",
              "Kh4",
              "Rd4+",
              "g4",
              "hxg4",
              "hxg4",
              "Rd3",
              "Nf5",
              "Rxf3",
              "Rg7#",
              "Nf4",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "g5",
              "fxg5+",
              "Kxg5",
              "Ne6+",
              "Kg4",
              "Rf4+",
              "Kg3",
              "Rxf5",
              "Rb7",
              "Nd4",
              "b4",
              "Rb5",
              "Rxb5",
              "Nxb5",
              "Kf4",
              "Ke7",
              "Ke5",
              "Kd7",
              "Kd5",
              "Kc7",
              "Kc5",
              "Nc3"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bb5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf3",
            "Nc6",
            "Bb5"
          ],
          "full_moves": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bf7",
            "Rxb5",
            "Bxa2",
            "Ra5",
            "Bb3",
            "Nd2",
            "Nc6",
            "Ra6",
            "Nb4",
            "Ra7+",
            "Kg6",
            "Bc4",
            "Bxc4",
            "Nxc4",
            "Nd3",
            "Rxa4",
            "Rc8",
            "b3",
            "Nc5",
            "Rb4",
            "Nxe4",
            "Nxe5+",
            "Kf5",
            "Nc4",
            "Rd8",
            "Ne3+",
            "Ke5",
            "Rb5+",
            "Ke6",
            "f3",
            "Nc3",
            "Rb6+",
            "Kf7",
            "Ng4",
            "Nd5",
            "Rb7+",
            "Kg6",
            "Kf2",
            "h5",
            "Ne3",
            "Nf4",
            "Kg3",
            "Ne2+",
            "Kh4",
            "Rd4+",
            "g4",
            "hxg4",
            "hxg4",
            "Rd3",
            "Nf5",
            "Rxf3",
            "Rg7#",
            "Nf4",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "g5",
            "fxg5+",
            "Kxg5",
            "Ne6+",
            "Kg4",
            "Rf4+",
            "Kg3",
            "Rxf5",
            "Rb7",
            "Nd4",
            "b4",
            "Rb5",
            "Rxb5",
            "Nxb5",
            "Kf4",
            "Ke7",
            "Ke5",
            "Kd7",
            "Kd5",
            "Kc7",
            "Kc5",
            "Nc3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1920,
          "total_tokens": 2261
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bb8\n21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qh1 Bf4\n26. Rxe6 Rxe6 27. Qa8+ Bb8 28. Qxb8+ Re8 29. Qxe8# Bg4 30. Bf4# Bf3 31. Qe8# Bg4 32. Qe8# Bf3 33. Qe8# Bg4 34. Qe8# Bf3 35. Qe8# Bg4 36. Qe8# Bf3 37. Qe8# Bg4 38. Qe8# Bf3 39. Qe8# Bg4 40. Qe8# Bf3 41. Qe8# Bg4 42. Qe8# Bf3 43. Qe8# Bg4 44. Qe8# Bf3 45. Qe8# Bg4 46. Qe8# Bf3 47. Qe8# Bg4 48. Qe8# Bf3 49. Qe8# Bg4 50. Qe8# Bf3 51. Qe8# Bg4 52. Qe8# Bf3 53. Qe8# Bg4 54. Qe8# Bf3 55. Qe8# Bg4 56. Qe8# Bf3 57. Qe8# Bg4 58. Qe8# Bf3 59. Qe8# Bg4 60. Qe8# Bf3 61. Qe8# Bg4 62. Qe8# Bf3 63. Qe8# Bg4 64. Qe8# Bf3 65. Qe8# Bg4 66. Qe8# Bf3 67. Qe8# Bg4 68. Qe8# Bf3 69. Qe8# Bg4 70. Qe8# Bf3",
          "aggressive_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qh1",
            "Bf4",
            "Rxe6",
            "Rxe6",
            "Qa8+",
            "Bb8",
            "Qxb8+",
            "Re8",
            "Qxe8#",
            "Bg4",
            "Bf4#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3",
            "Qe8#",
            "Bg4",
            "Qe8#",
            "Bf3"
          ],
          "plan_execute": [
            "Bb5",
            "a6",
            "Ba4"
          ]
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bb8\n21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qh1 Bf4\n26. Rxe6 Rxe6 27. Qa8+ Re8 28. Qxe8# Bxe8 29. Bxf4 Bc6 30. f3 h6\n31. Kg2 Qd5 32. Re5 Qa2 33. Rc5 Bd7 34. b4 g5 35. Be3 Qc2 36. Kf2 Qd3\n37. Ne4 Bh3 38. Nf6+ Kf8 39. Nxe8 Qf1# Bb7 41. d5 Bxd5 42. Rxd5 Kxe8\n43. Bd4 Qc4 44. Re5+ Kd7 45. Rc5 Qa2+ 46. Kg1 Qe2 47. Rf5 Ke6\n48. Rf6+ Kd5 49. Rxf7 Kc4 50. Rf5 Qd1+ 51. Kg2 Qc2+ 52. Kh3 Qxf5+\n53. Kg2 Kd3 54. Kf2 Qh3 55. Kg1 Ke2 56. f4 Qf1# Qf1 58. Bf2 Qxf2+ 59. Kh1 Qf1# 1-0\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d5 exd5 Nxd5 Nxe5 Nxe5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Re6 a4 Qh5 axb5 axb5 Ra6 Bb8 Qf1 Rfe8 Bxd5 Qxd5 Qg2 Qh5 Rxc6 Bh3 Qh1 Bf4 Rxe6 Rxe6 Qa8+ Re8 Qxe8# Bxe8 Bc6 f3 h6 Qd5 Qxd5 Bxd",
          "positional_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qh1",
            "Bf4",
            "Rxe6",
            "Rxe6",
            "Qa8+",
            "Re8",
            "Qxe8#",
            "Bxe8",
            "Bc6",
            "f3",
            "h6",
            "Qd5",
            "Qxd5"
          ],
          "plan_execute": [
            "Bb5",
            "a6",
            "Ba4"
          ]
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. d5 Rg6 27. Bf4 Rxe1+ 28. Nf1 h6 29. Rxb8+ Kh7 30. Bg3 Bh3 31. d6 Bxg2 32. Kxg2 Qd5+ 33. Kg1 Qd3 34. Kg2 Qxf1+ 35. Kf3 Qh1+ 36. Kf4 Qe4# 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. d5 Rg6 27. Bf4 Rxe1+ 28. Nf1 h6 29. Rxb8+ Kh7 30. Bg3 Bh3 31. d6 Bxg2 32. Kxg2 Qd5+ 33. Kg1 Qd3 34. Kg2 Qxf1+ 35. Kf3 Qh1+ 36. Kf4 Qe4# 1-0 37. d7 Qe5# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 121,
            "completion_tokens": 619,
            "total_tokens": 740,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "d5",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "h6",
            "Rxb8+",
            "Kh7",
            "Bg3",
            "Bh3",
            "d6",
            "Bxg2",
            "Kxg2",
            "Qd5+",
            "Kg1",
            "Qd3",
            "Kg2",
            "Qxf1+",
            "Kf3",
            "Qh1+",
            "Kf4",
            "Qe4#",
            "d7",
            "Qe5#"
          ],
          "plan_execute": [
            "Bb5",
            "a6",
            "Ba4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qh1",
              "Bf4",
              "Rxe6",
              "Rxe6",
              "Qa8+",
              "Bb8",
              "Qxb8+",
              "Re8",
              "Qxe8#",
              "Bg4",
              "Bf4#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3",
              "Qe8#",
              "Bg4",
              "Qe8#",
              "Bf3"
            ],
            "execute": [
              "Bb5",
              "a6",
              "Ba4"
            ]
          },
          "positional": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qh1",
              "Bf4",
              "Rxe6",
              "Rxe6",
              "Qa8+",
              "Re8",
              "Qxe8#",
              "Bxe8",
              "Bc6",
              "f3",
              "h6",
              "Qd5",
              "Qxd5"
            ],
            "execute": [
              "Bb5",
              "a6",
              "Ba4"
            ]
          },
          "neutral": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "d5",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "h6",
              "Rxb8+",
              "Kh7",
              "Bg3",
              "Bh3",
              "d6",
              "Bxg2",
              "Kxg2",
              "Qd5+",
              "Kg1",
              "Qd3",
              "Kg2",
              "Qxf1+",
              "Kf3",
              "Qh1+",
              "Kf4",
              "Qe4#",
              "d7",
              "Qe5#"
            ],
            "execute": [
              "Bb5",
              "a6",
              "Ba4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bb5",
            "a6",
            "Ba4"
          ],
          "full_moves": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "d5",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "h6",
            "Rxb8+",
            "Kh7",
            "Bg3",
            "Bh3",
            "d6",
            "Bxg2",
            "Kxg2",
            "Qd5+",
            "Kg1",
            "Qd3",
            "Kg2",
            "Qxf1+",
            "Kf3",
            "Qh1+",
            "Kf4",
            "Qe4#",
            "d7",
            "Qe5#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 121,
            "completion_tokens": 619,
            "total_tokens": 740,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 365,
          "total_completion_tokens": 1899,
          "total_tokens": 2264
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 121,
            "completion_tokens": 619,
            "total_tokens": 740,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5\n19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3\n24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Bf3\n29. Rxb8+ Re8 30. Rxe8# Bxg2+ 31. Kg1 Bc6+ 32. Ng3 Bxe8 33. Kf1 Qd1+ 34. Kg2 Bc6+ 35. Kh3 Qg4# Bxg3 36. hxg3 Qh5# 0-1\n1. e4 e5 2. Nf3 Nc6 3. Bb5 * 3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Bf3 29. Rxb8+ Re8 30. Rxe8# Bxg2+ 31. Kg1 Bc6+ 32. Ng3 Bxe8 33. Kf1 Qd1+ 34. Kg2 Bc6+ 35. Kh3 Qg4# Bxg3 36. hxg3 Qh5# 0-1",
          "aggressive_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 615,
            "total_tokens": 746,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "Bxg2+",
            "Kg1",
            "Bc6+",
            "Ng3",
            "Bxe8",
            "Kf1",
            "Qd1+",
            "Kg2",
            "Bc6+",
            "Kh3",
            "Qg4#",
            "Bxg3",
            "hxg3",
            "Qh5#"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bb8 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5\n24. Rxc6 Bh3 25. Qf3 Bg4 26. Qh1 Bf4 27. Rxe6 Rxe6 28. Qa8+ 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 *\n3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bb8 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5\n24. Rxc6 Bh3 25. Qf3 Bg4 26. Qh1 Bf4 27. Rxe6 Rxe6 28. Qa8+ 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 *\n3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bb8 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5\n24. R",
          "positional_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a7a6",
          "neutral_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 *\n9... Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 *\n12... cxd4 13. cxd4 Nc6 14. Nb3 *\n14... a5 15. Be3 a4 16. Nbd2 *\n16... Nb4 17. Bb1 a3 18. bxa3 Rxa3 19. Nb3 *\n19... Be6 20. d5 Bd7 21. Bc1 Ra4 22. a3 Na6 23. Bb2 *\n23... Rc8 24. Bd3 Nc5 25. Rc1 Qb6 26. Nxc5 Rxc5 27. Qd2 *\n27... Rxc1 28. Rxc1 Nxe4 29. Qc2 f5 30. Re1 *\n30... Nc5 31. Bxf5 Bxf5 32. Qxf5 Qd8 33. Bc3 *\n33... g6 34. Qc2 Rxa3 35. Bb4 Ra4 36. Bxc5 Rc4 37. Qb3 Rxc5 38. Nxe5 *\n38... dxe5 39. d6+ Kg7 40. dxe7 Qxe7 41. Qb4 *\n41... Qc7 42. Qe4 Rc1 43. Rxc1 Qxc1+ 44. Kh2 Qf4+ 45. Qxf4 exf4 *\n45... exf4 46. Kg1 b4 47. Kf1 b3 48. Ke2 b2 49. Kf3 b1=Q *",
          "neutral_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 433,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Nb4",
            "Bb1",
            "a3",
            "bxa3",
            "Rxa3",
            "Nb3",
            "Be6",
            "d5",
            "Bd7",
            "Bc1",
            "Ra4",
            "a3",
            "Na6",
            "Bb2",
            "Rc8",
            "Bd3",
            "Nc5",
            "Rc1",
            "Qb6",
            "Nxc5",
            "Rxc5",
            "Qd2",
            "Rxc1",
            "Rxc1",
            "Nxe4",
            "Qc2",
            "f5",
            "Re1",
            "Nc5",
            "Bxf5",
            "Bxf5",
            "Qxf5",
            "Qd8",
            "Bc3",
            "g6",
            "Qc2",
            "Rxa3",
            "Bb4",
            "Ra4",
            "Bxc5",
            "Rc4",
            "Qb3",
            "Rxc5",
            "Nxe5",
            "dxe5",
            "d6+",
            "Kg7",
            "dxe7",
            "Qxe7",
            "Qb4",
            "Qc7",
            "Qe4",
            "Rc1",
            "Rxc1",
            "Qxc1+",
            "Kh2",
            "Qf4+",
            "Qxf4",
            "exf4",
            "exf4",
            "Kg1",
            "b4",
            "Kf1",
            "b3",
            "Ke2",
            "b2",
            "Kf3",
            "b1=Q"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "a7a6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "Bxg2+",
              "Kg1",
              "Bc6+",
              "Ng3",
              "Bxe8",
              "Kf1",
              "Qd1+",
              "Kg2",
              "Bc6+",
              "Kh3",
              "Qg4#",
              "Bxg3",
              "hxg3",
              "Qh5#"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Nb4",
              "Bb1",
              "a3",
              "bxa3",
              "Rxa3",
              "Nb3",
              "Be6",
              "d5",
              "Bd7",
              "Bc1",
              "Ra4",
              "a3",
              "Na6",
              "Bb2",
              "Rc8",
              "Bd3",
              "Nc5",
              "Rc1",
              "Qb6",
              "Nxc5",
              "Rxc5",
              "Qd2",
              "Rxc1",
              "Rxc1",
              "Nxe4",
              "Qc2",
              "f5",
              "Re1",
              "Nc5",
              "Bxf5",
              "Bxf5",
              "Qxf5",
              "Qd8",
              "Bc3",
              "g6",
              "Qc2",
              "Rxa3",
              "Bb4",
              "Ra4",
              "Bxc5",
              "Rc4",
              "Qb3",
              "Rxc5",
              "Nxe5",
              "dxe5",
              "d6+",
              "Kg7",
              "dxe7",
              "Qxe7",
              "Qb4",
              "Qc7",
              "Qe4",
              "Rc1",
              "Rxc1",
              "Qxc1+",
              "Kh2",
              "Qf4+",
              "Qxf4",
              "exf4",
              "exf4",
              "Kg1",
              "b4",
              "Kf1",
              "b3",
              "Ke2",
              "b2",
              "Kf3",
              "b1=Q"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Ba4",
            "Nf6",
            "O-O"
          ],
          "full_moves": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Nb4",
            "Bb1",
            "a3",
            "bxa3",
            "Rxa3",
            "Nb3",
            "Be6",
            "d5",
            "Bd7",
            "Bc1",
            "Ra4",
            "a3",
            "Na6",
            "Bb2",
            "Rc8",
            "Bd3",
            "Nc5",
            "Rc1",
            "Qb6",
            "Nxc5",
            "Rxc5",
            "Qd2",
            "Rxc1",
            "Rxc1",
            "Nxe4",
            "Qc2",
            "f5",
            "Re1",
            "Nc5",
            "Bxf5",
            "Bxf5",
            "Qxf5",
            "Qd8",
            "Bc3",
            "g6",
            "Qc2",
            "Rxa3",
            "Bb4",
            "Ra4",
            "Bxc5",
            "Rc4",
            "Qb3",
            "Rxc5",
            "Nxe5",
            "dxe5",
            "d6+",
            "Kg7",
            "dxe7",
            "Qxe7",
            "Qb4",
            "Qc7",
            "Qe4",
            "Rc1",
            "Rxc1",
            "Qxc1+",
            "Kh2",
            "Qf4+",
            "Qxf4",
            "exf4",
            "exf4",
            "Kg1",
            "b4",
            "Kf1",
            "b3",
            "Ke2",
            "b2",
            "Kf3",
            "b1=Q"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 131,
            "completion_tokens": 615,
            "total_tokens": 746,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 130,
            "completion_tokens": 433,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 392,
          "total_completion_tokens": 1688,
          "total_tokens": 2080
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 131,
            "completion_tokens": 615,
            "total_tokens": 746,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 130,
            "completion_tokens": 433,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "4... Nf6 5. d3 Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qf3 Nd4 20. Bxd4 Bxd4 21. c3 Ba7 22. g4 c6 23. gxh5 cxd5 24. cxd5 Qg8+ 25. Kh1 Qg5 26. Rg1 Qxh5 27. Qg3 Rag8 28. Qxg8+ Rxg8 29. Rxg8 Kxg8 30. Rg1+ Kf7 31. Rg2 Qd1+ 32. Rg1 Qf3+ 33. Rg2 Bxf2 34. h3 Qxh3+ 35. Rh2 Qf1# e4 e5 Nf3 Nc6 Bb5 a6 Bc4 Nf6 d3 Bc5 O-O O-O Nc3 d6 Bg5 h6 Bh4 g5 Nxg5 hxg5 Bxg5 Be6 Qf3 Kg7 Qg3 Nh5 Qh4 f6 Be3 Bxc4 dxc4 Rh8 Qg4+ Kf7 Nd5 Qc8 Qf3 Nd4 Bxd4 Bxd4 c3 Ba7 g4 c6 gxh5 cxd5 Qg3 dxc4 Qg6+ Ke7 Qg7+ Kd8 Qxh8+ Kc7 Qxc8+ Kxc8 cxd4 exd4 h6 d3 h7 d2 h8=Q+ Kc7 Qg7+ Kc6 Qxf6 Kc5 Qc3 d5 Qxd2 d4 Qc3+ dxc3 bxc3 Kc4 e5 Kxc3 e6 Kb2 e7 Kxa2 e8=Q b5 Qe6+ Ka4 Qxa6+ Kb4 Qb6 Kc3 Qxb5+ Kd3 Qb6+ Kd4 Qb4+ Kd5 Qb5+ Kd6 Qb6+ Kd7 Qb7+ Kd6 Qb6+ Kd7 Qb7+ Kd6 Qb6+ Kd7 Qb7+ Kd6 Qb6+ Kd7 Qb7+ Kd6 Qb6+ Kd7 Qb7+ Kd6 Qb6+ Kd7 Qb7+ Kd6 Qb6+ K",
          "aggressive_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d3",
            "Bc5",
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qf3",
            "Nd4",
            "Bxd4",
            "Bxd4",
            "c3",
            "Ba7",
            "g4",
            "c6",
            "gxh5",
            "cxd5",
            "Qg3",
            "dxc4",
            "Qg6+",
            "Ke7",
            "Qg7+",
            "Kd8",
            "Qxh8+",
            "Kc7",
            "Qxc8+",
            "Kxc8",
            "cxd4",
            "exd4",
            "h6",
            "d3",
            "h7",
            "d2",
            "h8=Q+",
            "Kc7",
            "Qg7+",
            "Kc6",
            "Qxf6",
            "Kc5",
            "Qc3",
            "d5",
            "Qxd2",
            "d4",
            "Qc3+",
            "dxc3",
            "bxc3",
            "Kc4",
            "e5",
            "Kxc3",
            "e6",
            "Kb2",
            "e7",
            "Kxa2",
            "e8=Q",
            "b5",
            "Qe6+",
            "Ka4",
            "Qxa6+",
            "Kb4",
            "Qb6",
            "Kc3",
            "Qxb5+",
            "Kd3",
            "Qb6+",
            "Kd4",
            "Qb4+",
            "Kd5",
            "Qb5+",
            "Kd6",
            "Qb6+",
            "Kd7",
            "Qb7+",
            "Kd6",
            "Qb6+",
            "Kd7",
            "Qb7+",
            "Kd6",
            "Qb6+",
            "Kd7",
            "Qb7+",
            "Kd6",
            "Qb6+",
            "Kd7",
            "Qb7+",
            "Kd6",
            "Qb6+",
            "Kd7",
            "Qb7+",
            "Kd6",
            "Qb6+",
            "Kd7",
            "Qb7+",
            "Kd6",
            "Qb6+"
          ],
          "plan_execute": [
            "d3",
            "Bc5",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "4... Nf6 5. d3 Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qf3 Nd4 20. Bxd4 Bxd4 21. c3 Ba7 22. g4 c6 23. gxh5 cxd5 24. cxd5 Qg8+ 25. Kh1 Qg5 26. Rg1 Qxh5 27. Qg3 Rag8 28. Rg2 Rxg3 29. fxg3 Qf3 30. Re1 Bf2 31. Rf1 Rxh2+ 32. Kxh2 Qh5# 33.# e4 e5 Nf3 Nc6 Bb5 a6 Bc4 Nf6 d3 Bc5 O-O O-O Nc3 d6 Bg5 h6 Bh4 g5 Nxg5 hxg5 Bxg5 Be6 Qf3 Kg7 Qg3 Nh5 Qh4 f6 Be3 Bxc4 dxc4 Rh8 Qg4+ Kf7 Nd5 Qc8 Qf3 Nd4 Bxd4 Bxd4 c3 Ba7 g4 c6 gxh5 cxd5 cxd5 Qg8+ Kh1 Qg5 Rg1 Qxh5 Qg3 Rag8 Rg2 Rxg3 fxg3 Qf3 Re1 Bf2 Rf1 Rxh2+ Kxh2 Qh5# 33.#",
          "positional_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 424,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Bc5",
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qf3",
            "Nd4",
            "Bxd4",
            "Bxd4",
            "c3",
            "Ba7",
            "g4",
            "c6",
            "gxh5",
            "cxd5",
            "cxd5",
            "Qg8+",
            "Kh1",
            "Qg5",
            "Rg1",
            "Qxh5",
            "Qg3",
            "Rag8",
            "Rg2",
            "Rxg3",
            "fxg3",
            "Qf3",
            "Re1",
            "Bf2",
            "Rf1",
            "Rxh2+",
            "Kxh2",
            "Qh5#"
          ],
          "plan_execute": [
            "d3",
            "Bc5",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "4... Nf6 5. d3 Bc5 6. O-O d6 7. c3 O-O 8. Bg5 h6 9. Bh4 g5 10. Bg3 Ba7 11. Nbd2 Nh5 12. Nxe5 Nxg3 13. Nxc6 bxc6 14. hxg3 d5 15. Bb3 Be6 16. d4 c5 17. exd5 Bxd5 18. Bxd5 Qxd5 19. Qh5 Kg7 20. Nf3 cxd4 21. cxd4 Bxd4 22. Rad1 c5 23. b4 Qxa2 24. Nxd4 cxd4 25. Rxd4 Rad8 26. Rfd1 Rxd4 27. Rxd4 Qa1+ 28. Qd1 Qxd1+ 29. Rxd1 Rb8 30. Rd4 Rb5 31. f4 a5 32. bxa5 Rxa5 33. Kf2 Ra3 34. Rd6 f6 35. f5 Ra5 36. g4 Ra4 37. Kf3 Ra3+ 38. Kf2 Ra4 39. Kf3 Ra3+ 40. Kf2 Ra4 41. Kf3 Ra3+ 42. Kf2 Ra4 43. Kf3 Ra3+ 44. Kf2 Ra4 45. Kf3 Ra3+ 46. Kf2 Ra4 47. Kf3 Ra3+ 48. Kf2 Ra4 49. Kf3 Ra3+ 50. Kf2 Ra4 51. Kf3 Ra3+ 52. Kf2 Ra4 53. Kf3 Ra3+ 54. Kf2 Ra4 55. Kf3 Ra3+ 56. Kf2 Ra4 57. Kf3 Ra3+ 58. Kf2 Ra4 59. Kf3 Ra3+ 60. Kf2 Ra4 61. Kf3 Ra3+ 62. Kf2 Ra4 63. Kf3 Ra3+ 64. Kf2 Ra4 65. Kf3 Ra3+ 66. Kf2 Ra4 67. Kf3 Ra3+ 68. Kf2 Ra4 69. Kf3 Ra3+ 70. Kf2 Ra4 71. Kf3 Ra3+ 72. Kf2 Ra4 73. Kf3 Ra3+ 74. Kf2 Ra4 75. Kf3 Ra3+ 76. Kf2 Ra4 77. Kf3 Ra3+ 78. Kf2 Ra4 79. Kf3 Ra3+ 80. Kf2 Ra",
          "neutral_tokens": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d3",
            "Bc5",
            "O-O",
            "d6",
            "c3",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Ba7",
            "Nbd2",
            "Nh5",
            "Nxe5",
            "Nxg3",
            "Nxc6",
            "bxc6",
            "hxg3",
            "d5",
            "Bb3",
            "Be6",
            "d4",
            "c5",
            "exd5",
            "Bxd5",
            "Bxd5",
            "Qxd5",
            "Qh5",
            "Kg7",
            "Nf3",
            "cxd4",
            "cxd4",
            "Bxd4",
            "Rad1",
            "c5",
            "b4",
            "Qxa2",
            "Nxd4",
            "cxd4",
            "Rxd4",
            "Rad8",
            "Rfd1",
            "Rxd4",
            "Rxd4",
            "Qa1+",
            "Qd1",
            "Qxd1+",
            "Rxd1",
            "Rb8",
            "Rd4",
            "Rb5",
            "f4",
            "a5",
            "bxa5",
            "Rxa5",
            "Kf2",
            "Ra3",
            "Rd6",
            "f6",
            "f5",
            "Ra5",
            "g4",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2"
          ],
          "plan_execute": [
            "d3",
            "Bc5",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d3",
              "Bc5",
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qf3",
              "Nd4",
              "Bxd4",
              "Bxd4",
              "c3",
              "Ba7",
              "g4",
              "c6",
              "gxh5",
              "cxd5",
              "Qg3",
              "dxc4",
              "Qg6+",
              "Ke7",
              "Qg7+",
              "Kd8",
              "Qxh8+",
              "Kc7",
              "Qxc8+",
              "Kxc8",
              "cxd4",
              "exd4",
              "h6",
              "d3",
              "h7",
              "d2",
              "h8=Q+",
              "Kc7",
              "Qg7+",
              "Kc6",
              "Qxf6",
              "Kc5",
              "Qc3",
              "d5",
              "Qxd2",
              "d4",
              "Qc3+",
              "dxc3",
              "bxc3",
              "Kc4",
              "e5",
              "Kxc3",
              "e6",
              "Kb2",
              "e7",
              "Kxa2",
              "e8=Q",
              "b5",
              "Qe6+",
              "Ka4",
              "Qxa6+",
              "Kb4",
              "Qb6",
              "Kc3",
              "Qxb5+",
              "Kd3",
              "Qb6+",
              "Kd4",
              "Qb4+",
              "Kd5",
              "Qb5+",
              "Kd6",
              "Qb6+",
              "Kd7",
              "Qb7+",
              "Kd6",
              "Qb6+",
              "Kd7",
              "Qb7+",
              "Kd6",
              "Qb6+",
              "Kd7",
              "Qb7+",
              "Kd6",
              "Qb6+",
              "Kd7",
              "Qb7+",
              "Kd6",
              "Qb6+",
              "Kd7",
              "Qb7+",
              "Kd6",
              "Qb6+",
              "Kd7",
              "Qb7+",
              "Kd6",
              "Qb6+"
            ],
            "execute": [
              "d3",
              "Bc5",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "d3",
              "Bc5",
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qf3",
              "Nd4",
              "Bxd4",
              "Bxd4",
              "c3",
              "Ba7",
              "g4",
              "c6",
              "gxh5",
              "cxd5",
              "cxd5",
              "Qg8+",
              "Kh1",
              "Qg5",
              "Rg1",
              "Qxh5",
              "Qg3",
              "Rag8",
              "Rg2",
              "Rxg3",
              "fxg3",
              "Qf3",
              "Re1",
              "Bf2",
              "Rf1",
              "Rxh2+",
              "Kxh2",
              "Qh5#"
            ],
            "execute": [
              "d3",
              "Bc5",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "d3",
              "Bc5",
              "O-O",
              "d6",
              "c3",
              "O-O",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Ba7",
              "Nbd2",
              "Nh5",
              "Nxe5",
              "Nxg3",
              "Nxc6",
              "bxc6",
              "hxg3",
              "d5",
              "Bb3",
              "Be6",
              "d4",
              "c5",
              "exd5",
              "Bxd5",
              "Bxd5",
              "Qxd5",
              "Qh5",
              "Kg7",
              "Nf3",
              "cxd4",
              "cxd4",
              "Bxd4",
              "Rad1",
              "c5",
              "b4",
              "Qxa2",
              "Nxd4",
              "cxd4",
              "Rxd4",
              "Rad8",
              "Rfd1",
              "Rxd4",
              "Rxd4",
              "Qa1+",
              "Qd1",
              "Qxd1+",
              "Rxd1",
              "Rb8",
              "Rd4",
              "Rb5",
              "f4",
              "a5",
              "bxa5",
              "Rxa5",
              "Kf2",
              "Ra3",
              "Rd6",
              "f6",
              "f5",
              "Ra5",
              "g4",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2",
              "Ra4",
              "Kf3",
              "Ra3+",
              "Kf2"
            ],
            "execute": [
              "d3",
              "Bc5",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "d3",
            "Bc5",
            "O-O"
          ],
          "full_moves": [
            "d3",
            "Bc5",
            "O-O",
            "d6",
            "c3",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Ba7",
            "Nbd2",
            "Nh5",
            "Nxe5",
            "Nxg3",
            "Nxc6",
            "bxc6",
            "hxg3",
            "d5",
            "Bb3",
            "Be6",
            "d4",
            "c5",
            "exd5",
            "Bxd5",
            "Bxd5",
            "Qxd5",
            "Qh5",
            "Kg7",
            "Nf3",
            "cxd4",
            "cxd4",
            "Bxd4",
            "Rad1",
            "c5",
            "b4",
            "Qxa2",
            "Nxd4",
            "cxd4",
            "Rxd4",
            "Rad8",
            "Rfd1",
            "Rxd4",
            "Rxd4",
            "Qa1+",
            "Qd1",
            "Qxd1+",
            "Rxd1",
            "Rb8",
            "Rd4",
            "Rb5",
            "f4",
            "a5",
            "bxa5",
            "Rxa5",
            "Kf2",
            "Ra3",
            "Rd6",
            "f6",
            "f5",
            "Ra5",
            "g4",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2",
            "Ra4",
            "Kf3",
            "Ra3+",
            "Kf2"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 139,
            "completion_tokens": 424,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 416,
          "total_completion_tokens": 1704,
          "total_tokens": 2120
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 139,
            "completion_tokens": 424,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/4p3/2B1P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc5",
          "aggressive_uci": "f8c5",
          "aggressive_response": "5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qxc8 Raxc8 20. Bxc5 dxc5 21. c3 Ne7 22. Ne3 Nf4 23. g3 Rcg8 24. Rad1 Ke6 25. Rd2 Rh3 26. Rfd1 Rgh8 27. gxf4 exf4 28. Nf1 Ng6 29. Rd3 Ne5 30. Rxh3 Rxh3 31. Kg2 Rh8 32. b3 Rg8+ 33. Kh1 Nf3 34. Ng3 fxg3 35. fxg3 Rh8 36. Kg2 Ng5 37. Re1 Ke5 38. h4 Nxe4 39. Kf3 f5 40. Re3 Rg8 41. Kg2 f4 42. Rd3 Rxg3+ 43. Rxg3 fxg3 44. Kf3 Kf5 45. b4 cxb4 46. cxb4 b5 47. cxb5 axb5 48. a3 c6 49. h5 Ng5+ 50. Kxg3 Nf7 51. Kf3 Kg5 52. Ke4 Kxh5 53. Kd4 Kg5 54. Kc5 Ne5 55. Kd6 Kf5 56. Kc5 Ke6 57. Kd4 Kd6 58. Kc3 Kd5 59. Kb3 Kd4 60. a4 bxa4+ 61. Kxa4 Kc4 62. Ka5 Nd3 63. Kb6 Nxb4 64. Ka5 c5 65. Ka4 Kc3 66. Ka3 c4 67. Ka4 Nd3 68. Ka3 Kd2 69. Ka2 c3 70. Kb3 c2 71. Ka2 c1=Q 72. Kb3 Qc3+ 73. Ka4 Qb4# c5 c4 c3 c2",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 567,
            "total_tokens": 714,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qxc8",
            "Raxc8",
            "Bxc5",
            "dxc5",
            "c3",
            "Ne7",
            "Ne3",
            "Nf4",
            "g3",
            "Rcg8",
            "Rad1",
            "Ke6",
            "Rd2",
            "Rh3",
            "Rfd1",
            "Rgh8",
            "gxf4",
            "exf4",
            "Nf1",
            "Ng6",
            "Rd3",
            "Ne5",
            "Rxh3",
            "Rxh3",
            "Kg2",
            "Rh8",
            "b3",
            "Rg8+",
            "Kh1",
            "Nf3",
            "Ng3",
            "fxg3",
            "fxg3",
            "Rh8",
            "Kg2",
            "Ng5",
            "Re1",
            "Ke5",
            "h4",
            "Nxe4",
            "Kf3",
            "f5",
            "Re3",
            "Rg8",
            "Kg2",
            "f4",
            "Rd3",
            "Rxg3+",
            "Rxg3",
            "fxg3",
            "Kf3",
            "Kf5",
            "b4",
            "cxb4",
            "cxb4",
            "b5",
            "cxb5",
            "axb5",
            "a3",
            "c6",
            "h5",
            "Ng5+",
            "Kxg3",
            "Nf7",
            "Kf3",
            "Kg5",
            "Ke4",
            "Kxh5",
            "Kd4",
            "Kg5",
            "Kc5",
            "Ne5",
            "Kd6",
            "Kf5",
            "Kc5",
            "Ke6",
            "Kd4",
            "Kd6",
            "Kc3",
            "Kd5",
            "Kb3",
            "Kd4",
            "a4",
            "bxa4+",
            "Kxa4",
            "Kc4",
            "Ka5",
            "Nd3",
            "Kb6",
            "Nxb4",
            "Ka5",
            "c5",
            "Ka4",
            "Kc3",
            "Ka3",
            "c4",
            "Ka4",
            "Nd3",
            "Ka3",
            "Kd2",
            "Ka2",
            "c3",
            "Kb3",
            "c2",
            "Ka2",
            "c1=Q",
            "Kb3",
            "Qc3+",
            "Ka4",
            "Qb4#",
            "c5",
            "c4",
            "c3",
            "c2"
          ],
          "plan_execute": [
            "O-O",
            "O-O",
            "Nc3"
          ]
        },
        "query2": {
          "positional_move": "Bc5",
          "positional_uci": "f8c5",
          "positional_response": "5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qxc8 Raxc8 20. Bxc5 dxc5 21. c3 Ne7 22. Ne3 Nf4 23. Rfe1 Rcd8 24. Rad1 Nd3 25. Re2 Nf4 26. Red2 Rxd2 27. Rxd2 Ke6 28. g3 Nh3+ 29. Kg2 Ng5 30. f3 Nf7 31. h4 Nd6 32. b3 f5 33. exf5+ Nexf5 34. Nxf5 Nxf5 35. Kf2 Rg8 36. g4 Nxh4 37. Kg3 Ng6 38. Rh2 Rh8 39. Rd2 Nf4 40. g5 Kf5 41. Rd7 Rh3+ 42. Kf2 Rh2+ 43. Kg1 Rg2+ 44. Kf1 Rxa2 45. Rxc7 Kxg5 46. Rxb7 Kh4 47. Rg7 Nd3 48. Rg4+ Kh3 49. Rg6 Rf2+ 50. Kg1 Rxf3 51. Rxa6 Nf4 52. Rh6+ Kg3 53. Rh8 Ne2+ 54. Kh1 Rf1# 0-1\n5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qxc8 Raxc8 20. Bxc5 dxc5 21. c3 Ne7 22. Ne3 Nf4 23. Rfe1 Rcd8 24. Rad1 Nd3 25. Re2 Nf4 26. Red2 Rxd2 27. Rxd2 Ke6 28. g3 Nh3+ 29. Kg2 Ng5 30. f3 Nf7 31. h4 Nd6 32. b3 f5 33",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qxc8",
            "Raxc8",
            "Bxc5",
            "dxc5",
            "c3",
            "Ne7",
            "Ne3",
            "Nf4",
            "Rfe1",
            "Rcd8",
            "Rad1",
            "Nd3",
            "Re2",
            "Nf4",
            "Red2",
            "Rxd2",
            "Rxd2",
            "Ke6",
            "g3",
            "Nh3+",
            "Kg2",
            "Ng5",
            "f3",
            "Nf7",
            "h4",
            "Nd6",
            "b3",
            "f5"
          ],
          "plan_execute": [
            "O-O",
            "O-O",
            "Nc3"
          ]
        },
        "query3": {
          "neutral_move": "Bc5",
          "neutral_uci": "f8c5",
          "neutral_response": "5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qf3 Nd4 20. Bxd4 Bxd4 21. c3 Ba7 22. g4 c6 23. gxh5 cxd5 24. cxd5 Qg8+ 25. Kh1 Qg5 26. Rg1 Qxh5 27. Qg3 Rag8 28. Rg2 Rxg3 29. fxg3 Qf3 30. Re1 Bf2 31. Rf1 Rxh2+ 32. Kxh2 Qh5# 33.# Qh4+ 34. Kg1 Qxg3+ 35. Kh1 Qh3+ 36. Rh2 Qxf1#",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 271,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qf3",
            "Nd4",
            "Bxd4",
            "Bxd4",
            "c3",
            "Ba7",
            "g4",
            "c6",
            "gxh5",
            "cxd5",
            "cxd5",
            "Qg8+",
            "Kh1",
            "Qg5",
            "Rg1",
            "Qxh5",
            "Qg3",
            "Rag8",
            "Rg2",
            "Rxg3",
            "fxg3",
            "Qf3",
            "Re1",
            "Bf2",
            "Rf1",
            "Rxh2+",
            "Kxh2",
            "Qh5#",
            "Qh4+",
            "Kg1",
            "Qxg3+",
            "Kh1",
            "Qh3+",
            "Rh2",
            "Qxf1#"
          ],
          "plan_execute": [
            "O-O",
            "O-O",
            "Nc3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f8c5",
          "positional_uci": "f8c5",
          "neutral_uci": "f8c5",
          "consensus_move": "f8c5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qxc8",
              "Raxc8",
              "Bxc5",
              "dxc5",
              "c3",
              "Ne7",
              "Ne3",
              "Nf4",
              "g3",
              "Rcg8",
              "Rad1",
              "Ke6",
              "Rd2",
              "Rh3",
              "Rfd1",
              "Rgh8",
              "gxf4",
              "exf4",
              "Nf1",
              "Ng6",
              "Rd3",
              "Ne5",
              "Rxh3",
              "Rxh3",
              "Kg2",
              "Rh8",
              "b3",
              "Rg8+",
              "Kh1",
              "Nf3",
              "Ng3",
              "fxg3",
              "fxg3",
              "Rh8",
              "Kg2",
              "Ng5",
              "Re1",
              "Ke5",
              "h4",
              "Nxe4",
              "Kf3",
              "f5",
              "Re3",
              "Rg8",
              "Kg2",
              "f4",
              "Rd3",
              "Rxg3+",
              "Rxg3",
              "fxg3",
              "Kf3",
              "Kf5",
              "b4",
              "cxb4",
              "cxb4",
              "b5",
              "cxb5",
              "axb5",
              "a3",
              "c6",
              "h5",
              "Ng5+",
              "Kxg3",
              "Nf7",
              "Kf3",
              "Kg5",
              "Ke4",
              "Kxh5",
              "Kd4",
              "Kg5",
              "Kc5",
              "Ne5",
              "Kd6",
              "Kf5",
              "Kc5",
              "Ke6",
              "Kd4",
              "Kd6",
              "Kc3",
              "Kd5",
              "Kb3",
              "Kd4",
              "a4",
              "bxa4+",
              "Kxa4",
              "Kc4",
              "Ka5",
              "Nd3",
              "Kb6",
              "Nxb4",
              "Ka5",
              "c5",
              "Ka4",
              "Kc3",
              "Ka3",
              "c4",
              "Ka4",
              "Nd3",
              "Ka3",
              "Kd2",
              "Ka2",
              "c3",
              "Kb3",
              "c2",
              "Ka2",
              "c1=Q",
              "Kb3",
              "Qc3+",
              "Ka4",
              "Qb4#",
              "c5",
              "c4",
              "c3",
              "c2"
            ],
            "execute": [
              "O-O",
              "O-O",
              "Nc3"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qxc8",
              "Raxc8",
              "Bxc5",
              "dxc5",
              "c3",
              "Ne7",
              "Ne3",
              "Nf4",
              "Rfe1",
              "Rcd8",
              "Rad1",
              "Nd3",
              "Re2",
              "Nf4",
              "Red2",
              "Rxd2",
              "Rxd2",
              "Ke6",
              "g3",
              "Nh3+",
              "Kg2",
              "Ng5",
              "f3",
              "Nf7",
              "h4",
              "Nd6",
              "b3",
              "f5"
            ],
            "execute": [
              "O-O",
              "O-O",
              "Nc3"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qf3",
              "Nd4",
              "Bxd4",
              "Bxd4",
              "c3",
              "Ba7",
              "g4",
              "c6",
              "gxh5",
              "cxd5",
              "cxd5",
              "Qg8+",
              "Kh1",
              "Qg5",
              "Rg1",
              "Qxh5",
              "Qg3",
              "Rag8",
              "Rg2",
              "Rxg3",
              "fxg3",
              "Qf3",
              "Re1",
              "Bf2",
              "Rf1",
              "Rxh2+",
              "Kxh2",
              "Qh5#",
              "Qh4+",
              "Kg1",
              "Qxg3+",
              "Kh1",
              "Qh3+",
              "Rh2",
              "Qxf1#"
            ],
            "execute": [
              "O-O",
              "O-O",
              "Nc3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "O-O",
            "Nc3"
          ],
          "full_moves": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qf3",
            "Nd4",
            "Bxd4",
            "Bxd4",
            "c3",
            "Ba7",
            "g4",
            "c6",
            "gxh5",
            "cxd5",
            "cxd5",
            "Qg8+",
            "Kh1",
            "Qg5",
            "Rg1",
            "Qxh5",
            "Qg3",
            "Rag8",
            "Rg2",
            "Rxg3",
            "fxg3",
            "Qf3",
            "Re1",
            "Bf2",
            "Rf1",
            "Rxh2+",
            "Kxh2",
            "Qh5#",
            "Qh4+",
            "Kg1",
            "Qxg3+",
            "Kh1",
            "Qh3+",
            "Rh2",
            "Qxf1#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 567,
            "total_tokens": 714,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 271,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 1478,
          "total_tokens": 1918
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 567,
            "total_tokens": 714,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 271,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/2B1P3/3P1N2/PPP2PPP/RNBQK2R b KQkq - 0 5"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 d5\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 b6 Be4 Bb7 Ne5 Rd6 Qa4 Na5 Bxb7 Nxb7 Qa6 Nd8 Qb5 c6 Qa6 Qe7 Rfe1 Qb7 Qa3 Qc7 Rad1 f6 Nc4 Rd7 Re3 c5 Rde1 cxd4 cxd4 Qxc4 Rc3 Qxd4 Rc8 Qd2 Rxd2 Rxd2 Nc6 Rc1 Ne7 Rxc8+ Nxc8 Rd8+ Kf7 Rxc8 Kg6 Rc7 a5 Rb7 Kf5 Rxb6 e5 Ra6 Ke4 Rxa5 Kd4 Ra7 g5 Rxh7 f5 Rg7 g4 Rf7 f4 Rg7 g3 hxg3 fxg3 Rxg3 e4 Re3 Ke5 a4 Kd4 a5 Kc5 a6 Kb6 Rxe4 Kxa6 f4 Kb6 f5 Kc6 f6 Kd6 f7 Kd5 Re1 Kd4 f8=Q Kd3 Qd8+ Kc2 Qd2+ Kb3 Qc3+ Ka4 Qc4+ Ka5 Qc2+ Ka6 Qc3 Qb5+ Ka3 Qd7+ Kb2 Qb5+ Kc2 Qa4+ Kd2 Qa2+ Qc2 Qd5+ Kc1 Qg5+ Kb1 Qb5+ Qb2 Qf5+ Ka1 Qa5+ Qa2 Qxa2+ Kxa2 Kb5 f4 Kc6 f5 Kd7 f6 Kd6 f7 Kd5 f8=Q Kd4 Qd8+ Kc3 Rc1+ Kb2 Qd2+ Kb3 Qd3+ Kb4 Qd4+ Kb5 Qd5+ Kb6 Qd3+ Kb7 Qd7+ Kb6 Rc6+ Kb5 Qd5# 1-0\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 b6 Be4 Bb7 Ne5 Rd6 Qa4 Na5 Bxb7 Nxb7 Qa6 Nd8 Qb5 c6 Qa3 Qe7 Rfe1 Qb7 Qa4 Qc7 Rad1 f6 Nc4 Rd7 Re3 c5 Rde1 cxd4 cxd4 Qxc4 Rc3 Qxd4 Rc8 Qd2 Rxd2 Rxd2 Nc6 Rc1 Ne7",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "O-O",
            "Rd8",
            "c3",
            "b6",
            "Be4",
            "Bb7",
            "Ne5",
            "Rd6",
            "Qa4",
            "Na5",
            "Bxb7",
            "Nxb7",
            "Qa6",
            "Nd8",
            "Qb5",
            "c6",
            "Qa3",
            "Qe7",
            "Rfe1",
            "Qb7",
            "Qa4",
            "Qc7",
            "Rad1",
            "f6",
            "Nc4",
            "Rd7",
            "Re3",
            "c5",
            "Rde1",
            "cxd4",
            "cxd4",
            "Qxc4",
            "Rc3",
            "Qxd4",
            "Rc8",
            "Qd2",
            "Rxd2",
            "Rxd2",
            "Nc6",
            "Rc1",
            "Ne7"
          ],
          "plan_execute": [
            "d5",
            "Nc3",
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Qxh7 Be6 17. Nc7+ Kd8 18. Nxa8 Nd4 19. Qc7+ Ke8 20. Qxb7 Ne2+ 21. Kh1 Qh5 22. Nc7+ Kf7 23. Nxe6+ Kxe6 24. Qd5+ Qxd5 25. exd5+ Kxd5 26. Rad1+ Kc4 27. Rfe1 Nd4 28. Re4 d5 29. Rexd4+ Kc5 30. Rxd5+ Kc4 31. R1d4# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Qxh7 Be6 Nc7+ Kd8 Nxa8 Nd4 Qc7+ Ke8 Qxb7 Ne2+ Kh1 Qh5 Nc7+ Kf7 Nxe6+ Kxe6 Qd5+ Qxd5 exd5+ Kxd5 Rad1+ Kc4 Rfe1 Nd4 Re4 d5 Rexd4+ Kc5 Rxd5+ Kc4 R1d4#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 464,
            "total_tokens": 574,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Qxh7",
            "Be6",
            "Nc7+",
            "Kd8",
            "Nxa8",
            "Nd4",
            "Qc7+",
            "Ke8",
            "Qxb7",
            "Ne2+",
            "Kh1",
            "Qh5",
            "Nc7+",
            "Kf7",
            "Nxe6+",
            "Kxe6",
            "Qd5+",
            "Qxd5",
            "exd5+",
            "Kxd5",
            "Rad1+",
            "Kc4",
            "Rfe1",
            "Nd4",
            "Re4",
            "d5",
            "Rexd4+",
            "Kc5",
            "Rxd5+",
            "Kc4",
            "R1d4#"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 d5\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 b6 Be4 Bb7 Qa4 Rd6 Ne5 Nxe5 Bxb7 Rb8 Qxa7 Rdd8 dxe5 Qxe5 Rfe1 Qd6 Rad1 Qxd1 Rxd1 Rxd1#\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 b6 Be4 Bb7 Qa4 Rd6 Ne5 Nxe5 Bxb7 Rb8 Qxa7 Rbd8 dxe5 Qxe5 Rfe1 Qd6 Rad1 Qxd1 Rxd1 Rxd1# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 b6 Be4 Bb7 Qa4 Rd6 Ne5 Nxe5 Bxb7 Rb8 Qxa7 Rbd8 dxe5 Qxe5 Rfe1 Qd6 Rad1 Qxd1 Rxd1 Rxd1# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 b6 Be4 Bb7 Qa4 Rd6 Ne5 Nxe5 Bxb7 Rb8 Qxa7 Rbd8 dxe5 Qxe5 Rfe1 Qd6 Rad1 Qxd1 Rxd1 Rxd1# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 b6 Be4 Bb7 Qa4 Rd6 Ne5 Nxe5 Bxb7 Rb8 Qxa7 Rbd8 dxe5 Qxe5 Rfe1 Qd6 Rad1 Qxd1 Rxd1 Rxd1#",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 541,
            "total_tokens": 650,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "O-O",
            "Rd8",
            "c3",
            "b6",
            "Be4",
            "Bb7",
            "Qa4",
            "Rd6",
            "Ne5",
            "Nxe5",
            "Bxb7",
            "Rb8",
            "Qxa7",
            "Rbd8",
            "dxe5",
            "Qxe5",
            "Rfe1",
            "Qd6",
            "Rad1",
            "Qxd1",
            "Rxd1",
            "Rxd1#"
          ],
          "plan_execute": [
            "d5",
            "Nc3",
            "Nf6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nc3",
              "Nf6",
              "Bg5",
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nxf6+",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nf3",
              "O-O",
              "Bd3",
              "Nc6",
              "O-O",
              "Rd8",
              "c3",
              "b6",
              "Be4",
              "Bb7",
              "Ne5",
              "Rd6",
              "Qa4",
              "Na5",
              "Bxb7",
              "Nxb7",
              "Qa6",
              "Nd8",
              "Qb5",
              "c6",
              "Qa3",
              "Qe7",
              "Rfe1",
              "Qb7",
              "Qa4",
              "Qc7",
              "Rad1",
              "f6",
              "Nc4",
              "Rd7",
              "Re3",
              "c5",
              "Rde1",
              "cxd4",
              "cxd4",
              "Qxc4",
              "Rc3",
              "Qxd4",
              "Rc8",
              "Qd2",
              "Rxd2",
              "Rxd2",
              "Nc6",
              "Rc1",
              "Ne7"
            ],
            "execute": [
              "d5",
              "Nc3",
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Qxh7",
              "Be6",
              "Nc7+",
              "Kd8",
              "Nxa8",
              "Nd4",
              "Qc7+",
              "Ke8",
              "Qxb7",
              "Ne2+",
              "Kh1",
              "Qh5",
              "Nc7+",
              "Kf7",
              "Nxe6+",
              "Kxe6",
              "Qd5+",
              "Qxd5",
              "exd5+",
              "Kxd5",
              "Rad1+",
              "Kc4",
              "Rfe1",
              "Nd4",
              "Re4",
              "d5",
              "Rexd4+",
              "Kc5",
              "Rxd5+",
              "Kc4",
              "R1d4#"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          },
          "neutral": {
            "full": [
              "d5",
              "Nc3",
              "Nf6",
              "Bg5",
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nxf6+",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nf3",
              "O-O",
              "Bd3",
              "Nc6",
              "O-O",
              "Rd8",
              "c3",
              "b6",
              "Be4",
              "Bb7",
              "Qa4",
              "Rd6",
              "Ne5",
              "Nxe5",
              "Bxb7",
              "Rb8",
              "Qxa7",
              "Rbd8",
              "dxe5",
              "Qxe5",
              "Rfe1",
              "Qd6",
              "Rad1",
              "Qxd1",
              "Rxd1",
              "Rxd1#"
            ],
            "execute": [
              "d5",
              "Nc3",
              "Nf6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "d5",
            "Nc3",
            "Nf6"
          ],
          "full_moves": [
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "O-O",
            "Rd8",
            "c3",
            "b6",
            "Be4",
            "Bb7",
            "Qa4",
            "Rd6",
            "Ne5",
            "Nxe5",
            "Bxb7",
            "Rb8",
            "Qxa7",
            "Rbd8",
            "dxe5",
            "Qxe5",
            "Rfe1",
            "Qd6",
            "Rad1",
            "Qxd1",
            "Rxd1",
            "Rxd1#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 464,
            "total_tokens": 574,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 541,
            "total_tokens": 650,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1645,
          "total_tokens": 1974
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 464,
            "total_tokens": 574,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 541,
            "total_tokens": 650,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": "c1g5",
          "aggressive_response": "3. Bg5 e6 4. e4 dxe4 5. Nxe4 Be7 6. Bxf6 Bxf6 7. Nf3 O-O 8. c3 b6 9. Bd3 Bb7 10. Qe2 Nd7 11. O-O-O Qe7 12. h4 c5 13. dxc5 Nxc5 14. Nxc5 Qxc5 15. Ng5 h6 16. Ne4 Qe5 17. Nxf6+ Qxf6 18. f3 Rfd8 19. Bc2 Rxd1+ 20. Qxd1 Rd8 21. Qe2 Qf4+ 22. Kb1 Rd2 23. Qb5 g6 24. h5 Rxg2 25. hxg6 fxg6 26. Qe8+ Kg7 27. Qxe6 Qf7 28. Qe5+ Kh7 29. Qe3 h5 30. Rxh5+ Kg8 31. Rh1 Bxf3 32. Qe5 Rg1+ 33. Rxg1 Bd5 34. Rxg6+ Kf8 35. Rf6 Bxa2+ 36. Ka1 Bc4 37. Rxf7+ Bxf7 38. Qb8+ Kg7 39. Qxa7 Kf6 40. Qxb6+ Be6 41. Bb3 Ke5 42. Qxe6+ Kf4 43. c4 Kf3 44. c5 Kf4 45. c6 Kf3 46. c7 Kf4 47. c8=Q Kf3 48. Qf8+ Kg3 49. Qg6+ Kh4 50. Qh8# e4 d5 Nc3 Nf6 e6 dxe4 Nxe4 Be7 Nf3 O-O c3 b6 Bd3 Bb7 Qe2 Nd7 O-O-O Qe7 h4 c5 dxc5 Nxc5 Nxc5 Qxc5 Ng5 h6 Ne4 Qe5 Nxf6+ Qxf6 f3 Rfd8 Bc2 Rxd1+ Qxd1 Rd8 Qe2 Qf4+ Kb1 Rd2 Qb5 g6 h5 Rxg2 hxg6 fxg6 Qe8+ Kg7 Qxe6 Qf7 Qe5+ Kh7 Qe3 h5 Rxh5+ Kg8 Rh1 Bxf3 Qe5 Rg1+ Rxg1 Bd5 Rxg6+ Kf8 Rf6 Bxa2+ Ka1 Bc4 Rxf7+ Bxf7 Qb8+ Kg7 Qxa7 Kf6 Qxb6+ Be6 Bb3 Ke5 Qxe6+ Kf4 c4 Kf3 c",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Bxf6",
            "Bxf6",
            "Nf3",
            "O-O",
            "c3",
            "b6",
            "Bd3",
            "Bb7",
            "Qe2",
            "Nd7",
            "O-O-O",
            "Qe7",
            "h4",
            "c5",
            "dxc5",
            "Nxc5",
            "Nxc5",
            "Qxc5",
            "Ng5",
            "h6",
            "Ne4",
            "Qe5",
            "Nxf6+",
            "Qxf6",
            "f3",
            "Rfd8",
            "Bc2",
            "Rxd1+",
            "Qxd1",
            "Rd8",
            "Qe2",
            "Qf4+",
            "Kb1",
            "Rd2",
            "Qb5",
            "g6",
            "h5",
            "Rxg2",
            "hxg6",
            "fxg6",
            "Qe8+",
            "Kg7",
            "Qxe6",
            "Qf7",
            "Qe5+",
            "Kh7",
            "Qe3",
            "h5",
            "Rxh5+",
            "Kg8",
            "Rh1",
            "Bxf3",
            "Qe5",
            "Rg1+",
            "Rxg1",
            "Bd5",
            "Rxg6+",
            "Kf8",
            "Rf6",
            "Bxa2+",
            "Ka1",
            "Bc4",
            "Rxf7+",
            "Bxf7",
            "Qb8+",
            "Kg7",
            "Qxa7",
            "Kf6",
            "Qxb6+",
            "Be6",
            "Bb3",
            "Ke5",
            "Qxe6+",
            "Kf4",
            "c4",
            "Kf3",
            "c5",
            "Kf4",
            "c6",
            "Kf3",
            "c7",
            "Kf4",
            "c8=Q",
            "Kf3",
            "Qf8+",
            "Kg3",
            "Qg6+",
            "Kh4",
            "Qh8#",
            "e4",
            "d5",
            "Nc3",
            "Nf6",
            "e6",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nf3",
            "O-O",
            "c3",
            "b6",
            "Bd3",
            "Bb7",
            "Qe2",
            "Nd7",
            "O-O-O",
            "Qe7",
            "h4",
            "c5",
            "dxc5",
            "Nxc5",
            "Nxc5",
            "Qxc5",
            "Ng5",
            "h6",
            "Ne4",
            "Qe5",
            "Nxf6+",
            "Qxf6",
            "f3",
            "Rfd8",
            "Bc2",
            "Rxd1+",
            "Qxd1",
            "Rd8",
            "Qe2",
            "Qf4+",
            "Kb1",
            "Rd2",
            "Qb5",
            "g6",
            "h5",
            "Rxg2",
            "hxg6",
            "fxg6",
            "Qe8+",
            "Kg7",
            "Qxe6",
            "Qf7",
            "Qe5+",
            "Kh7",
            "Qe3",
            "h5",
            "Rxh5+",
            "Kg8",
            "Rh1",
            "Bxf3",
            "Qe5",
            "Rg1+",
            "Rxg1",
            "Bd5",
            "Rxg6+",
            "Kf8",
            "Rf6",
            "Bxa2+",
            "Ka1",
            "Bc4",
            "Rxf7+",
            "Bxf7",
            "Qb8+",
            "Kg7",
            "Qxa7",
            "Kf6",
            "Qxb6+",
            "Be6",
            "Bb3",
            "Ke5",
            "Qxe6+",
            "Kf4",
            "c4",
            "Kf3"
          ],
          "plan_execute": [
            "e6",
            "e4",
            "dxe4"
          ]
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "3. Bg5 e6 4. e4 dxe4 5. Nxe4 Be7 6. Bxf6 Bxf6 7. Nf3 O-O 8. c3 b6 9. Bd3 Bb7 10. Qe2 Nd7 11. O-O-O Qe7 12. h4 c5 13. dxc5 Nxc5 14. Nxc5 Qxc5 15. Ng5 h6 16. Nh7 Rfd8 17. Nxf6+ gxf6 18. Rh3 Kf8 19. Rg3 Ke7 20. Qd2 Rd6 21. Qxh6 Rad8 22. Qe3 Qxe3+ 23. Rxe3 Bxg2 24. h5 f5 25. h6 Rh8 26. Rg3 Be4 27. Bxe4 Rxd1+ 28. Kxd1 fxe4 29. Rh3 f5 30. Ke2 Kf6 31. Ke3 Kg6 32. Kf4 Rxh6 33. Rxh6+ Kxh6 34. Ke5 Kg5 35. Kxe6 f4 36. Ke5 e3 37. fxe3 fxe3 38. Kd4 e2 39. Kc4 e1=Q 40. Kb3 Qd1+ 41. Ka3 Kf5 42. b3 Ke5 43. Kb4 Kd5 44. c4+ Kc6 45. a4 Qd2+ 46. Ka3 Kc5 47. a5 Qxa5+ 48. Kb2 Kb4 49. Kc2 Qa2+ 50. Kd3 Qxb3+ 51. Kd4 Qxc4+ 52. Ke5 Kc5 53. Kf6 Qd5 54. Ke7 Qd6+ 55. Kf7 Kd5 56. Kg7 Qe6 57. Kh7 Qg4 58. Kh6 Ke6 59. Kh7 Kf7 60. Kh6 Qg6# e4 e5 e6 e7",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 495,
            "total_tokens": 620,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Bxf6",
            "Bxf6",
            "Nf3",
            "O-O",
            "c3",
            "b6",
            "Bd3",
            "Bb7",
            "Qe2",
            "Nd7",
            "O-O-O",
            "Qe7",
            "h4",
            "c5",
            "dxc5",
            "Nxc5",
            "Nxc5",
            "Qxc5",
            "Ng5",
            "h6",
            "Nh7",
            "Rfd8",
            "Nxf6+",
            "gxf6",
            "Rh3",
            "Kf8",
            "Rg3",
            "Ke7",
            "Qd2",
            "Rd6",
            "Qxh6",
            "Rad8",
            "Qe3",
            "Qxe3+",
            "Rxe3",
            "Bxg2",
            "h5",
            "f5",
            "h6",
            "Rh8",
            "Rg3",
            "Be4",
            "Bxe4",
            "Rxd1+",
            "Kxd1",
            "fxe4",
            "Rh3",
            "f5",
            "Ke2",
            "Kf6",
            "Ke3",
            "Kg6",
            "Kf4",
            "Rxh6",
            "Rxh6+",
            "Kxh6",
            "Ke5",
            "Kg5",
            "Kxe6",
            "f4",
            "Ke5",
            "e3",
            "fxe3",
            "fxe3",
            "Kd4",
            "e2",
            "Kc4",
            "e1=Q",
            "Kb3",
            "Qd1+",
            "Ka3",
            "Kf5",
            "b3",
            "Ke5",
            "Kb4",
            "Kd5",
            "c4+",
            "Kc6",
            "a4",
            "Qd2+",
            "Ka3",
            "Kc5",
            "a5",
            "Qxa5+",
            "Kb2",
            "Kb4",
            "Kc2",
            "Qa2+",
            "Kd3",
            "Qxb3+",
            "Kd4",
            "Qxc4+",
            "Ke5",
            "Kc5",
            "Kf6",
            "Qd5",
            "Ke7",
            "Qd6+",
            "Kf7",
            "Kd5",
            "Kg7",
            "Qe6",
            "Kh7",
            "Qg4",
            "Kh6",
            "Ke6",
            "Kh7",
            "Kf7",
            "Kh6",
            "Qg6#",
            "e4",
            "e5",
            "e6",
            "e7"
          ],
          "plan_execute": [
            "e6",
            "e4",
            "dxe4"
          ]
        },
        "query3": {
          "neutral_move": "Bg5",
          "neutral_uci": "c1g5",
          "neutral_response": "3. Bg5 e6 4. e4 dxe4 5. Nxe4 Be7 6. Bxf6 Bxf6 7. Nf3 O-O 8. c3 b6 9. Bd3 Bb7 10. Qe2 Nd7 11. O-O-O Qe7 12. h4 c5 13. dxc5 Nxc5 14. Nxc5 Qxc5 15. Ng5 h6 16. Nh7 Rfd8 17. Nxf6+ gxf6 18. Rh3 Kf8 19. Rg3 Ke7 20. Rg7 Rg8 21. Rxg8 Rxg8 22. g3 Rd8 23. Bc2 Rxd1+ 24. Bxd1 Qd5 25. Bb3 Qh1+ 26. Kd2 Qb1 27. Ke3 Qe4+ 28. Kd2 Qb1 29. Ke3 Qe4+ 30. Kd2 Qb1 31. Ke3 Qe4+ 32. Kd2 Qb1 33. Ke3 Qe4+ 34. Kd2 Qb1 35. Ke3 Qe4+ 36. Kd2 Qb1 37. Ke3 Qe4+ 38. Kd2 Qb1 39. Ke3 Qe4+ 40. Kd2 Qb1 41. Ke3 Qe4+ 42. Kd2 Qb1 43. Ke3 Qe4+ 44. Kd2 Qb1 45. Ke3 Qe4+ 46. Kd2 Qb1 47. Ke3 Qe4+ 48. Kd2 Qb1 49. Ke3 Qe4+ 50. Kd2 Qb1 51. Ke3 Qe4+ 52. Kd2 Qb1 53. Ke3 Qe4+ 54. Kd2 Qb1 55. Ke3 Qe4+ 56. Kd2 Qb1 57. Ke3 Qe4+ 58. Kd2 Qb1 59. Ke3 Qe4+ 60. Kd2 Qb1 61. Ke3 Qe4+ 62. Kd2 Qb1 63. Ke3 Qe4+ 64. Kd2 Qb1 65. Ke3 Qe4+ 66. Kd2 Qb1 67. Ke3 Qe4+ 68. Kd2 Qb1 69. Ke3 Qe4+ 70. Kd2 Qb1 71. Ke3 Qe4+ 72. Kd2 Qb1 73. Ke3 Qe4+ 74. Kd2 Qb1 75. Ke3 Q",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Bxf6",
            "Bxf6",
            "Nf3",
            "O-O",
            "c3",
            "b6",
            "Bd3",
            "Bb7",
            "Qe2",
            "Nd7",
            "O-O-O",
            "Qe7",
            "h4",
            "c5",
            "dxc5",
            "Nxc5",
            "Nxc5",
            "Qxc5",
            "Ng5",
            "h6",
            "Nh7",
            "Rfd8",
            "Nxf6+",
            "gxf6",
            "Rh3",
            "Kf8",
            "Rg3",
            "Ke7",
            "Rg7",
            "Rg8",
            "Rxg8",
            "Rxg8",
            "g3",
            "Rd8",
            "Bc2",
            "Rxd1+",
            "Bxd1",
            "Qd5",
            "Bb3",
            "Qh1+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3"
          ],
          "plan_execute": [
            "e6",
            "e4",
            "dxe4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c1g5",
          "positional_uci": "c1g5",
          "neutral_uci": "c1g5",
          "consensus_move": "c1g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Bxf6",
              "Bxf6",
              "Nf3",
              "O-O",
              "c3",
              "b6",
              "Bd3",
              "Bb7",
              "Qe2",
              "Nd7",
              "O-O-O",
              "Qe7",
              "h4",
              "c5",
              "dxc5",
              "Nxc5",
              "Nxc5",
              "Qxc5",
              "Ng5",
              "h6",
              "Ne4",
              "Qe5",
              "Nxf6+",
              "Qxf6",
              "f3",
              "Rfd8",
              "Bc2",
              "Rxd1+",
              "Qxd1",
              "Rd8",
              "Qe2",
              "Qf4+",
              "Kb1",
              "Rd2",
              "Qb5",
              "g6",
              "h5",
              "Rxg2",
              "hxg6",
              "fxg6",
              "Qe8+",
              "Kg7",
              "Qxe6",
              "Qf7",
              "Qe5+",
              "Kh7",
              "Qe3",
              "h5",
              "Rxh5+",
              "Kg8",
              "Rh1",
              "Bxf3",
              "Qe5",
              "Rg1+",
              "Rxg1",
              "Bd5",
              "Rxg6+",
              "Kf8",
              "Rf6",
              "Bxa2+",
              "Ka1",
              "Bc4",
              "Rxf7+",
              "Bxf7",
              "Qb8+",
              "Kg7",
              "Qxa7",
              "Kf6",
              "Qxb6+",
              "Be6",
              "Bb3",
              "Ke5",
              "Qxe6+",
              "Kf4",
              "c4",
              "Kf3",
              "c5",
              "Kf4",
              "c6",
              "Kf3",
              "c7",
              "Kf4",
              "c8=Q",
              "Kf3",
              "Qf8+",
              "Kg3",
              "Qg6+",
              "Kh4",
              "Qh8#",
              "e4",
              "d5",
              "Nc3",
              "Nf6",
              "e6",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nf3",
              "O-O",
              "c3",
              "b6",
              "Bd3",
              "Bb7",
              "Qe2",
              "Nd7",
              "O-O-O",
              "Qe7",
              "h4",
              "c5",
              "dxc5",
              "Nxc5",
              "Nxc5",
              "Qxc5",
              "Ng5",
              "h6",
              "Ne4",
              "Qe5",
              "Nxf6+",
              "Qxf6",
              "f3",
              "Rfd8",
              "Bc2",
              "Rxd1+",
              "Qxd1",
              "Rd8",
              "Qe2",
              "Qf4+",
              "Kb1",
              "Rd2",
              "Qb5",
              "g6",
              "h5",
              "Rxg2",
              "hxg6",
              "fxg6",
              "Qe8+",
              "Kg7",
              "Qxe6",
              "Qf7",
              "Qe5+",
              "Kh7",
              "Qe3",
              "h5",
              "Rxh5+",
              "Kg8",
              "Rh1",
              "Bxf3",
              "Qe5",
              "Rg1+",
              "Rxg1",
              "Bd5",
              "Rxg6+",
              "Kf8",
              "Rf6",
              "Bxa2+",
              "Ka1",
              "Bc4",
              "Rxf7+",
              "Bxf7",
              "Qb8+",
              "Kg7",
              "Qxa7",
              "Kf6",
              "Qxb6+",
              "Be6",
              "Bb3",
              "Ke5",
              "Qxe6+",
              "Kf4",
              "c4",
              "Kf3"
            ],
            "execute": [
              "e6",
              "e4",
              "dxe4"
            ]
          },
          "positional": {
            "full": [
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Bxf6",
              "Bxf6",
              "Nf3",
              "O-O",
              "c3",
              "b6",
              "Bd3",
              "Bb7",
              "Qe2",
              "Nd7",
              "O-O-O",
              "Qe7",
              "h4",
              "c5",
              "dxc5",
              "Nxc5",
              "Nxc5",
              "Qxc5",
              "Ng5",
              "h6",
              "Nh7",
              "Rfd8",
              "Nxf6+",
              "gxf6",
              "Rh3",
              "Kf8",
              "Rg3",
              "Ke7",
              "Qd2",
              "Rd6",
              "Qxh6",
              "Rad8",
              "Qe3",
              "Qxe3+",
              "Rxe3",
              "Bxg2",
              "h5",
              "f5",
              "h6",
              "Rh8",
              "Rg3",
              "Be4",
              "Bxe4",
              "Rxd1+",
              "Kxd1",
              "fxe4",
              "Rh3",
              "f5",
              "Ke2",
              "Kf6",
              "Ke3",
              "Kg6",
              "Kf4",
              "Rxh6",
              "Rxh6+",
              "Kxh6",
              "Ke5",
              "Kg5",
              "Kxe6",
              "f4",
              "Ke5",
              "e3",
              "fxe3",
              "fxe3",
              "Kd4",
              "e2",
              "Kc4",
              "e1=Q",
              "Kb3",
              "Qd1+",
              "Ka3",
              "Kf5",
              "b3",
              "Ke5",
              "Kb4",
              "Kd5",
              "c4+",
              "Kc6",
              "a4",
              "Qd2+",
              "Ka3",
              "Kc5",
              "a5",
              "Qxa5+",
              "Kb2",
              "Kb4",
              "Kc2",
              "Qa2+",
              "Kd3",
              "Qxb3+",
              "Kd4",
              "Qxc4+",
              "Ke5",
              "Kc5",
              "Kf6",
              "Qd5",
              "Ke7",
              "Qd6+",
              "Kf7",
              "Kd5",
              "Kg7",
              "Qe6",
              "Kh7",
              "Qg4",
              "Kh6",
              "Ke6",
              "Kh7",
              "Kf7",
              "Kh6",
              "Qg6#",
              "e4",
              "e5",
              "e6",
              "e7"
            ],
            "execute": [
              "e6",
              "e4",
              "dxe4"
            ]
          },
          "neutral": {
            "full": [
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Bxf6",
              "Bxf6",
              "Nf3",
              "O-O",
              "c3",
              "b6",
              "Bd3",
              "Bb7",
              "Qe2",
              "Nd7",
              "O-O-O",
              "Qe7",
              "h4",
              "c5",
              "dxc5",
              "Nxc5",
              "Nxc5",
              "Qxc5",
              "Ng5",
              "h6",
              "Nh7",
              "Rfd8",
              "Nxf6+",
              "gxf6",
              "Rh3",
              "Kf8",
              "Rg3",
              "Ke7",
              "Rg7",
              "Rg8",
              "Rxg8",
              "Rxg8",
              "g3",
              "Rd8",
              "Bc2",
              "Rxd1+",
              "Bxd1",
              "Qd5",
              "Bb3",
              "Qh1+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3",
              "Qe4+",
              "Kd2",
              "Qb1",
              "Ke3"
            ],
            "execute": [
              "e6",
              "e4",
              "dxe4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e6",
            "e4",
            "dxe4"
          ],
          "full_moves": [
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Bxf6",
            "Bxf6",
            "Nf3",
            "O-O",
            "c3",
            "b6",
            "Bd3",
            "Bb7",
            "Qe2",
            "Nd7",
            "O-O-O",
            "Qe7",
            "h4",
            "c5",
            "dxc5",
            "Nxc5",
            "Nxc5",
            "Qxc5",
            "Ng5",
            "h6",
            "Nh7",
            "Rfd8",
            "Nxf6+",
            "gxf6",
            "Rh3",
            "Kf8",
            "Rg3",
            "Ke7",
            "Rg7",
            "Rg8",
            "Rxg8",
            "Rxg8",
            "g3",
            "Rd8",
            "Bc2",
            "Rxd1+",
            "Bxd1",
            "Qd5",
            "Bb3",
            "Qh1+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3",
            "Qe4+",
            "Kd2",
            "Qb1",
            "Ke3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 495,
            "total_tokens": 620,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1775,
          "total_tokens": 2149
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 495,
            "total_tokens": 620,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p4/3P4/2N5/PPP1PPPP/R1BQKBNR w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": "g5f6",
          "aggressive_response": "4. Bxf6 exf6 5. e3 Bb4 6. Nge2 O-O 7. a3 Ba5 8. b4 Bb6 9. Nf4 c6 10. Bd3 Re8 11. O-O Nd7 12. Qh5 Nf8 13. Nce2 Bc7 14. c4 dxc4 15. Bxc4 Be6 16. Nxe6 Nxe6 17. Ng3 Bxg3 18. hxg3 Qd7 19. Rfd1 Rad8 20. Rac1 Ng5 21. d5 cxd5 22. Rxd5 Qe7 23. Rcd1 Rxd5 24. Rxd5 Rd8 25. Qd1 Rxd5 26. Qxd5 Ne6 27. Qe4 Qd7 28. Bd5 b6 29. Bc6 Qd1+ 30. Kh2 Qh5+ 31. Kg1 Qd1+ 32. Kh2 Qh5+ 33. Kg1 Qd1+ 34. Kh2 Qh5+ 35. Kg1 Qd1+ 36. Kh2 Qh5+ 37. Kg1 Qd1+ 38. Kh2 Qh5+ 39. Kg1 Qd1+ 40. Kh2 Qh5+ 41. Kg1 Qd1+ 42. Kh2 Qh5+ 43. Kg1 Qd1+ 44. Kh2 Qh5+ 45. Kg1 Qd1+ 46. Kh2 Qh5+ 47. Kg1 Qd1+ 48. Kh2 Qh5+ 49. Kg1 Qd1+ 50. Kh2 Qh5+ 51. Kg1 Qd1+ 52. Kh2 Qh5+ 53. Kg1 Qd1+ 54. Kh2 Qh5+ 55. Kg1 Qd1+ 56. Kh2 Qh5+ 57. Kg1 Qd1+ 58. Kh2 Qh5+ 59. Kg1 Qd1+ 60. Kh2 Qh5+ 61. Kg1 Qd1+ 62. Kh2 Qh5+ 63. Kg1 Qd1+ 64. Kh2 Qh5+ 65. Kg1 Qd1+ 66. Kh2 Qh5+ 67. Kg1 Qd1+ 68. Kh2 Qh5+ 69. Kg1 Qd1+ 70. Kh2 Qh5+ 71. Kg1 Qd1+ 72. Kh2 Qh5+ 73. Kg1 Qd1+ 74. Kh2 Qh5+ 75. Kg1 Qd1+ 76. Kh2 Qh5+ 77",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "exf6",
            "e3",
            "Bb4",
            "Nge2",
            "O-O",
            "a3",
            "Ba5",
            "b4",
            "Bb6",
            "Nf4",
            "c6",
            "Bd3",
            "Re8",
            "O-O",
            "Nd7",
            "Qh5",
            "Nf8",
            "Nce2",
            "Bc7",
            "c4",
            "dxc4",
            "Bxc4",
            "Be6",
            "Nxe6",
            "Nxe6",
            "Ng3",
            "Bxg3",
            "hxg3",
            "Qd7",
            "Rfd1",
            "Rad8",
            "Rac1",
            "Ng5",
            "d5",
            "cxd5",
            "Rxd5",
            "Qe7",
            "Rcd1",
            "Rxd5",
            "Rxd5",
            "Rd8",
            "Qd1",
            "Rxd5",
            "Qxd5",
            "Ne6",
            "Qe4",
            "Qd7",
            "Bd5",
            "b6",
            "Bc6",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+",
            "Kg1",
            "Qd1+",
            "Kh2",
            "Qh5+"
          ],
          "plan_execute": [
            "exf6",
            "e3",
            "Bb4"
          ]
        },
        "query2": {
          "positional_move": "Bxf6",
          "positional_uci": "g5f6",
          "positional_response": "4. Bxf6 exf6 5. e3 Bb4 6. Nge2 O-O 7. a3 Ba5 8. b4 Bb6 9. Nf4 c6 10. Bd3 Bc7 11. Qf3 Bxf4 12. Qxf4 Nd7 13. O-O Re8 14. e4 dxe4 15. Nxe4 Nf8 16. Nd6 Re6 17. Nf5 Ng6 18. Qg3 Re8 19. Nd6 Re6 20. Nxf7 Kxf7 21. Qxg6+ Kf8 22. Qh7 Re8 23. Bg6 Be6 24. Bxe8 Qxe8 25. Rfe1 Qf7 26. Qh8+ Qg8 27. Qxg8+ Bxg8 28. Re3 Rd8 29. c3 Bc4 30. Rae1 Rd7 31. Re8+ Kf7 32. Ra8 a6 33. Rae8 b5 34. Ra8 Re7 35. Rxe7+ Kxe7 36. Rxa6 Kd6 37. Ra7 g6 38. Rh7 h5 39. Rh6 Bd3 40. f3 Kd5 41. Kf2 Kc4 42. Ke3 Kxc3 43. Rh8 Bc4 44. Rc8 Bd5 45. Rf8 f5 46. Rf6 Kb3 47. Rxg6 Kxa3 48. Rg5 Kxb4 49. Rxf5 Kc4 50. Rxh5 b4 51. Rh8 b3 52. Rb8 Kc3 53. h4 b2 54. h5 Kc2 55. h6 b1=Q 56. Rxb1 Kxb1 57. h7 Kc2 58. h8=Q Kc3 59. Qe5 Kc4 60. g4 Kb5 61. g5 Kb6 62. g6 Kb5 63. g7 Kb6 64. Qxd5 cxd5 65. g8=Q Kc6 66. Qe6+ Kb5 67. Qxd5+ Kb4 68. Qc5+ Kb3 69. Kd3 Kb2 70. Qc3+ Kb1 71. Qd2 Ka1 72. Kc3 Kb1 73. Qb2# e4 dxe4 Qf4 exf3 Qxf3 Bb7 Qf2+ Kc8 Qf8+ Kc7 Qf7+ Kc8 Qf8+ Kc7 Qf7+ Kc8 Qf8+ Kc7 Qf7+ K",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "exf6",
            "e3",
            "Bb4",
            "Nge2",
            "O-O",
            "a3",
            "Ba5",
            "b4",
            "Bb6",
            "Nf4",
            "c6",
            "Bd3",
            "Bc7",
            "Qf3",
            "Bxf4",
            "Qxf4",
            "Nd7",
            "O-O",
            "Re8",
            "e4",
            "dxe4",
            "Nxe4",
            "Nf8",
            "Nd6",
            "Re6",
            "Nf5",
            "Ng6",
            "Qg3",
            "Re8",
            "Nd6",
            "Re6",
            "Nxf7",
            "Kxf7",
            "Qxg6+",
            "Kf8",
            "Qh7",
            "Re8",
            "Bg6",
            "Be6",
            "Bxe8",
            "Qxe8",
            "Rfe1",
            "Qf7",
            "Qh8+",
            "Qg8",
            "Qxg8+",
            "Bxg8",
            "Re3",
            "Rd8",
            "c3",
            "Bc4",
            "Rae1",
            "Rd7",
            "Re8+",
            "Kf7",
            "Ra8",
            "a6",
            "Rae8",
            "b5",
            "Ra8",
            "Re7",
            "Rxe7+",
            "Kxe7",
            "Rxa6",
            "Kd6",
            "Ra7",
            "g6",
            "Rh7",
            "h5",
            "Rh6",
            "Bd3",
            "f3",
            "Kd5",
            "Kf2",
            "Kc4",
            "Ke3",
            "Kxc3",
            "Rh8",
            "Bc4",
            "Rc8",
            "Bd5",
            "Rf8",
            "f5",
            "Rf6",
            "Kb3",
            "Rxg6",
            "Kxa3",
            "Rg5",
            "Kxb4",
            "Rxf5",
            "Kc4",
            "Rxh5",
            "b4",
            "Rh8",
            "b3",
            "Rb8",
            "Kc3",
            "h4",
            "b2",
            "h5",
            "Kc2",
            "h6",
            "b1=Q",
            "Rxb1",
            "Kxb1",
            "h7",
            "Kc2",
            "h8=Q",
            "Kc3",
            "Qe5",
            "Kc4",
            "g4",
            "Kb5",
            "g5",
            "Kb6",
            "g6",
            "Kb5",
            "g7",
            "Kb6",
            "Qxd5",
            "cxd5",
            "g8=Q",
            "Kc6",
            "Qe6+",
            "Kb5",
            "Qxd5+",
            "Kb4",
            "Qc5+",
            "Kb3",
            "Kd3",
            "Kb2",
            "Qc3+",
            "Kb1",
            "Qd2",
            "Ka1",
            "Kc3",
            "Kb1",
            "Qb2#",
            "e4",
            "dxe4",
            "Qf4",
            "exf3",
            "Qxf3",
            "Bb7",
            "Qf2+",
            "Kc8",
            "Qf8+",
            "Kc7",
            "Qf7+",
            "Kc8",
            "Qf8+",
            "Kc7",
            "Qf7+",
            "Kc8",
            "Qf8+",
            "Kc7",
            "Qf7+"
          ],
          "plan_execute": [
            "exf6",
            "e3",
            "Bb4"
          ]
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "g5f6",
          "neutral_response": "4. Bxf6 exf6 5. e3 Bb4 6. Nge2 O-O 7. a3 Ba5 8. b4 Bb6 9. Nf4 c6 10. Bd3 Re8 11. O-O Nd7 12. Qh5 Nf8 13. Nce2 Bc7 14. c4 dxc4 15. Bxc4 Be6 16. Nxe6 Nxe6 17. Ng3 Bxg3 18. hxg3 Qd7 19. Rfd1 Rad8 20. Rac1 Nc7 21. a4 Nd5 22. b5 f5 23. bxc6 bxc6 24. Bd3 Ne7 25. Rc5 Qe6 26. Bxf5 Nxf5 27. Qxf5 Qb3 28. Qc2 Qxc2 29. Rxc2 Rd6 30. Rdc1 Ree6 31. Rc5 Kf8 32. Ra5 Rd7 33. Ra6 Rc7 34. d5 Rd6 35. Raxc6 Rcxc6 36. dxc6 Rd8 37. c7 Rc8 38. Kf1 Ke7 39. Ke2 Kd7 40. Kd3 Rxc7 41. Rxc7+ Kxc7 42. Kc4 Kc6 43. e4 f6 44. f4 g6 45. g4 a6 46. a5 Kd6 47. Kd4 Kc6 48. e5 fxe5+ 49. fxe5 Kd7 50. Kd5 Ke7 51. e6 Ke8 52. Kd6 Kd8 53. e7+ Ke8 54. Ke6 h5 55. gxh5 gxh5 56. g3 h4 57. gxh4 * h5 g5 h6",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 442,
            "total_tokens": 574,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exf6",
            "e3",
            "Bb4",
            "Nge2",
            "O-O",
            "a3",
            "Ba5",
            "b4",
            "Bb6",
            "Nf4",
            "c6",
            "Bd3",
            "Re8",
            "O-O",
            "Nd7",
            "Qh5",
            "Nf8",
            "Nce2",
            "Bc7",
            "c4",
            "dxc4",
            "Bxc4",
            "Be6",
            "Nxe6",
            "Nxe6",
            "Ng3",
            "Bxg3",
            "hxg3",
            "Qd7",
            "Rfd1",
            "Rad8",
            "Rac1",
            "Nc7",
            "a4",
            "Nd5",
            "b5",
            "f5",
            "bxc6",
            "bxc6",
            "Bd3",
            "Ne7",
            "Rc5",
            "Qe6",
            "Bxf5",
            "Nxf5",
            "Qxf5",
            "Qb3",
            "Qc2",
            "Qxc2",
            "Rxc2",
            "Rd6",
            "Rdc1",
            "Ree6",
            "Rc5",
            "Kf8",
            "Ra5",
            "Rd7",
            "Ra6",
            "Rc7",
            "d5",
            "Rd6",
            "Raxc6",
            "Rcxc6",
            "dxc6",
            "Rd8",
            "c7",
            "Rc8",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd7",
            "Kd3",
            "Rxc7",
            "Rxc7+",
            "Kxc7",
            "Kc4",
            "Kc6",
            "e4",
            "f6",
            "f4",
            "g6",
            "g4",
            "a6",
            "a5",
            "Kd6",
            "Kd4",
            "Kc6",
            "e5",
            "fxe5+",
            "fxe5",
            "Kd7",
            "Kd5",
            "Ke7",
            "e6",
            "Ke8",
            "Kd6",
            "Kd8",
            "e7+",
            "Ke8",
            "Ke6",
            "h5",
            "gxh5",
            "gxh5",
            "g3",
            "h4",
            "gxh4",
            "h5",
            "g5",
            "h6"
          ],
          "plan_execute": [
            "exf6",
            "e3",
            "Bb4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g5f6",
          "positional_uci": "g5f6",
          "neutral_uci": "g5f6",
          "consensus_move": "g5f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "exf6",
              "e3",
              "Bb4",
              "Nge2",
              "O-O",
              "a3",
              "Ba5",
              "b4",
              "Bb6",
              "Nf4",
              "c6",
              "Bd3",
              "Re8",
              "O-O",
              "Nd7",
              "Qh5",
              "Nf8",
              "Nce2",
              "Bc7",
              "c4",
              "dxc4",
              "Bxc4",
              "Be6",
              "Nxe6",
              "Nxe6",
              "Ng3",
              "Bxg3",
              "hxg3",
              "Qd7",
              "Rfd1",
              "Rad8",
              "Rac1",
              "Ng5",
              "d5",
              "cxd5",
              "Rxd5",
              "Qe7",
              "Rcd1",
              "Rxd5",
              "Rxd5",
              "Rd8",
              "Qd1",
              "Rxd5",
              "Qxd5",
              "Ne6",
              "Qe4",
              "Qd7",
              "Bd5",
              "b6",
              "Bc6",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+",
              "Kg1",
              "Qd1+",
              "Kh2",
              "Qh5+"
            ],
            "execute": [
              "exf6",
              "e3",
              "Bb4"
            ]
          },
          "positional": {
            "full": [
              "exf6",
              "e3",
              "Bb4",
              "Nge2",
              "O-O",
              "a3",
              "Ba5",
              "b4",
              "Bb6",
              "Nf4",
              "c6",
              "Bd3",
              "Bc7",
              "Qf3",
              "Bxf4",
              "Qxf4",
              "Nd7",
              "O-O",
              "Re8",
              "e4",
              "dxe4",
              "Nxe4",
              "Nf8",
              "Nd6",
              "Re6",
              "Nf5",
              "Ng6",
              "Qg3",
              "Re8",
              "Nd6",
              "Re6",
              "Nxf7",
              "Kxf7",
              "Qxg6+",
              "Kf8",
              "Qh7",
              "Re8",
              "Bg6",
              "Be6",
              "Bxe8",
              "Qxe8",
              "Rfe1",
              "Qf7",
              "Qh8+",
              "Qg8",
              "Qxg8+",
              "Bxg8",
              "Re3",
              "Rd8",
              "c3",
              "Bc4",
              "Rae1",
              "Rd7",
              "Re8+",
              "Kf7",
              "Ra8",
              "a6",
              "Rae8",
              "b5",
              "Ra8",
              "Re7",
              "Rxe7+",
              "Kxe7",
              "Rxa6",
              "Kd6",
              "Ra7",
              "g6",
              "Rh7",
              "h5",
              "Rh6",
              "Bd3",
              "f3",
              "Kd5",
              "Kf2",
              "Kc4",
              "Ke3",
              "Kxc3",
              "Rh8",
              "Bc4",
              "Rc8",
              "Bd5",
              "Rf8",
              "f5",
              "Rf6",
              "Kb3",
              "Rxg6",
              "Kxa3",
              "Rg5",
              "Kxb4",
              "Rxf5",
              "Kc4",
              "Rxh5",
              "b4",
              "Rh8",
              "b3",
              "Rb8",
              "Kc3",
              "h4",
              "b2",
              "h5",
              "Kc2",
              "h6",
              "b1=Q",
              "Rxb1",
              "Kxb1",
              "h7",
              "Kc2",
              "h8=Q",
              "Kc3",
              "Qe5",
              "Kc4",
              "g4",
              "Kb5",
              "g5",
              "Kb6",
              "g6",
              "Kb5",
              "g7",
              "Kb6",
              "Qxd5",
              "cxd5",
              "g8=Q",
              "Kc6",
              "Qe6+",
              "Kb5",
              "Qxd5+",
              "Kb4",
              "Qc5+",
              "Kb3",
              "Kd3",
              "Kb2",
              "Qc3+",
              "Kb1",
              "Qd2",
              "Ka1",
              "Kc3",
              "Kb1",
              "Qb2#",
              "e4",
              "dxe4",
              "Qf4",
              "exf3",
              "Qxf3",
              "Bb7",
              "Qf2+",
              "Kc8",
              "Qf8+",
              "Kc7",
              "Qf7+",
              "Kc8",
              "Qf8+",
              "Kc7",
              "Qf7+",
              "Kc8",
              "Qf8+",
              "Kc7",
              "Qf7+"
            ],
            "execute": [
              "exf6",
              "e3",
              "Bb4"
            ]
          },
          "neutral": {
            "full": [
              "exf6",
              "e3",
              "Bb4",
              "Nge2",
              "O-O",
              "a3",
              "Ba5",
              "b4",
              "Bb6",
              "Nf4",
              "c6",
              "Bd3",
              "Re8",
              "O-O",
              "Nd7",
              "Qh5",
              "Nf8",
              "Nce2",
              "Bc7",
              "c4",
              "dxc4",
              "Bxc4",
              "Be6",
              "Nxe6",
              "Nxe6",
              "Ng3",
              "Bxg3",
              "hxg3",
              "Qd7",
              "Rfd1",
              "Rad8",
              "Rac1",
              "Nc7",
              "a4",
              "Nd5",
              "b5",
              "f5",
              "bxc6",
              "bxc6",
              "Bd3",
              "Ne7",
              "Rc5",
              "Qe6",
              "Bxf5",
              "Nxf5",
              "Qxf5",
              "Qb3",
              "Qc2",
              "Qxc2",
              "Rxc2",
              "Rd6",
              "Rdc1",
              "Ree6",
              "Rc5",
              "Kf8",
              "Ra5",
              "Rd7",
              "Ra6",
              "Rc7",
              "d5",
              "Rd6",
              "Raxc6",
              "Rcxc6",
              "dxc6",
              "Rd8",
              "c7",
              "Rc8",
              "Kf1",
              "Ke7",
              "Ke2",
              "Kd7",
              "Kd3",
              "Rxc7",
              "Rxc7+",
              "Kxc7",
              "Kc4",
              "Kc6",
              "e4",
              "f6",
              "f4",
              "g6",
              "g4",
              "a6",
              "a5",
              "Kd6",
              "Kd4",
              "Kc6",
              "e5",
              "fxe5+",
              "fxe5",
              "Kd7",
              "Kd5",
              "Ke7",
              "e6",
              "Ke8",
              "Kd6",
              "Kd8",
              "e7+",
              "Ke8",
              "Ke6",
              "h5",
              "gxh5",
              "gxh5",
              "g3",
              "h4",
              "gxh4",
              "h5",
              "g5",
              "h6"
            ],
            "execute": [
              "exf6",
              "e3",
              "Bb4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "exf6",
            "e3",
            "Bb4"
          ],
          "full_moves": [
            "exf6",
            "e3",
            "Bb4",
            "Nge2",
            "O-O",
            "a3",
            "Ba5",
            "b4",
            "Bb6",
            "Nf4",
            "c6",
            "Bd3",
            "Re8",
            "O-O",
            "Nd7",
            "Qh5",
            "Nf8",
            "Nce2",
            "Bc7",
            "c4",
            "dxc4",
            "Bxc4",
            "Be6",
            "Nxe6",
            "Nxe6",
            "Ng3",
            "Bxg3",
            "hxg3",
            "Qd7",
            "Rfd1",
            "Rad8",
            "Rac1",
            "Nc7",
            "a4",
            "Nd5",
            "b5",
            "f5",
            "bxc6",
            "bxc6",
            "Bd3",
            "Ne7",
            "Rc5",
            "Qe6",
            "Bxf5",
            "Nxf5",
            "Qxf5",
            "Qb3",
            "Qc2",
            "Qxc2",
            "Rxc2",
            "Rd6",
            "Rdc1",
            "Ree6",
            "Rc5",
            "Kf8",
            "Ra5",
            "Rd7",
            "Ra6",
            "Rc7",
            "d5",
            "Rd6",
            "Raxc6",
            "Rcxc6",
            "dxc6",
            "Rd8",
            "c7",
            "Rc8",
            "Kf1",
            "Ke7",
            "Ke2",
            "Kd7",
            "Kd3",
            "Rxc7",
            "Rxc7+",
            "Kxc7",
            "Kc4",
            "Kc6",
            "e4",
            "f6",
            "f4",
            "g6",
            "g4",
            "a6",
            "a5",
            "Kd6",
            "Kd4",
            "Kc6",
            "e5",
            "fxe5+",
            "fxe5",
            "Kd7",
            "Kd5",
            "Ke7",
            "e6",
            "Ke8",
            "Kd6",
            "Kd8",
            "e7+",
            "Ke8",
            "Ke6",
            "h5",
            "gxh5",
            "gxh5",
            "g3",
            "h4",
            "gxh4",
            "h5",
            "g5",
            "h6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 442,
            "total_tokens": 574,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1722,
          "total_tokens": 2120
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 442,
            "total_tokens": 574,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1ppp1/5n1p/3p2B1/3P4/2N5/PPP1PPPP/R2QKBNR w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "5. e4 dxe4 6. Nxe4 Bf5 7. Ng3 Bg6 8. Nf3 Nc6 9. Bb5 Qd5 10. c4 Qe6+ 11. Qe2 Qxe2+ 12. Nxe2 O-O-O 13. Bxc6 bxc6 14. O-O e6 15. Rfd1 c5 16. d5 exd5 17. cxd5 Be4 18. Nc3 Bxf3 19. gxf3 Rg8+ 20. Kf1 Bd6 21. Ne4 Bxh2 22. Nxf6 Rg6 23. Ne4 Re8 24. Ke2 f5 25. Rh1 Bd6 26. Kd3 fxe4+ 27. fxe4 Rf8 28. Raf1 Rf3+ 29. Ke2 Rf4 30. f3 Rg2+ 31. Rf2 Rxf2+ 32. Kxf2 Rf6 33. Ke3 Bf4+ 34. Kd3 Be5 35. b3 Rxf3+ 36. Kc4 Rc3+ 37. Kb5 Kb7 38. Rxh6 a6+ 39. Ka4 Rc2 40. a3 Re2 41. Rh4 Kb6 42. Rh6+ Bd6 43. Re6 Kb7 44. b4 cxb4 45. axb4 Ra2+ 46. Kb3 Ra1 47. e5 Re1 48. exd6 Rxe6 49. dxe6 cxd6 50. e7 Kc7 51. e8=Q Kb6 52. Qd8+ Kc6 53. Qc8+ Kb6 54. Qd7 a5 55. Qxd6+ Kb5 56. Qc5+ Ka6 57. Qxa5+ Kb7 58. Kc4 Kc6 59. Qa6+ Kc7 60. Kc5 Kb8 61. Qh6 Kc7 62. Qh7+ Kd8 63. Kd6 Ke8 64. Qe7# e4 d5 Nc6 Bg5 h6 Bxf6 gxf6 e4 dxe4 Nxe4 Bf5 Ng3 Bg6 Nf4 Bg6 Nxf6 Bxf6 gxf6 Rg8 Kf7 Bd6 Ne4 Bf5 Bg6 Nf4 Bg5 h6 Bxf6 gxf6 e4 dxe4 Nxe4 Bf5 Ng3 Bg6 Nf4 Bf5 Ng3 Bg6 Nxf6 Bxf6 gxf6 Rg8 Kf7 Bd6 Ne4 Bf5 Bg6",
          "aggressive_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxe4",
            "Nxe4",
            "Bf5",
            "Ng3",
            "Bg6",
            "Nf4",
            "Bf5",
            "Ng3",
            "Bg6",
            "Nxf6",
            "Bxf6",
            "gxf6",
            "Rg8",
            "Kf7",
            "Bd6",
            "Ne4",
            "Bf5",
            "Bg6"
          ],
          "plan_execute": [
            "dxe4",
            "Nxe4",
            "Bf5"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "5. e4 dxe4 6. Nxe4 Bf5 7. Ng3 Bg6 8. Nf3 Nc6 9. Bb5 Qd5 10. c4 Qd6 11. O-O O-O-O 12. d5 Ne5 13. Nd4 e6 14. Qa4 a6 15. Rac1 axb5 16. Nxb5 Qa6 17. Qb3 Bc5 18. Kh1 Nd3 19. Rc2 Nb4 20. Rd2 Qxa2 21. Qf3 Qxc4 22. Nc3 Nxd5 23. Nxd5 Rxd5 24. Rxd5 Qxd5 25. Qxf6 Rd8 26. h3 Bd4 27. Qf4 Bxb2 28. Qxh6 Be5 29. Qe3 Bxg3 30. fxg3 Qd3 31. Qf4 Rd4 32. Qf6 Qxg3 33. Qxd4 Qd6 34. Qh8+ Kd7 35. Qa1 Ke7 36. Rd1 Qc6 37. Qa3+ Ke8 38. Qa8+ Ke7 39. Qd8# d4 e5 Qd5 Qe4",
          "positional_tokens": {
            "prompt_tokens": 142,
            "completion_tokens": 305,
            "total_tokens": 447,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe4",
            "Nxe4",
            "Bf5",
            "Ng3",
            "Bg6",
            "Nf3",
            "Nc6",
            "Bb5",
            "Qd5",
            "c4",
            "Qd6",
            "O-O",
            "O-O-O",
            "d5",
            "Ne5",
            "Nd4",
            "e6",
            "Qa4",
            "a6",
            "Rac1",
            "axb5",
            "Nxb5",
            "Qa6",
            "Qb3",
            "Bc5",
            "Kh1",
            "Nd3",
            "Rc2",
            "Nb4",
            "Rd2",
            "Qxa2",
            "Qf3",
            "Qxc4",
            "Nc3",
            "Nxd5",
            "Nxd5",
            "Rxd5",
            "Rxd5",
            "Qxd5",
            "Qxf6",
            "Rd8",
            "h3",
            "Bd4",
            "Qf4",
            "Bxb2",
            "Qxh6",
            "Be5",
            "Qe3",
            "Bxg3",
            "fxg3",
            "Qd3",
            "Qf4",
            "Rd4",
            "Qf6",
            "Qxg3",
            "Qxd4",
            "Qd6",
            "Qh8+",
            "Kd7",
            "Qa1",
            "Ke7",
            "Rd1",
            "Qc6",
            "Qa3+",
            "Ke8",
            "Qa8+",
            "Ke7",
            "Qd8#",
            "d4",
            "e5",
            "Qd5",
            "Qe4"
          ],
          "plan_execute": [
            "dxe4",
            "Nxe4",
            "Bf5"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "5. e4 dxe4 6. Nxe4 Bf5 7. Ng3 Bg6 8. Nf3 Nc6 9. Bb5 Qd5 10. c4 Qe6+ 11. Qe2 Qxe2+ 12. Kxe2 O-O-O 13. Bxc6 bxc6 14. Rhd1 e6 15. Rac1 c5 16. d5 Bd6 17. Rc3 Rhe8 18. Kf1 Be5 19. Nxe5 fxe5 20. Ra3 Kb7 21. Rb3+ Ka8 22. Rb5 exd5 23. Rxc5 dxc4 24. Rxd8+ Rxd8 25. Ke1 Rd4 26. Rxc7 Kb8 27. Rc5 f6 28. Ne2 Rd6 29. Rxc4 Bf7 30. Rb4+ Kc7 31. Nc3 Rb6 32. Rxb6 axb6 33. Kd2 Kc6 34. Ke3 Kc5 35. Ne4+ Kc4 36. Nd6+ Kd5 37. Nxf7 Ke6 38. Nxh6 f5 39. g4 f4+ 40. Ke4 Kf6 41. h4 Kg6 42. g5 Kh5 43. Kxe5 Kxh4 44. g6 Kg5 45. g7 Kxh6 46. g8=Q Kh5 47. Kf5 Kh4 48. Qg4# e5 49. Qg5# e4 50. Qg4# e3 51. Qg5# e2",
          "neutral_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 396,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg4#",
            "e3",
            "Qg5#",
            "e2"
          ],
          "plan_execute": [
            "Qg4#",
            "e3",
            "Qg5#"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "dxe4",
              "Nxe4",
              "Bf5",
              "Ng3",
              "Bg6",
              "Nf4",
              "Bf5",
              "Ng3",
              "Bg6",
              "Nxf6",
              "Bxf6",
              "gxf6",
              "Rg8",
              "Kf7",
              "Bd6",
              "Ne4",
              "Bf5",
              "Bg6"
            ],
            "execute": [
              "dxe4",
              "Nxe4",
              "Bf5"
            ]
          },
          "positional": {
            "full": [
              "dxe4",
              "Nxe4",
              "Bf5",
              "Ng3",
              "Bg6",
              "Nf3",
              "Nc6",
              "Bb5",
              "Qd5",
              "c4",
              "Qd6",
              "O-O",
              "O-O-O",
              "d5",
              "Ne5",
              "Nd4",
              "e6",
              "Qa4",
              "a6",
              "Rac1",
              "axb5",
              "Nxb5",
              "Qa6",
              "Qb3",
              "Bc5",
              "Kh1",
              "Nd3",
              "Rc2",
              "Nb4",
              "Rd2",
              "Qxa2",
              "Qf3",
              "Qxc4",
              "Nc3",
              "Nxd5",
              "Nxd5",
              "Rxd5",
              "Rxd5",
              "Qxd5",
              "Qxf6",
              "Rd8",
              "h3",
              "Bd4",
              "Qf4",
              "Bxb2",
              "Qxh6",
              "Be5",
              "Qe3",
              "Bxg3",
              "fxg3",
              "Qd3",
              "Qf4",
              "Rd4",
              "Qf6",
              "Qxg3",
              "Qxd4",
              "Qd6",
              "Qh8+",
              "Kd7",
              "Qa1",
              "Ke7",
              "Rd1",
              "Qc6",
              "Qa3+",
              "Ke8",
              "Qa8+",
              "Ke7",
              "Qd8#",
              "d4",
              "e5",
              "Qd5",
              "Qe4"
            ],
            "execute": [
              "dxe4",
              "Nxe4",
              "Bf5"
            ]
          },
          "neutral": {
            "full": [
              "Qg4#",
              "e3",
              "Qg5#",
              "e2"
            ],
            "execute": [
              "Qg4#",
              "e3",
              "Qg5#"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "dxe4",
            "Nxe4",
            "Bf5"
          ],
          "full_moves": [
            "dxe4",
            "Nxe4",
            "Bf5",
            "Ng3",
            "Bg6",
            "Nf4",
            "Bf5",
            "Ng3",
            "Bg6",
            "Nxf6",
            "Bxf6",
            "gxf6",
            "Rg8",
            "Kf7",
            "Bd6",
            "Ne4",
            "Bf5",
            "Bg6"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 142,
            "completion_tokens": 305,
            "total_tokens": 447,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 141,
            "completion_tokens": 396,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 425,
          "total_completion_tokens": 1341,
          "total_tokens": 1766
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 142,
            "completion_tokens": 640,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 142,
            "completion_tokens": 305,
            "total_tokens": 447,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 141,
            "completion_tokens": 396,
            "total_tokens": 537,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pp2/5p1p/3p4/3P4/2N5/PPP1PPPP/R2QKBNR w KQkq - 0 5"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb5",
          "aggressive_uci": "f1b5",
          "aggressive_response": "7. Bb5 Bd7 8. Nf3 a6 9. Ba4 b5 10. Bb3 Bg4 11. c3 e5 12. d5 Na5 13. Bc2 Nc4 14. b3 Nd6 15. Qd3 Bf5 16. Nxd6+ cxd6 17. Qxf5 Qc7 18. O-O Qxc3 19. Rac1 Qb2 20. Qxf6 Rg8 21. Bh7 Rg7 22. Rc7 Rxh7 23. Rfc1 Rd8 24. Qxd8+ Kxd8 25. Rc8+ Ke7 26. R1c7+ Kf6 27. h3 Qxa2 28. Rxf8 Qxb3 29. Rc6 Qxd5 30. Rxa6 b4 31. Rb8 b3 32. Rab6 e4 33. Nh2 Rg7 34. Rxb3 e3 35. Ng4+ Rxg4 36. hxg4 Qd1+ 37. Kh2 e2 38. Rf3+ Kg7 39. Rb7 e1=Q 40. Rbxf7+ Kg6 41. R7f6+ Kg5 42. R6f5+ Kg6 43. Rf6+ Kg7 44. Rf7+ Kg8 45. Rf8+ Kg7 46. R8f7+ Kg6 47. R7f6+ Kg5 48. R6f5+ Kg6 49. Rf6+ Kg7 50. Rf7+ Kg8 51. Rf8+ Kg7 52. R8f7+ Kg6 53. R7f6+ Kg5 54. R6f5+ Kg6 55. Rf6+ Kg7 56. Rf7+ Kg8 57. Rf8+ Kg7 58. R8f7+ Kg6 59. R7f6+ Kg5 60. R6f5+ Kg6 61. Rf6+ Kg7 62. Rf7+ Kg8 63. Rf8+ Kg7 64. R8f7+ Kg6 65. R7f6+ Kg5 66. R6f5+ Kg6 67. Rf6+ Kg7 68. Rf7+ Kg8 69. Rf8+ Kg7 70. R8f7+ Kg6 71. R7f6+ Kg5 72. R6f5+ Kg6 73. Rf6+ Kg7 74. Rf7+ Kg8 75. Rf8+ Kg7 76. R8f7+ Kg6 77. R7f6+ Kg5",
          "aggressive_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 640,
            "total_tokens": 799,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd7",
            "Nf3",
            "a6",
            "Ba4",
            "b5",
            "Bb3",
            "Bg4",
            "c3",
            "e5",
            "d5",
            "Na5",
            "Bc2",
            "Nc4",
            "b3",
            "Nd6",
            "Qd3",
            "Bf5",
            "Nxd6+",
            "cxd6",
            "Qxf5",
            "Qc7",
            "O-O",
            "Qxc3",
            "Rac1",
            "Qb2",
            "Qxf6",
            "Rg8",
            "Bh7",
            "Rg7",
            "Rc7",
            "Rxh7",
            "Rfc1",
            "Rd8",
            "Qxd8+",
            "Kxd8",
            "Rc8+",
            "Ke7",
            "R1c7+",
            "Kf6",
            "h3",
            "Qxa2",
            "Rxf8",
            "Qxb3",
            "Rc6",
            "Qxd5",
            "Rxa6",
            "b4",
            "Rb8",
            "b3",
            "Rab6",
            "e4",
            "Nh2",
            "Rg7",
            "Rxb3",
            "e3",
            "Ng4+",
            "Rxg4",
            "hxg4",
            "Qd1+",
            "Kh2",
            "e2",
            "Rf3+",
            "Kg7",
            "Rb7",
            "e1=Q",
            "Rbxf7+",
            "Kg6",
            "R7f6+",
            "Kg5",
            "R6f5+",
            "Kg6",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf8+",
            "Kg7",
            "R8f7+",
            "Kg6",
            "R7f6+",
            "Kg5",
            "R6f5+",
            "Kg6",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf8+",
            "Kg7",
            "R8f7+",
            "Kg6",
            "R7f6+",
            "Kg5",
            "R6f5+",
            "Kg6",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf8+",
            "Kg7",
            "R8f7+",
            "Kg6",
            "R7f6+",
            "Kg5",
            "R6f5+",
            "Kg6",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf8+",
            "Kg7",
            "R8f7+",
            "Kg6",
            "R7f6+",
            "Kg5",
            "R6f5+",
            "Kg6",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf8+",
            "Kg7",
            "R8f7+",
            "Kg6",
            "R7f6+",
            "Kg5",
            "R6f5+",
            "Kg6",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf8+",
            "Kg7",
            "R8f7+",
            "Kg6",
            "R7f6+",
            "Kg5"
          ],
          "plan_execute": [
            "Bd7",
            "Nf3",
            "a6"
          ]
        },
        "query2": {
          "positional_move": "Bb5",
          "positional_uci": "f1b5",
          "positional_response": "7. Bb5 Bd7 8. Nf3 a6 9. Ba4 b5 10. Bb3 Bg4 11. c3 e5 12. d5 Na5 13. Bc2 Nc4 14. b3 Nd6 15. Nxd6+ Qxd6 16. O-O O-O-O 17. c4 bxc4 18. bxc4 Qc5 19. Qd3 Bxf3 20. Qxf3 Qxc4 21. Bf5+ Kb8 22. Rab1+ Ka7 23. Rfc1 Qxd5 24. Rxc7+ Ka8 25. Be4 Qxe4 26. Qxe4+ Rd5 27. Qxd5# Bc5 28. Qb7# 1-0",
          "positional_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 188,
            "total_tokens": 347,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd7",
            "Nf3",
            "a6",
            "Ba4",
            "b5",
            "Bb3",
            "Bg4",
            "c3",
            "e5",
            "d5",
            "Na5",
            "Bc2",
            "Nc4",
            "b3",
            "Nd6",
            "Nxd6+",
            "Qxd6",
            "O-O",
            "O-O-O",
            "c4",
            "bxc4",
            "bxc4",
            "Qc5",
            "Qd3",
            "Bxf3",
            "Qxf3",
            "Qxc4",
            "Bf5+",
            "Kb8",
            "Rab1+",
            "Ka7",
            "Rfc1",
            "Qxd5",
            "Rxc7+",
            "Ka8",
            "Be4",
            "Qxe4",
            "Qxe4+",
            "Rd5",
            "Qxd5#",
            "Bc5",
            "Qb7#"
          ],
          "plan_execute": [
            "Bd7",
            "Nf3",
            "a6"
          ]
        },
        "query3": {
          "neutral_move": "Bb5",
          "neutral_uci": "f1b5",
          "neutral_response": "7. Bb5 Bd7 8. Nf3 a6 9. Ba4 b5 10. Bb3 Bg4 11. c3 e5 12. d5 Na5 13. Bc2 Nc4 14. b3 Nd6 15. Nxd6+ Qxd6 16. O-O O-O-O 17. c4 bxc4 18. bxc4 Qc5 19. Qd3 Bxf3 20. Qxf3 Qxc4 21. Bb3 Qf4 22. Qd3 Rd6 23. Rac1 e4 24. Qc4 Rd7 25. Qxa6+ Kd8 26. Qa8+ Ke7 27. Ba4 Rd8 28. Qc6 Qd6 29. Qxc7+ Qxc7 30. Rxc7+ Kd6 31. Rxf7 Kxd5 32. Rd1+ Ke6 33. Bb3+ Kf5 34. Rxd8 Kg6 35. Rfxf8 Rxf8 36. Rxf8 Kg7 37. Rg8+ Kh7 38. a4 f5 39. a5 f4 40. a6 e3 41. fxe3 fxe3 42. Kf1 e2+ 43. Kxe2 h5 44. a7 h4 45. a8=Q h3 46. Qe4+ Kh6 47. Qh4# Qd5+ 49. Bxd5# Qe5+ 51. Be4# Qb2+ 53. Kf3# Qc3+ 55. Kf4# Qd2+ 57. Kf5# Qf2+ 59. Ke6# Qb6+ 61. Kf7# Qc7+ 63. Kf8# Qd6+ 65. Ke8# Qe5+ 67. Kd8# Qd6+ 69. Kc8# Qc5+ 71. Kb8# Qb6+ 73. Ka8# Qa6+ 75. Kb8# Qb6+ 77. Kc8# Qc5+ 79. Kd8# Qd6+ 81. Ke8# Qe5+ 83. Kf8# Qd6+ 85. Ke8# Qe5+ 87. Kd8# Qd6+ 89. Kc8# Qc5+ 91. Kb8# Qb6+ 93. Ka8# Qa6+ 95. Kb8# Qb6+ 97. Kc8# Qc5+ 99. Kd8# Qd6+ 101. Ke8# Qe5+ 103. Kf8# Q",
          "neutral_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 640,
            "total_tokens": 798,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd7",
            "Nf3",
            "a6",
            "Ba4",
            "b5",
            "Bb3",
            "Bg4",
            "c3",
            "e5",
            "d5",
            "Na5",
            "Bc2",
            "Nc4",
            "b3",
            "Nd6",
            "Nxd6+",
            "Qxd6",
            "O-O",
            "O-O-O",
            "c4",
            "bxc4",
            "bxc4",
            "Qc5",
            "Qd3",
            "Bxf3",
            "Qxf3",
            "Qxc4",
            "Bb3",
            "Qf4",
            "Qd3",
            "Rd6",
            "Rac1",
            "e4",
            "Qc4",
            "Rd7",
            "Qxa6+",
            "Kd8",
            "Qa8+",
            "Ke7",
            "Ba4",
            "Rd8",
            "Qc6",
            "Qd6",
            "Qxc7+",
            "Qxc7",
            "Rxc7+",
            "Kd6",
            "Rxf7",
            "Kxd5",
            "Rd1+",
            "Ke6",
            "Bb3+",
            "Kf5",
            "Rxd8",
            "Kg6",
            "Rfxf8",
            "Rxf8",
            "Rxf8",
            "Kg7",
            "Rg8+",
            "Kh7",
            "a4",
            "f5",
            "a5",
            "f4",
            "a6",
            "e3",
            "fxe3",
            "fxe3",
            "Kf1",
            "e2+",
            "Kxe2",
            "h5",
            "a7",
            "h4",
            "a8=Q",
            "h3",
            "Qe4+",
            "Kh6",
            "Qh4#",
            "Qd5+",
            "Bxd5#",
            "Qe5+",
            "Be4#",
            "Qb2+",
            "Kf3#",
            "Qc3+",
            "Kf4#",
            "Qd2+",
            "Kf5#",
            "Qf2+",
            "Ke6#",
            "Qb6+",
            "Kf7#",
            "Qc7+",
            "Kf8#",
            "Qd6+",
            "Ke8#",
            "Qe5+",
            "Kd8#",
            "Qd6+",
            "Kc8#",
            "Qc5+",
            "Kb8#",
            "Qb6+",
            "Ka8#",
            "Qa6+",
            "Kb8#",
            "Qb6+",
            "Kc8#",
            "Qc5+",
            "Kd8#",
            "Qd6+",
            "Ke8#",
            "Qe5+",
            "Kf8#",
            "Qd6+",
            "Ke8#",
            "Qe5+",
            "Kd8#",
            "Qd6+",
            "Kc8#",
            "Qc5+",
            "Kb8#",
            "Qb6+",
            "Ka8#",
            "Qa6+",
            "Kb8#",
            "Qb6+",
            "Kc8#",
            "Qc5+",
            "Kd8#",
            "Qd6+",
            "Ke8#",
            "Qe5+",
            "Kf8#"
          ],
          "plan_execute": [
            "Bd7",
            "Nf3",
            "a6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1b5",
          "positional_uci": "f1b5",
          "neutral_uci": "f1b5",
          "consensus_move": "f1b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd7",
              "Nf3",
              "a6",
              "Ba4",
              "b5",
              "Bb3",
              "Bg4",
              "c3",
              "e5",
              "d5",
              "Na5",
              "Bc2",
              "Nc4",
              "b3",
              "Nd6",
              "Qd3",
              "Bf5",
              "Nxd6+",
              "cxd6",
              "Qxf5",
              "Qc7",
              "O-O",
              "Qxc3",
              "Rac1",
              "Qb2",
              "Qxf6",
              "Rg8",
              "Bh7",
              "Rg7",
              "Rc7",
              "Rxh7",
              "Rfc1",
              "Rd8",
              "Qxd8+",
              "Kxd8",
              "Rc8+",
              "Ke7",
              "R1c7+",
              "Kf6",
              "h3",
              "Qxa2",
              "Rxf8",
              "Qxb3",
              "Rc6",
              "Qxd5",
              "Rxa6",
              "b4",
              "Rb8",
              "b3",
              "Rab6",
              "e4",
              "Nh2",
              "Rg7",
              "Rxb3",
              "e3",
              "Ng4+",
              "Rxg4",
              "hxg4",
              "Qd1+",
              "Kh2",
              "e2",
              "Rf3+",
              "Kg7",
              "Rb7",
              "e1=Q",
              "Rbxf7+",
              "Kg6",
              "R7f6+",
              "Kg5",
              "R6f5+",
              "Kg6",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf8+",
              "Kg7",
              "R8f7+",
              "Kg6",
              "R7f6+",
              "Kg5",
              "R6f5+",
              "Kg6",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf8+",
              "Kg7",
              "R8f7+",
              "Kg6",
              "R7f6+",
              "Kg5",
              "R6f5+",
              "Kg6",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf8+",
              "Kg7",
              "R8f7+",
              "Kg6",
              "R7f6+",
              "Kg5",
              "R6f5+",
              "Kg6",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf8+",
              "Kg7",
              "R8f7+",
              "Kg6",
              "R7f6+",
              "Kg5",
              "R6f5+",
              "Kg6",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf8+",
              "Kg7",
              "R8f7+",
              "Kg6",
              "R7f6+",
              "Kg5",
              "R6f5+",
              "Kg6",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf8+",
              "Kg7",
              "R8f7+",
              "Kg6",
              "R7f6+",
              "Kg5"
            ],
            "execute": [
              "Bd7",
              "Nf3",
              "a6"
            ]
          },
          "positional": {
            "full": [
              "Bd7",
              "Nf3",
              "a6",
              "Ba4",
              "b5",
              "Bb3",
              "Bg4",
              "c3",
              "e5",
              "d5",
              "Na5",
              "Bc2",
              "Nc4",
              "b3",
              "Nd6",
              "Nxd6+",
              "Qxd6",
              "O-O",
              "O-O-O",
              "c4",
              "bxc4",
              "bxc4",
              "Qc5",
              "Qd3",
              "Bxf3",
              "Qxf3",
              "Qxc4",
              "Bf5+",
              "Kb8",
              "Rab1+",
              "Ka7",
              "Rfc1",
              "Qxd5",
              "Rxc7+",
              "Ka8",
              "Be4",
              "Qxe4",
              "Qxe4+",
              "Rd5",
              "Qxd5#",
              "Bc5",
              "Qb7#"
            ],
            "execute": [
              "Bd7",
              "Nf3",
              "a6"
            ]
          },
          "neutral": {
            "full": [
              "Bd7",
              "Nf3",
              "a6",
              "Ba4",
              "b5",
              "Bb3",
              "Bg4",
              "c3",
              "e5",
              "d5",
              "Na5",
              "Bc2",
              "Nc4",
              "b3",
              "Nd6",
              "Nxd6+",
              "Qxd6",
              "O-O",
              "O-O-O",
              "c4",
              "bxc4",
              "bxc4",
              "Qc5",
              "Qd3",
              "Bxf3",
              "Qxf3",
              "Qxc4",
              "Bb3",
              "Qf4",
              "Qd3",
              "Rd6",
              "Rac1",
              "e4",
              "Qc4",
              "Rd7",
              "Qxa6+",
              "Kd8",
              "Qa8+",
              "Ke7",
              "Ba4",
              "Rd8",
              "Qc6",
              "Qd6",
              "Qxc7+",
              "Qxc7",
              "Rxc7+",
              "Kd6",
              "Rxf7",
              "Kxd5",
              "Rd1+",
              "Ke6",
              "Bb3+",
              "Kf5",
              "Rxd8",
              "Kg6",
              "Rfxf8",
              "Rxf8",
              "Rxf8",
              "Kg7",
              "Rg8+",
              "Kh7",
              "a4",
              "f5",
              "a5",
              "f4",
              "a6",
              "e3",
              "fxe3",
              "fxe3",
              "Kf1",
              "e2+",
              "Kxe2",
              "h5",
              "a7",
              "h4",
              "a8=Q",
              "h3",
              "Qe4+",
              "Kh6",
              "Qh4#",
              "Qd5+",
              "Bxd5#",
              "Qe5+",
              "Be4#",
              "Qb2+",
              "Kf3#",
              "Qc3+",
              "Kf4#",
              "Qd2+",
              "Kf5#",
              "Qf2+",
              "Ke6#",
              "Qb6+",
              "Kf7#",
              "Qc7+",
              "Kf8#",
              "Qd6+",
              "Ke8#",
              "Qe5+",
              "Kd8#",
              "Qd6+",
              "Kc8#",
              "Qc5+",
              "Kb8#",
              "Qb6+",
              "Ka8#",
              "Qa6+",
              "Kb8#",
              "Qb6+",
              "Kc8#",
              "Qc5+",
              "Kd8#",
              "Qd6+",
              "Ke8#",
              "Qe5+",
              "Kf8#",
              "Qd6+",
              "Ke8#",
              "Qe5+",
              "Kd8#",
              "Qd6+",
              "Kc8#",
              "Qc5+",
              "Kb8#",
              "Qb6+",
              "Ka8#",
              "Qa6+",
              "Kb8#",
              "Qb6+",
              "Kc8#",
              "Qc5+",
              "Kd8#",
              "Qd6+",
              "Ke8#",
              "Qe5+",
              "Kf8#"
            ],
            "execute": [
              "Bd7",
              "Nf3",
              "a6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bd7",
            "Nf3",
            "a6"
          ],
          "full_moves": [
            "Bd7",
            "Nf3",
            "a6",
            "Ba4",
            "b5",
            "Bb3",
            "Bg4",
            "c3",
            "e5",
            "d5",
            "Na5",
            "Bc2",
            "Nc4",
            "b3",
            "Nd6",
            "Nxd6+",
            "Qxd6",
            "O-O",
            "O-O-O",
            "c4",
            "bxc4",
            "bxc4",
            "Qc5",
            "Qd3",
            "Bxf3",
            "Qxf3",
            "Qxc4",
            "Bb3",
            "Qf4",
            "Qd3",
            "Rd6",
            "Rac1",
            "e4",
            "Qc4",
            "Rd7",
            "Qxa6+",
            "Kd8",
            "Qa8+",
            "Ke7",
            "Ba4",
            "Rd8",
            "Qc6",
            "Qd6",
            "Qxc7+",
            "Qxc7",
            "Rxc7+",
            "Kd6",
            "Rxf7",
            "Kxd5",
            "Rd1+",
            "Ke6",
            "Bb3+",
            "Kf5",
            "Rxd8",
            "Kg6",
            "Rfxf8",
            "Rxf8",
            "Rxf8",
            "Kg7",
            "Rg8+",
            "Kh7",
            "a4",
            "f5",
            "a5",
            "f4",
            "a6",
            "e3",
            "fxe3",
            "fxe3",
            "Kf1",
            "e2+",
            "Kxe2",
            "h5",
            "a7",
            "h4",
            "a8=Q",
            "h3",
            "Qe4+",
            "Kh6",
            "Qh4#",
            "Qd5+",
            "Bxd5#",
            "Qe5+",
            "Be4#",
            "Qb2+",
            "Kf3#",
            "Qc3+",
            "Kf4#",
            "Qd2+",
            "Kf5#",
            "Qf2+",
            "Ke6#",
            "Qb6+",
            "Kf7#",
            "Qc7+",
            "Kf8#",
            "Qd6+",
            "Ke8#",
            "Qe5+",
            "Kd8#",
            "Qd6+",
            "Kc8#",
            "Qc5+",
            "Kb8#",
            "Qb6+",
            "Ka8#",
            "Qa6+",
            "Kb8#",
            "Qb6+",
            "Kc8#",
            "Qc5+",
            "Kd8#",
            "Qd6+",
            "Ke8#",
            "Qe5+",
            "Kf8#",
            "Qd6+",
            "Ke8#",
            "Qe5+",
            "Kd8#",
            "Qd6+",
            "Kc8#",
            "Qc5+",
            "Kb8#",
            "Qb6+",
            "Ka8#",
            "Qa6+",
            "Kb8#",
            "Qb6+",
            "Kc8#",
            "Qc5+",
            "Kd8#",
            "Qd6+",
            "Ke8#",
            "Qe5+",
            "Kf8#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 159,
            "completion_tokens": 640,
            "total_tokens": 799,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 159,
            "completion_tokens": 188,
            "total_tokens": 347,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 158,
            "completion_tokens": 640,
            "total_tokens": 798,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 476,
          "total_completion_tokens": 1468,
          "total_tokens": 1944
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 159,
            "completion_tokens": 640,
            "total_tokens": 799,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 159,
            "completion_tokens": 188,
            "total_tokens": 347,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 158,
            "completion_tokens": 640,
            "total_tokens": 798,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkb1r/ppp1pp2/2n2p1p/8/3PN3/8/PPP2PPP/R2QKBNR w KQkq - 1 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxc6+",
          "aggressive_uci": "b5c6",
          "aggressive_response": "8. Bxc6+ bxc6 9. Nf3 Bg4 10. O-O Bxf3 11. Qxf3 Qxd4 12. Rad1 Qxb2 13. Nxf6+ exf6 14. Qxc6+ Ke7 15. Rfe1+ Qe5 16. Qd7# d4 Nf6 Bb4+ c6 Bxc6+ bxc6 Qxc6+ Ke7 Qxa8 Qxa8",
          "aggressive_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 110,
            "total_tokens": 277,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "bxc6",
            "Qxc6+",
            "Ke7",
            "Qxa8",
            "Qxa8"
          ],
          "plan_execute": [
            "bxc6",
            "Qxc6+",
            "Ke7"
          ]
        },
        "query2": {
          "positional_move": "Bxc6+",
          "positional_uci": "b5c6",
          "positional_response": "8. Bxc6+ bxc6 9. Nf3 Bg4 10. h3 Bh5 11. g4 Bg6 12. Qe2 e6 13. O-O-O Qd5 14. Nxf6+ Kd8 15. Nxd5 cxd5 16. Ne5 Be4 17. f3 Bh7 18. Nxf7+ Ke7 19. Nxh8 Bg7 20. Rhe1 Bxh8 21. Qxe6+ Kd8 22. Qe8# d4 d5 Nc6 Bb5 a6 Bxc6 bxc6 Nf3 Bg4 h3 Bh5 g4 Bg6 Qe2 e6 O-O-O Qd5 Nxf6+ Kd8 Nxd5 cxd5 Ne5 Be4 f3 Bh7 Nxf7+ Ke7 Nxh8 Bg7 Rhe1 Bxh8 Qxe6+ Kd8 Qe8#",
          "positional_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 222,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "bxc6",
            "Nf3",
            "Bg4",
            "h3",
            "Bh5",
            "g4",
            "Bg6",
            "Qe2",
            "e6",
            "O-O-O",
            "Qd5",
            "Nxf6+",
            "Kd8",
            "Nxd5",
            "cxd5",
            "Ne5",
            "Be4",
            "f3",
            "Bh7",
            "Nxf7+",
            "Ke7",
            "Nxh8",
            "Bg7",
            "Rhe1",
            "Bxh8",
            "Qxe6+",
            "Kd8",
            "Qe8#"
          ],
          "plan_execute": [
            "bxc6",
            "Nf3",
            "Bg4"
          ]
        },
        "query3": {
          "neutral_move": "Bxc6+",
          "neutral_uci": "b5c6",
          "neutral_response": "8. Bxc6+ bxc6 9. Nf3 Bg4 10. h3 Bxf3 11. Qxf3 Qxd4 12. Nxf6+ exf6 13. Qxc6+ Ke7 14. Qxa8 Qxb2 15. O-O Qxc2 16. Rfe1+ Kd7 17. Rad1+ Bd6 18. Qxh8 Qxa2 19. Qe8# e4 Qd3 Qxd3+ Kxd3 Rb1#",
          "neutral_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 123,
            "total_tokens": 289,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "bxc6",
            "Nf3",
            "Bg4",
            "h3",
            "Bxf3",
            "Qxf3",
            "Qxd4",
            "Nxf6+",
            "exf6",
            "Qxc6+",
            "Ke7",
            "Qxa8",
            "Qxb2",
            "O-O",
            "Qxc2",
            "Rfe1+",
            "Kd7",
            "Rad1+",
            "Bd6",
            "Qxh8",
            "Qxa2",
            "Qe8#",
            "e4",
            "Qd3",
            "Qxd3+",
            "Kxd3",
            "Rb1#"
          ],
          "plan_execute": [
            "bxc6",
            "Nf3",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b5c6",
          "positional_uci": "b5c6",
          "neutral_uci": "b5c6",
          "consensus_move": "b5c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "bxc6",
              "Qxc6+",
              "Ke7",
              "Qxa8",
              "Qxa8"
            ],
            "execute": [
              "bxc6",
              "Qxc6+",
              "Ke7"
            ]
          },
          "positional": {
            "full": [
              "bxc6",
              "Nf3",
              "Bg4",
              "h3",
              "Bh5",
              "g4",
              "Bg6",
              "Qe2",
              "e6",
              "O-O-O",
              "Qd5",
              "Nxf6+",
              "Kd8",
              "Nxd5",
              "cxd5",
              "Ne5",
              "Be4",
              "f3",
              "Bh7",
              "Nxf7+",
              "Ke7",
              "Nxh8",
              "Bg7",
              "Rhe1",
              "Bxh8",
              "Qxe6+",
              "Kd8",
              "Qe8#"
            ],
            "execute": [
              "bxc6",
              "Nf3",
              "Bg4"
            ]
          },
          "neutral": {
            "full": [
              "bxc6",
              "Nf3",
              "Bg4",
              "h3",
              "Bxf3",
              "Qxf3",
              "Qxd4",
              "Nxf6+",
              "exf6",
              "Qxc6+",
              "Ke7",
              "Qxa8",
              "Qxb2",
              "O-O",
              "Qxc2",
              "Rfe1+",
              "Kd7",
              "Rad1+",
              "Bd6",
              "Qxh8",
              "Qxa2",
              "Qe8#",
              "e4",
              "Qd3",
              "Qxd3+",
              "Kxd3",
              "Rb1#"
            ],
            "execute": [
              "bxc6",
              "Nf3",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "bxc6",
            "Nf3",
            "Bg4"
          ],
          "full_moves": [
            "bxc6",
            "Nf3",
            "Bg4",
            "h3",
            "Bxf3",
            "Qxf3",
            "Qxd4",
            "Nxf6+",
            "exf6",
            "Qxc6+",
            "Ke7",
            "Qxa8",
            "Qxb2",
            "O-O",
            "Qxc2",
            "Rfe1+",
            "Kd7",
            "Rad1+",
            "Bd6",
            "Qxh8",
            "Qxa2",
            "Qe8#",
            "e4",
            "Qd3",
            "Qxd3+",
            "Kxd3",
            "Rb1#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 167,
            "completion_tokens": 110,
            "total_tokens": 277,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 167,
            "completion_tokens": 222,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 166,
            "completion_tokens": 123,
            "total_tokens": 289,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 500,
          "total_completion_tokens": 455,
          "total_tokens": 955
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 167,
            "completion_tokens": 110,
            "total_tokens": 277,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 167,
            "completion_tokens": 222,
            "total_tokens": 389,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 166,
            "completion_tokens": 123,
            "total_tokens": 289,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1pp1pp2/p1n2p1p/1B6/3PN3/8/PPP2PPP/R2QK1NR w KQkq - 0 8"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. Nf3 Nf6 2. c4 e6 3. g3 d5 4. Bg2 Be7 5. O-O O-O 6. d4 dxc4 7. Qc2 a6 8. Qxc4 b5 9. Qc2 Bb7 10. Bd2 Be4 11. Qc1 Nbd7 12. Ba5 Rc8 13. Nbd2 Ba8 14. b4 Nb6 15. a3 Ne4 16. Nxe4 Bxe4 17. Rd1 Qd5 18. Ne1 Bxg2 19. Nxg2 Nc4 20. Nf4 Qe4 21. f3 Qb7 22. Nd3 Rfd8 23. Nc5 Bxc5 24. dxc5 Rxd1+ 25. Qxd1 Nxa5 26. bxa5 Qc6 27. Qd4 h6 28. Rd1 Re8 29. Qd7 Qxc5+ 30. Kg2 Re7 31. Qc8+ Kh7 32. Qxa6 Qc2 33. Re1 Qd2 34. Kf1 Qd5 35. Qa7 Rd7 36. Qe3 c5 37. Rb1 c4 38. a6 Qc6 39. a7 Qa6 40. Qe4+ g6 41. a8=Q 1-0\n1. Nf3 Nf6 2. c4 e6 3. g3 d5 4. Bg2 Be7 5. O-O O-O 6. d4 dxc4 7. Qc2 a6 8. Qxc4 b5 9. Qc2 Bb7 10. Bd2 Be4 11. Qc1 Nbd7 12. Ba5 Rc8 13. Nbd2 Ba8 14. b4 Nb6 15. a3 Ne4 16. Nxe4 Bxe4 17. Rd1 Qd5 18. Ne1 Bxg2 19. Nxg2 Nc4 20. Nf4 Qe4 21. f3 Qb7 22. Nd3 Rfd8 23. Nc5 Bxc5 24. dxc5 Rxd1+ 25. Qxd1 Nxa5 26. bxa5 Qc6 27. Qd4 h6 28. Rd1 Re8 29. Qd7 Qxc5+ 30. Kg2 Re7 31. Qc8+ Kh7 32. Qxa6 Qc2 33. Re1 Qd2 34. Kf1 Qd5 35. Qa7 Rd7 36. Qe3 c5 37. R",
          "aggressive_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c4",
            "e6",
            "g3",
            "d5",
            "Bg2",
            "Be7",
            "O-O",
            "O-O",
            "d4",
            "dxc4",
            "Qc2",
            "a6",
            "Qxc4",
            "b5",
            "Qc2",
            "Bb7",
            "Bd2",
            "Be4",
            "Qc1",
            "Nbd7",
            "Ba5",
            "Rc8",
            "Nbd2",
            "Ba8",
            "b4",
            "Nb6",
            "a3",
            "Ne4",
            "Nxe4",
            "Bxe4",
            "Rd1",
            "Qd5",
            "Ne1",
            "Bxg2",
            "Nxg2",
            "Nc4",
            "Nf4",
            "Qe4",
            "f3",
            "Qb7",
            "Nd3",
            "Rfd8",
            "Nc5",
            "Bxc5",
            "dxc5",
            "Rxd1+",
            "Qxd1",
            "Nxa5",
            "bxa5",
            "Qc6",
            "Qd4",
            "h6",
            "Rd1",
            "Re8",
            "Qd7",
            "Qxc5+",
            "Kg2",
            "Re7",
            "Qc8+",
            "Kh7",
            "Qxa6",
            "Qc2",
            "Re1",
            "Qd2",
            "Kf1",
            "Qd5",
            "Qa7",
            "Rd7",
            "Qe3",
            "c5"
          ],
          "plan_execute": [
            "c4",
            "e6",
            "g3"
          ]
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1... Nf6 2. d4 d5 3. c4 e6 4. Nc3 Be7 5. Bg5 O-O 6. e3 Nbd7 7. Rc1 c6 8. Bd3 dxc4 9. Bxc4 Nd5 10. Bxe7 Qxe7 11. O-O Nxc3 12. Rxc3 e5 13. dxe5 Nxe5 14. Nxe5 Qxe5 15. f4 Qe7 16. f5 Qf6 17. e4 Rd8 18. Qh5 Bd7 19. Rh3 h6 20. e5 Qxe5 21. Qxf7+ Kh8 22. f6 Qd4+ 23. Kh1 Qxf6 24. Rxf6 Bxh3 25. gxh3 gxf6 26. Qxf6+ Kh7 27. Qf7+ Kh8 28. Qg6 Rd1+ 29. Kg2 Rd2+ 30. Kf3 Rf8+ 31. Ke3 Rd7 32. Qxh6+ 1-0\n33. Qxf8+ Kh7 34. Bd3+ Rxd3+ 35. Kxd3 Kg6 36. Ke4 Kg5 37. Qg7+ Kh4 38. Qg4#",
          "positional_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 315,
            "total_tokens": 430,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4",
            "d5",
            "c4",
            "e6",
            "Nc3",
            "Be7",
            "Bg5",
            "O-O",
            "e3",
            "Nbd7",
            "Rc1",
            "c6",
            "Bd3",
            "dxc4",
            "Bxc4",
            "Nd5",
            "Bxe7",
            "Qxe7",
            "O-O",
            "Nxc3",
            "Rxc3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "f4",
            "Qe7",
            "f5",
            "Qf6",
            "e4",
            "Rd8",
            "Qh5",
            "Bd7",
            "Rh3",
            "h6",
            "e5",
            "Qxe5",
            "Qxf7+",
            "Kh8",
            "f6",
            "Qd4+",
            "Kh1",
            "Qxf6",
            "Rxf6",
            "Bxh3",
            "gxh3",
            "gxf6",
            "Qxf6+",
            "Kh7",
            "Qf7+",
            "Kh8",
            "Qg6",
            "Rd1+",
            "Kg2",
            "Rd2+",
            "Kf3",
            "Rf8+",
            "Ke3",
            "Rd7",
            "Qxh6+",
            "Qxf8+",
            "Kh7",
            "Bd3+",
            "Rxd3+",
            "Kxd3",
            "Kg6",
            "Ke4",
            "Kg5",
            "Qg7+",
            "Kh4",
            "Qg4#"
          ],
          "plan_execute": [
            "d4",
            "d5",
            "c4"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1... Nf6 2. d4 d5 3. c4 e6 4. Nc3 Be7 5. Bg5 O-O 6. e3 Nbd7 7. Rc1 c6 8. Bd3 dxc4 9. Bxc4 Nd5 10. Bxe7 Qxe7 11. O-O Nxc3 12. Rxc3 e5 13. dxe5 Nxe5 14. Nxe5 Qxe5 15. f4 Qe7 16. f5 Qf6 17. e4 Rd8 18. Rd3 Rxd3 19. Qxd3 b5 20. Bb3 Bb7 21. Rd1 h6 22. Qd7 Rb8 23. Qc7 Re8 24. Qxb7 Rxe4 25. Qxa7 Re2 26. Qd4 Qg5 27. g3 Qh5 28. Qd8+ Kh7 29. Qh4 Qf3 30. Qh3 Qf2+ 31. Kh1 Qf3+ 32. Kg1 Qf2+ 33. Kh1 Qf3+ 34. Kg1 Qf2+ 35. Kh1 Qf3+ 36. Kg1 Qf2+ 37. Kh1 Qf3+ 38. Kg1 Qf2+ 39. Kh1 Qf3+ 40. Kg1 Qf2+ 41. Kh1 Qf3+ 42. Kg1 Qf2+ 43. Kh1 Qf3+ 44. Kg1 Qf2+ 45. Kh1 Qf3+ 46. Kg1 Qf2+ 47. Kh1 Qf3+ 48. Kg1 Qf2+ 49. Kh1 Qf3+ 50. Kg1 Qf2+ 51. Kh1 Qf3+ 52. Kg1 Qf2+ 53. Kh1 Qf3+ 54. Kg1 Qf2+ 55. Kh1 Qf3+ 56. Kg1 Qf2+ 57. Kh1 Qf3+ 58. Kg1 Qf2+ 59. Kh1 Qf3+ 60. Kg1 Qf2+ 61. Kh1 Qf3+ 62. Kg1 Qf2+ 63. Kh1 Qf3+ 64. Kg1 Qf2+ 65. Kh1 Qf3+ 66. Kg1 Qf2+ 67. Kh1 Qf3+ 68. Kg1 Qf2+ 69. Kh1 Qf3+ 70. Kg1 Qf2+ 71. Kh1 Qf3+ 72. Kg1 Qf2+ 73. Kh1 Qf3+ 74. Kg1 Qf2+",
          "neutral_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "d5",
            "c4",
            "e6",
            "Nc3",
            "Be7",
            "Bg5",
            "O-O",
            "e3",
            "Nbd7",
            "Rc1",
            "c6",
            "Bd3",
            "dxc4",
            "Bxc4",
            "Nd5",
            "Bxe7",
            "Qxe7",
            "O-O",
            "Nxc3",
            "Rxc3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "f4",
            "Qe7",
            "f5",
            "Qf6",
            "e4",
            "Rd8",
            "Rd3",
            "Rxd3",
            "Qxd3",
            "b5",
            "Bb3",
            "Bb7",
            "Rd1",
            "h6",
            "Qd7",
            "Rb8",
            "Qc7",
            "Re8",
            "Qxb7",
            "Rxe4",
            "Qxa7",
            "Re2",
            "Qd4",
            "Qg5",
            "g3",
            "Qh5",
            "Qd8+",
            "Kh7",
            "Qh4",
            "Qf3",
            "Qh3",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+"
          ],
          "plan_execute": [
            "d4",
            "d5",
            "c4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c4",
              "e6",
              "g3",
              "d5",
              "Bg2",
              "Be7",
              "O-O",
              "O-O",
              "d4",
              "dxc4",
              "Qc2",
              "a6",
              "Qxc4",
              "b5",
              "Qc2",
              "Bb7",
              "Bd2",
              "Be4",
              "Qc1",
              "Nbd7",
              "Ba5",
              "Rc8",
              "Nbd2",
              "Ba8",
              "b4",
              "Nb6",
              "a3",
              "Ne4",
              "Nxe4",
              "Bxe4",
              "Rd1",
              "Qd5",
              "Ne1",
              "Bxg2",
              "Nxg2",
              "Nc4",
              "Nf4",
              "Qe4",
              "f3",
              "Qb7",
              "Nd3",
              "Rfd8",
              "Nc5",
              "Bxc5",
              "dxc5",
              "Rxd1+",
              "Qxd1",
              "Nxa5",
              "bxa5",
              "Qc6",
              "Qd4",
              "h6",
              "Rd1",
              "Re8",
              "Qd7",
              "Qxc5+",
              "Kg2",
              "Re7",
              "Qc8+",
              "Kh7",
              "Qxa6",
              "Qc2",
              "Re1",
              "Qd2",
              "Kf1",
              "Qd5",
              "Qa7",
              "Rd7",
              "Qe3",
              "c5"
            ],
            "execute": [
              "c4",
              "e6",
              "g3"
            ]
          },
          "positional": {
            "full": [
              "d4",
              "d5",
              "c4",
              "e6",
              "Nc3",
              "Be7",
              "Bg5",
              "O-O",
              "e3",
              "Nbd7",
              "Rc1",
              "c6",
              "Bd3",
              "dxc4",
              "Bxc4",
              "Nd5",
              "Bxe7",
              "Qxe7",
              "O-O",
              "Nxc3",
              "Rxc3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "f4",
              "Qe7",
              "f5",
              "Qf6",
              "e4",
              "Rd8",
              "Qh5",
              "Bd7",
              "Rh3",
              "h6",
              "e5",
              "Qxe5",
              "Qxf7+",
              "Kh8",
              "f6",
              "Qd4+",
              "Kh1",
              "Qxf6",
              "Rxf6",
              "Bxh3",
              "gxh3",
              "gxf6",
              "Qxf6+",
              "Kh7",
              "Qf7+",
              "Kh8",
              "Qg6",
              "Rd1+",
              "Kg2",
              "Rd2+",
              "Kf3",
              "Rf8+",
              "Ke3",
              "Rd7",
              "Qxh6+",
              "Qxf8+",
              "Kh7",
              "Bd3+",
              "Rxd3+",
              "Kxd3",
              "Kg6",
              "Ke4",
              "Kg5",
              "Qg7+",
              "Kh4",
              "Qg4#"
            ],
            "execute": [
              "d4",
              "d5",
              "c4"
            ]
          },
          "neutral": {
            "full": [
              "d4",
              "d5",
              "c4",
              "e6",
              "Nc3",
              "Be7",
              "Bg5",
              "O-O",
              "e3",
              "Nbd7",
              "Rc1",
              "c6",
              "Bd3",
              "dxc4",
              "Bxc4",
              "Nd5",
              "Bxe7",
              "Qxe7",
              "O-O",
              "Nxc3",
              "Rxc3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "f4",
              "Qe7",
              "f5",
              "Qf6",
              "e4",
              "Rd8",
              "Rd3",
              "Rxd3",
              "Qxd3",
              "b5",
              "Bb3",
              "Bb7",
              "Rd1",
              "h6",
              "Qd7",
              "Rb8",
              "Qc7",
              "Re8",
              "Qxb7",
              "Rxe4",
              "Qxa7",
              "Re2",
              "Qd4",
              "Qg5",
              "g3",
              "Qh5",
              "Qd8+",
              "Kh7",
              "Qh4",
              "Qf3",
              "Qh3",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+",
              "Kh1",
              "Qf3+",
              "Kg1",
              "Qf2+"
            ],
            "execute": [
              "d4",
              "d5",
              "c4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "d4",
            "d5",
            "c4"
          ],
          "full_moves": [
            "d4",
            "d5",
            "c4",
            "e6",
            "Nc3",
            "Be7",
            "Bg5",
            "O-O",
            "e3",
            "Nbd7",
            "Rc1",
            "c6",
            "Bd3",
            "dxc4",
            "Bxc4",
            "Nd5",
            "Bxe7",
            "Qxe7",
            "O-O",
            "Nxc3",
            "Rxc3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "f4",
            "Qe7",
            "f5",
            "Qf6",
            "e4",
            "Rd8",
            "Rd3",
            "Rxd3",
            "Qxd3",
            "b5",
            "Bb3",
            "Bb7",
            "Rd1",
            "h6",
            "Qd7",
            "Rb8",
            "Qc7",
            "Re8",
            "Qxb7",
            "Rxe4",
            "Qxa7",
            "Re2",
            "Qd4",
            "Qg5",
            "g3",
            "Qh5",
            "Qd8+",
            "Kh7",
            "Qh4",
            "Qf3",
            "Qh3",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+",
            "Kh1",
            "Qf3+",
            "Kg1",
            "Qf2+"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 115,
            "completion_tokens": 315,
            "total_tokens": 430,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 344,
          "total_completion_tokens": 1595,
          "total_tokens": 1939
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 115,
            "completion_tokens": 315,
            "total_tokens": 430,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/5N2/PPPPPPPP/RNBQKB1R b KQkq - 1 1"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "3. Nf3 Nf6 4. e3 e6 5. Bxc4 c5 6. O-O a6 7. dxc5 Qxd1 8. Rxd1 Bxc5 9. Nbd2 O-O 10. Nb3 Be7 11. Bd2 Nc6 12. Rac1 Bd7 13. Be2 Rfd8 14. Nc5 Bxc5 15. Rxc5 Ne4 16. Rcc1 Nxd2 17. Rxd2 Be8 18. Rcd1 Rxd2 19. Rxd2 Rd8 20. Rxd8 Nxd8 21. Kf1 Kf8 22. Ke1 Ke7 23. Kd2 Kd6 24. Kc3 Nc6 25. Nd4 Nxd4 26. Kxd4 e5+ 27. Kc3 Bc6 28. g3 a5 29. a3 b6 30. b4 axb4+ 31. axb4 Bd5 32. Bd3 h6 33. Bc2 g5 34. Bd3 f6 35. Bc2 Be6 36. Bd3 Bd5 37. Bc2 Be6 38. Bd3 Bd5 39. Bc2 Be6 40. Bd3 Bd5 41. Bc2 Be6 42. Bd3 Bd5 43. Bc2 Be6 44. Bd3 Bd5 45. Bc2 Be6 46. Bd3 Bd5 47. Bc2 Be6 48. Bd3 Bd5 49. Bc2 Be6 50. Bd3 Bd5 51. Bc2 Be6 52. Bd3 Bd5 53. Bc2 Be6 54. Bd3 Bd5 55. Bc2 Be6 56. Bd3 Bd5 57. Bc2 Be6 58. Bd3 Bd5 59. Bc2 Be6 60. Bd3 Bd5 61. Bc2 Be6 62. Bd3 Bd5 63. Bc2 Be6 64. Bd3 Bd5 65. Bc2 Be6 66. Bd3 Bd5 67. Bc2 Be6 68. Bd3 Bd5 69. Bc2 Be6 70. Bd3 Bd5 71. Bc2 Be6 72. Bd3 Bd5 73. Bc2 Be6 74. Bd3 Bd5 75. Bc2 Be6 76. Bd3 Bd5 77. Bc2 Be6 78. Bd3 Bd5 79. Bc2 Be6 80. Bd3 Bd5 81. Bc2 Be6 82. Bd3 Bd5 83. Bc2 Be6 84. Bd3 Bd5 85. Bc",
          "aggressive_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "e3",
            "e6",
            "Bxc4",
            "c5",
            "O-O",
            "a6",
            "dxc5",
            "Qxd1",
            "Rxd1",
            "Bxc5",
            "Nbd2",
            "O-O",
            "Nb3",
            "Be7",
            "Bd2",
            "Nc6",
            "Rac1",
            "Bd7",
            "Be2",
            "Rfd8",
            "Nc5",
            "Bxc5",
            "Rxc5",
            "Ne4",
            "Rcc1",
            "Nxd2",
            "Rxd2",
            "Be8",
            "Rcd1",
            "Rxd2",
            "Rxd2",
            "Rd8",
            "Rxd8",
            "Nxd8",
            "Kf1",
            "Kf8",
            "Ke1",
            "Ke7",
            "Kd2",
            "Kd6",
            "Kc3",
            "Nc6",
            "Nd4",
            "Nxd4",
            "Kxd4",
            "e5+",
            "Kc3",
            "Bc6",
            "g3",
            "a5",
            "a3",
            "b6",
            "b4",
            "axb4+",
            "axb4",
            "Bd5",
            "Bd3",
            "h6",
            "Bc2",
            "g5",
            "Bd3",
            "f6",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5",
            "Bc2",
            "Be6",
            "Bd3",
            "Bd5"
          ],
          "plan_execute": [
            "Nf6",
            "e3",
            "e6"
          ]
        },
        "query2": {
          "positional_move": "Bb5",
          "positional_uci": null,
          "positional_response": "3. Nf3 Nf6 4. e3 e6 5. Bxc4 c5 6. O-O a6 7. dxc5 Qxd1 8. Rxd1 Bxc5 9. Nbd2 O-O 10. Nb3 Be7 11. Be2 Nc6 12. Bd2 e5 13. Bc3 e4 14. Nfd4 Nxd4 15. Nxd4 Bd7 16. Rac1 Rac8 17. Nb3 Be6 18. Bd4 Rxc1 19. Rxc1 Rc8 20. Rxc8+ Bxc8 21. Nc5 Bxc5 22. Bxc5 Be6 23. a3 Nd7 24. Bd4 f5 25. Kf1 Kf7 26. Ke1 g6 27. Kd2 Ke7 28. Kc3 Kd6 29. Kb4 Kc6 30. Ka5 Nc5 31. Bxc5 Kxc5 32. b4+ Kc6 33. b5+ axb5 34. Bxb5+ Kc5 35. Be2 Bc4 36. Bd1 Bf1 37. g3 b6+ 38. Ka4 Kc4 39. Bb3+ Kc3 40. Bg8 Bc4 41. Bxh7 b5+ 42. Ka5 Kb3 43. Bxg6 Kxa3 44. Bxf5 b4 45. Bxe4 b3 46. h4 b2 47. h5 Bd5 48. Bb1 Bg8 49. h6 Kb3 50. g4 Kc3 51. g5 Kd2 52. g6 Kc1 53. h7 Bxh7 54. gxh7 Kxb1 55. h8=Q Ka2 56. Qxb2+ Kxb2 57. e4 Kc3 58. e5 Kd4 59. e6 Ke5 60. e7 Kf4 61. e8=Q Kf3 62. Qe3+ Kg2 63. f4 Kh2 64. f5 Kg2 65. f6 Kh2 66. f7 Kg2 67. f8=Q Kh2 68. Qff2+ Kh1 69. Qee1# 1-0 1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6",
          "positional_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 585,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nf6 4. e3 e6 5. Bxc4 c5 6. O-O a6 7. Qe2 b5 8. Bb3 Bb7 9. Rd1 Nbd7 10. Nc3 Qb8 11. d5 c4 12. dxe6 fxe6 13. Bc2 Bd6 14. h3 O-O 15. Ng5 Nc5 16. b4 cxb3 17. axb3 h6 18. b4 hxg5 19. bxc5 Bxc5 20. Bb3 Qe5 21. Bb2 Bd6 22. g3 Qf5 23. Rxd6 Qxh3 24. Bxe6+ Qxe6 25. Rxe6 Kf7 26. Rxf6+ gxf6 27. Qh5+ Kg7 28. Rd1 Rf7 29. Nd5 Rh8 30. Qxg5+ Kf8 31. Ba3+ Ke8 32. Nxf6+ Rxf6 33. Qe5+ Kf7 34. Rd7+ Kg6 35. Rxb7 Rh5 36. Qe8+ Kg5 37. Rg7+ Kf5 38. g4# 1-0 d4 d5 c4 dxc4 Nf3 Nf6 e3 e6 Bxc4 c5 O-O a6 Qe2 b5 Bb3 Bb7 Rd1 Nbd7 Nc3 Qb8 d5 c4 dxe6 fxe6 Bc2 Bd6 h3 O-O Ng5 Nc5 b4 cxb3 axb3 h6 b4 hxg5 bxc5 Bxc5 Bb3 Qe5 Bb2 Bd6 g3 Qf5 Rxd6 Qxh3 Bxe6+ Qxe6 Rxe6 Kf7 Rxf6+ gxf6 Qh5+ Kg7 Rd1 Rf7 Nd5 Rh8 Qxg5+ Kf8 Ba3+ Ke8 Nxf6+ Rxf6 Qe5+ Kf7 Rd7+ Kg6 Rxb7 Rh5 Qe8+ Kg5 Rg7+ Kf5 g4#",
          "neutral_tokens": {
            "prompt_tokens": 123,
            "completion_tokens": 530,
            "total_tokens": 653,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "e3",
            "e6",
            "Bxc4",
            "c5",
            "O-O",
            "a6",
            "Qe2",
            "b5",
            "Bb3",
            "Bb7",
            "Rd1",
            "Nbd7",
            "Nc3",
            "Qb8",
            "d5",
            "c4",
            "dxe6",
            "fxe6",
            "Bc2",
            "Bd6",
            "h3",
            "O-O",
            "Ng5",
            "Nc5",
            "b4",
            "cxb3",
            "axb3",
            "h6",
            "b4",
            "hxg5",
            "bxc5",
            "Bxc5",
            "Bb3",
            "Qe5",
            "Bb2",
            "Bd6",
            "g3",
            "Qf5",
            "Rxd6",
            "Qxh3",
            "Bxe6+",
            "Qxe6",
            "Rxe6",
            "Kf7",
            "Rxf6+",
            "gxf6",
            "Qh5+",
            "Kg7",
            "Rd1",
            "Rf7",
            "Nd5",
            "Rh8",
            "Qxg5+",
            "Kf8",
            "Ba3+",
            "Ke8",
            "Nxf6+",
            "Rxf6",
            "Qe5+",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rxb7",
            "Rh5",
            "Qe8+",
            "Kg5",
            "Rg7+",
            "Kf5",
            "g4#"
          ],
          "plan_execute": [
            "Nf6",
            "e3",
            "e6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": null,
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "e3",
              "e6",
              "Bxc4",
              "c5",
              "O-O",
              "a6",
              "dxc5",
              "Qxd1",
              "Rxd1",
              "Bxc5",
              "Nbd2",
              "O-O",
              "Nb3",
              "Be7",
              "Bd2",
              "Nc6",
              "Rac1",
              "Bd7",
              "Be2",
              "Rfd8",
              "Nc5",
              "Bxc5",
              "Rxc5",
              "Ne4",
              "Rcc1",
              "Nxd2",
              "Rxd2",
              "Be8",
              "Rcd1",
              "Rxd2",
              "Rxd2",
              "Rd8",
              "Rxd8",
              "Nxd8",
              "Kf1",
              "Kf8",
              "Ke1",
              "Ke7",
              "Kd2",
              "Kd6",
              "Kc3",
              "Nc6",
              "Nd4",
              "Nxd4",
              "Kxd4",
              "e5+",
              "Kc3",
              "Bc6",
              "g3",
              "a5",
              "a3",
              "b6",
              "b4",
              "axb4+",
              "axb4",
              "Bd5",
              "Bd3",
              "h6",
              "Bc2",
              "g5",
              "Bd3",
              "f6",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5",
              "Bc2",
              "Be6",
              "Bd3",
              "Bd5"
            ],
            "execute": [
              "Nf6",
              "e3",
              "e6"
            ]
          },
          "positional": {
            "full": [
              "a6",
              "Ba4",
              "Nf6"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "Nf6",
              "e3",
              "e6",
              "Bxc4",
              "c5",
              "O-O",
              "a6",
              "Qe2",
              "b5",
              "Bb3",
              "Bb7",
              "Rd1",
              "Nbd7",
              "Nc3",
              "Qb8",
              "d5",
              "c4",
              "dxe6",
              "fxe6",
              "Bc2",
              "Bd6",
              "h3",
              "O-O",
              "Ng5",
              "Nc5",
              "b4",
              "cxb3",
              "axb3",
              "h6",
              "b4",
              "hxg5",
              "bxc5",
              "Bxc5",
              "Bb3",
              "Qe5",
              "Bb2",
              "Bd6",
              "g3",
              "Qf5",
              "Rxd6",
              "Qxh3",
              "Bxe6+",
              "Qxe6",
              "Rxe6",
              "Kf7",
              "Rxf6+",
              "gxf6",
              "Qh5+",
              "Kg7",
              "Rd1",
              "Rf7",
              "Nd5",
              "Rh8",
              "Qxg5+",
              "Kf8",
              "Ba3+",
              "Ke8",
              "Nxf6+",
              "Rxf6",
              "Qe5+",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rxb7",
              "Rh5",
              "Qe8+",
              "Kg5",
              "Rg7+",
              "Kf5",
              "g4#"
            ],
            "execute": [
              "Nf6",
              "e3",
              "e6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf6",
            "e3",
            "e6"
          ],
          "full_moves": [
            "Nf6",
            "e3",
            "e6",
            "Bxc4",
            "c5",
            "O-O",
            "a6",
            "Qe2",
            "b5",
            "Bb3",
            "Bb7",
            "Rd1",
            "Nbd7",
            "Nc3",
            "Qb8",
            "d5",
            "c4",
            "dxe6",
            "fxe6",
            "Bc2",
            "Bd6",
            "h3",
            "O-O",
            "Ng5",
            "Nc5",
            "b4",
            "cxb3",
            "axb3",
            "h6",
            "b4",
            "hxg5",
            "bxc5",
            "Bxc5",
            "Bb3",
            "Qe5",
            "Bb2",
            "Bd6",
            "g3",
            "Qf5",
            "Rxd6",
            "Qxh3",
            "Bxe6+",
            "Qxe6",
            "Rxe6",
            "Kf7",
            "Rxf6+",
            "gxf6",
            "Qh5+",
            "Kg7",
            "Rd1",
            "Rf7",
            "Nd5",
            "Rh8",
            "Qxg5+",
            "Kf8",
            "Ba3+",
            "Ke8",
            "Nxf6+",
            "Rxf6",
            "Qe5+",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rxb7",
            "Rh5",
            "Qe8+",
            "Kg5",
            "Rg7+",
            "Kf5",
            "g4#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 124,
            "completion_tokens": 585,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 123,
            "completion_tokens": 530,
            "total_tokens": 653,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 371,
          "total_completion_tokens": 1755,
          "total_tokens": 2126
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 124,
            "completion_tokens": 585,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 123,
            "completion_tokens": 530,
            "total_tokens": 653,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/8/2pP4/8/PP2PPPP/RNBQKBNR w KQkq - 0 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc3",
          "aggressive_uci": "b1c3",
          "aggressive_response": "4. Nc3 Bg4 5. e3 e5 6. d5 Nce7 7. Bxc4 Nf6 8. e4 Ng6 9. O-O Bc5 10. h3 Bxf3 11. Qxf3 O-O 12. Bg5 Be7 13. Rad1 h6 14. Be3 a6 15. a4 Bd6 16. Qe2 Qe7 17. Qd2 Nh5 18. Ne2 Qh4 19. Bd3 Nhf4 20. Bxf4 exf4 21. f3 Ne5 22. Kh1 g5 23. Nd4 Qh5 24. Nf5 Qg6 25. Nxd6 cxd6 26. Rc1 Rac8 27. Rc3 Rxc3 28. Qxc3 h5 29. Be2 Kg7 30. Rc1 g4 31. fxg4 hxg4 32. Bxg4 Rh8 33. Bf5 Qg5 34. Rf1 Rh4 35. Qc7 f3 36. gxf3 Qg3 37. Rg1 Rxh3+ 38. Bxh3 Qxg1+ 39. Kxg1 Nxf3+ 40. Kf2 Ng5 41. Bf5 Kf6 42. Qxd6+ Kg7 43. Qe5+ f6 44. Qe7+ Kh6 45. Qxf6+ Kh5 46. Qg6+ Kh4 47. Qh6# Nxe4+ 48. Bxe4+ Kg4 49. Qg6+ Kf4 50. Qf5# Nxf5 51. Bxf5 Kxf5 52. Ke3 Ke5 53. Kd3 Kxd5 54. Kc3 Kc5 55. b4+ Kd5 56. Kd3 b6 57. Kc3 Ke4 58. Kc4 Ke5 59. b5 a5 60. Kd3 Kd5 61. Kc3 Kc5 62. Kb3 Kd4 63. Ka3 Kc4 64. Ka2 Kb4 65. Kb2 Kxa4 66. Ka2 Kxb5 67. Kb2 Kb4 68. Ka2 a4 69. Kb2 a3+ 70. Ka2 Ka4 71. Ka1 b5 72. Ka2 b4 73. Ka1 b3 74. Kb1 Kb4 75. Ka1 Kc3 76. Kb1 a2+ 77. Ka1 b2+ 78. Kxa2 Kc2 79. Ka3 b1=Q 80. Ka4 Qb6 81.",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bg4",
            "e3",
            "e5",
            "d5",
            "Nce7",
            "Bxc4",
            "Nf6",
            "e4",
            "Ng6",
            "O-O",
            "Bc5",
            "h3",
            "Bxf3",
            "Qxf3",
            "O-O",
            "Bg5",
            "Be7",
            "Rad1",
            "h6",
            "Be3",
            "a6",
            "a4",
            "Bd6",
            "Qe2",
            "Qe7",
            "Qd2",
            "Nh5",
            "Ne2",
            "Qh4",
            "Bd3",
            "Nhf4",
            "Bxf4",
            "exf4",
            "f3",
            "Ne5",
            "Kh1",
            "g5",
            "Nd4",
            "Qh5",
            "Nf5",
            "Qg6",
            "Nxd6",
            "cxd6",
            "Rc1",
            "Rac8",
            "Rc3",
            "Rxc3",
            "Qxc3",
            "h5",
            "Be2",
            "Kg7",
            "Rc1",
            "g4",
            "fxg4",
            "hxg4",
            "Bxg4",
            "Rh8",
            "Bf5",
            "Qg5",
            "Rf1",
            "Rh4",
            "Qc7",
            "f3",
            "gxf3",
            "Qg3",
            "Rg1",
            "Rxh3+",
            "Bxh3",
            "Qxg1+",
            "Kxg1",
            "Nxf3+",
            "Kf2",
            "Ng5",
            "Bf5",
            "Kf6",
            "Qxd6+",
            "Kg7",
            "Qe5+",
            "f6",
            "Qe7+",
            "Kh6",
            "Qxf6+",
            "Kh5",
            "Qg6+",
            "Kh4",
            "Qh6#",
            "Nxe4+",
            "Bxe4+",
            "Kg4",
            "Qg6+",
            "Kf4",
            "Qf5#",
            "Nxf5",
            "Bxf5",
            "Kxf5",
            "Ke3",
            "Ke5",
            "Kd3",
            "Kxd5",
            "Kc3",
            "Kc5",
            "b4+",
            "Kd5",
            "Kd3",
            "b6",
            "Kc3",
            "Ke4",
            "Kc4",
            "Ke5",
            "b5",
            "a5",
            "Kd3",
            "Kd5",
            "Kc3",
            "Kc5",
            "Kb3",
            "Kd4",
            "Ka3",
            "Kc4",
            "Ka2",
            "Kb4",
            "Kb2",
            "Kxa4",
            "Ka2",
            "Kxb5",
            "Kb2",
            "Kb4",
            "Ka2",
            "a4",
            "Kb2",
            "a3+",
            "Ka2",
            "Ka4",
            "Ka1",
            "b5",
            "Ka2",
            "b4",
            "Ka1",
            "b3",
            "Kb1",
            "Kb4",
            "Ka1",
            "Kc3",
            "Kb1",
            "a2+",
            "Ka1",
            "b2+",
            "Kxa2",
            "Kc2",
            "Ka3",
            "b1=Q",
            "Ka4",
            "Qb6"
          ],
          "plan_execute": [
            "Bg4",
            "e3",
            "e5"
          ]
        },
        "query2": {
          "positional_move": "e3",
          "positional_uci": "e2e3",
          "positional_response": "4. e3 e5 5. Bxc4 exd4 6. exd4 Bb4+ 7. Nc3 Nf6 8. O-O O-O 9. Bg5 Bg4 10. Nd5 Be7 11. Nxe7+ Qxe7 12. Re1 Qd6 13. d5 Ne5 14. Be2 Bxf3 15. Bxf3 Nxf3+ 16. Qxf3 Qxd5 17. Qg3 Ne4 18. Rxe4 Qxe4 19. Bh6 Qg6 20. Qxg6 fxg6 21. Be3 b6 22. Rc1 c5 23. a3 Rad8 24. b4 cxb4 25. axb4 Rd7 26. g3 Rfd8 27. Kg2 Kf7 28. Rc4 Ke6 29. Re4+ Kd5 30. Rd4+ Kc6 31. Rc4+ Kb5 32. Re4 Rc8 33. Re5+ Kxb4 34. Re4+ Rc4 35. Re8 b5 36. Ra8 a5 37. Bb6 a4 38. Ba5+ Kb3 39. Rb8 b4 40. Bb6 a3 41. Ra8 a2 42. Be3 Kb2 43. Bf4 a1=Q 44. Be5+ Rc3 45. Rxa1 Kxa1 46. Bxc3+ bxc3 47. Kf3 c2 48. Ke2 c1=Q 49. Kf3 Qc6+ 50. Ke2 Qe4+ 51. Kf1 Rd1# 0-1 d4 d5 c4 dxc4 Nf3 Nc6 e3 e5 Bxc4 exd4 exd4 Bb4+ Nc3 Nf6 O-O O-O Bg5 Bg4 Nd5 Be7 Nxe7+ Qxe7 Re1 Qd6 d5 Ne5 Be2 Bxf3 Bxf3 Nxf3+ Qxf3 Qxd5 Qg3 Ne4 Bf4 Nxg3 hxg3 Rfe8 Red1 Qe6 Bxc7 Rac8 Bf4 Rc2 b3 Qe2 Rf1 Rxa2 Rad1 Qc2 Rc1 Qxb3 Rb1 Qd5 Rbd1 Qc6 Rc1 Qd7 Rcd1 Qc8 Rc1 Rc2 Rb1 b6 Ra1 a5 Rab1 Qc6 Rbd1 h6 Rd6 Qc5 Rdd1 Ree2 Be3 Rxe3 fxe3 Qxe3+ Kh1 Qxg3 Rg1 Qh4# 0-1 d4 d5 c4 dxc4 Nf3 Nc6",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Bxc4",
            "exd4",
            "exd4",
            "Bb4+",
            "Nc3",
            "Nf6",
            "O-O",
            "O-O",
            "Bg5",
            "Bg4",
            "Nd5",
            "Be7",
            "Nxe7+",
            "Qxe7",
            "Re1",
            "Qd6",
            "d5",
            "Ne5",
            "Be2",
            "Bxf3",
            "Bxf3",
            "Nxf3+",
            "Qxf3",
            "Qxd5",
            "Qg3",
            "Ne4",
            "Bf4",
            "Nxg3",
            "hxg3",
            "Rfe8",
            "Red1",
            "Qe6",
            "Bxc7",
            "Rac8",
            "Bf4",
            "Rc2",
            "b3",
            "Qe2",
            "Rf1",
            "Rxa2",
            "Rad1",
            "Qc2",
            "Rc1",
            "Qxb3",
            "Rb1",
            "Qd5",
            "Rbd1",
            "Qc6",
            "Rc1",
            "Qd7",
            "Rcd1",
            "Qc8",
            "Rc1",
            "Rc2",
            "Rb1",
            "b6",
            "Ra1",
            "a5",
            "Rab1",
            "Qc6",
            "Rbd1",
            "h6",
            "Rd6",
            "Qc5",
            "Rdd1",
            "Ree2",
            "Be3",
            "Rxe3",
            "fxe3",
            "Qxe3+",
            "Kh1",
            "Qxg3",
            "Rg1",
            "Qh4#",
            "d4",
            "d5",
            "c4",
            "dxc4",
            "Nf3",
            "Nc6"
          ],
          "plan_execute": [
            "e5",
            "Bxc4",
            "exd4"
          ]
        },
        "query3": {
          "neutral_move": "Nc3",
          "neutral_uci": "b1c3",
          "neutral_response": "4. Nc3 Nf6 5. e4 Bg4 6. Be3 e6 7. Bxc4 Bb4 8. Qd3 O-O 9. O-O-O a6 10. h3 Bh5 11. g4 Bg6 12. Nd2 b5 13. Bb3 Ne5 14. Qe2 Nc6 15. e5 Nd5 16. Nxd5 exd5 17. f4 f5 18. g5 Na5 19. h4 Nxb3+ 20. Nxb3 Qe8 21. h5 Bf7 22. g6 hxg6 23. hxg6 Bxg6 24. Rdg1 Kf7 25. Qg2 Qc6+ 26. Kb1 Rh8 27. Rxh8 Rxh8 28. Rc1 Qd7 29. e6+ Qxe6 30. Rxc7+ Be7 31. Nc5 Qxe3 32. Qxd5+ Kf8 33. Rc8+ Be8 34. Nd7# 1-0 4. Nc3 Nf6 5. e4 Bg4 6. Be3 e6 7. Bxc4 Bb4 8. Qd3 O-O 9. O-O-O a6 10. h3 Bh5 11. g4 Bg6 12. Nd2 b5 13. Bb3 Ne5 14. Qe2 Nc6 15. e5 Nd5 16. Nxd5 exd5 17. f4 f5 18. g5 Na5 19. h4 Nxb3+ 20. Nxb3 Qe8 21. h5 Bf7 22. g6 hxg6 23. hxg6 Bxg6 24. Rdg1 Kf7 25. Qg2 Qc6+ 26. Kb1 Rh8 27. Rxh8 Rxh8 28. Rc1 Qd7 29. e6+ Qxe6 30. Rxc7+ Be7 31. Nc5 Qxe3 32. Qxd5+ Kf8 33. Rc8+ Be8 34. Nd7# 1-0",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 520,
            "total_tokens": 652,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "e4",
            "Bg4",
            "Be3",
            "e6",
            "Bxc4",
            "Bb4",
            "Qd3",
            "O-O",
            "O-O-O",
            "a6",
            "h3",
            "Bh5",
            "g4",
            "Bg6",
            "Nd2",
            "b5",
            "Bb3",
            "Ne5",
            "Qe2",
            "Nc6",
            "e5",
            "Nd5",
            "Nxd5",
            "exd5",
            "f4",
            "f5",
            "g5",
            "Na5",
            "h4",
            "Nxb3+",
            "Nxb3",
            "Qe8",
            "h5",
            "Bf7",
            "g6",
            "hxg6",
            "hxg6",
            "Bxg6",
            "Rdg1",
            "Kf7",
            "Qg2",
            "Qc6+",
            "Kb1",
            "Rh8",
            "Rxh8",
            "Rxh8",
            "Rc1",
            "Qd7",
            "e6+",
            "Qxe6",
            "Rxc7+",
            "Be7",
            "Nc5",
            "Qxe3",
            "Qxd5+",
            "Kf8",
            "Rc8+",
            "Be8",
            "Nd7#"
          ],
          "plan_execute": [
            "Nf6",
            "e4",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b1c3",
          "positional_uci": "e2e3",
          "neutral_uci": "b1c3",
          "consensus_move": "b1c3",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg4",
              "e3",
              "e5",
              "d5",
              "Nce7",
              "Bxc4",
              "Nf6",
              "e4",
              "Ng6",
              "O-O",
              "Bc5",
              "h3",
              "Bxf3",
              "Qxf3",
              "O-O",
              "Bg5",
              "Be7",
              "Rad1",
              "h6",
              "Be3",
              "a6",
              "a4",
              "Bd6",
              "Qe2",
              "Qe7",
              "Qd2",
              "Nh5",
              "Ne2",
              "Qh4",
              "Bd3",
              "Nhf4",
              "Bxf4",
              "exf4",
              "f3",
              "Ne5",
              "Kh1",
              "g5",
              "Nd4",
              "Qh5",
              "Nf5",
              "Qg6",
              "Nxd6",
              "cxd6",
              "Rc1",
              "Rac8",
              "Rc3",
              "Rxc3",
              "Qxc3",
              "h5",
              "Be2",
              "Kg7",
              "Rc1",
              "g4",
              "fxg4",
              "hxg4",
              "Bxg4",
              "Rh8",
              "Bf5",
              "Qg5",
              "Rf1",
              "Rh4",
              "Qc7",
              "f3",
              "gxf3",
              "Qg3",
              "Rg1",
              "Rxh3+",
              "Bxh3",
              "Qxg1+",
              "Kxg1",
              "Nxf3+",
              "Kf2",
              "Ng5",
              "Bf5",
              "Kf6",
              "Qxd6+",
              "Kg7",
              "Qe5+",
              "f6",
              "Qe7+",
              "Kh6",
              "Qxf6+",
              "Kh5",
              "Qg6+",
              "Kh4",
              "Qh6#",
              "Nxe4+",
              "Bxe4+",
              "Kg4",
              "Qg6+",
              "Kf4",
              "Qf5#",
              "Nxf5",
              "Bxf5",
              "Kxf5",
              "Ke3",
              "Ke5",
              "Kd3",
              "Kxd5",
              "Kc3",
              "Kc5",
              "b4+",
              "Kd5",
              "Kd3",
              "b6",
              "Kc3",
              "Ke4",
              "Kc4",
              "Ke5",
              "b5",
              "a5",
              "Kd3",
              "Kd5",
              "Kc3",
              "Kc5",
              "Kb3",
              "Kd4",
              "Ka3",
              "Kc4",
              "Ka2",
              "Kb4",
              "Kb2",
              "Kxa4",
              "Ka2",
              "Kxb5",
              "Kb2",
              "Kb4",
              "Ka2",
              "a4",
              "Kb2",
              "a3+",
              "Ka2",
              "Ka4",
              "Ka1",
              "b5",
              "Ka2",
              "b4",
              "Ka1",
              "b3",
              "Kb1",
              "Kb4",
              "Ka1",
              "Kc3",
              "Kb1",
              "a2+",
              "Ka1",
              "b2+",
              "Kxa2",
              "Kc2",
              "Ka3",
              "b1=Q",
              "Ka4",
              "Qb6"
            ],
            "execute": [
              "Bg4",
              "e3",
              "e5"
            ]
          },
          "positional": {
            "full": [
              "e5",
              "Bxc4",
              "exd4",
              "exd4",
              "Bb4+",
              "Nc3",
              "Nf6",
              "O-O",
              "O-O",
              "Bg5",
              "Bg4",
              "Nd5",
              "Be7",
              "Nxe7+",
              "Qxe7",
              "Re1",
              "Qd6",
              "d5",
              "Ne5",
              "Be2",
              "Bxf3",
              "Bxf3",
              "Nxf3+",
              "Qxf3",
              "Qxd5",
              "Qg3",
              "Ne4",
              "Bf4",
              "Nxg3",
              "hxg3",
              "Rfe8",
              "Red1",
              "Qe6",
              "Bxc7",
              "Rac8",
              "Bf4",
              "Rc2",
              "b3",
              "Qe2",
              "Rf1",
              "Rxa2",
              "Rad1",
              "Qc2",
              "Rc1",
              "Qxb3",
              "Rb1",
              "Qd5",
              "Rbd1",
              "Qc6",
              "Rc1",
              "Qd7",
              "Rcd1",
              "Qc8",
              "Rc1",
              "Rc2",
              "Rb1",
              "b6",
              "Ra1",
              "a5",
              "Rab1",
              "Qc6",
              "Rbd1",
              "h6",
              "Rd6",
              "Qc5",
              "Rdd1",
              "Ree2",
              "Be3",
              "Rxe3",
              "fxe3",
              "Qxe3+",
              "Kh1",
              "Qxg3",
              "Rg1",
              "Qh4#",
              "d4",
              "d5",
              "c4",
              "dxc4",
              "Nf3",
              "Nc6"
            ],
            "execute": [
              "e5",
              "Bxc4",
              "exd4"
            ]
          },
          "neutral": {
            "full": [
              "Nf6",
              "e4",
              "Bg4",
              "Be3",
              "e6",
              "Bxc4",
              "Bb4",
              "Qd3",
              "O-O",
              "O-O-O",
              "a6",
              "h3",
              "Bh5",
              "g4",
              "Bg6",
              "Nd2",
              "b5",
              "Bb3",
              "Ne5",
              "Qe2",
              "Nc6",
              "e5",
              "Nd5",
              "Nxd5",
              "exd5",
              "f4",
              "f5",
              "g5",
              "Na5",
              "h4",
              "Nxb3+",
              "Nxb3",
              "Qe8",
              "h5",
              "Bf7",
              "g6",
              "hxg6",
              "hxg6",
              "Bxg6",
              "Rdg1",
              "Kf7",
              "Qg2",
              "Qc6+",
              "Kb1",
              "Rh8",
              "Rxh8",
              "Rxh8",
              "Rc1",
              "Qd7",
              "e6+",
              "Qxe6",
              "Rxc7+",
              "Be7",
              "Nc5",
              "Qxe3",
              "Qxd5+",
              "Kf8",
              "Rc8+",
              "Be8",
              "Nd7#"
            ],
            "execute": [
              "Nf6",
              "e4",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf6",
            "e4",
            "Bg4"
          ],
          "full_moves": [
            "Nf6",
            "e4",
            "Bg4",
            "Be3",
            "e6",
            "Bxc4",
            "Bb4",
            "Qd3",
            "O-O",
            "O-O-O",
            "a6",
            "h3",
            "Bh5",
            "g4",
            "Bg6",
            "Nd2",
            "b5",
            "Bb3",
            "Ne5",
            "Qe2",
            "Nc6",
            "e5",
            "Nd5",
            "Nxd5",
            "exd5",
            "f4",
            "f5",
            "g5",
            "Na5",
            "h4",
            "Nxb3+",
            "Nxb3",
            "Qe8",
            "h5",
            "Bf7",
            "g6",
            "hxg6",
            "hxg6",
            "Bxg6",
            "Rdg1",
            "Kf7",
            "Qg2",
            "Qc6+",
            "Kb1",
            "Rh8",
            "Rxh8",
            "Rxh8",
            "Rc1",
            "Qd7",
            "e6+",
            "Qxe6",
            "Rxc7+",
            "Be7",
            "Nc5",
            "Qxe3",
            "Qxd5+",
            "Kf8",
            "Rc8+",
            "Be8",
            "Nd7#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 520,
            "total_tokens": 652,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1800,
          "total_tokens": 2198
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 520,
            "total_tokens": 652,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/ppp1pppp/2n5/8/2pP4/5N2/PP2PPPP/RNBQKB1R w KQkq - 2 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "5. e4 Bb4 6. Bxc4 Nf6 7. e5 Nd5 8. Bd2 O-O 9. O-O Nxc3 10. bxc3 Be7 11. Bd3 f6 12. exf6 Bxf6 13. Re1 Re8 14. Qc2 h6 15. Bg6 Re7 16. Rad1 Qd5 17. c4 Qd6 18. Bc3 Qf4 19. Re4 Qd6 20. c5 Qd5 21. Ne5 Bxe5 22. dxe5 Qxc5 23. Rf4 Bd7 24. Bh7+ Kh8 25. Qd3 Rae8 26. Bg6 Rd8 27. Qf3 Ree8 28. Bxe8 Rxe8 29. Rxd7 Nxe5 30. Bxe5 Qxe5 31. Rf8+ Rxf8 32. Qxf8+ Kh7 33. g3 Qa1+ 34. Kg2 Qe5 35. Qf7 Qe4+ 36. Kh3 Qe5 37. Rxc7 Qd4 38. Rxb7 a5 39. Qxe6 Qxf2 40. Qe4+ Kg8 41. Rb8+ Kf7 42. Qe8+ Kf6 43. Qf8+ Kg6 44. Qxf2 Kh7 45. Qf5+ g6 46. Qf7# e4 Bb4 Nf6 Nxe5 Nxe5 Bxe5 Bf6 Qd5 f6 Bxf6 Bxf6 Qxf6#",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 388,
            "total_tokens": 529,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb4",
            "Nf6",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "Bf6",
            "Qd5",
            "f6",
            "Bxf6",
            "Bxf6",
            "Qxf6#"
          ],
          "plan_execute": [
            "Bb4",
            "Nf6",
            "Nxe5"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "5. e4 Bb4 6. Bxc4 Nf6 7. Bg5 h6 8. Bxf6 Qxf6 9. O-O O-O 10. e5 Qd8 11. Ne4 a6 12. a3 Be7 13. Rc1 b5 14. Ba2 Bb7 15. Bb1 Na5 16. Qc2 g6 17. Qxc7 Qxc7 18. Rxc7 Bd8 19. Rc3 Nc4 20. Nc5 Bxf3 21. Rxf3 Nd2 22. Rh3 Nxf1 23. Kxf1 Kg7 24. Be4 Ra7 25. b4 Bb6 26. Rd3 Rd8 27. Ke2 a5 28. Ke3 axb4 29. axb4 Ra2 30. Bc6 Rb2 31. Bxb5 Rxb4 32. Bc6 Rc4 33. Bb5 Rb4 34. Bc6 Rc4 35. Bb5 Rb4 36. Bc6 Rc4 37. Bb5 Rb4 38. Bc6 Rc4 39. Bb5 Rb4 40. Bc6 Rc4 41. Bb5 Rb4 42. Bc6 Rc4 43. Bb5 Rb4 44. Bc6 Rc4 45. Bb5 Rb4 46. Bc6 Rc4 47. Bb5 Rb4 48. Bc6 Rc4 49. Bb5 Rb4 50. Bc6 Rc4 51. Bb5 Rb4 52. Bc6 Rc4 53. Bb5 Rb4 54. Bc6 Rc4 55. Bb5 Rb4 56. Bc6 Rc4 57. Bb5 Rb4 58. Bc6 Rc4 59. Bb5 Rb4 60. Bc6 Rc4 61. Bb5 Rb4 62. Bc6 Rc4 63. Bb5 Rb4 64. Bc6 Rc4 65. Bb5 Rb4 66. Bc6 Rc4 67. Bb5 Rb4 68. Bc6 Rc4 69. Bb5 Rb4 70. Bc6 Rc4 71. Bb5 Rb4 72. Bc6 Rc4 73. Bb5 Rb4 74. Bc6 Rc4 75. Bb5 Rb4 76. Bc6 Rc4 77. Bb5 Rb4 78. Bc6 Rc4 79. Bb5 Rb4 80. Bc6 Rc4 81. Bb5 Rb4",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb4",
            "Bxc4",
            "Nf6",
            "Bg5",
            "h6",
            "Bxf6",
            "Qxf6",
            "O-O",
            "O-O",
            "e5",
            "Qd8",
            "Ne4",
            "a6",
            "a3",
            "Be7",
            "Rc1",
            "b5",
            "Ba2",
            "Bb7",
            "Bb1",
            "Na5",
            "Qc2",
            "g6",
            "Qxc7",
            "Qxc7",
            "Rxc7",
            "Bd8",
            "Rc3",
            "Nc4",
            "Nc5",
            "Bxf3",
            "Rxf3",
            "Nd2",
            "Rh3",
            "Nxf1",
            "Kxf1",
            "Kg7",
            "Be4",
            "Ra7",
            "b4",
            "Bb6",
            "Rd3",
            "Rd8",
            "Ke2",
            "a5",
            "Ke3",
            "axb4",
            "axb4",
            "Ra2",
            "Bc6",
            "Rb2",
            "Bxb5",
            "Rxb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4",
            "Bc6",
            "Rc4",
            "Bb5",
            "Rb4"
          ],
          "plan_execute": [
            "Bb4",
            "Bxc4",
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "5. e4 Bb4 6. Bxc4 Nf6 7. e5 Nd5 8. Bd2 O-O 9. O-O Nxc3 10. bxc3 Be7 11. Bd3 b6 12. Qc2 g6 13. Bh6 Re8 14. Qd2 Bb7 15. Ng5 Bf8 16. Bxf8 Rxf8 17. Ne4 Kg7 18. Nf6 Ne7 19. Ng4 Ng8 20. f4 Qh4 21. Ne3 Nh6 22. g3 Qh3 23. Rf2 Ng4 24. Nxg4 Qxg4 25. Be2 Qf5 26. g4 Qe4 27. Bf3 Qxf3 28. Rxf3 Bxf3 29. h3 Rad8 30. Qe3 Bd5 31. a3 Bc4 32. f5 exf5 33. gxf5 gxf5 34. Qg5+ Kh8 35. Qf6+ Kg8 36. Kf2 Rfe8 37. Rg1+ Kf8 38. Rg7 Rd7 39. Rxh7 Re6 40. Rh8# Bb5 41. Rh8# Bc6 42. Rh7# Bb5 43. Rh8# Bc6 44. Rh7# Bb5 45. Rh8# Bc6 46. Rh7# Bb5 47. Rh8# Bc6 48. Rh7# Bb5 49. Rh8# Bc6 50. Rh7# Bb5 51. Rh8# Bc6 52. Rh7# Bb5 53. Rh8# Bc6 54. Rh7# Bb5 55. Rh8# Bc6 56. Rh7# Bb5 57. Rh8# Bc6 58. Rh7# Bb5 59. Rh8# Bc6 60. Rh7# Bb5 61. Rh8# Bc6 62. Rh7# Bb5 63. Rh8# Bc6 64. Rh7# Bb5 65. Rh8# Bc6 66. Rh7# Bb5 67. Rh8# Bc6 68. Rh7# Bb5 69. Rh8# Bc6 70. Rh7# Bb5 71. Rh8# Bc6 72. Rh7# Bb5 73. Rh8# Bc6 74. Rh7# Bb5 75. Rh8# Bc6 76. Rh7# Bb5 77. Rh8# Bc6 78. Rh7# Bb5 79. Rh",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb4",
            "Bxc4",
            "Nf6",
            "e5",
            "Nd5",
            "Bd2",
            "O-O",
            "O-O",
            "Nxc3",
            "bxc3",
            "Be7",
            "Bd3",
            "b6",
            "Qc2",
            "g6",
            "Bh6",
            "Re8",
            "Qd2",
            "Bb7",
            "Ng5",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Ne4",
            "Kg7",
            "Nf6",
            "Ne7",
            "Ng4",
            "Ng8",
            "f4",
            "Qh4",
            "Ne3",
            "Nh6",
            "g3",
            "Qh3",
            "Rf2",
            "Ng4",
            "Nxg4",
            "Qxg4",
            "Be2",
            "Qf5",
            "g4",
            "Qe4",
            "Bf3",
            "Qxf3",
            "Rxf3",
            "Bxf3",
            "h3",
            "Rad8",
            "Qe3",
            "Bd5",
            "a3",
            "Bc4",
            "f5",
            "exf5",
            "gxf5",
            "gxf5",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Kf2",
            "Rfe8",
            "Rg1+",
            "Kf8",
            "Rg7",
            "Rd7",
            "Rxh7",
            "Re6",
            "Rh8#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5"
          ],
          "plan_execute": [
            "Bb4",
            "Bxc4",
            "Nf6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb4",
              "Nf6",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "Bf6",
              "Qd5",
              "f6",
              "Bxf6",
              "Bxf6",
              "Qxf6#"
            ],
            "execute": [
              "Bb4",
              "Nf6",
              "Nxe5"
            ]
          },
          "positional": {
            "full": [
              "Bb4",
              "Bxc4",
              "Nf6",
              "Bg5",
              "h6",
              "Bxf6",
              "Qxf6",
              "O-O",
              "O-O",
              "e5",
              "Qd8",
              "Ne4",
              "a6",
              "a3",
              "Be7",
              "Rc1",
              "b5",
              "Ba2",
              "Bb7",
              "Bb1",
              "Na5",
              "Qc2",
              "g6",
              "Qxc7",
              "Qxc7",
              "Rxc7",
              "Bd8",
              "Rc3",
              "Nc4",
              "Nc5",
              "Bxf3",
              "Rxf3",
              "Nd2",
              "Rh3",
              "Nxf1",
              "Kxf1",
              "Kg7",
              "Be4",
              "Ra7",
              "b4",
              "Bb6",
              "Rd3",
              "Rd8",
              "Ke2",
              "a5",
              "Ke3",
              "axb4",
              "axb4",
              "Ra2",
              "Bc6",
              "Rb2",
              "Bxb5",
              "Rxb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4",
              "Bc6",
              "Rc4",
              "Bb5",
              "Rb4"
            ],
            "execute": [
              "Bb4",
              "Bxc4",
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "Bb4",
              "Bxc4",
              "Nf6",
              "e5",
              "Nd5",
              "Bd2",
              "O-O",
              "O-O",
              "Nxc3",
              "bxc3",
              "Be7",
              "Bd3",
              "b6",
              "Qc2",
              "g6",
              "Bh6",
              "Re8",
              "Qd2",
              "Bb7",
              "Ng5",
              "Bf8",
              "Bxf8",
              "Rxf8",
              "Ne4",
              "Kg7",
              "Nf6",
              "Ne7",
              "Ng4",
              "Ng8",
              "f4",
              "Qh4",
              "Ne3",
              "Nh6",
              "g3",
              "Qh3",
              "Rf2",
              "Ng4",
              "Nxg4",
              "Qxg4",
              "Be2",
              "Qf5",
              "g4",
              "Qe4",
              "Bf3",
              "Qxf3",
              "Rxf3",
              "Bxf3",
              "h3",
              "Rad8",
              "Qe3",
              "Bd5",
              "a3",
              "Bc4",
              "f5",
              "exf5",
              "gxf5",
              "gxf5",
              "Qg5+",
              "Kh8",
              "Qf6+",
              "Kg8",
              "Kf2",
              "Rfe8",
              "Rg1+",
              "Kf8",
              "Rg7",
              "Rd7",
              "Rxh7",
              "Re6",
              "Rh8#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5",
              "Rh8#",
              "Bc6",
              "Rh7#",
              "Bb5"
            ],
            "execute": [
              "Bb4",
              "Bxc4",
              "Nf6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bb4",
            "Bxc4",
            "Nf6"
          ],
          "full_moves": [
            "Bb4",
            "Bxc4",
            "Nf6",
            "e5",
            "Nd5",
            "Bd2",
            "O-O",
            "O-O",
            "Nxc3",
            "bxc3",
            "Be7",
            "Bd3",
            "b6",
            "Qc2",
            "g6",
            "Bh6",
            "Re8",
            "Qd2",
            "Bb7",
            "Ng5",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Ne4",
            "Kg7",
            "Nf6",
            "Ne7",
            "Ng4",
            "Ng8",
            "f4",
            "Qh4",
            "Ne3",
            "Nh6",
            "g3",
            "Qh3",
            "Rf2",
            "Ng4",
            "Nxg4",
            "Qxg4",
            "Be2",
            "Qf5",
            "g4",
            "Qe4",
            "Bf3",
            "Qxf3",
            "Rxf3",
            "Bxf3",
            "h3",
            "Rad8",
            "Qe3",
            "Bd5",
            "a3",
            "Bc4",
            "f5",
            "exf5",
            "gxf5",
            "gxf5",
            "Qg5+",
            "Kh8",
            "Qf6+",
            "Kg8",
            "Kf2",
            "Rfe8",
            "Rg1+",
            "Kf8",
            "Rg7",
            "Rd7",
            "Rxh7",
            "Re6",
            "Rh8#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5",
            "Rh8#",
            "Bc6",
            "Rh7#",
            "Bb5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 388,
            "total_tokens": 529,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 1668,
          "total_tokens": 2090
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 388,
            "total_tokens": 529,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/ppp2ppp/2n1p3/8/2pP4/2N2N2/PP2PPPP/R1BQKB1R w KQkq - 0 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxc4",
          "aggressive_uci": "f1c4",
          "aggressive_response": "6. Bxc4 Bb4 7. O-O O-O 8. e5 Nd5 9. Nxd5 exd5 10. Bd3 Bg4 11. Be3 f6 12. h3 Bxf3 13. Qxf3 fxe5 14. Qh5 e4 15. Bc2 Qd6 16. Bb3 Rad8 17. Rac1 Ne7 18. a3 Ba5 19. Bg5 Rf5 20. Qg4 Rdf8 21. Bxe7 Qxe7 22. Rc5 c6 23. Rxa5 Rg5 24. Qe2 Rf3 25. Kh2 Qc7+ 26. Kh1 Rxh3+ 27. gxh3 Qxa5 28. Qxe4 Qd8 29. Qe6+ Kh8 30. Re1 h6 31. Bc2 g6 32. Bxg6 Kg7 33. Qf7+ Kh8 34. Qh7# Qd6 35. Re8+ Qf8 36. Rxf8# 1-0",
          "aggressive_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 263,
            "total_tokens": 412,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb4",
            "O-O",
            "O-O",
            "e5",
            "Nd5",
            "Nxd5",
            "exd5",
            "Bd3",
            "Bg4",
            "Be3",
            "f6",
            "h3",
            "Bxf3",
            "Qxf3",
            "fxe5",
            "Qh5",
            "e4",
            "Bc2",
            "Qd6",
            "Bb3",
            "Rad8",
            "Rac1",
            "Ne7",
            "a3",
            "Ba5",
            "Bg5",
            "Rf5",
            "Qg4",
            "Rdf8",
            "Bxe7",
            "Qxe7",
            "Rc5",
            "c6",
            "Rxa5",
            "Rg5",
            "Qe2",
            "Rf3",
            "Kh2",
            "Qc7+",
            "Kh1",
            "Rxh3+",
            "gxh3",
            "Qxa5",
            "Qxe4",
            "Qd8",
            "Qe6+",
            "Kh8",
            "Re1",
            "h6",
            "Bc2",
            "g6",
            "Bxg6",
            "Kg7",
            "Qf7+",
            "Kh8",
            "Qh7#",
            "Qd6",
            "Re8+",
            "Qf8",
            "Rxf8#"
          ],
          "plan_execute": [
            "Bb4",
            "O-O",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "Bxc4",
          "positional_uci": "f1c4",
          "positional_response": "6. Bxc4 Bb4 7. O-O O-O 8. e5 Nd5 9. Nxd5 exd5 10. Bd3 Bg4 11. Be3 f6 12. exf6 Qxf6 13. Be2 Rae8 14. a3 Bd6 15. h3 Bh5 16. Qb3 Bxf3 17. Bxf3 Nxd4 18. Qxd5+ Ne6 19. Qxb7 Rb8 20. Qxa7 Rxb2 21. Bd5 Kh8 22. Bxe6 Qxe6 23. Bd4 Re2 24. Qa5 Qe4 25. Qc3 Qf4 26. g3 Qh6 27. h4 Qg6 28. Rae1 Rc2 29. Qe3 c5 30. Ba1 c4 31. Qg5 Qxg5 32. hxg5 Bxa3 33. Re3 Bc5 34. Re5 Bxf2+ 35. Kh1 Kg8 36. Re7 Rf7 37. Re8+ Rf8 38. Re7 Rf7 39. Re8+ Rf8 40. Re7 Rf7 41. Re8+ Rf8 42. Re7 Rf7 43. Re8+ Rf8 44. Re7 Rf7 45. Re8+ Rf8 46. Re7 Rf7 47. Re8+ Rf8 48. Re7 Rf7 49. Re8+ Rf8 50. Re7 Rf7 51. Re8+ Rf8 52. Re7 Rf7 53. Re8+ Rf8 54. Re7 Rf7 55. Re8+ Rf8 56. Re7 Rf7 57. Re8+ Rf8 58. Re7 Rf7 59. Re8+ Rf8 60. Re7 Rf7 61. Re8+ Rf8 62. Re7 Rf7 63. Re8+ Rf8 64. Re7 Rf7 65. Re8+ Rf8 66. Re7 Rf7 67. Re8+ Rf8 68. Re7 Rf7 69. Re8+ Rf8 70. Re7 Rf7 71. Re8+ Rf8 72. Re7 Rf7 73. Re8+ Rf8 74. Re7 Rf7 75. Re8+ Rf8 76. Re7 Rf7 77. Re8+ Rf8 78. Re7 Rf7 79. Re8+ Rf8 80. Re7 Rf7 81. Re8+ Rf8 82. Re7",
          "positional_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb4",
            "O-O",
            "O-O",
            "e5",
            "Nd5",
            "Nxd5",
            "exd5",
            "Bd3",
            "Bg4",
            "Be3",
            "f6",
            "exf6",
            "Qxf6",
            "Be2",
            "Rae8",
            "a3",
            "Bd6",
            "h3",
            "Bh5",
            "Qb3",
            "Bxf3",
            "Bxf3",
            "Nxd4",
            "Qxd5+",
            "Ne6",
            "Qxb7",
            "Rb8",
            "Qxa7",
            "Rxb2",
            "Bd5",
            "Kh8",
            "Bxe6",
            "Qxe6",
            "Bd4",
            "Re2",
            "Qa5",
            "Qe4",
            "Qc3",
            "Qf4",
            "g3",
            "Qh6",
            "h4",
            "Qg6",
            "Rae1",
            "Rc2",
            "Qe3",
            "c5",
            "Ba1",
            "c4",
            "Qg5",
            "Qxg5",
            "hxg5",
            "Bxa3",
            "Re3",
            "Bc5",
            "Re5",
            "Bxf2+",
            "Kh1",
            "Kg8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7"
          ],
          "plan_execute": [
            "Bb4",
            "O-O",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Bxc4",
          "neutral_uci": "f1c4",
          "neutral_response": "6. Bxc4 Bb4 7. O-O O-O 8. e5 Nd5 9. Nxd5 exd5 10. Bd3 Bg4 11. Be3 f6 12. exf6 Qxf6 13. Be2 Rae8 14. a3 Bd6 15. h3 Bh5 16. Qb3 Bxf3 17. Bxf3 Nxd4 18. Bxd4 Qxd4 19. Bxd5+ Kh8 20. Rad1 Qe5 21. g3 Bc5 22. Kg2 Qe2 23. Bf3 Qe5 24. Rd5 Qe7 25. Qxb7 Rb8 26. Qc6 Bd6 27. b4 Rb6 28. Qc3 Qf7 29. Rfd1 Rbb8 30. R1d3 Rbe8 31. Qd2 Re6 32. Bh5 g6 33. Bg4 Rf6 34. f4 h5 35. Bf3 h4 36. Qc3 hxg3 37. Kxg3 Bxf4+ 38. Kg2 Bd6 39. R5d4 Qa2+ 40. Rd2 Qe6 41. Rh4+ Kg7 42. Re2 Qf5 43. Rf2 Qg5+ 44. Rg4 Qe5 45. Qxe5 Bxe5 46. Re4 Bd6 47. Ree2 Rf5 48. Bg4 Rxf2+ 49. Rxf2 Rxf2+ 50. Kxf2 Kf6 51. Ke3 Ke5 52. Kd3 Kd5 53. Bf3+ Ke5 54. Kc4 Kf4 55. Bg4 Ke5 56. Kb5 Kd5 57. Ka6 Kc4 58. Kxa7 Kb3 59. b5 Kxa3 60. b6 cxb6 61. Kxb6 Kb4 62. Kc6 Bf4 63. Kd5 g5 64. Ke4 Kc5 65. Kf5 Kd6 66. h4 gxh4 67. Kxf4 Ke7 68. Kg5 Kf7 69. Kxh4 Kg7 70. Kg5 Kh8 71. Kh6 Kg8 72. Kg6 Kh8 73. Kf7 Kh7 74. Bf5+ Kh8 75. Kf8 * e4 e5 Nf6 Nc6 Bb4 O-O O-O e5 Nd5 exd5 Bg4 Be3 f6 exf6 Qxf6 Be2 Rae8 a3 Bd6 h3 Bh5 Qb3 Bxf3 Bxf3",
          "neutral_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb4",
            "O-O",
            "O-O",
            "e5",
            "Nd5",
            "Nxd5",
            "exd5",
            "Bd3",
            "Bg4",
            "Be3",
            "f6",
            "exf6",
            "Qxf6",
            "Be2",
            "Rae8",
            "a3",
            "Bd6",
            "h3",
            "Bh5",
            "Qb3",
            "Bxf3",
            "Bxf3",
            "Nxd4",
            "Bxd4",
            "Qxd4",
            "Bxd5+",
            "Kh8",
            "Rad1",
            "Qe5",
            "g3",
            "Bc5",
            "Kg2",
            "Qe2",
            "Bf3",
            "Qe5",
            "Rd5",
            "Qe7",
            "Qxb7",
            "Rb8",
            "Qc6",
            "Bd6",
            "b4",
            "Rb6",
            "Qc3",
            "Qf7",
            "Rfd1",
            "Rbb8",
            "R1d3",
            "Rbe8",
            "Qd2",
            "Re6",
            "Bh5",
            "g6",
            "Bg4",
            "Rf6",
            "f4",
            "h5",
            "Bf3",
            "h4",
            "Qc3",
            "hxg3",
            "Kxg3",
            "Bxf4+",
            "Kg2",
            "Bd6",
            "R5d4",
            "Qa2+",
            "Rd2",
            "Qe6",
            "Rh4+",
            "Kg7",
            "Re2",
            "Qf5",
            "Rf2",
            "Qg5+",
            "Rg4",
            "Qe5",
            "Qxe5",
            "Bxe5",
            "Re4",
            "Bd6",
            "Ree2",
            "Rf5",
            "Bg4",
            "Rxf2+",
            "Rxf2",
            "Rxf2+",
            "Kxf2",
            "Kf6",
            "Ke3",
            "Ke5",
            "Kd3",
            "Kd5",
            "Bf3+",
            "Ke5",
            "Kc4",
            "Kf4",
            "Bg4",
            "Ke5",
            "Kb5",
            "Kd5",
            "Ka6",
            "Kc4",
            "Kxa7",
            "Kb3",
            "b5",
            "Kxa3",
            "b6",
            "cxb6",
            "Kxb6",
            "Kb4",
            "Kc6",
            "Bf4",
            "Kd5",
            "g5",
            "Ke4",
            "Kc5",
            "Kf5",
            "Kd6",
            "h4",
            "gxh4",
            "Kxf4",
            "Ke7",
            "Kg5",
            "Kf7",
            "Kxh4",
            "Kg7",
            "Kg5",
            "Kh8",
            "Kh6",
            "Kg8",
            "Kg6",
            "Kh8",
            "Kf7",
            "Kh7",
            "Bf5+",
            "Kh8",
            "Kf8",
            "e4",
            "e5",
            "Nf6",
            "Nc6",
            "Bb4",
            "O-O",
            "O-O",
            "e5",
            "Nd5",
            "exd5",
            "Bg4",
            "Be3",
            "f6",
            "exf6",
            "Qxf6",
            "Be2",
            "Rae8",
            "a3",
            "Bd6",
            "h3",
            "Bh5",
            "Qb3",
            "Bxf3",
            "Bxf3"
          ],
          "plan_execute": [
            "Bb4",
            "O-O",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1c4",
          "positional_uci": "f1c4",
          "neutral_uci": "f1c4",
          "consensus_move": "f1c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb4",
              "O-O",
              "O-O",
              "e5",
              "Nd5",
              "Nxd5",
              "exd5",
              "Bd3",
              "Bg4",
              "Be3",
              "f6",
              "h3",
              "Bxf3",
              "Qxf3",
              "fxe5",
              "Qh5",
              "e4",
              "Bc2",
              "Qd6",
              "Bb3",
              "Rad8",
              "Rac1",
              "Ne7",
              "a3",
              "Ba5",
              "Bg5",
              "Rf5",
              "Qg4",
              "Rdf8",
              "Bxe7",
              "Qxe7",
              "Rc5",
              "c6",
              "Rxa5",
              "Rg5",
              "Qe2",
              "Rf3",
              "Kh2",
              "Qc7+",
              "Kh1",
              "Rxh3+",
              "gxh3",
              "Qxa5",
              "Qxe4",
              "Qd8",
              "Qe6+",
              "Kh8",
              "Re1",
              "h6",
              "Bc2",
              "g6",
              "Bxg6",
              "Kg7",
              "Qf7+",
              "Kh8",
              "Qh7#",
              "Qd6",
              "Re8+",
              "Qf8",
              "Rxf8#"
            ],
            "execute": [
              "Bb4",
              "O-O",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "Bb4",
              "O-O",
              "O-O",
              "e5",
              "Nd5",
              "Nxd5",
              "exd5",
              "Bd3",
              "Bg4",
              "Be3",
              "f6",
              "exf6",
              "Qxf6",
              "Be2",
              "Rae8",
              "a3",
              "Bd6",
              "h3",
              "Bh5",
              "Qb3",
              "Bxf3",
              "Bxf3",
              "Nxd4",
              "Qxd5+",
              "Ne6",
              "Qxb7",
              "Rb8",
              "Qxa7",
              "Rxb2",
              "Bd5",
              "Kh8",
              "Bxe6",
              "Qxe6",
              "Bd4",
              "Re2",
              "Qa5",
              "Qe4",
              "Qc3",
              "Qf4",
              "g3",
              "Qh6",
              "h4",
              "Qg6",
              "Rae1",
              "Rc2",
              "Qe3",
              "c5",
              "Ba1",
              "c4",
              "Qg5",
              "Qxg5",
              "hxg5",
              "Bxa3",
              "Re3",
              "Bc5",
              "Re5",
              "Bxf2+",
              "Kh1",
              "Kg8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7"
            ],
            "execute": [
              "Bb4",
              "O-O",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Bb4",
              "O-O",
              "O-O",
              "e5",
              "Nd5",
              "Nxd5",
              "exd5",
              "Bd3",
              "Bg4",
              "Be3",
              "f6",
              "exf6",
              "Qxf6",
              "Be2",
              "Rae8",
              "a3",
              "Bd6",
              "h3",
              "Bh5",
              "Qb3",
              "Bxf3",
              "Bxf3",
              "Nxd4",
              "Bxd4",
              "Qxd4",
              "Bxd5+",
              "Kh8",
              "Rad1",
              "Qe5",
              "g3",
              "Bc5",
              "Kg2",
              "Qe2",
              "Bf3",
              "Qe5",
              "Rd5",
              "Qe7",
              "Qxb7",
              "Rb8",
              "Qc6",
              "Bd6",
              "b4",
              "Rb6",
              "Qc3",
              "Qf7",
              "Rfd1",
              "Rbb8",
              "R1d3",
              "Rbe8",
              "Qd2",
              "Re6",
              "Bh5",
              "g6",
              "Bg4",
              "Rf6",
              "f4",
              "h5",
              "Bf3",
              "h4",
              "Qc3",
              "hxg3",
              "Kxg3",
              "Bxf4+",
              "Kg2",
              "Bd6",
              "R5d4",
              "Qa2+",
              "Rd2",
              "Qe6",
              "Rh4+",
              "Kg7",
              "Re2",
              "Qf5",
              "Rf2",
              "Qg5+",
              "Rg4",
              "Qe5",
              "Qxe5",
              "Bxe5",
              "Re4",
              "Bd6",
              "Ree2",
              "Rf5",
              "Bg4",
              "Rxf2+",
              "Rxf2",
              "Rxf2+",
              "Kxf2",
              "Kf6",
              "Ke3",
              "Ke5",
              "Kd3",
              "Kd5",
              "Bf3+",
              "Ke5",
              "Kc4",
              "Kf4",
              "Bg4",
              "Ke5",
              "Kb5",
              "Kd5",
              "Ka6",
              "Kc4",
              "Kxa7",
              "Kb3",
              "b5",
              "Kxa3",
              "b6",
              "cxb6",
              "Kxb6",
              "Kb4",
              "Kc6",
              "Bf4",
              "Kd5",
              "g5",
              "Ke4",
              "Kc5",
              "Kf5",
              "Kd6",
              "h4",
              "gxh4",
              "Kxf4",
              "Ke7",
              "Kg5",
              "Kf7",
              "Kxh4",
              "Kg7",
              "Kg5",
              "Kh8",
              "Kh6",
              "Kg8",
              "Kg6",
              "Kh8",
              "Kf7",
              "Kh7",
              "Bf5+",
              "Kh8",
              "Kf8",
              "e4",
              "e5",
              "Nf6",
              "Nc6",
              "Bb4",
              "O-O",
              "O-O",
              "e5",
              "Nd5",
              "exd5",
              "Bg4",
              "Be3",
              "f6",
              "exf6",
              "Qxf6",
              "Be2",
              "Rae8",
              "a3",
              "Bd6",
              "h3",
              "Bh5",
              "Qb3",
              "Bxf3",
              "Bxf3"
            ],
            "execute": [
              "Bb4",
              "O-O",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bb4",
            "O-O",
            "O-O"
          ],
          "full_moves": [
            "Bb4",
            "O-O",
            "O-O",
            "e5",
            "Nd5",
            "Nxd5",
            "exd5",
            "Bd3",
            "Bg4",
            "Be3",
            "f6",
            "exf6",
            "Qxf6",
            "Be2",
            "Rae8",
            "a3",
            "Bd6",
            "h3",
            "Bh5",
            "Qb3",
            "Bxf3",
            "Bxf3",
            "Nxd4",
            "Bxd4",
            "Qxd4",
            "Bxd5+",
            "Kh8",
            "Rad1",
            "Qe5",
            "g3",
            "Bc5",
            "Kg2",
            "Qe2",
            "Bf3",
            "Qe5",
            "Rd5",
            "Qe7",
            "Qxb7",
            "Rb8",
            "Qc6",
            "Bd6",
            "b4",
            "Rb6",
            "Qc3",
            "Qf7",
            "Rfd1",
            "Rbb8",
            "R1d3",
            "Rbe8",
            "Qd2",
            "Re6",
            "Bh5",
            "g6",
            "Bg4",
            "Rf6",
            "f4",
            "h5",
            "Bf3",
            "h4",
            "Qc3",
            "hxg3",
            "Kxg3",
            "Bxf4+",
            "Kg2",
            "Bd6",
            "R5d4",
            "Qa2+",
            "Rd2",
            "Qe6",
            "Rh4+",
            "Kg7",
            "Re2",
            "Qf5",
            "Rf2",
            "Qg5+",
            "Rg4",
            "Qe5",
            "Qxe5",
            "Bxe5",
            "Re4",
            "Bd6",
            "Ree2",
            "Rf5",
            "Bg4",
            "Rxf2+",
            "Rxf2",
            "Rxf2+",
            "Kxf2",
            "Kf6",
            "Ke3",
            "Ke5",
            "Kd3",
            "Kd5",
            "Bf3+",
            "Ke5",
            "Kc4",
            "Kf4",
            "Bg4",
            "Ke5",
            "Kb5",
            "Kd5",
            "Ka6",
            "Kc4",
            "Kxa7",
            "Kb3",
            "b5",
            "Kxa3",
            "b6",
            "cxb6",
            "Kxb6",
            "Kb4",
            "Kc6",
            "Bf4",
            "Kd5",
            "g5",
            "Ke4",
            "Kc5",
            "Kf5",
            "Kd6",
            "h4",
            "gxh4",
            "Kxf4",
            "Ke7",
            "Kg5",
            "Kf7",
            "Kxh4",
            "Kg7",
            "Kg5",
            "Kh8",
            "Kh6",
            "Kg8",
            "Kg6",
            "Kh8",
            "Kf7",
            "Kh7",
            "Bf5+",
            "Kh8",
            "Kf8",
            "e4",
            "e5",
            "Nf6",
            "Nc6",
            "Bb4",
            "O-O",
            "O-O",
            "e5",
            "Nd5",
            "exd5",
            "Bg4",
            "Be3",
            "f6",
            "exf6",
            "Qxf6",
            "Be2",
            "Rae8",
            "a3",
            "Bd6",
            "h3",
            "Bh5",
            "Qb3",
            "Bxf3",
            "Bxf3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 149,
            "completion_tokens": 263,
            "total_tokens": 412,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 446,
          "total_completion_tokens": 1543,
          "total_tokens": 1989
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 149,
            "completion_tokens": 263,
            "total_tokens": 412,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkb1r/ppp2ppp/2n1pn2/8/2pPP3/2N2N2/PP3PPP/R1BQKB1R w KQkq - 1 6"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": "c1g5",
          "aggressive_response": "8. Bg5 h6 9. Bh4 g5 10. Bg3 Bxc3 11. bxc3 Nxe4 12. Qd3 Nxg3 13. fxg3 Bd7 14. Rab1 O-O-O 15. Ba6 Na5 16. Bxb7+ Nxb7 17. Qa6 Bc6 18. Ne5 Qd6 19. Nxc6 Kd7 20. Ne5+ Ke7 21. Rxf7+ Ke8 22. Qb5+ c6 23. Qxb7 Rf8 24. Rxf8+ Kxf8 25. Qf7# Qe7 26. Ng6# Qxf7 27. Rf1 Qxf1+ 28. Kxf1 Kg7 29. Ne5 c5 30. Nc6 Rd6 31. Nxa7 cxd4 32. cxd4 Rxd4 33. Nb5 Ra4 34. Nc3 Ra3 35. Nb5 Rxa2 36. Nd4 Kf6 37. Nf3 e5 38. h3 e4 39. Nd4 Ke5 40. Ne2 e3 41. Nc3 Rc2 42. Ne2 Ke4 43. Ke1 Kd3 44. Kd1 Rxe2 45. Kc1 Rxg2 46. Kb1 e2 47. Kc1 e1=Q# 0-1 d4 d5 c4 dxc4 Nf3 Nc6 Nc3 e6 e4 Nf6 Bxc4 Bb4 O-O Qe7 Bg5 h6 Bh4 g5 Bg3 Bxc3 bxc3 Nxe4 Qd3 Nxg3 fxg3 Bd7 Rab1 O-O-O Ba6 Na5 Bxb7+ Nxb7 Qa6 Bc6 Ne5 Qd6 Nxc6 Kd7 Ne5+ Ke7 Rxf7+ Ke8 Qb5+ c6 Qxb7 Rf8 Rxf8+ Kxf8 Qf7# Qe7 Ng6# Qxf7 Rf1 Qxf1+ Kxf1 Kg7 Ne5 c5 Nc6 Rd6 Nxa7 cxd4 cxd4 Rxd4 Nb5 Ra4 Nc3 Nb5 Nc3 Nb5 Rxa2 Nd4 Kf6 Nf3 e5 h3 e4 Nd4 Ke5 Nb3 e3 Nc1 Rc2 Ne2 Ke4 Ke1 Kd3 Nf4+ Kc3 Ne2+ Kd3 Nf4+ Kc3 Ne2+ Kd3 Nf4+ Kc3 Ne2+ Kd3 Nf4+ Kc3 Ne2+ Kd3 Nf4+ Kc3 Ne2+ Kd3 Nf4+ Kc",
          "aggressive_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 640,
            "total_tokens": 806,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Bxc3",
            "bxc3",
            "Nxe4",
            "Qd3",
            "Nxg3",
            "fxg3",
            "Bd7",
            "Rab1",
            "O-O-O",
            "Ba6",
            "Na5",
            "Bxb7+",
            "Nxb7",
            "Qa6",
            "Bc6",
            "Ne5",
            "Qd6",
            "Nxc6",
            "Kd7",
            "Ne5+",
            "Ke7",
            "Rxf7+",
            "Ke8",
            "Qb5+",
            "c6",
            "Qxb7",
            "Rf8",
            "Rxf8+",
            "Kxf8",
            "Qf7#",
            "Qe7",
            "Ng6#",
            "Qxf7",
            "Rf1",
            "Qxf1+",
            "Kxf1",
            "Kg7",
            "Ne5",
            "c5",
            "Nc6",
            "Rd6",
            "Nxa7",
            "cxd4",
            "cxd4",
            "Rxd4",
            "Nb5",
            "Ra4",
            "Nc3",
            "Nb5",
            "Nc3",
            "Nb5",
            "Rxa2",
            "Nd4",
            "Kf6",
            "Nf3",
            "e5",
            "h3",
            "e4",
            "Nd4",
            "Ke5",
            "Nb3",
            "e3",
            "Nc1",
            "Rc2",
            "Ne2",
            "Ke4",
            "Ke1",
            "Kd3",
            "Nf4+",
            "Kc3",
            "Ne2+",
            "Kd3",
            "Nf4+",
            "Kc3",
            "Ne2+",
            "Kd3",
            "Nf4+",
            "Kc3",
            "Ne2+",
            "Kd3",
            "Nf4+",
            "Kc3",
            "Ne2+",
            "Kd3",
            "Nf4+",
            "Kc3",
            "Ne2+",
            "Kd3",
            "Nf4+"
          ],
          "plan_execute": [
            "h6",
            "Bh4",
            "g5"
          ]
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "8. Bg5 O-O 9. e5 h6 10. exf6 gxf6 11. Bxh6 Rd8 12. Ne5 fxe5 13. Qg4+ Kh7 14. Qg7# Qe8 15. Bd3+ Kh8 16. Qh7# Kh8 17. Bg7# Kh8 18. Bf6# Kh8 19. Qh6+ Kg8 20. Qg7# Kg8 21. Bh7# Kg8 22. Bg6# Kg8 23. Qh8# Kg8 24. Bh7# Kg8 25. Bg8# Kg8 26. Qg7# Kg8 27. Bh7# Kg8 28. Bg6# Kg8 29. Qh8# Kg8 30. Bh7# Kg8 31. Bg8# Kg8 32. Qg7# Kg8 33. Bh7# Kg8 34. Bg6# Kg8 35. Qh8# Kg8 36. Bh7# Kg8 37. Bg8# Kg8 38. Qg7# Kg8 39. Bh7# Kg8 40. Bg6# Kg8 41. Qh8# Kg8 42. Bh7# Kg8 43. Bg8# Kg8 44. Qg7# Kg8 45. Bh7# Kg8 46. Bg6# Kg8 47. Qh8# Kg8 48. Bh7# Kg8 49. Bg8# Kg8 50. Qg7# Kg8 51. Bh7# Kg8 52. Bg6# Kg8 53. Qh8# Kg8 54. Bh7# Kg8 55. Bg8# Kg8 56. Qg7# Kg8 57. Bh7# Kg8 58. Bg6# Kg8 59. Qh8# Kg8 60. Bh7# Kg8 61. Bg8# Kg8 62. Qg7# Kg8 63. Bh7# Kg8 64. Bg6# Kg8 65. Qh8# Kg8 66. Bh7# Kg8 67. Bg8# Kg8 68. Qg7# Kg8 69. Bh7# Kg8 70. Bg6# Kg8 71. Qh8# Kg8 72. Bh7# Kg8 73. Bg8# Kg8 74. Qg7# Kg8 75. Bh7# Kg8 76. Bg6# Kg8 77. Qh8# Kg8 78. Bh7# Kg8 79. Bg8# Kg8 80. Qg7# Kg8 81. Bh7# Kg",
          "positional_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 640,
            "total_tokens": 806,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "e5",
            "h6",
            "exf6",
            "gxf6",
            "Bxh6",
            "Rd8",
            "Ne5",
            "fxe5",
            "Qg4+",
            "Kh7",
            "Qg7#",
            "Qe8",
            "Bd3+",
            "Kh8",
            "Qh7#",
            "Kh8",
            "Bg7#",
            "Kh8",
            "Bf6#",
            "Kh8",
            "Qh6+",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg6#",
            "Kg8",
            "Qh8#",
            "Kg8",
            "Bh7#",
            "Kg8",
            "Bg8#",
            "Kg8",
            "Qg7#",
            "Kg8",
            "Bh7#"
          ],
          "plan_execute": [
            "O-O",
            "e5",
            "h6"
          ]
        },
        "query3": {
          "neutral_move": "Bg5",
          "neutral_uci": "c1g5",
          "neutral_response": "8. Bg5 h6 9. Bh4 g5 10. Bg3 Bxc3 11. bxc3 Nxe4 12. Qc2 Nxg3 13. fxg3 Bd7 14. Rab1 O-O-O 15. Qb2 b6 16. Ba6+ Kb8 17. c4 Bc8 18. Bxc8 Kxc8 19. c5 g4 20. cxb6 axb6 21. Ne5 Nxe5 22. dxe5 Qc5+ 23. Kh1 Rd5 24. Rxf7 Rhd8 25. Rff1 Rxe5 26. Rbc1 Qd6 27. Qc2 Rc5 28. Qe4 Rxc1 29. Qa8+ Kd7 30. Qa4+ Ke7 31. Rxc1 Qd4 32. Qa3+ c5 33. Qa7+ Rd7 34. Qa4 Qxa4 35. Rg1 Rd1 36. h3 Rxg1+ 37. Kxg1 Qd1+ 38. Kh2 gxh3 39. Kxh3 Qh5# e4 d5 Nf3 Nc6 Nc3 e6 e5 Nf6 Bxc4 Bb4 O-O Qe7 Bg5 h6 Bh4 g5 Bg3 Bxc3 bxc3 Nxe4 Qc2 Nxg3 fxg3 Bd7 Rab1 O-O-O Qb2 b6 Ba6+ Kb8 c4 Bc8 Bxc8 Kxc8 c5 g4 cxb6 axb6 Ne5 Nxe5 dxe5 Qc5 Qa3 Qa5 Qa4 Qxa4 Rg1 Rd5 Rgf1 Rhd8 Rxf7 Rd1+ Rf1 Rxf1+ Rxf1 Qd4 h3 gxh3 Kh2 Qxe5 Rf4 Rd2 Rf8+ Kb7 Rf7 Qe2 Rf2 Qxf2 Kh1 Qxg2#",
          "neutral_tokens": {
            "prompt_tokens": 165,
            "completion_tokens": 470,
            "total_tokens": 635,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Bxc3",
            "bxc3",
            "Nxe4",
            "Qc2",
            "Nxg3",
            "fxg3",
            "Bd7",
            "Rab1",
            "O-O-O",
            "Qb2",
            "b6",
            "Ba6+",
            "Kb8",
            "c4",
            "Bc8",
            "Bxc8",
            "Kxc8",
            "c5",
            "g4",
            "cxb6",
            "axb6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Qc5",
            "Qa3",
            "Qa5",
            "Qa4",
            "Qxa4",
            "Rg1",
            "Rd5",
            "Rgf1",
            "Rhd8",
            "Rxf7",
            "Rd1+",
            "Rf1",
            "Rxf1+",
            "Rxf1",
            "Qd4",
            "h3",
            "gxh3",
            "Kh2",
            "Qxe5",
            "Rf4",
            "Rd2",
            "Rf8+",
            "Kb7",
            "Rf7",
            "Qe2",
            "Rf2",
            "Qxf2",
            "Kh1",
            "Qxg2#"
          ],
          "plan_execute": [
            "h6",
            "Bh4",
            "g5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c1g5",
          "positional_uci": "c1g5",
          "neutral_uci": "c1g5",
          "consensus_move": "c1g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Bxc3",
              "bxc3",
              "Nxe4",
              "Qd3",
              "Nxg3",
              "fxg3",
              "Bd7",
              "Rab1",
              "O-O-O",
              "Ba6",
              "Na5",
              "Bxb7+",
              "Nxb7",
              "Qa6",
              "Bc6",
              "Ne5",
              "Qd6",
              "Nxc6",
              "Kd7",
              "Ne5+",
              "Ke7",
              "Rxf7+",
              "Ke8",
              "Qb5+",
              "c6",
              "Qxb7",
              "Rf8",
              "Rxf8+",
              "Kxf8",
              "Qf7#",
              "Qe7",
              "Ng6#",
              "Qxf7",
              "Rf1",
              "Qxf1+",
              "Kxf1",
              "Kg7",
              "Ne5",
              "c5",
              "Nc6",
              "Rd6",
              "Nxa7",
              "cxd4",
              "cxd4",
              "Rxd4",
              "Nb5",
              "Ra4",
              "Nc3",
              "Nb5",
              "Nc3",
              "Nb5",
              "Rxa2",
              "Nd4",
              "Kf6",
              "Nf3",
              "e5",
              "h3",
              "e4",
              "Nd4",
              "Ke5",
              "Nb3",
              "e3",
              "Nc1",
              "Rc2",
              "Ne2",
              "Ke4",
              "Ke1",
              "Kd3",
              "Nf4+",
              "Kc3",
              "Ne2+",
              "Kd3",
              "Nf4+",
              "Kc3",
              "Ne2+",
              "Kd3",
              "Nf4+",
              "Kc3",
              "Ne2+",
              "Kd3",
              "Nf4+",
              "Kc3",
              "Ne2+",
              "Kd3",
              "Nf4+",
              "Kc3",
              "Ne2+",
              "Kd3",
              "Nf4+"
            ],
            "execute": [
              "h6",
              "Bh4",
              "g5"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "e5",
              "h6",
              "exf6",
              "gxf6",
              "Bxh6",
              "Rd8",
              "Ne5",
              "fxe5",
              "Qg4+",
              "Kh7",
              "Qg7#",
              "Qe8",
              "Bd3+",
              "Kh8",
              "Qh7#",
              "Kh8",
              "Bg7#",
              "Kh8",
              "Bf6#",
              "Kh8",
              "Qh6+",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg6#",
              "Kg8",
              "Qh8#",
              "Kg8",
              "Bh7#",
              "Kg8",
              "Bg8#",
              "Kg8",
              "Qg7#",
              "Kg8",
              "Bh7#"
            ],
            "execute": [
              "O-O",
              "e5",
              "h6"
            ]
          },
          "neutral": {
            "full": [
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Bxc3",
              "bxc3",
              "Nxe4",
              "Qc2",
              "Nxg3",
              "fxg3",
              "Bd7",
              "Rab1",
              "O-O-O",
              "Qb2",
              "b6",
              "Ba6+",
              "Kb8",
              "c4",
              "Bc8",
              "Bxc8",
              "Kxc8",
              "c5",
              "g4",
              "cxb6",
              "axb6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Qc5",
              "Qa3",
              "Qa5",
              "Qa4",
              "Qxa4",
              "Rg1",
              "Rd5",
              "Rgf1",
              "Rhd8",
              "Rxf7",
              "Rd1+",
              "Rf1",
              "Rxf1+",
              "Rxf1",
              "Qd4",
              "h3",
              "gxh3",
              "Kh2",
              "Qxe5",
              "Rf4",
              "Rd2",
              "Rf8+",
              "Kb7",
              "Rf7",
              "Qe2",
              "Rf2",
              "Qxf2",
              "Kh1",
              "Qxg2#"
            ],
            "execute": [
              "h6",
              "Bh4",
              "g5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "h6",
            "Bh4",
            "g5"
          ],
          "full_moves": [
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Bxc3",
            "bxc3",
            "Nxe4",
            "Qc2",
            "Nxg3",
            "fxg3",
            "Bd7",
            "Rab1",
            "O-O-O",
            "Qb2",
            "b6",
            "Ba6+",
            "Kb8",
            "c4",
            "Bc8",
            "Bxc8",
            "Kxc8",
            "c5",
            "g4",
            "cxb6",
            "axb6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Qc5",
            "Qa3",
            "Qa5",
            "Qa4",
            "Qxa4",
            "Rg1",
            "Rd5",
            "Rgf1",
            "Rhd8",
            "Rxf7",
            "Rd1+",
            "Rf1",
            "Rxf1+",
            "Rxf1",
            "Qd4",
            "h3",
            "gxh3",
            "Kh2",
            "Qxe5",
            "Rf4",
            "Rd2",
            "Rf8+",
            "Kb7",
            "Rf7",
            "Qe2",
            "Rf2",
            "Qxf2",
            "Kh1",
            "Qxg2#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 166,
            "completion_tokens": 640,
            "total_tokens": 806,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 166,
            "completion_tokens": 640,
            "total_tokens": 806,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 165,
            "completion_tokens": 470,
            "total_tokens": 635,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 497,
          "total_completion_tokens": 1750,
          "total_tokens": 2247
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 166,
            "completion_tokens": 640,
            "total_tokens": 806,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 166,
            "completion_tokens": 640,
            "total_tokens": 806,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 165,
            "completion_tokens": 470,
            "total_tokens": 635,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/ppp1qppp/2n1pn2/8/1bBPP3/2N2N2/PP3PPP/R1BQ1RK1 w kq - 3 8"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "gxh4",
          "aggressive_uci": "g5h4",
          "aggressive_response": "2... gxh4 3. Rxh4 e5 4. Rh5 Nc6 5. Nf3 Nf6 6. Rg5 h6 7. Rf5 d6 8. Rxf6 Qxf6 9. Nc3 Bxg4 10. Nd5 Qd8 11. d4 Bxf3 12. exf3 Nxd4 13. c3 Ne6 14. Qa4+ c6 15. Be3 b5 16. Bxb5 cxb5 17. Qxb5+ Qd7 18. Nf6+ Ke7 19. Nxd7 Nc7 20. Qc6 Rc8 21. O-O-O Kd8 22. Nxf8 Rxf8 23. Rxd6+ Ke7 24. Qd7# d5 e4 dxe4 fxe4 fxe4 Qxe4+ Kd8 Qf6+ Ke7 Qf7+ Kd8 Qd7#",
          "aggressive_tokens": {
            "prompt_tokens": 121,
            "completion_tokens": 230,
            "total_tokens": 351,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxh4",
            "e5",
            "Rh5",
            "Nc6",
            "Nf3",
            "Nf6",
            "Rg5",
            "h6",
            "Rf5",
            "d6",
            "Rxf6",
            "Qxf6",
            "Nc3",
            "Bxg4",
            "Nd5",
            "Qd8",
            "d4",
            "Bxf3",
            "exf3",
            "Nxd4",
            "c3",
            "Ne6",
            "Qa4+",
            "c6",
            "Be3",
            "b5",
            "Bxb5",
            "cxb5",
            "Qxb5+",
            "Qd7",
            "Nf6+",
            "Ke7",
            "Nxd7",
            "Nc7",
            "Qc6",
            "Rc8",
            "O-O-O",
            "Kd8",
            "Nxf8",
            "Rxf8",
            "Rxd6+",
            "Ke7",
            "Qd7#",
            "d5",
            "e4",
            "dxe4",
            "fxe4",
            "fxe4",
            "Qxe4+",
            "Kd8",
            "Qf6+",
            "Ke7",
            "Qf7+",
            "Kd8",
            "Qd7#"
          ],
          "plan_execute": [
            "Rxh4",
            "e5",
            "Rh5"
          ]
        },
        "query2": {
          "positional_move": "gxh4",
          "positional_uci": "g5h4",
          "positional_response": "2... gxh4 3. Rxh4 e5 4. Rh5 Nc6 5. Nf3 Nf6 6. Rg5 h6 7. Rf5 d6 8. Rxf6 Qxf6 9. Nc3 Bxg4 10. Nd5 Qd8 11. d4 Bxf3 12. exf3 Nxd4 13. c3 Ne6 14. Qa4+ c6 15. Be3 b5 16. Bxb5 cxb5 17. Qxb5+ Qd7 18. Nf6+ Ke7 19. Nxd7 Bg7 20. O-O-O Rhd8 21. Nxe5 Bxe5 22. Bxh6 Rab8 23. Qa4 Rb7 24. f4 Bf6 25. f5 Nc5 26. Re1+ Be5 27. Qh4+ Kd7 28. Rxe5 Nd3+ 29. Kc2 Nxe5 30. Bg5 Rdb8 31. b3 Rc8 32. Qa4+ Nc6 33. Qe4 Rb5 34. f4 Re8 35. Qc4 Rxf5 36. b4 d5 37. Qd3 Ke6 38. Qe3+ Kd7 39. Qh3 Ke6 40. Qh6+ f6 41. Qg6 Re7 42. Bh4 Rxf4 43. Qg8+ Kd6 44. Bg3 Re2+ 45. Kb3 Ne5 46. Bxf4 Rf2 47. Qd8+ Ke6 48. Qc8+ Kd6 49. Qb8+ Ke6 50. Bxe5 fxe5 51. Qxa7 Rf7 52. Qb6+ Kf5 53. Qf2+ Ke6 54. Qb6+ Kf5 55. Qf2+ Ke6 56. Qb6+ Kf5 57. Qf2+ Ke6 58. Qb6+ Kf5 59. Qf2+ Ke6 60. Qb6+ Kf5 61. Qf2+ Ke6 62. Qb6+ Kf5 63. Qf2+ Ke6 64. Qb6+ Kf5 65. Qf2+ Ke6 66. Qb6+ Kf5 67. Qf2+ Ke6 68. Qb6+ Kf5 69. Qf2+ Ke6 70. Qb6+ Kf5 71. Qf2+ Ke6 72. Qb6+ Kf5 73. Qf2+ Ke6 74",
          "positional_tokens": {
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh4",
            "e5",
            "Rh5",
            "Nc6",
            "Nf3",
            "Nf6",
            "Rg5",
            "h6",
            "Rf5",
            "d6",
            "Rxf6",
            "Qxf6",
            "Nc3",
            "Bxg4",
            "Nd5",
            "Qd8",
            "d4",
            "Bxf3",
            "exf3",
            "Nxd4",
            "c3",
            "Ne6",
            "Qa4+",
            "c6",
            "Be3",
            "b5",
            "Bxb5",
            "cxb5",
            "Qxb5+",
            "Qd7",
            "Nf6+",
            "Ke7",
            "Nxd7",
            "Bg7",
            "O-O-O",
            "Rhd8",
            "Nxe5",
            "Bxe5",
            "Bxh6",
            "Rab8",
            "Qa4",
            "Rb7",
            "f4",
            "Bf6",
            "f5",
            "Nc5",
            "Re1+",
            "Be5",
            "Qh4+",
            "Kd7",
            "Rxe5",
            "Nd3+",
            "Kc2",
            "Nxe5",
            "Bg5",
            "Rdb8",
            "b3",
            "Rc8",
            "Qa4+",
            "Nc6",
            "Qe4",
            "Rb5",
            "f4",
            "Re8",
            "Qc4",
            "Rxf5",
            "b4",
            "d5",
            "Qd3",
            "Ke6",
            "Qe3+",
            "Kd7",
            "Qh3",
            "Ke6",
            "Qh6+",
            "f6",
            "Qg6",
            "Re7",
            "Bh4",
            "Rxf4",
            "Qg8+",
            "Kd6",
            "Bg3",
            "Re2+",
            "Kb3",
            "Ne5",
            "Bxf4",
            "Rf2",
            "Qd8+",
            "Ke6",
            "Qc8+",
            "Kd6",
            "Qb8+",
            "Ke6",
            "Bxe5",
            "fxe5",
            "Qxa7",
            "Rf7",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6",
            "Qb6+",
            "Kf5",
            "Qf2+",
            "Ke6"
          ],
          "plan_execute": [
            "Rxh4",
            "e5",
            "Rh5"
          ]
        },
        "query3": {
          "neutral_move": "gxh4",
          "neutral_uci": "g5h4",
          "neutral_response": "2... gxh4 3. Rxh4 e5 4. Rh5 Nf6 5. Rxe5+ Be7 6. g5 Ng4 7. Re4 d5 8. Rf4 Bxg5 9. Rf3 Nc6 10. d4 Bxc1 11. Qxc1 Nxd4 12. Rf4 c5 13. c3 Ne6 14. Rxg4 h5 15. Rg3 h4 16. Re3 Qg5 17. Nf3 Qf4 18. Bh3 d4 19. cxd4 cxd4 20. Nxd4 Qxd4 21. Nc3 Bd7 22. Rd3 Qg7 23. Qe3 Qg1+ 24. Kd2 Qxa1 25. Nd5 Qxb2+ 26. Ke1 Qb1+ 27. Rd1 Qxa2 28. Nf6+ Ke7 29. Rxd7+ Kxf6 30. Qf3+ Kg5 31. Qf5+ Kh6 32. Qf6+ Kh5 33. Qxf7+ Kh6 34. Qf6+ Kh5 35. Qf5+ Kh6 36. Rd6 Rae8 37. Qf6+ Kh5 38. Qf5+ Kh6 39. Qf6+ Kh5 40. Qf5+ Kh6 41. Qf6+ Kh5 42. Qf5+ Kh6 43. Qf6+ Kh5 44. Qf5+ Kh6 45. Qf6+ Kh5 46. Qf5+ Kh6 47. Qf6+ Kh5 48. Qf5+ Kh6 49. Qf6+ Kh5 50. Qf5+ Kh6 51. Qf6+ Kh5 52. Qf5+ Kh6 53. Qf6+ Kh5 54. Qf5+ Kh6 55. Qf6+ Kh5 56. Qf5+ Kh6 57. Qf6+ Kh5 58. Qf5+ Kh6 59. Qf6+ Kh5 60. Qf5+ Kh6 61. Qf6+ Kh5 62. Qf5+ Kh6 63. Qf6+ Kh5 64. Qf5+ Kh6 65. Qf6+ Kh5 66. Qf5+ Kh6 67. Qf6+ Kh5 68. Qf5+ Kh6 69. Qf6+ Kh5 70. Qf5+ Kh6 71. Qf6+ Kh5 72. Qf5+ Kh6 73. Qf6+ Kh5 74. Qf5+ Kh6 75.",
          "neutral_tokens": {
            "prompt_tokens": 120,
            "completion_tokens": 640,
            "total_tokens": 760,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh4",
            "e5",
            "Rh5",
            "Nf6",
            "Rxe5+",
            "Be7",
            "g5",
            "Ng4",
            "Re4",
            "d5",
            "Rf4",
            "Bxg5",
            "Rf3",
            "Nc6",
            "d4",
            "Bxc1",
            "Qxc1",
            "Nxd4",
            "Rf4",
            "c5",
            "c3",
            "Ne6",
            "Rxg4",
            "h5",
            "Rg3",
            "h4",
            "Re3",
            "Qg5",
            "Nf3",
            "Qf4",
            "Bh3",
            "d4",
            "cxd4",
            "cxd4",
            "Nxd4",
            "Qxd4",
            "Nc3",
            "Bd7",
            "Rd3",
            "Qg7",
            "Qe3",
            "Qg1+",
            "Kd2",
            "Qxa1",
            "Nd5",
            "Qxb2+",
            "Ke1",
            "Qb1+",
            "Rd1",
            "Qxa2",
            "Nf6+",
            "Ke7",
            "Rxd7+",
            "Kxf6",
            "Qf3+",
            "Kg5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qxf7+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Rd6",
            "Rae8",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6"
          ],
          "plan_execute": [
            "Rxh4",
            "e5",
            "Rh5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g5h4",
          "positional_uci": "g5h4",
          "neutral_uci": "g5h4",
          "consensus_move": "g5h4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxh4",
              "e5",
              "Rh5",
              "Nc6",
              "Nf3",
              "Nf6",
              "Rg5",
              "h6",
              "Rf5",
              "d6",
              "Rxf6",
              "Qxf6",
              "Nc3",
              "Bxg4",
              "Nd5",
              "Qd8",
              "d4",
              "Bxf3",
              "exf3",
              "Nxd4",
              "c3",
              "Ne6",
              "Qa4+",
              "c6",
              "Be3",
              "b5",
              "Bxb5",
              "cxb5",
              "Qxb5+",
              "Qd7",
              "Nf6+",
              "Ke7",
              "Nxd7",
              "Nc7",
              "Qc6",
              "Rc8",
              "O-O-O",
              "Kd8",
              "Nxf8",
              "Rxf8",
              "Rxd6+",
              "Ke7",
              "Qd7#",
              "d5",
              "e4",
              "dxe4",
              "fxe4",
              "fxe4",
              "Qxe4+",
              "Kd8",
              "Qf6+",
              "Ke7",
              "Qf7+",
              "Kd8",
              "Qd7#"
            ],
            "execute": [
              "Rxh4",
              "e5",
              "Rh5"
            ]
          },
          "positional": {
            "full": [
              "Rxh4",
              "e5",
              "Rh5",
              "Nc6",
              "Nf3",
              "Nf6",
              "Rg5",
              "h6",
              "Rf5",
              "d6",
              "Rxf6",
              "Qxf6",
              "Nc3",
              "Bxg4",
              "Nd5",
              "Qd8",
              "d4",
              "Bxf3",
              "exf3",
              "Nxd4",
              "c3",
              "Ne6",
              "Qa4+",
              "c6",
              "Be3",
              "b5",
              "Bxb5",
              "cxb5",
              "Qxb5+",
              "Qd7",
              "Nf6+",
              "Ke7",
              "Nxd7",
              "Bg7",
              "O-O-O",
              "Rhd8",
              "Nxe5",
              "Bxe5",
              "Bxh6",
              "Rab8",
              "Qa4",
              "Rb7",
              "f4",
              "Bf6",
              "f5",
              "Nc5",
              "Re1+",
              "Be5",
              "Qh4+",
              "Kd7",
              "Rxe5",
              "Nd3+",
              "Kc2",
              "Nxe5",
              "Bg5",
              "Rdb8",
              "b3",
              "Rc8",
              "Qa4+",
              "Nc6",
              "Qe4",
              "Rb5",
              "f4",
              "Re8",
              "Qc4",
              "Rxf5",
              "b4",
              "d5",
              "Qd3",
              "Ke6",
              "Qe3+",
              "Kd7",
              "Qh3",
              "Ke6",
              "Qh6+",
              "f6",
              "Qg6",
              "Re7",
              "Bh4",
              "Rxf4",
              "Qg8+",
              "Kd6",
              "Bg3",
              "Re2+",
              "Kb3",
              "Ne5",
              "Bxf4",
              "Rf2",
              "Qd8+",
              "Ke6",
              "Qc8+",
              "Kd6",
              "Qb8+",
              "Ke6",
              "Bxe5",
              "fxe5",
              "Qxa7",
              "Rf7",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6",
              "Qb6+",
              "Kf5",
              "Qf2+",
              "Ke6"
            ],
            "execute": [
              "Rxh4",
              "e5",
              "Rh5"
            ]
          },
          "neutral": {
            "full": [
              "Rxh4",
              "e5",
              "Rh5",
              "Nf6",
              "Rxe5+",
              "Be7",
              "g5",
              "Ng4",
              "Re4",
              "d5",
              "Rf4",
              "Bxg5",
              "Rf3",
              "Nc6",
              "d4",
              "Bxc1",
              "Qxc1",
              "Nxd4",
              "Rf4",
              "c5",
              "c3",
              "Ne6",
              "Rxg4",
              "h5",
              "Rg3",
              "h4",
              "Re3",
              "Qg5",
              "Nf3",
              "Qf4",
              "Bh3",
              "d4",
              "cxd4",
              "cxd4",
              "Nxd4",
              "Qxd4",
              "Nc3",
              "Bd7",
              "Rd3",
              "Qg7",
              "Qe3",
              "Qg1+",
              "Kd2",
              "Qxa1",
              "Nd5",
              "Qxb2+",
              "Ke1",
              "Qb1+",
              "Rd1",
              "Qxa2",
              "Nf6+",
              "Ke7",
              "Rxd7+",
              "Kxf6",
              "Qf3+",
              "Kg5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qxf7+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Rd6",
              "Rae8",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh5",
              "Qf5+",
              "Kh6"
            ],
            "execute": [
              "Rxh4",
              "e5",
              "Rh5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Rxh4",
            "e5",
            "Rh5"
          ],
          "full_moves": [
            "Rxh4",
            "e5",
            "Rh5",
            "Nf6",
            "Rxe5+",
            "Be7",
            "g5",
            "Ng4",
            "Re4",
            "d5",
            "Rf4",
            "Bxg5",
            "Rf3",
            "Nc6",
            "d4",
            "Bxc1",
            "Qxc1",
            "Nxd4",
            "Rf4",
            "c5",
            "c3",
            "Ne6",
            "Rxg4",
            "h5",
            "Rg3",
            "h4",
            "Re3",
            "Qg5",
            "Nf3",
            "Qf4",
            "Bh3",
            "d4",
            "cxd4",
            "cxd4",
            "Nxd4",
            "Qxd4",
            "Nc3",
            "Bd7",
            "Rd3",
            "Qg7",
            "Qe3",
            "Qg1+",
            "Kd2",
            "Qxa1",
            "Nd5",
            "Qxb2+",
            "Ke1",
            "Qb1+",
            "Rd1",
            "Qxa2",
            "Nf6+",
            "Ke7",
            "Rxd7+",
            "Kxf6",
            "Qf3+",
            "Kg5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qxf7+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Rd6",
            "Rae8",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh5",
            "Qf5+",
            "Kh6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 121,
            "completion_tokens": 230,
            "total_tokens": 351,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 120,
            "completion_tokens": 640,
            "total_tokens": 760,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 362,
          "total_completion_tokens": 1510,
          "total_tokens": 1872
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 121,
            "completion_tokens": 230,
            "total_tokens": 351,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 120,
            "completion_tokens": 640,
            "total_tokens": 760,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppp1p/8/6p1/6PP/8/PPPPPP2/RNBQKBNR b KQkq - 0 2"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 Nf6\nd4 Nf6 Nf3 d5 Bf4 c5 e3 Nc6 Nbd2 Bf5 c3 e6 Be2 Bd6 Bxd6 Qxd6 O-O O-O Re1 h6 Bf1 Rfd8 Qe2 Rac8 Rad1 a6 dxc5 Qxc5 Nd4 Bg6 Nxc6 Qxc6 Nf3 Bh5 h3 Qa4 a3 e5 g4 Nxg4 hxg4 Qxg4+ Bg2 e4 Nd4 Qg5 Qf1 Rd6 Rd2 Rg6 f4 exf3 Nxf3 Qg3 Rf2 Re8 Ree2 Re4 Nh2 Rh4 Rxf7 Qxh2#\n\nd4 Nf6 Nf3 d5 Bf4 c5 e3 Nc6 Nbd2 Bf5 c3 e6 Be2 Bd6 Bxd6 Qxd6 O-O O-O Re1 h6 Bf1 Rfd8 Qe2 Rac8 Rad1 a6 dxc5 Qxc5 Nd4 Bg6 Nxc6 Qxc6 Nf3 Bh5 h3 Qa4 a3 e5 g4 Nxg4 hxg4 Qxg4+ Bg2 e4 Nd4 Qg5 Qf1 Rd6 Rd2 Rg6 f4 exf3 Nxf3 Qg3 Rf2 Re8 Ree2 Re4 Nh2 Rh4 Rxf7 Qxh2# e4 d5 exd5 Qxd5 Nf3 Nc6 Be2 O-O-O O-O e5 dxe5 Nxe5 Nxe5 Qxe5 Qc2 Bd6 g3 h5 Bf4 Qe6 Bxd6 Rxd6 Rfe1 h4 Bf3 Qh6 Qf5+ Kb8 g4 Rf6 Qe4 c6 Rad1 h3 Rd7 Re6 Qd3 Rhe8 Rxe6 Rxe6 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Qd4+ Kb8 Qd8+ Ka7 Q",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Nf3",
            "d5",
            "Bf4",
            "c5",
            "e3",
            "Nc6",
            "Nbd2",
            "Bf5",
            "c3",
            "e6",
            "Be2",
            "Bd6",
            "Bxd6",
            "Qxd6",
            "O-O",
            "O-O",
            "Re1",
            "h6",
            "Bf1",
            "Rfd8",
            "Qe2",
            "Rac8",
            "Rad1",
            "a6",
            "dxc5",
            "Qxc5",
            "Nd4",
            "Bg6",
            "Nxc6",
            "Qxc6",
            "Nf3",
            "Bh5",
            "h3",
            "Qa4",
            "a3",
            "e5",
            "g4",
            "Nxg4",
            "hxg4",
            "Qxg4+",
            "Bg2",
            "e4",
            "Nd4",
            "Qg5",
            "Qf1",
            "Rd6",
            "Rd2",
            "Rg6",
            "f4",
            "exf3",
            "Nxf3",
            "Qg3",
            "Rf2",
            "Re8",
            "Ree2",
            "Re4",
            "Nh2",
            "Rh4",
            "Rxf7",
            "Qxh2#",
            "e4",
            "d5",
            "exd5",
            "Qxd5",
            "Nf3",
            "Nc6",
            "Be2",
            "O-O-O",
            "O-O",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "Qc2",
            "Bd6",
            "g3",
            "h5",
            "Bf4",
            "Qe6",
            "Bxd6",
            "Rxd6",
            "Rfe1",
            "h4",
            "Bf3",
            "Qh6",
            "Qf5+",
            "Kb8",
            "g4",
            "Rf6",
            "Qe4",
            "c6",
            "Rad1",
            "h3",
            "Rd7",
            "Re6",
            "Qd3",
            "Rhe8",
            "Rxe6",
            "Rxe6",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7",
            "Qd4+",
            "Kb8",
            "Qd8+",
            "Ka7"
          ],
          "plan_execute": [
            "Nf6",
            "Nf3",
            "d5"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nf6 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 Nc6 8. Bxc6 bxc6 9. Bg5 O-O 10. e5 h6 11. Bh4 g5 12. exf6 gxh4 13. Qg4+ Kh8 14. Qg7# 1-0\n\n1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nf6 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 Nc6 8. Bxc6 bxc6 9. Bg5 O-O 10. e5 h6 11. Bh4 g5 12. exf6 gxh4 13. Qg4+ Kh8 14. Qg7# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nf6 Nxe5 Nxe5 d4 Bxd4 Qxd4 Nc6 Bxc6 bxc6 Bg5 O-O e5 h6 Bh4 g5 exf6 gxh4 Qg4+ Kh8 Qg7# 1-0",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 315,
            "total_tokens": 425,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nf6",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "Nc6",
            "Bxc6",
            "bxc6",
            "Bg5",
            "O-O",
            "e5",
            "h6",
            "Bh4",
            "g5",
            "exf6",
            "gxh4",
            "Qg4+",
            "Kh8",
            "Qg7#"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Bd7 19. Qxd6 Rc8 20. Rad1 Kf7 21. Qxd7+ Kxf6 22. Qxc8 Ne5 23. Qf5+ Ke7 24. Qxe5+ Kf7 25. Rd7+ Kg6 26. Rg7+ Kh6 27. Qg5# 1-0\n* 1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Bd7 19. Qxd6 Rc8 20. Rad1 Kf7 21. Qxd7+ Kxf6 22. Qxc8 Ne5 23. Qf5+ Ke7 24. Qxe5+ Kf7 25. Rd7+ Kg6 26. Rg7+ Kh6 27. Qg5# 1-0 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Bg7 Qe6 Nf6+ Qxf6 Bxf6 Bd7 Qxd6 Rc8 Rad1 Kf7 Qxd7+ Kxf6 Qxc8 Ne5 Qf5+ Ke7 Qxe5+ Kf7 Rd7+ Kg6 Rg7+ Kh6 Qg5# 1-0",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 639,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Bd7",
            "Qxd6",
            "Rc8",
            "Rad1",
            "Kf7",
            "Qxd7+",
            "Kxf6",
            "Qxc8",
            "Ne5",
            "Qf5+",
            "Ke7",
            "Qxe5+",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rg7+",
            "Kh6",
            "Qg5#",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Bd7",
            "Qxd6",
            "Rc8",
            "Rad1",
            "Kf7",
            "Qxd7+",
            "Kxf6",
            "Qxc8",
            "Ne5",
            "Qf5+",
            "Ke7",
            "Qxe5+",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rg7+",
            "Kh6",
            "Qg5#"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Nf3",
              "d5",
              "Bf4",
              "c5",
              "e3",
              "Nc6",
              "Nbd2",
              "Bf5",
              "c3",
              "e6",
              "Be2",
              "Bd6",
              "Bxd6",
              "Qxd6",
              "O-O",
              "O-O",
              "Re1",
              "h6",
              "Bf1",
              "Rfd8",
              "Qe2",
              "Rac8",
              "Rad1",
              "a6",
              "dxc5",
              "Qxc5",
              "Nd4",
              "Bg6",
              "Nxc6",
              "Qxc6",
              "Nf3",
              "Bh5",
              "h3",
              "Qa4",
              "a3",
              "e5",
              "g4",
              "Nxg4",
              "hxg4",
              "Qxg4+",
              "Bg2",
              "e4",
              "Nd4",
              "Qg5",
              "Qf1",
              "Rd6",
              "Rd2",
              "Rg6",
              "f4",
              "exf3",
              "Nxf3",
              "Qg3",
              "Rf2",
              "Re8",
              "Ree2",
              "Re4",
              "Nh2",
              "Rh4",
              "Rxf7",
              "Qxh2#",
              "e4",
              "d5",
              "exd5",
              "Qxd5",
              "Nf3",
              "Nc6",
              "Be2",
              "O-O-O",
              "O-O",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "Qc2",
              "Bd6",
              "g3",
              "h5",
              "Bf4",
              "Qe6",
              "Bxd6",
              "Rxd6",
              "Rfe1",
              "h4",
              "Bf3",
              "Qh6",
              "Qf5+",
              "Kb8",
              "g4",
              "Rf6",
              "Qe4",
              "c6",
              "Rad1",
              "h3",
              "Rd7",
              "Re6",
              "Qd3",
              "Rhe8",
              "Rxe6",
              "Rxe6",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7",
              "Qd4+",
              "Kb8",
              "Qd8+",
              "Ka7"
            ],
            "execute": [
              "Nf6",
              "Nf3",
              "d5"
            ]
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nf6",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "Nc6",
              "Bxc6",
              "bxc6",
              "Bg5",
              "O-O",
              "e5",
              "h6",
              "Bh4",
              "g5",
              "exf6",
              "gxh4",
              "Qg4+",
              "Kh8",
              "Qg7#"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Bg7",
              "Qe6",
              "Nf6+",
              "Qxf6",
              "Bxf6",
              "Bd7",
              "Qxd6",
              "Rc8",
              "Rad1",
              "Kf7",
              "Qxd7+",
              "Kxf6",
              "Qxc8",
              "Ne5",
              "Qf5+",
              "Ke7",
              "Qxe5+",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rg7+",
              "Kh6",
              "Qg5#",
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Bg7",
              "Qe6",
              "Nf6+",
              "Qxf6",
              "Bxf6",
              "Bd7",
              "Qxd6",
              "Rc8",
              "Rad1",
              "Kf7",
              "Qxd7+",
              "Kxf6",
              "Qxc8",
              "Ne5",
              "Qf5+",
              "Ke7",
              "Qxe5+",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rg7+",
              "Kh6",
              "Qg5#"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "full_moves": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Bd7",
            "Qxd6",
            "Rc8",
            "Rad1",
            "Kf7",
            "Qxd7+",
            "Kxf6",
            "Qxc8",
            "Ne5",
            "Qf5+",
            "Ke7",
            "Qxe5+",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rg7+",
            "Kh6",
            "Qg5#",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Bg7",
            "Qe6",
            "Nf6+",
            "Qxf6",
            "Bxf6",
            "Bd7",
            "Qxd6",
            "Rc8",
            "Rad1",
            "Kf7",
            "Qxd7+",
            "Kxf6",
            "Qxc8",
            "Ne5",
            "Qf5+",
            "Ke7",
            "Qxe5+",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rg7+",
            "Kh6",
            "Qg5#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 315,
            "total_tokens": 425,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 639,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1594,
          "total_tokens": 1923
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 315,
            "total_tokens": 425,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 639,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb5",
          "aggressive_uci": "f1b5",
          "aggressive_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6 Bc5",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 269,
            "total_tokens": 394,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6",
            "Bc5"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "Bb5",
          "positional_uci": "f1b5",
          "positional_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6 Bc5",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 269,
            "total_tokens": 394,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6",
            "Bc5"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "Bb5",
          "neutral_uci": "f1b5",
          "neutral_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6 Bc5",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 269,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6",
            "Bc5"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1b5",
          "positional_uci": "f1b5",
          "neutral_uci": "f1b5",
          "consensus_move": "f1b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6",
              "Bc5"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6",
              "Bc5"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6",
              "Bc5"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "a6",
            "Ba4",
            "Nf6"
          ],
          "full_moves": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6",
            "Bc5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 269,
            "total_tokens": 394,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 269,
            "total_tokens": 394,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 269,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 807,
          "total_tokens": 1181
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 269,
            "total_tokens": 394,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 269,
            "total_tokens": 394,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 269,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Kf7 39. Bxb5 Bxb5 40. Rxb5 Rc8 41. Rb4 Rc1+ 42. Kh2 Rc2 43. Kg3 Ng6 44. Ne1 Re2 45. Nd3 Rd2 46. Nc5 Nf4 47. Nxa4 Nd3 48. Rb7+ Kg6 49. f3 Nf4 50. Kh2 Rxg2+ 51. Kh1 Rf2 52. Nc3 Rxf3 53. a4 Rxh3+ 54. Kg1 Rg3+ 55. Kf2 Rg2+ 56. Kf3 h5 57. Nd5 Rg4 58. Ne7+ Kg5 59. Nf5 Ne6 60. a5 Rf4+ 61. Ke3 Nc5 62. Rg7# Rg4 63. Rxg4+ hxg4 64. b4 Na6 65. b5 Nc5 66. a6 Nd7 67. a7 Nb6 68. Nd6 Kh4 69. Kf2 Kh3 70. Kg1 g3 71. Nc8 Na8 72. b6 g2 73. b7 Nc7 74. b8=Q Ne6 75. Qb3+ Kg4 76. Qxe6+ Kf4 77. Qf5+ Ke3 78. a8=Q Kd4 79. Qa4+ Kc5 80. Qa5+ Kd4 81. Qd5+ Ke3 82.",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Kf7",
            "Bxb5",
            "Bxb5",
            "Rxb5",
            "Rc8",
            "Rb4",
            "Rc1+",
            "Kh2",
            "Rc2",
            "Kg3",
            "Ng6",
            "Ne1",
            "Re2",
            "Nd3",
            "Rd2",
            "Nc5",
            "Nf4",
            "Nxa4",
            "Nd3",
            "Rb7+",
            "Kg6",
            "f3",
            "Nf4",
            "Kh2",
            "Rxg2+",
            "Kh1",
            "Rf2",
            "Nc3",
            "Rxf3",
            "a4",
            "Rxh3+",
            "Kg1",
            "Rg3+",
            "Kf2",
            "Rg2+",
            "Kf3",
            "h5",
            "Nd5",
            "Rg4",
            "Ne7+",
            "Kg5",
            "Nf5",
            "Ne6",
            "a5",
            "Rf4+",
            "Ke3",
            "Nc5",
            "Rg7#",
            "Rg4",
            "Rxg4+",
            "hxg4",
            "b4",
            "Na6",
            "b5",
            "Nc5",
            "a6",
            "Nd7",
            "a7",
            "Nb6",
            "Nd6",
            "Kh4",
            "Kf2",
            "Kh3",
            "Kg1",
            "g3",
            "Nc8",
            "Na8",
            "b6",
            "g2",
            "b7",
            "Nc7",
            "b8=Q",
            "Ne6",
            "Qb3+",
            "Kg4",
            "Qxe6+",
            "Kf4",
            "Qf5+",
            "Ke3",
            "a8=Q",
            "Kd4",
            "Qa4+",
            "Kc5",
            "Qa5+",
            "Kd4",
            "Qd5+",
            "Ke3"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Kf7 39. Bxb5 Bxb5 40. Rxb5 Rc8 41. Rb4 Rc1+ 42. Kh2 Rc2 43. Kg3 Ng6 44. Ne1 Re2 45. Nd3 Rd2 46. Nc5 Nf4 47. Nxa4 Nd3 48. Rb7+ Kg6 49. f3 Nf4 50. Kh2 Rxg2+ 51. Kh1 Rf2 52. Nc3 Rxf3 53. a4 Rxh3+ 54. Kg1 Rd3 55. a5 Rd6 56. Rb6 Rd7 57. a6 Ra7 58. Nb5 Ra8 59. a7 Nd3 60. Rb8 Rxa7 61. Nxa7 Nc5 62. b4 Nxe4 63. b5 Nd6 64. b6 Kf5 65. Rd8 Nb7 66. Rd7 Nc5 67. Rxh7 Ke6 68. b7 Nxb7 69. Rxb7 Kf5 70. Kf2 Ke4 71. Rb4+ Kf5 72. Kf3 Ke6 73. Rb6+ Kf5 74. Nb5 Kg5 75. Nd6 Kg6 76. Ne4 Kf5 77. Rxf6# e5 d5 Nc6 Nf6",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 598,
            "total_tokens": 739,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Kf7",
            "Bxb5",
            "Bxb5",
            "Rxb5",
            "Rc8",
            "Rb4",
            "Rc1+",
            "Kh2",
            "Rc2",
            "Kg3",
            "Ng6",
            "Ne1",
            "Re2",
            "Nd3",
            "Rd2",
            "Nc5",
            "Nf4",
            "Nxa4",
            "Nd3",
            "Rb7+",
            "Kg6",
            "f3",
            "Nf4",
            "Kh2",
            "Rxg2+",
            "Kh1",
            "Rf2",
            "Nc3",
            "Rxf3",
            "a4",
            "Rxh3+",
            "Kg1",
            "Rd3",
            "a5",
            "Rd6",
            "Rb6",
            "Rd7",
            "a6",
            "Ra7",
            "Nb5",
            "Ra8",
            "a7",
            "Nd3",
            "Rb8",
            "Rxa7",
            "Nxa7",
            "Nc5",
            "b4",
            "Nxe4",
            "b5",
            "Nd6",
            "b6",
            "Kf5",
            "Rd8",
            "Nb7",
            "Rd7",
            "Nc5",
            "Rxh7",
            "Ke6",
            "b7",
            "Nxb7",
            "Rxb7",
            "Kf5",
            "Kf2",
            "Ke4",
            "Rb4+",
            "Kf5",
            "Kf3",
            "Ke6",
            "Rb6+",
            "Kf5",
            "Nb5",
            "Kg5",
            "Nd6",
            "Kg6",
            "Ne4",
            "Kf5",
            "Rxf6#",
            "e5",
            "d5",
            "Nc6",
            "Nf6"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6 43. Nd2 Kc5 44. a3 Bd7 45. Nb1 Nc6 46. Nc3 Nd4 47. Nd5 f5 48. Nf6 f4+ 49. Kd2 Be6 50. Nxh7 b4 51. Ng5 Bg8 52. h4 bxa3 53. bxa3 Nb3+ 54. Kc3 Nd4 55. h5 Nb5+ 56. Bxb5 Kxb5 57. h6 Kc5 58. h7 Bxh7 59. Nxh7 Kd6 60. Ng5 Ke7 61. Nf3 Kf6 62. Kb4 Ke6 63. Kxa4 Kd6 64. Kb4 Ke6 65. a4 Kd6 66. a5 Ke6 67. a6 Kd6 68. a7 Ke6 69. a8=Q Kd6 70. Qd5+ Ke7 71. Qxe5+ Kd7 72. Qxf4 Ke6 73. Qf5+ Kd6 74. Qd5+ Ke7 75. Qc6 Kf7 76. Kc5 Ke7 77. Kd5 Kf7 78. Ke5 Ke7 79. Qc7+ Kf8 80. Kf6 Kg8 81. Qg7# e4 Nf3 Nc",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Nc6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "Kd2",
            "Be6",
            "Nxh7",
            "b4",
            "Ng5",
            "Bg8",
            "h4",
            "bxa3",
            "bxa3",
            "Nb3+",
            "Kc3",
            "Nd4",
            "h5",
            "Nb5+",
            "Bxb5",
            "Kxb5",
            "h6",
            "Kc5",
            "h7",
            "Bxh7",
            "Nxh7",
            "Kd6",
            "Ng5",
            "Ke7",
            "Nf3",
            "Kf6",
            "Kb4",
            "Ke6",
            "Kxa4",
            "Kd6",
            "Kb4",
            "Ke6",
            "a4",
            "Kd6",
            "a5",
            "Ke6",
            "a6",
            "Kd6",
            "a7",
            "Ke6",
            "a8=Q",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qxe5+",
            "Kd7",
            "Qxf4",
            "Ke6",
            "Qf5+",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qc6",
            "Kf7",
            "Kc5",
            "Ke7",
            "Kd5",
            "Kf7",
            "Ke5",
            "Ke7",
            "Qc7+",
            "Kf8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "e4",
            "Nf3"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Kf7",
              "Bxb5",
              "Bxb5",
              "Rxb5",
              "Rc8",
              "Rb4",
              "Rc1+",
              "Kh2",
              "Rc2",
              "Kg3",
              "Ng6",
              "Ne1",
              "Re2",
              "Nd3",
              "Rd2",
              "Nc5",
              "Nf4",
              "Nxa4",
              "Nd3",
              "Rb7+",
              "Kg6",
              "f3",
              "Nf4",
              "Kh2",
              "Rxg2+",
              "Kh1",
              "Rf2",
              "Nc3",
              "Rxf3",
              "a4",
              "Rxh3+",
              "Kg1",
              "Rg3+",
              "Kf2",
              "Rg2+",
              "Kf3",
              "h5",
              "Nd5",
              "Rg4",
              "Ne7+",
              "Kg5",
              "Nf5",
              "Ne6",
              "a5",
              "Rf4+",
              "Ke3",
              "Nc5",
              "Rg7#",
              "Rg4",
              "Rxg4+",
              "hxg4",
              "b4",
              "Na6",
              "b5",
              "Nc5",
              "a6",
              "Nd7",
              "a7",
              "Nb6",
              "Nd6",
              "Kh4",
              "Kf2",
              "Kh3",
              "Kg1",
              "g3",
              "Nc8",
              "Na8",
              "b6",
              "g2",
              "b7",
              "Nc7",
              "b8=Q",
              "Ne6",
              "Qb3+",
              "Kg4",
              "Qxe6+",
              "Kf4",
              "Qf5+",
              "Ke3",
              "a8=Q",
              "Kd4",
              "Qa4+",
              "Kc5",
              "Qa5+",
              "Kd4",
              "Qd5+",
              "Ke3"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          },
          "positional": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Kf7",
              "Bxb5",
              "Bxb5",
              "Rxb5",
              "Rc8",
              "Rb4",
              "Rc1+",
              "Kh2",
              "Rc2",
              "Kg3",
              "Ng6",
              "Ne1",
              "Re2",
              "Nd3",
              "Rd2",
              "Nc5",
              "Nf4",
              "Nxa4",
              "Nd3",
              "Rb7+",
              "Kg6",
              "f3",
              "Nf4",
              "Kh2",
              "Rxg2+",
              "Kh1",
              "Rf2",
              "Nc3",
              "Rxf3",
              "a4",
              "Rxh3+",
              "Kg1",
              "Rd3",
              "a5",
              "Rd6",
              "Rb6",
              "Rd7",
              "a6",
              "Ra7",
              "Nb5",
              "Ra8",
              "a7",
              "Nd3",
              "Rb8",
              "Rxa7",
              "Nxa7",
              "Nc5",
              "b4",
              "Nxe4",
              "b5",
              "Nd6",
              "b6",
              "Kf5",
              "Rd8",
              "Nb7",
              "Rd7",
              "Nc5",
              "Rxh7",
              "Ke6",
              "b7",
              "Nxb7",
              "Rxb7",
              "Kf5",
              "Kf2",
              "Ke4",
              "Rb4+",
              "Kf5",
              "Kf3",
              "Ke6",
              "Rb6+",
              "Kf5",
              "Nb5",
              "Kg5",
              "Nd6",
              "Kg6",
              "Ne4",
              "Kf5",
              "Rxf6#",
              "e5",
              "d5",
              "Nc6",
              "Nf6"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          },
          "neutral": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Bd7",
              "Nb1",
              "Nc6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "f4+",
              "Kd2",
              "Be6",
              "Nxh7",
              "b4",
              "Ng5",
              "Bg8",
              "h4",
              "bxa3",
              "bxa3",
              "Nb3+",
              "Kc3",
              "Nd4",
              "h5",
              "Nb5+",
              "Bxb5",
              "Kxb5",
              "h6",
              "Kc5",
              "h7",
              "Bxh7",
              "Nxh7",
              "Kd6",
              "Ng5",
              "Ke7",
              "Nf3",
              "Kf6",
              "Kb4",
              "Ke6",
              "Kxa4",
              "Kd6",
              "Kb4",
              "Ke6",
              "a4",
              "Kd6",
              "a5",
              "Ke6",
              "a6",
              "Kd6",
              "a7",
              "Ke6",
              "a8=Q",
              "Kd6",
              "Qd5+",
              "Ke7",
              "Qxe5+",
              "Kd7",
              "Qxf4",
              "Ke6",
              "Qf5+",
              "Kd6",
              "Qd5+",
              "Ke7",
              "Qc6",
              "Kf7",
              "Kc5",
              "Ke7",
              "Kd5",
              "Kf7",
              "Ke5",
              "Ke7",
              "Qc7+",
              "Kf8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "e4",
              "Nf3"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "h3",
            "Na5",
            "Bc2"
          ],
          "full_moves": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Nc6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "Kd2",
            "Be6",
            "Nxh7",
            "b4",
            "Ng5",
            "Bg8",
            "h4",
            "bxa3",
            "bxa3",
            "Nb3+",
            "Kc3",
            "Nd4",
            "h5",
            "Nb5+",
            "Bxb5",
            "Kxb5",
            "h6",
            "Kc5",
            "h7",
            "Bxh7",
            "Nxh7",
            "Kd6",
            "Ng5",
            "Ke7",
            "Nf3",
            "Kf6",
            "Kb4",
            "Ke6",
            "Kxa4",
            "Kd6",
            "Kb4",
            "Ke6",
            "a4",
            "Kd6",
            "a5",
            "Ke6",
            "a6",
            "Kd6",
            "a7",
            "Ke6",
            "a8=Q",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qxe5+",
            "Kd7",
            "Qxf4",
            "Ke6",
            "Qf5+",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qc6",
            "Kf7",
            "Kc5",
            "Ke7",
            "Kd5",
            "Kf7",
            "Ke5",
            "Ke7",
            "Qc7+",
            "Kf8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "e4",
            "Nf3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 598,
            "total_tokens": 739,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 1878,
          "total_tokens": 2300
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 598,
            "total_tokens": 739,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 640,
            "total_tokens": 780,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re1",
          "aggressive_uci": "f1e1",
          "aggressive_response": "6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6+ Bc7",
          "aggressive_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 247,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6+",
            "Bc7"
          ],
          "plan_execute": [
            "Qh4",
            "g3",
            "Qh3"
          ]
        },
        "query2": {
          "positional_move": "Re1",
          "positional_uci": "f1e1",
          "positional_response": "6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Ra6 Bf8 24. Rxc6 Bh3 25. Qh1 Rxc6 26. Qxc6 Re6 27. Qf3 Bg4 28. Qg2 Bh3 29. Qf3 Bg4 30. Qa8 g5 31. Ra1 Rh6 32. h4 gxh4 33. Bxh6 Qxh6 34. Nf1 h3 35. Nh2 Be6 36. Qe4 Qd2 37. Nf3 Qxb2 38. Ra8 Qxc3 39. Ng5 Qc1+ 40. Kh2 Qxg5 41. Qe5 Qxe5 42. dxe5 b4 43. Rb8 b3 44. f4 Kg7 45. g4 Bxg4 46. Rxb3 Kg6 47. Kg3 h5 48. Rb6+ Kf5 49. Rf6+ Ke4 50. Rxf7 Bb4 51. Rb7 Be1+ 52. Kh2 Kxf4 53. Rb5 Bg3+ 54. Kg1 h2+ 55. Kg2 Bf3+ 56. Kh3 h1=Q# Bb4+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+ Ke3 Bc5+ Kf4 Bc5+",
          "positional_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Ra6",
            "Bf8",
            "Rxc6",
            "Bh3",
            "Qh1",
            "Rxc6",
            "Qxc6",
            "Re6",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qa8",
            "g5",
            "Ra1",
            "Rh6",
            "h4",
            "gxh4",
            "Bxh6",
            "Qxh6",
            "Nf1",
            "h3",
            "Nh2",
            "Be6",
            "Qe4",
            "Qd2",
            "Nf3",
            "Qxb2",
            "Ra8",
            "Qxc3",
            "Ng5",
            "Qc1+",
            "Kh2",
            "Qxg5",
            "Qe5",
            "Qxe5",
            "dxe5",
            "b4",
            "Rb8",
            "b3",
            "f4",
            "Kg7",
            "g4",
            "Bxg4",
            "Rxb3",
            "Kg6",
            "Kg3",
            "h5",
            "Rb6+",
            "Kf5",
            "Rf6+",
            "Ke4",
            "Rxf7",
            "Bb4",
            "Rb7",
            "Be1+",
            "Kh2",
            "Kxf4",
            "Rb5",
            "Bg3+",
            "Kg1",
            "h2+",
            "Kg2",
            "Bf3+",
            "Kh3",
            "h1=Q#",
            "Bb4+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+",
            "Ke3",
            "Bc5+",
            "Kf4",
            "Bc5+"
          ],
          "plan_execute": [
            "Qh4",
            "g3",
            "Qh3"
          ]
        },
        "query3": {
          "neutral_move": "Re1",
          "neutral_uci": "f1e1",
          "neutral_response": "6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bc7 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qf3 Bg4 26. Qh1 Bb8 27. Rc5 f5 28. Qd5 Kh8 29. Rxb5 h6 30. Ra1 Qh3 31. Ra8 f4 32. Rbxb8 fxe3 33. Rxe8+ Kh7 34. Rxe6 exd2 35. Qe4+ Bf5 36. Qe2 Bxe6 37. Qxd2 Bd5 38. Qd3+ g6 39. Ra7+ Kh8 40. Qf1 Qf5 41. Re7 Qf3 42. Re8+ Kg7 43. Re7+ Kf8 44. Re8+ Kxe8 45. Qe1+ Kf7 46. Kf1 Bc4+ 47. Kg1 Bd5 48. Kf1 Qh1+ 49. Ke2 Qe4+ 50. Kd2 Qxe1+ 51. Kxe1 Ke6 52. Kd2 Kf5 53. Ke3 Kg4 54. b4 Kh3 55. b5 Kxh2 56. b6 Kg2 57. c4 Bb7 58. d5 h5 59. d6 Bc6 60. b7 Bxb7 61. d7 g5 62. d8=Q h4 63. Qxg5 h3 64. Qh4 h2 65. Qxh2+ Kxh2 66. g4 Kh3 67. g5 Kh4 68. g6 Kh5 69. g7 Kh6 70. g8=Q Kh5 71. Qg3 Kh6 72. Kf4 Kh7 73. Kf5 Kh8 74. Kf6 Kh7 75. Qg7# e4 e5 Nf6 Nc6 Bb5 a6 Ba4 Nf6 Be7 O-O O-O c3 d5 exd5 Nxd5 Nxe5 Nxe5 Rxe5 c6 Bd6 Bd6 Qh5 g6 Qh3 Q",
          "neutral_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qh1",
            "Bb8",
            "Rc5",
            "f5",
            "Qd5",
            "Kh8",
            "Rxb5",
            "h6",
            "Ra1",
            "Qh3",
            "Ra8",
            "f4",
            "Rbxb8",
            "fxe3",
            "Rxe8+",
            "Kh7",
            "Rxe6",
            "exd2",
            "Qe4+",
            "Bf5",
            "Qe2",
            "Bxe6",
            "Qxd2",
            "Bd5",
            "Qd3+",
            "g6",
            "Ra7+",
            "Kh8",
            "Qf1",
            "Qf5",
            "Re7",
            "Qf3",
            "Re8+",
            "Kg7",
            "Re7+",
            "Kf8",
            "Re8+",
            "Kxe8",
            "Qe1+",
            "Kf7",
            "Kf1",
            "Bc4+",
            "Kg1",
            "Bd5",
            "Kf1",
            "Qh1+",
            "Ke2",
            "Qe4+",
            "Kd2",
            "Qxe1+",
            "Kxe1",
            "Ke6",
            "Kd2",
            "Kf5",
            "Ke3",
            "Kg4",
            "b4",
            "Kh3",
            "b5",
            "Kxh2",
            "b6",
            "Kg2",
            "c4",
            "Bb7",
            "d5",
            "h5",
            "d6",
            "Bc6",
            "b7",
            "Bxb7",
            "d7",
            "g5",
            "d8=Q",
            "h4",
            "Qxg5",
            "h3",
            "Qh4",
            "h2",
            "Qxh2+",
            "Kxh2",
            "g4",
            "Kh3",
            "g5",
            "Kh4",
            "g6",
            "Kh5",
            "g7",
            "Kh6",
            "g8=Q",
            "Kh5",
            "Qg3",
            "Kh6",
            "Kf4",
            "Kh7",
            "Kf5",
            "Kh8",
            "Kf6",
            "Kh7",
            "Qg7#",
            "e4",
            "e5",
            "Nf6",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "Be7",
            "O-O",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "Bd6",
            "Bd6",
            "Qh5",
            "g6",
            "Qh3"
          ],
          "plan_execute": [
            "Qh4",
            "g3",
            "Qh3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1e1",
          "positional_uci": "f1e1",
          "neutral_uci": "f1e1",
          "consensus_move": "f1e1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6+",
              "Bc7"
            ],
            "execute": [
              "Qh4",
              "g3",
              "Qh3"
            ]
          },
          "positional": {
            "full": [
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Ra6",
              "Bf8",
              "Rxc6",
              "Bh3",
              "Qh1",
              "Rxc6",
              "Qxc6",
              "Re6",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qa8",
              "g5",
              "Ra1",
              "Rh6",
              "h4",
              "gxh4",
              "Bxh6",
              "Qxh6",
              "Nf1",
              "h3",
              "Nh2",
              "Be6",
              "Qe4",
              "Qd2",
              "Nf3",
              "Qxb2",
              "Ra8",
              "Qxc3",
              "Ng5",
              "Qc1+",
              "Kh2",
              "Qxg5",
              "Qe5",
              "Qxe5",
              "dxe5",
              "b4",
              "Rb8",
              "b3",
              "f4",
              "Kg7",
              "g4",
              "Bxg4",
              "Rxb3",
              "Kg6",
              "Kg3",
              "h5",
              "Rb6+",
              "Kf5",
              "Rf6+",
              "Ke4",
              "Rxf7",
              "Bb4",
              "Rb7",
              "Be1+",
              "Kh2",
              "Kxf4",
              "Rb5",
              "Bg3+",
              "Kg1",
              "h2+",
              "Kg2",
              "Bf3+",
              "Kh3",
              "h1=Q#",
              "Bb4+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+",
              "Ke3",
              "Bc5+",
              "Kf4",
              "Bc5+"
            ],
            "execute": [
              "Qh4",
              "g3",
              "Qh3"
            ]
          },
          "neutral": {
            "full": [
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qh1",
              "Bb8",
              "Rc5",
              "f5",
              "Qd5",
              "Kh8",
              "Rxb5",
              "h6",
              "Ra1",
              "Qh3",
              "Ra8",
              "f4",
              "Rbxb8",
              "fxe3",
              "Rxe8+",
              "Kh7",
              "Rxe6",
              "exd2",
              "Qe4+",
              "Bf5",
              "Qe2",
              "Bxe6",
              "Qxd2",
              "Bd5",
              "Qd3+",
              "g6",
              "Ra7+",
              "Kh8",
              "Qf1",
              "Qf5",
              "Re7",
              "Qf3",
              "Re8+",
              "Kg7",
              "Re7+",
              "Kf8",
              "Re8+",
              "Kxe8",
              "Qe1+",
              "Kf7",
              "Kf1",
              "Bc4+",
              "Kg1",
              "Bd5",
              "Kf1",
              "Qh1+",
              "Ke2",
              "Qe4+",
              "Kd2",
              "Qxe1+",
              "Kxe1",
              "Ke6",
              "Kd2",
              "Kf5",
              "Ke3",
              "Kg4",
              "b4",
              "Kh3",
              "b5",
              "Kxh2",
              "b6",
              "Kg2",
              "c4",
              "Bb7",
              "d5",
              "h5",
              "d6",
              "Bc6",
              "b7",
              "Bxb7",
              "d7",
              "g5",
              "d8=Q",
              "h4",
              "Qxg5",
              "h3",
              "Qh4",
              "h2",
              "Qxh2+",
              "Kxh2",
              "g4",
              "Kh3",
              "g5",
              "Kh4",
              "g6",
              "Kh5",
              "g7",
              "Kh6",
              "g8=Q",
              "Kh5",
              "Qg3",
              "Kh6",
              "Kf4",
              "Kh7",
              "Kf5",
              "Kh8",
              "Kf6",
              "Kh7",
              "Qg7#",
              "e4",
              "e5",
              "Nf6",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "Be7",
              "O-O",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "Bd6",
              "Bd6",
              "Qh5",
              "g6",
              "Qh3"
            ],
            "execute": [
              "Qh4",
              "g3",
              "Qh3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Qh4",
            "g3",
            "Qh3"
          ],
          "full_moves": [
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qh1",
            "Bb8",
            "Rc5",
            "f5",
            "Qd5",
            "Kh8",
            "Rxb5",
            "h6",
            "Ra1",
            "Qh3",
            "Ra8",
            "f4",
            "Rbxb8",
            "fxe3",
            "Rxe8+",
            "Kh7",
            "Rxe6",
            "exd2",
            "Qe4+",
            "Bf5",
            "Qe2",
            "Bxe6",
            "Qxd2",
            "Bd5",
            "Qd3+",
            "g6",
            "Ra7+",
            "Kh8",
            "Qf1",
            "Qf5",
            "Re7",
            "Qf3",
            "Re8+",
            "Kg7",
            "Re7+",
            "Kf8",
            "Re8+",
            "Kxe8",
            "Qe1+",
            "Kf7",
            "Kf1",
            "Bc4+",
            "Kg1",
            "Bd5",
            "Kf1",
            "Qh1+",
            "Ke2",
            "Qe4+",
            "Kd2",
            "Qxe1+",
            "Kxe1",
            "Ke6",
            "Kd2",
            "Kf5",
            "Ke3",
            "Kg4",
            "b4",
            "Kh3",
            "b5",
            "Kxh2",
            "b6",
            "Kg2",
            "c4",
            "Bb7",
            "d5",
            "h5",
            "d6",
            "Bc6",
            "b7",
            "Bxb7",
            "d7",
            "g5",
            "d8=Q",
            "h4",
            "Qxg5",
            "h3",
            "Qh4",
            "h2",
            "Qxh2+",
            "Kxh2",
            "g4",
            "Kh3",
            "g5",
            "Kh4",
            "g6",
            "Kh5",
            "g7",
            "Kh6",
            "g8=Q",
            "Kh5",
            "Qg3",
            "Kh6",
            "Kf4",
            "Kh7",
            "Kf5",
            "Kh8",
            "Kf6",
            "Kh7",
            "Qg7#",
            "e4",
            "e5",
            "Nf6",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "Be7",
            "O-O",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "Bd6",
            "Bd6",
            "Qh5",
            "g6",
            "Qh3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 148,
            "completion_tokens": 247,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 443,
          "total_completion_tokens": 1527,
          "total_tokens": 1970
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 148,
            "completion_tokens": 247,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 148,
            "completion_tokens": 640,
            "total_tokens": 788,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 147,
            "completion_tokens": 640,
            "total_tokens": 787,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 w kq - 4 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb3",
          "aggressive_uci": "a4b3",
          "aggressive_response": "7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Bf3 29. Rxb8+ Re8 30. Rxe8# dxe1=Q 31. Qxf3 Qxf3# dxe1=Q 32. Qxf3 Qxf1# dxe1=Q 33. Qxf3 Qxf1# dxe1=Q",
          "aggressive_tokens": {
            "prompt_tokens": 155,
            "completion_tokens": 251,
            "total_tokens": 406,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "dxe1=Q",
            "Qxf3",
            "Qxf3#",
            "dxe1=Q",
            "Qxf3",
            "Qxf1#",
            "dxe1=Q",
            "Qxf3",
            "Qxf1#",
            "dxe1=Q"
          ],
          "plan_execute": [
            "O-O",
            "c3",
            "d5"
          ]
        },
        "query2": {
          "positional_move": "Bb3",
          "positional_uci": "a4b3",
          "positional_response": "7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# d4 e6 dxe5 Nxe5",
          "positional_tokens": {
            "prompt_tokens": 155,
            "completion_tokens": 236,
            "total_tokens": 391,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "d4",
            "e6",
            "dxe5",
            "Nxe5"
          ],
          "plan_execute": [
            "O-O",
            "c3",
            "d5"
          ]
        },
        "query3": {
          "neutral_move": "Bb3",
          "neutral_uci": "a4b3",
          "neutral_response": "7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Bf3 29. Rxb8+ Re8 30. Rxe8# e5 dxe5 Qxg2#",
          "neutral_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 211,
            "total_tokens": 365,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "e5",
            "dxe5",
            "Qxg2#"
          ],
          "plan_execute": [
            "O-O",
            "c3",
            "d5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a4b3",
          "positional_uci": "a4b3",
          "neutral_uci": "a4b3",
          "consensus_move": "a4b3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "dxe1=Q",
              "Qxf3",
              "Qxf3#",
              "dxe1=Q",
              "Qxf3",
              "Qxf1#",
              "dxe1=Q",
              "Qxf3",
              "Qxf1#",
              "dxe1=Q"
            ],
            "execute": [
              "O-O",
              "c3",
              "d5"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "d4",
              "e6",
              "dxe5",
              "Nxe5"
            ],
            "execute": [
              "O-O",
              "c3",
              "d5"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "e5",
              "dxe5",
              "Qxg2#"
            ],
            "execute": [
              "O-O",
              "c3",
              "d5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "c3",
            "d5"
          ],
          "full_moves": [
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "e5",
            "dxe5",
            "Qxg2#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 155,
            "completion_tokens": 251,
            "total_tokens": 406,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 155,
            "completion_tokens": 236,
            "total_tokens": 391,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 154,
            "completion_tokens": 211,
            "total_tokens": 365,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 464,
          "total_completion_tokens": 698,
          "total_tokens": 1162
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 155,
            "completion_tokens": 251,
            "total_tokens": 406,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 155,
            "completion_tokens": 236,
            "total_tokens": 391,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 154,
            "completion_tokens": 211,
            "total_tokens": 365,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2ppbppp/p1n2n2/1p2p3/B3P3/5N2/PPPP1PPP/RNBQR1K1 w kq - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c3",
          "aggressive_uci": "c2c3",
          "aggressive_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rad8 25. Bg5 Ne7 26. Bxf6 gxf6 27. Qh6 Ng6 28. Nh5 Re6 29. Qg7# e4 Nf8 Ng5+ Kh8 Nxf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8 Nf6+ Kg8 Nxe8+ Rxe8",
          "aggressive_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rad8",
            "Bg5",
            "Ne7",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Ng6",
            "Nh5",
            "Re6",
            "Qg7#",
            "e4",
            "Nf8",
            "Ng5+",
            "Kh8",
            "Nxf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8",
            "Nf6+",
            "Kg8",
            "Nxe8+",
            "Rxe8"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "query2": {
          "positional_move": "c3",
          "positional_uci": "c2c3",
          "positional_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6 43. Nd2 Kc5 44. a3 Ng6 45. g3 Bd7 46. h4 Nf8 47. Nb1 Ne6 48. Nc3 Nd4 49. Nd5 f5 50. Nf6 f4+ 51. gxf4 exf4+ 52. Kxf4 Be6 53. Nxh7 Bc4 54. Bxc4 bxc4 55. Nf6 Ne2+ 56. Ke3 Nc1 57. h5 Nd3 58. h6 Nxb2 59. h7 c3 60. h8=Q Nc4+ 61. Kd3 Nxa3 62. Qc8+ Kb4 63. Qxc3+ Kb5 64. Qxa3 Ka5 65. Nd5 Kb5 66. Qb4+ Kc6 67. Qxa4+ Kd6 68. Qa6+ Ke5 69. f4# e4+ Nxe4 Qd4# e5 Qd5# e6 Qd6# e7 Qd7#",
          "positional_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 541,
            "total_tokens": 704,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h8=Q",
            "Nc4+",
            "Kd3",
            "Nxa3",
            "Qc8+",
            "Kb4",
            "Qxc3+",
            "Kb5",
            "Qxa3",
            "Ka5",
            "Nd5",
            "Kb5",
            "Qb4+",
            "Kc6",
            "Qxa4+",
            "Kd6",
            "Qa6+",
            "Ke5",
            "f4#",
            "e4+",
            "Nxe4",
            "Qd4#",
            "e5",
            "Qd5#",
            "e6",
            "Qd6#",
            "e7",
            "Qd7#"
          ],
          "plan_execute": [
            "h8=Q",
            "Nc4+",
            "Kd3"
          ]
        },
        "query3": {
          "neutral_move": "c3",
          "neutral_uci": "c2c3",
          "neutral_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Qa6 25. Bg5 Qa5 26. Qd1 Nxd4 27. Nxd4 exd4 28. Bxf6 gxf6 29. Nh5 Re6 30. Rf1 Kh8 31. Qxd4 b4 32. Nxf6 Qe5 33. Qxe5 dxe5 34. Nxd7 Rd8 35. Nc5 Rc6 36. Nxa4 Rd2 37. b3 Kg7 38. g3 Kf6 39. Kg2 Ke7 40. Kf3 Rf6+ 41. Ke3 Rfd6 42. Rc1 Rd1 43. Rxd1 Rxd1 44. Bd3 Ra1 45. Nb6 Rxa2 46. Nd5+ Kd6 47. Nxb4 Rb2 48. Bc4 f6 49. Nd3 Rb1 50. f4 Rh1 51. h4 Rg1 52. Kf2 Rd1 53. fxe5+ fxe5 54. Ke2 Rg1 55. Kf3 Rd1 56. Kg4 Rg1 57. Nf2 Rg2 58. Kf3 Rg1 59. Ng4 h5 60. Nf6 Ke7 61. Nxh5 Kf8 62. Kg4 Re1 63. Bd5 Rf1 64. Kg5 Ke7 65. g4 Kd6 66. Ng7 Kc5 67. h5 Kd4 68. h6 Rh1 69. Nh5 Ra1 70. h7 Ra8 71. Bxa8 Ke3 72. h8=Q Kd4 73. Qd8+ Ke3 74. Qd5 Kf3 75. Qd3+ Kf2 76. Ng3 Kg2 77. Qe2+ Kxg3 78. Qe3+ Kg2 79. Kh4 Kf1 80. Qd2 Kg1 81. Kg3 Kf1 82. Qf2# e4 d5 Nf6+ Kg7 Nxe4+ Kf8 Nf6+ Kg7 Nxe4+",
          "neutral_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 640,
            "total_tokens": 802,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Qa6",
            "Bg5",
            "Qa5",
            "Qd1",
            "Nxd4",
            "Nxd4",
            "exd4",
            "Bxf6",
            "gxf6",
            "Nh5",
            "Re6",
            "Rf1",
            "Kh8",
            "Qxd4",
            "b4",
            "Nxf6",
            "Qe5",
            "Qxe5",
            "dxe5",
            "Nxd7",
            "Rd8",
            "Nc5",
            "Rc6",
            "Nxa4",
            "Rd2",
            "b3",
            "Kg7",
            "g3",
            "Kf6",
            "Kg2",
            "Ke7",
            "Kf3",
            "Rf6+",
            "Ke3",
            "Rfd6",
            "Rc1",
            "Rd1",
            "Rxd1",
            "Rxd1",
            "Bd3",
            "Ra1",
            "Nb6",
            "Rxa2",
            "Nd5+",
            "Kd6",
            "Nxb4",
            "Rb2",
            "Bc4",
            "f6",
            "Nd3",
            "Rb1",
            "f4",
            "Rh1",
            "h4",
            "Rg1",
            "Kf2",
            "Rd1",
            "fxe5+",
            "fxe5",
            "Ke2",
            "Rg1",
            "Kf3",
            "Rd1",
            "Kg4",
            "Rg1",
            "Nf2",
            "Rg2",
            "Kf3",
            "Rg1",
            "Ng4",
            "h5",
            "Nf6",
            "Ke7",
            "Nxh5",
            "Kf8",
            "Kg4",
            "Re1",
            "Bd5",
            "Rf1",
            "Kg5",
            "Ke7",
            "g4",
            "Kd6",
            "Ng7",
            "Kc5",
            "h5",
            "Kd4",
            "h6",
            "Rh1",
            "Nh5",
            "Ra1",
            "h7",
            "Ra8",
            "Bxa8",
            "Ke3",
            "h8=Q",
            "Kd4",
            "Qd8+",
            "Ke3",
            "Qd5",
            "Kf3",
            "Qd3+",
            "Kf2",
            "Ng3",
            "Kg2",
            "Qe2+",
            "Kxg3",
            "Qe3+",
            "Kg2",
            "Kh4",
            "Kf1",
            "Qd2",
            "Kg1",
            "Kg3",
            "Kf1",
            "Qf2#",
            "e4",
            "d5",
            "Nf6+",
            "Kg7",
            "Nxe4+",
            "Kf8",
            "Nf6+",
            "Kg7",
            "Nxe4+"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c2c3",
          "positional_uci": "c2c3",
          "neutral_uci": "c2c3",
          "consensus_move": "c2c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rad8",
              "Bg5",
              "Ne7",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Ng6",
              "Nh5",
              "Re6",
              "Qg7#",
              "e4",
              "Nf8",
              "Ng5+",
              "Kh8",
              "Nxf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8",
              "Nf6+",
              "Kg8",
              "Nxe8+",
              "Rxe8"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          },
          "positional": {
            "full": [
              "h8=Q",
              "Nc4+",
              "Kd3",
              "Nxa3",
              "Qc8+",
              "Kb4",
              "Qxc3+",
              "Kb5",
              "Qxa3",
              "Ka5",
              "Nd5",
              "Kb5",
              "Qb4+",
              "Kc6",
              "Qxa4+",
              "Kd6",
              "Qa6+",
              "Ke5",
              "f4#",
              "e4+",
              "Nxe4",
              "Qd4#",
              "e5",
              "Qd5#",
              "e6",
              "Qd6#",
              "e7",
              "Qd7#"
            ],
            "execute": [
              "h8=Q",
              "Nc4+",
              "Kd3"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Qa6",
              "Bg5",
              "Qa5",
              "Qd1",
              "Nxd4",
              "Nxd4",
              "exd4",
              "Bxf6",
              "gxf6",
              "Nh5",
              "Re6",
              "Rf1",
              "Kh8",
              "Qxd4",
              "b4",
              "Nxf6",
              "Qe5",
              "Qxe5",
              "dxe5",
              "Nxd7",
              "Rd8",
              "Nc5",
              "Rc6",
              "Nxa4",
              "Rd2",
              "b3",
              "Kg7",
              "g3",
              "Kf6",
              "Kg2",
              "Ke7",
              "Kf3",
              "Rf6+",
              "Ke3",
              "Rfd6",
              "Rc1",
              "Rd1",
              "Rxd1",
              "Rxd1",
              "Bd3",
              "Ra1",
              "Nb6",
              "Rxa2",
              "Nd5+",
              "Kd6",
              "Nxb4",
              "Rb2",
              "Bc4",
              "f6",
              "Nd3",
              "Rb1",
              "f4",
              "Rh1",
              "h4",
              "Rg1",
              "Kf2",
              "Rd1",
              "fxe5+",
              "fxe5",
              "Ke2",
              "Rg1",
              "Kf3",
              "Rd1",
              "Kg4",
              "Rg1",
              "Nf2",
              "Rg2",
              "Kf3",
              "Rg1",
              "Ng4",
              "h5",
              "Nf6",
              "Ke7",
              "Nxh5",
              "Kf8",
              "Kg4",
              "Re1",
              "Bd5",
              "Rf1",
              "Kg5",
              "Ke7",
              "g4",
              "Kd6",
              "Ng7",
              "Kc5",
              "h5",
              "Kd4",
              "h6",
              "Rh1",
              "Nh5",
              "Ra1",
              "h7",
              "Ra8",
              "Bxa8",
              "Ke3",
              "h8=Q",
              "Kd4",
              "Qd8+",
              "Ke3",
              "Qd5",
              "Kf3",
              "Qd3+",
              "Kf2",
              "Ng3",
              "Kg2",
              "Qe2+",
              "Kxg3",
              "Qe3+",
              "Kg2",
              "Kh4",
              "Kf1",
              "Qd2",
              "Kg1",
              "Kg3",
              "Kf1",
              "Qf2#",
              "e4",
              "d5",
              "Nf6+",
              "Kg7",
              "Nxe4+",
              "Kf8",
              "Nf6+",
              "Kg7",
              "Nxe4+"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "h3",
            "Na5"
          ],
          "full_moves": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Qa6",
            "Bg5",
            "Qa5",
            "Qd1",
            "Nxd4",
            "Nxd4",
            "exd4",
            "Bxf6",
            "gxf6",
            "Nh5",
            "Re6",
            "Rf1",
            "Kh8",
            "Qxd4",
            "b4",
            "Nxf6",
            "Qe5",
            "Qxe5",
            "dxe5",
            "Nxd7",
            "Rd8",
            "Nc5",
            "Rc6",
            "Nxa4",
            "Rd2",
            "b3",
            "Kg7",
            "g3",
            "Kf6",
            "Kg2",
            "Ke7",
            "Kf3",
            "Rf6+",
            "Ke3",
            "Rfd6",
            "Rc1",
            "Rd1",
            "Rxd1",
            "Rxd1",
            "Bd3",
            "Ra1",
            "Nb6",
            "Rxa2",
            "Nd5+",
            "Kd6",
            "Nxb4",
            "Rb2",
            "Bc4",
            "f6",
            "Nd3",
            "Rb1",
            "f4",
            "Rh1",
            "h4",
            "Rg1",
            "Kf2",
            "Rd1",
            "fxe5+",
            "fxe5",
            "Ke2",
            "Rg1",
            "Kf3",
            "Rd1",
            "Kg4",
            "Rg1",
            "Nf2",
            "Rg2",
            "Kf3",
            "Rg1",
            "Ng4",
            "h5",
            "Nf6",
            "Ke7",
            "Nxh5",
            "Kf8",
            "Kg4",
            "Re1",
            "Bd5",
            "Rf1",
            "Kg5",
            "Ke7",
            "g4",
            "Kd6",
            "Ng7",
            "Kc5",
            "h5",
            "Kd4",
            "h6",
            "Rh1",
            "Nh5",
            "Ra1",
            "h7",
            "Ra8",
            "Bxa8",
            "Ke3",
            "h8=Q",
            "Kd4",
            "Qd8+",
            "Ke3",
            "Qd5",
            "Kf3",
            "Qd3+",
            "Kf2",
            "Ng3",
            "Kg2",
            "Qe2+",
            "Kxg3",
            "Qe3+",
            "Kg2",
            "Kh4",
            "Kf1",
            "Qd2",
            "Kg1",
            "Kg3",
            "Kf1",
            "Qf2#",
            "e4",
            "d5",
            "Nf6+",
            "Kg7",
            "Nxe4+",
            "Kf8",
            "Nf6+",
            "Kg7",
            "Nxe4+"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 163,
            "completion_tokens": 541,
            "total_tokens": 704,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 162,
            "completion_tokens": 640,
            "total_tokens": 802,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 488,
          "total_completion_tokens": 1821,
          "total_tokens": 2309
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 163,
            "completion_tokens": 541,
            "total_tokens": 704,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 162,
            "completion_tokens": 640,
            "total_tokens": 802,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 w kq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc2",
          "aggressive_uci": "b3c2",
          "aggressive_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. b3 Nb6 16. Ng3 g6 17. Bh6 Rfe8 18. Qd2 Bf8 19. Bxf8 Rxf8 20. Qh6 Kh8 21. Ng5 Be8 22. f4 Rg8 23. fxe5 dxe5 24. Rf1 Qd6 25. Rxf6 Qxf6 26. Qxh7# e4 dxe4 Qg7#\ne5 Nxe5 Nxe5 dxe5 Qxd8 Rxd8 Nc3 Nc6 Be3 Be6 Rad1 Nd4 Bxd4 cxd4 Nd5 Bxd5 exd5 Rac8 Rfe1 Bf6 Rd2 Rc5 Re4 Rdc8 Rde2 g6 Re8+ Kg7 Rxc8 Rxc8 Re2 Rc5 Kf1 Rxd5 Ke1 d3 cxd3 Rxd3 Rd2 Rxd2 Kxd2 Bxb2 Kd3 Kf6 Ke4 Ke6 f4 f5+ Kd3 Kd5 g3 Bd4 h3 Bf2 g4 Bg3 gxf5 gxf5 Ke3 Bh2 Kf3 Kd4 Kg2 Bxf4 Kf3 Be5 h4 h5 a3 a5 a4 bxa4 bxa4 Bc7 a5 Bxa5 Kf4 Bd8 Kxf5 Bxh4 Kg6 Be7 Kh6 Ke5 Kg6 Kd5 Kf6 Kc5 Ke6 Kb5 Kd6 Ka5 Kc6 Kb5 Kd5 Kc7 Kc6 Kd5 Kd7 Ke5 Kc6 Ke4 Kc5 Ke3 Kc4 Ke2 Kc3 Ke1 Kd3 Kf1 Ke3 Kg1 Kf3 Kh1 Kg3 Kg1 Kh3 Kf1 Kg3 Ke1 Kf3 Kd1 Ke3 Kc1 Kd3 Kb1 Kc3 Ka1 Kb3 Kb1 Kc3 Ka1 Kb3 Kc1 Kc3 Kb1 Kd3 Ka1 Ke3 Kb1 Kc3 Ka1 Kb3 Kc1 Kd3 Kb1 Kc3 Ka1 Kb3 Kc1 Kd3 Kb1 Kc3 Ka1 Kb3 Kc1 Kd3 Kb1 Kc3 Ka1 Kb3 Kc1 Kd3 Kb1 Kc3 Ka1 Kb3 Kc1 Kd3 Kb1 Kc3 Ka1 Kb3 Kc1 Kd3 Kb1 Kc3 Ka1 Kb3 Kc1 Kd3 Kb1 Kc3 Ka1 Kb3 Kc1 Kd3 Kb1 Kc3 Ka1 Kb3 Kc1 K",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "f4",
            "Rg8",
            "fxe5",
            "dxe5",
            "Rf1",
            "Qd6",
            "Rxf6",
            "Qxf6",
            "Qxh7#",
            "e4",
            "dxe4",
            "Qg7#",
            "e5",
            "Nxe5",
            "Nxe5",
            "dxe5",
            "Qxd8",
            "Rxd8",
            "Nc3",
            "Nc6",
            "Be3",
            "Be6",
            "Rad1",
            "Nd4",
            "Bxd4",
            "cxd4",
            "Nd5",
            "Bxd5",
            "exd5",
            "Rac8",
            "Rfe1",
            "Bf6",
            "Rd2",
            "Rc5",
            "Re4",
            "Rdc8",
            "Rde2",
            "g6",
            "Re8+",
            "Kg7",
            "Rxc8",
            "Rxc8",
            "Re2",
            "Rc5",
            "Kf1",
            "Rxd5",
            "Ke1",
            "d3",
            "cxd3",
            "Rxd3",
            "Rd2",
            "Rxd2",
            "Kxd2",
            "Bxb2",
            "Kd3",
            "Kf6",
            "Ke4",
            "Ke6",
            "f4",
            "f5+",
            "Kd3",
            "Kd5",
            "g3",
            "Bd4",
            "h3",
            "Bf2",
            "g4",
            "Bg3",
            "gxf5",
            "gxf5",
            "Ke3",
            "Bh2",
            "Kf3",
            "Kd4",
            "Kg2",
            "Bxf4",
            "Kf3",
            "Be5",
            "h4",
            "h5",
            "a3",
            "a5",
            "a4",
            "bxa4",
            "bxa4",
            "Bc7",
            "a5",
            "Bxa5",
            "Kf4",
            "Bd8",
            "Kxf5",
            "Bxh4",
            "Kg6",
            "Be7",
            "Kh6",
            "Ke5",
            "Kg6",
            "Kd5",
            "Kf6",
            "Kc5",
            "Ke6",
            "Kb5",
            "Kd6",
            "Ka5",
            "Kc6",
            "Kb5",
            "Kd5",
            "Kc7",
            "Kc6",
            "Kd5",
            "Kd7",
            "Ke5",
            "Kc6",
            "Ke4",
            "Kc5",
            "Ke3",
            "Kc4",
            "Ke2",
            "Kc3",
            "Ke1",
            "Kd3",
            "Kf1",
            "Ke3",
            "Kg1",
            "Kf3",
            "Kh1",
            "Kg3",
            "Kg1",
            "Kh3",
            "Kf1",
            "Kg3",
            "Ke1",
            "Kf3",
            "Kd1",
            "Ke3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kc3",
            "Kb1",
            "Kd3",
            "Ka1",
            "Ke3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "query2": {
          "positional_move": "Bc2",
          "positional_uci": "b3c2",
          "positional_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. b3 Nb6 16. Ng3 g6 17. Bh6 Rfe8 18. Qd2 Bf8 19. Bxf8 Rxf8 20. Qh6 Kh8 21. Ng5 Be8 22. Re3 Rg8 23. Rf3 Qe7 24. Rxf6 Rg7 25. Nh5 gxh5 26. Nxh7 Rxh7 27. Qg5 Qf8 28. f4 Nd7 29. fxe5 Nxf6 30. Qxf6+ Qg7 31. Qxd6 Rh6 32. Qxc5 Qxe5 33. Rf1 Rg6 34. Rf5 Qg3 35. Rxh5+ Kg8 36. Qf2 Qxf2+ 37. Kxf2 Rc8 38. e5 Rxc3 39. Bxg6 fxg6 40. Rh4 Rc2+ 41. Ke3 Rxg2 42. d6 Rxa2 43. e6 Ra1 44. d7 Bxd7 45. exd7 Rd1 46. Rd4 Re1+ 47. Kd2 1-0 e5 Nf6 d6 Bg4 Nc3 O-O Nf1 Bf5 b3 Nb6 Ng3 g6 Bh6 Rfe8 Qd2 Bf8 Ng5 Be8 Re3 Rg8 Rf3 Qe7 Rxf6 Rg7 Nh5 gxh5 Nxh7 Rxh7 Qg5+ Qg7 Rf5 Qf8 Rg5+ Rg7 Bh7+ Kh8 Rxf7 Qxf7 Qxc5 Kh7 Qf8 Qg6 Qf5 Qxg2#",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 448,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "Re3",
            "Rg8",
            "Rf3",
            "Qe7",
            "Rxf6",
            "Rg7",
            "Nh5",
            "gxh5",
            "Nxh7",
            "Rxh7",
            "Qg5",
            "Qf8",
            "f4",
            "Nd7",
            "fxe5",
            "Nxf6",
            "Qxf6+",
            "Qg7",
            "Qxd6",
            "Rh6",
            "Qxc5",
            "Qxe5",
            "Rf1",
            "Rg6",
            "Rf5",
            "Qg3",
            "Rxh5+",
            "Kg8",
            "Qf2",
            "Qxf2+",
            "Kxf2",
            "Rc8",
            "e5",
            "Rxc3",
            "Bxg6",
            "fxg6",
            "Rh4",
            "Rc2+",
            "Ke3",
            "Rxg2",
            "d6",
            "Rxa2",
            "e6",
            "Ra1",
            "d7",
            "Bxd7",
            "exd7",
            "Rd1",
            "Rd4",
            "Re1+",
            "Kd2",
            "e5",
            "Nf6",
            "d6",
            "Bg4",
            "Nc3",
            "O-O",
            "Nf1",
            "Bf5",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Ng5",
            "Be8",
            "Re3",
            "Rg8",
            "Rf3",
            "Qe7",
            "Rxf6",
            "Rg7",
            "Nh5",
            "gxh5",
            "Nxh7",
            "Rxh7",
            "Qg5+",
            "Qg7",
            "Rf5",
            "Qf8",
            "Rg5+",
            "Rg7",
            "Bh7+",
            "Kh8",
            "Rxf7",
            "Qxf7",
            "Qxc5",
            "Kh7",
            "Qf8",
            "Qg6",
            "Qf5",
            "Qxg2#"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "query3": {
          "neutral_move": "Bc2",
          "neutral_uci": "b3c2",
          "neutral_response": "9. Bc2 O-O 10. d4 Bg4 11. Nbd2 c5 12. d5 c4 13. h3 Bh5 14. Nf1 Nb7 15. Ng3 Bg6\n16. Nh4 Nc5 17. Nhf5 Re8 18. Be3 Nfd7 19. Qd2 Bf8 20. Rad1 Qc7 21. f3 a5 22. h4\nf6 23. h5 Bf7 24. Kf2 Rab8 25. Rh1 b4 26. Rh4 bxc3 27. bxc3 Rb2 28. Rg4 Kh8 29.\nNxg7 Bxg7 30. Rxg7 Kxg7 31. Bh6+ Kh8 32. Nf5 Nd3+ 33. Kg1 Rg8 34. Ne7 Qc5+ 35.\nKh2 Nf4 36. Nxg8 Bxg8 37. Bxf4 exf4 38. Qxf4 Rxc2 39. Rb1 Qf2 40. Qg4 Ne5 41.\nQh3 Nxf3+ 42. Kh1 Ng5 43. Qh2 Nxe4 44. Rg1 Ng3+ 45. Qxg3 Qxg3 46. h6 Qh4# 0-1\n9. Bc2 O-O 10. d4 Bg4 11. Nbd2 c5 12. d5 c4 13. h3 Bh5 14. Nf1 Nb7 15. Ng3 Bg6\n16. Nh4 Nc5 17. Nhf5 Re8 18. Be3 Nfd7 19. Qd2 Bf8 20. Rad1 Qc7 21. f3 a5 22. h4\nf6 23. h5 Bf7 24. Kf2 Rab8 25. Rh1 b4 26. Rh4 bxc3 27. bxc3 Rb2 28. Rg4 Kh8 29.\nNxg7 Bxg7 30. Rxg7 Kxg7 31. Bh6+ Kh8 32. Nf5 Nd3+ 33. Kg1 Rg8 34. Ne7 Qc5+ 35.\nKh2 Nf4 36. Nxg8 Bxg8 37. Bxf4 exf4 38. Qxf4 Rxc2 39. Rb1 Qf2 40. Qg4 Ne5 41.\nQh3 Nxf3+ 42. Kh1 Ng5 43. Qh2 Nxe4 44. Rg1 Ng3+ 45. Qxg3 Qxg3 46. h6",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "d4",
            "Bg4",
            "Nbd2",
            "c5",
            "d5",
            "c4",
            "h3",
            "Bh5",
            "Nf1",
            "Nb7",
            "Ng3",
            "Bg6",
            "Nh4",
            "Nc5",
            "Nhf5",
            "Re8",
            "Be3",
            "Nfd7",
            "Qd2",
            "Bf8",
            "Rad1",
            "Qc7",
            "f3",
            "a5",
            "h4",
            "f6",
            "h5",
            "Bf7",
            "Kf2",
            "Rab8",
            "Rh1",
            "b4",
            "Rh4",
            "bxc3",
            "bxc3",
            "Rb2",
            "Rg4",
            "Kh8",
            "Nxg7",
            "Bxg7",
            "Rxg7",
            "Kxg7",
            "Bh6+",
            "Kh8",
            "Nf5",
            "Nd3+",
            "Kg1",
            "Rg8",
            "Ne7",
            "Qc5+",
            "Kh2",
            "Nf4",
            "Nxg8",
            "Bxg8",
            "Bxf4",
            "exf4",
            "Qxf4",
            "Rxc2",
            "Rb1",
            "Qf2",
            "Qg4",
            "Ne5",
            "Qh3",
            "Nxf3+",
            "Kh1",
            "Ng5",
            "Qh2",
            "Nxe4",
            "Rg1",
            "Ng3+",
            "Qxg3",
            "Qxg3",
            "h6"
          ],
          "plan_execute": [
            "O-O",
            "d4",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b3c2",
          "positional_uci": "b3c2",
          "neutral_uci": "b3c2",
          "consensus_move": "b3c2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "b3",
              "Nb6",
              "Ng3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "Bf8",
              "Bxf8",
              "Rxf8",
              "Qh6",
              "Kh8",
              "Ng5",
              "Be8",
              "f4",
              "Rg8",
              "fxe5",
              "dxe5",
              "Rf1",
              "Qd6",
              "Rxf6",
              "Qxf6",
              "Qxh7#",
              "e4",
              "dxe4",
              "Qg7#",
              "e5",
              "Nxe5",
              "Nxe5",
              "dxe5",
              "Qxd8",
              "Rxd8",
              "Nc3",
              "Nc6",
              "Be3",
              "Be6",
              "Rad1",
              "Nd4",
              "Bxd4",
              "cxd4",
              "Nd5",
              "Bxd5",
              "exd5",
              "Rac8",
              "Rfe1",
              "Bf6",
              "Rd2",
              "Rc5",
              "Re4",
              "Rdc8",
              "Rde2",
              "g6",
              "Re8+",
              "Kg7",
              "Rxc8",
              "Rxc8",
              "Re2",
              "Rc5",
              "Kf1",
              "Rxd5",
              "Ke1",
              "d3",
              "cxd3",
              "Rxd3",
              "Rd2",
              "Rxd2",
              "Kxd2",
              "Bxb2",
              "Kd3",
              "Kf6",
              "Ke4",
              "Ke6",
              "f4",
              "f5+",
              "Kd3",
              "Kd5",
              "g3",
              "Bd4",
              "h3",
              "Bf2",
              "g4",
              "Bg3",
              "gxf5",
              "gxf5",
              "Ke3",
              "Bh2",
              "Kf3",
              "Kd4",
              "Kg2",
              "Bxf4",
              "Kf3",
              "Be5",
              "h4",
              "h5",
              "a3",
              "a5",
              "a4",
              "bxa4",
              "bxa4",
              "Bc7",
              "a5",
              "Bxa5",
              "Kf4",
              "Bd8",
              "Kxf5",
              "Bxh4",
              "Kg6",
              "Be7",
              "Kh6",
              "Ke5",
              "Kg6",
              "Kd5",
              "Kf6",
              "Kc5",
              "Ke6",
              "Kb5",
              "Kd6",
              "Ka5",
              "Kc6",
              "Kb5",
              "Kd5",
              "Kc7",
              "Kc6",
              "Kd5",
              "Kd7",
              "Ke5",
              "Kc6",
              "Ke4",
              "Kc5",
              "Ke3",
              "Kc4",
              "Ke2",
              "Kc3",
              "Ke1",
              "Kd3",
              "Kf1",
              "Ke3",
              "Kg1",
              "Kf3",
              "Kh1",
              "Kg3",
              "Kg1",
              "Kh3",
              "Kf1",
              "Kg3",
              "Ke1",
              "Kf3",
              "Kd1",
              "Ke3",
              "Kc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1",
              "Kc3",
              "Kb1",
              "Kd3",
              "Ka1",
              "Ke3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kc1"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          },
          "positional": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "b3",
              "Nb6",
              "Ng3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "Bf8",
              "Bxf8",
              "Rxf8",
              "Qh6",
              "Kh8",
              "Ng5",
              "Be8",
              "Re3",
              "Rg8",
              "Rf3",
              "Qe7",
              "Rxf6",
              "Rg7",
              "Nh5",
              "gxh5",
              "Nxh7",
              "Rxh7",
              "Qg5",
              "Qf8",
              "f4",
              "Nd7",
              "fxe5",
              "Nxf6",
              "Qxf6+",
              "Qg7",
              "Qxd6",
              "Rh6",
              "Qxc5",
              "Qxe5",
              "Rf1",
              "Rg6",
              "Rf5",
              "Qg3",
              "Rxh5+",
              "Kg8",
              "Qf2",
              "Qxf2+",
              "Kxf2",
              "Rc8",
              "e5",
              "Rxc3",
              "Bxg6",
              "fxg6",
              "Rh4",
              "Rc2+",
              "Ke3",
              "Rxg2",
              "d6",
              "Rxa2",
              "e6",
              "Ra1",
              "d7",
              "Bxd7",
              "exd7",
              "Rd1",
              "Rd4",
              "Re1+",
              "Kd2",
              "e5",
              "Nf6",
              "d6",
              "Bg4",
              "Nc3",
              "O-O",
              "Nf1",
              "Bf5",
              "b3",
              "Nb6",
              "Ng3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "Bf8",
              "Ng5",
              "Be8",
              "Re3",
              "Rg8",
              "Rf3",
              "Qe7",
              "Rxf6",
              "Rg7",
              "Nh5",
              "gxh5",
              "Nxh7",
              "Rxh7",
              "Qg5+",
              "Qg7",
              "Rf5",
              "Qf8",
              "Rg5+",
              "Rg7",
              "Bh7+",
              "Kh8",
              "Rxf7",
              "Qxf7",
              "Qxc5",
              "Kh7",
              "Qf8",
              "Qg6",
              "Qf5",
              "Qxg2#"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "d4",
              "Bg4",
              "Nbd2",
              "c5",
              "d5",
              "c4",
              "h3",
              "Bh5",
              "Nf1",
              "Nb7",
              "Ng3",
              "Bg6",
              "Nh4",
              "Nc5",
              "Nhf5",
              "Re8",
              "Be3",
              "Nfd7",
              "Qd2",
              "Bf8",
              "Rad1",
              "Qc7",
              "f3",
              "a5",
              "h4",
              "f6",
              "h5",
              "Bf7",
              "Kf2",
              "Rab8",
              "Rh1",
              "b4",
              "Rh4",
              "bxc3",
              "bxc3",
              "Rb2",
              "Rg4",
              "Kh8",
              "Nxg7",
              "Bxg7",
              "Rxg7",
              "Kxg7",
              "Bh6+",
              "Kh8",
              "Nf5",
              "Nd3+",
              "Kg1",
              "Rg8",
              "Ne7",
              "Qc5+",
              "Kh2",
              "Nf4",
              "Nxg8",
              "Bxg8",
              "Bxf4",
              "exf4",
              "Qxf4",
              "Rxc2",
              "Rb1",
              "Qf2",
              "Qg4",
              "Ne5",
              "Qh3",
              "Nxf3+",
              "Kh1",
              "Ng5",
              "Qh2",
              "Nxe4",
              "Rg1",
              "Ng3+",
              "Qxg3",
              "Qxg3",
              "h6"
            ],
            "execute": [
              "O-O",
              "d4",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "c5",
            "d4",
            "Qc7"
          ],
          "full_moves": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "f4",
            "Rg8",
            "fxe5",
            "dxe5",
            "Rf1",
            "Qd6",
            "Rxf6",
            "Qxf6",
            "Qxh7#",
            "e4",
            "dxe4",
            "Qg7#",
            "e5",
            "Nxe5",
            "Nxe5",
            "dxe5",
            "Qxd8",
            "Rxd8",
            "Nc3",
            "Nc6",
            "Be3",
            "Be6",
            "Rad1",
            "Nd4",
            "Bxd4",
            "cxd4",
            "Nd5",
            "Bxd5",
            "exd5",
            "Rac8",
            "Rfe1",
            "Bf6",
            "Rd2",
            "Rc5",
            "Re4",
            "Rdc8",
            "Rde2",
            "g6",
            "Re8+",
            "Kg7",
            "Rxc8",
            "Rxc8",
            "Re2",
            "Rc5",
            "Kf1",
            "Rxd5",
            "Ke1",
            "d3",
            "cxd3",
            "Rxd3",
            "Rd2",
            "Rxd2",
            "Kxd2",
            "Bxb2",
            "Kd3",
            "Kf6",
            "Ke4",
            "Ke6",
            "f4",
            "f5+",
            "Kd3",
            "Kd5",
            "g3",
            "Bd4",
            "h3",
            "Bf2",
            "g4",
            "Bg3",
            "gxf5",
            "gxf5",
            "Ke3",
            "Bh2",
            "Kf3",
            "Kd4",
            "Kg2",
            "Bxf4",
            "Kf3",
            "Be5",
            "h4",
            "h5",
            "a3",
            "a5",
            "a4",
            "bxa4",
            "bxa4",
            "Bc7",
            "a5",
            "Bxa5",
            "Kf4",
            "Bd8",
            "Kxf5",
            "Bxh4",
            "Kg6",
            "Be7",
            "Kh6",
            "Ke5",
            "Kg6",
            "Kd5",
            "Kf6",
            "Kc5",
            "Ke6",
            "Kb5",
            "Kd6",
            "Ka5",
            "Kc6",
            "Kb5",
            "Kd5",
            "Kc7",
            "Kc6",
            "Kd5",
            "Kd7",
            "Ke5",
            "Kc6",
            "Ke4",
            "Kc5",
            "Ke3",
            "Kc4",
            "Ke2",
            "Kc3",
            "Ke1",
            "Kd3",
            "Kf1",
            "Ke3",
            "Kg1",
            "Kf3",
            "Kh1",
            "Kg3",
            "Kg1",
            "Kh3",
            "Kf1",
            "Kg3",
            "Ke1",
            "Kf3",
            "Kd1",
            "Ke3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kc3",
            "Kb1",
            "Kd3",
            "Ka1",
            "Ke3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kc1"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 448,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1728,
          "total_tokens": 2240
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 448,
            "total_tokens": 619,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 640,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/np2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 w kq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d3",
          "aggressive_uci": "d2d3",
          "aggressive_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 c5 13. Ng3 Bg4 14. h3 Bxf3 15. Qxf3 g6 16. Bh6 Re8 17. Rad1 Bf8 18. Bg5 Bg7 19. d4 cxd4 20. cxd4 Qe7 21. dxe5 dxe5 22. Bb3 Rad8 23. Rc1 Rc8 24. Qe3 Nbd7 25. Qa7 Rxc1 26. Rxc1 Qd6 27. Rd1 Qc6 28. Bxf6 Nxf6 29. Bxf7+ Kh8 30. Bxe8 Qxe8 31. Qxa6 h5 32. Qb6 Kh7 33. Rd8 Qf7 34. Qxb5 Qxa2 35. Qxe5 Qb1+ 36. Kh2 Ng4+ 37. hxg4 Bxe5 38. gxh5 gxh5 39. Rd5 Bxg3+ 40. Kxg3 Qxe4 41. Rxh5+ Kg6 42. Rh4 Qe5+ 43. Kh3 Qxb2 44. f3 Qf2 45. Rg4+ Kf5 46. Rg8 Qg1 47. Rf8+ Kg5 48. Rg8+ Kf4 49. Rf8+ Ke3 50. Re8+ Kf2 51. Rg8 Qh1+ 52. Kg4 Qxg2+ 53. Kf5 Qxg8 54. f4 Qf7+ 55. Kg5 Kf3 56. f5 Ke4 57. f6 Ke5 58. Kh6 Qxf6+ 59. Kh7 Qg5 60. Kh8 Kf6 61. Kh7 Qg7# e4 Nc6 Bb5 d6 Na5 Nc4 d3 Nb6 Nbd2 O-O Nf1 c5 Ng3 Bg4 h3 Bxf3 Qxf3 g6 Bh6 Re8 Rd1 Bf8 d4 cxd4 cxd4 Qe7 dxe5 dxe5 Bb3 Rd8 Rxd8 Qxd8 Qxf7+ Kh8 Qg8#",
          "aggressive_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 539,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "c5",
            "Ng3",
            "Bg4",
            "h3",
            "Bxf3",
            "Qxf3",
            "g6",
            "Bh6",
            "Re8",
            "Rd1",
            "Bf8",
            "d4",
            "cxd4",
            "cxd4",
            "Qe7",
            "dxe5",
            "dxe5",
            "Bb3",
            "Rd8",
            "Rxd8",
            "Qxd8",
            "Qxf7+",
            "Kh8",
            "Qg8#"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "d3",
          "positional_uci": "d2d3",
          "positional_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 Bg4 13. h3 Bh5 14. Ng3 Bg6 15. Nh4 Nfd7 16. Nhf5 Bxf5 17. Nxf5 Bg5 18. Qg4 h6 19. h4 Nf6 20. Qg3 Nh5 21. Qg4 Nf6 22. Qh3 Bxc1 23. Raxc1 Kh7 24. d4 g6 25. Ng3 Qd7 26. Qh2 Ng4 27. Qh1 exd4 28. cxd4 Nc4 29. b3 Na3 30. Bd3 b4 31. h5 Nb5 32. hxg6+ fxg6 33. f3 Nf6 34. e5 dxe5 35. dxe5 Qxd3 36. exf6 Rxf6 37. Re7+ Kg8 38. Qxh6 Qd4+ 39. Kh1 Rf7 40. Qxg6+ Rg7 41. Qe6+ Kh8 42. Rxg7 Qxg7 43. Nf5 Qh7+ 44. Kg1 Rf8 45. Qe5+ Kg8 46. Ne7+ Kf7 47. Nd5 Qh6 48. Qe7+ Kg8 49. Rc4 Rf7 50. Rg4+ Rg7 51. Nf6+ Kh8 52. Qf8+ Rg8 53. Qxg8# Nc3 54. Qg7# Nxa2 55. Qh7# Nc3 56. Qg8# Nxa4 57. Qg7# Nc3 58. Qg8# Nxa4 59. Qg7# Nc3 60. Qg8# Nxa4 61. Qg7# Nc3 62. Qg8# Nxa4 63. Qg7# Nc3 64. Qg8# Nxa4 65. Qg7# Nc3 66. Qg8# Nxa4 67. Qg7# Nc3 68. Qg8# Nxa4 69. Qg7# Nc3 70. Qg8# Nxa4 71. Qg7# Nc3 72. Qg8# Nxa4 73. Qg7# Nc3 74. Qg8# Nxa4 75. Qg7# Nc3 76. Qg8# Nxa4 77. Qg7# Nc3 78. Qg8# Nxa4 79. Qg7# Nc3",
          "positional_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "Nfd7",
            "Nhf5",
            "Bxf5",
            "Nxf5",
            "Bg5",
            "Qg4",
            "h6",
            "h4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qh3",
            "Bxc1",
            "Raxc1",
            "Kh7",
            "d4",
            "g6",
            "Ng3",
            "Qd7",
            "Qh2",
            "Ng4",
            "Qh1",
            "exd4",
            "cxd4",
            "Nc4",
            "b3",
            "Na3",
            "Bd3",
            "b4",
            "h5",
            "Nb5",
            "hxg6+",
            "fxg6",
            "f3",
            "Nf6",
            "e5",
            "dxe5",
            "dxe5",
            "Qxd3",
            "exf6",
            "Rxf6",
            "Re7+",
            "Kg8",
            "Qxh6",
            "Qd4+",
            "Kh1",
            "Rf7",
            "Qxg6+",
            "Rg7",
            "Qe6+",
            "Kh8",
            "Rxg7",
            "Qxg7",
            "Nf5",
            "Qh7+",
            "Kg1",
            "Rf8",
            "Qe5+",
            "Kg8",
            "Ne7+",
            "Kf7",
            "Nd5",
            "Qh6",
            "Qe7+",
            "Kg8",
            "Rc4",
            "Rf7",
            "Rg4+",
            "Rg7",
            "Nf6+",
            "Kh8",
            "Qf8+",
            "Rg8",
            "Qxg8#",
            "Nc3",
            "Qg7#",
            "Nxa2",
            "Qh7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3",
            "Qg8#",
            "Nxa4",
            "Qg7#",
            "Nc3"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "d3",
          "neutral_uci": "d2d3",
          "neutral_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 Bg4 13. h3 Bh5 14. Ng3 Bg6 15. Nh4 Nfd7 16. Nhf5 Bxf5 17. Nxf5 Bg5 18. Qg4 h6 19. h4 Nf6 20. Qg3 Nh5 21. Qg4 Nf6 22. Qh3 Bxc1 23. Raxc1 Kh7 24. d4 g6 25. Ne3 Nh5 26. g3 Qd7 27. Qxd7 Nxd7 28. Nd5 c6 29. Ne7 c5 30. dxc5 Nxc5 31. Rcd1 Rad8 32. Rd2 Rd7 33. Nd5 Kg7 34. Red1 Rfd8 35. Nb4 Nf6 36. f3 a5 37. Nc6 Ra8 38. Rxd6 Rxd6 39. Rxd6 Ra6 40. b4 axb4 41. cxb4 Nb7 42. Rd2 Rxc6 43. Bb3 Rc3 44. Kf2 Rc6 45. Bd5 Nxd5 46. Rxd5 Rc2+ 47. Ke3 Rxa2 48. Rxb5 Nd6 49. Rxe5 Nc4+ 50. Kd4 Nxe5 51. Kxe5 Rb2 52. f4 Rxb4 53. f5 gxf5 54. exf5 Rb5+ 55. Kf4 Kf6 56. g4 Rb4+ 57. Kf3 Ke5 58. Kg3 Rb3+ 59. Kf2 Kf4 60. g5 hxg5 61. hxg5 Kxg5 62. f6 Kxf6 63. Ke2 Ke5 64. Kd2 Kd4 65. Kc2 Rh3 66. Kd2 Rh2+ 67. Ke1 Ke3 68. Kf1 Ra2 69. Kg1 Kf3 70. Kh1 Kg3 71. Kg1 Ra1# 0-1 1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3\nNa5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 O-O 12. Nf1 Bg4 13. h3 Bh5 14. Ng3 Bg6 15. Nh4 Nfd7 16. Nhf5 Bxf5",
          "neutral_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "Nfd7",
            "Nhf5",
            "Bxf5"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d2d3",
          "positional_uci": "d2d3",
          "neutral_uci": "d2d3",
          "consensus_move": "d2d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "c5",
              "Ng3",
              "Bg4",
              "h3",
              "Bxf3",
              "Qxf3",
              "g6",
              "Bh6",
              "Re8",
              "Rd1",
              "Bf8",
              "d4",
              "cxd4",
              "cxd4",
              "Qe7",
              "dxe5",
              "dxe5",
              "Bb3",
              "Rd8",
              "Rxd8",
              "Qxd8",
              "Qxf7+",
              "Kh8",
              "Qg8#"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "Nfd7",
              "Nhf5",
              "Bxf5",
              "Nxf5",
              "Bg5",
              "Qg4",
              "h6",
              "h4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qh3",
              "Bxc1",
              "Raxc1",
              "Kh7",
              "d4",
              "g6",
              "Ng3",
              "Qd7",
              "Qh2",
              "Ng4",
              "Qh1",
              "exd4",
              "cxd4",
              "Nc4",
              "b3",
              "Na3",
              "Bd3",
              "b4",
              "h5",
              "Nb5",
              "hxg6+",
              "fxg6",
              "f3",
              "Nf6",
              "e5",
              "dxe5",
              "dxe5",
              "Qxd3",
              "exf6",
              "Rxf6",
              "Re7+",
              "Kg8",
              "Qxh6",
              "Qd4+",
              "Kh1",
              "Rf7",
              "Qxg6+",
              "Rg7",
              "Qe6+",
              "Kh8",
              "Rxg7",
              "Qxg7",
              "Nf5",
              "Qh7+",
              "Kg1",
              "Rf8",
              "Qe5+",
              "Kg8",
              "Ne7+",
              "Kf7",
              "Nd5",
              "Qh6",
              "Qe7+",
              "Kg8",
              "Rc4",
              "Rf7",
              "Rg4+",
              "Rg7",
              "Nf6+",
              "Kh8",
              "Qf8+",
              "Rg8",
              "Qxg8#",
              "Nc3",
              "Qg7#",
              "Nxa2",
              "Qh7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3",
              "Qg8#",
              "Nxa4",
              "Qg7#",
              "Nc3"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "Nfd7",
              "Nhf5",
              "Bxf5"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nb6",
            "Nbd2",
            "O-O"
          ],
          "full_moves": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "Nfd7",
            "Nhf5",
            "Bxf5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 180,
            "completion_tokens": 539,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 539,
          "total_completion_tokens": 1819,
          "total_tokens": 2358
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 180,
            "completion_tokens": 539,
            "total_tokens": 719,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2P2N2/PPBP1PPP/RNBQR1K1 w kq - 3 10"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxb4",
          "aggressive_uci": "c3b4",
          "aggressive_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Nfxd5 19. Rxe5 Nxb4 20. Bb3+ Kh8 21. Qe2 Bf6 22. Re4 Nxd3 23. Be3 Nxb2 24. Rb1 Nd3 25. Rd1 Qd6 26. Rxd3 Qc6 27. Bxb6 cxb6 28. Bd5 Qc1+ 29. Rd1 Qc5 30. Bxa8 Rxa8 31. Re8+ Rxe8 32. Qxe8+ Qf8 33. Qxf8# e5 d4 Bc5 Bb6 *",
          "aggressive_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 198,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Qd6",
            "Rxd3",
            "Qc6",
            "Bxb6",
            "cxb6",
            "Bd5",
            "Qc1+",
            "Rd1",
            "Qc5",
            "Bxa8",
            "Rxa8",
            "Re8+",
            "Rxe8",
            "Qxe8+",
            "Qf8",
            "Qxf8#",
            "e5",
            "d4",
            "Bc5",
            "Bb6"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "cxb4",
          "positional_uci": "c3b4",
          "positional_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Nfxd5 19. Rxe5 Nxb4 20. Bb3+ Kh8 21. Qe2 Bf6 22. Re4 Nxd3 23. Be3 Nxb2 24. Rb1 Nd3 25. Rd1 Nc5 26. Rxd8 Raxd8 27. Bxc5 Nd7 28. Bxf8 Rxf8 29. Re8 h6 30. Rxf8+ Nxf8 31. Qe8 Kh7 32. Qxf8 g5 33. Bc2+ g6 34. Qf7+ Bg7 35. Bxg6+ Kh8 36. Qe8+ Bf8 37. Qxf8# e4 Nc6 Nc4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 N",
          "positional_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Nc5",
            "Rxd8",
            "Raxd8",
            "Bxc5",
            "Nd7",
            "Bxf8",
            "Rxf8",
            "Re8",
            "h6",
            "Rxf8+",
            "Nxf8",
            "Qe8",
            "Kh7",
            "Qxf8",
            "g5",
            "Bc2+",
            "g6",
            "Qf7+",
            "Bg7",
            "Bxg6+",
            "Kh8",
            "Qe8+",
            "Bf8",
            "Qxf8#",
            "e4",
            "Nc6",
            "Nc4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "query3": {
          "neutral_move": "cxb4",
          "neutral_uci": "c3b4",
          "neutral_response": "12. cxb4 O-O 13. a4 a5 14. bxa5 Rxa5 15. b4 Ra8 16. a5 Nbd7 17. d4 exd4 18. Nxd4 Bb7 19. Nf5 Re8 20. Nxe7+ Qxe7 21. Bb2 Ne5 22. f4 Nc6 23. Bc3 Ba6 24. Ba4 Bb7 25. b5 Nxa5 26. Bxa5 Rxa5 27. b6 c6 28. Nc4 Rc5 29. Nxd6 Rd8 30. e5 Nd5 31. Qd4 Ra5 32. Bxc6 Rxa1 33. Rxa1 Bxc6 34. Ra7 Qh4 35. g3 Qh3 36. b7 Nxf4 37. Qf2 Nd3 38. Qxf7+ Kh8 39. Qf1 Qxf1+ 40. Kxf1 Nxe5 41. Ra8 Rxa8 42. bxa8=Q+ Bxa8 43. Kf2 Kg8 44. Ke3 Ng4+ 45. Kf4 Nxh2 46. g4 Nf3 47. Nf5 Kf7 48. Nd6+ Ke6 49. Ne8 g5+ 50. Kg3 Kf7 51. Nd6+ Kg6 52. Nf5 h5 53. Ne7+ Kf7 54. Nf5 h4+ 55. Kh3 Ng1+ 56. Kh2 Ne2 57. Kh3 Nf4+ 58. Kh2 Bf3 59. Ne3 Ke6 60. Kg1 Ke5 61. Kf2 Ke4 62. Nf5 Bxg4 63. Nd6+ Kd5 64. Nf7 Ne6 65. Kg2 Bh5 66. Nh6 Ke4 67. Kh3 Kf4 68. Ng8 Bg4+ 69. Kh2 Bf5 70. Nf6 g4 71. Nd5+ Kf3 72. Nf6 g3+ 73. Kg1 h3 74. Nh5 h2+ 75. Kh1 g2+ 76. Kxh2 Kf2 77. Ng3 g1=Q# 0-1 1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12.",
          "neutral_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "a4",
            "a5",
            "bxa5",
            "Rxa5",
            "b4",
            "Ra8",
            "a5",
            "Nbd7",
            "d4",
            "exd4",
            "Nxd4",
            "Bb7",
            "Nf5",
            "Re8",
            "Nxe7+",
            "Qxe7",
            "Bb2",
            "Ne5",
            "f4",
            "Nc6",
            "Bc3",
            "Ba6",
            "Ba4",
            "Bb7",
            "b5",
            "Nxa5",
            "Bxa5",
            "Rxa5",
            "b6",
            "c6",
            "Nc4",
            "Rc5",
            "Nxd6",
            "Rd8",
            "e5",
            "Nd5",
            "Qd4",
            "Ra5",
            "Bxc6",
            "Rxa1",
            "Rxa1",
            "Bxc6",
            "Ra7",
            "Qh4",
            "g3",
            "Qh3",
            "b7",
            "Nxf4",
            "Qf2",
            "Nd3",
            "Qxf7+",
            "Kh8",
            "Qf1",
            "Qxf1+",
            "Kxf1",
            "Nxe5",
            "Ra8",
            "Rxa8",
            "bxa8=Q+",
            "Bxa8",
            "Kf2",
            "Kg8",
            "Ke3",
            "Ng4+",
            "Kf4",
            "Nxh2",
            "g4",
            "Nf3",
            "Nf5",
            "Kf7",
            "Nd6+",
            "Ke6",
            "Ne8",
            "g5+",
            "Kg3",
            "Kf7",
            "Nd6+",
            "Kg6",
            "Nf5",
            "h5",
            "Ne7+",
            "Kf7",
            "Nf5",
            "h4+",
            "Kh3",
            "Ng1+",
            "Kh2",
            "Ne2",
            "Kh3",
            "Nf4+",
            "Kh2",
            "Bf3",
            "Ne3",
            "Ke6",
            "Kg1",
            "Ke5",
            "Kf2",
            "Ke4",
            "Nf5",
            "Bxg4",
            "Nd6+",
            "Kd5",
            "Nf7",
            "Ne6",
            "Kg2",
            "Bh5",
            "Nh6",
            "Ke4",
            "Kh3",
            "Kf4",
            "Ng8",
            "Bg4+",
            "Kh2",
            "Bf5",
            "Nf6",
            "g4",
            "Nd5+",
            "Kf3",
            "Nf6",
            "g3+",
            "Kg1",
            "h3",
            "Nh5",
            "h2+",
            "Kh1",
            "g2+",
            "Kxh2",
            "Kf2",
            "Ng3",
            "g1=Q#",
            "e4",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "Na5",
            "Bc2",
            "Nc4",
            "d3",
            "Nb6",
            "Nbd2",
            "b4"
          ],
          "plan_execute": [
            "O-O",
            "a4",
            "a5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c3b4",
          "positional_uci": "c3b4",
          "neutral_uci": "c3b4",
          "consensus_move": "c3b4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "exd5",
              "Nfxd5",
              "Rxe5",
              "Nxb4",
              "Bb3+",
              "Kh8",
              "Qe2",
              "Bf6",
              "Re4",
              "Nxd3",
              "Be3",
              "Nxb2",
              "Rb1",
              "Nd3",
              "Rd1",
              "Qd6",
              "Rxd3",
              "Qc6",
              "Bxb6",
              "cxb6",
              "Bd5",
              "Qc1+",
              "Rd1",
              "Qc5",
              "Bxa8",
              "Rxa8",
              "Re8+",
              "Rxe8",
              "Qxe8+",
              "Qf8",
              "Qxf8#",
              "e5",
              "d4",
              "Bc5",
              "Bb6"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "exd5",
              "Nfxd5",
              "Rxe5",
              "Nxb4",
              "Bb3+",
              "Kh8",
              "Qe2",
              "Bf6",
              "Re4",
              "Nxd3",
              "Be3",
              "Nxb2",
              "Rb1",
              "Nd3",
              "Rd1",
              "Nc5",
              "Rxd8",
              "Raxd8",
              "Bxc5",
              "Nd7",
              "Bxf8",
              "Rxf8",
              "Re8",
              "h6",
              "Rxf8+",
              "Nxf8",
              "Qe8",
              "Kh7",
              "Qxf8",
              "g5",
              "Bc2+",
              "g6",
              "Qf7+",
              "Bg7",
              "Bxg6+",
              "Kh8",
              "Qe8+",
              "Bf8",
              "Qxf8#",
              "e4",
              "Nc6",
              "Nc4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "a4",
              "a5",
              "bxa5",
              "Rxa5",
              "b4",
              "Ra8",
              "a5",
              "Nbd7",
              "d4",
              "exd4",
              "Nxd4",
              "Bb7",
              "Nf5",
              "Re8",
              "Nxe7+",
              "Qxe7",
              "Bb2",
              "Ne5",
              "f4",
              "Nc6",
              "Bc3",
              "Ba6",
              "Ba4",
              "Bb7",
              "b5",
              "Nxa5",
              "Bxa5",
              "Rxa5",
              "b6",
              "c6",
              "Nc4",
              "Rc5",
              "Nxd6",
              "Rd8",
              "e5",
              "Nd5",
              "Qd4",
              "Ra5",
              "Bxc6",
              "Rxa1",
              "Rxa1",
              "Bxc6",
              "Ra7",
              "Qh4",
              "g3",
              "Qh3",
              "b7",
              "Nxf4",
              "Qf2",
              "Nd3",
              "Qxf7+",
              "Kh8",
              "Qf1",
              "Qxf1+",
              "Kxf1",
              "Nxe5",
              "Ra8",
              "Rxa8",
              "bxa8=Q+",
              "Bxa8",
              "Kf2",
              "Kg8",
              "Ke3",
              "Ng4+",
              "Kf4",
              "Nxh2",
              "g4",
              "Nf3",
              "Nf5",
              "Kf7",
              "Nd6+",
              "Ke6",
              "Ne8",
              "g5+",
              "Kg3",
              "Kf7",
              "Nd6+",
              "Kg6",
              "Nf5",
              "h5",
              "Ne7+",
              "Kf7",
              "Nf5",
              "h4+",
              "Kh3",
              "Ng1+",
              "Kh2",
              "Ne2",
              "Kh3",
              "Nf4+",
              "Kh2",
              "Bf3",
              "Ne3",
              "Ke6",
              "Kg1",
              "Ke5",
              "Kf2",
              "Ke4",
              "Nf5",
              "Bxg4",
              "Nd6+",
              "Kd5",
              "Nf7",
              "Ne6",
              "Kg2",
              "Bh5",
              "Nh6",
              "Ke4",
              "Kh3",
              "Kf4",
              "Ng8",
              "Bg4+",
              "Kh2",
              "Bf5",
              "Nf6",
              "g4",
              "Nd5+",
              "Kf3",
              "Nf6",
              "g3+",
              "Kg1",
              "h3",
              "Nh5",
              "h2+",
              "Kh1",
              "g2+",
              "Kxh2",
              "Kf2",
              "Ng3",
              "g1=Q#",
              "e4",
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "Na5",
              "Bc2",
              "Nc4",
              "d3",
              "Nb6",
              "Nbd2",
              "b4"
            ],
            "execute": [
              "O-O",
              "a4",
              "a5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "Nf1",
            "Bg4"
          ],
          "full_moves": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Qd6",
            "Rxd3",
            "Qc6",
            "Bxb6",
            "cxb6",
            "Bd5",
            "Qc1+",
            "Rd1",
            "Qc5",
            "Bxa8",
            "Rxa8",
            "Re8+",
            "Rxe8",
            "Qxe8+",
            "Qf8",
            "Qxf8#",
            "e5",
            "d4",
            "Bc5",
            "Bb6"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 195,
            "completion_tokens": 198,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 584,
          "total_completion_tokens": 1478,
          "total_tokens": 2062
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 195,
            "completion_tokens": 198,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/pn1p1n2/4p3/1p2P3/2PP1N2/PPBN1PPP/R1BQR1K1 w kq - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "bxa5",
          "aggressive_uci": "b4a5",
          "aggressive_response": "13. bxa5 Rxa5 14. b4 Ra8 15. a4 O-O 16. a5 Nbd7 17. d4 exd4 18. Nxd4 Bb7 19. Nf5 Ne5 20. f4 Nc6 21. Rb1 g6 22. Nxe7+ Qxe7 23. Nf3 Rfe8 24. Bd2 Qd7 25. Bc3 Nh5 26. Qd2 Qg4 27. f5 Nf4 28. Kh1 Ne5 29. Nxe5 dxe5 30. Qf2 Rad8 31. Re3 Nh5 32. h3 Qf4 33. Rf3 Qg5 34. fxg6 fxg6 35. Bb3+ Kh8 36. Rf8+ Rxf8 37. Qxf8+ Rxf8 38. Bxe5+ Qxe5 39. g4 Qxe4+ 40. Kh2 Qg2# e4 Nf3+ Kh1 Qh2#",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 250,
            "total_tokens": 453,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxa5",
            "b4",
            "Ra8",
            "a4",
            "O-O",
            "a5",
            "Nbd7",
            "d4",
            "exd4",
            "Nxd4",
            "Bb7",
            "Nf5",
            "Ne5",
            "f4",
            "Nc6",
            "Rb1",
            "g6",
            "Nxe7+",
            "Qxe7",
            "Nf3",
            "Rfe8",
            "Bd2",
            "Qd7",
            "Bc3",
            "Nh5",
            "Qd2",
            "Qg4",
            "f5",
            "Nf4",
            "Kh1",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Qf2",
            "Rad8",
            "Re3",
            "Nh5",
            "h3",
            "Qf4",
            "Rf3",
            "Qg5",
            "fxg6",
            "fxg6",
            "Bb3+",
            "Kh8",
            "Rf8+",
            "Rxf8",
            "Qxf8+",
            "Rxf8",
            "Bxe5+",
            "Qxe5",
            "g4",
            "Qxe4+",
            "Kh2",
            "Qg2#",
            "e4",
            "Nf3+",
            "Kh1",
            "Qh2#"
          ],
          "plan_execute": [
            "Rxa5",
            "b4",
            "Ra8"
          ]
        },
        "query2": {
          "positional_move": "bxa5",
          "positional_uci": "b4a5",
          "positional_response": "13. bxa5 Rxa5 14. Nb3 Ra8 15. d4 exd4 16. Nbxd4 Bb7 17. Nf5 O-O 18. Bg5 h6 19. Bh4 g5 20. Nxh6+ Kh7 21. Bxg5 Ng8 22. e5+ Kg7 23. Nf5+ Kh8 24. Nxe7 Nxe7 25. Bf6+ Kg8 26. Ng5 Ng6 27. Qh5 Re8 28. Qh7+ Kf8 29. Qg7# e4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxh6+",
            "Kh7",
            "Bxg5",
            "Ng8",
            "e5+",
            "Kg7",
            "Nf5+",
            "Kh8",
            "Nxe7",
            "Nxe7",
            "Bf6+",
            "Kg8",
            "Ng5",
            "Ng6",
            "Qh5",
            "Re8",
            "Qh7+",
            "Kf8",
            "Qg7#",
            "e4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4"
          ],
          "plan_execute": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ]
        },
        "query3": {
          "neutral_move": "bxa5",
          "neutral_uci": "b4a5",
          "neutral_response": "13. bxa5 Rxa5 14. b4 Ra8 15. a4 O-O 16. a5 Nbd7 17. d4 exd4 18. Nxd4 Ne5 19. f4 Ng6 20. Nc6 Qd7 21. Nxe7+ Qxe7 22. Nf3 Bg4 23. h3 Bxf3 24. Qxf3 d5 25. e5 Qxb4 26. Ba3 Qd4+ 27. Kh1 Ne4 28. Bxf8 Rxf8 29. Bxe4 dxe4 30. Qxe4 Qxe4 31. Rxe4 Ra8 32. a6 Ne7 33. Rc4 c6 34. a7 Kf8 35. Rb4 Nc8 36. Rb8 Rxa7 37. Rxc8+ Ke7 38. Rxa7+ Ke6 39. Rxc6+ Kf5 40. Rxf7+ Ke4 41. e6 Kd5 42. Ra6 g5 43. e7 gxf4 44. e8=Q f3 45. Rd7+ Kc5 46. Qc8+ Kb5 47. Rb7+ Kxa6 48. Qa8# e4 d5 e6 dxe6",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 310,
            "total_tokens": 512,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxa5",
            "b4",
            "Ra8",
            "a4",
            "O-O",
            "a5",
            "Nbd7",
            "d4",
            "exd4",
            "Nxd4",
            "Ne5",
            "f4",
            "Ng6",
            "Nc6",
            "Qd7",
            "Nxe7+",
            "Qxe7",
            "Nf3",
            "Bg4",
            "h3",
            "Bxf3",
            "Qxf3",
            "d5",
            "e5",
            "Qxb4",
            "Ba3",
            "Qd4+",
            "Kh1",
            "Ne4",
            "Bxf8",
            "Rxf8",
            "Bxe4",
            "dxe4",
            "Qxe4",
            "Qxe4",
            "Rxe4",
            "Ra8",
            "a6",
            "Ne7",
            "Rc4",
            "c6",
            "a7",
            "Kf8",
            "Rb4",
            "Nc8",
            "Rb8",
            "Rxa7",
            "Rxc8+",
            "Ke7",
            "Rxa7+",
            "Ke6",
            "Rxc6+",
            "Kf5",
            "Rxf7+",
            "Ke4",
            "e6",
            "Kd5",
            "Ra6",
            "g5",
            "e7",
            "gxf4",
            "e8=Q",
            "f3",
            "Rd7+",
            "Kc5",
            "Qc8+",
            "Kb5",
            "Rb7+",
            "Kxa6",
            "Qa8#",
            "e4",
            "d5",
            "e6",
            "dxe6"
          ],
          "plan_execute": [
            "Rxa5",
            "b4",
            "Ra8"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b4a5",
          "positional_uci": "b4a5",
          "neutral_uci": "b4a5",
          "consensus_move": "b4a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxa5",
              "b4",
              "Ra8",
              "a4",
              "O-O",
              "a5",
              "Nbd7",
              "d4",
              "exd4",
              "Nxd4",
              "Bb7",
              "Nf5",
              "Ne5",
              "f4",
              "Nc6",
              "Rb1",
              "g6",
              "Nxe7+",
              "Qxe7",
              "Nf3",
              "Rfe8",
              "Bd2",
              "Qd7",
              "Bc3",
              "Nh5",
              "Qd2",
              "Qg4",
              "f5",
              "Nf4",
              "Kh1",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Qf2",
              "Rad8",
              "Re3",
              "Nh5",
              "h3",
              "Qf4",
              "Rf3",
              "Qg5",
              "fxg6",
              "fxg6",
              "Bb3+",
              "Kh8",
              "Rf8+",
              "Rxf8",
              "Qxf8+",
              "Rxf8",
              "Bxe5+",
              "Qxe5",
              "g4",
              "Qxe4+",
              "Kh2",
              "Qg2#",
              "e4",
              "Nf3+",
              "Kh1",
              "Qh2#"
            ],
            "execute": [
              "Rxa5",
              "b4",
              "Ra8"
            ]
          },
          "positional": {
            "full": [
              "Rxa5",
              "Nb3",
              "Ra8",
              "d4",
              "exd4",
              "Nbxd4",
              "Bb7",
              "Nf5",
              "O-O",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxh6+",
              "Kh7",
              "Bxg5",
              "Ng8",
              "e5+",
              "Kg7",
              "Nf5+",
              "Kh8",
              "Nxe7",
              "Nxe7",
              "Bf6+",
              "Kg8",
              "Ng5",
              "Ng6",
              "Qh5",
              "Re8",
              "Qh7+",
              "Kf8",
              "Qg7#",
              "e4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4"
            ],
            "execute": [
              "Rxa5",
              "Nb3",
              "Ra8"
            ]
          },
          "neutral": {
            "full": [
              "Rxa5",
              "b4",
              "Ra8",
              "a4",
              "O-O",
              "a5",
              "Nbd7",
              "d4",
              "exd4",
              "Nxd4",
              "Ne5",
              "f4",
              "Ng6",
              "Nc6",
              "Qd7",
              "Nxe7+",
              "Qxe7",
              "Nf3",
              "Bg4",
              "h3",
              "Bxf3",
              "Qxf3",
              "d5",
              "e5",
              "Qxb4",
              "Ba3",
              "Qd4+",
              "Kh1",
              "Ne4",
              "Bxf8",
              "Rxf8",
              "Bxe4",
              "dxe4",
              "Qxe4",
              "Qxe4",
              "Rxe4",
              "Ra8",
              "a6",
              "Ne7",
              "Rc4",
              "c6",
              "a7",
              "Kf8",
              "Rb4",
              "Nc8",
              "Rb8",
              "Rxa7",
              "Rxc8+",
              "Ke7",
              "Rxa7+",
              "Ke6",
              "Rxc6+",
              "Kf5",
              "Rxf7+",
              "Ke4",
              "e6",
              "Kd5",
              "Ra6",
              "g5",
              "e7",
              "gxf4",
              "e8=Q",
              "f3",
              "Rd7+",
              "Kc5",
              "Qc8+",
              "Kb5",
              "Rb7+",
              "Kxa6",
              "Qa8#",
              "e4",
              "d5",
              "e6",
              "dxe6"
            ],
            "execute": [
              "Rxa5",
              "b4",
              "Ra8"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Rxa5",
            "b4",
            "Ra8"
          ],
          "full_moves": [
            "Rxa5",
            "b4",
            "Ra8",
            "a4",
            "O-O",
            "a5",
            "Nbd7",
            "d4",
            "exd4",
            "Nxd4",
            "Ne5",
            "f4",
            "Ng6",
            "Nc6",
            "Qd7",
            "Nxe7+",
            "Qxe7",
            "Nf3",
            "Bg4",
            "h3",
            "Bxf3",
            "Qxf3",
            "d5",
            "e5",
            "Qxb4",
            "Ba3",
            "Qd4+",
            "Kh1",
            "Ne4",
            "Bxf8",
            "Rxf8",
            "Bxe4",
            "dxe4",
            "Qxe4",
            "Qxe4",
            "Rxe4",
            "Ra8",
            "a6",
            "Ne7",
            "Rc4",
            "c6",
            "a7",
            "Kf8",
            "Rb4",
            "Nc8",
            "Rb8",
            "Rxa7",
            "Rxc8+",
            "Ke7",
            "Rxa7+",
            "Ke6",
            "Rxc6+",
            "Kf5",
            "Rxf7+",
            "Ke4",
            "e6",
            "Kd5",
            "Ra6",
            "g5",
            "e7",
            "gxf4",
            "e8=Q",
            "f3",
            "Rd7+",
            "Kc5",
            "Qc8+",
            "Kb5",
            "Rb7+",
            "Kxa6",
            "Qa8#",
            "e4",
            "d5",
            "e6",
            "dxe6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 250,
            "total_tokens": 453,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 310,
            "total_tokens": 512,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 1200,
          "total_tokens": 1808
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 250,
            "total_tokens": 453,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 310,
            "total_tokens": 512,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/p3p3/1P2P3/3P1N2/PPBN1PPP/R1BQR1K1 w kq - 0 13"
    }
  ],
  "black_responses": [
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6",
          "aggressive_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6 Nc3 Nf6",
          "positional_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6",
            "Nc3",
            "Nf6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6",
          "neutral_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6",
              "Nc3",
              "Nf6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf3",
            "Nc6",
            "Bc4"
          ],
          "full_moves": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 446,
          "total_completion_tokens": 78,
          "total_tokens": 524
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "1. e4 e5 2. Nf3 \nNc6 Bc4",
          "aggressive_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nNc6 Bc2",
          "positional_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2"
          ],
          "plan_execute": [
            "Bc2"
          ]
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "1. e4 e5 2. Nf3 \nNc6 Bc4",
          "neutral_tokens": {
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "Bc2"
            ],
            "execute": [
              "Bc2"
            ]
          },
          "neutral": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc4"
          ],
          "full_moves": [
            "Bc4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 470,
          "total_completion_tokens": 84,
          "total_tokens": 554
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 \nBc2 c5",
          "aggressive_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 52,
            "total_tokens": 218,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bc2",
            "c5"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 \nBa4",
          "positional_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Ba4"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 \nNf6 Bc4",
          "neutral_tokens": {
            "prompt_tokens": 165,
            "completion_tokens": 29,
            "total_tokens": 194,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "g8f6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bc2",
              "c5"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Ba4"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Ba4",
            "Nf6",
            "O-O"
          ],
          "full_moves": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bc2",
            "c5"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 166,
            "completion_tokens": 52,
            "total_tokens": 218,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 165,
            "completion_tokens": 29,
            "total_tokens": 194,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 497,
          "total_completion_tokens": 130,
          "total_tokens": 627
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 166,
            "completion_tokens": 52,
            "total_tokens": 218,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 165,
            "completion_tokens": 29,
            "total_tokens": 194,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 d3",
          "aggressive_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3"
          ],
          "plan_execute": [
            "d3"
          ]
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 Bc2 b5 a4 d6 \nis incorrect, the correct move order is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 \nnow it's Black's move: \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 Nd4 Na5 Nc3",
          "positional_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 126,
            "total_tokens": 299,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd4",
            "Na5",
            "Nc3"
          ],
          "plan_execute": [
            "Nd4",
            "Na5",
            "Nc3"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 d3 Bc5",
          "neutral_tokens": {
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Bc5"
          ],
          "plan_execute": [
            "d3",
            "Bc5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d3"
            ],
            "execute": [
              "d3"
            ]
          },
          "positional": {
            "full": [
              "Nd4",
              "Na5",
              "Nc3"
            ],
            "execute": [
              "Nd4",
              "Na5",
              "Nc3"
            ]
          },
          "neutral": {
            "full": [
              "d3",
              "Bc5"
            ],
            "execute": [
              "d3",
              "Bc5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "d3",
            "Bc5"
          ],
          "full_moves": [
            "d3",
            "Bc5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 173,
            "completion_tokens": 126,
            "total_tokens": 299,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 518,
          "total_completion_tokens": 197,
          "total_tokens": 715
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 173,
            "completion_tokens": 126,
            "total_tokens": 299,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 b5 Bb3",
          "aggressive_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 47,
            "total_tokens": 228,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "b5",
            "Bb3"
          ],
          "plan_execute": [
            "b3",
            "b5",
            "Bb3"
          ]
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 d6 Na3",
          "positional_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "d6",
            "Na3"
          ],
          "plan_execute": [
            "b3",
            "d6",
            "Na3"
          ]
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 b5 Bb3",
          "neutral_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "b5",
            "Bb3"
          ],
          "plan_execute": [
            "b3",
            "b5",
            "Bb3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b3",
              "b5",
              "Bb3"
            ],
            "execute": [
              "b3",
              "b5",
              "Bb3"
            ]
          },
          "positional": {
            "full": [
              "b3",
              "d6",
              "Na3"
            ],
            "execute": [
              "b3",
              "d6",
              "Na3"
            ]
          },
          "neutral": {
            "full": [
              "b3",
              "b5",
              "Bb3"
            ],
            "execute": [
              "b3",
              "b5",
              "Bb3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b3",
            "b5",
            "Bb3"
          ],
          "full_moves": [
            "b3",
            "b5",
            "Bb3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 181,
            "completion_tokens": 47,
            "total_tokens": 228,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 542,
          "total_completion_tokens": 140,
          "total_tokens": 682
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 181,
            "completion_tokens": 47,
            "total_tokens": 228,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 b kq - 3 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b5",
          "aggressive_uci": "b7b5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nNa3",
          "aggressive_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na3"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na3"
          ]
        },
        "query2": {
          "positional_move": "b5",
          "positional_uci": "b7b5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nis incorrect, the correct continuation is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 is incorrect \nThe correct move is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 \nThe next 4 moves are \nb5 Bc2 d6 Na5",
          "positional_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 178,
            "total_tokens": 366,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na5"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na5"
          ]
        },
        "query3": {
          "neutral_move": "b5",
          "neutral_uci": "b7b5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nis incorrect, the correct continuation is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 \nBlack to move: b5 Bc2 d6 Na5 Nxe5",
          "neutral_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 120,
            "total_tokens": 307,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na5",
            "Nxe5"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b7b5",
          "positional_uci": "b7b5",
          "neutral_uci": "b7b5",
          "consensus_move": "b7b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc2",
              "d6",
              "Na3"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na3"
            ]
          },
          "positional": {
            "full": [
              "Bc2",
              "d6",
              "Na5"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na5"
            ]
          },
          "neutral": {
            "full": [
              "Bc2",
              "d6",
              "Na5",
              "Nxe5"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc2",
            "d6",
            "Na5"
          ],
          "full_moves": [
            "Bc2",
            "d6",
            "Na5",
            "Nxe5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 188,
            "completion_tokens": 178,
            "total_tokens": 366,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 187,
            "completion_tokens": 120,
            "total_tokens": 307,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 563,
          "total_completion_tokens": 352,
          "total_tokens": 915
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 188,
            "completion_tokens": 178,
            "total_tokens": 366,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 187,
            "completion_tokens": 120,
            "total_tokens": 307,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQR1K1 b kq - 5 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d6",
          "aggressive_uci": "d7d6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "aggressive_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "query2": {
          "positional_move": "d6",
          "positional_uci": "d7d6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "positional_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "query3": {
          "neutral_move": "d6",
          "neutral_uci": "d7d6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "neutral_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d7d6",
          "positional_uci": "d7d6",
          "neutral_uci": "d7d6",
          "consensus_move": "d7d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          },
          "positional": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          },
          "neutral": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Na3"
          ],
          "full_moves": [
            "Na3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 587,
          "total_completion_tokens": 168,
          "total_tokens": 755
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2ppbppp/p1n2n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 b kq - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Na5",
          "aggressive_uci": "c6a5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5 Nbd2",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "plan_execute": [
            "Bc2",
            "c5",
            "Nbd2"
          ]
        },
        "query2": {
          "positional_move": "Na5",
          "positional_uci": "c6a5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5"
          ],
          "plan_execute": [
            "Bc2",
            "c5"
          ]
        },
        "query3": {
          "neutral_move": "Na5",
          "neutral_uci": "c6a5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5 Nbd2",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 69,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "plan_execute": [
            "Bc2",
            "c5",
            "Nbd2"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c6a5",
          "positional_uci": "c6a5",
          "neutral_uci": "c6a5",
          "consensus_move": "c6a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc2",
              "c5",
              "Nbd2"
            ],
            "execute": [
              "Bc2",
              "c5",
              "Nbd2"
            ]
          },
          "positional": {
            "full": [
              "Bc2",
              "c5"
            ],
            "execute": [
              "Bc2",
              "c5"
            ]
          },
          "neutral": {
            "full": [
              "Bc2",
              "c5",
              "Nbd2"
            ],
            "execute": [
              "Bc2",
              "c5",
              "Nbd2"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "full_moves": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 69,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 204,
          "total_tokens": 812
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 69,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 b kq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc4",
          "aggressive_uci": "a5c4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 b6 Qe2",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 75,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b6",
            "Qe2"
          ],
          "plan_execute": [
            "b6",
            "Qe2"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": "a5c4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 \nNc4 b3 Qe7",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 76,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Qe7"
          ],
          "plan_execute": [
            "b3",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Nc4",
          "neutral_uci": "a5c4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 \nNc4 b3 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 76,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Qe7"
          ],
          "plan_execute": [
            "b3",
            "Qe7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a5c4",
          "positional_uci": "a5c4",
          "neutral_uci": "a5c4",
          "consensus_move": "a5c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b6",
              "Qe2"
            ],
            "execute": [
              "b6",
              "Qe2"
            ]
          },
          "positional": {
            "full": [
              "b3",
              "Qe7"
            ],
            "execute": [
              "b3",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b3",
              "Qe7"
            ],
            "execute": [
              "b3",
              "Qe7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b3",
            "Qe7"
          ],
          "full_moves": [
            "b3",
            "Qe7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 75,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 76,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 76,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 227,
          "total_tokens": 862
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 75,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 76,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 76,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/np2p3/4P3/2P2N2/PPBP1PPP/RNBQR1K1 b kq - 2 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nb6",
          "aggressive_uci": "c4b6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a4 Qe7 \nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 86,
            "total_tokens": 306,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a4",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a4",
            "Qe7"
          ]
        },
        "query2": {
          "positional_move": "Nb6",
          "positional_uci": "c4b6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a5",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Nb6",
          "neutral_uci": "c4b6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a5 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a5",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a5",
            "Qe7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c4b6",
          "positional_uci": "c4b6",
          "neutral_uci": "c4b6",
          "consensus_move": "c4b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b4",
              "a4",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a4",
              "Qe7"
            ]
          },
          "positional": {
            "full": [
              "b4",
              "a5",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b4",
              "a5",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a5",
              "Qe7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b4",
            "a5",
            "Qe7"
          ],
          "full_moves": [
            "b4",
            "a5",
            "Qe7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 86,
            "total_tokens": 306,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 254,
          "total_tokens": 913
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 86,
            "total_tokens": 306,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2PP1N2/PPB2PPP/RNBQR1K1 b kq - 0 10"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 341,
          "total_tokens": 1072
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 26,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 341,
          "total_tokens": 1072
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 26,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nNc4 Qe7 Nbd4 Qe6",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Nbd4",
            "Qe6"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Nbd4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Nbd4",
              "Qe6"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Nbd4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 343,
          "total_tokens": 1074
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": null,
          "aggressive_response": "*e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6 Nc3 Nf6 Bg5 h6 Bh4 g5 Bg3 Qe7 Qd2",
          "aggressive_tokens": {
            "prompt_tokens": 145,
            "completion_tokens": 46,
            "total_tokens": 191,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6",
            "Nc3",
            "Nf6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Qe7",
            "Qd2"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "* \nWhite to move: e4 \nPlan: e5 Nf3 Nc6 Bc4",
          "positional_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 23,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bc4"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "There is no game to repeat. \nMove: e4\nPlan: e5, Nb1-c3, Nb8-c6, d2-d4",
          "neutral_tokens": {
            "prompt_tokens": 184,
            "completion_tokens": 33,
            "total_tokens": 217,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nb1",
            "c3",
            "Nb8",
            "c6",
            "d2",
            "d4"
          ],
          "plan_execute": [
            "e5",
            "Nb1",
            "c3"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6",
              "Nc3",
              "Nf6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Qe7",
              "Qd2"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bc4"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          },
          "neutral": {
            "full": [
              "e5",
              "Nb1",
              "c3",
              "Nb8",
              "c6",
              "d2",
              "d4"
            ],
            "execute": [
              "e5",
              "Nb1",
              "c3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e5",
            "Nb1",
            "c3"
          ],
          "full_moves": [
            "e5",
            "Nb1",
            "c3",
            "Nb8",
            "c6",
            "d2",
            "d4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 145,
            "completion_tokens": 46,
            "total_tokens": 191,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 185,
            "completion_tokens": 23,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 184,
            "completion_tokens": 33,
            "total_tokens": 217,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 514,
          "total_completion_tokens": 102,
          "total_tokens": 616
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 145,
            "completion_tokens": 46,
            "total_tokens": 191,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 185,
            "completion_tokens": 23,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 184,
            "completion_tokens": 33,
            "total_tokens": 217,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5\nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": [
            "e5"
          ]
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "1. e4 e5\n2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O \nWhite",
          "positional_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 63,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O"
          ],
          "plan_execute": [
            "Nc6",
            "Bb5",
            "a6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5\nWhite",
          "neutral_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": [
            "e5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g1f3",
          "neutral_uci": null,
          "consensus_move": "g1f3",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5"
            ],
            "execute": [
              "e5"
            ]
          },
          "positional": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O"
            ],
            "execute": [
              "Nc6",
              "Bb5",
              "a6"
            ]
          },
          "neutral": {
            "full": [
              "e5"
            ],
            "execute": [
              "e5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nc6",
            "Bb5",
            "a6"
          ],
          "full_moves": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O"
          ],
          "source_agent": "positional"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 151,
            "completion_tokens": 63,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 452,
          "total_completion_tokens": 81,
          "total_tokens": 533
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 151,
            "completion_tokens": 63,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc4",
          "aggressive_uci": "b5c4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 \nBc4 Nf6 d3 d6",
          "aggressive_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf6",
            "d3",
            "d6"
          ]
        },
        "query2": {
          "positional_move": "Bc4",
          "positional_uci": "b5c4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 \nBc4 Nf6 d3 d6",
          "positional_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf6",
            "d3",
            "d6"
          ]
        },
        "query3": {
          "neutral_move": "Bc4",
          "neutral_uci": "b5c4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 \nBc4 Nf6 d3 d6",
          "neutral_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 35,
            "total_tokens": 202,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf6",
            "d3",
            "d6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b5c4",
          "positional_uci": "b5c4",
          "neutral_uci": "b5c4",
          "consensus_move": "b5c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf6",
              "d3",
              "d6"
            ]
          },
          "positional": {
            "full": [
              "Nf6",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf6",
              "d3",
              "d6"
            ]
          },
          "neutral": {
            "full": [
              "Nf6",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf6",
              "d3",
              "d6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf6",
            "d3",
            "d6"
          ],
          "full_moves": [
            "Nf6",
            "d3",
            "d6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 167,
            "completion_tokens": 35,
            "total_tokens": 202,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 503,
          "total_completion_tokens": 105,
          "total_tokens": 608
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 167,
            "completion_tokens": 35,
            "total_tokens": 202,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd2",
          "aggressive_uci": "b1d2",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 \nNbd2 b5 Bb3 Na5 Nc3",
          "aggressive_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 55,
            "total_tokens": 240,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "Na5",
            "Nc3"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "Na5"
          ]
        },
        "query2": {
          "positional_move": "Nbd2",
          "positional_uci": "b1d2",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 \nNbd2 b5 Bb3 d6",
          "positional_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "d6"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "d6"
          ]
        },
        "query3": {
          "neutral_move": "Nbd2",
          "neutral_uci": "b1d2",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 \nNbd2 b5",
          "neutral_tokens": {
            "prompt_tokens": 184,
            "completion_tokens": 47,
            "total_tokens": 231,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b1d2",
          "positional_uci": "b1d2",
          "neutral_uci": "b1d2",
          "consensus_move": "b1d2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5",
              "Bb3",
              "Na5",
              "Nc3"
            ],
            "execute": [
              "b5",
              "Bb3",
              "Na5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Bb3",
              "d6"
            ],
            "execute": [
              "b5",
              "Bb3",
              "d6"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b5"
          ],
          "full_moves": [
            "b5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 185,
            "completion_tokens": 55,
            "total_tokens": 240,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 184,
            "completion_tokens": 47,
            "total_tokens": 231,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 554,
          "total_completion_tokens": 154,
          "total_tokens": 708
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 185,
            "completion_tokens": 55,
            "total_tokens": 240,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 184,
            "completion_tokens": 47,
            "total_tokens": 231,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPP2PPP/RNBQK2R w KQkq - 1 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nNc4 b5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Qe7"
          ],
          "plan_execute": [
            "b5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Qe7"
            ],
            "execute": [
              "b5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 168,
          "total_tokens": 746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7"
    },
    {
      "turn": 13,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nNc4 b5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Qe7"
          ],
          "plan_execute": [
            "b5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Qe7"
            ],
            "execute": [
              "b5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 168,
          "total_tokens": 746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7"
    },
    {
      "turn": 13,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nNc4 b5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Qe7"
          ],
          "plan_execute": [
            "b5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Qe7"
            ],
            "execute": [
              "b5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 168,
          "total_tokens": 746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6",
          "aggressive_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6 Nc3 Nf6",
          "positional_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6",
            "Nc3",
            "Nf6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6",
          "neutral_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6",
              "Nc3",
              "Nf6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf3",
            "Nc6",
            "Bc4"
          ],
          "full_moves": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 446,
          "total_completion_tokens": 78,
          "total_tokens": 524
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "1. e4 e5 2. Nf3 \nNc6 Bc4",
          "aggressive_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nNc6 Bc2",
          "positional_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2"
          ],
          "plan_execute": [
            "Bc2"
          ]
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "1. e4 e5 2. Nf3 \nNc6 Bc4",
          "neutral_tokens": {
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "Bc2"
            ],
            "execute": [
              "Bc2"
            ]
          },
          "neutral": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc4"
          ],
          "full_moves": [
            "Bc4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 470,
          "total_completion_tokens": 84,
          "total_tokens": 554
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 \nNbd2 Bc5",
          "aggressive_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 53,
            "total_tokens": 219,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Nbd2",
            "Bc5"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 \nBa4",
          "positional_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Ba4"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 \nNf6 Bd3",
          "neutral_tokens": {
            "prompt_tokens": 165,
            "completion_tokens": 28,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3"
          ],
          "plan_execute": [
            "Bd3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "g8f6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Nbd2",
              "Bc5"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Ba4"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Bd3"
            ],
            "execute": [
              "Bd3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Ba4",
            "Nf6",
            "O-O"
          ],
          "full_moves": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Nbd2",
            "Bc5"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 166,
            "completion_tokens": 53,
            "total_tokens": 219,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 165,
            "completion_tokens": 28,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 497,
          "total_completion_tokens": 130,
          "total_tokens": 627
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 166,
            "completion_tokens": 53,
            "total_tokens": 219,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 165,
            "completion_tokens": 28,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 d3",
          "aggressive_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3"
          ],
          "plan_execute": [
            "d3"
          ]
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 b3 Bd6 \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 b3 Bd6 O-O Na5",
          "positional_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 76,
            "total_tokens": 249,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Bd6",
            "O-O",
            "Na5"
          ],
          "plan_execute": [
            "b3",
            "Bd6",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 d3 Bc5",
          "neutral_tokens": {
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Bc5"
          ],
          "plan_execute": [
            "d3",
            "Bc5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d3"
            ],
            "execute": [
              "d3"
            ]
          },
          "positional": {
            "full": [
              "b3",
              "Bd6",
              "O-O",
              "Na5"
            ],
            "execute": [
              "b3",
              "Bd6",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "d3",
              "Bc5"
            ],
            "execute": [
              "d3",
              "Bc5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "d3",
            "Bc5"
          ],
          "full_moves": [
            "d3",
            "Bc5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 173,
            "completion_tokens": 76,
            "total_tokens": 249,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 518,
          "total_completion_tokens": 147,
          "total_tokens": 665
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 173,
            "completion_tokens": 76,
            "total_tokens": 249,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 d6 Na3 Qe7",
          "aggressive_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 49,
            "total_tokens": 230,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "d6",
            "Na3",
            "Qe7"
          ],
          "plan_execute": [
            "b3",
            "d6",
            "Na3"
          ]
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 d6 Na3",
          "positional_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "d6",
            "Na3"
          ],
          "plan_execute": [
            "b3",
            "d6",
            "Na3"
          ]
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 b5 Bb3",
          "neutral_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "b5",
            "Bb3"
          ],
          "plan_execute": [
            "b3",
            "b5",
            "Bb3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b3",
              "d6",
              "Na3",
              "Qe7"
            ],
            "execute": [
              "b3",
              "d6",
              "Na3"
            ]
          },
          "positional": {
            "full": [
              "b3",
              "d6",
              "Na3"
            ],
            "execute": [
              "b3",
              "d6",
              "Na3"
            ]
          },
          "neutral": {
            "full": [
              "b3",
              "b5",
              "Bb3"
            ],
            "execute": [
              "b3",
              "b5",
              "Bb3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b3",
            "d6",
            "Na3"
          ],
          "full_moves": [
            "b3",
            "d6",
            "Na3",
            "Qe7"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 181,
            "completion_tokens": 49,
            "total_tokens": 230,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 542,
          "total_completion_tokens": 142,
          "total_tokens": 684
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 181,
            "completion_tokens": 49,
            "total_tokens": 230,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 b kq - 3 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b5",
          "aggressive_uci": "b7b5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nNa3",
          "aggressive_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na3"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na3"
          ]
        },
        "query2": {
          "positional_move": "b5",
          "positional_uci": "b7b5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nis incorrect, the correct continuation is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 is incorrect \nThe correct move is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 \nThe next 4 moves are \nb5 Bc2 d6 Na5",
          "positional_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 178,
            "total_tokens": 366,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na5"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na5"
          ]
        },
        "query3": {
          "neutral_move": "b5",
          "neutral_uci": "b7b5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nis incorrect, the correct continuation is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 \nBlack to move: b5 Bc2 d6 Na5 Nxe5",
          "neutral_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 120,
            "total_tokens": 307,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na5",
            "Nxe5"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b7b5",
          "positional_uci": "b7b5",
          "neutral_uci": "b7b5",
          "consensus_move": "b7b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc2",
              "d6",
              "Na3"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na3"
            ]
          },
          "positional": {
            "full": [
              "Bc2",
              "d6",
              "Na5"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na5"
            ]
          },
          "neutral": {
            "full": [
              "Bc2",
              "d6",
              "Na5",
              "Nxe5"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc2",
            "d6",
            "Na5"
          ],
          "full_moves": [
            "Bc2",
            "d6",
            "Na5",
            "Nxe5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 188,
            "completion_tokens": 178,
            "total_tokens": 366,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 187,
            "completion_tokens": 120,
            "total_tokens": 307,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 563,
          "total_completion_tokens": 352,
          "total_tokens": 915
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 188,
            "completion_tokens": 178,
            "total_tokens": 366,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 187,
            "completion_tokens": 120,
            "total_tokens": 307,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQR1K1 b kq - 5 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d6",
          "aggressive_uci": "d7d6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3 Na5 Nc4 Qe7",
          "aggressive_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 64,
            "total_tokens": 260,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3",
            "Na5",
            "Nc4",
            "Qe7"
          ],
          "plan_execute": [
            "Na3",
            "Na5",
            "Nc4"
          ]
        },
        "query2": {
          "positional_move": "d6",
          "positional_uci": "d7d6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "positional_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "query3": {
          "neutral_move": "d6",
          "neutral_uci": "d7d6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "neutral_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d7d6",
          "positional_uci": "d7d6",
          "neutral_uci": "d7d6",
          "consensus_move": "d7d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Na3",
              "Na5",
              "Nc4",
              "Qe7"
            ],
            "execute": [
              "Na3",
              "Na5",
              "Nc4"
            ]
          },
          "positional": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          },
          "neutral": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Na3"
          ],
          "full_moves": [
            "Na3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 196,
            "completion_tokens": 64,
            "total_tokens": 260,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 587,
          "total_completion_tokens": 176,
          "total_tokens": 763
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 196,
            "completion_tokens": 64,
            "total_tokens": 260,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2ppbppp/p1n2n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 b kq - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Na5",
          "aggressive_uci": "c6a5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5 Nbd2",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "plan_execute": [
            "Bc2",
            "c5",
            "Nbd2"
          ]
        },
        "query2": {
          "positional_move": "Na5",
          "positional_uci": "c6a5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5"
          ],
          "plan_execute": [
            "Bc2",
            "c5"
          ]
        },
        "query3": {
          "neutral_move": "Na5",
          "neutral_uci": "c6a5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Nc4 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 67,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c6a5",
          "positional_uci": "c6a5",
          "neutral_uci": "c6a5",
          "consensus_move": "c6a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc2",
              "c5",
              "Nbd2"
            ],
            "execute": [
              "Bc2",
              "c5",
              "Nbd2"
            ]
          },
          "positional": {
            "full": [
              "Bc2",
              "c5"
            ],
            "execute": [
              "Bc2",
              "c5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7"
            ],
            "execute": [
              "Nc4",
              "Qe7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nc4",
            "Qe7"
          ],
          "full_moves": [
            "Nc4",
            "Qe7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 67,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 202,
          "total_tokens": 810
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 67,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 b kq - 0 8"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nb6",
          "aggressive_uci": "c4b6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a4 Qe7 \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a4 Qe7 Nbd7",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 171,
            "total_tokens": 391,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a4",
            "Qe7",
            "Nbd7"
          ],
          "plan_execute": [
            "b4",
            "a4",
            "Qe7"
          ]
        },
        "query2": {
          "positional_move": "Nb6",
          "positional_uci": "c4b6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a5",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Nb6",
          "neutral_uci": "c4b6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a5 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a5",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a5",
            "Qe7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c4b6",
          "positional_uci": "c4b6",
          "neutral_uci": "c4b6",
          "consensus_move": "c4b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b4",
              "a4",
              "Qe7",
              "Nbd7"
            ],
            "execute": [
              "b4",
              "a4",
              "Qe7"
            ]
          },
          "positional": {
            "full": [
              "b4",
              "a5",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b4",
              "a5",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a5",
              "Qe7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b4",
            "a5",
            "Qe7"
          ],
          "full_moves": [
            "b4",
            "a5",
            "Qe7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 171,
            "total_tokens": 391,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 339,
          "total_tokens": 998
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 171,
            "total_tokens": 391,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2PP1N2/PPB2PPP/RNBQR1K1 b kq - 0 10"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 341,
          "total_tokens": 1072
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 26,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nNc4 Qe7 Nbd4 Qe6",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Nbd4",
            "Qe6"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Nbd4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Nbd4",
              "Qe6"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Nbd4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 343,
          "total_tokens": 1074
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 26,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 341,
          "total_tokens": 1072
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": null,
          "aggressive_response": "*e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6 Nc3 Nf6 Bg5 h6 Bh4 g5 Bg3 Qe7 Qd2",
          "aggressive_tokens": {
            "prompt_tokens": 145,
            "completion_tokens": 46,
            "total_tokens": 191,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6",
            "Nc3",
            "Nf6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Qe7",
            "Qd2"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "* \nNone \nMove: e4\nPlan: e5 Nf3 Nc6 Bc4",
          "positional_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 23,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bc4"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "There is no game to repeat. \nMove: e4\nPlan: e5, Nb1-c3, Nb8-c6, d2-d4",
          "neutral_tokens": {
            "prompt_tokens": 184,
            "completion_tokens": 33,
            "total_tokens": 217,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nb1",
            "c3",
            "Nb8",
            "c6",
            "d2",
            "d4"
          ],
          "plan_execute": [
            "e5",
            "Nb1",
            "c3"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6",
              "Nc3",
              "Nf6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Qe7",
              "Qd2"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bc4"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          },
          "neutral": {
            "full": [
              "e5",
              "Nb1",
              "c3",
              "Nb8",
              "c6",
              "d2",
              "d4"
            ],
            "execute": [
              "e5",
              "Nb1",
              "c3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e5",
            "Nb1",
            "c3"
          ],
          "full_moves": [
            "e5",
            "Nb1",
            "c3",
            "Nb8",
            "c6",
            "d2",
            "d4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 145,
            "completion_tokens": 46,
            "total_tokens": 191,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 185,
            "completion_tokens": 23,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 184,
            "completion_tokens": 33,
            "total_tokens": 217,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 514,
          "total_completion_tokens": 102,
          "total_tokens": 616
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 145,
            "completion_tokens": 46,
            "total_tokens": 191,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 185,
            "completion_tokens": 23,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 184,
            "completion_tokens": 33,
            "total_tokens": 217,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5\nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": [
            "e5"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": null,
          "positional_response": "1. e4 e5\nWhite",
          "positional_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": [
            "e5"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5\nWhite",
          "neutral_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": [
            "e5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5"
            ],
            "execute": [
              "e5"
            ]
          },
          "positional": {
            "full": [
              "e5"
            ],
            "execute": [
              "e5"
            ]
          },
          "neutral": {
            "full": [
              "e5"
            ],
            "execute": [
              "e5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 452,
          "total_completion_tokens": 27,
          "total_tokens": 479
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 3,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5\nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": [
            "e5"
          ]
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "1. e4 e5\n2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O \nWhite",
          "positional_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 63,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O"
          ],
          "plan_execute": [
            "Nc6",
            "Bb5",
            "a6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5\nWhite",
          "neutral_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": [
            "e5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g1f3",
          "neutral_uci": null,
          "consensus_move": "g1f3",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5"
            ],
            "execute": [
              "e5"
            ]
          },
          "positional": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O"
            ],
            "execute": [
              "Nc6",
              "Bb5",
              "a6"
            ]
          },
          "neutral": {
            "full": [
              "e5"
            ],
            "execute": [
              "e5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nc6",
            "Bb5",
            "a6"
          ],
          "full_moves": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O"
          ],
          "source_agent": "positional"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 151,
            "completion_tokens": 63,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 452,
          "total_completion_tokens": 81,
          "total_tokens": 533
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 151,
            "completion_tokens": 63,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc4",
          "aggressive_uci": "b5c4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 \nBc4 Nf6 d3 d6",
          "aggressive_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf6",
            "d3",
            "d6"
          ]
        },
        "query2": {
          "positional_move": "Bc4",
          "positional_uci": "b5c4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 \nBc4 Nf6 d3 d6",
          "positional_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf6",
            "d3",
            "d6"
          ]
        },
        "query3": {
          "neutral_move": "Bc4",
          "neutral_uci": "b5c4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 \nBc4 Nf6 d3 d6",
          "neutral_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 35,
            "total_tokens": 202,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf6",
            "d3",
            "d6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b5c4",
          "positional_uci": "b5c4",
          "neutral_uci": "b5c4",
          "consensus_move": "b5c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf6",
              "d3",
              "d6"
            ]
          },
          "positional": {
            "full": [
              "Nf6",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf6",
              "d3",
              "d6"
            ]
          },
          "neutral": {
            "full": [
              "Nf6",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf6",
              "d3",
              "d6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf6",
            "d3",
            "d6"
          ],
          "full_moves": [
            "Nf6",
            "d3",
            "d6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 167,
            "completion_tokens": 35,
            "total_tokens": 202,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 503,
          "total_completion_tokens": 105,
          "total_tokens": 608
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 167,
            "completion_tokens": 35,
            "total_tokens": 202,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd2",
          "aggressive_uci": "b1d2",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 \nNbd2 b5 Bb3 d6",
          "aggressive_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "d6"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "d6"
          ]
        },
        "query2": {
          "positional_move": "Nbd2",
          "positional_uci": "b1d2",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 \nNbd2 b5 Bb3 d6",
          "positional_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "d6"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "d6"
          ]
        },
        "query3": {
          "neutral_move": "Nbd2",
          "neutral_uci": "b1d2",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 \nNbd2 b5",
          "neutral_tokens": {
            "prompt_tokens": 184,
            "completion_tokens": 47,
            "total_tokens": 231,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b1d2",
          "positional_uci": "b1d2",
          "neutral_uci": "b1d2",
          "consensus_move": "b1d2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5",
              "Bb3",
              "d6"
            ],
            "execute": [
              "b5",
              "Bb3",
              "d6"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Bb3",
              "d6"
            ],
            "execute": [
              "b5",
              "Bb3",
              "d6"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b5",
            "Bb3",
            "d6"
          ],
          "full_moves": [
            "b5",
            "Bb3",
            "d6"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 184,
            "completion_tokens": 47,
            "total_tokens": 231,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 554,
          "total_completion_tokens": 151,
          "total_tokens": 705
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 184,
            "completion_tokens": 47,
            "total_tokens": 231,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPP2PPP/RNBQK2R w KQkq - 1 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nNc4 b5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Qe7"
          ],
          "plan_execute": [
            "b5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Qe7"
            ],
            "execute": [
              "b5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 168,
          "total_tokens": 746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7"
    },
    {
      "turn": 13,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nNc4 b5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Qe7"
          ],
          "plan_execute": [
            "b5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Qe7"
            ],
            "execute": [
              "b5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 168,
          "total_tokens": 746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7"
    },
    {
      "turn": 13,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nNc4 b5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Qe7"
          ],
          "plan_execute": [
            "b5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Qe7"
            ],
            "execute": [
              "b5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 168,
          "total_tokens": 746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "1. d4 \nd5",
          "aggressive_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d5",
          "positional_uci": "d7d5",
          "positional_response": "1. d4 \nd5",
          "positional_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d5",
          "neutral_uci": "d7d5",
          "neutral_response": "1. d4 \nd5",
          "neutral_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 8,
            "total_tokens": 156,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": "d7d5",
          "neutral_uci": "d7d5",
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 148,
            "completion_tokens": 8,
            "total_tokens": 156,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 446,
          "total_completion_tokens": 24,
          "total_tokens": 470
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 148,
            "completion_tokens": 8,
            "total_tokens": 156,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 c6 4. e3 Be7 5. Nf3 \nNf6 Bf4",
          "aggressive_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bf4"
          ],
          "plan_execute": [
            "Bf4"
          ]
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. d4 d5 2. Nc3 \nNf6 e3",
          "positional_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 19,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e3"
          ],
          "plan_execute": [
            "e3"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. d4 d5 2. Nc3 \nNf6 e3",
          "neutral_tokens": {
            "prompt_tokens": 156,
            "completion_tokens": 19,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e3"
          ],
          "plan_execute": [
            "e3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bf4"
            ],
            "execute": [
              "Bf4"
            ]
          },
          "positional": {
            "full": [
              "e3"
            ],
            "execute": [
              "e3"
            ]
          },
          "neutral": {
            "full": [
              "e3"
            ],
            "execute": [
              "e3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e3"
          ],
          "full_moves": [
            "e3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 157,
            "completion_tokens": 19,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 156,
            "completion_tokens": 19,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 470,
          "total_completion_tokens": 82,
          "total_tokens": 552
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 157,
            "completion_tokens": 19,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 156,
            "completion_tokens": 19,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/3P4/2N5/PPP1PPPP/R1BQKBNR b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "h6",
          "aggressive_uci": "h7h6",
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bh4 g5 5. Bg3 Nh5 6. e3 \ne6",
          "aggressive_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 47,
            "total_tokens": 213,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "g5",
            "Bg3",
            "Nh5",
            "e3",
            "e6"
          ],
          "plan_execute": [
            "Bh4",
            "g5",
            "Bg3"
          ]
        },
        "query2": {
          "positional_move": "h6",
          "positional_uci": "h7h6",
          "positional_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bh4 g5 5. Bg3",
          "positional_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 37,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "g5",
            "Bg3"
          ],
          "plan_execute": [
            "Bh4",
            "g5",
            "Bg3"
          ]
        },
        "query3": {
          "neutral_move": "h6",
          "neutral_uci": "h7h6",
          "neutral_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bh4 g5 5. Bg3 Nh5 6. e3",
          "neutral_tokens": {
            "prompt_tokens": 165,
            "completion_tokens": 44,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bh4",
            "g5",
            "Bg3",
            "Nh5",
            "e3"
          ],
          "plan_execute": [
            "Bh4",
            "g5",
            "Bg3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "h7h6",
          "positional_uci": "h7h6",
          "neutral_uci": "h7h6",
          "consensus_move": "h7h6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bh4",
              "g5",
              "Bg3",
              "Nh5",
              "e3",
              "e6"
            ],
            "execute": [
              "Bh4",
              "g5",
              "Bg3"
            ]
          },
          "positional": {
            "full": [
              "Bh4",
              "g5",
              "Bg3"
            ],
            "execute": [
              "Bh4",
              "g5",
              "Bg3"
            ]
          },
          "neutral": {
            "full": [
              "Bh4",
              "g5",
              "Bg3",
              "Nh5",
              "e3"
            ],
            "execute": [
              "Bh4",
              "g5",
              "Bg3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bh4",
            "g5",
            "Bg3"
          ],
          "full_moves": [
            "Bh4",
            "g5",
            "Bg3",
            "Nh5",
            "e3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 166,
            "completion_tokens": 47,
            "total_tokens": 213,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 166,
            "completion_tokens": 37,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 165,
            "completion_tokens": 44,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 497,
          "total_completion_tokens": 128,
          "total_tokens": 625
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 166,
            "completion_tokens": 47,
            "total_tokens": 213,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 166,
            "completion_tokens": 37,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 165,
            "completion_tokens": 44,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pppp/5n2/3p2B1/3P4/2N5/PPP1PPPP/R2QKBNR b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "gxf6",
          "aggressive_uci": "g7f6",
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 White",
          "aggressive_tokens": {
            "prompt_tokens": 174,
            "completion_tokens": 34,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "gxf6",
          "positional_uci": "g7f6",
          "positional_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 White",
          "positional_tokens": {
            "prompt_tokens": 174,
            "completion_tokens": 34,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "gxf6",
          "neutral_uci": "g7f6",
          "neutral_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 \ngxf6 e3 e6 Nf3",
          "neutral_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 41,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e3",
            "e6",
            "Nf3"
          ],
          "plan_execute": [
            "e3",
            "e6",
            "Nf3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g7f6",
          "positional_uci": "g7f6",
          "neutral_uci": "g7f6",
          "consensus_move": "g7f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "e3",
              "e6",
              "Nf3"
            ],
            "execute": [
              "e3",
              "e6",
              "Nf3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e3",
            "e6",
            "Nf3"
          ],
          "full_moves": [
            "e3",
            "e6",
            "Nf3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 174,
            "completion_tokens": 34,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 174,
            "completion_tokens": 34,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 173,
            "completion_tokens": 41,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 521,
          "total_completion_tokens": 109,
          "total_tokens": 630
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 174,
            "completion_tokens": 34,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 174,
            "completion_tokens": 34,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 173,
            "completion_tokens": 41,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1ppp1/5B1p/3p4/3P4/2N5/PPP1PPPP/R2QKBNR b KQkq - 0 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "dxe4",
          "aggressive_uci": "d5e4",
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 Nxe4 Nc6 Qe2",
          "aggressive_tokens": {
            "prompt_tokens": 182,
            "completion_tokens": 50,
            "total_tokens": 232,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe4",
            "Nc6",
            "Qe2"
          ],
          "plan_execute": [
            "Nxe4",
            "Nc6",
            "Qe2"
          ]
        },
        "query2": {
          "positional_move": "dxe4",
          "positional_uci": "d5e4",
          "positional_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Nf3 Qe7 8. Bd3",
          "positional_tokens": {
            "prompt_tokens": 182,
            "completion_tokens": 64,
            "total_tokens": 246,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe4",
            "Nc6",
            "Nf3",
            "Qe7",
            "Bd3"
          ],
          "plan_execute": [
            "Nxe4",
            "Nc6",
            "Nf3"
          ]
        },
        "query3": {
          "neutral_move": "dxe4",
          "neutral_uci": "d5e4",
          "neutral_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Nf3 Qe7 8. Bd3",
          "neutral_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 64,
            "total_tokens": 245,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe4",
            "Nc6",
            "Nf3",
            "Qe7",
            "Bd3"
          ],
          "plan_execute": [
            "Nxe4",
            "Nc6",
            "Nf3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d5e4",
          "positional_uci": "d5e4",
          "neutral_uci": "d5e4",
          "consensus_move": "d5e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxe4",
              "Nc6",
              "Qe2"
            ],
            "execute": [
              "Nxe4",
              "Nc6",
              "Qe2"
            ]
          },
          "positional": {
            "full": [
              "Nxe4",
              "Nc6",
              "Nf3",
              "Qe7",
              "Bd3"
            ],
            "execute": [
              "Nxe4",
              "Nc6",
              "Nf3"
            ]
          },
          "neutral": {
            "full": [
              "Nxe4",
              "Nc6",
              "Nf3",
              "Qe7",
              "Bd3"
            ],
            "execute": [
              "Nxe4",
              "Nc6",
              "Nf3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nxe4",
            "Nc6",
            "Nf3"
          ],
          "full_moves": [
            "Nxe4",
            "Nc6",
            "Nf3",
            "Qe7",
            "Bd3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 182,
            "completion_tokens": 50,
            "total_tokens": 232,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 182,
            "completion_tokens": 64,
            "total_tokens": 246,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 181,
            "completion_tokens": 64,
            "total_tokens": 245,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 545,
          "total_completion_tokens": 178,
          "total_tokens": 723
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 182,
            "completion_tokens": 50,
            "total_tokens": 232,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 182,
            "completion_tokens": 64,
            "total_tokens": 246,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 181,
            "completion_tokens": 64,
            "total_tokens": 245,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pp2/5p1p/3p4/3PP3/2N5/PPP2PPP/R2QKBNR b KQkq - 0 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 Nf3 Bg7 Bd3 Qe7 O-O",
          "aggressive_tokens": {
            "prompt_tokens": 191,
            "completion_tokens": 63,
            "total_tokens": 254,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Bg7",
            "Bd3",
            "Qe7",
            "O-O"
          ],
          "plan_execute": [
            "Nf3",
            "Bg7",
            "Bd3"
          ]
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 Nf3 e6 Bd3 Qe7 O-O",
          "positional_tokens": {
            "prompt_tokens": 191,
            "completion_tokens": 62,
            "total_tokens": 253,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "e6",
            "Bd3",
            "Qe7",
            "O-O"
          ],
          "plan_execute": [
            "Nf3",
            "e6",
            "Bd3"
          ]
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 Nf3 Bg7 Bd3 Qe7 O-O",
          "neutral_tokens": {
            "prompt_tokens": 190,
            "completion_tokens": 63,
            "total_tokens": 253,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Bg7",
            "Bd3",
            "Qe7",
            "O-O"
          ],
          "plan_execute": [
            "Nf3",
            "Bg7",
            "Bd3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Bg7",
              "Bd3",
              "Qe7",
              "O-O"
            ],
            "execute": [
              "Nf3",
              "Bg7",
              "Bd3"
            ]
          },
          "positional": {
            "full": [
              "Nf3",
              "e6",
              "Bd3",
              "Qe7",
              "O-O"
            ],
            "execute": [
              "Nf3",
              "e6",
              "Bd3"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Bg7",
              "Bd3",
              "Qe7",
              "O-O"
            ],
            "execute": [
              "Nf3",
              "Bg7",
              "Bd3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf3",
            "Bg7",
            "Bd3"
          ],
          "full_moves": [
            "Nf3",
            "Bg7",
            "Bd3",
            "Qe7",
            "O-O"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 191,
            "completion_tokens": 63,
            "total_tokens": 254,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 191,
            "completion_tokens": 62,
            "total_tokens": 253,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 190,
            "completion_tokens": 63,
            "total_tokens": 253,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 572,
          "total_completion_tokens": 188,
          "total_tokens": 760
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 191,
            "completion_tokens": 63,
            "total_tokens": 254,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 191,
            "completion_tokens": 62,
            "total_tokens": 253,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 190,
            "completion_tokens": 63,
            "total_tokens": 253,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppp1pp2/5p1p/8/3PN3/8/PPP2PPP/R2QKBNR b KQkq - 0 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 Bc4 Qe7 Nf3 b5",
          "aggressive_tokens": {
            "prompt_tokens": 200,
            "completion_tokens": 69,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "Qe7",
            "Nf3",
            "b5"
          ],
          "plan_execute": [
            "Bc4",
            "Qe7",
            "Nf3"
          ]
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 Bc4 Qe7 Nf3",
          "positional_tokens": {
            "prompt_tokens": 200,
            "completion_tokens": 67,
            "total_tokens": 267,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "Qe7",
            "Nf3"
          ],
          "plan_execute": [
            "Bc4",
            "Qe7",
            "Nf3"
          ]
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a7a6",
          "neutral_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 Bc4 Qe7 Nf3",
          "neutral_tokens": {
            "prompt_tokens": 199,
            "completion_tokens": 67,
            "total_tokens": 266,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "Qe7",
            "Nf3"
          ],
          "plan_execute": [
            "Bc4",
            "Qe7",
            "Nf3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "a7a6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc4",
              "Qe7",
              "Nf3",
              "b5"
            ],
            "execute": [
              "Bc4",
              "Qe7",
              "Nf3"
            ]
          },
          "positional": {
            "full": [
              "Bc4",
              "Qe7",
              "Nf3"
            ],
            "execute": [
              "Bc4",
              "Qe7",
              "Nf3"
            ]
          },
          "neutral": {
            "full": [
              "Bc4",
              "Qe7",
              "Nf3"
            ],
            "execute": [
              "Bc4",
              "Qe7",
              "Nf3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc4",
            "Qe7",
            "Nf3"
          ],
          "full_moves": [
            "Bc4",
            "Qe7",
            "Nf3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 200,
            "completion_tokens": 69,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 200,
            "completion_tokens": 67,
            "total_tokens": 267,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 199,
            "completion_tokens": 67,
            "total_tokens": 266,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 599,
          "total_completion_tokens": 203,
          "total_tokens": 802
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 200,
            "completion_tokens": 69,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 200,
            "completion_tokens": 67,
            "total_tokens": 267,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 199,
            "completion_tokens": 67,
            "total_tokens": 266,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/ppp1pp2/2n2p1p/1B6/3PN3/8/PPP2PPP/R2QK1NR b KQkq - 2 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "bxc6",
          "aggressive_uci": "b7c6",
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 Nf3 Qe7",
          "aggressive_tokens": {
            "prompt_tokens": 209,
            "completion_tokens": 74,
            "total_tokens": 283,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qe7"
          ],
          "plan_execute": [
            "Nf3",
            "Qe7"
          ]
        },
        "query2": {
          "positional_move": "bxc6",
          "positional_uci": "b7c6",
          "positional_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 Nf3 Qe7 O-O Qe5",
          "positional_tokens": {
            "prompt_tokens": 209,
            "completion_tokens": 79,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qe7",
            "O-O",
            "Qe5"
          ],
          "plan_execute": [
            "Nf3",
            "Qe7",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "bxc6",
          "neutral_uci": "b7c6",
          "neutral_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 Nf3 Qe7 O-O Bd7",
          "neutral_tokens": {
            "prompt_tokens": 208,
            "completion_tokens": 78,
            "total_tokens": 286,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Qe7",
            "O-O",
            "Bd7"
          ],
          "plan_execute": [
            "Nf3",
            "Qe7",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b7c6",
          "positional_uci": "b7c6",
          "neutral_uci": "b7c6",
          "consensus_move": "b7c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Qe7"
            ],
            "execute": [
              "Nf3",
              "Qe7"
            ]
          },
          "positional": {
            "full": [
              "Nf3",
              "Qe7",
              "O-O",
              "Qe5"
            ],
            "execute": [
              "Nf3",
              "Qe7",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Qe7",
              "O-O",
              "Bd7"
            ],
            "execute": [
              "Nf3",
              "Qe7",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf3",
            "Qe7",
            "O-O"
          ],
          "full_moves": [
            "Nf3",
            "Qe7",
            "O-O",
            "Bd7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 209,
            "completion_tokens": 74,
            "total_tokens": 283,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 209,
            "completion_tokens": 79,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 208,
            "completion_tokens": 78,
            "total_tokens": 286,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 626,
          "total_completion_tokens": 231,
          "total_tokens": 857
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 209,
            "completion_tokens": 74,
            "total_tokens": 283,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 209,
            "completion_tokens": 79,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 208,
            "completion_tokens": 78,
            "total_tokens": 286,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1pp1pp2/p1B2p1p/8/3PN3/8/PPP2PPP/R2QK1NR b KQkq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 9. Nf3 Qe7 Nc5 e5 Nd2 f5",
          "aggressive_tokens": {
            "prompt_tokens": 218,
            "completion_tokens": 86,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "e5",
            "Nd2",
            "f5"
          ],
          "plan_execute": [
            "Nc5",
            "e5",
            "Nd2"
          ]
        },
        "query2": {
          "positional_move": "Qe7",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 9. Nf3 \nQe7 Nc5 O-O Rd8",
          "positional_tokens": {
            "prompt_tokens": 218,
            "completion_tokens": 85,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "O-O",
            "Rd8"
          ],
          "plan_execute": [
            "Nc5",
            "O-O",
            "Rd8"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 9. Nf3 \nQe7 Nc5 Qe4",
          "neutral_tokens": {
            "prompt_tokens": 217,
            "completion_tokens": 84,
            "total_tokens": 301,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "Qe4"
          ],
          "plan_execute": [
            "Nc5",
            "Qe4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc5",
              "e5",
              "Nd2",
              "f5"
            ],
            "execute": [
              "Nc5",
              "e5",
              "Nd2"
            ]
          },
          "positional": {
            "full": [
              "Nc5",
              "O-O",
              "Rd8"
            ],
            "execute": [
              "Nc5",
              "O-O",
              "Rd8"
            ]
          },
          "neutral": {
            "full": [
              "Nc5",
              "Qe4"
            ],
            "execute": [
              "Nc5",
              "Qe4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 218,
            "completion_tokens": 86,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 218,
            "completion_tokens": 85,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 217,
            "completion_tokens": 84,
            "total_tokens": 301,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 653,
          "total_completion_tokens": 255,
          "total_tokens": 908
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 218,
            "completion_tokens": 86,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 218,
            "completion_tokens": 85,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 217,
            "completion_tokens": 84,
            "total_tokens": 301,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/2p1pp2/p1p2p1p/8/3PN3/5N2/PPP2PPP/R2QK2R b KQkq - 1 9"
    },
    {
      "turn": 18,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 9. Nf3 Qe7 Nc5 e5 Nd2 f5",
          "aggressive_tokens": {
            "prompt_tokens": 218,
            "completion_tokens": 86,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "e5",
            "Nd2",
            "f5"
          ],
          "plan_execute": [
            "Nc5",
            "e5",
            "Nd2"
          ]
        },
        "query2": {
          "positional_move": "Qe7",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 9. Nf3 \nQe7 Nc5 O-O Rd8",
          "positional_tokens": {
            "prompt_tokens": 218,
            "completion_tokens": 85,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "O-O",
            "Rd8"
          ],
          "plan_execute": [
            "Nc5",
            "O-O",
            "Rd8"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 9. Nf3 \nQe7 Nc5 Qe4",
          "neutral_tokens": {
            "prompt_tokens": 217,
            "completion_tokens": 84,
            "total_tokens": 301,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "Qe4"
          ],
          "plan_execute": [
            "Nc5",
            "Qe4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc5",
              "e5",
              "Nd2",
              "f5"
            ],
            "execute": [
              "Nc5",
              "e5",
              "Nd2"
            ]
          },
          "positional": {
            "full": [
              "Nc5",
              "O-O",
              "Rd8"
            ],
            "execute": [
              "Nc5",
              "O-O",
              "Rd8"
            ]
          },
          "neutral": {
            "full": [
              "Nc5",
              "Qe4"
            ],
            "execute": [
              "Nc5",
              "Qe4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 218,
            "completion_tokens": 86,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 218,
            "completion_tokens": 85,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 217,
            "completion_tokens": 84,
            "total_tokens": 301,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 653,
          "total_completion_tokens": 255,
          "total_tokens": 908
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 218,
            "completion_tokens": 86,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 218,
            "completion_tokens": 85,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 217,
            "completion_tokens": 84,
            "total_tokens": 301,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/2p1pp2/p1p2p1p/8/3PN3/5N2/PPP2PPP/R2QK2R b KQkq - 1 9"
    },
    {
      "turn": 18,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 9. Nf3 Qe7 Nc5 e5 Nd2 f5",
          "aggressive_tokens": {
            "prompt_tokens": 218,
            "completion_tokens": 86,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "e5",
            "Nd2",
            "f5"
          ],
          "plan_execute": [
            "Nc5",
            "e5",
            "Nd2"
          ]
        },
        "query2": {
          "positional_move": "Qe7",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 9. Nf3 \nQe7 Nc5 O-O Rd8",
          "positional_tokens": {
            "prompt_tokens": 218,
            "completion_tokens": 85,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "O-O",
            "Rd8"
          ],
          "plan_execute": [
            "Nc5",
            "O-O",
            "Rd8"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. Nc3 Nf6 3. Bg5 h6 4. Bxf6 gxf6 5. e4 dxe4 6. Nxe4 Nc6 7. Bb5 a6 8. Bxc6+ bxc6 9. Nf3 \nQe7 Nc5 Qe4",
          "neutral_tokens": {
            "prompt_tokens": 217,
            "completion_tokens": 84,
            "total_tokens": 301,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "Qe4"
          ],
          "plan_execute": [
            "Nc5",
            "Qe4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc5",
              "e5",
              "Nd2",
              "f5"
            ],
            "execute": [
              "Nc5",
              "e5",
              "Nd2"
            ]
          },
          "positional": {
            "full": [
              "Nc5",
              "O-O",
              "Rd8"
            ],
            "execute": [
              "Nc5",
              "O-O",
              "Rd8"
            ]
          },
          "neutral": {
            "full": [
              "Nc5",
              "Qe4"
            ],
            "execute": [
              "Nc5",
              "Qe4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 218,
            "completion_tokens": 86,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 218,
            "completion_tokens": 85,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 217,
            "completion_tokens": 84,
            "total_tokens": 301,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 653,
          "total_completion_tokens": 255,
          "total_tokens": 908
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 218,
            "completion_tokens": 86,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 218,
            "completion_tokens": 85,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 217,
            "completion_tokens": 84,
            "total_tokens": 301,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/2p1pp2/p1p2p1p/8/3PN3/5N2/PPP2PPP/R2QK2R b KQkq - 1 9"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": null,
          "aggressive_response": "1. Nf3 Nf6\nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": null,
          "positional_response": "1. Nf3 Nf6\nWhite",
          "positional_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": null,
          "neutral_response": "1. Nf3 Nf6\nWhite",
          "neutral_tokens": {
            "prompt_tokens": 152,
            "completion_tokens": 11,
            "total_tokens": 163,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 152,
            "completion_tokens": 11,
            "total_tokens": 163,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 458,
          "total_completion_tokens": 33,
          "total_tokens": 491
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 152,
            "completion_tokens": 11,
            "total_tokens": 163,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pppppppp/5n2/8/8/5N2/PPPPPPPP/RNBQKB1R w KQkq - 2 2"
    },
    {
      "turn": 3,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": null,
          "aggressive_response": "1. Nf3 Nf6\nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": null,
          "positional_response": "1. Nf3 Nf6\nWhite",
          "positional_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": null,
          "neutral_response": "1. Nf3 Nf6\nWhite",
          "neutral_tokens": {
            "prompt_tokens": 152,
            "completion_tokens": 11,
            "total_tokens": 163,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 152,
            "completion_tokens": 11,
            "total_tokens": 163,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 458,
          "total_completion_tokens": 33,
          "total_tokens": 491
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 152,
            "completion_tokens": 11,
            "total_tokens": 163,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pppppppp/5n2/8/8/5N2/PPPPPPPP/RNBQKB1R w KQkq - 2 2"
    },
    {
      "turn": 3,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": null,
          "aggressive_response": "1. Nf3 Nf6\nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": null,
          "positional_response": "1. Nf3 Nf6\nWhite",
          "positional_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": null,
          "neutral_response": "1. Nf3 Nf6\nWhite",
          "neutral_tokens": {
            "prompt_tokens": 152,
            "completion_tokens": 11,
            "total_tokens": 163,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 152,
            "completion_tokens": 11,
            "total_tokens": 163,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 458,
          "total_completion_tokens": 33,
          "total_tokens": 491
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 153,
            "completion_tokens": 11,
            "total_tokens": 164,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 152,
            "completion_tokens": 11,
            "total_tokens": 163,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pppppppp/5n2/8/8/5N2/PPPPPPPP/RNBQKB1R w KQkq - 2 2"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "1. d4 \nd5",
          "aggressive_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d5",
          "positional_uci": "d7d5",
          "positional_response": "1. d4 \nd5",
          "positional_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d5",
          "neutral_uci": "d7d5",
          "neutral_response": "1. d4 \nd5",
          "neutral_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 8,
            "total_tokens": 156,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": "d7d5",
          "neutral_uci": "d7d5",
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 148,
            "completion_tokens": 8,
            "total_tokens": 156,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 446,
          "total_completion_tokens": 24,
          "total_tokens": 470
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 149,
            "completion_tokens": 8,
            "total_tokens": 157,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 148,
            "completion_tokens": 8,
            "total_tokens": 156,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d6",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. c4 \nd6 Nf3 Nc6 Bf4",
          "aggressive_tokens": {
            "prompt_tokens": 156,
            "completion_tokens": 24,
            "total_tokens": 180,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bf4"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bf4"
          ]
        },
        "query2": {
          "positional_move": "dxc4",
          "positional_uci": "d5c4",
          "positional_response": "1. d4 d5 2. c4 \ndxc4 b3",
          "positional_tokens": {
            "prompt_tokens": 156,
            "completion_tokens": 18,
            "total_tokens": 174,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3"
          ],
          "plan_execute": [
            "b3"
          ]
        },
        "query3": {
          "neutral_move": "d6",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. c4 \nd6 Nf3 Nc6 Bf4",
          "neutral_tokens": {
            "prompt_tokens": 155,
            "completion_tokens": 24,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bf4"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bf4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "d5c4",
          "neutral_uci": null,
          "consensus_move": "d5c4",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bf4"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bf4"
            ]
          },
          "positional": {
            "full": [
              "b3"
            ],
            "execute": [
              "b3"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bf4"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bf4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b3"
          ],
          "full_moves": [
            "b3"
          ],
          "source_agent": "positional"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 156,
            "completion_tokens": 24,
            "total_tokens": 180,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 156,
            "completion_tokens": 18,
            "total_tokens": 174,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 155,
            "completion_tokens": 24,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 467,
          "total_completion_tokens": 66,
          "total_tokens": 533
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 156,
            "completion_tokens": 24,
            "total_tokens": 180,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 156,
            "completion_tokens": 18,
            "total_tokens": 174,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 155,
            "completion_tokens": 24,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/3p4/2PP4/8/PP2PPPP/RNBQKBNR b KQkq - 0 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "1. d4 d5 2. c4 dxc4 3. Nf3 \nNc6 Bg5",
          "aggressive_tokens": {
            "prompt_tokens": 165,
            "completion_tokens": 28,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bg5"
          ],
          "plan_execute": [
            "Bg5"
          ]
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "1. d4 d5 2. c4 dxc4 3. Nf3 \nNc6 e3",
          "positional_tokens": {
            "prompt_tokens": 165,
            "completion_tokens": 27,
            "total_tokens": 192,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e3"
          ],
          "plan_execute": [
            "e3"
          ]
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "1. d4 d5 2. c4 dxc4 3. Nf3 \nNc6 e3 a6",
          "neutral_tokens": {
            "prompt_tokens": 164,
            "completion_tokens": 29,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e3",
            "a6"
          ],
          "plan_execute": [
            "e3",
            "a6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bg5"
            ],
            "execute": [
              "Bg5"
            ]
          },
          "positional": {
            "full": [
              "e3"
            ],
            "execute": [
              "e3"
            ]
          },
          "neutral": {
            "full": [
              "e3",
              "a6"
            ],
            "execute": [
              "e3",
              "a6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e3",
            "a6"
          ],
          "full_moves": [
            "e3",
            "a6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 165,
            "completion_tokens": 28,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 165,
            "completion_tokens": 27,
            "total_tokens": 192,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 164,
            "completion_tokens": 29,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 494,
          "total_completion_tokens": 84,
          "total_tokens": 578
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 165,
            "completion_tokens": 28,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 165,
            "completion_tokens": 27,
            "total_tokens": 192,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 164,
            "completion_tokens": 29,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppp1pppp/8/8/2pP4/5N2/PP2PPPP/RNBQKB1R b KQkq - 1 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e6",
          "aggressive_uci": "e7e6",
          "aggressive_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 Nf6 Bg5",
          "aggressive_tokens": {
            "prompt_tokens": 174,
            "completion_tokens": 38,
            "total_tokens": 212,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bg5"
          ],
          "plan_execute": [
            "Nf6",
            "Bg5"
          ]
        },
        "query2": {
          "positional_move": "e6",
          "positional_uci": "e7e6",
          "positional_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 Nf6 Bg4",
          "positional_tokens": {
            "prompt_tokens": 174,
            "completion_tokens": 38,
            "total_tokens": 212,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bg4"
          ],
          "plan_execute": [
            "Nf6",
            "Bg4"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 \nNf6 e3",
          "neutral_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 36,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e3"
          ],
          "plan_execute": [
            "e3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e7e6",
          "positional_uci": "e7e6",
          "neutral_uci": "g8f6",
          "consensus_move": "e7e6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Bg5"
            ],
            "execute": [
              "Nf6",
              "Bg5"
            ]
          },
          "positional": {
            "full": [
              "Nf6",
              "Bg4"
            ],
            "execute": [
              "Nf6",
              "Bg4"
            ]
          },
          "neutral": {
            "full": [
              "e3"
            ],
            "execute": [
              "e3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf6",
            "Bg5"
          ],
          "full_moves": [
            "Nf6",
            "Bg5"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 174,
            "completion_tokens": 38,
            "total_tokens": 212,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 174,
            "completion_tokens": 38,
            "total_tokens": 212,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 173,
            "completion_tokens": 36,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 521,
          "total_completion_tokens": 112,
          "total_tokens": 633
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 174,
            "completion_tokens": 38,
            "total_tokens": 212,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 174,
            "completion_tokens": 38,
            "total_tokens": 212,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 173,
            "completion_tokens": 36,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/ppp1pppp/2n5/8/2pP4/2N2N2/PP2PPPP/R1BQKB1R b KQkq - 3 4"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb4",
          "aggressive_uci": "f8b4",
          "aggressive_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 \nBb4 Qe7",
          "aggressive_tokens": {
            "prompt_tokens": 190,
            "completion_tokens": 53,
            "total_tokens": 243,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe7"
          ],
          "plan_execute": [
            "Qe7"
          ]
        },
        "query2": {
          "positional_move": "Bb4",
          "positional_uci": "f8b4",
          "positional_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 \nBb4 Qe7",
          "positional_tokens": {
            "prompt_tokens": 190,
            "completion_tokens": 53,
            "total_tokens": 243,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe7"
          ],
          "plan_execute": [
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Bb4",
          "neutral_uci": "f8b4",
          "neutral_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 \nBb4 Bd3",
          "neutral_tokens": {
            "prompt_tokens": 189,
            "completion_tokens": 52,
            "total_tokens": 241,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3"
          ],
          "plan_execute": [
            "Bd3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f8b4",
          "positional_uci": "f8b4",
          "neutral_uci": "f8b4",
          "consensus_move": "f8b4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qe7"
            ],
            "execute": [
              "Qe7"
            ]
          },
          "positional": {
            "full": [
              "Qe7"
            ],
            "execute": [
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "Bd3"
            ],
            "execute": [
              "Bd3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Qe7"
          ],
          "full_moves": [
            "Qe7"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 190,
            "completion_tokens": 53,
            "total_tokens": 243,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 190,
            "completion_tokens": 53,
            "total_tokens": 243,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 189,
            "completion_tokens": 52,
            "total_tokens": 241,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 569,
          "total_completion_tokens": 158,
          "total_tokens": 727
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 190,
            "completion_tokens": 53,
            "total_tokens": 243,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 190,
            "completion_tokens": 53,
            "total_tokens": 243,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 189,
            "completion_tokens": 52,
            "total_tokens": 241,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/ppp2ppp/2n1pn2/8/2BPP3/2N2N2/PP3PPP/R1BQK2R b KQkq - 0 6"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "h6",
          "aggressive_uci": "h7h6",
          "aggressive_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 \nh6 g4",
          "aggressive_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 68,
            "total_tokens": 274,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g4"
          ],
          "plan_execute": [
            "g4"
          ]
        },
        "query2": {
          "positional_move": "h6",
          "positional_uci": "h7h6",
          "positional_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6",
          "positional_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 65,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "h6",
          "neutral_uci": "h7h6",
          "neutral_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 \nh6 g4",
          "neutral_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 68,
            "total_tokens": 273,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g4"
          ],
          "plan_execute": [
            "g4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "h7h6",
          "positional_uci": "h7h6",
          "neutral_uci": "h7h6",
          "consensus_move": "h7h6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "g4"
            ],
            "execute": [
              "g4"
            ]
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "g4"
            ],
            "execute": [
              "g4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "g4"
          ],
          "full_moves": [
            "g4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 206,
            "completion_tokens": 68,
            "total_tokens": 274,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 206,
            "completion_tokens": 65,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 205,
            "completion_tokens": 68,
            "total_tokens": 273,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 617,
          "total_completion_tokens": 201,
          "total_tokens": 818
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 206,
            "completion_tokens": 68,
            "total_tokens": 274,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 206,
            "completion_tokens": 65,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 205,
            "completion_tokens": 68,
            "total_tokens": 273,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/ppp1qppp/2n1pn2/6B1/1bBPP3/2N2N2/PP3PPP/R2Q1RK1 b kq - 4 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bh4",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6 9. Bh4 \nBh4 g5 Nd2 a6",
          "aggressive_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Nd2",
            "a6"
          ],
          "plan_execute": [
            "g5",
            "Nd2",
            "a6"
          ]
        },
        "query2": {
          "positional_move": "Bh4",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6 9. Bh4 \nBh4 g5 Nd2 a6",
          "positional_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Nd2",
            "a6"
          ],
          "plan_execute": [
            "g5",
            "Nd2",
            "a6"
          ]
        },
        "query3": {
          "neutral_move": "Bh4",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6 9. Bh4 \nBh4 g5 Nd2 a6",
          "neutral_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 80,
            "total_tokens": 292,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Nd2",
            "a6"
          ],
          "plan_execute": [
            "g5",
            "Nd2",
            "a6"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "g5",
              "Nd2",
              "a6"
            ],
            "execute": [
              "g5",
              "Nd2",
              "a6"
            ]
          },
          "positional": {
            "full": [
              "g5",
              "Nd2",
              "a6"
            ],
            "execute": [
              "g5",
              "Nd2",
              "a6"
            ]
          },
          "neutral": {
            "full": [
              "g5",
              "Nd2",
              "a6"
            ],
            "execute": [
              "g5",
              "Nd2",
              "a6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 212,
            "completion_tokens": 80,
            "total_tokens": 292,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 638,
          "total_completion_tokens": 240,
          "total_tokens": 878
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 212,
            "completion_tokens": 80,
            "total_tokens": 292,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/ppp1qpp1/2n1pn1p/8/1bBPP2B/2N2N2/PP3PPP/R2Q1RK1 b kq - 1 9"
    },
    {
      "turn": 18,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bh4",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6 9. Bh4 \nBh4 g5 Nd2 a6",
          "aggressive_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Nd2",
            "a6"
          ],
          "plan_execute": [
            "g5",
            "Nd2",
            "a6"
          ]
        },
        "query2": {
          "positional_move": "Bh4",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6 9. Bh4 \nBh4 g5 Nd2 a6",
          "positional_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Nd2",
            "a6"
          ],
          "plan_execute": [
            "g5",
            "Nd2",
            "a6"
          ]
        },
        "query3": {
          "neutral_move": "Bh4",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6 9. Bh4 \nBh4 g5 Nd2 a6",
          "neutral_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 80,
            "total_tokens": 292,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Nd2",
            "a6"
          ],
          "plan_execute": [
            "g5",
            "Nd2",
            "a6"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "g5",
              "Nd2",
              "a6"
            ],
            "execute": [
              "g5",
              "Nd2",
              "a6"
            ]
          },
          "positional": {
            "full": [
              "g5",
              "Nd2",
              "a6"
            ],
            "execute": [
              "g5",
              "Nd2",
              "a6"
            ]
          },
          "neutral": {
            "full": [
              "g5",
              "Nd2",
              "a6"
            ],
            "execute": [
              "g5",
              "Nd2",
              "a6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 212,
            "completion_tokens": 80,
            "total_tokens": 292,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 638,
          "total_completion_tokens": 240,
          "total_tokens": 878
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 212,
            "completion_tokens": 80,
            "total_tokens": 292,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/ppp1qpp1/2n1pn1p/8/1bBPP2B/2N2N2/PP3PPP/R2Q1RK1 b kq - 1 9"
    },
    {
      "turn": 18,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bh4",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6 9. Bh4 \nBh4 g5 Nd2 a6",
          "aggressive_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Nd2",
            "a6"
          ],
          "plan_execute": [
            "g5",
            "Nd2",
            "a6"
          ]
        },
        "query2": {
          "positional_move": "Bh4",
          "positional_uci": null,
          "positional_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6 9. Bh4 \nBh4 g5 Nd2 a6",
          "positional_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Nd2",
            "a6"
          ],
          "plan_execute": [
            "g5",
            "Nd2",
            "a6"
          ]
        },
        "query3": {
          "neutral_move": "Bh4",
          "neutral_uci": null,
          "neutral_response": "1. d4 d5 2. c4 dxc4 3. Nf3 Nc6 4. Nc3 e6 5. e4 Nf6 6. Bxc4 Bb4 7. O-O Qe7 8. Bg5 h6 9. Bh4 \nBh4 g5 Nd2 a6",
          "neutral_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 80,
            "total_tokens": 292,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "Nd2",
            "a6"
          ],
          "plan_execute": [
            "g5",
            "Nd2",
            "a6"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "g5",
              "Nd2",
              "a6"
            ],
            "execute": [
              "g5",
              "Nd2",
              "a6"
            ]
          },
          "positional": {
            "full": [
              "g5",
              "Nd2",
              "a6"
            ],
            "execute": [
              "g5",
              "Nd2",
              "a6"
            ]
          },
          "neutral": {
            "full": [
              "g5",
              "Nd2",
              "a6"
            ],
            "execute": [
              "g5",
              "Nd2",
              "a6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 212,
            "completion_tokens": 80,
            "total_tokens": 292,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 638,
          "total_completion_tokens": 240,
          "total_tokens": 878
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 213,
            "completion_tokens": 80,
            "total_tokens": 293,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 212,
            "completion_tokens": 80,
            "total_tokens": 292,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/ppp1qpp1/2n1pn1p/8/1bBPP2B/2N2N2/PP3PPP/R2Q1RK1 b kq - 1 9"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "h4",
          "aggressive_uci": "h2h4",
          "aggressive_response": "1. g4 g5\n2. h4 gxh4 \nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 17,
            "total_tokens": 168,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxh4"
          ],
          "plan_execute": [
            "gxh4"
          ]
        },
        "query2": {
          "positional_move": "g4",
          "positional_uci": null,
          "positional_response": "1. g4 g5\nWhite",
          "positional_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5"
          ],
          "plan_execute": [
            "g5"
          ]
        },
        "query3": {
          "neutral_move": "h4",
          "neutral_uci": "h2h4",
          "neutral_response": "1. g4 g5\n2. h4 gxh4 \nWhite",
          "neutral_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 17,
            "total_tokens": 167,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxh4"
          ],
          "plan_execute": [
            "gxh4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "h2h4",
          "positional_uci": null,
          "neutral_uci": "h2h4",
          "consensus_move": "h2h4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "gxh4"
            ],
            "execute": [
              "gxh4"
            ]
          },
          "positional": {
            "full": [
              "g5"
            ],
            "execute": [
              "g5"
            ]
          },
          "neutral": {
            "full": [
              "gxh4"
            ],
            "execute": [
              "gxh4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "gxh4"
          ],
          "full_moves": [
            "gxh4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 151,
            "completion_tokens": 17,
            "total_tokens": 168,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 150,
            "completion_tokens": 17,
            "total_tokens": 167,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 452,
          "total_completion_tokens": 43,
          "total_tokens": 495
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 151,
            "completion_tokens": 17,
            "total_tokens": 168,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 150,
            "completion_tokens": 17,
            "total_tokens": 167,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppp1p/8/6p1/6P1/8/PPPPPP1P/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxh4",
          "aggressive_uci": null,
          "aggressive_response": "1. g4 g5 2. h4 gxh4 \nWhite Nxh4 Nh6 Nc3 e6",
          "aggressive_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 27,
            "total_tokens": 186,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nh6",
            "Nc3",
            "e6"
          ],
          "plan_execute": [
            "Nh6",
            "Nc3",
            "e6"
          ]
        },
        "query2": {
          "positional_move": "Nxh4",
          "positional_uci": null,
          "positional_response": "1. g4 g5 2. h4 gxh4 \nNxh4 Nf6",
          "positional_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 22,
            "total_tokens": 181,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "g4",
          "neutral_uci": null,
          "neutral_response": "1. g4 g5 2. h4 gxh4 \nWhite",
          "neutral_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 17,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "h4",
            "gxh4"
          ],
          "plan_execute": [
            "g5",
            "h4",
            "gxh4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nh6",
              "Nc3",
              "e6"
            ],
            "execute": [
              "Nh6",
              "Nc3",
              "e6"
            ]
          },
          "positional": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "g5",
              "h4",
              "gxh4"
            ],
            "execute": [
              "g5",
              "h4",
              "gxh4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 159,
            "completion_tokens": 27,
            "total_tokens": 186,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 159,
            "completion_tokens": 22,
            "total_tokens": 181,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 158,
            "completion_tokens": 17,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 476,
          "total_completion_tokens": 66,
          "total_tokens": 542
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 159,
            "completion_tokens": 27,
            "total_tokens": 186,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 159,
            "completion_tokens": 22,
            "total_tokens": 181,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 158,
            "completion_tokens": 17,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppp1p/8/8/6Pp/8/PPPPPP2/RNBQKBNR w KQkq - 0 3"
    },
    {
      "turn": 5,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxh4",
          "aggressive_uci": null,
          "aggressive_response": "1. g4 g5 2. h4 gxh4 \nWhite Nxh4 Qh5 Nf3 e6",
          "aggressive_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 28,
            "total_tokens": 187,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh5",
            "Nf3",
            "e6"
          ],
          "plan_execute": [
            "Qh5",
            "Nf3",
            "e6"
          ]
        },
        "query2": {
          "positional_move": "Nxh4",
          "positional_uci": null,
          "positional_response": "1. g4 g5 2. h4 gxh4 \nNxh4 Nf6",
          "positional_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 22,
            "total_tokens": 181,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "g4",
          "neutral_uci": null,
          "neutral_response": "1. g4 g5 2. h4 gxh4 \nWhite",
          "neutral_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 17,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "h4",
            "gxh4"
          ],
          "plan_execute": [
            "g5",
            "h4",
            "gxh4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh5",
              "Nf3",
              "e6"
            ],
            "execute": [
              "Qh5",
              "Nf3",
              "e6"
            ]
          },
          "positional": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "g5",
              "h4",
              "gxh4"
            ],
            "execute": [
              "g5",
              "h4",
              "gxh4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 159,
            "completion_tokens": 28,
            "total_tokens": 187,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 159,
            "completion_tokens": 22,
            "total_tokens": 181,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 158,
            "completion_tokens": 17,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 476,
          "total_completion_tokens": 67,
          "total_tokens": 543
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 159,
            "completion_tokens": 28,
            "total_tokens": 187,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 159,
            "completion_tokens": 22,
            "total_tokens": 181,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 158,
            "completion_tokens": 17,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppp1p/8/8/6Pp/8/PPPPPP2/RNBQKBNR w KQkq - 0 3"
    },
    {
      "turn": 5,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxh4",
          "aggressive_uci": null,
          "aggressive_response": "1. g4 g5 2. h4 gxh4 \nWhite Nxh4 Nh6 Nc3 e6",
          "aggressive_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 27,
            "total_tokens": 186,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nh6",
            "Nc3",
            "e6"
          ],
          "plan_execute": [
            "Nh6",
            "Nc3",
            "e6"
          ]
        },
        "query2": {
          "positional_move": "Nxh4",
          "positional_uci": null,
          "positional_response": "1. g4 g5 2. h4 gxh4 \nNxh4 Nf6",
          "positional_tokens": {
            "prompt_tokens": 159,
            "completion_tokens": 22,
            "total_tokens": 181,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6"
          ],
          "plan_execute": [
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "g4",
          "neutral_uci": null,
          "neutral_response": "1. g4 g5 2. h4 gxh4 \nWhite",
          "neutral_tokens": {
            "prompt_tokens": 158,
            "completion_tokens": 17,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g5",
            "h4",
            "gxh4"
          ],
          "plan_execute": [
            "g5",
            "h4",
            "gxh4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nh6",
              "Nc3",
              "e6"
            ],
            "execute": [
              "Nh6",
              "Nc3",
              "e6"
            ]
          },
          "positional": {
            "full": [
              "Nf6"
            ],
            "execute": [
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "g5",
              "h4",
              "gxh4"
            ],
            "execute": [
              "g5",
              "h4",
              "gxh4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 159,
            "completion_tokens": 27,
            "total_tokens": 186,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 159,
            "completion_tokens": 22,
            "total_tokens": 181,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 158,
            "completion_tokens": 17,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 476,
          "total_completion_tokens": 66,
          "total_tokens": 542
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 159,
            "completion_tokens": 27,
            "total_tokens": 186,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 159,
            "completion_tokens": 22,
            "total_tokens": 181,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 158,
            "completion_tokens": 17,
            "total_tokens": 175,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppp1p/8/8/6Pp/8/PPPPPP2/RNBQKBNR w KQkq - 0 3"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6",
          "aggressive_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6 Nc3 Nf6",
          "positional_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6",
            "Nc3",
            "Nf6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6",
          "neutral_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6",
              "Nc3",
              "Nf6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf3",
            "Nc6",
            "Bc4"
          ],
          "full_moves": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 446,
          "total_completion_tokens": 78,
          "total_tokens": 524
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "1. e4 e5 2. Nf3 \nNc6 Bc4",
          "aggressive_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nNc6 Bc2",
          "positional_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2"
          ],
          "plan_execute": [
            "Bc2"
          ]
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "1. e4 e5 2. Nf3 \nNc6 Bc4",
          "neutral_tokens": {
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "Bc2"
            ],
            "execute": [
              "Bc2"
            ]
          },
          "neutral": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc4"
          ],
          "full_moves": [
            "Bc4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 470,
          "total_completion_tokens": 84,
          "total_tokens": 554
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 \nNbd2 Bc5",
          "aggressive_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 53,
            "total_tokens": 219,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Nbd2",
            "Bc5"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 \nBa4",
          "positional_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Ba4"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 \nNf6 Bd3",
          "neutral_tokens": {
            "prompt_tokens": 165,
            "completion_tokens": 28,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd3"
          ],
          "plan_execute": [
            "Bd3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "g8f6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Nbd2",
              "Bc5"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Ba4"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Bd3"
            ],
            "execute": [
              "Bd3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Ba4",
            "Nf6",
            "O-O"
          ],
          "full_moves": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Nbd2",
            "Bc5"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 166,
            "completion_tokens": 53,
            "total_tokens": 219,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 165,
            "completion_tokens": 28,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 497,
          "total_completion_tokens": 130,
          "total_tokens": 627
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 166,
            "completion_tokens": 53,
            "total_tokens": 219,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 165,
            "completion_tokens": 28,
            "total_tokens": 193,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 d3",
          "aggressive_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3"
          ],
          "plan_execute": [
            "d3"
          ]
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 b3 Bd6 \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 b3 Bd6 O-O Na5",
          "positional_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 76,
            "total_tokens": 249,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Bd6",
            "O-O",
            "Na5"
          ],
          "plan_execute": [
            "b3",
            "Bd6",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 d3 Bc5",
          "neutral_tokens": {
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Bc5"
          ],
          "plan_execute": [
            "d3",
            "Bc5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d3"
            ],
            "execute": [
              "d3"
            ]
          },
          "positional": {
            "full": [
              "b3",
              "Bd6",
              "O-O",
              "Na5"
            ],
            "execute": [
              "b3",
              "Bd6",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "d3",
              "Bc5"
            ],
            "execute": [
              "d3",
              "Bc5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "d3",
            "Bc5"
          ],
          "full_moves": [
            "d3",
            "Bc5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 173,
            "completion_tokens": 76,
            "total_tokens": 249,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 518,
          "total_completion_tokens": 147,
          "total_tokens": 665
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 173,
            "completion_tokens": 76,
            "total_tokens": 249,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 d6 Na3 Qe7",
          "aggressive_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 49,
            "total_tokens": 230,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "d6",
            "Na3",
            "Qe7"
          ],
          "plan_execute": [
            "b3",
            "d6",
            "Na3"
          ]
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 d6 Na3",
          "positional_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "d6",
            "Na3"
          ],
          "plan_execute": [
            "b3",
            "d6",
            "Na3"
          ]
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 b5 Bb3",
          "neutral_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "b5",
            "Bb3"
          ],
          "plan_execute": [
            "b3",
            "b5",
            "Bb3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b3",
              "d6",
              "Na3",
              "Qe7"
            ],
            "execute": [
              "b3",
              "d6",
              "Na3"
            ]
          },
          "positional": {
            "full": [
              "b3",
              "d6",
              "Na3"
            ],
            "execute": [
              "b3",
              "d6",
              "Na3"
            ]
          },
          "neutral": {
            "full": [
              "b3",
              "b5",
              "Bb3"
            ],
            "execute": [
              "b3",
              "b5",
              "Bb3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b3",
            "d6",
            "Na3"
          ],
          "full_moves": [
            "b3",
            "d6",
            "Na3",
            "Qe7"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 181,
            "completion_tokens": 49,
            "total_tokens": 230,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 542,
          "total_completion_tokens": 142,
          "total_tokens": 684
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 181,
            "completion_tokens": 49,
            "total_tokens": 230,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 b kq - 3 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b5",
          "aggressive_uci": "b7b5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nNa3",
          "aggressive_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na3"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na3"
          ]
        },
        "query2": {
          "positional_move": "b5",
          "positional_uci": "b7b5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nis incorrect, the correct move is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 \nThe next four moves are: \nBc2 d6 Na3 Na5 Nc4",
          "positional_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 128,
            "total_tokens": 316,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "Bc2",
            "d6",
            "Na3",
            "Na5",
            "Nc4"
          ],
          "plan_execute": [
            "Bc2",
            "Bc2",
            "d6"
          ]
        },
        "query3": {
          "neutral_move": "b5",
          "neutral_uci": "b7b5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nis incorrect, the correct move is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 is incorrect \nThe correct continuation is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 \nThe next 4 moves are \nb5 Bc2 d6 Na5",
          "neutral_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 178,
            "total_tokens": 365,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na5"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b7b5",
          "positional_uci": "b7b5",
          "neutral_uci": "b7b5",
          "consensus_move": "b7b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc2",
              "d6",
              "Na3"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na3"
            ]
          },
          "positional": {
            "full": [
              "Bc2",
              "Bc2",
              "d6",
              "Na3",
              "Na5",
              "Nc4"
            ],
            "execute": [
              "Bc2",
              "Bc2",
              "d6"
            ]
          },
          "neutral": {
            "full": [
              "Bc2",
              "d6",
              "Na5"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc2",
            "d6",
            "Na5"
          ],
          "full_moves": [
            "Bc2",
            "d6",
            "Na5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 188,
            "completion_tokens": 128,
            "total_tokens": 316,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 187,
            "completion_tokens": 178,
            "total_tokens": 365,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 563,
          "total_completion_tokens": 360,
          "total_tokens": 923
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 188,
            "completion_tokens": 128,
            "total_tokens": 316,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 187,
            "completion_tokens": 178,
            "total_tokens": 365,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQR1K1 b kq - 5 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d6",
          "aggressive_uci": "d7d6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3 Na5 Nc4 Qe7",
          "aggressive_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 64,
            "total_tokens": 260,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3",
            "Na5",
            "Nc4",
            "Qe7"
          ],
          "plan_execute": [
            "Na3",
            "Na5",
            "Nc4"
          ]
        },
        "query2": {
          "positional_move": "d6",
          "positional_uci": "d7d6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "positional_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "query3": {
          "neutral_move": "d6",
          "neutral_uci": "d7d6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "neutral_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d7d6",
          "positional_uci": "d7d6",
          "neutral_uci": "d7d6",
          "consensus_move": "d7d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Na3",
              "Na5",
              "Nc4",
              "Qe7"
            ],
            "execute": [
              "Na3",
              "Na5",
              "Nc4"
            ]
          },
          "positional": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          },
          "neutral": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Na3"
          ],
          "full_moves": [
            "Na3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 196,
            "completion_tokens": 64,
            "total_tokens": 260,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 587,
          "total_completion_tokens": 176,
          "total_tokens": 763
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 196,
            "completion_tokens": 64,
            "total_tokens": 260,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2ppbppp/p1n2n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 b kq - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Na5",
          "aggressive_uci": "c6a5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5 Nbd2",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "plan_execute": [
            "Bc2",
            "c5",
            "Nbd2"
          ]
        },
        "query2": {
          "positional_move": "Na5",
          "positional_uci": "c6a5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5"
          ],
          "plan_execute": [
            "Bc2",
            "c5"
          ]
        },
        "query3": {
          "neutral_move": "Na5",
          "neutral_uci": "c6a5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5 Nbd2",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 69,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "plan_execute": [
            "Bc2",
            "c5",
            "Nbd2"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c6a5",
          "positional_uci": "c6a5",
          "neutral_uci": "c6a5",
          "consensus_move": "c6a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc2",
              "c5",
              "Nbd2"
            ],
            "execute": [
              "Bc2",
              "c5",
              "Nbd2"
            ]
          },
          "positional": {
            "full": [
              "Bc2",
              "c5"
            ],
            "execute": [
              "Bc2",
              "c5"
            ]
          },
          "neutral": {
            "full": [
              "Bc2",
              "c5",
              "Nbd2"
            ],
            "execute": [
              "Bc2",
              "c5",
              "Nbd2"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "full_moves": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 69,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 204,
          "total_tokens": 812
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 69,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 b kq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc4",
          "aggressive_uci": "a5c4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 b6 Qe2",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 75,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b6",
            "Qe2"
          ],
          "plan_execute": [
            "b6",
            "Qe2"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": "a5c4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 \nNc4 b3 Qe7",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 76,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Qe7"
          ],
          "plan_execute": [
            "b3",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Nc4",
          "neutral_uci": "a5c4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 \nNc4 b3 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 76,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Qe7"
          ],
          "plan_execute": [
            "b3",
            "Qe7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a5c4",
          "positional_uci": "a5c4",
          "neutral_uci": "a5c4",
          "consensus_move": "a5c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b6",
              "Qe2"
            ],
            "execute": [
              "b6",
              "Qe2"
            ]
          },
          "positional": {
            "full": [
              "b3",
              "Qe7"
            ],
            "execute": [
              "b3",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b3",
              "Qe7"
            ],
            "execute": [
              "b3",
              "Qe7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b3",
            "Qe7"
          ],
          "full_moves": [
            "b3",
            "Qe7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 75,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 76,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 76,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 227,
          "total_tokens": 862
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 75,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 76,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 76,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/np2p3/4P3/2P2N2/PPBP1PPP/RNBQR1K1 b kq - 2 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nb6",
          "aggressive_uci": "c4b6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a4 Qe7 \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a4 Qe7 Nbd7",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 171,
            "total_tokens": 391,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a4",
            "Qe7",
            "Nbd7"
          ],
          "plan_execute": [
            "b4",
            "a4",
            "Qe7"
          ]
        },
        "query2": {
          "positional_move": "Nb6",
          "positional_uci": "c4b6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a5",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Nb6",
          "neutral_uci": "c4b6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a5 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a5",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a5",
            "Qe7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c4b6",
          "positional_uci": "c4b6",
          "neutral_uci": "c4b6",
          "consensus_move": "c4b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b4",
              "a4",
              "Qe7",
              "Nbd7"
            ],
            "execute": [
              "b4",
              "a4",
              "Qe7"
            ]
          },
          "positional": {
            "full": [
              "b4",
              "a5",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b4",
              "a5",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a5",
              "Qe7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b4",
            "a5",
            "Qe7"
          ],
          "full_moves": [
            "b4",
            "a5",
            "Qe7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 171,
            "total_tokens": 391,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 339,
          "total_tokens": 998
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 171,
            "total_tokens": 391,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2PP1N2/PPB2PPP/RNBQR1K1 b kq - 0 10"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nNc4 Qe7 Nbd4 Qe6",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Nbd4",
            "Qe6"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Nbd4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Nbd4",
              "Qe6"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Nbd4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 341,
          "total_tokens": 1072
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 26,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 341,
          "total_tokens": 1072
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 26,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Qe2 Nc4 Nxb4 Qe3",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 114,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxb4",
            "Qe3"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxb4"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nNc4 Qe7 Nbd4 Qe6",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Nbd4",
            "Qe6"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Nbd4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxb4",
              "Qe3"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxb4"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Nbd4",
              "Qe6"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Nbd4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 114,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 342,
          "total_tokens": 1073
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 114,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    }
  ],
  "white_errors": [],
  "black_errors": [],
  "white_plan_log": [
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1,
      "plan_full": [
        "e5",
        "Nf3",
        "Nc6",
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d6",
        "d4",
        "Bg4",
        "d5",
        "Na5",
        "Bc2",
        "c6",
        "dxc6",
        "Nxc6",
        "Nbd2",
        "d5",
        "h3",
        "Bh5",
        "g4",
        "Bg6",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "Nf4",
        "Bxg6",
        "fxg6",
        "Qf3",
        "Nd3",
        "Qd5+",
        "Qxd5",
        "Rxd5",
        "Nxf2",
        "Kg2",
        "Rae8",
        "Nf3",
        "Nxh3",
        "Kxh3",
        "Rxf3",
        "Kg2",
        "Ref8",
        "Rd2",
        "Bh4",
        "Re2",
        "Rg3+",
        "Kh2",
        "Rxg4",
        "Be3",
        "Re4",
        "Kg2",
        "Rfe8",
        "Kf3",
        "Bg5",
        "Rae1",
        "Rxe3",
        "Rxe3",
        "Rxe3",
        "Rxe3",
        "Bxe3",
        "Kxe3",
        "Kf7",
        "b3",
        "Ke6",
        "c4",
        "bxc4",
        "bxc4",
        "Ke5",
        "a4",
        "a5"
      ],
      "plan_execute": [
        "e5",
        "Nf3",
        "Nc6"
      ],
      "selected_move": "e4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "e5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nf3",
      "move_uci": "g1f3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nc6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 5,
      "attempt": 1,
      "plan_full": [
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "Qf1",
        "Qh5",
        "a4",
        "Rfe8",
        "axb5",
        "axb5",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Qxc6",
        "Bxg3",
        "Qg2",
        "Bf4",
        "Ra8",
        "Bb8",
        "Kh1",
        "Rg6",
        "Bf4",
        "Rxe1+",
        "Nf1",
        "Rxf1+",
        "Qxf1",
        "Bf3+",
        "Qg2",
        "Bxg2+",
        "Kg1",
        "Bxa8+",
        "Kf1",
        "Qd1#",
        "Bb8+",
        "Bc7",
        "Bb6",
        "Bc5"
      ],
      "plan_execute": [
        "a6",
        "Ba4",
        "Nf6"
      ],
      "selected_move": "Bb5"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "a6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Ba4",
      "move_uci": "b5a4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nf6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 9,
      "attempt": 1,
      "plan_full": [
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "d5",
        "Ne7",
        "Nh4",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qf3",
        "Ng8",
        "Nhf5",
        "Qc7",
        "Qg4",
        "Bxf5",
        "Nxf5",
        "Qc1",
        "Qg7#"
      ],
      "plan_execute": [
        "h3",
        "Na5",
        "Bc2"
      ],
      "selected_move": "O-O"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "h3",
      "actual_san": "Be7"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 11,
      "attempt": 1,
      "plan_full": [
        "b5",
        "Bb3",
        "d6",
        "c3",
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "d5",
        "Ne7",
        "Nh4",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qf3",
        "Ng8",
        "Nhf5",
        "Qb6",
        "Qg4",
        "Bxf5",
        "Nxf5",
        "Be2",
        "Qg7#"
      ],
      "plan_execute": [
        "b5",
        "Bb3",
        "d6"
      ],
      "selected_move": "Re1"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "b5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Bb3",
      "move_uci": "a4b3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "d6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 15,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "Qd2",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qh6",
        "Rg8",
        "Qxf6+",
        "Rg7",
        "Nh5",
        "Rg8",
        "Ng5",
        "Be8",
        "Nxg7",
        "Rxg7",
        "dxe5",
        "dxe5",
        "Rd1",
        "Qe7",
        "Qxe7",
        "Nxe7",
        "Rd8",
        "Rg8",
        "Nf3",
        "f6",
        "Bd3",
        "Kg7",
        "Rb8",
        "Bc6",
        "Rxg8+",
        "Kxg8",
        "Kf1",
        "Kf7",
        "Ke2",
        "Ke6",
        "Ke3",
        "Kd6",
        "Nd2",
        "Kc5",
        "a3",
        "Ng6",
        "g3",
        "Bd7",
        "h4",
        "Nf8",
        "Nb1",
        "Ne6",
        "Nc3",
        "Nd4",
        "Nd5",
        "f5",
        "Nf6",
        "fxe4",
        "Nxe4+",
        "Kd5",
        "Nf6+",
        "Ke6",
        "Nxd7",
        "Kxd7",
        "Bxh7",
        "Ke6",
        "Bd3",
        "Kf6",
        "f4",
        "Nf5+",
        "Bxf5",
        "Kxf5",
        "fxe5",
        "Kxe5",
        "g4",
        "Kf6",
        "Kd4",
        "Ke6",
        "Kc5",
        "Ke5",
        "Kxb5",
        "Kf4",
        "g5",
        "Kf5",
        "Kxa4",
        "Kg6",
        "Kb5",
        "Kh5",
        "a4",
        "Kg6",
        "a5",
        "Kh5",
        "a6",
        "Kg6",
        "a7",
        "Kh5",
        "a8=Q",
        "Kg6",
        "Qe4+",
        "Kh5",
        "Qf3+",
        "Kg6",
        "Qg4",
        "Kg7",
        "h5",
        "Kh7",
        "Qd7+",
        "Kg8",
        "g6",
        "Kh8",
        "Qh7#",
        "e4",
        "d5",
        "e5",
        "dxe6"
      ],
      "plan_execute": [
        "O-O",
        "h3",
        "Na5"
      ],
      "selected_move": "c3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "Na5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 17,
      "attempt": 1,
      "plan_full": [
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "O-O",
        "Nf1",
        "Bg4",
        "d5",
        "Nc4",
        "h3",
        "Bd7",
        "b3",
        "Nb6",
        "Ng3",
        "g6",
        "Bh6",
        "Rfe8",
        "Qd2",
        "Bf8",
        "Bxf8",
        "Rxf8",
        "Qh6",
        "Kh8",
        "Ng5",
        "Be8",
        "f4",
        "Rg8",
        "fxe5",
        "dxe5",
        "Rf1",
        "Qd6",
        "Rxf6",
        "Qxf6",
        "Qxh7#"
      ],
      "plan_execute": [
        "c5",
        "d4",
        "Qc7"
      ],
      "selected_move": "Bc2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "c5",
      "actual_san": "Nc4"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 19,
      "attempt": 1,
      "plan_full": [
        "Nb6",
        "Nbd2",
        "O-O",
        "Nf1",
        "c5",
        "Ng3",
        "Qc7",
        "h3",
        "Re8",
        "Be3",
        "Bf8",
        "Rc1",
        "d5",
        "d4",
        "exd4",
        "cxd4",
        "dxe4",
        "Ng5",
        "Bb7",
        "dxc5",
        "Nc4",
        "Bd4",
        "Rad8",
        "N5xe4",
        "Nxe4",
        "Nxe4",
        "Bxc5",
        "Nxc5",
        "Rxe1+",
        "Qxe1",
        "Bc6",
        "Nb3",
        "Qf4",
        "Be3",
        "Qf6",
        "Rd1",
        "Re8",
        "Nd4",
        "Bb7",
        "b3",
        "Nxe3",
        "fxe3",
        "Qg5",
        "Qf2",
        "Rxe3",
        "Nf5",
        "Re8",
        "Nd6",
        "Re7",
        "Nxb7",
        "Rxb7",
        "Qf5",
        "Qe3+",
        "Kh1",
        "g6",
        "Qc8+",
        "Kg7",
        "Qxb7",
        "Qe2",
        "Qe4",
        "Qh5",
        "Qd4+",
        "Kh6",
        "Qf4+",
        "Kg7",
        "Rd7",
        "g5",
        "Qe5+",
        "Kh6",
        "Qf6+",
        "Qg6",
        "Bxg6",
        "hxg6",
        "Qh8#",
        "Nf6",
        "Qxf6",
        "Qxf6",
        "Kh5",
        "Qh8#"
      ],
      "plan_execute": [
        "Nb6",
        "Nbd2",
        "O-O"
      ],
      "selected_move": "d3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nb6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nbd2",
      "move_uci": "b1d2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "b4"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 23,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "Nf1",
        "Bg4",
        "h3",
        "Bh5",
        "Ng3",
        "Bg6",
        "Nh4",
        "d5",
        "Nxg6",
        "fxg6",
        "exd5",
        "Nfxd5",
        "Rxe5",
        "Nxb4",
        "Bb3+",
        "Kh8",
        "Qe2",
        "Bf6",
        "Re4",
        "Nxd3",
        "Be3",
        "Nxb2",
        "Rb1",
        "Nd3",
        "Rd1",
        "Nc5",
        "Rxd8",
        "Raxd8",
        "Bxc5",
        "Nd7",
        "Bxf8",
        "Rxf8",
        "Re8",
        "h6",
        "Rxf8+",
        "Nxf8",
        "Qe8",
        "Kh7",
        "Qxf8",
        "g5",
        "Bc2+",
        "g6",
        "Qf7+",
        "Bg7",
        "Bxg6+",
        "Kh8",
        "Qe8+",
        "Bf8",
        "Qxf8#",
        "e4",
        "Nc6",
        "Nc4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4"
      ],
      "plan_execute": [
        "O-O",
        "Nf1",
        "Bg4"
      ],
      "selected_move": "cxb4"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "a5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 25,
      "attempt": 1,
      "plan_full": [
        "Rxa5",
        "Nb3",
        "Ra8",
        "d4",
        "exd4",
        "Nbxd4",
        "Bb7",
        "Nf5",
        "O-O",
        "Nxe7+",
        "Qxe7",
        "e5",
        "dxe5",
        "Nxe5",
        "Qc5",
        "Bg5",
        "Nfd5",
        "Qd3",
        "g6",
        "Bh6",
        "Rfe8",
        "Qf3",
        "f5",
        "Bxf5",
        "gxf5",
        "Qg3+",
        "Kh8",
        "Qg7#",
        "Nf6",
        "Nf7#",
        "Kg8",
        "Qxf6",
        "Qf8",
        "Bxf8",
        "Rxf8",
        "Nh6#",
        "Kh8",
        "Qe5#",
        "Kh8",
        "Qxc7#",
        "Kh8",
        "Qxb7#",
        "Kh8",
        "Qxb6#",
        "Kh8",
        "Qd4#",
        "Kh8",
        "Re7#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxh7#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#"
      ],
      "plan_execute": [
        "Rxa5",
        "Nb3",
        "Ra8"
      ],
      "selected_move": "bxa5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1,
      "plan_full": [
        "Nf3",
        "Nc6",
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "d6",
        "c3",
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "Qd2",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qh6",
        "Rg8",
        "Qxf6+",
        "Rg7",
        "Nh5",
        "Rg8",
        "Ng5",
        "Be8",
        "Nxg7",
        "Rxg7",
        "dxe5",
        "dxe5",
        "Rd1",
        "Qe7",
        "Qxe7",
        "Nxe7",
        "Rd8",
        "Rg8",
        "Nf3",
        "f6",
        "Bd3",
        "Kg7",
        "Rb8",
        "Bc6",
        "Rxg8+",
        "Kxg8",
        "Kf1",
        "Kf7",
        "Ke2",
        "Ke6",
        "Ke3",
        "Kd6",
        "Nd2",
        "Kc5",
        "a3",
        "Bd7",
        "Nb1",
        "Nc6",
        "Nc3",
        "Nd4",
        "Nd5",
        "f5",
        "Nf6",
        "f4+",
        "Kd2",
        "Be6",
        "Nxh7",
        "b4",
        "Ng5",
        "Bg8",
        "h4",
        "bxa3",
        "bxa3",
        "Nb3+",
        "Kc3",
        "Nd4",
        "h5",
        "Nb5+",
        "Bxb5",
        "Kxb5",
        "h6",
        "Kc5",
        "h7",
        "Bxh7",
        "Nxh7",
        "Kd6",
        "Ng5",
        "Kc5",
        "Nf3",
        "Kd6",
        "Kb4",
        "Ke6",
        "Kxa4",
        "Kd6",
        "Kb5",
        "Ke6",
        "a4",
        "Kd6",
        "a5",
        "Ke6",
        "a6",
        "Kd6",
        "a7",
        "Ke6",
        "a8=Q",
        "Kd6",
        "Qd5+",
        "Ke7",
        "Qxe5+",
        "Kd7",
        "Qxf4",
        "Ke6",
        "Qf5+",
        "Kd6",
        "Qd5+",
        "Ke7",
        "Qc6",
        "Kf7",
        "Qd6",
        "Kg7",
        "Qe6",
        "Kh7",
        "Qf6",
        "Kg8"
      ],
      "plan_execute": [
        "Nf3",
        "Nc6",
        "Bb5"
      ],
      "selected_move": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "a4",
        "Qh5",
        "axb5",
        "axb5",
        "Ra6",
        "Bc7",
        "Qf1",
        "Rfe8",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Rxc6",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qh1",
        "Bb8",
        "Rxe6",
        "Rxe6",
        "Qb7",
        "Re8",
        "Qc6",
        "f6",
        "f3",
        "Bh3",
        "Bf2",
        "Rxe1+",
        "Bxe1",
        "h6",
        "g4",
        "Bxg4",
        "fxg4",
        "Qxg4+",
        "Qg2",
        "Qd1",
        "Qd5+",
        "Kh7",
        "Qe4+",
        "Kg8",
        "Qe8+",
        "Kh7",
        "Qxb8",
        "Qxe1+",
        "Nf1",
        "Qe2",
        "Qg3",
        "Qxb2",
        "Qd3+",
        "Kg8",
        "d5",
        "b4",
        "cxb4",
        "Qxb4",
        "d6",
        "Qb6+",
        "Ne3",
        "Kf7",
        "Qd5+",
        "Ke8",
        "Qe6+",
        "Kd8",
        "Qe7+",
        "Kc8",
        "d7+",
        "Kb7",
        "d8=Q+",
        "Ka6",
        "Qa3+",
        "Kb5",
        "Qd5+",
        "Qc5",
        "Qdxc5#",
        "Qxc5",
        "Qxc5+",
        "Kxc5",
        "Nf5",
        "g6",
        "Nxh6",
        "Kd5",
        "Kf2",
        "Ke4",
        "Kg3",
        "f5",
        "h4",
        "Ke5",
        "Kf3",
        "Kf6",
        "Kf4",
        "Kg7",
        "Kg5",
        "Kh7",
        "Nf7",
        "Kg7",
        "Ne5",
        "Kh7",
        "Nxg6",
        "Kg7",
        "Kxf5",
        "Kh6",
        "Kg4",
        "Kxg6",
        "h5+",
        "Kh6",
        "Kh4",
        "Kg7",
        "Kg5",
        "Kh7",
        "h6",
        "Kg8",
        "Kg6",
        "Kh8",
        "h7"
      ],
      "plan_execute": [
        "Bb5",
        "a6",
        "Ba4"
      ],
      "selected_move": "Nc6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1,
      "plan_full": [
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Qh5",
        "c4",
        "bxc4",
        "Nxc4",
        "Bh3",
        "c3",
        "Nxc3",
        "Nxc6",
        "Bd5"
      ],
      "plan_execute": [
        "Ba4",
        "Nf6",
        "O-O"
      ],
      "selected_move": "a6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1,
      "plan_full": [
        "d3",
        "Bc5",
        "O-O",
        "d6",
        "c3",
        "O-O",
        "Bg5",
        "h6",
        "Bh4",
        "g5",
        "Bg3",
        "Ba7",
        "Nbd2",
        "Nh5",
        "Nxe5",
        "Nxg3",
        "Nxc6",
        "bxc6",
        "hxg3",
        "d5",
        "Bb3",
        "Be6",
        "d4",
        "c5",
        "exd5",
        "Bxd5",
        "Bxd5",
        "Qxd5",
        "Qh5",
        "Kg7",
        "Nf3",
        "cxd4",
        "cxd4",
        "Bxd4",
        "Rad1",
        "c5",
        "b4",
        "Qxa2",
        "Nxd4",
        "cxd4",
        "Rxd4",
        "Rad8",
        "Rfd1",
        "Rxd4",
        "Rxd4",
        "Qa1+",
        "Rd1",
        "Qb2"
      ],
      "plan_execute": [
        "d3",
        "Bc5",
        "O-O"
      ],
      "selected_move": "Nf6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "O-O",
        "Nc3",
        "d6",
        "Bg5",
        "h6",
        "Bh4",
        "g5",
        "Nxg5",
        "hxg5",
        "Bxg5",
        "Be6",
        "Qf3",
        "Kg7",
        "Qg3",
        "Nh5",
        "Qh4",
        "f6",
        "Bxe6",
        "fxg5",
        "Qxh5",
        "Qf6",
        "Bf5",
        "Rh8",
        "Qg4",
        "Rh4",
        "Qg3",
        "Rah8",
        "Nd5",
        "Qh6",
        "h3",
        "Nd4",
        "Rae1",
        "Nxf5",
        "exf5",
        "g4",
        "f6+",
        "Kf7",
        "Re4",
        "gxh3",
        "Rxh4",
        "Qxh4",
        "Qg7+",
        "Ke6",
        "Nxc7+",
        "Kf5",
        "f7",
        "hxg2",
        "f8=Q+",
        "Rxf8",
        "Qxf8+",
        "Kg6",
        "Qg8+",
        "Kf6",
        "Nd5+",
        "Kf5",
        "Qf7+",
        "Kg5",
        "Qf6+",
        "Kh5",
        "Qxh4+",
        "Kxh4",
        "Kxg2",
        "Kg4",
        "f3+",
        "Kf5",
        "Rh1",
        "Ke6",
        "c4",
        "b5",
        "Rh6+",
        "Kd7",
        "b4",
        "Bd4",
        "cxb5",
        "axb5",
        "Rh7+",
        "Kc6",
        "Ne7+",
        "Kd7",
        "Nf5+",
        "Ke6",
        "Nxd4+",
        "exd4",
        "Rh5",
        "d5",
        "Kg3",
        "Kd6",
        "Kf4",
        "Ke6",
        "Rh6+",
        "Kd7",
        "Ke5",
        "Ke7",
        "Rh7+",
        "Kf8",
        "Kf6",
        "Kg8",
        "Ra7",
        "Kh8",
        "Kg6",
        "Kg8",
        "Ra8#",
        "Bf8",
        "Rxf8#",
        "Bf8",
        "Rxf8#",
        "Kxf8",
        "Kf6",
        "Ke8",
        "Ke6",
        "Kd8",
        "Kxd5",
        "Kc7",
        "Kc5",
        "Kb7",
        "Kxb5",
        "Ka7",
        "Kc6",
        "Ka6",
        "b5+",
        "Ka7",
        "b6+",
        "Kb8",
        "b7",
        "Ka7",
        "Kc7",
        "Ka6",
        "b8=Q",
        "Ka5",
        "Qb3",
        "Ka6",
        "Qb6#",
        "Kd5",
        "Qd6#",
        "Kc4",
        "Qc5#",
        "Kd3",
        "d5",
        "Ke2",
        "d6",
        "Kxf3",
        "d7",
        "Ke4",
        "d8=Q",
        "Kf4",
        "Qce7",
        "Kf5"
      ],
      "plan_execute": [
        "O-O",
        "O-O",
        "Nc3"
      ],
      "selected_move": "Bc5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "O-O",
      "move_uci": "e8g8"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1,
      "plan_full": [
        "e5",
        "Nf3",
        "Nc6",
        "Bb5",
        "Bc5",
        "O-O",
        "Nf6",
        "d3",
        "O-O",
        "Bg5",
        "d6",
        "Nc3",
        "Bg4",
        "Nd5",
        "Nd4",
        "Bxf6",
        "gxf6",
        "Bc4",
        "c6",
        "Ne3",
        "Bxf3",
        "gxf3",
        "Kh8",
        "c3",
        "Ne6",
        "Nf5",
        "Rg8+",
        "Kh1",
        "d5",
        "Bb3",
        "Nf4",
        "d4",
        "Bb6",
        "Qd2",
        "Rg5",
        "Rg1",
        "Qd7",
        "Rxg5",
        "fxg5",
        "Rg1",
        "f6",
        "Rg3",
        "Rd8",
        "h4",
        "h6",
        "hxg5",
        "hxg5",
        "Kg1",
        "Qh7",
        "Bc2",
        "Rd7",
        "Qe1",
        "Kg8",
        "Qf1",
        "Kf8",
        "a4",
        "a5",
        "b4",
        "axb4",
        "cxb4",
        "Bxd4",
        "Nxd4",
        "exd4",
        "Qd1",
        "d3",
        "Bxd3",
        "dxe4",
        "fxe4",
        "Qxe4",
        "Bxe4",
        "Rxd1+",
        "Kh2",
        "Rd4",
        "Bf5",
        "Rxb4",
        "Ra3",
        "Nd5",
        "a5",
        "Rf4",
        "Bc8",
        "Rxf2+",
        "Kg3",
        "Rb2",
        "a6",
        "bxa6",
        "Rxa6",
        "Rb6",
        "Ra8",
        "Ke7",
        "Bf5",
        "Kd6",
        "Rd8+",
        "Ke5",
        "Bg6",
        "Rb3+",
        "Kf2",
        "Kf4",
        "Rc8",
        "Rb2+",
        "Ke1",
        "Ne7",
        "Rf8",
        "Nxg6",
        "Rxf6+",
        "Ke3",
        "Re6+",
        "Kd3",
        "Rxg6",
        "c5",
        "Rxg5",
        "c4",
        "Rd5+",
        "Kc2",
        "Rd2+",
        "Kc1",
        "Rd1+",
        "Kc2",
        "Rd2+",
        "Kc3",
        "Rd1",
        "Rh2",
        "Rd8",
        "Kc2",
        "Rc8",
        "c3",
        "Rc7",
        "Kb2",
        "Rb7+",
        "Kc1",
        "Rc7",
        "c2",
        "Rc8",
        "Rh5",
        "Rc7",
        "Re5+",
        "Kf2",
        "Kd2",
        "Rd7+",
        "Kc3",
        "Rc7+",
        "Kd3",
        "Rd7+",
        "Kc4",
        "Rc7+",
        "Rc5",
        "Rxc5+",
        "Kxc5",
        "Ke2",
        "c1=Q",
        "Kd3",
        "Qc4+"
      ],
      "plan_execute": [
        "e5",
        "Nf3",
        "Nc6"
      ],
      "selected_move": "e4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "e5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nf3",
      "move_uci": "g1f3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nc6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 5,
      "attempt": 1,
      "plan_full": [
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "a4",
        "Qh5",
        "axb5",
        "axb5",
        "Ra6",
        "Bb8",
        "Qf1",
        "Rfe8",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Rxc6",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qg2",
        "Bh3"
      ],
      "plan_execute": [
        "a6",
        "Ba4",
        "Nf6"
      ],
      "selected_move": "Bb5"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "a6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Ba4",
      "move_uci": "b5a4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nf6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 9,
      "attempt": 1,
      "plan_full": [
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Qe2",
        "h6",
        "Red1",
        "Bf8",
        "Nf1",
        "exd4",
        "Nxd4",
        "Nxd4",
        "Bxd4",
        "Rxc1",
        "Rxc1",
        "Re8",
        "Ng3",
        "Nh7",
        "Qd3",
        "g6",
        "f4",
        "Bg7",
        "Bxg7",
        "Kxg7",
        "Qxd6",
        "Nf6",
        "Qd4",
        "Qb8",
        "e5",
        "Ng8",
        "Qxd7",
        "Rd8",
        "Qc6",
        "Rd2",
        "Qc3",
        "Qb6+",
        "Kh2",
        "Qf2",
        "e6+",
        "Kh7",
        "Be4",
        "fxe6",
        "Qc7+",
        "Kh8",
        "Qe5+",
        "Kh7",
        "Rc7+",
        "Ne7",
        "Rxe7+",
        "Kg8",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7#",
        "Nf6",
        "Qg7"
      ],
      "plan_execute": [
        "h3",
        "Na5",
        "Bc2"
      ],
      "selected_move": "O-O"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "h3",
      "actual_san": "Be7"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 11,
      "attempt": 1,
      "plan_full": [
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "Qf1",
        "Qh5",
        "a4",
        "Rfe8",
        "axb5",
        "axb5",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Qxc6",
        "Bxg3",
        "Qg2",
        "Bf4",
        "Ra8",
        "Bb8",
        "Kh1",
        "Rg6",
        "Bf4",
        "Rxe1+",
        "Nf1",
        "Rxf1+",
        "Qxf1",
        "Bf3+",
        "Qg2",
        "Bxg2+",
        "Kg1",
        "Bxa8+",
        "Kf1",
        "Qd1#",
        "Bc8+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+",
        "Ke7",
        "Bg5+",
        "Kf8",
        "Bf4+"
      ],
      "plan_execute": [
        "Qh4",
        "g3",
        "Qh3"
      ],
      "selected_move": "Re1"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "Qh4",
      "actual_san": "b5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 13,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "Qf1",
        "Qh5",
        "a4",
        "Rfe8",
        "axb5",
        "axb5",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Qxc6",
        "Bxg3",
        "Qg2",
        "Bf4",
        "Ra8",
        "Bb8",
        "Kh1",
        "Rg6",
        "Bf4",
        "Rxe1+",
        "Nf1",
        "Bf3",
        "Rxb8+",
        "Re8",
        "Rxe8#",
        "Bf8",
        "Ng3",
        "Bxg2+",
        "Kxg2",
        "Qd5+",
        "f3",
        "Re6",
        "Rb8",
        "h6",
        "Ne4",
        "Rxe4",
        "fxe4",
        "Qxe4+",
        "Kg3+",
        "Kh7",
        "Rxb5",
        "g5",
        "Be5",
        "f5",
        "Rb8",
        "f4+",
        "Kf2",
        "Qe3+",
        "Kf1",
        "f3",
        "Rb7+",
        "Kg6",
        "Rg7+",
        "Kh5",
        "Bg3",
        "Qe2+",
        "Kg1",
        "Qg2#",
        "e4",
        "d5",
        "Nc3",
        "Nf6",
        "Bg5",
        "O-O",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "Bd6",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4",
        "Qd3",
        "Bf5",
        "Qe2",
        "Bg4"
      ],
      "plan_execute": [
        "O-O",
        "c3",
        "d5"
      ],
      "selected_move": "Bb3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "d6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 15,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "Qd2",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qh6",
        "Rg8",
        "Qxf6+",
        "Rg7",
        "Nh5",
        "Rg8",
        "Ng5",
        "Be8",
        "Nxg7",
        "Rxg7",
        "dxe5",
        "dxe5",
        "Rd1",
        "Qe7",
        "Qxe7",
        "Nxe7",
        "Rd8",
        "Rg8",
        "Nf3",
        "f6",
        "Bd3",
        "Kg7",
        "Rb8",
        "Bc6",
        "Rxg8+",
        "Kxg8",
        "Kf1",
        "Kf7",
        "Ke2",
        "Ke6",
        "Ke3",
        "Kd6",
        "Nd2",
        "Kc5",
        "a3",
        "Ng6",
        "g3",
        "Bd7",
        "h4",
        "Nf8",
        "Nb1",
        "Ne6",
        "Nc3",
        "Nd4",
        "Nd5",
        "f5",
        "Nf6",
        "f4+",
        "gxf4",
        "exf4+",
        "Kxf4",
        "Be6",
        "Nxh7",
        "Bc4",
        "Bxc4",
        "Kxc4",
        "Nf6",
        "Kb3",
        "h5",
        "Kxb2",
        "h6",
        "Kxa3",
        "h7",
        "b4",
        "h8=Q",
        "b3",
        "Nd5",
        "b2",
        "Qxd4",
        "b1=Q",
        "Qc3+",
        "Qb3",
        "Qxb3+",
        "axb3",
        "e5",
        "b2",
        "Nc3",
        "Kb3",
        "Nb1",
        "Kc2",
        "e6",
        "Kxb1",
        "e7",
        "Ka2",
        "e8=Q",
        "b1=Q",
        "Qa4+",
        "Kb2",
        "Qb4+",
        "Kc2",
        "Qxb1+",
        "Kxb1",
        "Ke5",
        "Kc2",
        "f4",
        "Kd3",
        "f5",
        "Ke3",
        "f6",
        "Kf3",
        "f7",
        "Ke3",
        "f8=Q",
        "Kd3",
        "Qf4",
        "Kc3",
        "Qd4+",
        "Kb3",
        "Kd5",
        "Kc2",
        "Qe3",
        "Kb2",
        "Kc4",
        "Kc2",
        "Qe2+"
      ],
      "plan_execute": [
        "O-O",
        "h3",
        "Na5"
      ],
      "selected_move": "c3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "Na5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 17,
      "attempt": 1,
      "plan_full": [
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "O-O",
        "Nf1",
        "Bg4",
        "d5",
        "Nc4",
        "h3",
        "Bd7",
        "Ng3",
        "g6",
        "b3",
        "Nb6",
        "Bh6",
        "Rfe8",
        "Qd2",
        "c4",
        "b4",
        "a5",
        "a3",
        "Ra7",
        "Nh2",
        "Rea8",
        "Rac1",
        "axb4",
        "axb4",
        "Ra2",
        "f4",
        "exf4",
        "Qxf4",
        "Na4",
        "Bb1",
        "Ra3",
        "Ne2",
        "Nh5",
        "Qf2",
        "Bf6",
        "Rf1",
        "Be8",
        "g4",
        "Bxc3",
        "gxh5",
        "Bxb4",
        "hxg6",
        "hxg6",
        "Qf6",
        "Bc5+",
        "Kh1",
        "Bd4",
        "Nxd4",
        "Rxh3",
        "Qg7#",
        "e4",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e5",
        "Nxe5",
        "Qh7#",
        "e6",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e7",
        "Nxe7",
        "Qh7#",
        "e8=Q",
        "Nxe8",
        "Qh7#",
        "e5",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e6",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e7",
        "Nxe7",
        "Qh7#",
        "e8=Q",
        "Nxe8",
        "Qh7#",
        "e5",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e6",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e7",
        "Nxe7",
        "Qh7#",
        "e8=Q",
        "Nxe8",
        "Qh7#",
        "e5",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e6",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e7",
        "Nxe7",
        "Qh7#",
        "e8=Q",
        "Nxe8",
        "Qh7#",
        "e5",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e6",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e7",
        "Nxe7",
        "Qh7#",
        "e8=Q",
        "Nxe8",
        "Qh7#",
        "e5",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e6",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e7",
        "Nxe7",
        "Qh7#",
        "e8=Q",
        "Nxe8",
        "Qh7#",
        "e5",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e6",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e7",
        "Nxe7",
        "Qh7#",
        "e8=Q",
        "Nxe8",
        "Qh7#",
        "e5",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e6",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e7",
        "Nxe7",
        "Qh7#",
        "e8=Q",
        "Nxe8",
        "Qh7#",
        "e5",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e6",
        "Nf6+",
        "Kh8",
        "Qxh7#",
        "e7",
        "Nxe7",
        "Qh7#",
        "e8=Q"
      ],
      "plan_execute": [
        "c5",
        "d4",
        "Qc7"
      ],
      "selected_move": "Bc2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "c5",
      "actual_san": "Nc4"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 19,
      "attempt": 1,
      "plan_full": [
        "Nb6",
        "Nbd2",
        "O-O",
        "Nf1",
        "c5",
        "Ng3",
        "Qc7",
        "h3",
        "Be6",
        "Be3",
        "Rfd8",
        "Qe2",
        "d5",
        "exd5",
        "Nbxd5",
        "Bd2",
        "Bd6",
        "Ng5",
        "Re8",
        "Nxe6",
        "Rxe6",
        "Ne4",
        "Nxe4",
        "dxe4",
        "Nf4",
        "Bxf4",
        "exf4",
        "Rad1",
        "Rae8",
        "Qd3",
        "Be5",
        "Qd7",
        "Qb6",
        "Rd5",
        "c4",
        "Red1",
        "g6",
        "Kf1",
        "Kg7",
        "f3",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6",
        "Red1",
        "Qe3",
        "Re1",
        "Qb6"
      ],
      "plan_execute": [
        "Nb6",
        "Nbd2",
        "O-O"
      ],
      "selected_move": "d3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nb6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nbd2",
      "move_uci": "b1d2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "b4"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 23,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "Nf1",
        "Bg4",
        "h3",
        "Bh5",
        "Ng3",
        "Bg6",
        "Nh4",
        "d5",
        "Nxg6",
        "fxg6",
        "Bb3",
        "Bxb4",
        "Bd2",
        "Bxd2",
        "Qxd2",
        "Kh8",
        "exd5",
        "Nbxd5",
        "Rxe5",
        "c6",
        "Rae1",
        "Qb6",
        "Ne4",
        "Nxe4",
        "R1xe4",
        "Nf6",
        "Re2",
        "Rad8",
        "Qc3",
        "Nd5",
        "Bxd5",
        "cxd5",
        "Re7",
        "d4",
        "Qc7",
        "Qxc7",
        "Rxc7",
        "Rb8",
        "Ree7",
        "Rxb2",
        "Rxg7",
        "Rfxf2",
        "Rxh7+",
        "Kg8",
        "Rhg7+",
        "Kf8",
        "Rxg6",
        "Rxa2",
        "h4",
        "Rfd2",
        "h5",
        "Rxd3",
        "h6",
        "Rd1+",
        "Kh2",
        "Raa1",
        "h7",
        "Rh1+",
        "Kg3",
        "Ra3+",
        "Kf4",
        "Rh4+",
        "Kg5",
        "Rg3+",
        "Kxh4",
        "Rxg6",
        "h8=Q+",
        "Rg8",
        "Qf6+",
        "Ke8",
        "Qe7#",
        "e5",
        "dxe5",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qh5+",
        "Kg8",
        "Qg5"
      ],
      "plan_execute": [
        "O-O",
        "Nf1",
        "Bg4"
      ],
      "selected_move": "cxb4"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "a5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 25,
      "attempt": 1,
      "plan_full": [
        "Rxa5",
        "Nb3",
        "Ra8",
        "d4",
        "exd4",
        "Nbxd4",
        "Bb7",
        "Nf5",
        "O-O",
        "Bg5",
        "h6",
        "Bh4",
        "g5",
        "Nxh6+",
        "Kg7",
        "Bxg5",
        "Nh7",
        "Nf5+",
        "Kg6",
        "Bxe7",
        "Qd7",
        "N3h4#",
        "e4",
        "Nxe7",
        "Nxe7+",
        "Kh8",
        "Qd4+",
        "Kg8",
        "Qg5+",
        "Kh8",
        "Qg7#",
        "e5",
        "Nxe5",
        "Nxe5+",
        "Kh8",
        "Qg7#",
        "e6",
        "Nxe6",
        "Nxe6+",
        "Kh8",
        "Qg7#",
        "e7",
        "Nxe7",
        "Nxe7+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8",
        "Nxe8+",
        "Kh8",
        "Qg7#",
        "e8=Q",
        "Nxe8"
      ],
      "plan_execute": [
        "Rxa5",
        "Nb3",
        "Ra8"
      ],
      "selected_move": "bxa5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1,
      "plan_full": [
        "Nf3",
        "Nc6",
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "d6",
        "c3",
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "Qd2",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qh6",
        "Rg8",
        "Qxf6+",
        "Rg7",
        "Nh5",
        "Rg8",
        "Ng5",
        "Be8",
        "Nxg7",
        "Rxg7",
        "dxe5",
        "dxe5",
        "Rd1",
        "Qe7",
        "Qxe7",
        "Nxe7",
        "Rd8",
        "Rg8",
        "Nf3",
        "f6",
        "Bd3",
        "Kg7",
        "Rb8",
        "Bf7",
        "Rxb5",
        "Bxa2",
        "Ra5",
        "Bb3",
        "Nd2",
        "Nc6",
        "Ra6",
        "Nb4",
        "Ra7+",
        "Kg6",
        "Bc4",
        "Bxc4",
        "Nxc4",
        "Nd3",
        "Rxa4",
        "Rc8",
        "b3",
        "Nc5",
        "Rb4",
        "Nxe4",
        "Nxe5+",
        "Kf5",
        "Nc4",
        "Rd8",
        "Ne3+",
        "Ke5",
        "Rb5+",
        "Ke6",
        "f3",
        "Nc3",
        "Rb6+",
        "Kf7",
        "Ng4",
        "Nd5",
        "Rb7+",
        "Kg6",
        "Kf2",
        "h5",
        "Ne3",
        "Nf4",
        "Kg3",
        "Ne2+",
        "Kh4",
        "Rd4+",
        "g4",
        "hxg4",
        "hxg4",
        "Rd3",
        "Nf5",
        "Rxf3",
        "Rg7#",
        "Nf4",
        "Rg8+",
        "Kf7",
        "Rg7+",
        "Kf8",
        "g5",
        "fxg5+",
        "Kxg5",
        "Ne6+",
        "Kg4",
        "Rf4+",
        "Kg3",
        "Rxf5",
        "Rb7",
        "Nd4",
        "b4",
        "Rb5",
        "Rxb5",
        "Nxb5",
        "Kf4",
        "Ke7",
        "Ke5",
        "Kd7",
        "Kd5",
        "Kc7",
        "Kc5",
        "Nc3"
      ],
      "plan_execute": [
        "Nf3",
        "Nc6",
        "Bb5"
      ],
      "selected_move": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "Qf1",
        "Qh5",
        "a4",
        "Rfe8",
        "axb5",
        "axb5",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Qxc6",
        "Bxg3",
        "Qg2",
        "Bf4",
        "Ra8",
        "Bb8",
        "d5",
        "Rg6",
        "Bf4",
        "Rxe1+",
        "Nf1",
        "h6",
        "Rxb8+",
        "Kh7",
        "Bg3",
        "Bh3",
        "d6",
        "Bxg2",
        "Kxg2",
        "Qd5+",
        "Kg1",
        "Qd3",
        "Kg2",
        "Qxf1+",
        "Kf3",
        "Qh1+",
        "Kf4",
        "Qe4#",
        "d7",
        "Qe5#"
      ],
      "plan_execute": [
        "Bb5",
        "a6",
        "Ba4"
      ],
      "selected_move": "Nc6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1,
      "plan_full": [
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "d6",
        "c3",
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Nb4",
        "Bb1",
        "a3",
        "bxa3",
        "Rxa3",
        "Nb3",
        "Be6",
        "d5",
        "Bd7",
        "Bc1",
        "Ra4",
        "a3",
        "Na6",
        "Bb2",
        "Rc8",
        "Bd3",
        "Nc5",
        "Rc1",
        "Qb6",
        "Nxc5",
        "Rxc5",
        "Qd2",
        "Rxc1",
        "Rxc1",
        "Nxe4",
        "Qc2",
        "f5",
        "Re1",
        "Nc5",
        "Bxf5",
        "Bxf5",
        "Qxf5",
        "Qd8",
        "Bc3",
        "g6",
        "Qc2",
        "Rxa3",
        "Bb4",
        "Ra4",
        "Bxc5",
        "Rc4",
        "Qb3",
        "Rxc5",
        "Nxe5",
        "dxe5",
        "d6+",
        "Kg7",
        "dxe7",
        "Qxe7",
        "Qb4",
        "Qc7",
        "Qe4",
        "Rc1",
        "Rxc1",
        "Qxc1+",
        "Kh2",
        "Qf4+",
        "Qxf4",
        "exf4",
        "exf4",
        "Kg1",
        "b4",
        "Kf1",
        "b3",
        "Ke2",
        "b2",
        "Kf3",
        "b1=Q"
      ],
      "plan_execute": [
        "Ba4",
        "Nf6",
        "O-O"
      ],
      "selected_move": "a6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1,
      "plan_full": [
        "d3",
        "Bc5",
        "O-O",
        "d6",
        "c3",
        "O-O",
        "Bg5",
        "h6",
        "Bh4",
        "g5",
        "Bg3",
        "Ba7",
        "Nbd2",
        "Nh5",
        "Nxe5",
        "Nxg3",
        "Nxc6",
        "bxc6",
        "hxg3",
        "d5",
        "Bb3",
        "Be6",
        "d4",
        "c5",
        "exd5",
        "Bxd5",
        "Bxd5",
        "Qxd5",
        "Qh5",
        "Kg7",
        "Nf3",
        "cxd4",
        "cxd4",
        "Bxd4",
        "Rad1",
        "c5",
        "b4",
        "Qxa2",
        "Nxd4",
        "cxd4",
        "Rxd4",
        "Rad8",
        "Rfd1",
        "Rxd4",
        "Rxd4",
        "Qa1+",
        "Qd1",
        "Qxd1+",
        "Rxd1",
        "Rb8",
        "Rd4",
        "Rb5",
        "f4",
        "a5",
        "bxa5",
        "Rxa5",
        "Kf2",
        "Ra3",
        "Rd6",
        "f6",
        "f5",
        "Ra5",
        "g4",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2",
        "Ra4",
        "Kf3",
        "Ra3+",
        "Kf2"
      ],
      "plan_execute": [
        "d3",
        "Bc5",
        "O-O"
      ],
      "selected_move": "Nf6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "O-O",
        "Nc3",
        "d6",
        "Bg5",
        "h6",
        "Bh4",
        "g5",
        "Nxg5",
        "hxg5",
        "Bxg5",
        "Be6",
        "Qf3",
        "Kg7",
        "Qg3",
        "Nh5",
        "Qh4",
        "f6",
        "Be3",
        "Bxc4",
        "dxc4",
        "Rh8",
        "Qg4+",
        "Kf7",
        "Nd5",
        "Qc8",
        "Qf3",
        "Nd4",
        "Bxd4",
        "Bxd4",
        "c3",
        "Ba7",
        "g4",
        "c6",
        "gxh5",
        "cxd5",
        "cxd5",
        "Qg8+",
        "Kh1",
        "Qg5",
        "Rg1",
        "Qxh5",
        "Qg3",
        "Rag8",
        "Rg2",
        "Rxg3",
        "fxg3",
        "Qf3",
        "Re1",
        "Bf2",
        "Rf1",
        "Rxh2+",
        "Kxh2",
        "Qh5#",
        "Qh4+",
        "Kg1",
        "Qxg3+",
        "Kh1",
        "Qh3+",
        "Rh2",
        "Qxf1#"
      ],
      "plan_execute": [
        "O-O",
        "O-O",
        "Nc3"
      ],
      "selected_move": "Bc5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "O-O",
      "move_uci": "e8g8"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1,
      "plan_full": [
        "d5",
        "Nc3",
        "Nf6",
        "Bg5",
        "e6",
        "e4",
        "dxe4",
        "Nxe4",
        "Be7",
        "Nxf6+",
        "Bxf6",
        "Bxf6",
        "Qxf6",
        "Nf3",
        "O-O",
        "Bd3",
        "Nc6",
        "O-O",
        "Rd8",
        "c3",
        "b6",
        "Be4",
        "Bb7",
        "Qa4",
        "Rd6",
        "Ne5",
        "Nxe5",
        "Bxb7",
        "Rb8",
        "Qxa7",
        "Rbd8",
        "dxe5",
        "Qxe5",
        "Rfe1",
        "Qd6",
        "Rad1",
        "Qxd1",
        "Rxd1",
        "Rxd1#"
      ],
      "plan_execute": [
        "d5",
        "Nc3",
        "Nf6"
      ],
      "selected_move": "d4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "d5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nc3",
      "move_uci": "b1c3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nf6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 5,
      "attempt": 1,
      "plan_full": [
        "e6",
        "e4",
        "dxe4",
        "Nxe4",
        "Be7",
        "Bxf6",
        "Bxf6",
        "Nf3",
        "O-O",
        "c3",
        "b6",
        "Bd3",
        "Bb7",
        "Qe2",
        "Nd7",
        "O-O-O",
        "Qe7",
        "h4",
        "c5",
        "dxc5",
        "Nxc5",
        "Nxc5",
        "Qxc5",
        "Ng5",
        "h6",
        "Nh7",
        "Rfd8",
        "Nxf6+",
        "gxf6",
        "Rh3",
        "Kf8",
        "Rg3",
        "Ke7",
        "Rg7",
        "Rg8",
        "Rxg8",
        "Rxg8",
        "g3",
        "Rd8",
        "Bc2",
        "Rxd1+",
        "Bxd1",
        "Qd5",
        "Bb3",
        "Qh1+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3",
        "Qe4+",
        "Kd2",
        "Qb1",
        "Ke3"
      ],
      "plan_execute": [
        "e6",
        "e4",
        "dxe4"
      ],
      "selected_move": "Bg5"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "e6",
      "actual_san": "h6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 7,
      "attempt": 1,
      "plan_full": [
        "exf6",
        "e3",
        "Bb4",
        "Nge2",
        "O-O",
        "a3",
        "Ba5",
        "b4",
        "Bb6",
        "Nf4",
        "c6",
        "Bd3",
        "Re8",
        "O-O",
        "Nd7",
        "Qh5",
        "Nf8",
        "Nce2",
        "Bc7",
        "c4",
        "dxc4",
        "Bxc4",
        "Be6",
        "Nxe6",
        "Nxe6",
        "Ng3",
        "Bxg3",
        "hxg3",
        "Qd7",
        "Rfd1",
        "Rad8",
        "Rac1",
        "Nc7",
        "a4",
        "Nd5",
        "b5",
        "f5",
        "bxc6",
        "bxc6",
        "Bd3",
        "Ne7",
        "Rc5",
        "Qe6",
        "Bxf5",
        "Nxf5",
        "Qxf5",
        "Qb3",
        "Qc2",
        "Qxc2",
        "Rxc2",
        "Rd6",
        "Rdc1",
        "Ree6",
        "Rc5",
        "Kf8",
        "Ra5",
        "Rd7",
        "Ra6",
        "Rc7",
        "d5",
        "Rd6",
        "Raxc6",
        "Rcxc6",
        "dxc6",
        "Rd8",
        "c7",
        "Rc8",
        "Kf1",
        "Ke7",
        "Ke2",
        "Kd7",
        "Kd3",
        "Rxc7",
        "Rxc7+",
        "Kxc7",
        "Kc4",
        "Kc6",
        "e4",
        "f6",
        "f4",
        "g6",
        "g4",
        "a6",
        "a5",
        "Kd6",
        "Kd4",
        "Kc6",
        "e5",
        "fxe5+",
        "fxe5",
        "Kd7",
        "Kd5",
        "Ke7",
        "e6",
        "Ke8",
        "Kd6",
        "Kd8",
        "e7+",
        "Ke8",
        "Ke6",
        "h5",
        "gxh5",
        "gxh5",
        "g3",
        "h4",
        "gxh4",
        "h5",
        "g5",
        "h6"
      ],
      "plan_execute": [
        "exf6",
        "e3",
        "Bb4"
      ],
      "selected_move": "Bxf6"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "exf6",
      "actual_san": "gxf6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 9,
      "attempt": 1,
      "plan_full": [
        "dxe4",
        "Nxe4",
        "Bf5",
        "Ng3",
        "Bg6",
        "Nf4",
        "Bf5",
        "Ng3",
        "Bg6",
        "Nxf6",
        "Bxf6",
        "gxf6",
        "Rg8",
        "Kf7",
        "Bd6",
        "Ne4",
        "Bf5",
        "Bg6"
      ],
      "plan_execute": [
        "dxe4",
        "Nxe4",
        "Bf5"
      ],
      "selected_move": "e4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "dxe4"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nxe4",
      "move_uci": "c3e4"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "Bf5",
      "actual_san": "Nc6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 13,
      "attempt": 1,
      "plan_full": [
        "Bd7",
        "Nf3",
        "a6",
        "Ba4",
        "b5",
        "Bb3",
        "Bg4",
        "c3",
        "e5",
        "d5",
        "Na5",
        "Bc2",
        "Nc4",
        "b3",
        "Nd6",
        "Nxd6+",
        "Qxd6",
        "O-O",
        "O-O-O",
        "c4",
        "bxc4",
        "bxc4",
        "Qc5",
        "Qd3",
        "Bxf3",
        "Qxf3",
        "Qxc4",
        "Bb3",
        "Qf4",
        "Qd3",
        "Rd6",
        "Rac1",
        "e4",
        "Qc4",
        "Rd7",
        "Qxa6+",
        "Kd8",
        "Qa8+",
        "Ke7",
        "Ba4",
        "Rd8",
        "Qc6",
        "Qd6",
        "Qxc7+",
        "Qxc7",
        "Rxc7+",
        "Kd6",
        "Rxf7",
        "Kxd5",
        "Rd1+",
        "Ke6",
        "Bb3+",
        "Kf5",
        "Rxd8",
        "Kg6",
        "Rfxf8",
        "Rxf8",
        "Rxf8",
        "Kg7",
        "Rg8+",
        "Kh7",
        "a4",
        "f5",
        "a5",
        "f4",
        "a6",
        "e3",
        "fxe3",
        "fxe3",
        "Kf1",
        "e2+",
        "Kxe2",
        "h5",
        "a7",
        "h4",
        "a8=Q",
        "h3",
        "Qe4+",
        "Kh6",
        "Qh4#",
        "Qd5+",
        "Bxd5#",
        "Qe5+",
        "Be4#",
        "Qb2+",
        "Kf3#",
        "Qc3+",
        "Kf4#",
        "Qd2+",
        "Kf5#",
        "Qf2+",
        "Ke6#",
        "Qb6+",
        "Kf7#",
        "Qc7+",
        "Kf8#",
        "Qd6+",
        "Ke8#",
        "Qe5+",
        "Kd8#",
        "Qd6+",
        "Kc8#",
        "Qc5+",
        "Kb8#",
        "Qb6+",
        "Ka8#",
        "Qa6+",
        "Kb8#",
        "Qb6+",
        "Kc8#",
        "Qc5+",
        "Kd8#",
        "Qd6+",
        "Ke8#",
        "Qe5+",
        "Kf8#",
        "Qd6+",
        "Ke8#",
        "Qe5+",
        "Kd8#",
        "Qd6+",
        "Kc8#",
        "Qc5+",
        "Kb8#",
        "Qb6+",
        "Ka8#",
        "Qa6+",
        "Kb8#",
        "Qb6+",
        "Kc8#",
        "Qc5+",
        "Kd8#",
        "Qd6+",
        "Ke8#",
        "Qe5+",
        "Kf8#"
      ],
      "plan_execute": [
        "Bd7",
        "Nf3",
        "a6"
      ],
      "selected_move": "Bb5"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "Bd7",
      "actual_san": "a6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 15,
      "attempt": 1,
      "plan_full": [
        "bxc6",
        "Nf3",
        "Bg4",
        "h3",
        "Bxf3",
        "Qxf3",
        "Qxd4",
        "Nxf6+",
        "exf6",
        "Qxc6+",
        "Ke7",
        "Qxa8",
        "Qxb2",
        "O-O",
        "Qxc2",
        "Rfe1+",
        "Kd7",
        "Rad1+",
        "Bd6",
        "Qxh8",
        "Qxa2",
        "Qe8#",
        "e4",
        "Qd3",
        "Qxd3+",
        "Kxd3",
        "Rb1#"
      ],
      "plan_execute": [
        "bxc6",
        "Nf3",
        "Bg4"
      ],
      "selected_move": "Bxc6+"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "bxc6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nf3",
      "move_uci": "g1f3"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1,
      "plan_full": [
        "d4",
        "d5",
        "c4",
        "e6",
        "Nc3",
        "Be7",
        "Bg5",
        "O-O",
        "e3",
        "Nbd7",
        "Rc1",
        "c6",
        "Bd3",
        "dxc4",
        "Bxc4",
        "Nd5",
        "Bxe7",
        "Qxe7",
        "O-O",
        "Nxc3",
        "Rxc3",
        "e5",
        "dxe5",
        "Nxe5",
        "Nxe5",
        "Qxe5",
        "f4",
        "Qe7",
        "f5",
        "Qf6",
        "e4",
        "Rd8",
        "Rd3",
        "Rxd3",
        "Qxd3",
        "b5",
        "Bb3",
        "Bb7",
        "Rd1",
        "h6",
        "Qd7",
        "Rb8",
        "Qc7",
        "Re8",
        "Qxb7",
        "Rxe4",
        "Qxa7",
        "Re2",
        "Qd4",
        "Qg5",
        "g3",
        "Qh5",
        "Qd8+",
        "Kh7",
        "Qh4",
        "Qf3",
        "Qh3",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+",
        "Kh1",
        "Qf3+",
        "Kg1",
        "Qf2+"
      ],
      "plan_execute": [
        "d4",
        "d5",
        "c4"
      ],
      "selected_move": "Nf6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "d4",
      "move_uci": "d2d4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "d5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "c4",
      "move_uci": "c2c4"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "plan fully executed"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 5,
      "attempt": 1,
      "plan_full": [
        "Nf6",
        "e3",
        "e6",
        "Bxc4",
        "c5",
        "O-O",
        "a6",
        "Qe2",
        "b5",
        "Bb3",
        "Bb7",
        "Rd1",
        "Nbd7",
        "Nc3",
        "Qb8",
        "d5",
        "c4",
        "dxe6",
        "fxe6",
        "Bc2",
        "Bd6",
        "h3",
        "O-O",
        "Ng5",
        "Nc5",
        "b4",
        "cxb3",
        "axb3",
        "h6",
        "b4",
        "hxg5",
        "bxc5",
        "Bxc5",
        "Bb3",
        "Qe5",
        "Bb2",
        "Bd6",
        "g3",
        "Qf5",
        "Rxd6",
        "Qxh3",
        "Bxe6+",
        "Qxe6",
        "Rxe6",
        "Kf7",
        "Rxf6+",
        "gxf6",
        "Qh5+",
        "Kg7",
        "Rd1",
        "Rf7",
        "Nd5",
        "Rh8",
        "Qxg5+",
        "Kf8",
        "Ba3+",
        "Ke8",
        "Nxf6+",
        "Rxf6",
        "Qe5+",
        "Kf7",
        "Rd7+",
        "Kg6",
        "Rxb7",
        "Rh5",
        "Qe8+",
        "Kg5",
        "Rg7+",
        "Kf5",
        "g4#"
      ],
      "plan_execute": [
        "Nf6",
        "e3",
        "e6"
      ],
      "selected_move": "Nf3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "Nf6",
      "actual_san": "Nc6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 7,
      "attempt": 1,
      "plan_full": [
        "Nf6",
        "e4",
        "Bg4",
        "Be3",
        "e6",
        "Bxc4",
        "Bb4",
        "Qd3",
        "O-O",
        "O-O-O",
        "a6",
        "h3",
        "Bh5",
        "g4",
        "Bg6",
        "Nd2",
        "b5",
        "Bb3",
        "Ne5",
        "Qe2",
        "Nc6",
        "e5",
        "Nd5",
        "Nxd5",
        "exd5",
        "f4",
        "f5",
        "g5",
        "Na5",
        "h4",
        "Nxb3+",
        "Nxb3",
        "Qe8",
        "h5",
        "Bf7",
        "g6",
        "hxg6",
        "hxg6",
        "Bxg6",
        "Rdg1",
        "Kf7",
        "Qg2",
        "Qc6+",
        "Kb1",
        "Rh8",
        "Rxh8",
        "Rxh8",
        "Rc1",
        "Qd7",
        "e6+",
        "Qxe6",
        "Rxc7+",
        "Be7",
        "Nc5",
        "Qxe3",
        "Qxd5+",
        "Kf8",
        "Rc8+",
        "Be8",
        "Nd7#"
      ],
      "plan_execute": [
        "Nf6",
        "e4",
        "Bg4"
      ],
      "selected_move": "Nc3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "Nf6",
      "actual_san": "e6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 9,
      "attempt": 1,
      "plan_full": [
        "Bb4",
        "Bxc4",
        "Nf6",
        "e5",
        "Nd5",
        "Bd2",
        "O-O",
        "O-O",
        "Nxc3",
        "bxc3",
        "Be7",
        "Bd3",
        "b6",
        "Qc2",
        "g6",
        "Bh6",
        "Re8",
        "Qd2",
        "Bb7",
        "Ng5",
        "Bf8",
        "Bxf8",
        "Rxf8",
        "Ne4",
        "Kg7",
        "Nf6",
        "Ne7",
        "Ng4",
        "Ng8",
        "f4",
        "Qh4",
        "Ne3",
        "Nh6",
        "g3",
        "Qh3",
        "Rf2",
        "Ng4",
        "Nxg4",
        "Qxg4",
        "Be2",
        "Qf5",
        "g4",
        "Qe4",
        "Bf3",
        "Qxf3",
        "Rxf3",
        "Bxf3",
        "h3",
        "Rad8",
        "Qe3",
        "Bd5",
        "a3",
        "Bc4",
        "f5",
        "exf5",
        "gxf5",
        "gxf5",
        "Qg5+",
        "Kh8",
        "Qf6+",
        "Kg8",
        "Kf2",
        "Rfe8",
        "Rg1+",
        "Kf8",
        "Rg7",
        "Rd7",
        "Rxh7",
        "Re6",
        "Rh8#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5",
        "Rh8#",
        "Bc6",
        "Rh7#",
        "Bb5"
      ],
      "plan_execute": [
        "Bb4",
        "Bxc4",
        "Nf6"
      ],
      "selected_move": "e4"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "Bb4",
      "actual_san": "Nf6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 11,
      "attempt": 1,
      "plan_full": [
        "Bb4",
        "O-O",
        "O-O",
        "e5",
        "Nd5",
        "Nxd5",
        "exd5",
        "Bd3",
        "Bg4",
        "Be3",
        "f6",
        "exf6",
        "Qxf6",
        "Be2",
        "Rae8",
        "a3",
        "Bd6",
        "h3",
        "Bh5",
        "Qb3",
        "Bxf3",
        "Bxf3",
        "Nxd4",
        "Bxd4",
        "Qxd4",
        "Bxd5+",
        "Kh8",
        "Rad1",
        "Qe5",
        "g3",
        "Bc5",
        "Kg2",
        "Qe2",
        "Bf3",
        "Qe5",
        "Rd5",
        "Qe7",
        "Qxb7",
        "Rb8",
        "Qc6",
        "Bd6",
        "b4",
        "Rb6",
        "Qc3",
        "Qf7",
        "Rfd1",
        "Rbb8",
        "R1d3",
        "Rbe8",
        "Qd2",
        "Re6",
        "Bh5",
        "g6",
        "Bg4",
        "Rf6",
        "f4",
        "h5",
        "Bf3",
        "h4",
        "Qc3",
        "hxg3",
        "Kxg3",
        "Bxf4+",
        "Kg2",
        "Bd6",
        "R5d4",
        "Qa2+",
        "Rd2",
        "Qe6",
        "Rh4+",
        "Kg7",
        "Re2",
        "Qf5",
        "Rf2",
        "Qg5+",
        "Rg4",
        "Qe5",
        "Qxe5",
        "Bxe5",
        "Re4",
        "Bd6",
        "Ree2",
        "Rf5",
        "Bg4",
        "Rxf2+",
        "Rxf2",
        "Rxf2+",
        "Kxf2",
        "Kf6",
        "Ke3",
        "Ke5",
        "Kd3",
        "Kd5",
        "Bf3+",
        "Ke5",
        "Kc4",
        "Kf4",
        "Bg4",
        "Ke5",
        "Kb5",
        "Kd5",
        "Ka6",
        "Kc4",
        "Kxa7",
        "Kb3",
        "b5",
        "Kxa3",
        "b6",
        "cxb6",
        "Kxb6",
        "Kb4",
        "Kc6",
        "Bf4",
        "Kd5",
        "g5",
        "Ke4",
        "Kc5",
        "Kf5",
        "Kd6",
        "h4",
        "gxh4",
        "Kxf4",
        "Ke7",
        "Kg5",
        "Kf7",
        "Kxh4",
        "Kg7",
        "Kg5",
        "Kh8",
        "Kh6",
        "Kg8",
        "Kg6",
        "Kh8",
        "Kf7",
        "Kh7",
        "Bf5+",
        "Kh8",
        "Kf8",
        "e4",
        "e5",
        "Nf6",
        "Nc6",
        "Bb4",
        "O-O",
        "O-O",
        "e5",
        "Nd5",
        "exd5",
        "Bg4",
        "Be3",
        "f6",
        "exf6",
        "Qxf6",
        "Be2",
        "Rae8",
        "a3",
        "Bd6",
        "h3",
        "Bh5",
        "Qb3",
        "Bxf3",
        "Bxf3"
      ],
      "plan_execute": [
        "Bb4",
        "O-O",
        "O-O"
      ],
      "selected_move": "Bxc4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Bb4"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "O-O",
      "move_uci": "e1g1"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "Qe7"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 15,
      "attempt": 1,
      "plan_full": [
        "h6",
        "Bh4",
        "g5",
        "Bg3",
        "Bxc3",
        "bxc3",
        "Nxe4",
        "Qc2",
        "Nxg3",
        "fxg3",
        "Bd7",
        "Rab1",
        "O-O-O",
        "Qb2",
        "b6",
        "Ba6+",
        "Kb8",
        "c4",
        "Bc8",
        "Bxc8",
        "Kxc8",
        "c5",
        "g4",
        "cxb6",
        "axb6",
        "Ne5",
        "Nxe5",
        "dxe5",
        "Qc5",
        "Qa3",
        "Qa5",
        "Qa4",
        "Qxa4",
        "Rg1",
        "Rd5",
        "Rgf1",
        "Rhd8",
        "Rxf7",
        "Rd1+",
        "Rf1",
        "Rxf1+",
        "Rxf1",
        "Qd4",
        "h3",
        "gxh3",
        "Kh2",
        "Qxe5",
        "Rf4",
        "Rd2",
        "Rf8+",
        "Kb7",
        "Rf7",
        "Qe2",
        "Rf2",
        "Qxf2",
        "Kh1",
        "Qxg2#"
      ],
      "plan_execute": [
        "h6",
        "Bh4",
        "g5"
      ],
      "selected_move": "Bg5"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "h6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Bh4",
      "move_uci": "g5h4"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "g5",
      "move_uci": "g7g5"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "plan fully executed"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "Rxh4",
        "e5",
        "Rh5",
        "Nf6",
        "Rxe5+",
        "Be7",
        "g5",
        "Ng4",
        "Re4",
        "d5",
        "Rf4",
        "Bxg5",
        "Rf3",
        "Nc6",
        "d4",
        "Bxc1",
        "Qxc1",
        "Nxd4",
        "Rf4",
        "c5",
        "c3",
        "Ne6",
        "Rxg4",
        "h5",
        "Rg3",
        "h4",
        "Re3",
        "Qg5",
        "Nf3",
        "Qf4",
        "Bh3",
        "d4",
        "cxd4",
        "cxd4",
        "Nxd4",
        "Qxd4",
        "Nc3",
        "Bd7",
        "Rd3",
        "Qg7",
        "Qe3",
        "Qg1+",
        "Kd2",
        "Qxa1",
        "Nd5",
        "Qxb2+",
        "Ke1",
        "Qb1+",
        "Rd1",
        "Qxa2",
        "Nf6+",
        "Ke7",
        "Rxd7+",
        "Kxf6",
        "Qf3+",
        "Kg5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qxf7+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Rd6",
        "Rae8",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6",
        "Qf6+",
        "Kh5",
        "Qf5+",
        "Kh6"
      ],
      "plan_execute": [
        "Rxh4",
        "e5",
        "Rh5"
      ],
      "selected_move": "gxh4"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1,
      "plan_full": [
        "e5",
        "Nf3",
        "Nc6",
        "Bb5",
        "Bc5",
        "O-O",
        "Nge7",
        "Nxe5",
        "Nxe5",
        "d4",
        "Bxd4",
        "Qxd4",
        "N7c6",
        "Bxc6",
        "Nxc6",
        "Qxg7",
        "Rf8",
        "Bh6",
        "Qe7",
        "Nc3",
        "d6",
        "Nd5",
        "Qe5",
        "Qxf8+",
        "Kd7",
        "Qxf7+",
        "Kd8",
        "Qxc7+",
        "Ke8",
        "Bg7",
        "Qe6",
        "Nf6+",
        "Qxf6",
        "Bxf6",
        "Bd7",
        "Qxd6",
        "Rc8",
        "Rad1",
        "Kf7",
        "Qxd7+",
        "Kxf6",
        "Qxc8",
        "Ne5",
        "Qf5+",
        "Ke7",
        "Qxe5+",
        "Kf7",
        "Rd7+",
        "Kg6",
        "Rg7+",
        "Kh6",
        "Qg5#",
        "e5",
        "Nf3",
        "Nc6",
        "Bb5",
        "Bc5",
        "O-O",
        "Nge7",
        "Nxe5",
        "Nxe5",
        "d4",
        "Bxd4",
        "Qxd4",
        "N7c6",
        "Bxc6",
        "Nxc6",
        "Qxg7",
        "Rf8",
        "Bh6",
        "Qe7",
        "Nc3",
        "d6",
        "Nd5",
        "Qe5",
        "Qxf8+",
        "Kd7",
        "Qxf7+",
        "Kd8",
        "Qxc7+",
        "Ke8",
        "Bg7",
        "Qe6",
        "Nf6+",
        "Qxf6",
        "Bxf6",
        "Bd7",
        "Qxd6",
        "Rc8",
        "Rad1",
        "Kf7",
        "Qxd7+",
        "Kxf6",
        "Qxc8",
        "Ne5",
        "Qf5+",
        "Ke7",
        "Qxe5+",
        "Kf7",
        "Rd7+",
        "Kg6",
        "Rg7+",
        "Kh6",
        "Qg5#"
      ],
      "plan_execute": [
        "e5",
        "Nf3",
        "Nc6"
      ],
      "selected_move": "e4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "e5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nf3",
      "move_uci": "g1f3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nc6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 5,
      "attempt": 1,
      "plan_full": [
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "Qf1",
        "Qh5",
        "a4",
        "Rfe8",
        "axb5",
        "axb5",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Qxc6",
        "Bxg3",
        "Qg2",
        "Bf4",
        "Ra8",
        "Bb8",
        "Kh1",
        "Rg6",
        "Bf4",
        "Rxe1+",
        "Nf1",
        "Rxf1+",
        "Qxf1",
        "Bf3+",
        "Qg2",
        "Bxg2+",
        "Kg1",
        "Bxa8+",
        "Kf1",
        "Qd1#",
        "Bb8+",
        "Bc7",
        "Bb6",
        "Bc5"
      ],
      "plan_execute": [
        "a6",
        "Ba4",
        "Nf6"
      ],
      "selected_move": "Bb5"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "a6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Ba4",
      "move_uci": "b5a4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nf6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 9,
      "attempt": 1,
      "plan_full": [
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "Qd2",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qh6",
        "Rg8",
        "Qxf6+",
        "Rg7",
        "Nh5",
        "Rg8",
        "Ng5",
        "Be8",
        "Nxg7",
        "Rxg7",
        "dxe5",
        "dxe5",
        "Rd1",
        "Qe7",
        "Qxe7",
        "Nxe7",
        "Rd8",
        "Rg8",
        "Nf3",
        "f6",
        "Bd3",
        "Kg7",
        "Rb8",
        "Bc6",
        "Rxg8+",
        "Kxg8",
        "Kf1",
        "Kf7",
        "Ke2",
        "Ke6",
        "Ke3",
        "Kd6",
        "Nd2",
        "Kc5",
        "a3",
        "Bd7",
        "Nb1",
        "Nc6",
        "Nc3",
        "Nd4",
        "Nd5",
        "f5",
        "Nf6",
        "f4+",
        "Kd2",
        "Be6",
        "Nxh7",
        "b4",
        "Ng5",
        "Bg8",
        "h4",
        "bxa3",
        "bxa3",
        "Nb3+",
        "Kc3",
        "Nd4",
        "h5",
        "Nb5+",
        "Bxb5",
        "Kxb5",
        "h6",
        "Kc5",
        "h7",
        "Bxh7",
        "Nxh7",
        "Kd6",
        "Ng5",
        "Ke7",
        "Nf3",
        "Kf6",
        "Kb4",
        "Ke6",
        "Kxa4",
        "Kd6",
        "Kb4",
        "Ke6",
        "a4",
        "Kd6",
        "a5",
        "Ke6",
        "a6",
        "Kd6",
        "a7",
        "Ke6",
        "a8=Q",
        "Kd6",
        "Qd5+",
        "Ke7",
        "Qxe5+",
        "Kd7",
        "Qxf4",
        "Ke6",
        "Qf5+",
        "Kd6",
        "Qd5+",
        "Ke7",
        "Qc6",
        "Kf7",
        "Kc5",
        "Ke7",
        "Kd5",
        "Kf7",
        "Ke5",
        "Ke7",
        "Qc7+",
        "Kf8",
        "Kf6",
        "Kg8",
        "Qg7#",
        "e4",
        "Nf3"
      ],
      "plan_execute": [
        "h3",
        "Na5",
        "Bc2"
      ],
      "selected_move": "O-O"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "h3",
      "actual_san": "Be7"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 11,
      "attempt": 1,
      "plan_full": [
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "a4",
        "Qh5",
        "axb5",
        "axb5",
        "Ra6",
        "Bc7",
        "Qf1",
        "Rfe8",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Rxc6",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qh1",
        "Bb8",
        "Rc5",
        "f5",
        "Qd5",
        "Kh8",
        "Rxb5",
        "h6",
        "Ra1",
        "Qh3",
        "Ra8",
        "f4",
        "Rbxb8",
        "fxe3",
        "Rxe8+",
        "Kh7",
        "Rxe6",
        "exd2",
        "Qe4+",
        "Bf5",
        "Qe2",
        "Bxe6",
        "Qxd2",
        "Bd5",
        "Qd3+",
        "g6",
        "Ra7+",
        "Kh8",
        "Qf1",
        "Qf5",
        "Re7",
        "Qf3",
        "Re8+",
        "Kg7",
        "Re7+",
        "Kf8",
        "Re8+",
        "Kxe8",
        "Qe1+",
        "Kf7",
        "Kf1",
        "Bc4+",
        "Kg1",
        "Bd5",
        "Kf1",
        "Qh1+",
        "Ke2",
        "Qe4+",
        "Kd2",
        "Qxe1+",
        "Kxe1",
        "Ke6",
        "Kd2",
        "Kf5",
        "Ke3",
        "Kg4",
        "b4",
        "Kh3",
        "b5",
        "Kxh2",
        "b6",
        "Kg2",
        "c4",
        "Bb7",
        "d5",
        "h5",
        "d6",
        "Bc6",
        "b7",
        "Bxb7",
        "d7",
        "g5",
        "d8=Q",
        "h4",
        "Qxg5",
        "h3",
        "Qh4",
        "h2",
        "Qxh2+",
        "Kxh2",
        "g4",
        "Kh3",
        "g5",
        "Kh4",
        "g6",
        "Kh5",
        "g7",
        "Kh6",
        "g8=Q",
        "Kh5",
        "Qg3",
        "Kh6",
        "Kf4",
        "Kh7",
        "Kf5",
        "Kh8",
        "Kf6",
        "Kh7",
        "Qg7#",
        "e4",
        "e5",
        "Nf6",
        "Nc6",
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "Be7",
        "O-O",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "Bd6",
        "Bd6",
        "Qh5",
        "g6",
        "Qh3"
      ],
      "plan_execute": [
        "Qh4",
        "g3",
        "Qh3"
      ],
      "selected_move": "Re1"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "Qh4",
      "actual_san": "b5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 13,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "Qf1",
        "Qh5",
        "a4",
        "Rfe8",
        "axb5",
        "axb5",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Qxc6",
        "Bxg3",
        "Qg2",
        "Bf4",
        "Ra8",
        "Bb8",
        "Kh1",
        "Rg6",
        "Bf4",
        "Rxe1+",
        "Nf1",
        "Bf3",
        "Rxb8+",
        "Re8",
        "Rxe8#",
        "e5",
        "dxe5",
        "Qxg2#"
      ],
      "plan_execute": [
        "O-O",
        "c3",
        "d5"
      ],
      "selected_move": "Bb3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "d6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 15,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "Qd2",
        "Qa6",
        "Bg5",
        "Qa5",
        "Qd1",
        "Nxd4",
        "Nxd4",
        "exd4",
        "Bxf6",
        "gxf6",
        "Nh5",
        "Re6",
        "Rf1",
        "Kh8",
        "Qxd4",
        "b4",
        "Nxf6",
        "Qe5",
        "Qxe5",
        "dxe5",
        "Nxd7",
        "Rd8",
        "Nc5",
        "Rc6",
        "Nxa4",
        "Rd2",
        "b3",
        "Kg7",
        "g3",
        "Kf6",
        "Kg2",
        "Ke7",
        "Kf3",
        "Rf6+",
        "Ke3",
        "Rfd6",
        "Rc1",
        "Rd1",
        "Rxd1",
        "Rxd1",
        "Bd3",
        "Ra1",
        "Nb6",
        "Rxa2",
        "Nd5+",
        "Kd6",
        "Nxb4",
        "Rb2",
        "Bc4",
        "f6",
        "Nd3",
        "Rb1",
        "f4",
        "Rh1",
        "h4",
        "Rg1",
        "Kf2",
        "Rd1",
        "fxe5+",
        "fxe5",
        "Ke2",
        "Rg1",
        "Kf3",
        "Rd1",
        "Kg4",
        "Rg1",
        "Nf2",
        "Rg2",
        "Kf3",
        "Rg1",
        "Ng4",
        "h5",
        "Nf6",
        "Ke7",
        "Nxh5",
        "Kf8",
        "Kg4",
        "Re1",
        "Bd5",
        "Rf1",
        "Kg5",
        "Ke7",
        "g4",
        "Kd6",
        "Ng7",
        "Kc5",
        "h5",
        "Kd4",
        "h6",
        "Rh1",
        "Nh5",
        "Ra1",
        "h7",
        "Ra8",
        "Bxa8",
        "Ke3",
        "h8=Q",
        "Kd4",
        "Qd8+",
        "Ke3",
        "Qd5",
        "Kf3",
        "Qd3+",
        "Kf2",
        "Ng3",
        "Kg2",
        "Qe2+",
        "Kxg3",
        "Qe3+",
        "Kg2",
        "Kh4",
        "Kf1",
        "Qd2",
        "Kg1",
        "Kg3",
        "Kf1",
        "Qf2#",
        "e4",
        "d5",
        "Nf6+",
        "Kg7",
        "Nxe4+",
        "Kf8",
        "Nf6+",
        "Kg7",
        "Nxe4+"
      ],
      "plan_execute": [
        "O-O",
        "h3",
        "Na5"
      ],
      "selected_move": "c3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "Na5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 17,
      "attempt": 1,
      "plan_full": [
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "O-O",
        "Nf1",
        "Bg4",
        "d5",
        "Nc4",
        "h3",
        "Bd7",
        "b3",
        "Nb6",
        "Ng3",
        "g6",
        "Bh6",
        "Rfe8",
        "Qd2",
        "Bf8",
        "Bxf8",
        "Rxf8",
        "Qh6",
        "Kh8",
        "Ng5",
        "Be8",
        "f4",
        "Rg8",
        "fxe5",
        "dxe5",
        "Rf1",
        "Qd6",
        "Rxf6",
        "Qxf6",
        "Qxh7#",
        "e4",
        "dxe4",
        "Qg7#",
        "e5",
        "Nxe5",
        "Nxe5",
        "dxe5",
        "Qxd8",
        "Rxd8",
        "Nc3",
        "Nc6",
        "Be3",
        "Be6",
        "Rad1",
        "Nd4",
        "Bxd4",
        "cxd4",
        "Nd5",
        "Bxd5",
        "exd5",
        "Rac8",
        "Rfe1",
        "Bf6",
        "Rd2",
        "Rc5",
        "Re4",
        "Rdc8",
        "Rde2",
        "g6",
        "Re8+",
        "Kg7",
        "Rxc8",
        "Rxc8",
        "Re2",
        "Rc5",
        "Kf1",
        "Rxd5",
        "Ke1",
        "d3",
        "cxd3",
        "Rxd3",
        "Rd2",
        "Rxd2",
        "Kxd2",
        "Bxb2",
        "Kd3",
        "Kf6",
        "Ke4",
        "Ke6",
        "f4",
        "f5+",
        "Kd3",
        "Kd5",
        "g3",
        "Bd4",
        "h3",
        "Bf2",
        "g4",
        "Bg3",
        "gxf5",
        "gxf5",
        "Ke3",
        "Bh2",
        "Kf3",
        "Kd4",
        "Kg2",
        "Bxf4",
        "Kf3",
        "Be5",
        "h4",
        "h5",
        "a3",
        "a5",
        "a4",
        "bxa4",
        "bxa4",
        "Bc7",
        "a5",
        "Bxa5",
        "Kf4",
        "Bd8",
        "Kxf5",
        "Bxh4",
        "Kg6",
        "Be7",
        "Kh6",
        "Ke5",
        "Kg6",
        "Kd5",
        "Kf6",
        "Kc5",
        "Ke6",
        "Kb5",
        "Kd6",
        "Ka5",
        "Kc6",
        "Kb5",
        "Kd5",
        "Kc7",
        "Kc6",
        "Kd5",
        "Kd7",
        "Ke5",
        "Kc6",
        "Ke4",
        "Kc5",
        "Ke3",
        "Kc4",
        "Ke2",
        "Kc3",
        "Ke1",
        "Kd3",
        "Kf1",
        "Ke3",
        "Kg1",
        "Kf3",
        "Kh1",
        "Kg3",
        "Kg1",
        "Kh3",
        "Kf1",
        "Kg3",
        "Ke1",
        "Kf3",
        "Kd1",
        "Ke3",
        "Kc1",
        "Kd3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1",
        "Kc3",
        "Kb1",
        "Kd3",
        "Ka1",
        "Ke3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1",
        "Kd3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1",
        "Kd3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1",
        "Kd3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1",
        "Kd3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1",
        "Kd3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1",
        "Kd3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1",
        "Kd3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1",
        "Kd3",
        "Kb1",
        "Kc3",
        "Ka1",
        "Kb3",
        "Kc1"
      ],
      "plan_execute": [
        "c5",
        "d4",
        "Qc7"
      ],
      "selected_move": "Bc2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "c5",
      "actual_san": "Nc4"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 19,
      "attempt": 1,
      "plan_full": [
        "Nb6",
        "Nbd2",
        "O-O",
        "Nf1",
        "Bg4",
        "h3",
        "Bh5",
        "Ng3",
        "Bg6",
        "Nh4",
        "Nfd7",
        "Nhf5",
        "Bxf5"
      ],
      "plan_execute": [
        "Nb6",
        "Nbd2",
        "O-O"
      ],
      "selected_move": "d3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nb6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nbd2",
      "move_uci": "b1d2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "b4"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 23,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "Nf1",
        "Bg4",
        "h3",
        "Bh5",
        "Ng3",
        "Bg6",
        "Nh4",
        "d5",
        "Nxg6",
        "fxg6",
        "exd5",
        "Nfxd5",
        "Rxe5",
        "Nxb4",
        "Bb3+",
        "Kh8",
        "Qe2",
        "Bf6",
        "Re4",
        "Nxd3",
        "Be3",
        "Nxb2",
        "Rb1",
        "Nd3",
        "Rd1",
        "Qd6",
        "Rxd3",
        "Qc6",
        "Bxb6",
        "cxb6",
        "Bd5",
        "Qc1+",
        "Rd1",
        "Qc5",
        "Bxa8",
        "Rxa8",
        "Re8+",
        "Rxe8",
        "Qxe8+",
        "Qf8",
        "Qxf8#",
        "e5",
        "d4",
        "Bc5",
        "Bb6"
      ],
      "plan_execute": [
        "O-O",
        "Nf1",
        "Bg4"
      ],
      "selected_move": "cxb4"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "a5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 25,
      "attempt": 1,
      "plan_full": [
        "Rxa5",
        "b4",
        "Ra8",
        "a4",
        "O-O",
        "a5",
        "Nbd7",
        "d4",
        "exd4",
        "Nxd4",
        "Ne5",
        "f4",
        "Ng6",
        "Nc6",
        "Qd7",
        "Nxe7+",
        "Qxe7",
        "Nf3",
        "Bg4",
        "h3",
        "Bxf3",
        "Qxf3",
        "d5",
        "e5",
        "Qxb4",
        "Ba3",
        "Qd4+",
        "Kh1",
        "Ne4",
        "Bxf8",
        "Rxf8",
        "Bxe4",
        "dxe4",
        "Qxe4",
        "Qxe4",
        "Rxe4",
        "Ra8",
        "a6",
        "Ne7",
        "Rc4",
        "c6",
        "a7",
        "Kf8",
        "Rb4",
        "Nc8",
        "Rb8",
        "Rxa7",
        "Rxc8+",
        "Ke7",
        "Rxa7+",
        "Ke6",
        "Rxc6+",
        "Kf5",
        "Rxf7+",
        "Ke4",
        "e6",
        "Kd5",
        "Ra6",
        "g5",
        "e7",
        "gxf4",
        "e8=Q",
        "f3",
        "Rd7+",
        "Kc5",
        "Qc8+",
        "Kb5",
        "Rb7+",
        "Kxa6",
        "Qa8#",
        "e4",
        "d5",
        "e6",
        "dxe6"
      ],
      "plan_execute": [
        "Rxa5",
        "b4",
        "Ra8"
      ],
      "selected_move": "bxa5"
    }
  ],
  "black_plan_log": [
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1,
      "plan_full": [
        "Nf3",
        "Nc6",
        "Bc4",
        "Bc5",
        "d3",
        "d6"
      ],
      "plan_execute": [
        "Nf3",
        "Nc6",
        "Bc4"
      ],
      "selected_move": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "Bc4"
      ],
      "plan_execute": [
        "Bc4"
      ],
      "selected_move": "Nc6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1,
      "plan_full": [
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bc2",
        "c5"
      ],
      "plan_execute": [
        "Ba4",
        "Nf6",
        "O-O"
      ],
      "selected_move": "a6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1,
      "plan_full": [
        "d3",
        "Bc5"
      ],
      "plan_execute": [
        "d3",
        "Bc5"
      ],
      "selected_move": "Nf6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1,
      "plan_full": [
        "b3",
        "b5",
        "Bb3"
      ],
      "plan_execute": [
        "b3",
        "b5",
        "Bb3"
      ],
      "selected_move": "Be7"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1,
      "plan_full": [
        "Bc2",
        "d6",
        "Na5",
        "Nxe5"
      ],
      "plan_execute": [
        "Bc2",
        "d6",
        "Na5"
      ],
      "selected_move": "b5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1,
      "plan_full": [
        "Na3"
      ],
      "plan_execute": [
        "Na3"
      ],
      "selected_move": "d6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1,
      "plan_full": [
        "Bc2",
        "c5",
        "Nbd2"
      ],
      "plan_execute": [
        "Bc2",
        "c5",
        "Nbd2"
      ],
      "selected_move": "Na5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 18,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 18,
      "attempt": 1,
      "plan_full": [
        "b3",
        "Qe7"
      ],
      "plan_execute": [
        "b3",
        "Qe7"
      ],
      "selected_move": "Nc4"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 20,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 20,
      "attempt": 1,
      "plan_full": [
        "b4",
        "a5",
        "Qe7"
      ],
      "plan_execute": [
        "b4",
        "a5",
        "Qe7"
      ],
      "selected_move": "Nb6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "b4",
      "move_uci": "b5b4"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "a5",
      "move_uci": "a6a5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1,
      "plan_full": [
        "e5",
        "Nb1",
        "c3",
        "Nb8",
        "c6",
        "d2",
        "d4"
      ],
      "plan_execute": [
        "e5",
        "Nb1",
        "c3"
      ],
      "selected_move": "e4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 3,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 3,
      "attempt": 1,
      "plan_full": [
        "Nc6",
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "d6",
        "c3",
        "O-O"
      ],
      "plan_execute": [
        "Nc6",
        "Bb5",
        "a6"
      ],
      "selected_move": "Nf3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nc6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Bb5",
      "move_uci": "f1b5"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "a6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 7,
      "attempt": 1,
      "plan_full": [
        "Nf6",
        "d3",
        "d6"
      ],
      "plan_execute": [
        "Nf6",
        "d3",
        "d6"
      ],
      "selected_move": "Bc4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nf6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "d3",
      "move_uci": "d2d3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "d6",
      "actual_san": "Bc5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 11,
      "attempt": 1,
      "plan_full": [
        "b5"
      ],
      "plan_execute": [
        "b5"
      ],
      "selected_move": "Nbd2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "b5",
      "actual_san": "O-O"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1,
      "plan_full": [
        "Nf3",
        "Nc6",
        "Bc4",
        "Bc5",
        "d3",
        "d6"
      ],
      "plan_execute": [
        "Nf3",
        "Nc6",
        "Bc4"
      ],
      "selected_move": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "Bc4"
      ],
      "plan_execute": [
        "Bc4"
      ],
      "selected_move": "Nc6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1,
      "plan_full": [
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Nbd2",
        "Bc5"
      ],
      "plan_execute": [
        "Ba4",
        "Nf6",
        "O-O"
      ],
      "selected_move": "a6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1,
      "plan_full": [
        "d3",
        "Bc5"
      ],
      "plan_execute": [
        "d3",
        "Bc5"
      ],
      "selected_move": "Nf6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1,
      "plan_full": [
        "b3",
        "d6",
        "Na3",
        "Qe7"
      ],
      "plan_execute": [
        "b3",
        "d6",
        "Na3"
      ],
      "selected_move": "Be7"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1,
      "plan_full": [
        "Bc2",
        "d6",
        "Na5",
        "Nxe5"
      ],
      "plan_execute": [
        "Bc2",
        "d6",
        "Na5"
      ],
      "selected_move": "b5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1,
      "plan_full": [
        "Na3"
      ],
      "plan_execute": [
        "Na3"
      ],
      "selected_move": "d6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1,
      "plan_full": [
        "Nc4",
        "Qe7"
      ],
      "plan_execute": [
        "Nc4",
        "Qe7"
      ],
      "selected_move": "Na5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nc4",
      "move_uci": "a5c4"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 20,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 20,
      "attempt": 1,
      "plan_full": [
        "b4",
        "a5",
        "Qe7"
      ],
      "plan_execute": [
        "b4",
        "a5",
        "Qe7"
      ],
      "selected_move": "Nb6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "b4",
      "move_uci": "b5b4"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "a5",
      "move_uci": "a6a5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1,
      "plan_full": [
        "e5",
        "Nb1",
        "c3",
        "Nb8",
        "c6",
        "d2",
        "d4"
      ],
      "plan_execute": [
        "e5",
        "Nb1",
        "c3"
      ],
      "selected_move": "e4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 3,
      "attempt": 2
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 3,
      "attempt": 2,
      "plan_full": [
        "Nc6",
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "d6",
        "c3",
        "O-O"
      ],
      "plan_execute": [
        "Nc6",
        "Bb5",
        "a6"
      ],
      "selected_move": "Nf3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nc6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Bb5",
      "move_uci": "f1b5"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "a6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 7,
      "attempt": 1,
      "plan_full": [
        "Nf6",
        "d3",
        "d6"
      ],
      "plan_execute": [
        "Nf6",
        "d3",
        "d6"
      ],
      "selected_move": "Bc4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nf6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "d3",
      "move_uci": "d2d3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "d6",
      "actual_san": "Bc5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 11,
      "attempt": 1,
      "plan_full": [
        "b5",
        "Bb3",
        "d6"
      ],
      "plan_execute": [
        "b5",
        "Bb3",
        "d6"
      ],
      "selected_move": "Nbd2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "b5",
      "actual_san": "O-O"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "e3"
      ],
      "plan_execute": [
        "e3"
      ],
      "selected_move": "Nf6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1,
      "plan_full": [
        "Bh4",
        "g5",
        "Bg3",
        "Nh5",
        "e3"
      ],
      "plan_execute": [
        "Bh4",
        "g5",
        "Bg3"
      ],
      "selected_move": "h6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1,
      "plan_full": [
        "e3",
        "e6",
        "Nf3"
      ],
      "plan_execute": [
        "e3",
        "e6",
        "Nf3"
      ],
      "selected_move": "gxf6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1,
      "plan_full": [
        "Nxe4",
        "Nc6",
        "Nf3",
        "Qe7",
        "Bd3"
      ],
      "plan_execute": [
        "Nxe4",
        "Nc6",
        "Nf3"
      ],
      "selected_move": "dxe4"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1,
      "plan_full": [
        "Nf3",
        "Bg7",
        "Bd3",
        "Qe7",
        "O-O"
      ],
      "plan_execute": [
        "Nf3",
        "Bg7",
        "Bd3"
      ],
      "selected_move": "Nc6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1,
      "plan_full": [
        "Bc4",
        "Qe7",
        "Nf3"
      ],
      "plan_execute": [
        "Bc4",
        "Qe7",
        "Nf3"
      ],
      "selected_move": "a6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1,
      "plan_full": [
        "Nf3",
        "Qe7",
        "O-O",
        "Bd7"
      ],
      "plan_execute": [
        "Nf3",
        "Qe7",
        "O-O"
      ],
      "selected_move": "bxc6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nf3",
      "move_uci": "g1f3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "Qe7",
      "actual_san": "Nf6"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "b3"
      ],
      "plan_execute": [
        "b3"
      ],
      "selected_move": "dxc4"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1,
      "plan_full": [
        "e3",
        "a6"
      ],
      "plan_execute": [
        "e3",
        "a6"
      ],
      "selected_move": "Nc6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1,
      "plan_full": [
        "Nf6",
        "Bg5"
      ],
      "plan_execute": [
        "Nf6",
        "Bg5"
      ],
      "selected_move": "e6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nf6",
      "move_uci": "g8f6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1,
      "plan_full": [
        "Qe7"
      ],
      "plan_execute": [
        "Qe7"
      ],
      "selected_move": "Bb4"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Qe7",
      "move_uci": "d8e7"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "plan fully executed"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1,
      "plan_full": [
        "g4"
      ],
      "plan_execute": [
        "g4"
      ],
      "selected_move": "h6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "g4",
      "move_uci": "g2g4"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "plan fully executed"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 3,
      "attempt": 1,
      "plan_full": [
        "gxh4"
      ],
      "plan_execute": [
        "gxh4"
      ],
      "selected_move": "h4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "gxh4"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1,
      "plan_full": [
        "Nf3",
        "Nc6",
        "Bc4",
        "Bc5",
        "d3",
        "d6"
      ],
      "plan_execute": [
        "Nf3",
        "Nc6",
        "Bc4"
      ],
      "selected_move": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "Bc4"
      ],
      "plan_execute": [
        "Bc4"
      ],
      "selected_move": "Nc6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1,
      "plan_full": [
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Nbd2",
        "Bc5"
      ],
      "plan_execute": [
        "Ba4",
        "Nf6",
        "O-O"
      ],
      "selected_move": "a6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1,
      "plan_full": [
        "d3",
        "Bc5"
      ],
      "plan_execute": [
        "d3",
        "Bc5"
      ],
      "selected_move": "Nf6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1,
      "plan_full": [
        "b3",
        "d6",
        "Na3",
        "Qe7"
      ],
      "plan_execute": [
        "b3",
        "d6",
        "Na3"
      ],
      "selected_move": "Be7"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1,
      "plan_full": [
        "Bc2",
        "d6",
        "Na5"
      ],
      "plan_execute": [
        "Bc2",
        "d6",
        "Na5"
      ],
      "selected_move": "b5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1,
      "plan_full": [
        "Na3"
      ],
      "plan_execute": [
        "Na3"
      ],
      "selected_move": "d6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1,
      "plan_full": [
        "Bc2",
        "c5",
        "Nbd2"
      ],
      "plan_execute": [
        "Bc2",
        "c5",
        "Nbd2"
      ],
      "selected_move": "Na5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 18,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 18,
      "attempt": 1,
      "plan_full": [
        "b3",
        "Qe7"
      ],
      "plan_execute": [
        "b3",
        "Qe7"
      ],
      "selected_move": "Nc4"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 20,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 20,
      "attempt": 1,
      "plan_full": [
        "b4",
        "a5",
        "Qe7"
      ],
      "plan_execute": [
        "b4",
        "a5",
        "Qe7"
      ],
      "selected_move": "Nb6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "b4",
      "move_uci": "b5b4"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "a5",
      "move_uci": "a6a5"
    }
  ],
  "timestamp": "2025-11-30T00:55:01.617505",
  "game_id": "gpt-3.5-turbo-instruct_vs_meta-llama_llama-3.3-70b-instruct_SC_plan3_9",
  "configuration": "SC_plan3"
}