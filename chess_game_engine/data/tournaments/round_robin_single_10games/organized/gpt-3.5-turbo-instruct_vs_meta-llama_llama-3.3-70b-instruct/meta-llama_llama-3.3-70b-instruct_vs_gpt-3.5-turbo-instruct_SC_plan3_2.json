{
  "result": "gpt-3.5-turbo-instruct wins by disqualification (meta-llama/llama-3.3-70b-instruct failed to produce a legal move)",
  "white_player": "meta-llama/llama-3.3-70b-instruct",
  "black_player": "gpt-3.5-turbo-instruct",
  "white_score": 0.0,
  "black_score": 1.0,
  "total_moves": 12,
  "moves": [
    "e2e4",
    "e7e5",
    "g1f3",
    "b8c6",
    "f1b5",
    "a7a6",
    "b5c4",
    "g8f6",
    "d2d3",
    "f8c5",
    "b1d2",
    "e8g8"
  ],
  "game_history": [
    {
      "move_number": 1,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "white",
      "move_uci": "e2e4",
      "move_san": "e4",
      "fen_after": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "move_number": 2,
      "player": "gpt-3.5-turbo-instruct",
      "color": "black",
      "move_uci": "e7e5",
      "move_san": "e5",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "move_number": 3,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "white",
      "move_uci": "g1f3",
      "move_san": "Nf3",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "move_number": 4,
      "player": "gpt-3.5-turbo-instruct",
      "color": "black",
      "move_uci": "b8c6",
      "move_san": "Nc6",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "move_number": 5,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "white",
      "move_uci": "f1b5",
      "move_san": "Bb5",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "move_number": 6,
      "player": "gpt-3.5-turbo-instruct",
      "color": "black",
      "move_uci": "a7a6",
      "move_san": "a6",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "move_number": 7,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "white",
      "move_uci": "b5c4",
      "move_san": "Bc4",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/4p3/2B1P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "move_number": 8,
      "player": "gpt-3.5-turbo-instruct",
      "color": "black",
      "move_uci": "g8f6",
      "move_san": "Nf6",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/2B1P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "move_number": 9,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "white",
      "move_uci": "d2d3",
      "move_san": "d3",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/2B1P3/3P1N2/PPP2PPP/RNBQK2R b KQkq - 0 5"
    },
    {
      "move_number": 10,
      "player": "gpt-3.5-turbo-instruct",
      "color": "black",
      "move_uci": "f8c5",
      "move_san": "Bc5",
      "fen_after": "r1bqk2r/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPP2PPP/RNBQK2R w KQkq - 1 6"
    },
    {
      "move_number": 11,
      "player": "meta-llama/llama-3.3-70b-instruct",
      "color": "white",
      "move_uci": "b1d2",
      "move_san": "Nbd2",
      "fen_after": "r1bqk2r/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R b KQkq - 2 6"
    },
    {
      "move_number": 12,
      "player": "gpt-3.5-turbo-instruct",
      "color": "black",
      "move_uci": "e8g8",
      "move_san": "O-O",
      "fen_after": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7",
      "from_plan": true,
      "plan_source": "self_consistency"
    }
  ],
  "final_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7",
  "white_tokens": {
    "prompt_tokens": 7548,
    "completion_tokens": 2276,
    "total_tokens": 9824
  },
  "black_tokens": {
    "prompt_tokens": 6253,
    "completion_tokens": 21300,
    "total_tokens": 27553
  },
  "white_token_log": [
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 24,
          "total_tokens": 173,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 30,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 24,
          "total_tokens": 172,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 446,
        "total_completion_tokens": 78,
        "total_tokens": 524
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 149,
          "completion_tokens": 24,
          "total_tokens": 173,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 149,
          "completion_tokens": 30,
          "total_tokens": 179,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 148,
          "completion_tokens": 24,
          "total_tokens": 172,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 20,
          "total_tokens": 177,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 20,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 470,
        "total_completion_tokens": 84,
        "total_tokens": 554
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 20,
          "total_tokens": 177,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 44,
          "total_tokens": 201,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 20,
          "total_tokens": 176,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 52,
          "total_tokens": 218,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 49,
          "total_tokens": 215,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 29,
          "total_tokens": 194,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 497,
        "total_completion_tokens": 130,
        "total_tokens": 627
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 166,
          "completion_tokens": 52,
          "total_tokens": 218,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 166,
          "completion_tokens": 49,
          "total_tokens": 215,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 165,
          "completion_tokens": 29,
          "total_tokens": 194,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 173,
          "completion_tokens": 34,
          "total_tokens": 207,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 173,
          "completion_tokens": 126,
          "total_tokens": 299,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 172,
          "completion_tokens": 37,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 518,
        "total_completion_tokens": 197,
        "total_tokens": 715
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 173,
          "completion_tokens": 34,
          "total_tokens": 207,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 173,
          "completion_tokens": 126,
          "total_tokens": 299,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 172,
          "completion_tokens": 37,
          "total_tokens": 209,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 47,
          "total_tokens": 228,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 46,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 47,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 542,
        "total_completion_tokens": 140,
        "total_tokens": 682
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 181,
          "completion_tokens": 47,
          "total_tokens": 228,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 181,
          "completion_tokens": 46,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 180,
          "completion_tokens": 47,
          "total_tokens": 227,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 54,
          "total_tokens": 242,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 178,
          "total_tokens": 366,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 120,
          "total_tokens": 307,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 563,
        "total_completion_tokens": 352,
        "total_tokens": 915
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 54,
          "total_tokens": 242,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 178,
          "total_tokens": 366,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 120,
          "total_tokens": 307,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 56,
          "total_tokens": 251,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 587,
        "total_completion_tokens": 168,
        "total_tokens": 755
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 56,
          "total_tokens": 252,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 56,
          "total_tokens": 251,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 69,
          "total_tokens": 272,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 66,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 69,
          "total_tokens": 271,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 204,
        "total_tokens": 812
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 69,
          "total_tokens": 272,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 66,
          "total_tokens": 269,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 69,
          "total_tokens": 271,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 75,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 76,
          "total_tokens": 288,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 76,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 635,
        "total_completion_tokens": 227,
        "total_tokens": 862
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 212,
          "completion_tokens": 75,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 212,
          "completion_tokens": 76,
          "total_tokens": 288,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 211,
          "completion_tokens": 76,
          "total_tokens": 287,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 86,
          "total_tokens": 306,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 84,
          "total_tokens": 304,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 84,
          "total_tokens": 303,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 659,
        "total_completion_tokens": 254,
        "total_tokens": 913
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 220,
          "completion_tokens": 86,
          "total_tokens": 306,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 220,
          "completion_tokens": 84,
          "total_tokens": 304,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 219,
          "completion_tokens": 84,
          "total_tokens": 303,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 46,
          "total_tokens": 191,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 23,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 33,
          "total_tokens": 217,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 514,
        "total_completion_tokens": 102,
        "total_tokens": 616
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 145,
          "completion_tokens": 46,
          "total_tokens": 191,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 23,
          "total_tokens": 208,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 33,
          "total_tokens": 217,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 9,
          "total_tokens": 160,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 63,
          "total_tokens": 214,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 9,
          "total_tokens": 159,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 452,
        "total_completion_tokens": 81,
        "total_tokens": 533
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 151,
          "completion_tokens": 9,
          "total_tokens": 160,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 151,
          "completion_tokens": 63,
          "total_tokens": 214,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 150,
          "completion_tokens": 9,
          "total_tokens": 159,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 35,
          "total_tokens": 202,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 503,
        "total_completion_tokens": 105,
        "total_tokens": 608
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 168,
          "completion_tokens": 35,
          "total_tokens": 203,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 167,
          "completion_tokens": 35,
          "total_tokens": 202,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 55,
          "total_tokens": 240,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 52,
          "total_tokens": 237,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 47,
          "total_tokens": 231,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 554,
        "total_completion_tokens": 154,
        "total_tokens": 708
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 185,
          "completion_tokens": 55,
          "total_tokens": 240,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 185,
          "completion_tokens": 52,
          "total_tokens": 237,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 184,
          "completion_tokens": 47,
          "total_tokens": 231,
          "model": "meta-llama/llama-3.3-70b-instruct",
          "finish_reason": "stop"
        }
      }
    }
  ],
  "black_token_log": [
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 443,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1723,
        "total_tokens": 2052
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 443,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 269,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1549,
        "total_tokens": 1923
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 269,
          "total_tokens": 393,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 227,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 1507,
        "total_tokens": 1929
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 640,
          "total_tokens": 781,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 227,
          "total_tokens": 367,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 148,
          "completion_tokens": 247,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 148,
          "completion_tokens": 282,
          "total_tokens": 430,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 147,
          "completion_tokens": 216,
          "total_tokens": 363,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 443,
        "total_completion_tokens": 745,
        "total_tokens": 1188
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 148,
          "completion_tokens": 247,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 148,
          "completion_tokens": 282,
          "total_tokens": 430,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 147,
          "completion_tokens": 216,
          "total_tokens": 363,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 163,
          "completion_tokens": 198,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 163,
          "completion_tokens": 640,
          "total_tokens": 803,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 162,
          "completion_tokens": 580,
          "total_tokens": 742,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 488,
        "total_completion_tokens": 1418,
        "total_tokens": 1906
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 163,
          "completion_tokens": 198,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 163,
          "completion_tokens": 640,
          "total_tokens": 803,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 162,
          "completion_tokens": 580,
          "total_tokens": 742,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 372,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 493,
          "total_tokens": 663,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1505,
        "total_tokens": 2017
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 372,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 493,
          "total_tokens": 663,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 470,
          "total_tokens": 650,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 339,
          "total_tokens": 518,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 539,
        "total_completion_tokens": 1449,
        "total_tokens": 1988
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 180,
          "completion_tokens": 640,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 180,
          "completion_tokens": 470,
          "total_tokens": 650,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 179,
          "completion_tokens": 339,
          "total_tokens": 518,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 175,
          "total_tokens": 370,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 502,
          "total_tokens": 697,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 640,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 584,
        "total_completion_tokens": 1317,
        "total_tokens": 1901
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 195,
          "completion_tokens": 175,
          "total_tokens": 370,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 195,
          "completion_tokens": 502,
          "total_tokens": 697,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 194,
          "completion_tokens": 640,
          "total_tokens": 834,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 640,
          "total_tokens": 842,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 608,
        "total_completion_tokens": 1920,
        "total_tokens": 2528
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 203,
          "completion_tokens": 640,
          "total_tokens": 843,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 202,
          "completion_tokens": 640,
          "total_tokens": 842,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 498,
          "total_tokens": 612,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 640,
          "total_tokens": 753,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1778,
        "total_tokens": 2119
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 498,
          "total_tokens": 612,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 640,
          "total_tokens": 753,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 328,
          "total_tokens": 450,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 609,
          "total_tokens": 730,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 365,
        "total_completion_tokens": 1577,
        "total_tokens": 1942
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 328,
          "total_tokens": 450,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 609,
          "total_tokens": 730,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 631,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 589,
          "total_tokens": 720,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 392,
        "total_completion_tokens": 1860,
        "total_tokens": 2252
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 631,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 589,
          "total_tokens": 720,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 139,
          "completion_tokens": 424,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 416,
        "total_completion_tokens": 1704,
        "total_tokens": 2120
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 139,
          "completion_tokens": 640,
          "total_tokens": 779,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 139,
          "completion_tokens": 424,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 347,
          "total_tokens": 494,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 261,
          "total_tokens": 408,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 640,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 440,
        "total_completion_tokens": 1248,
        "total_tokens": 1688
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 147,
          "completion_tokens": 347,
          "total_tokens": 494,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 147,
          "completion_tokens": 261,
          "total_tokens": 408,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 146,
          "completion_tokens": 640,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    }
  ],
  "white_responses": [
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6",
          "aggressive_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6 Nc3 Nf6",
          "positional_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6",
            "Nc3",
            "Nf6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1. e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6",
          "neutral_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6",
              "Nc3",
              "Nf6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf3",
            "Nc6",
            "Bc4"
          ],
          "full_moves": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 446,
          "total_completion_tokens": 78,
          "total_tokens": 524
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 149,
            "completion_tokens": 30,
            "total_tokens": 179,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 148,
            "completion_tokens": 24,
            "total_tokens": 172,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "1. e4 e5 2. Nf3 \nNc6 Bc4",
          "aggressive_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nNc6 Bc2",
          "positional_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2"
          ],
          "plan_execute": [
            "Bc2"
          ]
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "1. e4 e5 2. Nf3 \nNc6 Bc4",
          "neutral_tokens": {
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "Bc2"
            ],
            "execute": [
              "Bc2"
            ]
          },
          "neutral": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc4"
          ],
          "full_moves": [
            "Bc4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 470,
          "total_completion_tokens": 84,
          "total_tokens": 554
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 157,
            "completion_tokens": 20,
            "total_tokens": 177,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 157,
            "completion_tokens": 44,
            "total_tokens": 201,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 156,
            "completion_tokens": 20,
            "total_tokens": 176,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 \nBc2 c5",
          "aggressive_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 52,
            "total_tokens": 218,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bc2",
            "c5"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 \nBa4",
          "positional_tokens": {
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Ba4"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 \nNf6 Bc4",
          "neutral_tokens": {
            "prompt_tokens": 165,
            "completion_tokens": 29,
            "total_tokens": 194,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4"
          ],
          "plan_execute": [
            "Bc4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "g8f6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bc2",
              "c5"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Ba4"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Bc4"
            ],
            "execute": [
              "Bc4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Ba4",
            "Nf6",
            "O-O"
          ],
          "full_moves": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bc2",
            "c5"
          ],
          "source_agent": "aggressive"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 166,
            "completion_tokens": 52,
            "total_tokens": 218,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 165,
            "completion_tokens": 29,
            "total_tokens": 194,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 497,
          "total_completion_tokens": 130,
          "total_tokens": 627
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 166,
            "completion_tokens": 52,
            "total_tokens": 218,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 166,
            "completion_tokens": 49,
            "total_tokens": 215,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 165,
            "completion_tokens": 29,
            "total_tokens": 194,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 d3",
          "aggressive_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3"
          ],
          "plan_execute": [
            "d3"
          ]
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 Bc2 b5 a4 d6 \nis incorrect, the correct move order is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 \nnow it's Black's move: \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 Nd4 Na5 Nc3",
          "positional_tokens": {
            "prompt_tokens": 173,
            "completion_tokens": 126,
            "total_tokens": 299,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd4",
            "Na5",
            "Nc3"
          ],
          "plan_execute": [
            "Nd4",
            "Na5",
            "Nc3"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 d3 Bc5",
          "neutral_tokens": {
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Bc5"
          ],
          "plan_execute": [
            "d3",
            "Bc5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d3"
            ],
            "execute": [
              "d3"
            ]
          },
          "positional": {
            "full": [
              "Nd4",
              "Na5",
              "Nc3"
            ],
            "execute": [
              "Nd4",
              "Na5",
              "Nc3"
            ]
          },
          "neutral": {
            "full": [
              "d3",
              "Bc5"
            ],
            "execute": [
              "d3",
              "Bc5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "d3",
            "Bc5"
          ],
          "full_moves": [
            "d3",
            "Bc5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 173,
            "completion_tokens": 126,
            "total_tokens": 299,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 518,
          "total_completion_tokens": 197,
          "total_tokens": 715
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 173,
            "completion_tokens": 34,
            "total_tokens": 207,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 173,
            "completion_tokens": 126,
            "total_tokens": 299,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 172,
            "completion_tokens": 37,
            "total_tokens": 209,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be7",
          "aggressive_uci": "f8e7",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 b5 Bb3",
          "aggressive_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 47,
            "total_tokens": 228,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "b5",
            "Bb3"
          ],
          "plan_execute": [
            "b3",
            "b5",
            "Bb3"
          ]
        },
        "query2": {
          "positional_move": "Be7",
          "positional_uci": "f8e7",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 d6 Na3",
          "positional_tokens": {
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "d6",
            "Na3"
          ],
          "plan_execute": [
            "b3",
            "d6",
            "Na3"
          ]
        },
        "query3": {
          "neutral_move": "Be7",
          "neutral_uci": "f8e7",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O \nBe7 b3 b5 Bb3",
          "neutral_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "b5",
            "Bb3"
          ],
          "plan_execute": [
            "b3",
            "b5",
            "Bb3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f8e7",
          "positional_uci": "f8e7",
          "neutral_uci": "f8e7",
          "consensus_move": "f8e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b3",
              "b5",
              "Bb3"
            ],
            "execute": [
              "b3",
              "b5",
              "Bb3"
            ]
          },
          "positional": {
            "full": [
              "b3",
              "d6",
              "Na3"
            ],
            "execute": [
              "b3",
              "d6",
              "Na3"
            ]
          },
          "neutral": {
            "full": [
              "b3",
              "b5",
              "Bb3"
            ],
            "execute": [
              "b3",
              "b5",
              "Bb3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b3",
            "b5",
            "Bb3"
          ],
          "full_moves": [
            "b3",
            "b5",
            "Bb3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 181,
            "completion_tokens": 47,
            "total_tokens": 228,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 542,
          "total_completion_tokens": 140,
          "total_tokens": 682
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 181,
            "completion_tokens": 47,
            "total_tokens": 228,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 181,
            "completion_tokens": 46,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 180,
            "completion_tokens": 47,
            "total_tokens": 227,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 b kq - 3 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b5",
          "aggressive_uci": "b7b5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nNa3",
          "aggressive_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na3"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na3"
          ]
        },
        "query2": {
          "positional_move": "b5",
          "positional_uci": "b7b5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nis incorrect, the correct continuation is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 is incorrect \nThe correct move is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 \nThe next 4 moves are \nb5 Bc2 d6 Na5",
          "positional_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 178,
            "total_tokens": 366,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na5"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na5"
          ]
        },
        "query3": {
          "neutral_move": "b5",
          "neutral_uci": "b7b5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 Bc2 d6 \nis incorrect, the correct continuation is \n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 \nBlack to move: b5 Bc2 d6 Na5 Nxe5",
          "neutral_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 120,
            "total_tokens": 307,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "d6",
            "Na5",
            "Nxe5"
          ],
          "plan_execute": [
            "Bc2",
            "d6",
            "Na5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b7b5",
          "positional_uci": "b7b5",
          "neutral_uci": "b7b5",
          "consensus_move": "b7b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc2",
              "d6",
              "Na3"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na3"
            ]
          },
          "positional": {
            "full": [
              "Bc2",
              "d6",
              "Na5"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na5"
            ]
          },
          "neutral": {
            "full": [
              "Bc2",
              "d6",
              "Na5",
              "Nxe5"
            ],
            "execute": [
              "Bc2",
              "d6",
              "Na5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc2",
            "d6",
            "Na5"
          ],
          "full_moves": [
            "Bc2",
            "d6",
            "Na5",
            "Nxe5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 188,
            "completion_tokens": 178,
            "total_tokens": 366,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 187,
            "completion_tokens": 120,
            "total_tokens": 307,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 563,
          "total_completion_tokens": 352,
          "total_tokens": 915
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 188,
            "completion_tokens": 54,
            "total_tokens": 242,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 188,
            "completion_tokens": 178,
            "total_tokens": 366,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 187,
            "completion_tokens": 120,
            "total_tokens": 307,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQR1K1 b kq - 5 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d6",
          "aggressive_uci": "d7d6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "aggressive_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "query2": {
          "positional_move": "d6",
          "positional_uci": "d7d6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "positional_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "query3": {
          "neutral_move": "d6",
          "neutral_uci": "d7d6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 Na3",
          "neutral_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Na3"
          ],
          "plan_execute": [
            "Na3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d7d6",
          "positional_uci": "d7d6",
          "neutral_uci": "d7d6",
          "consensus_move": "d7d6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          },
          "positional": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          },
          "neutral": {
            "full": [
              "Na3"
            ],
            "execute": [
              "Na3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Na3"
          ],
          "full_moves": [
            "Na3"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 587,
          "total_completion_tokens": 168,
          "total_tokens": 755
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 196,
            "completion_tokens": 56,
            "total_tokens": 252,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 195,
            "completion_tokens": 56,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2ppbppp/p1n2n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 b kq - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Na5",
          "aggressive_uci": "c6a5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5 Nbd2",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "plan_execute": [
            "Bc2",
            "c5",
            "Nbd2"
          ]
        },
        "query2": {
          "positional_move": "Na5",
          "positional_uci": "c6a5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5"
          ],
          "plan_execute": [
            "Bc2",
            "c5"
          ]
        },
        "query3": {
          "neutral_move": "Na5",
          "neutral_uci": "c6a5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 Bc2 c5 Nbd2",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 69,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "plan_execute": [
            "Bc2",
            "c5",
            "Nbd2"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c6a5",
          "positional_uci": "c6a5",
          "neutral_uci": "c6a5",
          "consensus_move": "c6a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc2",
              "c5",
              "Nbd2"
            ],
            "execute": [
              "Bc2",
              "c5",
              "Nbd2"
            ]
          },
          "positional": {
            "full": [
              "Bc2",
              "c5"
            ],
            "execute": [
              "Bc2",
              "c5"
            ]
          },
          "neutral": {
            "full": [
              "Bc2",
              "c5",
              "Nbd2"
            ],
            "execute": [
              "Bc2",
              "c5",
              "Nbd2"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "full_moves": [
            "Bc2",
            "c5",
            "Nbd2"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 69,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 204,
          "total_tokens": 812
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 69,
            "total_tokens": 272,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 66,
            "total_tokens": 269,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 69,
            "total_tokens": 271,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 b kq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc4",
          "aggressive_uci": "a5c4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 b6 Qe2",
          "aggressive_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 75,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b6",
            "Qe2"
          ],
          "plan_execute": [
            "b6",
            "Qe2"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": "a5c4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 \nNc4 b3 Qe7",
          "positional_tokens": {
            "prompt_tokens": 212,
            "completion_tokens": 76,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Qe7"
          ],
          "plan_execute": [
            "b3",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Nc4",
          "neutral_uci": "a5c4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 \nNc4 b3 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 211,
            "completion_tokens": 76,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Qe7"
          ],
          "plan_execute": [
            "b3",
            "Qe7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a5c4",
          "positional_uci": "a5c4",
          "neutral_uci": "a5c4",
          "consensus_move": "a5c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b6",
              "Qe2"
            ],
            "execute": [
              "b6",
              "Qe2"
            ]
          },
          "positional": {
            "full": [
              "b3",
              "Qe7"
            ],
            "execute": [
              "b3",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b3",
              "Qe7"
            ],
            "execute": [
              "b3",
              "Qe7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b3",
            "Qe7"
          ],
          "full_moves": [
            "b3",
            "Qe7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 212,
            "completion_tokens": 75,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 212,
            "completion_tokens": 76,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 211,
            "completion_tokens": 76,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 635,
          "total_completion_tokens": 227,
          "total_tokens": 862
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 212,
            "completion_tokens": 75,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 212,
            "completion_tokens": 76,
            "total_tokens": 288,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 211,
            "completion_tokens": 76,
            "total_tokens": 287,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/np2p3/4P3/2P2N2/PPBP1PPP/RNBQR1K1 b kq - 2 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nb6",
          "aggressive_uci": "c4b6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a4 Qe7 \nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 86,
            "total_tokens": 306,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a4",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a4",
            "Qe7"
          ]
        },
        "query2": {
          "positional_move": "Nb6",
          "positional_uci": "c4b6",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a5",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Nb6",
          "neutral_uci": "c4b6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 b4 a5 Qe7",
          "neutral_tokens": {
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b4",
            "a5",
            "Qe7"
          ],
          "plan_execute": [
            "b4",
            "a5",
            "Qe7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c4b6",
          "positional_uci": "c4b6",
          "neutral_uci": "c4b6",
          "consensus_move": "c4b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b4",
              "a4",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a4",
              "Qe7"
            ]
          },
          "positional": {
            "full": [
              "b4",
              "a5",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b4",
              "a5",
              "Qe7"
            ],
            "execute": [
              "b4",
              "a5",
              "Qe7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b4",
            "a5",
            "Qe7"
          ],
          "full_moves": [
            "b4",
            "a5",
            "Qe7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 220,
            "completion_tokens": 86,
            "total_tokens": 306,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 659,
          "total_completion_tokens": 254,
          "total_tokens": 913
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 220,
            "completion_tokens": 86,
            "total_tokens": 306,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 220,
            "completion_tokens": 84,
            "total_tokens": 304,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 219,
            "completion_tokens": 84,
            "total_tokens": 303,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2PP1N2/PPB2PPP/RNBQR1K1 b kq - 0 10"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 341,
          "total_tokens": 1072
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 26,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 341,
          "total_tokens": 1072
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 113,
            "total_tokens": 356,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 26,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxa5",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 Nc4 Qe7 Bg4 h3",
          "aggressive_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Bg4",
            "h3"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "Nxa5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nQe2 Nc4 Nxe5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Nc4",
            "Nxe5",
            "Qe7"
          ],
          "plan_execute": [
            "Qe2",
            "Nc4",
            "Nxe5"
          ]
        },
        "query3": {
          "neutral_move": "Nxa5",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 Na5 9. Bc2 Nc4 10. d3 Nb6 11. Nbd2 b4 12. cxb4 a5 13. bxa5 Nxa5 \nNc4 Qe7 Nbd4 Qe6",
          "neutral_tokens": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc4",
            "Qe7",
            "Nbd4",
            "Qe6"
          ],
          "plan_execute": [
            "Nc4",
            "Qe7",
            "Nbd4"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc4",
              "Qe7",
              "Bg4",
              "h3"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "Qe2",
              "Nc4",
              "Nxe5",
              "Qe7"
            ],
            "execute": [
              "Qe2",
              "Nc4",
              "Nxe5"
            ]
          },
          "neutral": {
            "full": [
              "Nc4",
              "Qe7",
              "Nbd4",
              "Qe6"
            ],
            "execute": [
              "Nc4",
              "Qe7",
              "Nbd4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 731,
          "total_completion_tokens": 343,
          "total_tokens": 1074
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 244,
            "completion_tokens": 113,
            "total_tokens": 357,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 244,
            "completion_tokens": 115,
            "total_tokens": 359,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 243,
            "completion_tokens": 115,
            "total_tokens": 358,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/P3p3/4P3/3P1N2/PPBN1PPP/R1BQR1K1 b kq - 0 13"
    },
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": null,
          "aggressive_response": "*e4 \ne5 Nf3 Nc6 Bc4 Bc5 d3 d6 Nc3 Nf6 Bg5 h6 Bh4 g5 Bg3 Qe7 Qd2",
          "aggressive_tokens": {
            "prompt_tokens": 145,
            "completion_tokens": 46,
            "total_tokens": 191,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bc4",
            "Bc5",
            "d3",
            "d6",
            "Nc3",
            "Nf6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Qe7",
            "Qd2"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bc4"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "* \nWhite to move: e4 \nPlan: e5 Nf3 Nc6 Bc4",
          "positional_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 23,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bc4"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "There is no game to repeat. \nMove: e4\nPlan: e5, Nb1-c3, Nb8-c6, d2-d4",
          "neutral_tokens": {
            "prompt_tokens": 184,
            "completion_tokens": 33,
            "total_tokens": 217,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nb1",
            "c3",
            "Nb8",
            "c6",
            "d2",
            "d4"
          ],
          "plan_execute": [
            "e5",
            "Nb1",
            "c3"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bc4",
              "Bc5",
              "d3",
              "d6",
              "Nc3",
              "Nf6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Qe7",
              "Qd2"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bc4"
            ]
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bc4"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          },
          "neutral": {
            "full": [
              "e5",
              "Nb1",
              "c3",
              "Nb8",
              "c6",
              "d2",
              "d4"
            ],
            "execute": [
              "e5",
              "Nb1",
              "c3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e5",
            "Nb1",
            "c3"
          ],
          "full_moves": [
            "e5",
            "Nb1",
            "c3",
            "Nb8",
            "c6",
            "d2",
            "d4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 145,
            "completion_tokens": 46,
            "total_tokens": 191,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 185,
            "completion_tokens": 23,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 184,
            "completion_tokens": 33,
            "total_tokens": 217,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 514,
          "total_completion_tokens": 102,
          "total_tokens": 616
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 145,
            "completion_tokens": 46,
            "total_tokens": 191,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 185,
            "completion_tokens": 23,
            "total_tokens": 208,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 184,
            "completion_tokens": 33,
            "total_tokens": 217,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5\nWhite",
          "aggressive_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": [
            "e5"
          ]
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "1. e4 e5\n2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O \nWhite",
          "positional_tokens": {
            "prompt_tokens": 151,
            "completion_tokens": 63,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O"
          ],
          "plan_execute": [
            "Nc6",
            "Bb5",
            "a6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5\nWhite",
          "neutral_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5"
          ],
          "plan_execute": [
            "e5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g1f3",
          "neutral_uci": null,
          "consensus_move": "g1f3",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e5"
            ],
            "execute": [
              "e5"
            ]
          },
          "positional": {
            "full": [
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O"
            ],
            "execute": [
              "Nc6",
              "Bb5",
              "a6"
            ]
          },
          "neutral": {
            "full": [
              "e5"
            ],
            "execute": [
              "e5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nc6",
            "Bb5",
            "a6"
          ],
          "full_moves": [
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O"
          ],
          "source_agent": "positional"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 151,
            "completion_tokens": 63,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 452,
          "total_completion_tokens": 81,
          "total_tokens": 533
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 151,
            "completion_tokens": 9,
            "total_tokens": 160,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 151,
            "completion_tokens": 63,
            "total_tokens": 214,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 150,
            "completion_tokens": 9,
            "total_tokens": 159,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc4",
          "aggressive_uci": "b5c4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 \nBc4 Nf6 d3 d6",
          "aggressive_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf6",
            "d3",
            "d6"
          ]
        },
        "query2": {
          "positional_move": "Bc4",
          "positional_uci": "b5c4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 \nBc4 Nf6 d3 d6",
          "positional_tokens": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf6",
            "d3",
            "d6"
          ]
        },
        "query3": {
          "neutral_move": "Bc4",
          "neutral_uci": "b5c4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 \nBc4 Nf6 d3 d6",
          "neutral_tokens": {
            "prompt_tokens": 167,
            "completion_tokens": 35,
            "total_tokens": 202,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "d3",
            "d6"
          ],
          "plan_execute": [
            "Nf6",
            "d3",
            "d6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b5c4",
          "positional_uci": "b5c4",
          "neutral_uci": "b5c4",
          "consensus_move": "b5c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf6",
              "d3",
              "d6"
            ]
          },
          "positional": {
            "full": [
              "Nf6",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf6",
              "d3",
              "d6"
            ]
          },
          "neutral": {
            "full": [
              "Nf6",
              "d3",
              "d6"
            ],
            "execute": [
              "Nf6",
              "d3",
              "d6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf6",
            "d3",
            "d6"
          ],
          "full_moves": [
            "Nf6",
            "d3",
            "d6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 167,
            "completion_tokens": 35,
            "total_tokens": 202,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 503,
          "total_completion_tokens": 105,
          "total_tokens": 608
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 168,
            "completion_tokens": 35,
            "total_tokens": 203,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 167,
            "completion_tokens": 35,
            "total_tokens": 202,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd2",
          "aggressive_uci": "b1d2",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 \nNbd2 b5 Bb3 Na5 Nc3",
          "aggressive_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 55,
            "total_tokens": 240,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "Na5",
            "Nc3"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "Na5"
          ]
        },
        "query2": {
          "positional_move": "Nbd2",
          "positional_uci": "b1d2",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 \nNbd2 b5 Bb3 d6",
          "positional_tokens": {
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "d6"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "d6"
          ]
        },
        "query3": {
          "neutral_move": "Nbd2",
          "neutral_uci": "b1d2",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 \nNbd2 b5",
          "neutral_tokens": {
            "prompt_tokens": 184,
            "completion_tokens": 47,
            "total_tokens": 231,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b1d2",
          "positional_uci": "b1d2",
          "neutral_uci": "b1d2",
          "consensus_move": "b1d2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5",
              "Bb3",
              "Na5",
              "Nc3"
            ],
            "execute": [
              "b5",
              "Bb3",
              "Na5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Bb3",
              "d6"
            ],
            "execute": [
              "b5",
              "Bb3",
              "d6"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b5"
          ],
          "full_moves": [
            "b5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 185,
            "completion_tokens": 55,
            "total_tokens": 240,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 184,
            "completion_tokens": 47,
            "total_tokens": 231,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 554,
          "total_completion_tokens": 154,
          "total_tokens": 708
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 185,
            "completion_tokens": 55,
            "total_tokens": 240,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 185,
            "completion_tokens": 52,
            "total_tokens": 237,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 184,
            "completion_tokens": 47,
            "total_tokens": 231,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPP2PPP/RNBQK2R w KQkq - 1 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nNc4 b5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Qe7"
          ],
          "plan_execute": [
            "b5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Qe7"
            ],
            "execute": [
              "b5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 168,
          "total_tokens": 746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7"
    },
    {
      "turn": 13,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nNc4 b5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Qe7"
          ],
          "plan_execute": [
            "b5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Qe7"
            ],
            "execute": [
              "b5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 168,
          "total_tokens": 746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7"
    },
    {
      "turn": 13,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe7",
          "aggressive_uci": null,
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "aggressive_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nNc4 b5 Qe7",
          "positional_tokens": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Qe7"
          ],
          "plan_execute": [
            "b5",
            "Qe7"
          ]
        },
        "query3": {
          "neutral_move": "Qe7",
          "neutral_uci": null,
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bc4 Nf6 5. d3 Bc5 6. Nbd2 O-O \nQe7 b5",
          "neutral_tokens": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5"
          ],
          "plan_execute": [
            "b5"
          ]
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Qe7"
            ],
            "execute": [
              "b5",
              "Qe7"
            ]
          },
          "neutral": {
            "full": [
              "b5"
            ],
            "execute": [
              "b5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 578,
          "total_completion_tokens": 168,
          "total_tokens": 746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 193,
            "completion_tokens": 55,
            "total_tokens": 248,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 193,
            "completion_tokens": 58,
            "total_tokens": 251,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 192,
            "completion_tokens": 55,
            "total_tokens": 247,
            "model": "meta-llama/llama-3.3-70b-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bq1rk1/1ppp1ppp/p1n2n2/2b1p3/2B1P3/3P1N2/PPPN1PPP/R1BQK2R w KQ - 3 7"
    }
  ],
  "black_responses": [
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 d5\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg6 Qh4+ Kg8 Re8#\nd4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8 c3 e5 dxe5 Nxe5 Nxe5 Qxe5 Bxh7+ Kxh7 Qxd8 b6 Rfe1 Qg5 Qh4+ Kg8 Re8# d4 d5 Nc3 Nf6 Bg5 e6 e4 dxe4 Nxe4 Be7 Nxf6+ Bxf6 Bxf6 Qxf6 Nf3 O-O Bd3 Nc6 O-O Rd8",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "e6",
            "e4",
            "dxe4",
            "Nxe4",
            "Be7",
            "Nxf6+",
            "Bxf6",
            "Bxf6",
            "Qxf6",
            "Nf3",
            "O-O",
            "Bd3",
            "Nc6",
            "O-O",
            "Rd8"
          ],
          "plan_execute": [
            "d5",
            "Nc3",
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Bg7 Qe6 17. Nf6+ Qxf6 18. Bxf6 Be6 19. Qxb7 Rc8 20. Rad1 Bd7 21. Rxd6 Nb8 22. Rfd1 Rxc2 23. Rxd7 Nxd7 24. Qxd7+ Kf8 25. Qe7+ Kg8 26. Qg7# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Bg7 Qe6 Nf6 Qxf6 Bxf6 Be6 Qxb7 Rc8 Rad1 Bd7 Rxd6 Nb8 Qxd7+ Nxd7 Rxd7+ Ke8 Rfd1 Kf8 R1d6 Kg8 Rg6+ Kh8 Rh6+ Kg8 Rg6+ Kh8 Rgg7 Rxc2 Rh7+ Kg8 Rdg7+ Kf8 Rf7+ Kg8 Rhg7+ Kh8 Rh7+ Kg8 Rfg7+ Kf8 Rf7+ Kg8 Rhg7+ Kh8 Rg6 Rc1#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 443,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Bg7",
            "Qe6",
            "Nf6",
            "Qxf6",
            "Bxf6",
            "Be6",
            "Qxb7",
            "Rc8",
            "Rad1",
            "Bd7",
            "Rxd6",
            "Nb8",
            "Qxd7+",
            "Nxd7",
            "Rxd7+",
            "Ke8",
            "Rfd1",
            "Kf8",
            "R1d6",
            "Kg8",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Kg8",
            "Rg6+",
            "Kh8",
            "Rgg7",
            "Rxc2",
            "Rh7+",
            "Kg8",
            "Rdg7+",
            "Kf8",
            "Rf7+",
            "Kg8",
            "Rhg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rfg7+",
            "Kf8",
            "Rf7+",
            "Kg8",
            "Rhg7+",
            "Kh8",
            "Rg6",
            "Rc1#"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "1. e4 e5\n2. Nf3 Nc6\n3. Bb5 a6\n4. Ba4 Nf6\n5. O-O Be7\n6. Re1 b5\n7. Bb3 O-O\n8. c3 d6\n9. d4 Bg4\n10. d5 Na5\n11. Bc2 c6\n12. dxc6 Nxc6\n13. Nbd2 d5\n14. h3 Bh5\n15. g4 Bg6\n16. exd5 Nxd5\n17. Nxe5 Nxe5\n18. Rxe5 Nf4\n19. Bxg6 fxg6\n20. Qf3 Nd3\n21. Qd5+ Qxd5\n22. Rxd5 Nxf2\n23. Kg2 Rae8\n24. Nf3 Nxh3\n25. Kxh3 Rxf3+\n26. Kg2 Ref8\n27. Rd2 Bh4\n28. Re2 Rg3+\n29. Kh2 Rxg4\n30. Be3 Re4\n31. Kg2 Rfe8\n32. Kf3 Bg5\n33. Rae1 Rxe3+\n34. Rxe3 Rxe3+\n35. Rxe3 Bxe3\n36. Kxe3 Kf7\n37. b3 Ke6\n38. c4 bxc4\n39. bxc4 Ke5\n40. a4 a5\n41. Kd3 h5\n42. Ke3 g5\n43. Kd3 h4\n44. Ke3 g4\n45. Kd3 h3\n46. Ke3 g5\n47. Kd3 h2\n48. Ke3 g3\n49. Kd3 h1=Q\n50. Ke3 Qe4+\n51. Kd2 Kd4\n52. Kc1 Kc3\n53. Kd1 Qe3\ne4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d6 d4 Bg4 d5 Na5 Bc2 c6 dxc6 Nxc6 Nbd2 d5 h3 Bh5 g4 Bg6 exd5 Nxd5 Nxe5 Nxe5 Rxe5 Nf4 Bxg6 fxg6 Qf3 Nd3 Qd5+ Qxd5 Rxd5 Nxf2 Kg2 Rae8 Nf3 Nxh3 Kxh3 Rxf3 Kg2 Ref8 Rd2 Bh4 Re2 Rg3+ Kh2 Rxg4 Be3 Re4 Kg2 Rfe8 Kf3 Bg5 Rae1 Rxe3 Rxe3 Rxe3 Rxe3 Bxe3 Kxe3 Kf7 b3 Ke6 c4 bxc4 bxc4 Ke5 a4 a5 Kd",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "d4",
            "Bg4",
            "d5",
            "Na5",
            "Bc2",
            "c6",
            "dxc6",
            "Nxc6",
            "Nbd2",
            "d5",
            "h3",
            "Bh5",
            "g4",
            "Bg6",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Nf4",
            "Bxg6",
            "fxg6",
            "Qf3",
            "Nd3",
            "Qd5+",
            "Qxd5",
            "Rxd5",
            "Nxf2",
            "Kg2",
            "Rae8",
            "Nf3",
            "Nxh3",
            "Kxh3",
            "Rxf3",
            "Kg2",
            "Ref8",
            "Rd2",
            "Bh4",
            "Re2",
            "Rg3+",
            "Kh2",
            "Rxg4",
            "Be3",
            "Re4",
            "Kg2",
            "Rfe8",
            "Kf3",
            "Bg5",
            "Rae1",
            "Rxe3",
            "Rxe3",
            "Rxe3",
            "Rxe3",
            "Bxe3",
            "Kxe3",
            "Kf7",
            "b3",
            "Ke6",
            "c4",
            "bxc4",
            "bxc4",
            "Ke5",
            "a4",
            "a5"
          ],
          "plan_execute": [
            "e5",
            "Nf3",
            "Nc6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nc3",
              "Nf6",
              "Bg5",
              "e6",
              "e4",
              "dxe4",
              "Nxe4",
              "Be7",
              "Nxf6+",
              "Bxf6",
              "Bxf6",
              "Qxf6",
              "Nf3",
              "O-O",
              "Bd3",
              "Nc6",
              "O-O",
              "Rd8"
            ],
            "execute": [
              "d5",
              "Nc3",
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Bg7",
              "Qe6",
              "Nf6",
              "Qxf6",
              "Bxf6",
              "Be6",
              "Qxb7",
              "Rc8",
              "Rad1",
              "Bd7",
              "Rxd6",
              "Nb8",
              "Qxd7+",
              "Nxd7",
              "Rxd7+",
              "Ke8",
              "Rfd1",
              "Kf8",
              "R1d6",
              "Kg8",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Kg8",
              "Rg6+",
              "Kh8",
              "Rgg7",
              "Rxc2",
              "Rh7+",
              "Kg8",
              "Rdg7+",
              "Kf8",
              "Rf7+",
              "Kg8",
              "Rhg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rfg7+",
              "Kf8",
              "Rf7+",
              "Kg8",
              "Rhg7+",
              "Kh8",
              "Rg6",
              "Rc1#"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d6",
              "d4",
              "Bg4",
              "d5",
              "Na5",
              "Bc2",
              "c6",
              "dxc6",
              "Nxc6",
              "Nbd2",
              "d5",
              "h3",
              "Bh5",
              "g4",
              "Bg6",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Nf4",
              "Bxg6",
              "fxg6",
              "Qf3",
              "Nd3",
              "Qd5+",
              "Qxd5",
              "Rxd5",
              "Nxf2",
              "Kg2",
              "Rae8",
              "Nf3",
              "Nxh3",
              "Kxh3",
              "Rxf3",
              "Kg2",
              "Ref8",
              "Rd2",
              "Bh4",
              "Re2",
              "Rg3+",
              "Kh2",
              "Rxg4",
              "Be3",
              "Re4",
              "Kg2",
              "Rfe8",
              "Kf3",
              "Bg5",
              "Rae1",
              "Rxe3",
              "Rxe3",
              "Rxe3",
              "Rxe3",
              "Bxe3",
              "Kxe3",
              "Kf7",
              "b3",
              "Ke6",
              "c4",
              "bxc4",
              "bxc4",
              "Ke5",
              "a4",
              "a5"
            ],
            "execute": [
              "e5",
              "Nf3",
              "Nc6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "e5",
            "Nf3",
            "Nc6"
          ],
          "full_moves": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d6",
            "d4",
            "Bg4",
            "d5",
            "Na5",
            "Bc2",
            "c6",
            "dxc6",
            "Nxc6",
            "Nbd2",
            "d5",
            "h3",
            "Bh5",
            "g4",
            "Bg6",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Nf4",
            "Bxg6",
            "fxg6",
            "Qf3",
            "Nd3",
            "Qd5+",
            "Qxd5",
            "Rxd5",
            "Nxf2",
            "Kg2",
            "Rae8",
            "Nf3",
            "Nxh3",
            "Kxh3",
            "Rxf3",
            "Kg2",
            "Ref8",
            "Rd2",
            "Bh4",
            "Re2",
            "Rg3+",
            "Kh2",
            "Rxg4",
            "Be3",
            "Re4",
            "Kg2",
            "Rfe8",
            "Kf3",
            "Bg5",
            "Rae1",
            "Rxe3",
            "Rxe3",
            "Rxe3",
            "Rxe3",
            "Bxe3",
            "Kxe3",
            "Kf7",
            "b3",
            "Ke6",
            "c4",
            "bxc4",
            "bxc4",
            "Ke5",
            "a4",
            "a5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 443,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1723,
          "total_tokens": 2052
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 443,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bb5",
          "aggressive_uci": "f1b5",
          "aggressive_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Qh5 18. a4 Re6 19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5 22. f3 Bf5 23. Qf1 Rfe8 24. Qf2 h5 25. Nf1 Bd3 26. Raa1 Rf6 27. Nd2 Rfe6 28. Nf1 Rf6 29. Nd2 Rfe6 30. Nf1 Rf6 31. Nd2 Rfe6 32. Nf1 Rf6 33. Nd2 Rfe6 34. Nf1 Rf6 35. Nd2 Rfe6 36. Nf1 Rf6 37. Nd2 Rfe6 38. Nf1 Rf6 39. Nd2 Rfe6 40. Nf1 Rf6 41. Nd2 Rfe6 42. Nf1 Rf6 43. Nd2 Rfe6 44. Nf1 Rf6 45. Nd2 Rfe6 46. Nf1 Rf6 47. Nd2 Rfe6 48. Nf1 Rf6 49. Nd2 Rfe6 50. Nf1 Rf6 51. Nd2 Rfe6 52. Nf1 Rf6 53. Nd2 Rfe6 54. Nf1 Rf6 55. Nd2 Rfe6 56. Nf1 Rf6 57. Nd2 Rfe6 58. Nf1 Rf6 59. Nd2 Rfe6 60. Nf1 Rf6 61. Nd2 Rfe6 62. Nf1 Rf6 63. Nd2 Rfe6 64. Nf1 Rf6 65. Nd2 Rfe6 66. Nf1 Rf6 67. Nd2 Rfe6 68. Nf1 Rf6 69. Nd2 Rfe6 70. Nf1 Rf6 71. Nd2 Rfe6 72. Nf1 Rf6 73. Nd2 Rfe6 74. Nf1 Rf6 75. Nd2 Rfe6 76. Nf1 Rf6 77. Nd2 Rfe6 78. Nf1 Rf6 79. Nd2",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Qh5",
            "a4",
            "Re6",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bxd5",
            "Qxd5",
            "f3",
            "Bf5",
            "Qf1",
            "Rfe8",
            "Qf2",
            "h5",
            "Nf1",
            "Bd3",
            "Raa1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2",
            "Rfe6",
            "Nf1",
            "Rf6",
            "Nd2"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "query2": {
          "positional_move": "Bb5",
          "positional_uci": "f1b5",
          "positional_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bb8 25. Ra8 Rg6 26. Bf4 Rxe1+ 27. Nf1 h6 28. Rxb8+ Kh7 29. Bg3 Bh3 30. Qa8 Rxf1# e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d5 exd5 Nxd5 Nxe5 Nxe5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Re6 Qf1 Qh5 a4 Rfe8 axb5 axb5 Bxd5 Qxd5 Qg2 Qh5 Qxc6 Bxg3 Qg2 Bb8 Bd4 Rg6 Bg3 Bh3 Qa8 Rge6 Rxe6 fxe6 Nf1 Bxg3 Nxg3 Qg6 Qe4 Qf7 Qe5 Rf8 Re2 Ra8 Qxe6 Ra1+ Kg2 Qxe6 Rxe6 Rb1 Re2 Kf7 Ne4 Ke6 Nc5+ Kd5 Nd3 Kc4 Ne5+ Kb3 Nd3+ Kxb2 Nxb4 Kc3 Nd5+ Kd4 Nf6 Re7 g5+ Ke5 Ng4+ Kf5 Nxh2 Rxh7 Nf3 Rh3 g4 Rg3 Kc4 Rxg4+ Kd3 Rg3 Ke5 Rg5+ Kf4 Rg4+ Kf5 Rg5+ Ke6 Rg6+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf7 Rg7+ Kf8 Rg8+ Kf",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bb8",
            "Bd4",
            "Rg6",
            "Bg3",
            "Bh3",
            "Qa8",
            "Rge6",
            "Rxe6",
            "fxe6",
            "Nf1",
            "Bxg3",
            "Nxg3",
            "Qg6",
            "Qe4",
            "Qf7",
            "Qe5",
            "Rf8",
            "Re2",
            "Ra8",
            "Qxe6",
            "Ra1+",
            "Kg2",
            "Qxe6",
            "Rxe6",
            "Rb1",
            "Re2",
            "Kf7",
            "Ne4",
            "Ke6",
            "Nc5+",
            "Kd5",
            "Nd3",
            "Kc4",
            "Ne5+",
            "Kb3",
            "Nd3+",
            "Kxb2",
            "Nxb4",
            "Kc3",
            "Nd5+",
            "Kd4",
            "Nf6",
            "Re7",
            "g5+",
            "Ke5",
            "Ng4+",
            "Kf5",
            "Nxh2",
            "Rxh7",
            "Nf3",
            "Rh3",
            "g4",
            "Rg3",
            "Kc4",
            "Rxg4+",
            "Kd3",
            "Rg3",
            "Ke5",
            "Rg5+",
            "Kf4",
            "Rg4+",
            "Kf5",
            "Rg5+",
            "Ke6",
            "Rg6+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Rg8+"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "query3": {
          "neutral_move": "Bb5",
          "neutral_uci": "f1b5",
          "neutral_response": "3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6 Bc5",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 269,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6",
            "Bc5"
          ],
          "plan_execute": [
            "a6",
            "Ba4",
            "Nf6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1b5",
          "positional_uci": "f1b5",
          "neutral_uci": "f1b5",
          "consensus_move": "f1b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Qh5",
              "a4",
              "Re6",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bxd5",
              "Qxd5",
              "f3",
              "Bf5",
              "Qf1",
              "Rfe8",
              "Qf2",
              "h5",
              "Nf1",
              "Bd3",
              "Raa1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2",
              "Rfe6",
              "Nf1",
              "Rf6",
              "Nd2"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          },
          "positional": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bb8",
              "Bd4",
              "Rg6",
              "Bg3",
              "Bh3",
              "Qa8",
              "Rge6",
              "Rxe6",
              "fxe6",
              "Nf1",
              "Bxg3",
              "Nxg3",
              "Qg6",
              "Qe4",
              "Qf7",
              "Qe5",
              "Rf8",
              "Re2",
              "Ra8",
              "Qxe6",
              "Ra1+",
              "Kg2",
              "Qxe6",
              "Rxe6",
              "Rb1",
              "Re2",
              "Kf7",
              "Ne4",
              "Ke6",
              "Nc5+",
              "Kd5",
              "Nd3",
              "Kc4",
              "Ne5+",
              "Kb3",
              "Nd3+",
              "Kxb2",
              "Nxb4",
              "Kc3",
              "Nd5+",
              "Kd4",
              "Nf6",
              "Re7",
              "g5+",
              "Ke5",
              "Ng4+",
              "Kf5",
              "Nxh2",
              "Rxh7",
              "Nf3",
              "Rh3",
              "g4",
              "Rg3",
              "Kc4",
              "Rxg4+",
              "Kd3",
              "Rg3",
              "Ke5",
              "Rg5+",
              "Kf4",
              "Rg4+",
              "Kf5",
              "Rg5+",
              "Ke6",
              "Rg6+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Rg8+"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          },
          "neutral": {
            "full": [
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6",
              "Bc5"
            ],
            "execute": [
              "a6",
              "Ba4",
              "Nf6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "a6",
            "Ba4",
            "Nf6"
          ],
          "full_moves": [
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6",
            "Bc5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 269,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1549,
          "total_tokens": 1923
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 269,
            "total_tokens": 393,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e1g1",
          "aggressive_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7\n17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7\n29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8 40. Kf1 Kf7\n41. Ke2 Ke6 42. Ke3 Kd6 43. Nd2 Kc5 44. a3 Bd7 45. Nb1 Be6 46. Nc3 Bc4\n47. Bxc4 Kxc4 48. Kd2 Nc6 49. Nd5 Kb3 50. Kc1 Nd4 51. Nxf6 Ne2+ 52. Kb1 Nf4\n53. Nxh7 Nxg2 54. Nf6 Nf4 55. h4 Nd3 56. h5 Nxb2 57. h6 Nc4 58. h7 Nxa3+\n59. Kc1 Nc4 60. h8=Q a3 61. Qh3+ Ka4 62. Nd5 b4 63. Qd3 Nb2 64. Qa6+ Kb3\n65. Qb5 Ka2 66. Nxb4+ Ka1 67. Nc2+ Ka2 68. Qd5+ Nc4 69. Qxc4# Nf6 70. Qb4 Nxe4\n71. Qxa3# Nc3 72. Qb2# Nxb2 73. Nxa3 Nd3+ 74. Kd2 Nxf2 75. Ke3 Ng4+ 76. Ke4 Kxa3\n77. Kf5 Kb4 78. Kxg4 Kc4 79. Kf3 Kd3 80. Kf2 e4 81. Ke",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Be6",
            "Nc3",
            "Bc4",
            "Bxc4",
            "Kxc4",
            "Kd2",
            "Nc6",
            "Nd5",
            "Kb3",
            "Kc1",
            "Nd4",
            "Nxf6",
            "Ne2+",
            "Kb1",
            "Nf4",
            "Nxh7",
            "Nxg2",
            "Nf6",
            "Nf4",
            "h4",
            "Nd3",
            "h5",
            "Nxb2",
            "h6",
            "Nc4",
            "h7",
            "Nxa3+",
            "Kc1",
            "Nc4",
            "h8=Q",
            "a3",
            "Qh3+",
            "Ka4",
            "Nd5",
            "b4",
            "Qd3",
            "Nb2",
            "Qa6+",
            "Kb3",
            "Qb5",
            "Ka2",
            "Nxb4+",
            "Ka1",
            "Nc2+",
            "Ka2",
            "Qd5+",
            "Nc4",
            "Qxc4#",
            "Nf6",
            "Qb4",
            "Nxe4",
            "Qxa3#",
            "Nc3",
            "Qb2#",
            "Nxb2",
            "Nxa3",
            "Nd3+",
            "Kd2",
            "Nxf2",
            "Ke3",
            "Ng4+",
            "Ke4",
            "Kxa3",
            "Kf5",
            "Kb4",
            "Kxg4",
            "Kc4",
            "Kf3",
            "Kd3",
            "Kf2",
            "e4"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e1g1",
          "positional_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Nb4 17. Bb1 Bd7 18. a3 Nc6 19. Bd3 Qb7 20. Rc1 Rfc8 21. Qe2 Rab8 22. d5 Na5 23. Nh2 Bd8 24. f4 Bb6 25. fxe5 dxe5 26. Nhf3 Bxe3+ 27. Qxe3 Re8 28. Rc5 Qb6 29. Rec1 Nb7 30. R5c3 Qxe3+ 31. Kh1 Qb6 32. Rc7 Rbc8 33. Rxc8 Rxc8 34. Rxc8+ Bxc8 35. Nxe5 Qd4 36. Ndf3 Qxb2 37. Nc6 Kf8 38. Na7 Bd7 39. Nc6 Bxc6 40. dxc6 Nd6 41. e5 Qc1+ 42. Kh2 Qxc6 43. exd6 Qxd6+ 44. Kh1 Qxd3 45. Ne5 Qxa3 46. Nc6 Qc1+ 47. Kh2 Qxc6 48. Kg3 a3 49. Kf4 a2 50. Ke5 a1=Q+ 51. Kf4 Qd4+ 52. Kg3 Qcc3+ 53. Kh2 Qf4+ 54. Kg1 Qe1# e4 Nc6 d4 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 N",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Nb4",
            "Bb1",
            "Bd7",
            "a3",
            "Nc6",
            "Bd3",
            "Qb7",
            "Rc1",
            "Rfc8",
            "Qe2",
            "Rab8",
            "d5",
            "Na5",
            "Nh2",
            "Bd8",
            "f4",
            "Bb6",
            "fxe5",
            "dxe5",
            "Nhf3",
            "Bxe3+",
            "Qxe3",
            "Re8",
            "Rc5",
            "Qb6",
            "Rec1",
            "Nb7",
            "R5c3",
            "Qxe3+",
            "Kh1",
            "Qb6",
            "Rc7",
            "Rbc8",
            "Rxc8",
            "Rxc8",
            "Rxc8+",
            "Bxc8",
            "Nxe5",
            "Qd4",
            "Ndf3",
            "Qxb2",
            "Nc6",
            "Kf8",
            "Na7",
            "Bd7",
            "Nc6",
            "Bxc6",
            "dxc6",
            "Nd6",
            "e5",
            "Qc1+",
            "Kh2",
            "Qxc6",
            "exd6",
            "Qxd6+",
            "Kh1",
            "Qxd3",
            "Ne5",
            "Qxa3",
            "Nc6",
            "Qc1+",
            "Kh2",
            "Qxc6",
            "Kg3",
            "a3",
            "Kf4",
            "a2",
            "Ke5",
            "a1=Q+",
            "Kf4",
            "Qd4+",
            "Kg3",
            "Qcc3+",
            "Kh2",
            "Qf4+",
            "Kg1",
            "Qe1#",
            "e4",
            "Nc6",
            "d4",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5",
            "Nxe5"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e1g1",
          "neutral_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. d5 Ne7 25. Nh4 Rac8 26. Bg5 Kh8 27. Bxf6 gxf6 28. Qf3 Ng8 29. Nhf5 Qc7 30. Qg4 Bxf5 31. Nxf5 *\n31... Qc1 32. Qg7#",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 227,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qf3",
            "Ng8",
            "Nhf5",
            "Qc7",
            "Qg4",
            "Bxf5",
            "Nxf5",
            "Qc1",
            "Qg7#"
          ],
          "plan_execute": [
            "h3",
            "Na5",
            "Bc2"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e1g1",
          "positional_uci": "e1g1",
          "neutral_uci": "e1g1",
          "consensus_move": "e1g1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Bd7",
              "Nb1",
              "Be6",
              "Nc3",
              "Bc4",
              "Bxc4",
              "Kxc4",
              "Kd2",
              "Nc6",
              "Nd5",
              "Kb3",
              "Kc1",
              "Nd4",
              "Nxf6",
              "Ne2+",
              "Kb1",
              "Nf4",
              "Nxh7",
              "Nxg2",
              "Nf6",
              "Nf4",
              "h4",
              "Nd3",
              "h5",
              "Nxb2",
              "h6",
              "Nc4",
              "h7",
              "Nxa3+",
              "Kc1",
              "Nc4",
              "h8=Q",
              "a3",
              "Qh3+",
              "Ka4",
              "Nd5",
              "b4",
              "Qd3",
              "Nb2",
              "Qa6+",
              "Kb3",
              "Qb5",
              "Ka2",
              "Nxb4+",
              "Ka1",
              "Nc2+",
              "Ka2",
              "Qd5+",
              "Nc4",
              "Qxc4#",
              "Nf6",
              "Qb4",
              "Nxe4",
              "Qxa3#",
              "Nc3",
              "Qb2#",
              "Nxb2",
              "Nxa3",
              "Nd3+",
              "Kd2",
              "Nxf2",
              "Ke3",
              "Ng4+",
              "Ke4",
              "Kxa3",
              "Kf5",
              "Kb4",
              "Kxg4",
              "Kc4",
              "Kf3",
              "Kd3",
              "Kf2",
              "e4"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          },
          "positional": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Nb4",
              "Bb1",
              "Bd7",
              "a3",
              "Nc6",
              "Bd3",
              "Qb7",
              "Rc1",
              "Rfc8",
              "Qe2",
              "Rab8",
              "d5",
              "Na5",
              "Nh2",
              "Bd8",
              "f4",
              "Bb6",
              "fxe5",
              "dxe5",
              "Nhf3",
              "Bxe3+",
              "Qxe3",
              "Re8",
              "Rc5",
              "Qb6",
              "Rec1",
              "Nb7",
              "R5c3",
              "Qxe3+",
              "Kh1",
              "Qb6",
              "Rc7",
              "Rbc8",
              "Rxc8",
              "Rxc8",
              "Rxc8+",
              "Bxc8",
              "Nxe5",
              "Qd4",
              "Ndf3",
              "Qxb2",
              "Nc6",
              "Kf8",
              "Na7",
              "Bd7",
              "Nc6",
              "Bxc6",
              "dxc6",
              "Nd6",
              "e5",
              "Qc1+",
              "Kh2",
              "Qxc6",
              "exd6",
              "Qxd6+",
              "Kh1",
              "Qxd3",
              "Ne5",
              "Qxa3",
              "Nc6",
              "Qc1+",
              "Kh2",
              "Qxc6",
              "Kg3",
              "a3",
              "Kf4",
              "a2",
              "Ke5",
              "a1=Q+",
              "Kf4",
              "Qd4+",
              "Kg3",
              "Qcc3+",
              "Kh2",
              "Qf4+",
              "Kg1",
              "Qe1#",
              "e4",
              "Nc6",
              "d4",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5",
              "Nxe5"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          },
          "neutral": {
            "full": [
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "d5",
              "Ne7",
              "Nh4",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qf3",
              "Ng8",
              "Nhf5",
              "Qc7",
              "Qg4",
              "Bxf5",
              "Nxf5",
              "Qc1",
              "Qg7#"
            ],
            "execute": [
              "h3",
              "Na5",
              "Bc2"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "h3",
            "Na5",
            "Bc2"
          ],
          "full_moves": [
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qf3",
            "Ng8",
            "Nhf5",
            "Qc7",
            "Qg4",
            "Bxf5",
            "Nxf5",
            "Qc1",
            "Qg7#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 227,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 1507,
          "total_tokens": 1929
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 640,
            "total_tokens": 781,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 227,
            "total_tokens": 367,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re1",
          "aggressive_uci": "f1e1",
          "aggressive_response": "6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ Bc7 Bb6+ Bc7",
          "aggressive_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 247,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Bc7",
            "Bb6+",
            "Bc7"
          ],
          "plan_execute": [
            "Qh4",
            "g3",
            "Qh3"
          ]
        },
        "query2": {
          "positional_move": "Re1",
          "positional_uci": "f1e1",
          "positional_response": "6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Nf1 Rfc8 19. Ng3 g6 20. Qd2 Bd8 21. Red1 Ba5 22. Qe2 Bb6 23. dxe5 dxe5 24. Bxb6 Qxb6 25. Rd6 Kg7 26. Qd2 Be8 27. Nf5+ gxf5 28. Qg5+ Kf8 29. Qxf6 Kg8 30. Qg5+ Kf8 31. Qh6+ Kg8 32. Ng5 Qc7 33. Nxh7 f6 34. Nxf6+ Kf7 35. Qh7+ Kf8 36. Qg8+ Ke7 37. Re6+ Kd8 38. Qxe8# e5 Nc6 Nxd4",
          "positional_tokens": {
            "prompt_tokens": 148,
            "completion_tokens": 282,
            "total_tokens": 430,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Nf1",
            "Rfc8",
            "Ng3",
            "g6",
            "Qd2",
            "Bd8",
            "Red1",
            "Ba5",
            "Qe2",
            "Bb6",
            "dxe5",
            "dxe5",
            "Bxb6",
            "Qxb6",
            "Rd6",
            "Kg7",
            "Qd2",
            "Be8",
            "Nf5+",
            "gxf5",
            "Qg5+",
            "Kf8",
            "Qxf6",
            "Kg8",
            "Qg5+",
            "Kf8",
            "Qh6+",
            "Kg8",
            "Ng5",
            "Qc7",
            "Nxh7",
            "f6",
            "Nxf6+",
            "Kf7",
            "Qh7+",
            "Kf8",
            "Qg8+",
            "Ke7",
            "Re6+",
            "Kd8",
            "Qxe8#",
            "e5",
            "Nc6",
            "Nxd4"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "d6"
          ]
        },
        "query3": {
          "neutral_move": "Re1",
          "neutral_uci": "f1e1",
          "neutral_response": "6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. d5 Ne7 25. Nh4 Rac8 26. Bg5 Kh8 27. Bxf6 gxf6 28. Qf3 Ng8 29. Nhf5 Qb6 30. Qg4 Bxf5 31. Nxf5 * Be2 32. Qg7#",
          "neutral_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 216,
            "total_tokens": 363,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qf3",
            "Ng8",
            "Nhf5",
            "Qb6",
            "Qg4",
            "Bxf5",
            "Nxf5",
            "Be2",
            "Qg7#"
          ],
          "plan_execute": [
            "b5",
            "Bb3",
            "d6"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f1e1",
          "positional_uci": "f1e1",
          "neutral_uci": "f1e1",
          "consensus_move": "f1e1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Bc7",
              "Bb6+",
              "Bc7"
            ],
            "execute": [
              "Qh4",
              "g3",
              "Qh3"
            ]
          },
          "positional": {
            "full": [
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Nf1",
              "Rfc8",
              "Ng3",
              "g6",
              "Qd2",
              "Bd8",
              "Red1",
              "Ba5",
              "Qe2",
              "Bb6",
              "dxe5",
              "dxe5",
              "Bxb6",
              "Qxb6",
              "Rd6",
              "Kg7",
              "Qd2",
              "Be8",
              "Nf5+",
              "gxf5",
              "Qg5+",
              "Kf8",
              "Qxf6",
              "Kg8",
              "Qg5+",
              "Kf8",
              "Qh6+",
              "Kg8",
              "Ng5",
              "Qc7",
              "Nxh7",
              "f6",
              "Nxf6+",
              "Kf7",
              "Qh7+",
              "Kf8",
              "Qg8+",
              "Ke7",
              "Re6+",
              "Kd8",
              "Qxe8#",
              "e5",
              "Nc6",
              "Nxd4"
            ],
            "execute": [
              "b5",
              "Bb3",
              "d6"
            ]
          },
          "neutral": {
            "full": [
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "d5",
              "Ne7",
              "Nh4",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qf3",
              "Ng8",
              "Nhf5",
              "Qb6",
              "Qg4",
              "Bxf5",
              "Nxf5",
              "Be2",
              "Qg7#"
            ],
            "execute": [
              "b5",
              "Bb3",
              "d6"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "b5",
            "Bb3",
            "d6"
          ],
          "full_moves": [
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "d5",
            "Ne7",
            "Nh4",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qf3",
            "Ng8",
            "Nhf5",
            "Qb6",
            "Qg4",
            "Bxf5",
            "Nxf5",
            "Be2",
            "Qg7#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 148,
            "completion_tokens": 247,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 148,
            "completion_tokens": 282,
            "total_tokens": 430,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 147,
            "completion_tokens": 216,
            "total_tokens": 363,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 443,
          "total_completion_tokens": 745,
          "total_tokens": 1188
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 148,
            "completion_tokens": 247,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 148,
            "completion_tokens": 282,
            "total_tokens": 430,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 147,
            "completion_tokens": 216,
            "total_tokens": 363,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/1pppbppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 w kq - 4 6"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c3",
          "aggressive_uci": "c2c3",
          "aggressive_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rad8 25. Bg5 exd4 26. Bxf6 gxf6 27. Qh6 Ne7 28. Nh5 Nf5 29. Nxf6+ Kh8 30. Qxh7# e4 Nxe4 Qe7 Qe6",
          "aggressive_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 198,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rad8",
            "Bg5",
            "exd4",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Ne7",
            "Nh5",
            "Nf5",
            "Nxf6+",
            "Kh8",
            "Qxh7#",
            "e4",
            "Nxe4",
            "Qe7",
            "Qe6"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "query2": {
          "positional_move": "c3",
          "positional_uci": "c2c3",
          "positional_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6 43. Nd2 Kc5 44. a3 Ng6 45. g3 Bd7 46. h4 Nf8 47. Nb1 Ne6 48. Nc3 Nd4 49. Nd5 f5 50. Nf6 fxe4 51. Nxd7+ Kd6 52. Bxe4 Kxd7 53. Bxh7 Ke6 54. Bd3 Kf6 55. f4 Ne6 56. Bxb5 exf4+ 57. gxf4 Nc5 58. Kd4 Ne6+ 59. Ke3 Nc5 60. Bd3 Ke6 61. h5 Kf6 62. h6 Ne6 63. Bc2 Nc5 64. Kd4 Ne6+ 65. Kc4 Nxf4 66. Bxa4 Kg6 67. Bc6 Kxh6 68. a4 Kg6 69. a5 Kf6 70. a6 Ne6 71. a7 Nc7 72. a8=Q Nxa8 73. Bxa8 Ke7 74. Kc5 Kd7 75. Kb6 Kc8 76. b4 Kb8 77. Bc6 Kc8 78. b5 Kb8 79. Bd5 Kc8 80. Ka7 Kc7 81. b6+ Kd6 82. b7 Kxd5 83. b8=Q Kc6 84. Qb4 Kd5 85. Kb",
          "positional_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Ng6",
            "g3",
            "Bd7",
            "h4",
            "Nf8",
            "Nb1",
            "Ne6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "fxe4",
            "Nxd7+",
            "Kd6",
            "Bxe4",
            "Kxd7",
            "Bxh7",
            "Ke6",
            "Bd3",
            "Kf6",
            "f4",
            "Ne6",
            "Bxb5",
            "exf4+",
            "gxf4",
            "Nc5",
            "Kd4",
            "Ne6+",
            "Ke3",
            "Nc5",
            "Bd3",
            "Ke6",
            "h5",
            "Kf6",
            "h6",
            "Ne6",
            "Bc2",
            "Nc5",
            "Kd4",
            "Ne6+",
            "Kc4",
            "Nxf4",
            "Bxa4",
            "Kg6",
            "Bc6",
            "Kxh6",
            "a4",
            "Kg6",
            "a5",
            "Kf6",
            "a6",
            "Ne6",
            "a7",
            "Nc7",
            "a8=Q",
            "Nxa8",
            "Bxa8",
            "Ke7",
            "Kc5",
            "Kd7",
            "Kb6",
            "Kc8",
            "b4",
            "Kb8",
            "Bc6",
            "Kc8",
            "b5",
            "Kb8",
            "Bd5",
            "Kc8",
            "Ka7",
            "Kc7",
            "b6+",
            "Kd6",
            "b7",
            "Kxd5",
            "b8=Q",
            "Kc6",
            "Qb4",
            "Kd5"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "query3": {
          "neutral_move": "c3",
          "neutral_uci": "c2c3",
          "neutral_response": "8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8 31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6 43. Nd2 Kc5 44. a3 Ng6 45. g3 Bd7 46. h4 Nf8 47. Nb1 Ne6 48. Nc3 Nd4 49. Nd5 f5 50. Nf6 fxe4 51. Nxe4+ Kd5 52. Nf6+ Ke6 53. Nxd7 Kxd7 54. Bxh7 Ke6 55. Bd3 Kf6 56. f4 Nf5+ 57. Bxf5 Kxf5 58. fxe5 Kxe5 59. g4 Kf6 60. Kd4 Ke6 61. Kc5 Ke5 62. Kxb5 Kf4 63. g5 Kf5 64. Kxa4 Kg6 65. Kb5 Kh5 66. a4 Kg6 67. a5 Kh5 68. a6 Kg6 69. a7 Kh5 70. a8=Q Kg6 71. Qe4+ Kh5 72. Qf3+ Kg6 73. Qg4 Kg7 74. h5 Kh7 75. Qd7+ Kg8 76. g6 Kh8 77. Qh7# e4 d5 e5 dxe6",
          "neutral_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 580,
            "total_tokens": 742,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Ng6",
            "g3",
            "Bd7",
            "h4",
            "Nf8",
            "Nb1",
            "Ne6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "fxe4",
            "Nxe4+",
            "Kd5",
            "Nf6+",
            "Ke6",
            "Nxd7",
            "Kxd7",
            "Bxh7",
            "Ke6",
            "Bd3",
            "Kf6",
            "f4",
            "Nf5+",
            "Bxf5",
            "Kxf5",
            "fxe5",
            "Kxe5",
            "g4",
            "Kf6",
            "Kd4",
            "Ke6",
            "Kc5",
            "Ke5",
            "Kxb5",
            "Kf4",
            "g5",
            "Kf5",
            "Kxa4",
            "Kg6",
            "Kb5",
            "Kh5",
            "a4",
            "Kg6",
            "a5",
            "Kh5",
            "a6",
            "Kg6",
            "a7",
            "Kh5",
            "a8=Q",
            "Kg6",
            "Qe4+",
            "Kh5",
            "Qf3+",
            "Kg6",
            "Qg4",
            "Kg7",
            "h5",
            "Kh7",
            "Qd7+",
            "Kg8",
            "g6",
            "Kh8",
            "Qh7#",
            "e4",
            "d5",
            "e5",
            "dxe6"
          ],
          "plan_execute": [
            "O-O",
            "h3",
            "Na5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c2c3",
          "positional_uci": "c2c3",
          "neutral_uci": "c2c3",
          "consensus_move": "c2c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rad8",
              "Bg5",
              "exd4",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Ne7",
              "Nh5",
              "Nf5",
              "Nxf6+",
              "Kh8",
              "Qxh7#",
              "e4",
              "Nxe4",
              "Qe7",
              "Qe6"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Ng6",
              "g3",
              "Bd7",
              "h4",
              "Nf8",
              "Nb1",
              "Ne6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "fxe4",
              "Nxd7+",
              "Kd6",
              "Bxe4",
              "Kxd7",
              "Bxh7",
              "Ke6",
              "Bd3",
              "Kf6",
              "f4",
              "Ne6",
              "Bxb5",
              "exf4+",
              "gxf4",
              "Nc5",
              "Kd4",
              "Ne6+",
              "Ke3",
              "Nc5",
              "Bd3",
              "Ke6",
              "h5",
              "Kf6",
              "h6",
              "Ne6",
              "Bc2",
              "Nc5",
              "Kd4",
              "Ne6+",
              "Kc4",
              "Nxf4",
              "Bxa4",
              "Kg6",
              "Bc6",
              "Kxh6",
              "a4",
              "Kg6",
              "a5",
              "Kf6",
              "a6",
              "Ne6",
              "a7",
              "Nc7",
              "a8=Q",
              "Nxa8",
              "Bxa8",
              "Ke7",
              "Kc5",
              "Kd7",
              "Kb6",
              "Kc8",
              "b4",
              "Kb8",
              "Bc6",
              "Kc8",
              "b5",
              "Kb8",
              "Bd5",
              "Kc8",
              "Ka7",
              "Kc7",
              "b6+",
              "Kd6",
              "b7",
              "Kxd5",
              "b8=Q",
              "Kc6",
              "Qb4",
              "Kd5"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Ng6",
              "g3",
              "Bd7",
              "h4",
              "Nf8",
              "Nb1",
              "Ne6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "fxe4",
              "Nxe4+",
              "Kd5",
              "Nf6+",
              "Ke6",
              "Nxd7",
              "Kxd7",
              "Bxh7",
              "Ke6",
              "Bd3",
              "Kf6",
              "f4",
              "Nf5+",
              "Bxf5",
              "Kxf5",
              "fxe5",
              "Kxe5",
              "g4",
              "Kf6",
              "Kd4",
              "Ke6",
              "Kc5",
              "Ke5",
              "Kxb5",
              "Kf4",
              "g5",
              "Kf5",
              "Kxa4",
              "Kg6",
              "Kb5",
              "Kh5",
              "a4",
              "Kg6",
              "a5",
              "Kh5",
              "a6",
              "Kg6",
              "a7",
              "Kh5",
              "a8=Q",
              "Kg6",
              "Qe4+",
              "Kh5",
              "Qf3+",
              "Kg6",
              "Qg4",
              "Kg7",
              "h5",
              "Kh7",
              "Qd7+",
              "Kg8",
              "g6",
              "Kh8",
              "Qh7#",
              "e4",
              "d5",
              "e5",
              "dxe6"
            ],
            "execute": [
              "O-O",
              "h3",
              "Na5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "h3",
            "Na5"
          ],
          "full_moves": [
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Ng6",
            "g3",
            "Bd7",
            "h4",
            "Nf8",
            "Nb1",
            "Ne6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "fxe4",
            "Nxe4+",
            "Kd5",
            "Nf6+",
            "Ke6",
            "Nxd7",
            "Kxd7",
            "Bxh7",
            "Ke6",
            "Bd3",
            "Kf6",
            "f4",
            "Nf5+",
            "Bxf5",
            "Kxf5",
            "fxe5",
            "Kxe5",
            "g4",
            "Kf6",
            "Kd4",
            "Ke6",
            "Kc5",
            "Ke5",
            "Kxb5",
            "Kf4",
            "g5",
            "Kf5",
            "Kxa4",
            "Kg6",
            "Kb5",
            "Kh5",
            "a4",
            "Kg6",
            "a5",
            "Kh5",
            "a6",
            "Kg6",
            "a7",
            "Kh5",
            "a8=Q",
            "Kg6",
            "Qe4+",
            "Kh5",
            "Qf3+",
            "Kg6",
            "Qg4",
            "Kg7",
            "h5",
            "Kh7",
            "Qd7+",
            "Kg8",
            "g6",
            "Kh8",
            "Qh7#",
            "e4",
            "d5",
            "e5",
            "dxe6"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 163,
            "completion_tokens": 198,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 162,
            "completion_tokens": 580,
            "total_tokens": 742,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 488,
          "total_completion_tokens": 1418,
          "total_tokens": 1906
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 163,
            "completion_tokens": 198,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 163,
            "completion_tokens": 640,
            "total_tokens": 803,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 162,
            "completion_tokens": 580,
            "total_tokens": 742,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p1np1n2/1p2p3/4P3/1B3N2/PPPP1PPP/RNBQR1K1 w kq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc2",
          "aggressive_uci": "b3c2",
          "aggressive_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. Ng3 g6 16. b3 Nb6 17. Bh6 Rfe8 18. Qd2 Bf8 19. Bxf8 Rxf8 20. Qh6 Kh8 21. Ng5 Be8 22. Re3 Rg8 23. Rf3 Qe7 24. Rxf6 Rg7 25. Nh5 gxh5 26. Nxh7 Rxh7 27. Qg5 Nd7 28. Rf5 Qxg5 29. Rxg5 f6 30. Rg3 Rg7 31. Rf3 Bg6 32. Re1 Rf8 33. Kh2 Bh7 34. Rfe3 f5 35. f3 f4 36. R3e2 Rfg8 37. Rf2 Nf6 38. Ree2 h4 39. Rd2 Nh5 40. Bd3 Ng3 41. Rc2 Rb8 42. Rb2 Rgb7 43. Rbc2 Bg6 44. Rb2 Be8 45. Rbc2 a5 46. Rb2 a4 47. Rbc2 axb3 48. axb3 Ra7 49. Rb2 Ra1 50. Rb1 Rba8 51. Rfb2 Rxb1 52. Rxb1 Ra2 53. Kg1 Kg7 54. Kh2 Kf6 55. Kg1 Ke7 56. Kh2 Kd8 57. Kg1 Kc7 58. Kh2 Kb6 59. Kg1 Ka5 60. Kh2 Kb6 61. Kg1 Bd7 62. Kh2 Bc8 63. Kg1 Ba6 64. Kh2 Ka5 65. Kg1 Kb6 66. Kh2 b4 67. c4 Rd2 68. Bf1 Nxf1+ 69. Rxf1 Rb2 70. Ra1 Rxb3 71. Ra2 Ra3 72. Rb2 Bxc4 73. Kg1 Ra1+ 74. Kh2 Ra2 75. Rb1 b3 76. Kg1 b2 77. Kh2 Bd3 78. Rd1 b1=Q 79. Rxb1+ Bxb1 80. Kg1 Bd3 81. Kh2 Bf1 82. Kg1 Bxg2 83. Kh2 Bxf3+ 84. Kg1 Bxe4 85. Kf1 Bxd5 86. Ke1 Bg2 87. Kd1 Bxh3 88.",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "Ng3",
            "g6",
            "b3",
            "Nb6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "Re3",
            "Rg8",
            "Rf3",
            "Qe7",
            "Rxf6",
            "Rg7",
            "Nh5",
            "gxh5",
            "Nxh7",
            "Rxh7",
            "Qg5",
            "Nd7",
            "Rf5",
            "Qxg5",
            "Rxg5",
            "f6",
            "Rg3",
            "Rg7",
            "Rf3",
            "Bg6",
            "Re1",
            "Rf8",
            "Kh2",
            "Bh7",
            "Rfe3",
            "f5",
            "f3",
            "f4",
            "R3e2",
            "Rfg8",
            "Rf2",
            "Nf6",
            "Ree2",
            "h4",
            "Rd2",
            "Nh5",
            "Bd3",
            "Ng3",
            "Rc2",
            "Rb8",
            "Rb2",
            "Rgb7",
            "Rbc2",
            "Bg6",
            "Rb2",
            "Be8",
            "Rbc2",
            "a5",
            "Rb2",
            "a4",
            "Rbc2",
            "axb3",
            "axb3",
            "Ra7",
            "Rb2",
            "Ra1",
            "Rb1",
            "Rba8",
            "Rfb2",
            "Rxb1",
            "Rxb1",
            "Ra2",
            "Kg1",
            "Kg7",
            "Kh2",
            "Kf6",
            "Kg1",
            "Ke7",
            "Kh2",
            "Kd8",
            "Kg1",
            "Kc7",
            "Kh2",
            "Kb6",
            "Kg1",
            "Ka5",
            "Kh2",
            "Kb6",
            "Kg1",
            "Bd7",
            "Kh2",
            "Bc8",
            "Kg1",
            "Ba6",
            "Kh2",
            "Ka5",
            "Kg1",
            "Kb6",
            "Kh2",
            "b4",
            "c4",
            "Rd2",
            "Bf1",
            "Nxf1+",
            "Rxf1",
            "Rb2",
            "Ra1",
            "Rxb3",
            "Ra2",
            "Ra3",
            "Rb2",
            "Bxc4",
            "Kg1",
            "Ra1+",
            "Kh2",
            "Ra2",
            "Rb1",
            "b3",
            "Kg1",
            "b2",
            "Kh2",
            "Bd3",
            "Rd1",
            "b1=Q",
            "Rxb1+",
            "Bxb1",
            "Kg1",
            "Bd3",
            "Kh2",
            "Bf1",
            "Kg1",
            "Bxg2",
            "Kh2",
            "Bxf3+",
            "Kg1",
            "Bxe4",
            "Kf1",
            "Bxd5",
            "Ke1",
            "Bg2",
            "Kd1",
            "Bxh3"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "query2": {
          "positional_move": "Bc2",
          "positional_uci": "b3c2",
          "positional_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. b3 Nb6 16. Ng3 g6 17. Bh6 Rfe8 18. Qd2 c4 19. b4 a5 20. a3 Ra7 21. Nh2 Rea8 22. Rac1 axb4 23. axb4 Ra2 24. f4 exf4 25. Qxf4 Be8 26. Rf1 Nbd7 27. Nf5 Ne5 28. Nxe7+ Qxe7 29. Qxf6 Qxf6 30. Rxf6 R8a6 31. Nf3 Nd7 32. Rf4 f6 33. Nd4 g5 34. Rf2 Rb6 35. h4 gxh4 36. Rcf1 Bg6 37. Bb1 Ra3 38. Rf3 Bh5 39. Rh3 Bg4 40. Rxh4 Ne5 41. Rxf6 Rb8 42. Nxb5 Ra1 43. Kh2 Rxb1 44. Nxd6 Bd7 45. Rhf4 Ng6 46. Rf7 Ba4 47. Rg7+ Kh8 48. Nf7# d3 Nf6+ Kh8 Nf7# d3 Nf6+ Kh8 Nf7# d3 Nf6+ Kh8 Nf7# d3 Nf6+ Kh8 Nf7#",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 372,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "c4",
            "b4",
            "a5",
            "a3",
            "Ra7",
            "Nh2",
            "Rea8",
            "Rac1",
            "axb4",
            "axb4",
            "Ra2",
            "f4",
            "exf4",
            "Qxf4",
            "Be8",
            "Rf1",
            "Nbd7",
            "Nf5",
            "Ne5",
            "Nxe7+",
            "Qxe7",
            "Qxf6",
            "Qxf6",
            "Rxf6",
            "R8a6",
            "Nf3",
            "Nd7",
            "Rf4",
            "f6",
            "Nd4",
            "g5",
            "Rf2",
            "Rb6",
            "h4",
            "gxh4",
            "Rcf1",
            "Bg6",
            "Bb1",
            "Ra3",
            "Rf3",
            "Bh5",
            "Rh3",
            "Bg4",
            "Rxh4",
            "Ne5",
            "Rxf6",
            "Rb8",
            "Nxb5",
            "Ra1",
            "Kh2",
            "Rxb1",
            "Nxd6",
            "Bd7",
            "Rhf4",
            "Ng6",
            "Rf7",
            "Ba4",
            "Rg7+",
            "Kh8",
            "Nf7#",
            "d3",
            "Nf6+",
            "Kh8",
            "Nf7#",
            "d3",
            "Nf6+",
            "Kh8",
            "Nf7#",
            "d3",
            "Nf6+",
            "Kh8",
            "Nf7#",
            "d3",
            "Nf6+",
            "Kh8",
            "Nf7#"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "query3": {
          "neutral_move": "Bc2",
          "neutral_uci": "b3c2",
          "neutral_response": "9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. b3 Nb6 16. Ng3 g6 17. Bh6 Rfe8 18. Qd2 Bf8 19. Bxf8 Rxf8 20. Qh6 Kh8 21. Ng5 Be8 22. f4 Rg8 23. fxe5 dxe5 24. Rf1 Qd6 25. Rxf6 Qxf6 26. Qxh7# 1-0\n\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3\nNa5 9. Bc2 c5 10. d4 Qc7 11. Nbd2 O-O 12. Nf1 Bg4 13. d5 Nc4 14. h3 Bd7 15. b3 Nb6 16. Ng3 g6 17. Bh6 Rfe8 18. Qd2 Bf8 19. Bxf8 Rxf8 20. Qh6 Kh8 21. Ng5 Be8 22. f4 Rg8 23. fxe5 dxe5 24. Rf1 Qd6 25. Rxf6 Qxf6 26. Qxh7# 1-0 1-0 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 d6 c3 Na5 Bc2 c5 d4 Qc7 Nbd2 O-O Nf1 Bg4 d5 Nc4 h3 Bd7 b3 Nb6 Ng3 g6 Bh6 Rfe8 Qd2 Bf8 Bxf8 Rxf8 Qh6 Kh8 Ng5 Be8 f4 Rg8 fxe5 dxe5 Rf1 Qd6 Rxf6 Qxf6 Qxh7#",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 493,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "f4",
            "Rg8",
            "fxe5",
            "dxe5",
            "Rf1",
            "Qd6",
            "Rxf6",
            "Qxf6",
            "Qxh7#"
          ],
          "plan_execute": [
            "c5",
            "d4",
            "Qc7"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b3c2",
          "positional_uci": "b3c2",
          "neutral_uci": "b3c2",
          "consensus_move": "b3c2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "Ng3",
              "g6",
              "b3",
              "Nb6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "Bf8",
              "Bxf8",
              "Rxf8",
              "Qh6",
              "Kh8",
              "Ng5",
              "Be8",
              "Re3",
              "Rg8",
              "Rf3",
              "Qe7",
              "Rxf6",
              "Rg7",
              "Nh5",
              "gxh5",
              "Nxh7",
              "Rxh7",
              "Qg5",
              "Nd7",
              "Rf5",
              "Qxg5",
              "Rxg5",
              "f6",
              "Rg3",
              "Rg7",
              "Rf3",
              "Bg6",
              "Re1",
              "Rf8",
              "Kh2",
              "Bh7",
              "Rfe3",
              "f5",
              "f3",
              "f4",
              "R3e2",
              "Rfg8",
              "Rf2",
              "Nf6",
              "Ree2",
              "h4",
              "Rd2",
              "Nh5",
              "Bd3",
              "Ng3",
              "Rc2",
              "Rb8",
              "Rb2",
              "Rgb7",
              "Rbc2",
              "Bg6",
              "Rb2",
              "Be8",
              "Rbc2",
              "a5",
              "Rb2",
              "a4",
              "Rbc2",
              "axb3",
              "axb3",
              "Ra7",
              "Rb2",
              "Ra1",
              "Rb1",
              "Rba8",
              "Rfb2",
              "Rxb1",
              "Rxb1",
              "Ra2",
              "Kg1",
              "Kg7",
              "Kh2",
              "Kf6",
              "Kg1",
              "Ke7",
              "Kh2",
              "Kd8",
              "Kg1",
              "Kc7",
              "Kh2",
              "Kb6",
              "Kg1",
              "Ka5",
              "Kh2",
              "Kb6",
              "Kg1",
              "Bd7",
              "Kh2",
              "Bc8",
              "Kg1",
              "Ba6",
              "Kh2",
              "Ka5",
              "Kg1",
              "Kb6",
              "Kh2",
              "b4",
              "c4",
              "Rd2",
              "Bf1",
              "Nxf1+",
              "Rxf1",
              "Rb2",
              "Ra1",
              "Rxb3",
              "Ra2",
              "Ra3",
              "Rb2",
              "Bxc4",
              "Kg1",
              "Ra1+",
              "Kh2",
              "Ra2",
              "Rb1",
              "b3",
              "Kg1",
              "b2",
              "Kh2",
              "Bd3",
              "Rd1",
              "b1=Q",
              "Rxb1+",
              "Bxb1",
              "Kg1",
              "Bd3",
              "Kh2",
              "Bf1",
              "Kg1",
              "Bxg2",
              "Kh2",
              "Bxf3+",
              "Kg1",
              "Bxe4",
              "Kf1",
              "Bxd5",
              "Ke1",
              "Bg2",
              "Kd1",
              "Bxh3"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          },
          "positional": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "b3",
              "Nb6",
              "Ng3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "c4",
              "b4",
              "a5",
              "a3",
              "Ra7",
              "Nh2",
              "Rea8",
              "Rac1",
              "axb4",
              "axb4",
              "Ra2",
              "f4",
              "exf4",
              "Qxf4",
              "Be8",
              "Rf1",
              "Nbd7",
              "Nf5",
              "Ne5",
              "Nxe7+",
              "Qxe7",
              "Qxf6",
              "Qxf6",
              "Rxf6",
              "R8a6",
              "Nf3",
              "Nd7",
              "Rf4",
              "f6",
              "Nd4",
              "g5",
              "Rf2",
              "Rb6",
              "h4",
              "gxh4",
              "Rcf1",
              "Bg6",
              "Bb1",
              "Ra3",
              "Rf3",
              "Bh5",
              "Rh3",
              "Bg4",
              "Rxh4",
              "Ne5",
              "Rxf6",
              "Rb8",
              "Nxb5",
              "Ra1",
              "Kh2",
              "Rxb1",
              "Nxd6",
              "Bd7",
              "Rhf4",
              "Ng6",
              "Rf7",
              "Ba4",
              "Rg7+",
              "Kh8",
              "Nf7#",
              "d3",
              "Nf6+",
              "Kh8",
              "Nf7#",
              "d3",
              "Nf6+",
              "Kh8",
              "Nf7#",
              "d3",
              "Nf6+",
              "Kh8",
              "Nf7#",
              "d3",
              "Nf6+",
              "Kh8",
              "Nf7#"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          },
          "neutral": {
            "full": [
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "d5",
              "Nc4",
              "h3",
              "Bd7",
              "b3",
              "Nb6",
              "Ng3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qd2",
              "Bf8",
              "Bxf8",
              "Rxf8",
              "Qh6",
              "Kh8",
              "Ng5",
              "Be8",
              "f4",
              "Rg8",
              "fxe5",
              "dxe5",
              "Rf1",
              "Qd6",
              "Rxf6",
              "Qxf6",
              "Qxh7#"
            ],
            "execute": [
              "c5",
              "d4",
              "Qc7"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "c5",
            "d4",
            "Qc7"
          ],
          "full_moves": [
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "d5",
            "Nc4",
            "h3",
            "Bd7",
            "b3",
            "Nb6",
            "Ng3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qd2",
            "Bf8",
            "Bxf8",
            "Rxf8",
            "Qh6",
            "Kh8",
            "Ng5",
            "Be8",
            "f4",
            "Rg8",
            "fxe5",
            "dxe5",
            "Rf1",
            "Qd6",
            "Rxf6",
            "Qxf6",
            "Qxh7#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 372,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 493,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1505,
          "total_tokens": 2017
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 372,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 493,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/np2p3/4P3/1BP2N2/PP1P1PPP/RNBQR1K1 w kq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d3",
          "aggressive_uci": "d2d3",
          "aggressive_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 Bg4 13. h3 Bh5 14. Ng3 Bg6 15. Nh4 Nfd7 16. Nhf5 Bxf5 17. Nxf5 Bg5 18. Qg4 h6 19. h4 Nf6 20. Qg3 Nh5 21. Qg4 Nf6 22. Qh3 Bxc1 23. Raxc1 Kh7 24. d4 g6 25. Ng3 Qd7 26. Qh2 Ng4 27. Qh1 exd4 28. cxd4 Nc4 29. b3 Na3 30. Bd3 b4 31. h5 Nb5 32. hxg6+ fxg6 33. f3 Nf6 34. e5 dxe5 35. dxe5 Qxd3 36. exf6 Rxf6 37. Re7+ Kg8 38. Qxh6 Qd4+ 39. Kh1 Rf7 40. Qxg6+ Qg7 41. Qxg7+ Rxg7 42. Rxg7+ Kxg7 43. Ne4 Rh8+ 44. Kg1 Rd8 45. Rc6 a5 46. Rc5 Rb8 47. Kf2 Kf7 48. g4 Ke6 49. f4 Kd7 50. g5 c6 51. f5 Nd4 52. Rxa5 Rf8 53. f6 Ke6 54. g6 Nf5 55. g7 Rg8 56. Ra6 Kd5 57. f7 Rxg7 58. f8=Q Kxe4 59. Qxb4+ Nd4 60. Ra4 Rf7+ 61. Kg2 Rg7+ 62. Kh3 Rh7+ 63. Kg4 Rg7+ 64. Kh5 Rh7+ 65. Kg6 Rd7 66. Qe1+ Kd5 67. Ra5+ c5 68. b4 Rd6+ 69. Kf7 Rd7+ 70. Ke8 Rc7 71. Rxc5+ Rxc5 72. bxc5 Kxc5 73. Qc3+ Kd5 74. a4 Nc6 75. a5 Kd6 76. a6 Kc7 77. Qc5 Kb8 78. Qxc6 Ka7 79. Qb7# Nf6+ 80. Kf7 Nd7 81. Qxd7+ Kxa6 82. Qc6+ Ka5 83. Qb7 Ka4 84. Ke6 Ka3 85. Kd5 Ka2",
          "aggressive_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "Nfd7",
            "Nhf5",
            "Bxf5",
            "Nxf5",
            "Bg5",
            "Qg4",
            "h6",
            "h4",
            "Nf6",
            "Qg3",
            "Nh5",
            "Qg4",
            "Nf6",
            "Qh3",
            "Bxc1",
            "Raxc1",
            "Kh7",
            "d4",
            "g6",
            "Ng3",
            "Qd7",
            "Qh2",
            "Ng4",
            "Qh1",
            "exd4",
            "cxd4",
            "Nc4",
            "b3",
            "Na3",
            "Bd3",
            "b4",
            "h5",
            "Nb5",
            "hxg6+",
            "fxg6",
            "f3",
            "Nf6",
            "e5",
            "dxe5",
            "dxe5",
            "Qxd3",
            "exf6",
            "Rxf6",
            "Re7+",
            "Kg8",
            "Qxh6",
            "Qd4+",
            "Kh1",
            "Rf7",
            "Qxg6+",
            "Qg7",
            "Qxg7+",
            "Rxg7",
            "Rxg7+",
            "Kxg7",
            "Ne4",
            "Rh8+",
            "Kg1",
            "Rd8",
            "Rc6",
            "a5",
            "Rc5",
            "Rb8",
            "Kf2",
            "Kf7",
            "g4",
            "Ke6",
            "f4",
            "Kd7",
            "g5",
            "c6",
            "f5",
            "Nd4",
            "Rxa5",
            "Rf8",
            "f6",
            "Ke6",
            "g6",
            "Nf5",
            "g7",
            "Rg8",
            "Ra6",
            "Kd5",
            "f7",
            "Rxg7",
            "f8=Q",
            "Kxe4",
            "Qxb4+",
            "Nd4",
            "Ra4",
            "Rf7+",
            "Kg2",
            "Rg7+",
            "Kh3",
            "Rh7+",
            "Kg4",
            "Rg7+",
            "Kh5",
            "Rh7+",
            "Kg6",
            "Rd7",
            "Qe1+",
            "Kd5",
            "Ra5+",
            "c5",
            "b4",
            "Rd6+",
            "Kf7",
            "Rd7+",
            "Ke8",
            "Rc7",
            "Rxc5+",
            "Rxc5",
            "bxc5",
            "Kxc5",
            "Qc3+",
            "Kd5",
            "a4",
            "Nc6",
            "a5",
            "Kd6",
            "a6",
            "Kc7",
            "Qc5",
            "Kb8",
            "Qxc6",
            "Ka7",
            "Qb7#",
            "Nf6+",
            "Kf7",
            "Nd7",
            "Qxd7+",
            "Kxa6",
            "Qc6+",
            "Ka5",
            "Qb7",
            "Ka4",
            "Ke6",
            "Ka3",
            "Kd5",
            "Ka2"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "query2": {
          "positional_move": "d3",
          "positional_uci": "d2d3",
          "positional_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 Bb7 13. Ng3 Re8 14. Nf5 Bf8 15. Bg5 h6 16. Bh4 g6 17. Ne3 Bg7 18. Qd2 Qd7 19. Rad1 d5 20. exd5 Nfxd5 21. Nxd5 Bxd5 22. Qe3 Qc6 23. Bg3 Bxf3 24. gxf3 Nd5 25. Qe4 f5 26. Qe2 f4 27. Bh4 g5 28. Qe4 gxh4 29. Bb3 Rad8 30. c4 bxc4 31. dxc4 Qf6 32. cxd5 Kh8 33. Bc2 Kg8 34. Kh1 Rd6 35. Rg1 Kf8 36. Rg6 Qf7 37. Rdg1 Rxg6 38. Rxg6 Rd8 39. Bb3 Rd6 40. Rxd6 cxd6 41. Qb4 Qc7 42. Bc4 a5 43. Qb5 Ke7 44. b4 axb4 45. Qxb4 Qa7 46. Kg2 Bf6 47. a4 Kd7 48. Bb5+ Ke7 49. a5 Kd8 50. Qxd6+ Kc8 51. Ba6+ Qxa6 52. Qxa6+ Kd7 53. Qxf6 Kc7 54. Qxe5+ Kb7 55. Qxf4 Ka6 56. Qxh4 Kxa5 57. Qxh6 Kb5 58. Qc6+ Kb4 59. d6 Kb3 60. d7 Kb2 61. d8=Q Kb1 62. Qb8+ Ka2 63. Qca8# d4 e5 d3 e4 d2 e3 d1=Q#",
          "positional_tokens": {
            "prompt_tokens": 180,
            "completion_tokens": 470,
            "total_tokens": 650,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e4",
            "d2",
            "e3",
            "d1=Q#"
          ],
          "plan_execute": [
            "e4",
            "d2",
            "e3"
          ]
        },
        "query3": {
          "neutral_move": "d3",
          "neutral_uci": "d2d3",
          "neutral_response": "10. d3 Nb6 11. Nbd2 O-O 12. Nf1 c5 13. Ng3 Qc7 14. h3 Re8 15. Be3 Bf8 16. Rc1 d5\n17. d4 exd4 18. cxd4 dxe4 19. Ng5 Bb7 20. dxc5 Nc4 21. Bd4 Rad8 22. N5xe4 Nxe4\n23. Nxe4 Bxc5 24. Nxc5 Rxe1+ 25. Qxe1 Bc6 26. Nb3 Qf4 27. Be3 Qf6 28. Rd1 Re8\n29. Nd4 Bb7 30. b3 Nxe3 31. fxe3 Qg5 32. Qf2 Rxe3 33. Nf5 Re8 34. Nd6 Re7\n35. Nxb7 Rxb7 36. Qf5 Qe3+ 37. Kh1 g6 38. Qc8+ Kg7 39. Qxb7 Qe2 40. Qe4 Qh5\n41. Qd4+ Kh6 42. Qf4+ Kg7 43. Rd7 g5 44. Qe5+ Kh6 45. Qf6+ Qg6 46. Bxg6 hxg6\n47. Qh8# Nf6 Qxf6 49. Qxf6 Kh5 50. Qh8#",
          "neutral_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 339,
            "total_tokens": 518,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "c5",
            "Ng3",
            "Qc7",
            "h3",
            "Re8",
            "Be3",
            "Bf8",
            "Rc1",
            "d5",
            "d4",
            "exd4",
            "cxd4",
            "dxe4",
            "Ng5",
            "Bb7",
            "dxc5",
            "Nc4",
            "Bd4",
            "Rad8",
            "N5xe4",
            "Nxe4",
            "Nxe4",
            "Bxc5",
            "Nxc5",
            "Rxe1+",
            "Qxe1",
            "Bc6",
            "Nb3",
            "Qf4",
            "Be3",
            "Qf6",
            "Rd1",
            "Re8",
            "Nd4",
            "Bb7",
            "b3",
            "Nxe3",
            "fxe3",
            "Qg5",
            "Qf2",
            "Rxe3",
            "Nf5",
            "Re8",
            "Nd6",
            "Re7",
            "Nxb7",
            "Rxb7",
            "Qf5",
            "Qe3+",
            "Kh1",
            "g6",
            "Qc8+",
            "Kg7",
            "Qxb7",
            "Qe2",
            "Qe4",
            "Qh5",
            "Qd4+",
            "Kh6",
            "Qf4+",
            "Kg7",
            "Rd7",
            "g5",
            "Qe5+",
            "Kh6",
            "Qf6+",
            "Qg6",
            "Bxg6",
            "hxg6",
            "Qh8#",
            "Nf6",
            "Qxf6",
            "Qxf6",
            "Kh5",
            "Qh8#"
          ],
          "plan_execute": [
            "Nb6",
            "Nbd2",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "d2d3",
          "positional_uci": "d2d3",
          "neutral_uci": "d2d3",
          "consensus_move": "d2d3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "Nfd7",
              "Nhf5",
              "Bxf5",
              "Nxf5",
              "Bg5",
              "Qg4",
              "h6",
              "h4",
              "Nf6",
              "Qg3",
              "Nh5",
              "Qg4",
              "Nf6",
              "Qh3",
              "Bxc1",
              "Raxc1",
              "Kh7",
              "d4",
              "g6",
              "Ng3",
              "Qd7",
              "Qh2",
              "Ng4",
              "Qh1",
              "exd4",
              "cxd4",
              "Nc4",
              "b3",
              "Na3",
              "Bd3",
              "b4",
              "h5",
              "Nb5",
              "hxg6+",
              "fxg6",
              "f3",
              "Nf6",
              "e5",
              "dxe5",
              "dxe5",
              "Qxd3",
              "exf6",
              "Rxf6",
              "Re7+",
              "Kg8",
              "Qxh6",
              "Qd4+",
              "Kh1",
              "Rf7",
              "Qxg6+",
              "Qg7",
              "Qxg7+",
              "Rxg7",
              "Rxg7+",
              "Kxg7",
              "Ne4",
              "Rh8+",
              "Kg1",
              "Rd8",
              "Rc6",
              "a5",
              "Rc5",
              "Rb8",
              "Kf2",
              "Kf7",
              "g4",
              "Ke6",
              "f4",
              "Kd7",
              "g5",
              "c6",
              "f5",
              "Nd4",
              "Rxa5",
              "Rf8",
              "f6",
              "Ke6",
              "g6",
              "Nf5",
              "g7",
              "Rg8",
              "Ra6",
              "Kd5",
              "f7",
              "Rxg7",
              "f8=Q",
              "Kxe4",
              "Qxb4+",
              "Nd4",
              "Ra4",
              "Rf7+",
              "Kg2",
              "Rg7+",
              "Kh3",
              "Rh7+",
              "Kg4",
              "Rg7+",
              "Kh5",
              "Rh7+",
              "Kg6",
              "Rd7",
              "Qe1+",
              "Kd5",
              "Ra5+",
              "c5",
              "b4",
              "Rd6+",
              "Kf7",
              "Rd7+",
              "Ke8",
              "Rc7",
              "Rxc5+",
              "Rxc5",
              "bxc5",
              "Kxc5",
              "Qc3+",
              "Kd5",
              "a4",
              "Nc6",
              "a5",
              "Kd6",
              "a6",
              "Kc7",
              "Qc5",
              "Kb8",
              "Qxc6",
              "Ka7",
              "Qb7#",
              "Nf6+",
              "Kf7",
              "Nd7",
              "Qxd7+",
              "Kxa6",
              "Qc6+",
              "Ka5",
              "Qb7",
              "Ka4",
              "Ke6",
              "Ka3",
              "Kd5",
              "Ka2"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          },
          "positional": {
            "full": [
              "e4",
              "d2",
              "e3",
              "d1=Q#"
            ],
            "execute": [
              "e4",
              "d2",
              "e3"
            ]
          },
          "neutral": {
            "full": [
              "Nb6",
              "Nbd2",
              "O-O",
              "Nf1",
              "c5",
              "Ng3",
              "Qc7",
              "h3",
              "Re8",
              "Be3",
              "Bf8",
              "Rc1",
              "d5",
              "d4",
              "exd4",
              "cxd4",
              "dxe4",
              "Ng5",
              "Bb7",
              "dxc5",
              "Nc4",
              "Bd4",
              "Rad8",
              "N5xe4",
              "Nxe4",
              "Nxe4",
              "Bxc5",
              "Nxc5",
              "Rxe1+",
              "Qxe1",
              "Bc6",
              "Nb3",
              "Qf4",
              "Be3",
              "Qf6",
              "Rd1",
              "Re8",
              "Nd4",
              "Bb7",
              "b3",
              "Nxe3",
              "fxe3",
              "Qg5",
              "Qf2",
              "Rxe3",
              "Nf5",
              "Re8",
              "Nd6",
              "Re7",
              "Nxb7",
              "Rxb7",
              "Qf5",
              "Qe3+",
              "Kh1",
              "g6",
              "Qc8+",
              "Kg7",
              "Qxb7",
              "Qe2",
              "Qe4",
              "Qh5",
              "Qd4+",
              "Kh6",
              "Qf4+",
              "Kg7",
              "Rd7",
              "g5",
              "Qe5+",
              "Kh6",
              "Qf6+",
              "Qg6",
              "Bxg6",
              "hxg6",
              "Qh8#",
              "Nf6",
              "Qxf6",
              "Qxf6",
              "Kh5",
              "Qh8#"
            ],
            "execute": [
              "Nb6",
              "Nbd2",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nb6",
            "Nbd2",
            "O-O"
          ],
          "full_moves": [
            "Nb6",
            "Nbd2",
            "O-O",
            "Nf1",
            "c5",
            "Ng3",
            "Qc7",
            "h3",
            "Re8",
            "Be3",
            "Bf8",
            "Rc1",
            "d5",
            "d4",
            "exd4",
            "cxd4",
            "dxe4",
            "Ng5",
            "Bb7",
            "dxc5",
            "Nc4",
            "Bd4",
            "Rad8",
            "N5xe4",
            "Nxe4",
            "Nxe4",
            "Bxc5",
            "Nxc5",
            "Rxe1+",
            "Qxe1",
            "Bc6",
            "Nb3",
            "Qf4",
            "Be3",
            "Qf6",
            "Rd1",
            "Re8",
            "Nd4",
            "Bb7",
            "b3",
            "Nxe3",
            "fxe3",
            "Qg5",
            "Qf2",
            "Rxe3",
            "Nf5",
            "Re8",
            "Nd6",
            "Re7",
            "Nxb7",
            "Rxb7",
            "Qf5",
            "Qe3+",
            "Kh1",
            "g6",
            "Qc8+",
            "Kg7",
            "Qxb7",
            "Qe2",
            "Qe4",
            "Qh5",
            "Qd4+",
            "Kh6",
            "Qf4+",
            "Kg7",
            "Rd7",
            "g5",
            "Qe5+",
            "Kh6",
            "Qf6+",
            "Qg6",
            "Bxg6",
            "hxg6",
            "Qh8#",
            "Nf6",
            "Qxf6",
            "Qxf6",
            "Kh5",
            "Qh8#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 180,
            "completion_tokens": 470,
            "total_tokens": 650,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 179,
            "completion_tokens": 339,
            "total_tokens": 518,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 539,
          "total_completion_tokens": 1449,
          "total_tokens": 1988
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 180,
            "completion_tokens": 640,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 180,
            "completion_tokens": 470,
            "total_tokens": 650,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 179,
            "completion_tokens": 339,
            "total_tokens": 518,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/p2p1n2/1p2p3/2n1P3/2P2N2/PPBP1PPP/RNBQR1K1 w kq - 3 10"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "cxb4",
          "aggressive_uci": "c3b4",
          "aggressive_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Qxd5 19. Bb3 Nc4 20. Bxc4 Qxc4 21. dxc4 Bxb4 22. Rxe5 Rad8 23. Qb3 Bd6 24. c5+ Kh8 25. cxd6 cxd6 26. Re7 d5 27. Bg5 d4 28. Bxf6 gxf6 29. Qb7 d3 30. Rxh7+ Kg8 31. Qg7# e4 d3 Qxd3 Qxd3",
          "aggressive_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 175,
            "total_tokens": 370,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Qxd5",
            "Bb3",
            "Nc4",
            "Bxc4",
            "Qxc4",
            "dxc4",
            "Bxb4",
            "Rxe5",
            "Rad8",
            "Qb3",
            "Bd6",
            "c5+",
            "Kh8",
            "cxd6",
            "cxd6",
            "Re7",
            "d5",
            "Bg5",
            "d4",
            "Bxf6",
            "gxf6",
            "Qb7",
            "d3",
            "Rxh7+",
            "Kg8",
            "Qg7#",
            "e4",
            "d3",
            "Qxd3",
            "Qxd3"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "query2": {
          "positional_move": "cxb4",
          "positional_uci": "c3b4",
          "positional_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Nfxd5 19. Rxe5 Nxb4 20. Bb3+ Kh8 21. Qe2 Bf6 22. Re4 Nxd3 23. Be3 Nxb2 24. Rb1 Nd3 25. Rd1 Re8 26. Rxd3 Qc8 27. Bxb6 cxb6 28. Rxe8+ Qxe8 29. Qxe8+ Rxe8 30. Rd6 Rb8 31. Ne4 Be5 32. Re6 Bd4 33. Nd6 h6 34. Re8+ Rxe8 35. Nxe8 Be5 36. g3 g5 37. Kg2 Kh7 38. Kf3 Kg6 39. Ke4 Bb8 40. Kd5 Kf7 41. Nd6+ Ke7 42. Nf5+ Kf6 43. Nd4 Be5 44. Nc6 Bc7 45. Nb4 a5 46. Na6 Bd8 47. Kc6 Ke5 48. Nc7 Kd4 49. Ne6+ Kc3 50. Nxd8 Kb4 51. Kxb6 a4 52. Bxa4 Kxa4 53. Ne6 Ka3 54. Nxg7 Kxa2 55. Nf5 Kb3 56. Nxh6 Kc4 57. Nf7 Kd5 58. Nxg5 Ke5 59. h4 Kf5 60. f3 Kg6 61. g4 Kh6 62. f4 Kg6 63. h5+ Kh6 64. Nf7+ Kg7 65. Ne5 Kh6 66. f5 Kg5 67. Kc6 Kf6 68. Kd6 Kg5 69. Ke6 Kh6 70. f6 Kh7 71. f7 Kg7 72. Ke7 Kh7 73. f8=Q *",
          "positional_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 502,
            "total_tokens": 697,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Re8",
            "Rxd3",
            "Qc8",
            "Bxb6",
            "cxb6",
            "Rxe8+",
            "Qxe8",
            "Qxe8+",
            "Rxe8",
            "Rd6",
            "Rb8",
            "Ne4",
            "Be5",
            "Re6",
            "Bd4",
            "Nd6",
            "h6",
            "Re8+",
            "Rxe8",
            "Nxe8",
            "Be5",
            "g3",
            "g5",
            "Kg2",
            "Kh7",
            "Kf3",
            "Kg6",
            "Ke4",
            "Bb8",
            "Kd5",
            "Kf7",
            "Nd6+",
            "Ke7",
            "Nf5+",
            "Kf6",
            "Nd4",
            "Be5",
            "Nc6",
            "Bc7",
            "Nb4",
            "a5",
            "Na6",
            "Bd8",
            "Kc6",
            "Ke5",
            "Nc7",
            "Kd4",
            "Ne6+",
            "Kc3",
            "Nxd8",
            "Kb4",
            "Kxb6",
            "a4",
            "Bxa4",
            "Kxa4",
            "Ne6",
            "Ka3",
            "Nxg7",
            "Kxa2",
            "Nf5",
            "Kb3",
            "Nxh6",
            "Kc4",
            "Nf7",
            "Kd5",
            "Nxg5",
            "Ke5",
            "h4",
            "Kf5",
            "f3",
            "Kg6",
            "g4",
            "Kh6",
            "f4",
            "Kg6",
            "h5+",
            "Kh6",
            "Nf7+",
            "Kg7",
            "Ne5",
            "Kh6",
            "f5",
            "Kg5",
            "Kc6",
            "Kf6",
            "Kd6",
            "Kg5",
            "Ke6",
            "Kh6",
            "f6",
            "Kh7",
            "f7",
            "Kg7",
            "Ke7",
            "Kh7",
            "f8=Q"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "query3": {
          "neutral_move": "cxb4",
          "neutral_uci": "c3b4",
          "neutral_response": "12. cxb4 O-O 13. Nf1 Bg4 14. h3 Bh5 15. Ng3 Bg6 16. Nh4 d5 17. Nxg6 fxg6 18. exd5 Nfxd5 19. Rxe5 Nxb4 20. Bb3+ Kh8 21. Qe2 Bf6 22. Re4 Nxd3 23. Be3 Nxb2 24. Rb1 Nd3 25. Rd1 Nc5 26. Rxd8 Raxd8 27. Bxc5 Nd7 28. Bxf8 Rxf8 29. Re8 h6 30. Rxf8+ Nxf8 31. Qe8 Kh7 32. Qxf8 g5 33. Bc2+ g6 34. Qf7+ Bg7 35. Bxg6+ Kh8 36. Qe8+ Bf8 37. Qxf8# e4 Nc6 Nc4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 Nxe4 N",
          "neutral_tokens": {
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Nc5",
            "Rxd8",
            "Raxd8",
            "Bxc5",
            "Nd7",
            "Bxf8",
            "Rxf8",
            "Re8",
            "h6",
            "Rxf8+",
            "Nxf8",
            "Qe8",
            "Kh7",
            "Qxf8",
            "g5",
            "Bc2+",
            "g6",
            "Qf7+",
            "Bg7",
            "Bxg6+",
            "Kh8",
            "Qe8+",
            "Bf8",
            "Qxf8#",
            "e4",
            "Nc6",
            "Nc4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4"
          ],
          "plan_execute": [
            "O-O",
            "Nf1",
            "Bg4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "c3b4",
          "positional_uci": "c3b4",
          "neutral_uci": "c3b4",
          "consensus_move": "c3b4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "exd5",
              "Qxd5",
              "Bb3",
              "Nc4",
              "Bxc4",
              "Qxc4",
              "dxc4",
              "Bxb4",
              "Rxe5",
              "Rad8",
              "Qb3",
              "Bd6",
              "c5+",
              "Kh8",
              "cxd6",
              "cxd6",
              "Re7",
              "d5",
              "Bg5",
              "d4",
              "Bxf6",
              "gxf6",
              "Qb7",
              "d3",
              "Rxh7+",
              "Kg8",
              "Qg7#",
              "e4",
              "d3",
              "Qxd3",
              "Qxd3"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "exd5",
              "Nfxd5",
              "Rxe5",
              "Nxb4",
              "Bb3+",
              "Kh8",
              "Qe2",
              "Bf6",
              "Re4",
              "Nxd3",
              "Be3",
              "Nxb2",
              "Rb1",
              "Nd3",
              "Rd1",
              "Re8",
              "Rxd3",
              "Qc8",
              "Bxb6",
              "cxb6",
              "Rxe8+",
              "Qxe8",
              "Qxe8+",
              "Rxe8",
              "Rd6",
              "Rb8",
              "Ne4",
              "Be5",
              "Re6",
              "Bd4",
              "Nd6",
              "h6",
              "Re8+",
              "Rxe8",
              "Nxe8",
              "Be5",
              "g3",
              "g5",
              "Kg2",
              "Kh7",
              "Kf3",
              "Kg6",
              "Ke4",
              "Bb8",
              "Kd5",
              "Kf7",
              "Nd6+",
              "Ke7",
              "Nf5+",
              "Kf6",
              "Nd4",
              "Be5",
              "Nc6",
              "Bc7",
              "Nb4",
              "a5",
              "Na6",
              "Bd8",
              "Kc6",
              "Ke5",
              "Nc7",
              "Kd4",
              "Ne6+",
              "Kc3",
              "Nxd8",
              "Kb4",
              "Kxb6",
              "a4",
              "Bxa4",
              "Kxa4",
              "Ne6",
              "Ka3",
              "Nxg7",
              "Kxa2",
              "Nf5",
              "Kb3",
              "Nxh6",
              "Kc4",
              "Nf7",
              "Kd5",
              "Nxg5",
              "Ke5",
              "h4",
              "Kf5",
              "f3",
              "Kg6",
              "g4",
              "Kh6",
              "f4",
              "Kg6",
              "h5+",
              "Kh6",
              "Nf7+",
              "Kg7",
              "Ne5",
              "Kh6",
              "f5",
              "Kg5",
              "Kc6",
              "Kf6",
              "Kd6",
              "Kg5",
              "Ke6",
              "Kh6",
              "f6",
              "Kh7",
              "f7",
              "Kg7",
              "Ke7",
              "Kh7",
              "f8=Q"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "Nf1",
              "Bg4",
              "h3",
              "Bh5",
              "Ng3",
              "Bg6",
              "Nh4",
              "d5",
              "Nxg6",
              "fxg6",
              "exd5",
              "Nfxd5",
              "Rxe5",
              "Nxb4",
              "Bb3+",
              "Kh8",
              "Qe2",
              "Bf6",
              "Re4",
              "Nxd3",
              "Be3",
              "Nxb2",
              "Rb1",
              "Nd3",
              "Rd1",
              "Nc5",
              "Rxd8",
              "Raxd8",
              "Bxc5",
              "Nd7",
              "Bxf8",
              "Rxf8",
              "Re8",
              "h6",
              "Rxf8+",
              "Nxf8",
              "Qe8",
              "Kh7",
              "Qxf8",
              "g5",
              "Bc2+",
              "g6",
              "Qf7+",
              "Bg7",
              "Bxg6+",
              "Kh8",
              "Qe8+",
              "Bf8",
              "Qxf8#",
              "e4",
              "Nc6",
              "Nc4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4",
              "Nxe4"
            ],
            "execute": [
              "O-O",
              "Nf1",
              "Bg4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "Nf1",
            "Bg4"
          ],
          "full_moves": [
            "O-O",
            "Nf1",
            "Bg4",
            "h3",
            "Bh5",
            "Ng3",
            "Bg6",
            "Nh4",
            "d5",
            "Nxg6",
            "fxg6",
            "exd5",
            "Nfxd5",
            "Rxe5",
            "Nxb4",
            "Bb3+",
            "Kh8",
            "Qe2",
            "Bf6",
            "Re4",
            "Nxd3",
            "Be3",
            "Nxb2",
            "Rb1",
            "Nd3",
            "Rd1",
            "Nc5",
            "Rxd8",
            "Raxd8",
            "Bxc5",
            "Nd7",
            "Bxf8",
            "Rxf8",
            "Re8",
            "h6",
            "Rxf8+",
            "Nxf8",
            "Qe8",
            "Kh7",
            "Qxf8",
            "g5",
            "Bc2+",
            "g6",
            "Qf7+",
            "Bg7",
            "Bxg6+",
            "Kh8",
            "Qe8+",
            "Bf8",
            "Qxf8#",
            "e4",
            "Nc6",
            "Nc4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4",
            "Nxe4"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 195,
            "completion_tokens": 175,
            "total_tokens": 370,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 195,
            "completion_tokens": 502,
            "total_tokens": 697,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 584,
          "total_completion_tokens": 1317,
          "total_tokens": 1901
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 195,
            "completion_tokens": 175,
            "total_tokens": 370,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 195,
            "completion_tokens": 502,
            "total_tokens": 697,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 194,
            "completion_tokens": 640,
            "total_tokens": 834,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/pn1p1n2/4p3/1p2P3/2PP1N2/PPBN1PPP/R1BQR1K1 w kq - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "bxa5",
          "aggressive_uci": "b4a5",
          "aggressive_response": "13. bxa5 Rxa5 14. b4 Ra8 15. a4 O-O 16. a5 Nbd7 17. d4 exd4 18. Nxd4 Bb7 19. Nf5 Re8 20. Nxe7+ Qxe7 21. Bb2 Ne5 22. f4 Nc6 23. Bc3 Ba6 24. Ba4 Bb7 25. b5 Nxa5 26. Bxa5 Rxa5 27. b6 c6 28. Nc4 Rc5 29. Nxd6 Rd8 30. e5 Nd5 31. Qd4 Ra5 32. Bxc6 Rxa1 33. Rxa1 Bxc6 34. Ra7 Qh4 35. g3 Qh3 36. b7 Ne3 37. Kf2 Ng4+ 38. Ke1 Nxh2 39. Qf2 Nf3+ 40. Ke2 Qh1 41. Ra8 Rxa8 42. bxa8=Q+ Bxa8 43. Qa7 Qe1+ 44. Kd3 Qd2+ 45. Kc4 Qd5+ 46. Kc3 h6 47. Qb8+ Kh7 48. Qb1+ g6 49. Qb8 Qd4+ 50. Kc2 Be4+ 51. Nxe4 Qxe4+ 52. Kc3 Qe3+ 53. Kc4 Qd4+ 54. Kb3 Nd2+ 55. Kc2 Ne4 56. Qc7 Qd2+ 57. Kb3 Qd5+ 58. Kb2 Nxg3 59. Qc3 Ne4 60. Qc7 Qd2+ 61. Kb3 Qd3+ 62. Kb2 Qb5+ 63. Kc2 Qc5+ 64. Qxc5 Nxc5 65. Kd2 h5 66. Ke3 Kh6 67. Kf3 g5 68. fxg5+ Kxg5 69. Kg3 Nd3 70. Kh3 Nxe5 71. Kg3 h4+ 72. Kh3 f5 73. Kg2 Kg4 74. Kh2 h3 75. Kg1 Kg3 76. Kh1 Ng4 77. Kg1 h2+ 78. Kh1 Nf2# 0-1 e4 Nf6 Bb5 a6 Ba4 Nc6 Nf3 Be7 Re1 b5 c3 Na5 Bc2 Nc4 d3 Nb6 Nbd2 b4 cxb4 a5 bxa5 Rxa5 b3 Ra8 a5 O-O a6 Nbd7 d4 exd4 Nxd4",
          "aggressive_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxa5",
            "b3",
            "Ra8",
            "a5",
            "O-O",
            "a6",
            "Nbd7",
            "d4",
            "exd4",
            "Nxd4"
          ],
          "plan_execute": [
            "Rxa5",
            "b3",
            "Ra8"
          ]
        },
        "query2": {
          "positional_move": "bxa5",
          "positional_uci": "b4a5",
          "positional_response": "13. bxa5 Rxa5 14. Nb3 Ra8 15. d4 exd4 16. Nbxd4 Bb7 17. Nf5 O-O 18. Bg5 h6 19. Bh4 g5 20. Nxh6+ Kg7 21. Bxg5 Nh7 22. Nf5+ Kg6 23. Bxe7 Qd7 24. N3h4# e4 Nxe7 Nxe7+ Kh8 Qd4+ Kg8 Qg5+ Kh8 Qg7# e5 Nxe5 Nxe5+ Kh8 Qg7# e6 Nxe6 Nxe6+ Kh8 Qg7# e7 Nxe7 Nxe7+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe8+ Kh8 Qg7# e8=Q Nxe8 Nxe",
          "positional_tokens": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxh6+",
            "Kg7",
            "Bxg5",
            "Nh7",
            "Nf5+",
            "Kg6",
            "Bxe7",
            "Qd7",
            "N3h4#",
            "e4",
            "Nxe7",
            "Nxe7+",
            "Kh8",
            "Qd4+",
            "Kg8",
            "Qg5+",
            "Kh8",
            "Qg7#",
            "e5",
            "Nxe5",
            "Nxe5+",
            "Kh8",
            "Qg7#",
            "e6",
            "Nxe6",
            "Nxe6+",
            "Kh8",
            "Qg7#",
            "e7",
            "Nxe7",
            "Nxe7+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8",
            "Nxe8+",
            "Kh8",
            "Qg7#",
            "e8=Q",
            "Nxe8"
          ],
          "plan_execute": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ]
        },
        "query3": {
          "neutral_move": "bxa5",
          "neutral_uci": "b4a5",
          "neutral_response": "13. bxa5 Rxa5 14. Nb3 Ra8 15. d4 exd4 16. Nbxd4 Bb7 17. Nf5 O-O 18. Nxe7+ Qxe7 19. e5 dxe5 20. Nxe5 Qc5 21. Bg5 Nfd5 22. Qd3 g6 23. Bh6 Rfe8 24. Qf3 f5 25. Bxf5 gxf5 26. Qg3+ Kh8 27. Qg7# Nf6 28. Nf7# Kg8 29. Qxf6 Qf8 30. Bxf8 Rxf8 31. Nh6# Kh8 32. Qe5# Kh8 33. Qxc7# Kh8 34. Qxb7# Kh8 35. Qxb6# Kh8 36. Qd4# Kh8 37. Re7# Kh8 38. Qg7# Kh8 39. Qxh7# Kh8 40. Qg7# Kh8 41. Qxf8# Kh8 42. Qg7# Kh8 43. Qxf8# Kh8 44. Qg7# Kh8 45. Qxf8# Kh8 46. Qg7# Kh8 47. Qxf8# Kh8 48. Qg7# Kh8 49. Qxf8# Kh8 50. Qg7# Kh8 51. Qxf8# Kh8 52. Qg7# Kh8 53. Qxf8# Kh8 54. Qg7# Kh8 55. Qxf8# Kh8 56. Qg7# Kh8 57. Qxf8# Kh8 58. Qg7# Kh8 59. Qxf8# Kh8 60. Qg7# Kh8 61. Qxf8# Kh8 62. Qg7# Kh8 63. Qxf8# Kh8 64. Qg7# Kh8 65. Qxf8# Kh8 66. Qg7# Kh8 67. Qxf8# Kh8 68. Qg7# Kh8 69. Qxf8# Kh8 70. Qg7# Kh8 71. Qxf8# Kh8 72. Qg7# Kh8 73. Qxf8# Kh8 74. Qg7# Kh8 75. Qxf8# Kh8 76. Qg7# Kh8 77. Qxf8# Kh8 78. Qg7# Kh8 79. Qxf8# Kh8 80. Qg7# Kh8 81. Qxf8# Kh8 82. Qg7# Kh8 83. Qxf8# Kh8 84. Qg7# Kh",
          "neutral_tokens": {
            "prompt_tokens": 202,
            "completion_tokens": 640,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Nxe7+",
            "Qxe7",
            "e5",
            "dxe5",
            "Nxe5",
            "Qc5",
            "Bg5",
            "Nfd5",
            "Qd3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qf3",
            "f5",
            "Bxf5",
            "gxf5",
            "Qg3+",
            "Kh8",
            "Qg7#",
            "Nf6",
            "Nf7#",
            "Kg8",
            "Qxf6",
            "Qf8",
            "Bxf8",
            "Rxf8",
            "Nh6#",
            "Kh8",
            "Qe5#",
            "Kh8",
            "Qxc7#",
            "Kh8",
            "Qxb7#",
            "Kh8",
            "Qxb6#",
            "Kh8",
            "Qd4#",
            "Kh8",
            "Re7#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxh7#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#"
          ],
          "plan_execute": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b4a5",
          "positional_uci": "b4a5",
          "neutral_uci": "b4a5",
          "consensus_move": "b4a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxa5",
              "b3",
              "Ra8",
              "a5",
              "O-O",
              "a6",
              "Nbd7",
              "d4",
              "exd4",
              "Nxd4"
            ],
            "execute": [
              "Rxa5",
              "b3",
              "Ra8"
            ]
          },
          "positional": {
            "full": [
              "Rxa5",
              "Nb3",
              "Ra8",
              "d4",
              "exd4",
              "Nbxd4",
              "Bb7",
              "Nf5",
              "O-O",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxh6+",
              "Kg7",
              "Bxg5",
              "Nh7",
              "Nf5+",
              "Kg6",
              "Bxe7",
              "Qd7",
              "N3h4#",
              "e4",
              "Nxe7",
              "Nxe7+",
              "Kh8",
              "Qd4+",
              "Kg8",
              "Qg5+",
              "Kh8",
              "Qg7#",
              "e5",
              "Nxe5",
              "Nxe5+",
              "Kh8",
              "Qg7#",
              "e6",
              "Nxe6",
              "Nxe6+",
              "Kh8",
              "Qg7#",
              "e7",
              "Nxe7",
              "Nxe7+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8",
              "Nxe8+",
              "Kh8",
              "Qg7#",
              "e8=Q",
              "Nxe8"
            ],
            "execute": [
              "Rxa5",
              "Nb3",
              "Ra8"
            ]
          },
          "neutral": {
            "full": [
              "Rxa5",
              "Nb3",
              "Ra8",
              "d4",
              "exd4",
              "Nbxd4",
              "Bb7",
              "Nf5",
              "O-O",
              "Nxe7+",
              "Qxe7",
              "e5",
              "dxe5",
              "Nxe5",
              "Qc5",
              "Bg5",
              "Nfd5",
              "Qd3",
              "g6",
              "Bh6",
              "Rfe8",
              "Qf3",
              "f5",
              "Bxf5",
              "gxf5",
              "Qg3+",
              "Kh8",
              "Qg7#",
              "Nf6",
              "Nf7#",
              "Kg8",
              "Qxf6",
              "Qf8",
              "Bxf8",
              "Rxf8",
              "Nh6#",
              "Kh8",
              "Qe5#",
              "Kh8",
              "Qxc7#",
              "Kh8",
              "Qxb7#",
              "Kh8",
              "Qxb6#",
              "Kh8",
              "Qd4#",
              "Kh8",
              "Re7#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxh7#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#",
              "Kh8",
              "Qxf8#",
              "Kh8",
              "Qg7#"
            ],
            "execute": [
              "Rxa5",
              "Nb3",
              "Ra8"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Rxa5",
            "Nb3",
            "Ra8"
          ],
          "full_moves": [
            "Rxa5",
            "Nb3",
            "Ra8",
            "d4",
            "exd4",
            "Nbxd4",
            "Bb7",
            "Nf5",
            "O-O",
            "Nxe7+",
            "Qxe7",
            "e5",
            "dxe5",
            "Nxe5",
            "Qc5",
            "Bg5",
            "Nfd5",
            "Qd3",
            "g6",
            "Bh6",
            "Rfe8",
            "Qf3",
            "f5",
            "Bxf5",
            "gxf5",
            "Qg3+",
            "Kh8",
            "Qg7#",
            "Nf6",
            "Nf7#",
            "Kg8",
            "Qxf6",
            "Qf8",
            "Bxf8",
            "Rxf8",
            "Nh6#",
            "Kh8",
            "Qe5#",
            "Kh8",
            "Qxc7#",
            "Kh8",
            "Qxb7#",
            "Kh8",
            "Qxb6#",
            "Kh8",
            "Qd4#",
            "Kh8",
            "Re7#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxh7#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#",
            "Kh8",
            "Qxf8#",
            "Kh8",
            "Qg7#"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 202,
            "completion_tokens": 640,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 608,
          "total_completion_tokens": 1920,
          "total_tokens": 2528
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 203,
            "completion_tokens": 640,
            "total_tokens": 843,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 202,
            "completion_tokens": 640,
            "total_tokens": 842,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/2p1bppp/1n1p1n2/p3p3/1P2P3/3P1N2/PPBN1PPP/R1BQR1K1 w kq - 0 13"
    },
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bf7\n39. Rxb5 Bxa2 40. Ra5 Bb3 41. Nd2 Nc6 42. Ra6 Nb4\n43. Ra7+ Kg6 44. Bc4 Bxc4 45. Nxc4 Nd3 46. Rxa4 Rc8\n47. b3 Nc5 48. Rb4 Nxe4 49. Nxe5+ Kf5 50. Nc4 Rd8\n51. Ne3+ Ke5 52. Rb5+ Ke6 53. Rb6+ Ke5 54. Ng4+ Kf5\n55. f3 Rd1+ 56. Kh2 Nd6 57. Ne3+ Ke5 58. Nxd1 1-0\n58... Kd5 59. Rxd6+ Kxd6 60. Kg3 Kc5",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 498,
            "total_tokens": 612,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bf7",
            "Rxb5",
            "Bxa2",
            "Ra5",
            "Bb3",
            "Nd2",
            "Nc6",
            "Ra6",
            "Nb4",
            "Ra7+",
            "Kg6",
            "Bc4",
            "Bxc4",
            "Nxc4",
            "Nd3",
            "Rxa4",
            "Rc8",
            "b3",
            "Nc5",
            "Rb4",
            "Nxe4",
            "Nxe5+",
            "Kf5",
            "Nc4",
            "Rd8",
            "Ne3+",
            "Ke5",
            "Rb5+",
            "Ke6",
            "Rb6+",
            "Ke5",
            "Ng4+",
            "Kf5",
            "f3",
            "Rd1+",
            "Kh2",
            "Nd6",
            "Ne3+",
            "Ke5",
            "Nxd1",
            "Kd5",
            "Rxd6+",
            "Kxd6",
            "Kg3",
            "Kc5"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bb5"
          ]
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6\n5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6\n13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8\n17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4\n25. Ra8 Bb8 26. Rea1 Rg6 27. R1a6 Be6 28. Qxg6 Qxg6+\n29. Kf1 Qd3+ 30. Ke1 Bg4 31. f3 Qxe3+ 32. Kd1 Bxf3+\n33. Nxf3 Qxf3+ 34. Kc2 Qe2+ 35. Kb3 Qc4+ 36. Ka3 b4+\n37. cxb4 Qxa6+ 38. Rxa6 Bxh2 39. b5 h5 40. b6 h4\n41. b7 h3 42. Ra8 Bb8 43. Ra5 h2 44. Rh5 g6\n45. Rh3 Kg7 46. Kb4 Rh8 47. Rxh8 Kxh8 48. Kc5 h1=Q\n49. d5 Qc1+ 50. Kb6 Qxb2+ 51. Kc6 Qc3+ 52. Kd7 Qc7+\n53. Ke8 Kg7 54. d6 Qxd6 55. b4 Qe6+ 56. Kd8 Qd6+ 57. Ke8 Qc6+ 58. Kd8 Qxb7 59. b5 Qc7+ 60. Ke8 Qc8+ 61. Ke7 Qe6+ 62. Kd8 Qd6+ 63. Ke8 Qe6+ 64. Kd8 Qd6+ 65. Ke8 Qe6+ 66. Kd8 Qd6+ 67. Ke8 Qe6+ 68. Kd8 Qd6+ 69. Ke8 Qe6+ 70. Kd8 Qd6+ 71. Ke8 Qe6+ 72. Kd8 Qd6+ 73. Ke8 Qe6+ 74. Kd8 Q",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Rea1",
            "Rg6",
            "R1a6",
            "Be6",
            "Qxg6",
            "Qxg6+",
            "Kf1",
            "Qd3+",
            "Ke1",
            "Bg4",
            "f3",
            "Qxe3+",
            "Kd1",
            "Bxf3+",
            "Nxf3",
            "Qxf3+",
            "Kc2",
            "Qe2+",
            "Kb3",
            "Qc4+",
            "Ka3",
            "b4+",
            "cxb4",
            "Qxa6+",
            "Rxa6",
            "Bxh2",
            "b5",
            "h5",
            "b6",
            "h4",
            "b7",
            "h3",
            "Ra8",
            "Bb8",
            "Ra5",
            "h2",
            "Rh5",
            "g6",
            "Rh3",
            "Kg7",
            "Kb4",
            "Rh8",
            "Rxh8",
            "Kxh8",
            "Kc5",
            "h1=Q",
            "d5",
            "Qc1+",
            "Kb6",
            "Qxb2+",
            "Kc6",
            "Qc3+",
            "Kd7",
            "Qc7+",
            "Ke8",
            "Kg7",
            "d6",
            "Qxd6",
            "b4",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qc6+",
            "Kd8",
            "Qxb7",
            "b5",
            "Qc7+",
            "Ke8",
            "Qc8+",
            "Ke7",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe6+",
            "Kd8"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bb5"
          ]
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6\n39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6\n43. Nd2 Kc5 44. a3 Bd7 45. Nb1 Nc6 46. Nc3 Nd4\n47. Nd5 f5 48. Nf6 f4+ 49. Kd2 Be6 50. Nxh7 b4\n51. Ng5 Bg8 52. h4 bxa3 53. bxa3 Nb3+ 54. Kc3 Nd4\n55. h5 Nb5+ 56. Bxb5 Kxb5 57. h6 Kc5 58. h7 Bxh7\n59. Nxh7 Kd6 60. Ng5 Kc5 61. Nf3 Kd6 62. Kb4 Ke6\n63. Kxa4 Kd6 64. Kb5 Ke6 65. a4 Kd6 66. a5 Ke6\n67. a6 Kd6 68. a7 Ke6 69. a8=Q Kd6 70. Qd5+ Ke7\n71. Qxe5+ Kd7 72. Qxf4 Ke6 73. Qf5+ Kd6 74. Qd5+ Ke7\n75. Qc6 Kf7 76. Qd6 Kg7 77. Qe6 Kh7 78. Qf6 Kg8",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Nc6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "Kd2",
            "Be6",
            "Nxh7",
            "b4",
            "Ng5",
            "Bg8",
            "h4",
            "bxa3",
            "bxa3",
            "Nb3+",
            "Kc3",
            "Nd4",
            "h5",
            "Nb5+",
            "Bxb5",
            "Kxb5",
            "h6",
            "Kc5",
            "h7",
            "Bxh7",
            "Nxh7",
            "Kd6",
            "Ng5",
            "Kc5",
            "Nf3",
            "Kd6",
            "Kb4",
            "Ke6",
            "Kxa4",
            "Kd6",
            "Kb5",
            "Ke6",
            "a4",
            "Kd6",
            "a5",
            "Ke6",
            "a6",
            "Kd6",
            "a7",
            "Ke6",
            "a8=Q",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qxe5+",
            "Kd7",
            "Qxf4",
            "Ke6",
            "Qf5+",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qc6",
            "Kf7",
            "Qd6",
            "Kg7",
            "Qe6",
            "Kh7",
            "Qf6",
            "Kg8"
          ],
          "plan_execute": [
            "Nf3",
            "Nc6",
            "Bb5"
          ]
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bf7",
              "Rxb5",
              "Bxa2",
              "Ra5",
              "Bb3",
              "Nd2",
              "Nc6",
              "Ra6",
              "Nb4",
              "Ra7+",
              "Kg6",
              "Bc4",
              "Bxc4",
              "Nxc4",
              "Nd3",
              "Rxa4",
              "Rc8",
              "b3",
              "Nc5",
              "Rb4",
              "Nxe4",
              "Nxe5+",
              "Kf5",
              "Nc4",
              "Rd8",
              "Ne3+",
              "Ke5",
              "Rb5+",
              "Ke6",
              "Rb6+",
              "Ke5",
              "Ng4+",
              "Kf5",
              "f3",
              "Rd1+",
              "Kh2",
              "Nd6",
              "Ne3+",
              "Ke5",
              "Nxd1",
              "Kd5",
              "Rxd6+",
              "Kxd6",
              "Kg3",
              "Kc5"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bb5"
            ]
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Rea1",
              "Rg6",
              "R1a6",
              "Be6",
              "Qxg6",
              "Qxg6+",
              "Kf1",
              "Qd3+",
              "Ke1",
              "Bg4",
              "f3",
              "Qxe3+",
              "Kd1",
              "Bxf3+",
              "Nxf3",
              "Qxf3+",
              "Kc2",
              "Qe2+",
              "Kb3",
              "Qc4+",
              "Ka3",
              "b4+",
              "cxb4",
              "Qxa6+",
              "Rxa6",
              "Bxh2",
              "b5",
              "h5",
              "b6",
              "h4",
              "b7",
              "h3",
              "Ra8",
              "Bb8",
              "Ra5",
              "h2",
              "Rh5",
              "g6",
              "Rh3",
              "Kg7",
              "Kb4",
              "Rh8",
              "Rxh8",
              "Kxh8",
              "Kc5",
              "h1=Q",
              "d5",
              "Qc1+",
              "Kb6",
              "Qxb2+",
              "Kc6",
              "Qc3+",
              "Kd7",
              "Qc7+",
              "Ke8",
              "Kg7",
              "d6",
              "Qxd6",
              "b4",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qc6+",
              "Kd8",
              "Qxb7",
              "b5",
              "Qc7+",
              "Ke8",
              "Qc8+",
              "Ke7",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe6+",
              "Kd8"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bb5"
            ]
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Bd7",
              "Nb1",
              "Nc6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "f4+",
              "Kd2",
              "Be6",
              "Nxh7",
              "b4",
              "Ng5",
              "Bg8",
              "h4",
              "bxa3",
              "bxa3",
              "Nb3+",
              "Kc3",
              "Nd4",
              "h5",
              "Nb5+",
              "Bxb5",
              "Kxb5",
              "h6",
              "Kc5",
              "h7",
              "Bxh7",
              "Nxh7",
              "Kd6",
              "Ng5",
              "Kc5",
              "Nf3",
              "Kd6",
              "Kb4",
              "Ke6",
              "Kxa4",
              "Kd6",
              "Kb5",
              "Ke6",
              "a4",
              "Kd6",
              "a5",
              "Ke6",
              "a6",
              "Kd6",
              "a7",
              "Ke6",
              "a8=Q",
              "Kd6",
              "Qd5+",
              "Ke7",
              "Qxe5+",
              "Kd7",
              "Qxf4",
              "Ke6",
              "Qf5+",
              "Kd6",
              "Qd5+",
              "Ke7",
              "Qc6",
              "Kf7",
              "Qd6",
              "Kg7",
              "Qe6",
              "Kh7",
              "Qf6",
              "Kg8"
            ],
            "execute": [
              "Nf3",
              "Nc6",
              "Bb5"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Nf3",
            "Nc6",
            "Bb5"
          ],
          "full_moves": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Nc6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "Kd2",
            "Be6",
            "Nxh7",
            "b4",
            "Ng5",
            "Bg8",
            "h4",
            "bxa3",
            "bxa3",
            "Nb3+",
            "Kc3",
            "Nd4",
            "h5",
            "Nb5+",
            "Bxb5",
            "Kxb5",
            "h6",
            "Kc5",
            "h7",
            "Bxh7",
            "Nxh7",
            "Kd6",
            "Ng5",
            "Kc5",
            "Nf3",
            "Kd6",
            "Kb4",
            "Ke6",
            "Kxa4",
            "Kd6",
            "Kb5",
            "Ke6",
            "a4",
            "Kd6",
            "a5",
            "Ke6",
            "a6",
            "Kd6",
            "a7",
            "Ke6",
            "a8=Q",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qxe5+",
            "Kd7",
            "Qxf4",
            "Ke6",
            "Qf5+",
            "Kd6",
            "Qd5+",
            "Ke7",
            "Qc6",
            "Kf7",
            "Qd6",
            "Kg7",
            "Qe6",
            "Kh7",
            "Qf6",
            "Kg8"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 498,
            "total_tokens": 612,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1778,
          "total_tokens": 2119
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 498,
            "total_tokens": 612,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 640,
            "total_tokens": 753,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1\nRg6 27. Bf4 Rxe1+ 28. Nf1 Bf3 29. Rxb8+ Re8 30. Rxe8# e5 dxe5 Bxg2+ Kxg2\nQg4+ Ng3 exf4 Rxe8+ Kxe8 Nxf4 Qxf4 Kg1 Qc1+ Kg2 Qxb2 Kg3 Qxc3+ Kg2 Qxd4 Kg3 b4 Kg2 b3 Kg3 b2 Kg2 b1=Q Kg3 Qg6+ Kf3 Qde4#",
          "aggressive_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 328,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "e5",
            "dxe5",
            "Bxg2+",
            "Kxg2",
            "Qg4+",
            "Ng3",
            "exf4",
            "Rxe8+",
            "Kxe8",
            "Nxf4",
            "Qxf4",
            "Kg1",
            "Qc1+",
            "Kg2",
            "Qxb2",
            "Kg3",
            "Qxc3+",
            "Kg2",
            "Qxd4",
            "Kg3",
            "b4",
            "Kg2",
            "b3",
            "Kg3",
            "b2",
            "Kg2",
            "b1=Q",
            "Kg3",
            "Qg6+",
            "Kf3",
            "Qde4#"
          ],
          "plan_execute": [
            "Bb5",
            "a6",
            "Ba4"
          ]
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1\nRg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+\n32. Kf1 Qd1# e5 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d5 exd5 Nxd5 Nxe5 Nxe5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Re6 Qf1 Qh5 a4 Rfe8 axb5 axb5 Bxd5 Qxd5 Qg2 Qh5 Qxc6 Bxg3 Qg2 Bf4 Bxf4 Rxe1+ Nf1 Rxf1+ Qxf1 Bf3 Bg3 Bb7 Qd3 Qd5 f3 Qxf3 Qxf3 Bxf3 Kf2 Bd5 Bd6 f6 Bc5 Kf7 Bd6 Ke6 Bc5 Kf5 Bd6 Ke4 Bc5 g6 Bd6 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3 Kd3 Bc5 Kc2 Bc5 Kd3",
          "positional_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Bxf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3",
            "Bg3",
            "Bb7",
            "Qd3",
            "Qd5",
            "f3",
            "Qxf3",
            "Qxf3",
            "Bxf3",
            "Kf2",
            "Bd5",
            "Bd6",
            "f6",
            "Bc5",
            "Kf7",
            "Bd6",
            "Ke6",
            "Bc5",
            "Kf5",
            "Bd6",
            "Ke4",
            "Bc5",
            "g6",
            "Bd6",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3",
            "Kd3",
            "Bc5",
            "Kc2",
            "Bc5",
            "Kd3"
          ],
          "plan_execute": [
            "Bb5",
            "a6",
            "Ba4"
          ]
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bc7 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qf3 Bg4 26. Qh1 Bb8 27. Rxe6 Rxe6 28. Qb7 Re8 29. Qc6 f6 30. f3 Bh3 31. Bf2 Rxe1+ 32. Bxe1 h6 33. g4 Bxg4 34. fxg4 Qxg4+ 35. Qg2 Qd1 36. Qd5+ Kh7 37. Qe4+ Kg8 38. Qe8+ Kh7 39. Qxb8 Qxe1+ 40. Nf1 Qe2 41. Qg3 Qxb2 42. Qd3+ Kg8 43. d5 b4 44. cxb4 Qxb4 45. d6 Qb6+ 46. Ne3 Kf7 47. Qd5+ Ke8 48. Qe6+ Kd8 49. Qe7+ Kc8 50. d7+ Kb7 51. d8=Q+ Ka6 52. Qa3+ Kb5 53. Qd5+ Qc5 54. Qdxc5# Qxc5 55. Qxc5+ Kxc5 56. Nf5 g6 57. Nxh6 Kd5 58. Kf2 Ke4 59. Kg3 f5 60. h4 Ke5 61. Kf3 Kf6 62. Kf4 Kg7 63. Kg5 Kh7 64. Nf7 Kg7 65. Ne5 Kh7 66. Nxg6 Kg7 67. Kxf5 Kh6 68. Kg4 Kxg6 69. h5+ Kh6 70. Kh4 Kg7 71. Kg5 Kh7 72. h6 Kg8 73. Kg6 Kh8 74. h7 *",
          "neutral_tokens": {
            "prompt_tokens": 121,
            "completion_tokens": 609,
            "total_tokens": 730,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qh1",
            "Bb8",
            "Rxe6",
            "Rxe6",
            "Qb7",
            "Re8",
            "Qc6",
            "f6",
            "f3",
            "Bh3",
            "Bf2",
            "Rxe1+",
            "Bxe1",
            "h6",
            "g4",
            "Bxg4",
            "fxg4",
            "Qxg4+",
            "Qg2",
            "Qd1",
            "Qd5+",
            "Kh7",
            "Qe4+",
            "Kg8",
            "Qe8+",
            "Kh7",
            "Qxb8",
            "Qxe1+",
            "Nf1",
            "Qe2",
            "Qg3",
            "Qxb2",
            "Qd3+",
            "Kg8",
            "d5",
            "b4",
            "cxb4",
            "Qxb4",
            "d6",
            "Qb6+",
            "Ne3",
            "Kf7",
            "Qd5+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qe7+",
            "Kc8",
            "d7+",
            "Kb7",
            "d8=Q+",
            "Ka6",
            "Qa3+",
            "Kb5",
            "Qd5+",
            "Qc5",
            "Qdxc5#",
            "Qxc5",
            "Qxc5+",
            "Kxc5",
            "Nf5",
            "g6",
            "Nxh6",
            "Kd5",
            "Kf2",
            "Ke4",
            "Kg3",
            "f5",
            "h4",
            "Ke5",
            "Kf3",
            "Kf6",
            "Kf4",
            "Kg7",
            "Kg5",
            "Kh7",
            "Nf7",
            "Kg7",
            "Ne5",
            "Kh7",
            "Nxg6",
            "Kg7",
            "Kxf5",
            "Kh6",
            "Kg4",
            "Kxg6",
            "h5+",
            "Kh6",
            "Kh4",
            "Kg7",
            "Kg5",
            "Kh7",
            "h6",
            "Kg8",
            "Kg6",
            "Kh8",
            "h7"
          ],
          "plan_execute": [
            "Bb5",
            "a6",
            "Ba4"
          ]
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "e5",
              "dxe5",
              "Bxg2+",
              "Kxg2",
              "Qg4+",
              "Ng3",
              "exf4",
              "Rxe8+",
              "Kxe8",
              "Nxf4",
              "Qxf4",
              "Kg1",
              "Qc1+",
              "Kg2",
              "Qxb2",
              "Kg3",
              "Qxc3+",
              "Kg2",
              "Qxd4",
              "Kg3",
              "b4",
              "Kg2",
              "b3",
              "Kg3",
              "b2",
              "Kg2",
              "b1=Q",
              "Kg3",
              "Qg6+",
              "Kf3",
              "Qde4#"
            ],
            "execute": [
              "Bb5",
              "a6",
              "Ba4"
            ]
          },
          "positional": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Bxf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3",
              "Bg3",
              "Bb7",
              "Qd3",
              "Qd5",
              "f3",
              "Qxf3",
              "Qxf3",
              "Bxf3",
              "Kf2",
              "Bd5",
              "Bd6",
              "f6",
              "Bc5",
              "Kf7",
              "Bd6",
              "Ke6",
              "Bc5",
              "Kf5",
              "Bd6",
              "Ke4",
              "Bc5",
              "g6",
              "Bd6",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3",
              "Kd3",
              "Bc5",
              "Kc2",
              "Bc5",
              "Kd3"
            ],
            "execute": [
              "Bb5",
              "a6",
              "Ba4"
            ]
          },
          "neutral": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qh1",
              "Bb8",
              "Rxe6",
              "Rxe6",
              "Qb7",
              "Re8",
              "Qc6",
              "f6",
              "f3",
              "Bh3",
              "Bf2",
              "Rxe1+",
              "Bxe1",
              "h6",
              "g4",
              "Bxg4",
              "fxg4",
              "Qxg4+",
              "Qg2",
              "Qd1",
              "Qd5+",
              "Kh7",
              "Qe4+",
              "Kg8",
              "Qe8+",
              "Kh7",
              "Qxb8",
              "Qxe1+",
              "Nf1",
              "Qe2",
              "Qg3",
              "Qxb2",
              "Qd3+",
              "Kg8",
              "d5",
              "b4",
              "cxb4",
              "Qxb4",
              "d6",
              "Qb6+",
              "Ne3",
              "Kf7",
              "Qd5+",
              "Ke8",
              "Qe6+",
              "Kd8",
              "Qe7+",
              "Kc8",
              "d7+",
              "Kb7",
              "d8=Q+",
              "Ka6",
              "Qa3+",
              "Kb5",
              "Qd5+",
              "Qc5",
              "Qdxc5#",
              "Qxc5",
              "Qxc5+",
              "Kxc5",
              "Nf5",
              "g6",
              "Nxh6",
              "Kd5",
              "Kf2",
              "Ke4",
              "Kg3",
              "f5",
              "h4",
              "Ke5",
              "Kf3",
              "Kf6",
              "Kf4",
              "Kg7",
              "Kg5",
              "Kh7",
              "Nf7",
              "Kg7",
              "Ne5",
              "Kh7",
              "Nxg6",
              "Kg7",
              "Kxf5",
              "Kh6",
              "Kg4",
              "Kxg6",
              "h5+",
              "Kh6",
              "Kh4",
              "Kg7",
              "Kg5",
              "Kh7",
              "h6",
              "Kg8",
              "Kg6",
              "Kh8",
              "h7"
            ],
            "execute": [
              "Bb5",
              "a6",
              "Ba4"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Bb5",
            "a6",
            "Ba4"
          ],
          "full_moves": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qh1",
            "Bb8",
            "Rxe6",
            "Rxe6",
            "Qb7",
            "Re8",
            "Qc6",
            "f6",
            "f3",
            "Bh3",
            "Bf2",
            "Rxe1+",
            "Bxe1",
            "h6",
            "g4",
            "Bxg4",
            "fxg4",
            "Qxg4+",
            "Qg2",
            "Qd1",
            "Qd5+",
            "Kh7",
            "Qe4+",
            "Kg8",
            "Qe8+",
            "Kh7",
            "Qxb8",
            "Qxe1+",
            "Nf1",
            "Qe2",
            "Qg3",
            "Qxb2",
            "Qd3+",
            "Kg8",
            "d5",
            "b4",
            "cxb4",
            "Qxb4",
            "d6",
            "Qb6+",
            "Ne3",
            "Kf7",
            "Qd5+",
            "Ke8",
            "Qe6+",
            "Kd8",
            "Qe7+",
            "Kc8",
            "d7+",
            "Kb7",
            "d8=Q+",
            "Ka6",
            "Qa3+",
            "Kb5",
            "Qd5+",
            "Qc5",
            "Qdxc5#",
            "Qxc5",
            "Qxc5+",
            "Kxc5",
            "Nf5",
            "g6",
            "Nxh6",
            "Kd5",
            "Kf2",
            "Ke4",
            "Kg3",
            "f5",
            "h4",
            "Ke5",
            "Kf3",
            "Kf6",
            "Kf4",
            "Kg7",
            "Kg5",
            "Kh7",
            "Nf7",
            "Kg7",
            "Ne5",
            "Kh7",
            "Nxg6",
            "Kg7",
            "Kxf5",
            "Kh6",
            "Kg4",
            "Kxg6",
            "h5+",
            "Kh6",
            "Kh4",
            "Kg7",
            "Kg5",
            "Kh7",
            "h6",
            "Kg8",
            "Kg6",
            "Kh8",
            "h7"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 122,
            "completion_tokens": 328,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 121,
            "completion_tokens": 609,
            "total_tokens": 730,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 365,
          "total_completion_tokens": 1577,
          "total_tokens": 1942
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 122,
            "completion_tokens": 328,
            "total_tokens": 450,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 121,
            "completion_tokens": 609,
            "total_tokens": 730,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5 22. c4 bxc4 23. Qxc4 Qh5\n24. Rxc6 Ba5 25. Rxe6 Bxe6 26. Qc5 Qxc5 27. dxc5 Rb8 28. Ra1 Bxd2\n29. Bxd2 Rxb2 30. Ra8+ 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6\n12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8\n17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5\n22. c4 bxc4 23. Qxc4 Qh5 24. Rxc6 Ba5 25. Rxe6 Bxe6 26. Qc5 Qxc5\n27. dxc5 Rb8 28. Ra1 Bxd2 29. Bxd2 Rxb2 30. Ra8+ 1-0 e5 d5 Nf6 Nc6 Bb4 a6 Ba4 b5 Bb3 Na5 O-O Nxb3 cxb3 Be7 Re1 O-O Nxe5 Nxe5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Re6 a4 Qh5 axb5 axb5 Ra6 Bc7 Bxd5 Qxd5 Qc4 Qh5 Rxc6 Ba5 Rxe6 Bxe6 Qc5 Qxc5 Nxc5 Bxb2 Nxb2 Bxb3 Re5 Bc4 Nxc4 bxc4 Rxc5 Rc8 Rxc8# 1-0",
          "aggressive_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 631,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "b5",
            "Bb3",
            "Na5",
            "O-O",
            "Nxb3",
            "cxb3",
            "Be7",
            "Re1",
            "O-O",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bxd5",
            "Qxd5",
            "Qc4",
            "Qh5",
            "Rxc6",
            "Ba5",
            "Rxe6",
            "Bxe6",
            "Qc5",
            "Qxc5",
            "Nxc5",
            "Bxb2",
            "Nxb2",
            "Bxb3",
            "Re5",
            "Bc4",
            "Nxc4",
            "bxc4",
            "Rxc5",
            "Rc8",
            "Rxc8#"
          ],
          "plan_execute": [
            "Ba4",
            "b5",
            "Bb3"
          ]
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5 22. c4 bxc4 23. Qxc4 Qh5\n24. Rxc6 Ba5 25. Rxe6 Bxe6 26. Qc5 Qxc5 27. dxc5 Rb8 28. Ra1 Bxd2\n29. Bxd2 Rxb2 30. Ra8+ 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6\n12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8\n17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5\n22. c4 bxc4 23. Qxc4 Qh5 24. Rxc6 Ba5 25. Rxe6 Bxe6 26. Qc5 Qxc5\n27. dxc5 Rb8 28. Ra1 Bxd2 29. Bxd2 Rxb2 30. Ra8+ 1-0 e5 d5 Nc3 Nf6 Bg5 Be7 O-O Be6 Re1 Qd7 Nbd2 O-O-O b4 Na5 a4 Nc4 Nxc4 Bxc4 Bxc4 dxc4 Qe2 Qe6 a5 Rd7 b6 cxb6 axb6 axb6 Ra8+ Kb7 Ra7+ Kc8 Ra8+ Kb7 Ra7+ Kc8 Ra8+ Kb7 Ra7+ Kc8 Ra8+ 1/2-1/2",
          "positional_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 589,
            "total_tokens": 720,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bxd5",
            "Qxd5",
            "c4",
            "bxc4",
            "Qxc4",
            "Qh5",
            "Rxc6",
            "Ba5",
            "Rxe6",
            "Bxe6",
            "Qc5",
            "Qxc5",
            "dxc5",
            "Rb8",
            "Ra1",
            "Bxd2",
            "Bxd2",
            "Rxb2",
            "Ra8+",
            "e5",
            "d5",
            "Nc3",
            "Nf6",
            "Bg5",
            "Be7",
            "O-O",
            "Be6",
            "Re1",
            "Qd7",
            "Nbd2",
            "O-O-O",
            "b4",
            "Na5",
            "a4",
            "Nc4",
            "Nxc4",
            "Bxc4",
            "Bxc4",
            "dxc4",
            "Qe2",
            "Qe6",
            "a5",
            "Rd7",
            "b6",
            "cxb6",
            "axb6",
            "axb6",
            "Ra8+",
            "Kb7",
            "Ra7+",
            "Kc8",
            "Ra8+",
            "Kb7",
            "Ra7+",
            "Kc8",
            "Ra8+",
            "Kb7",
            "Ra7+",
            "Kc8",
            "Ra8+"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a7a6",
          "neutral_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bb8 21. Bd1 Bxd1 22. Qf1 Bg4 23. c4 bxc4\n24. Nxc4 Bh3 25. Qe2 Qxe2 26. Rxe2 Nb4 27. Rb6 Nd5 28. Ra6 Rfe8\n29. Ra3 Bg4 30. Re1 Bf3 31. Nd2 Bg4 32. Kg2 Bd6 33. Rb3 Bb4\n34. h3 Bxd2 35. Bxd2 Rxe1 36. Bxe1 Be6 37. Ra3 h6 38. Bd2 Rb8\n39. Bc1 Rb4 40. Rd3 Bf5 41. Rd1 Bc2 42. Rd2 Be4+ 43. f3 Bg6\n44. Kf2 Rc4 45. Rd1 Rc2+ 46. Kg1 Nb4 47. b3 Nd3 48. Be3 Re2\n49. Bf4 Nxf4 50. gxf4 Bc2 51. Rc1 Bxb3 52. Rxc6 Bd5 53. Rc3 Rd2\n54. Rc8+ Kh7 55. Rd8 Rxd4 56. Kf2 Rd3 57. Ke2 Bc4 58. Rxd3 Bxd3+\n59. Kxd3 Kg6 60. Ke4 Kh5 61. Kf5 Kh4 62. Ke5 Kxh3 63. f5 Kg3\n64. f4 h5 65. f6 gxf6+ 66. Kxf6 Kxf4 67. Kxf7 h4 68. Kg6 h3\n69. Kh5 h2 70. Kh4 h1=Q# e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 Re1 b5 Bb3 O-O c3 d5 exd5 Nxd5 Rxe5 c6 d4 Bd6 Re1 Qh4 g3 Qh3 Be3 Bg4 Qd3 Rae8 Nd2 Qh5 c4 bxc4 Nxc4 Bh3 c3 Nxc3 Nxc6 Bd5 Qf",
          "neutral_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Qh5",
            "c4",
            "bxc4",
            "Nxc4",
            "Bh3",
            "c3",
            "Nxc3",
            "Nxc6",
            "Bd5"
          ],
          "plan_execute": [
            "Ba4",
            "Nf6",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "a7a6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "b5",
              "Bb3",
              "Na5",
              "O-O",
              "Nxb3",
              "cxb3",
              "Be7",
              "Re1",
              "O-O",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bxd5",
              "Qxd5",
              "Qc4",
              "Qh5",
              "Rxc6",
              "Ba5",
              "Rxe6",
              "Bxe6",
              "Qc5",
              "Qxc5",
              "Nxc5",
              "Bxb2",
              "Nxb2",
              "Bxb3",
              "Re5",
              "Bc4",
              "Nxc4",
              "bxc4",
              "Rxc5",
              "Rc8",
              "Rxc8#"
            ],
            "execute": [
              "Ba4",
              "b5",
              "Bb3"
            ]
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bxd5",
              "Qxd5",
              "c4",
              "bxc4",
              "Qxc4",
              "Qh5",
              "Rxc6",
              "Ba5",
              "Rxe6",
              "Bxe6",
              "Qc5",
              "Qxc5",
              "dxc5",
              "Rb8",
              "Ra1",
              "Bxd2",
              "Bxd2",
              "Rxb2",
              "Ra8+",
              "e5",
              "d5",
              "Nc3",
              "Nf6",
              "Bg5",
              "Be7",
              "O-O",
              "Be6",
              "Re1",
              "Qd7",
              "Nbd2",
              "O-O-O",
              "b4",
              "Na5",
              "a4",
              "Nc4",
              "Nxc4",
              "Bxc4",
              "Bxc4",
              "dxc4",
              "Qe2",
              "Qe6",
              "a5",
              "Rd7",
              "b6",
              "cxb6",
              "axb6",
              "axb6",
              "Ra8+",
              "Kb7",
              "Ra7+",
              "Kc8",
              "Ra8+",
              "Kb7",
              "Ra7+",
              "Kc8",
              "Ra8+",
              "Kb7",
              "Ra7+",
              "Kc8",
              "Ra8+"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Qh5",
              "c4",
              "bxc4",
              "Nxc4",
              "Bh3",
              "c3",
              "Nxc3",
              "Nxc6",
              "Bd5"
            ],
            "execute": [
              "Ba4",
              "Nf6",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "Ba4",
            "Nf6",
            "O-O"
          ],
          "full_moves": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Qh5",
            "c4",
            "bxc4",
            "Nxc4",
            "Bh3",
            "c3",
            "Nxc3",
            "Nxc6",
            "Bd5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 131,
            "completion_tokens": 631,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 131,
            "completion_tokens": 589,
            "total_tokens": 720,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 392,
          "total_completion_tokens": 1860,
          "total_tokens": 2252
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 131,
            "completion_tokens": 631,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 131,
            "completion_tokens": 589,
            "total_tokens": 720,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "4... Nf6 5. O-O Nxe4 6. Re1 d5 7. Bb3 Bc5 8. d4 Nxd4 9. Nxd4 Bxd4 10. Be3 Bxb2 11. Bxd5 Nf6 12. Bg5 Qxd5 13. Bxf6 Qxd1 14. Rxd1 gxf6 15. Nd2 Bxa1 16. Rxa1 Be6 17. Ne4 Ke7 18. Nc5 b6 19. Ne4 Rad8 20. h3 Rd4 21. f3 Rhd8 22. Kh2 Rd1 23. Rxd1 Rxd1 24. a3 Ra1 25. Nc3 Rxa3 26. Ne4 Ra2 27. c3 Bd5 28. Ng3 Bxf3 29. Nf5+ Ke6 30. Ng7+ Kd5 31. Kg3 Bxg2 32. Nf5 Be4 33. Ne3+ Kc5 34. Ng4 Rg2+ 35. Kh4 Rxg4+ 36. hxg4 a5 37. Kh5 a4 38. Kh6 a3 39. Kg7 a2 40. Kxf6 a1=Q 41. Kxe5 Qxc3+ 42. Kxe4 Qd4+ 43. Kf5 Kd5 44. g5 Qe4+ 45. Kf6 Qe6+ 46. Kg7 Qg6+ 47. Kf8 Ke6 48. Ke8 Qg8# e4 Nf6+ Bxf6 exf6 gxf6 Kxf6 Kd5 Kc5 Kd4 Kc4 Kd3 Kc3 Kc2 Kc1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2 Kd1 Kd2",
          "aggressive_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxf6",
            "exf6",
            "gxf6",
            "Kxf6",
            "Kd5",
            "Kc5",
            "Kd4",
            "Kc4",
            "Kd3",
            "Kc3",
            "Kc2",
            "Kc1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2",
            "Kd1",
            "Kd2"
          ],
          "plan_execute": [
            "Bxf6",
            "exf6",
            "gxf6"
          ]
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "4... Nf6 5. d3 Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qf3 Nd4 20. Bxd4 Bxd4 21. c3 Ba7 22. g4 c6 23. gxh5 cxd5 24. cxd5 Qg8+ 25. Kh1 Qg5 26. Rg1 Qxh5 27. Qg3 Rag8 28. Rg2 Rxg3 29. fxg3 Qf3 30. Re1 Bf2 31. Rf1 Rxh2+ 32. Kxh2 Qh5# 33.# e4 e5 Nf3 Nc6 Bb5 a6 Bc4 Nf6 d3 Bc5 O-O O-O Nc3 d6 Bg5 h6 Bh4 g5 Nxg5 hxg5 Bxg5 Be6 Qf3 Kg7 Qg3 Nh5 Qh4 f6 Be3 Bxc4 dxc4 Rh8 Qg4+ Kf7 Nd5 Qc8 Qf3 Nd4 Bxd4 Bxd4 c3 Ba7 g4 c6 gxh5 cxd5 cxd5 Qg8+ Kh1 Qg5 Rg1 Qxh5 Qg3 Rag8 Rg2 Rxg3 fxg3 Qf3 Re1 Bf2 Rf1 Rxh2+ Kxh2 Qh5# 33.#",
          "positional_tokens": {
            "prompt_tokens": 139,
            "completion_tokens": 424,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d3",
            "Bc5",
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qf3",
            "Nd4",
            "Bxd4",
            "Bxd4",
            "c3",
            "Ba7",
            "g4",
            "c6",
            "gxh5",
            "cxd5",
            "cxd5",
            "Qg8+",
            "Kh1",
            "Qg5",
            "Rg1",
            "Qxh5",
            "Qg3",
            "Rag8",
            "Rg2",
            "Rxg3",
            "fxg3",
            "Qf3",
            "Re1",
            "Bf2",
            "Rf1",
            "Rxh2+",
            "Kxh2",
            "Qh5#"
          ],
          "plan_execute": [
            "d3",
            "Bc5",
            "O-O"
          ]
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "4... Nf6 5. d3 Bc5 6. O-O d6 7. c3 O-O 8. Bg5 h6 9. Bh4 g5 10. Bg3 Ba7 11. Nbd2 Nh5 12. Nxe5 Nxg3 13. Nxc6 bxc6 14. hxg3 d5 15. Bb3 Be6 16. d4 c5 17. exd5 Bxd5 18. Bxd5 Qxd5 19. Qh5 Kg7 20. Nf3 cxd4 21. cxd4 Bxd4 22. Rad1 c5 23. b4 Qxa2 24. Nxd4 cxd4 25. Rxd4 Rad8 26. Rfd1 Rxd4 27. Rxd4 Qa1+ 28. Rd1 Qb2 29. Qg4 Rb8 30. Rd4 Re8 31. Qd1 Re2 32. Rd6 Rxf2 33. Qd4+ Qxd4 34. Rxd4 Rb2 35. g4 Kf6 36. Rd6+ Ke5 37. Rxa6 Rxb4 38. Rxh6 Rxg4 39. Kf2 f5 40. Rh8 Ra4 41. Re8+ Kf4 42. g3+ Kg4 43. Re2 Ra3 44. Rb2 Rf3+ 45. Kg2 Rxg3+ 46. Kh2 f4 47. Rb4 Ra3 48. Rb2 Kh4 49. Kg2 g4 50. Kh2 g3+ 51. Kg2 Kg4 52. Rb4 Ra2+ 53. Kg1 Kh3 54. Rb1 f3 55. Kh1 g2+ 56. Kg1 f2# 0-1\n4... Nf6 5. d3 Bc5 6. O-O d6 7. c3 O-O 8. Bg5 h6 9. Bh4 g5 10. Bg3 Ba7 11. Nbd2 Nh5 12. Nxe5 Nxg3 13. Nxc6 bxc6 14. hxg3 d5 15. Bb3 Be6 16. d4 c5 17. exd5 Bxd5 18. Bxd5 Qxd5 19. Qh5 Kg7 20. Nf3 cxd4 21. cxd4 Bxd4 22. Rad1 c5 23. b4 Qxa2 24. Nxd4 cxd4 25. Rxd4 Rad8 26. Rfd1 Rxd4 27. Rxd4 Qa1+ 28. Rd1 Qb2 29",
          "neutral_tokens": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d3",
            "Bc5",
            "O-O",
            "d6",
            "c3",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Ba7",
            "Nbd2",
            "Nh5",
            "Nxe5",
            "Nxg3",
            "Nxc6",
            "bxc6",
            "hxg3",
            "d5",
            "Bb3",
            "Be6",
            "d4",
            "c5",
            "exd5",
            "Bxd5",
            "Bxd5",
            "Qxd5",
            "Qh5",
            "Kg7",
            "Nf3",
            "cxd4",
            "cxd4",
            "Bxd4",
            "Rad1",
            "c5",
            "b4",
            "Qxa2",
            "Nxd4",
            "cxd4",
            "Rxd4",
            "Rad8",
            "Rfd1",
            "Rxd4",
            "Rxd4",
            "Qa1+",
            "Rd1",
            "Qb2"
          ],
          "plan_execute": [
            "d3",
            "Bc5",
            "O-O"
          ]
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf6",
              "exf6",
              "gxf6",
              "Kxf6",
              "Kd5",
              "Kc5",
              "Kd4",
              "Kc4",
              "Kd3",
              "Kc3",
              "Kc2",
              "Kc1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2",
              "Kd1",
              "Kd2"
            ],
            "execute": [
              "Bxf6",
              "exf6",
              "gxf6"
            ]
          },
          "positional": {
            "full": [
              "d3",
              "Bc5",
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qf3",
              "Nd4",
              "Bxd4",
              "Bxd4",
              "c3",
              "Ba7",
              "g4",
              "c6",
              "gxh5",
              "cxd5",
              "cxd5",
              "Qg8+",
              "Kh1",
              "Qg5",
              "Rg1",
              "Qxh5",
              "Qg3",
              "Rag8",
              "Rg2",
              "Rxg3",
              "fxg3",
              "Qf3",
              "Re1",
              "Bf2",
              "Rf1",
              "Rxh2+",
              "Kxh2",
              "Qh5#"
            ],
            "execute": [
              "d3",
              "Bc5",
              "O-O"
            ]
          },
          "neutral": {
            "full": [
              "d3",
              "Bc5",
              "O-O",
              "d6",
              "c3",
              "O-O",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Ba7",
              "Nbd2",
              "Nh5",
              "Nxe5",
              "Nxg3",
              "Nxc6",
              "bxc6",
              "hxg3",
              "d5",
              "Bb3",
              "Be6",
              "d4",
              "c5",
              "exd5",
              "Bxd5",
              "Bxd5",
              "Qxd5",
              "Qh5",
              "Kg7",
              "Nf3",
              "cxd4",
              "cxd4",
              "Bxd4",
              "Rad1",
              "c5",
              "b4",
              "Qxa2",
              "Nxd4",
              "cxd4",
              "Rxd4",
              "Rad8",
              "Rfd1",
              "Rxd4",
              "Rxd4",
              "Qa1+",
              "Rd1",
              "Qb2"
            ],
            "execute": [
              "d3",
              "Bc5",
              "O-O"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "d3",
            "Bc5",
            "O-O"
          ],
          "full_moves": [
            "d3",
            "Bc5",
            "O-O",
            "d6",
            "c3",
            "O-O",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Ba7",
            "Nbd2",
            "Nh5",
            "Nxe5",
            "Nxg3",
            "Nxc6",
            "bxc6",
            "hxg3",
            "d5",
            "Bb3",
            "Be6",
            "d4",
            "c5",
            "exd5",
            "Bxd5",
            "Bxd5",
            "Qxd5",
            "Qh5",
            "Kg7",
            "Nf3",
            "cxd4",
            "cxd4",
            "Bxd4",
            "Rad1",
            "c5",
            "b4",
            "Qxa2",
            "Nxd4",
            "cxd4",
            "Rxd4",
            "Rad8",
            "Rfd1",
            "Rxd4",
            "Rxd4",
            "Qa1+",
            "Rd1",
            "Qb2"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 139,
            "completion_tokens": 424,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 416,
          "total_completion_tokens": 1704,
          "total_tokens": 2120
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 139,
            "completion_tokens": 640,
            "total_tokens": 779,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 139,
            "completion_tokens": 424,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/4p3/2B1P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc5",
          "aggressive_uci": "f8c5",
          "aggressive_response": "5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qxc8 Raxc8 20. Bxc5 dxc5 21. c3 Ne7 22. Ne3 Nf4 23. Rfe1 Rcd8 24. Rad1 Nd3 25. Re2 Nf4 26. Red2 Rxd2 27. Rxd2 Ke6 28. g3 Nh3+ 29. Kg2 Ng5 30. f3 Nf7 31. h4 Nd6 32. b3 f5 33. exf5+ Nexf5 34. Nd5 c6 35. Nb6 Rg8 36. g4 Nxh4+ 37. Kg3 Nhf5+ 38. Kf2 Ne7 39. Na4 b6 40. Nxb6 e4 41. Na4 exf3 42. Nxc5+ Ke5 43. Kxf3 Rf8+ 44. Ke3 Rf4 45. Nd7+ Ke6 46. Kxf4 Kxd7 47. c5 *",
          "aggressive_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 347,
            "total_tokens": 494,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qxc8",
            "Raxc8",
            "Bxc5",
            "dxc5",
            "c3",
            "Ne7",
            "Ne3",
            "Nf4",
            "Rfe1",
            "Rcd8",
            "Rad1",
            "Nd3",
            "Re2",
            "Nf4",
            "Red2",
            "Rxd2",
            "Rxd2",
            "Ke6",
            "g3",
            "Nh3+",
            "Kg2",
            "Ng5",
            "f3",
            "Nf7",
            "h4",
            "Nd6",
            "b3",
            "f5",
            "exf5+",
            "Nexf5",
            "Nd5",
            "c6",
            "Nb6",
            "Rg8",
            "g4",
            "Nxh4+",
            "Kg3",
            "Nhf5+",
            "Kf2",
            "Ne7",
            "Na4",
            "b6",
            "Nxb6",
            "e4",
            "Na4",
            "exf3",
            "Nxc5+",
            "Ke5",
            "Kxf3",
            "Rf8+",
            "Ke3",
            "Rf4",
            "Nd7+",
            "Ke6",
            "Kxf4",
            "Kxd7",
            "c5"
          ],
          "plan_execute": [
            "O-O",
            "O-O",
            "Nc3"
          ]
        },
        "query2": {
          "positional_move": "Bc5",
          "positional_uci": "f8c5",
          "positional_response": "5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Be3 Bxc4 16. dxc4 Rh8 17. Qg4+ Kf7 18. Nd5 Qc8 19. Qf3 Nd4 20. Bxd4 Bxd4 21. c3 Ba7 22. g4 c6 23. gxh5 cxd5 24. cxd5 Qg8+ 25. Kh1 Qg5 26. Rg1 Qxh5 27. Qg3 Rag8 28. Rg2 Rxg3 29. fxg3 Qf3 30. Re1 Bf2 31. Rf1 Rxh2+ 32. Kxh2 Qh5# 0-1\n33. Rh2 Qf3 34. Rg2 Qh5# 0-1",
          "positional_tokens": {
            "prompt_tokens": 147,
            "completion_tokens": 261,
            "total_tokens": 408,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Be3",
            "Bxc4",
            "dxc4",
            "Rh8",
            "Qg4+",
            "Kf7",
            "Nd5",
            "Qc8",
            "Qf3",
            "Nd4",
            "Bxd4",
            "Bxd4",
            "c3",
            "Ba7",
            "g4",
            "c6",
            "gxh5",
            "cxd5",
            "cxd5",
            "Qg8+",
            "Kh1",
            "Qg5",
            "Rg1",
            "Qxh5",
            "Qg3",
            "Rag8",
            "Rg2",
            "Rxg3",
            "fxg3",
            "Qf3",
            "Re1",
            "Bf2",
            "Rf1",
            "Rxh2+",
            "Kxh2",
            "Qh5#",
            "Rh2",
            "Qf3",
            "Rg2",
            "Qh5#"
          ],
          "plan_execute": [
            "O-O",
            "O-O",
            "Nc3"
          ]
        },
        "query3": {
          "neutral_move": "Bc5",
          "neutral_uci": "f8c5",
          "neutral_response": "5... Bc5 6. O-O O-O 7. Nc3 d6 8. Bg5 h6 9. Bh4 g5 10. Nxg5 hxg5 11. Bxg5 Be6 12. Qf3 Kg7 13. Qg3 Nh5 14. Qh4 f6 15. Bxe6 fxg5 16. Qxh5 Qf6 17. Bf5 Rh8 18. Qg4 Rh4 19. Qg3 Rah8 20. Nd5 Qh6 21. h3 Nd4 22. Rae1 Nxf5 23. exf5 g4 24. f6+ Kf7 25. Re4 gxh3 26. Rxh4 Qxh4 27. Qg7+ Ke6 28. Nxc7+ Kf5 29. f7 hxg2 30. f8=Q+ Rxf8 31. Qxf8+ Kg6 32. Qg8+ Kf6 33. Nd5+ Kf5 34. Qf7+ Kg5 35. Qf6+ Kh5 36. Qxh4+ Kxh4 37. Kxg2 Kg4 38. f3+ Kf5 39. Rh1 Ke6 40. c4 b5 41. Rh6+ Kd7 42. b4 Bd4 43. cxb5 axb5 44. Rh7+ Kc6 45. Ne7+ Kd7 46. Nf5+ Ke6 47. Nxd4+ exd4 48. Rh5 d5 49. Kg3 Kd6 50. Kf4 Ke6 51. Rh6+ Kd7 52. Ke5 Ke7 53. Rh7+ Kf8 54. Kf6 Kg8 55. Ra7 Kh8 56. Kg6 Kg8 57. Ra8# Bf8 58. Rxf8# Bf8 59. Rxf8# Kxf8 60. Kf6 Ke8 61. Ke6 Kd8 62. Kxd5 Kc7 63. Kc5 Kb7 64. Kxb5 Ka7 65. Kc6 Ka6 66. b5+ Ka7 67. b6+ Kb8 68. b7 Ka7 69. Kc7 Ka6 70. b8=Q Ka5 71. Qb3 Ka6 72. Qb6# Kd5 73. Qd6# Kc4 74. Qc5# Kd3 75. d5 Ke2 76. d6 Kxf3 77. d7 Ke4 78. d8=Q Kf4 79. Qce7 Kf5 80. Q",
          "neutral_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Bxe6",
            "fxg5",
            "Qxh5",
            "Qf6",
            "Bf5",
            "Rh8",
            "Qg4",
            "Rh4",
            "Qg3",
            "Rah8",
            "Nd5",
            "Qh6",
            "h3",
            "Nd4",
            "Rae1",
            "Nxf5",
            "exf5",
            "g4",
            "f6+",
            "Kf7",
            "Re4",
            "gxh3",
            "Rxh4",
            "Qxh4",
            "Qg7+",
            "Ke6",
            "Nxc7+",
            "Kf5",
            "f7",
            "hxg2",
            "f8=Q+",
            "Rxf8",
            "Qxf8+",
            "Kg6",
            "Qg8+",
            "Kf6",
            "Nd5+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Qf6+",
            "Kh5",
            "Qxh4+",
            "Kxh4",
            "Kxg2",
            "Kg4",
            "f3+",
            "Kf5",
            "Rh1",
            "Ke6",
            "c4",
            "b5",
            "Rh6+",
            "Kd7",
            "b4",
            "Bd4",
            "cxb5",
            "axb5",
            "Rh7+",
            "Kc6",
            "Ne7+",
            "Kd7",
            "Nf5+",
            "Ke6",
            "Nxd4+",
            "exd4",
            "Rh5",
            "d5",
            "Kg3",
            "Kd6",
            "Kf4",
            "Ke6",
            "Rh6+",
            "Kd7",
            "Ke5",
            "Ke7",
            "Rh7+",
            "Kf8",
            "Kf6",
            "Kg8",
            "Ra7",
            "Kh8",
            "Kg6",
            "Kg8",
            "Ra8#",
            "Bf8",
            "Rxf8#",
            "Bf8",
            "Rxf8#",
            "Kxf8",
            "Kf6",
            "Ke8",
            "Ke6",
            "Kd8",
            "Kxd5",
            "Kc7",
            "Kc5",
            "Kb7",
            "Kxb5",
            "Ka7",
            "Kc6",
            "Ka6",
            "b5+",
            "Ka7",
            "b6+",
            "Kb8",
            "b7",
            "Ka7",
            "Kc7",
            "Ka6",
            "b8=Q",
            "Ka5",
            "Qb3",
            "Ka6",
            "Qb6#",
            "Kd5",
            "Qd6#",
            "Kc4",
            "Qc5#",
            "Kd3",
            "d5",
            "Ke2",
            "d6",
            "Kxf3",
            "d7",
            "Ke4",
            "d8=Q",
            "Kf4",
            "Qce7",
            "Kf5"
          ],
          "plan_execute": [
            "O-O",
            "O-O",
            "Nc3"
          ]
        },
        "final_moves": {
          "aggressive_uci": "f8c5",
          "positional_uci": "f8c5",
          "neutral_uci": "f8c5",
          "consensus_move": "f8c5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qxc8",
              "Raxc8",
              "Bxc5",
              "dxc5",
              "c3",
              "Ne7",
              "Ne3",
              "Nf4",
              "Rfe1",
              "Rcd8",
              "Rad1",
              "Nd3",
              "Re2",
              "Nf4",
              "Red2",
              "Rxd2",
              "Rxd2",
              "Ke6",
              "g3",
              "Nh3+",
              "Kg2",
              "Ng5",
              "f3",
              "Nf7",
              "h4",
              "Nd6",
              "b3",
              "f5",
              "exf5+",
              "Nexf5",
              "Nd5",
              "c6",
              "Nb6",
              "Rg8",
              "g4",
              "Nxh4+",
              "Kg3",
              "Nhf5+",
              "Kf2",
              "Ne7",
              "Na4",
              "b6",
              "Nxb6",
              "e4",
              "Na4",
              "exf3",
              "Nxc5+",
              "Ke5",
              "Kxf3",
              "Rf8+",
              "Ke3",
              "Rf4",
              "Nd7+",
              "Ke6",
              "Kxf4",
              "Kxd7",
              "c5"
            ],
            "execute": [
              "O-O",
              "O-O",
              "Nc3"
            ]
          },
          "positional": {
            "full": [
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Be3",
              "Bxc4",
              "dxc4",
              "Rh8",
              "Qg4+",
              "Kf7",
              "Nd5",
              "Qc8",
              "Qf3",
              "Nd4",
              "Bxd4",
              "Bxd4",
              "c3",
              "Ba7",
              "g4",
              "c6",
              "gxh5",
              "cxd5",
              "cxd5",
              "Qg8+",
              "Kh1",
              "Qg5",
              "Rg1",
              "Qxh5",
              "Qg3",
              "Rag8",
              "Rg2",
              "Rxg3",
              "fxg3",
              "Qf3",
              "Re1",
              "Bf2",
              "Rf1",
              "Rxh2+",
              "Kxh2",
              "Qh5#",
              "Rh2",
              "Qf3",
              "Rg2",
              "Qh5#"
            ],
            "execute": [
              "O-O",
              "O-O",
              "Nc3"
            ]
          },
          "neutral": {
            "full": [
              "O-O",
              "O-O",
              "Nc3",
              "d6",
              "Bg5",
              "h6",
              "Bh4",
              "g5",
              "Nxg5",
              "hxg5",
              "Bxg5",
              "Be6",
              "Qf3",
              "Kg7",
              "Qg3",
              "Nh5",
              "Qh4",
              "f6",
              "Bxe6",
              "fxg5",
              "Qxh5",
              "Qf6",
              "Bf5",
              "Rh8",
              "Qg4",
              "Rh4",
              "Qg3",
              "Rah8",
              "Nd5",
              "Qh6",
              "h3",
              "Nd4",
              "Rae1",
              "Nxf5",
              "exf5",
              "g4",
              "f6+",
              "Kf7",
              "Re4",
              "gxh3",
              "Rxh4",
              "Qxh4",
              "Qg7+",
              "Ke6",
              "Nxc7+",
              "Kf5",
              "f7",
              "hxg2",
              "f8=Q+",
              "Rxf8",
              "Qxf8+",
              "Kg6",
              "Qg8+",
              "Kf6",
              "Nd5+",
              "Kf5",
              "Qf7+",
              "Kg5",
              "Qf6+",
              "Kh5",
              "Qxh4+",
              "Kxh4",
              "Kxg2",
              "Kg4",
              "f3+",
              "Kf5",
              "Rh1",
              "Ke6",
              "c4",
              "b5",
              "Rh6+",
              "Kd7",
              "b4",
              "Bd4",
              "cxb5",
              "axb5",
              "Rh7+",
              "Kc6",
              "Ne7+",
              "Kd7",
              "Nf5+",
              "Ke6",
              "Nxd4+",
              "exd4",
              "Rh5",
              "d5",
              "Kg3",
              "Kd6",
              "Kf4",
              "Ke6",
              "Rh6+",
              "Kd7",
              "Ke5",
              "Ke7",
              "Rh7+",
              "Kf8",
              "Kf6",
              "Kg8",
              "Ra7",
              "Kh8",
              "Kg6",
              "Kg8",
              "Ra8#",
              "Bf8",
              "Rxf8#",
              "Bf8",
              "Rxf8#",
              "Kxf8",
              "Kf6",
              "Ke8",
              "Ke6",
              "Kd8",
              "Kxd5",
              "Kc7",
              "Kc5",
              "Kb7",
              "Kxb5",
              "Ka7",
              "Kc6",
              "Ka6",
              "b5+",
              "Ka7",
              "b6+",
              "Kb8",
              "b7",
              "Ka7",
              "Kc7",
              "Ka6",
              "b8=Q",
              "Ka5",
              "Qb3",
              "Ka6",
              "Qb6#",
              "Kd5",
              "Qd6#",
              "Kc4",
              "Qc5#",
              "Kd3",
              "d5",
              "Ke2",
              "d6",
              "Kxf3",
              "d7",
              "Ke4",
              "d8=Q",
              "Kf4",
              "Qce7",
              "Kf5"
            ],
            "execute": [
              "O-O",
              "O-O",
              "Nc3"
            ]
          }
        },
        "final_plan": {
          "moves_for_execution": [
            "O-O",
            "O-O",
            "Nc3"
          ],
          "full_moves": [
            "O-O",
            "O-O",
            "Nc3",
            "d6",
            "Bg5",
            "h6",
            "Bh4",
            "g5",
            "Nxg5",
            "hxg5",
            "Bxg5",
            "Be6",
            "Qf3",
            "Kg7",
            "Qg3",
            "Nh5",
            "Qh4",
            "f6",
            "Bxe6",
            "fxg5",
            "Qxh5",
            "Qf6",
            "Bf5",
            "Rh8",
            "Qg4",
            "Rh4",
            "Qg3",
            "Rah8",
            "Nd5",
            "Qh6",
            "h3",
            "Nd4",
            "Rae1",
            "Nxf5",
            "exf5",
            "g4",
            "f6+",
            "Kf7",
            "Re4",
            "gxh3",
            "Rxh4",
            "Qxh4",
            "Qg7+",
            "Ke6",
            "Nxc7+",
            "Kf5",
            "f7",
            "hxg2",
            "f8=Q+",
            "Rxf8",
            "Qxf8+",
            "Kg6",
            "Qg8+",
            "Kf6",
            "Nd5+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Qf6+",
            "Kh5",
            "Qxh4+",
            "Kxh4",
            "Kxg2",
            "Kg4",
            "f3+",
            "Kf5",
            "Rh1",
            "Ke6",
            "c4",
            "b5",
            "Rh6+",
            "Kd7",
            "b4",
            "Bd4",
            "cxb5",
            "axb5",
            "Rh7+",
            "Kc6",
            "Ne7+",
            "Kd7",
            "Nf5+",
            "Ke6",
            "Nxd4+",
            "exd4",
            "Rh5",
            "d5",
            "Kg3",
            "Kd6",
            "Kf4",
            "Ke6",
            "Rh6+",
            "Kd7",
            "Ke5",
            "Ke7",
            "Rh7+",
            "Kf8",
            "Kf6",
            "Kg8",
            "Ra7",
            "Kh8",
            "Kg6",
            "Kg8",
            "Ra8#",
            "Bf8",
            "Rxf8#",
            "Bf8",
            "Rxf8#",
            "Kxf8",
            "Kf6",
            "Ke8",
            "Ke6",
            "Kd8",
            "Kxd5",
            "Kc7",
            "Kc5",
            "Kb7",
            "Kxb5",
            "Ka7",
            "Kc6",
            "Ka6",
            "b5+",
            "Ka7",
            "b6+",
            "Kb8",
            "b7",
            "Ka7",
            "Kc7",
            "Ka6",
            "b8=Q",
            "Ka5",
            "Qb3",
            "Ka6",
            "Qb6#",
            "Kd5",
            "Qd6#",
            "Kc4",
            "Qc5#",
            "Kd3",
            "d5",
            "Ke2",
            "d6",
            "Kxf3",
            "d7",
            "Ke4",
            "d8=Q",
            "Kf4",
            "Qce7",
            "Kf5"
          ],
          "source_agent": "neutral"
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 147,
            "completion_tokens": 347,
            "total_tokens": 494,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 147,
            "completion_tokens": 261,
            "total_tokens": 408,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 440,
          "total_completion_tokens": 1248,
          "total_tokens": 1688
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 147,
            "completion_tokens": 347,
            "total_tokens": 494,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 147,
            "completion_tokens": 261,
            "total_tokens": 408,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/2B1P3/3P1N2/PPP2PPP/RNBQK2R b KQkq - 0 5"
    }
  ],
  "white_errors": [],
  "black_errors": [],
  "white_plan_log": [
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1,
      "plan_full": [
        "Nf3",
        "Nc6",
        "Bc4",
        "Bc5",
        "d3",
        "d6"
      ],
      "plan_execute": [
        "Nf3",
        "Nc6",
        "Bc4"
      ],
      "selected_move": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "Bc4"
      ],
      "plan_execute": [
        "Bc4"
      ],
      "selected_move": "Nc6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1,
      "plan_full": [
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bc2",
        "c5"
      ],
      "plan_execute": [
        "Ba4",
        "Nf6",
        "O-O"
      ],
      "selected_move": "a6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1,
      "plan_full": [
        "d3",
        "Bc5"
      ],
      "plan_execute": [
        "d3",
        "Bc5"
      ],
      "selected_move": "Nf6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1,
      "plan_full": [
        "b3",
        "b5",
        "Bb3"
      ],
      "plan_execute": [
        "b3",
        "b5",
        "Bb3"
      ],
      "selected_move": "Be7"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 12,
      "attempt": 1,
      "plan_full": [
        "Bc2",
        "d6",
        "Na5",
        "Nxe5"
      ],
      "plan_execute": [
        "Bc2",
        "d6",
        "Na5"
      ],
      "selected_move": "b5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 14,
      "attempt": 1,
      "plan_full": [
        "Na3"
      ],
      "plan_execute": [
        "Na3"
      ],
      "selected_move": "d6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 16,
      "attempt": 1,
      "plan_full": [
        "Bc2",
        "c5",
        "Nbd2"
      ],
      "plan_execute": [
        "Bc2",
        "c5",
        "Nbd2"
      ],
      "selected_move": "Na5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 18,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 18,
      "attempt": 1,
      "plan_full": [
        "b3",
        "Qe7"
      ],
      "plan_execute": [
        "b3",
        "Qe7"
      ],
      "selected_move": "Nc4"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 20,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 20,
      "attempt": 1,
      "plan_full": [
        "b4",
        "a5",
        "Qe7"
      ],
      "plan_execute": [
        "b4",
        "a5",
        "Qe7"
      ],
      "selected_move": "Nb6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "b4",
      "move_uci": "b5b4"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "a5",
      "move_uci": "a6a5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1,
      "plan_full": [
        "e5",
        "Nb1",
        "c3",
        "Nb8",
        "c6",
        "d2",
        "d4"
      ],
      "plan_execute": [
        "e5",
        "Nb1",
        "c3"
      ],
      "selected_move": "e4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 3,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 3,
      "attempt": 1,
      "plan_full": [
        "Nc6",
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "d6",
        "c3",
        "O-O"
      ],
      "plan_execute": [
        "Nc6",
        "Bb5",
        "a6"
      ],
      "selected_move": "Nf3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nc6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Bb5",
      "move_uci": "f1b5"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "a6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 7,
      "attempt": 1,
      "plan_full": [
        "Nf6",
        "d3",
        "d6"
      ],
      "plan_execute": [
        "Nf6",
        "d3",
        "d6"
      ],
      "selected_move": "Bc4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nf6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "d3",
      "move_uci": "d2d3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "d6",
      "actual_san": "Bc5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 11,
      "attempt": 1,
      "plan_full": [
        "b5"
      ],
      "plan_execute": [
        "b5"
      ],
      "selected_move": "Nbd2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "b5",
      "actual_san": "O-O"
    }
  ],
  "black_plan_log": [
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 1,
      "attempt": 1,
      "plan_full": [
        "e5",
        "Nf3",
        "Nc6",
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d6",
        "d4",
        "Bg4",
        "d5",
        "Na5",
        "Bc2",
        "c6",
        "dxc6",
        "Nxc6",
        "Nbd2",
        "d5",
        "h3",
        "Bh5",
        "g4",
        "Bg6",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "Nf4",
        "Bxg6",
        "fxg6",
        "Qf3",
        "Nd3",
        "Qd5+",
        "Qxd5",
        "Rxd5",
        "Nxf2",
        "Kg2",
        "Rae8",
        "Nf3",
        "Nxh3",
        "Kxh3",
        "Rxf3",
        "Kg2",
        "Ref8",
        "Rd2",
        "Bh4",
        "Re2",
        "Rg3+",
        "Kh2",
        "Rxg4",
        "Be3",
        "Re4",
        "Kg2",
        "Rfe8",
        "Kf3",
        "Bg5",
        "Rae1",
        "Rxe3",
        "Rxe3",
        "Rxe3",
        "Rxe3",
        "Bxe3",
        "Kxe3",
        "Kf7",
        "b3",
        "Ke6",
        "c4",
        "bxc4",
        "bxc4",
        "Ke5",
        "a4",
        "a5"
      ],
      "plan_execute": [
        "e5",
        "Nf3",
        "Nc6"
      ],
      "selected_move": "e4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "e5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nf3",
      "move_uci": "g1f3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nc6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 5,
      "attempt": 1,
      "plan_full": [
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "Qf1",
        "Qh5",
        "a4",
        "Rfe8",
        "axb5",
        "axb5",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Qxc6",
        "Bxg3",
        "Qg2",
        "Bf4",
        "Ra8",
        "Bb8",
        "Kh1",
        "Rg6",
        "Bf4",
        "Rxe1+",
        "Nf1",
        "Rxf1+",
        "Qxf1",
        "Bf3+",
        "Qg2",
        "Bxg2+",
        "Kg1",
        "Bxa8+",
        "Kf1",
        "Qd1#",
        "Bb8+",
        "Bc7",
        "Bb6",
        "Bc5"
      ],
      "plan_execute": [
        "a6",
        "Ba4",
        "Nf6"
      ],
      "selected_move": "Bb5"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "a6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Ba4",
      "move_uci": "b5a4"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nf6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 9,
      "attempt": 1,
      "plan_full": [
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "d5",
        "Ne7",
        "Nh4",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qf3",
        "Ng8",
        "Nhf5",
        "Qc7",
        "Qg4",
        "Bxf5",
        "Nxf5",
        "Qc1",
        "Qg7#"
      ],
      "plan_execute": [
        "h3",
        "Na5",
        "Bc2"
      ],
      "selected_move": "O-O"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "h3",
      "actual_san": "Be7"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 11,
      "attempt": 1,
      "plan_full": [
        "b5",
        "Bb3",
        "d6",
        "c3",
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "d5",
        "Ne7",
        "Nh4",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qf3",
        "Ng8",
        "Nhf5",
        "Qb6",
        "Qg4",
        "Bxf5",
        "Nxf5",
        "Be2",
        "Qg7#"
      ],
      "plan_execute": [
        "b5",
        "Bb3",
        "d6"
      ],
      "selected_move": "Re1"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "b5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Bb3",
      "move_uci": "a4b3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "d6"
    },
    {
      "event": "plan_completed",
      "source": "self_consistency",
      "reason": "opponent finished plan"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 15,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "Qd2",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qh6",
        "Rg8",
        "Qxf6+",
        "Rg7",
        "Nh5",
        "Rg8",
        "Ng5",
        "Be8",
        "Nxg7",
        "Rxg7",
        "dxe5",
        "dxe5",
        "Rd1",
        "Qe7",
        "Qxe7",
        "Nxe7",
        "Rd8",
        "Rg8",
        "Nf3",
        "f6",
        "Bd3",
        "Kg7",
        "Rb8",
        "Bc6",
        "Rxg8+",
        "Kxg8",
        "Kf1",
        "Kf7",
        "Ke2",
        "Ke6",
        "Ke3",
        "Kd6",
        "Nd2",
        "Kc5",
        "a3",
        "Ng6",
        "g3",
        "Bd7",
        "h4",
        "Nf8",
        "Nb1",
        "Ne6",
        "Nc3",
        "Nd4",
        "Nd5",
        "f5",
        "Nf6",
        "fxe4",
        "Nxe4+",
        "Kd5",
        "Nf6+",
        "Ke6",
        "Nxd7",
        "Kxd7",
        "Bxh7",
        "Ke6",
        "Bd3",
        "Kf6",
        "f4",
        "Nf5+",
        "Bxf5",
        "Kxf5",
        "fxe5",
        "Kxe5",
        "g4",
        "Kf6",
        "Kd4",
        "Ke6",
        "Kc5",
        "Ke5",
        "Kxb5",
        "Kf4",
        "g5",
        "Kf5",
        "Kxa4",
        "Kg6",
        "Kb5",
        "Kh5",
        "a4",
        "Kg6",
        "a5",
        "Kh5",
        "a6",
        "Kg6",
        "a7",
        "Kh5",
        "a8=Q",
        "Kg6",
        "Qe4+",
        "Kh5",
        "Qf3+",
        "Kg6",
        "Qg4",
        "Kg7",
        "h5",
        "Kh7",
        "Qd7+",
        "Kg8",
        "g6",
        "Kh8",
        "Qh7#",
        "e4",
        "d5",
        "e5",
        "dxe6"
      ],
      "plan_execute": [
        "O-O",
        "h3",
        "Na5"
      ],
      "selected_move": "c3"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "Na5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 17,
      "attempt": 1,
      "plan_full": [
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "O-O",
        "Nf1",
        "Bg4",
        "d5",
        "Nc4",
        "h3",
        "Bd7",
        "b3",
        "Nb6",
        "Ng3",
        "g6",
        "Bh6",
        "Rfe8",
        "Qd2",
        "Bf8",
        "Bxf8",
        "Rxf8",
        "Qh6",
        "Kh8",
        "Ng5",
        "Be8",
        "f4",
        "Rg8",
        "fxe5",
        "dxe5",
        "Rf1",
        "Qd6",
        "Rxf6",
        "Qxf6",
        "Qxh7#"
      ],
      "plan_execute": [
        "c5",
        "d4",
        "Qc7"
      ],
      "selected_move": "Bc2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "c5",
      "actual_san": "Nc4"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 19,
      "attempt": 1,
      "plan_full": [
        "Nb6",
        "Nbd2",
        "O-O",
        "Nf1",
        "c5",
        "Ng3",
        "Qc7",
        "h3",
        "Re8",
        "Be3",
        "Bf8",
        "Rc1",
        "d5",
        "d4",
        "exd4",
        "cxd4",
        "dxe4",
        "Ng5",
        "Bb7",
        "dxc5",
        "Nc4",
        "Bd4",
        "Rad8",
        "N5xe4",
        "Nxe4",
        "Nxe4",
        "Bxc5",
        "Nxc5",
        "Rxe1+",
        "Qxe1",
        "Bc6",
        "Nb3",
        "Qf4",
        "Be3",
        "Qf6",
        "Rd1",
        "Re8",
        "Nd4",
        "Bb7",
        "b3",
        "Nxe3",
        "fxe3",
        "Qg5",
        "Qf2",
        "Rxe3",
        "Nf5",
        "Re8",
        "Nd6",
        "Re7",
        "Nxb7",
        "Rxb7",
        "Qf5",
        "Qe3+",
        "Kh1",
        "g6",
        "Qc8+",
        "Kg7",
        "Qxb7",
        "Qe2",
        "Qe4",
        "Qh5",
        "Qd4+",
        "Kh6",
        "Qf4+",
        "Kg7",
        "Rd7",
        "g5",
        "Qe5+",
        "Kh6",
        "Qf6+",
        "Qg6",
        "Bxg6",
        "hxg6",
        "Qh8#",
        "Nf6",
        "Qxf6",
        "Qxf6",
        "Kh5",
        "Qh8#"
      ],
      "plan_execute": [
        "Nb6",
        "Nbd2",
        "O-O"
      ],
      "selected_move": "d3"
    },
    {
      "event": "plan_opponent_matched",
      "source": "self_consistency",
      "move_san": "Nb6"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "Nbd2",
      "move_uci": "b1d2"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "b4"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 23,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "Nf1",
        "Bg4",
        "h3",
        "Bh5",
        "Ng3",
        "Bg6",
        "Nh4",
        "d5",
        "Nxg6",
        "fxg6",
        "exd5",
        "Nfxd5",
        "Rxe5",
        "Nxb4",
        "Bb3+",
        "Kh8",
        "Qe2",
        "Bf6",
        "Re4",
        "Nxd3",
        "Be3",
        "Nxb2",
        "Rb1",
        "Nd3",
        "Rd1",
        "Nc5",
        "Rxd8",
        "Raxd8",
        "Bxc5",
        "Nd7",
        "Bxf8",
        "Rxf8",
        "Re8",
        "h6",
        "Rxf8+",
        "Nxf8",
        "Qe8",
        "Kh7",
        "Qxf8",
        "g5",
        "Bc2+",
        "g6",
        "Qf7+",
        "Bg7",
        "Bxg6+",
        "Kh8",
        "Qe8+",
        "Bf8",
        "Qxf8#",
        "e4",
        "Nc6",
        "Nc4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4",
        "Nxe4"
      ],
      "plan_execute": [
        "O-O",
        "Nf1",
        "Bg4"
      ],
      "selected_move": "cxb4"
    },
    {
      "event": "plan_aborted",
      "source": "self_consistency",
      "expected_san": "O-O",
      "actual_san": "a5"
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 25,
      "attempt": 1,
      "plan_full": [
        "Rxa5",
        "Nb3",
        "Ra8",
        "d4",
        "exd4",
        "Nbxd4",
        "Bb7",
        "Nf5",
        "O-O",
        "Nxe7+",
        "Qxe7",
        "e5",
        "dxe5",
        "Nxe5",
        "Qc5",
        "Bg5",
        "Nfd5",
        "Qd3",
        "g6",
        "Bh6",
        "Rfe8",
        "Qf3",
        "f5",
        "Bxf5",
        "gxf5",
        "Qg3+",
        "Kh8",
        "Qg7#",
        "Nf6",
        "Nf7#",
        "Kg8",
        "Qxf6",
        "Qf8",
        "Bxf8",
        "Rxf8",
        "Nh6#",
        "Kh8",
        "Qe5#",
        "Kh8",
        "Qxc7#",
        "Kh8",
        "Qxb7#",
        "Kh8",
        "Qxb6#",
        "Kh8",
        "Qd4#",
        "Kh8",
        "Re7#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxh7#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#",
        "Kh8",
        "Qxf8#",
        "Kh8",
        "Qg7#"
      ],
      "plan_execute": [
        "Rxa5",
        "Nb3",
        "Ra8"
      ],
      "selected_move": "bxa5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 2,
      "attempt": 1,
      "plan_full": [
        "Nf3",
        "Nc6",
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "d6",
        "c3",
        "O-O",
        "h3",
        "Na5",
        "Bc2",
        "c5",
        "d4",
        "Qc7",
        "Nbd2",
        "cxd4",
        "cxd4",
        "Nc6",
        "Nb3",
        "a5",
        "Be3",
        "a4",
        "Nbd2",
        "Bd7",
        "Rc1",
        "Qb7",
        "Bb1",
        "Rfc8",
        "Nf1",
        "Bd8",
        "Ng3",
        "Bb6",
        "Qd2",
        "Ba5",
        "Qe2",
        "Bxe1",
        "Rxe1",
        "Re8",
        "Qd2",
        "Rac8",
        "Bg5",
        "Kh8",
        "Bxf6",
        "gxf6",
        "Qh6",
        "Rg8",
        "Qxf6+",
        "Rg7",
        "Nh5",
        "Rg8",
        "Ng5",
        "Be8",
        "Nxg7",
        "Rxg7",
        "dxe5",
        "dxe5",
        "Rd1",
        "Qe7",
        "Qxe7",
        "Nxe7",
        "Rd8",
        "Rg8",
        "Nf3",
        "f6",
        "Bd3",
        "Kg7",
        "Rb8",
        "Bc6",
        "Rxg8+",
        "Kxg8",
        "Kf1",
        "Kf7",
        "Ke2",
        "Ke6",
        "Ke3",
        "Kd6",
        "Nd2",
        "Kc5",
        "a3",
        "Bd7",
        "Nb1",
        "Nc6",
        "Nc3",
        "Nd4",
        "Nd5",
        "f5",
        "Nf6",
        "f4+",
        "Kd2",
        "Be6",
        "Nxh7",
        "b4",
        "Ng5",
        "Bg8",
        "h4",
        "bxa3",
        "bxa3",
        "Nb3+",
        "Kc3",
        "Nd4",
        "h5",
        "Nb5+",
        "Bxb5",
        "Kxb5",
        "h6",
        "Kc5",
        "h7",
        "Bxh7",
        "Nxh7",
        "Kd6",
        "Ng5",
        "Kc5",
        "Nf3",
        "Kd6",
        "Kb4",
        "Ke6",
        "Kxa4",
        "Kd6",
        "Kb5",
        "Ke6",
        "a4",
        "Kd6",
        "a5",
        "Ke6",
        "a6",
        "Kd6",
        "a7",
        "Ke6",
        "a8=Q",
        "Kd6",
        "Qd5+",
        "Ke7",
        "Qxe5+",
        "Kd7",
        "Qxf4",
        "Ke6",
        "Qf5+",
        "Kd6",
        "Qd5+",
        "Ke7",
        "Qc6",
        "Kf7",
        "Qd6",
        "Kg7",
        "Qe6",
        "Kh7",
        "Qf6",
        "Kg8"
      ],
      "plan_execute": [
        "Nf3",
        "Nc6",
        "Bb5"
      ],
      "selected_move": "e5"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 4,
      "attempt": 1,
      "plan_full": [
        "Bb5",
        "a6",
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Nxe5",
        "Nxe5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Re6",
        "a4",
        "Qh5",
        "axb5",
        "axb5",
        "Ra6",
        "Bc7",
        "Qf1",
        "Rfe8",
        "Bxd5",
        "Qxd5",
        "Qg2",
        "Qh5",
        "Rxc6",
        "Bh3",
        "Qf3",
        "Bg4",
        "Qh1",
        "Bb8",
        "Rxe6",
        "Rxe6",
        "Qb7",
        "Re8",
        "Qc6",
        "f6",
        "f3",
        "Bh3",
        "Bf2",
        "Rxe1+",
        "Bxe1",
        "h6",
        "g4",
        "Bxg4",
        "fxg4",
        "Qxg4+",
        "Qg2",
        "Qd1",
        "Qd5+",
        "Kh7",
        "Qe4+",
        "Kg8",
        "Qe8+",
        "Kh7",
        "Qxb8",
        "Qxe1+",
        "Nf1",
        "Qe2",
        "Qg3",
        "Qxb2",
        "Qd3+",
        "Kg8",
        "d5",
        "b4",
        "cxb4",
        "Qxb4",
        "d6",
        "Qb6+",
        "Ne3",
        "Kf7",
        "Qd5+",
        "Ke8",
        "Qe6+",
        "Kd8",
        "Qe7+",
        "Kc8",
        "d7+",
        "Kb7",
        "d8=Q+",
        "Ka6",
        "Qa3+",
        "Kb5",
        "Qd5+",
        "Qc5",
        "Qdxc5#",
        "Qxc5",
        "Qxc5+",
        "Kxc5",
        "Nf5",
        "g6",
        "Nxh6",
        "Kd5",
        "Kf2",
        "Ke4",
        "Kg3",
        "f5",
        "h4",
        "Ke5",
        "Kf3",
        "Kf6",
        "Kf4",
        "Kg7",
        "Kg5",
        "Kh7",
        "Nf7",
        "Kg7",
        "Ne5",
        "Kh7",
        "Nxg6",
        "Kg7",
        "Kxf5",
        "Kh6",
        "Kg4",
        "Kxg6",
        "h5+",
        "Kh6",
        "Kh4",
        "Kg7",
        "Kg5",
        "Kh7",
        "h6",
        "Kg8",
        "Kg6",
        "Kh8",
        "h7"
      ],
      "plan_execute": [
        "Bb5",
        "a6",
        "Ba4"
      ],
      "selected_move": "Nc6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 6,
      "attempt": 1,
      "plan_full": [
        "Ba4",
        "Nf6",
        "O-O",
        "Be7",
        "Re1",
        "b5",
        "Bb3",
        "O-O",
        "c3",
        "d5",
        "exd5",
        "Nxd5",
        "Rxe5",
        "c6",
        "d4",
        "Bd6",
        "Re1",
        "Qh4",
        "g3",
        "Qh3",
        "Be3",
        "Bg4",
        "Qd3",
        "Rae8",
        "Nd2",
        "Qh5",
        "c4",
        "bxc4",
        "Nxc4",
        "Bh3",
        "c3",
        "Nxc3",
        "Nxc6",
        "Bd5"
      ],
      "plan_execute": [
        "Ba4",
        "Nf6",
        "O-O"
      ],
      "selected_move": "a6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 8,
      "attempt": 1,
      "plan_full": [
        "d3",
        "Bc5",
        "O-O",
        "d6",
        "c3",
        "O-O",
        "Bg5",
        "h6",
        "Bh4",
        "g5",
        "Bg3",
        "Ba7",
        "Nbd2",
        "Nh5",
        "Nxe5",
        "Nxg3",
        "Nxc6",
        "bxc6",
        "hxg3",
        "d5",
        "Bb3",
        "Be6",
        "d4",
        "c5",
        "exd5",
        "Bxd5",
        "Bxd5",
        "Qxd5",
        "Qh5",
        "Kg7",
        "Nf3",
        "cxd4",
        "cxd4",
        "Bxd4",
        "Rad1",
        "c5",
        "b4",
        "Qxa2",
        "Nxd4",
        "cxd4",
        "Rxd4",
        "Rad8",
        "Rfd1",
        "Rxd4",
        "Rxd4",
        "Qa1+",
        "Rd1",
        "Qb2"
      ],
      "plan_execute": [
        "d3",
        "Bc5",
        "O-O"
      ],
      "selected_move": "Nf6"
    },
    {
      "event": "plan_replaced",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1
    },
    {
      "event": "plan_generated",
      "source": "self_consistency",
      "turn": 10,
      "attempt": 1,
      "plan_full": [
        "O-O",
        "O-O",
        "Nc3",
        "d6",
        "Bg5",
        "h6",
        "Bh4",
        "g5",
        "Nxg5",
        "hxg5",
        "Bxg5",
        "Be6",
        "Qf3",
        "Kg7",
        "Qg3",
        "Nh5",
        "Qh4",
        "f6",
        "Bxe6",
        "fxg5",
        "Qxh5",
        "Qf6",
        "Bf5",
        "Rh8",
        "Qg4",
        "Rh4",
        "Qg3",
        "Rah8",
        "Nd5",
        "Qh6",
        "h3",
        "Nd4",
        "Rae1",
        "Nxf5",
        "exf5",
        "g4",
        "f6+",
        "Kf7",
        "Re4",
        "gxh3",
        "Rxh4",
        "Qxh4",
        "Qg7+",
        "Ke6",
        "Nxc7+",
        "Kf5",
        "f7",
        "hxg2",
        "f8=Q+",
        "Rxf8",
        "Qxf8+",
        "Kg6",
        "Qg8+",
        "Kf6",
        "Nd5+",
        "Kf5",
        "Qf7+",
        "Kg5",
        "Qf6+",
        "Kh5",
        "Qxh4+",
        "Kxh4",
        "Kxg2",
        "Kg4",
        "f3+",
        "Kf5",
        "Rh1",
        "Ke6",
        "c4",
        "b5",
        "Rh6+",
        "Kd7",
        "b4",
        "Bd4",
        "cxb5",
        "axb5",
        "Rh7+",
        "Kc6",
        "Ne7+",
        "Kd7",
        "Nf5+",
        "Ke6",
        "Nxd4+",
        "exd4",
        "Rh5",
        "d5",
        "Kg3",
        "Kd6",
        "Kf4",
        "Ke6",
        "Rh6+",
        "Kd7",
        "Ke5",
        "Ke7",
        "Rh7+",
        "Kf8",
        "Kf6",
        "Kg8",
        "Ra7",
        "Kh8",
        "Kg6",
        "Kg8",
        "Ra8#",
        "Bf8",
        "Rxf8#",
        "Bf8",
        "Rxf8#",
        "Kxf8",
        "Kf6",
        "Ke8",
        "Ke6",
        "Kd8",
        "Kxd5",
        "Kc7",
        "Kc5",
        "Kb7",
        "Kxb5",
        "Ka7",
        "Kc6",
        "Ka6",
        "b5+",
        "Ka7",
        "b6+",
        "Kb8",
        "b7",
        "Ka7",
        "Kc7",
        "Ka6",
        "b8=Q",
        "Ka5",
        "Qb3",
        "Ka6",
        "Qb6#",
        "Kd5",
        "Qd6#",
        "Kc4",
        "Qc5#",
        "Kd3",
        "d5",
        "Ke2",
        "d6",
        "Kxf3",
        "d7",
        "Ke4",
        "d8=Q",
        "Kf4",
        "Qce7",
        "Kf5"
      ],
      "plan_execute": [
        "O-O",
        "O-O",
        "Nc3"
      ],
      "selected_move": "Bc5"
    },
    {
      "event": "plan_move_used",
      "source": "self_consistency",
      "planned_san": "O-O",
      "move_uci": "e8g8"
    }
  ],
  "timestamp": "2025-11-30T00:38:40.882829",
  "game_id": "meta-llama_llama-3.3-70b-instruct_vs_gpt-3.5-turbo-instruct_SC_plan3_2",
  "configuration": "SC_plan3"
}