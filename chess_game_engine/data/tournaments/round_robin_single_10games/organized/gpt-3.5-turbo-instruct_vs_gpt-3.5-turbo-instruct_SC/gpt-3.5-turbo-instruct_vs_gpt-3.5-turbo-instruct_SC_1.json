{
  "result": "gpt-3.5-turbo-instruct wins by checkmate",
  "white_player": "gpt-3.5-turbo-instruct",
  "black_player": "gpt-3.5-turbo-instruct_SC",
  "white_score": 1.0,
  "black_score": 0.0,
  "total_moves": 57,
  "moves": [
    "e2e4",
    "e7e5",
    "g1f3",
    "b8c6",
    "f1b5",
    "a7a6",
    "b5a4",
    "g8f6",
    "e1g1",
    "f6e4",
    "d2d4",
    "b7b5",
    "a4b3",
    "d7d5",
    "d4e5",
    "c8e6",
    "c2c3",
    "f8c5",
    "b1d2",
    "e4f2",
    "f1f2",
    "c5f2",
    "g1f2",
    "e8g8",
    "d2f1",
    "f7f6",
    "e5f6",
    "d8f6",
    "b3d5",
    "a8d8",
    "c1g5",
    "f6g5",
    "d5e6",
    "g8h8",
    "d1e2",
    "c6e5",
    "f2g1",
    "e5f3",
    "g1h1",
    "f3d2",
    "f1g3",
    "d2c4",
    "e6c4",
    "d8d2",
    "e2e4",
    "b5c4",
    "e4c4",
    "d2b2",
    "c4c7",
    "g5d2",
    "c7c6",
    "d2c3",
    "c6c3",
    "b2b1",
    "a1b1",
    "f8b8",
    "b1b8"
  ],
  "game_history": [
    {
      "move_number": 1,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e4",
      "move_san": "e4",
      "fen_after": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "move_number": 2,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e7e5",
      "move_san": "e5",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "move_number": 3,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1f3",
      "move_san": "Nf3",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "move_number": 4,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "b8c6",
      "move_san": "Nc6",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "move_number": 5,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1b5",
      "move_san": "Bb5",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "move_number": 6,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "a7a6",
      "move_san": "a6",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "move_number": 7,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b5a4",
      "move_san": "Ba4",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "move_number": 8,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "g8f6",
      "move_san": "Nf6",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "move_number": 9,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1g1",
      "move_san": "O-O",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 b kq - 3 5"
    },
    {
      "move_number": 10,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f6e4",
      "move_san": "Nxe4",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n5/4p3/B3n3/5N2/PPPP1PPP/RNBQ1RK1 w kq - 0 6"
    },
    {
      "move_number": 11,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2d4",
      "move_san": "d4",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n5/4p3/B2Pn3/5N2/PPP2PPP/RNBQ1RK1 b kq - 0 6"
    },
    {
      "move_number": 12,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "b7b5",
      "move_san": "b5",
      "fen_after": "r1bqkb1r/2pp1ppp/p1n5/1p2p3/B2Pn3/5N2/PPP2PPP/RNBQ1RK1 w kq - 0 7"
    },
    {
      "move_number": 13,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a4b3",
      "move_san": "Bb3",
      "fen_after": "r1bqkb1r/2pp1ppp/p1n5/1p2p3/3Pn3/1B3N2/PPP2PPP/RNBQ1RK1 b kq - 1 7"
    },
    {
      "move_number": 14,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d7d5",
      "move_san": "d5",
      "fen_after": "r1bqkb1r/2p2ppp/p1n5/1p1pp3/3Pn3/1B3N2/PPP2PPP/RNBQ1RK1 w kq - 0 8"
    },
    {
      "move_number": 15,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d4e5",
      "move_san": "dxe5",
      "fen_after": "r1bqkb1r/2p2ppp/p1n5/1p1pP3/4n3/1B3N2/PPP2PPP/RNBQ1RK1 b kq - 0 8"
    },
    {
      "move_number": 16,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "c8e6",
      "move_san": "Be6",
      "fen_after": "r2qkb1r/2p2ppp/p1n1b3/1p1pP3/4n3/1B3N2/PPP2PPP/RNBQ1RK1 w kq - 1 9"
    },
    {
      "move_number": 17,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c2c3",
      "move_san": "c3",
      "fen_after": "r2qkb1r/2p2ppp/p1n1b3/1p1pP3/4n3/1BP2N2/PP3PPP/RNBQ1RK1 b kq - 0 9"
    },
    {
      "move_number": 18,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f8c5",
      "move_san": "Bc5",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/4n3/1BP2N2/PP3PPP/RNBQ1RK1 w kq - 1 10"
    },
    {
      "move_number": 19,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b1d2",
      "move_san": "Nbd2",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/4n3/1BP2N2/PP1N1PPP/R1BQ1RK1 b kq - 2 10"
    },
    {
      "move_number": 20,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e4f2",
      "move_san": "Nxf2",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/8/1BP2N2/PP1N1nPP/R1BQ1RK1 w kq - 0 11"
    },
    {
      "move_number": 21,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1f2",
      "move_san": "Rxf2",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/8/1BP2N2/PP1N1RPP/R1BQ2K1 b kq - 0 11"
    },
    {
      "move_number": 22,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "c5f2",
      "move_san": "Bxf2+",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1bPP/R1BQ2K1 w kq - 0 12"
    },
    {
      "move_number": 23,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1f2",
      "move_san": "Kxf2",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1KPP/R1BQ4 b kq - 0 12"
    },
    {
      "move_number": 24,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e8g8",
      "move_san": "O-O",
      "fen_after": "r2q1rk1/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1KPP/R1BQ4 w - - 1 13"
    },
    {
      "move_number": 25,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2f1",
      "move_san": "Nf1",
      "fen_after": "r2q1rk1/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP3KPP/R1BQ1N2 b - - 2 13"
    },
    {
      "move_number": 26,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f7f6",
      "move_san": "f6",
      "fen_after": "r2q1rk1/2p3pp/p1n1bp2/1p1pP3/8/1BP2N2/PP3KPP/R1BQ1N2 w - - 0 14"
    },
    {
      "move_number": 27,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e5f6",
      "move_san": "exf6",
      "fen_after": "r2q1rk1/2p3pp/p1n1bP2/1p1p4/8/1BP2N2/PP3KPP/R1BQ1N2 b - - 0 14"
    },
    {
      "move_number": 28,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d8f6",
      "move_san": "Qxf6",
      "fen_after": "r4rk1/2p3pp/p1n1bq2/1p1p4/8/1BP2N2/PP3KPP/R1BQ1N2 w - - 0 15"
    },
    {
      "move_number": 29,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b3d5",
      "move_san": "Bxd5",
      "fen_after": "r4rk1/2p3pp/p1n1bq2/1p1B4/8/2P2N2/PP3KPP/R1BQ1N2 b - - 0 15"
    },
    {
      "move_number": 30,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "a8d8",
      "move_san": "Rad8",
      "fen_after": "3r1rk1/2p3pp/p1n1bq2/1p1B4/8/2P2N2/PP3KPP/R1BQ1N2 w - - 1 16"
    },
    {
      "move_number": 31,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c1g5",
      "move_san": "Bg5",
      "fen_after": "3r1rk1/2p3pp/p1n1bq2/1p1B2B1/8/2P2N2/PP3KPP/R2Q1N2 b - - 2 16"
    },
    {
      "move_number": 32,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f6g5",
      "move_san": "Qxg5",
      "fen_after": "3r1rk1/2p3pp/p1n1b3/1p1B2q1/8/2P2N2/PP3KPP/R2Q1N2 w - - 0 17"
    },
    {
      "move_number": 33,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d5e6",
      "move_san": "Bxe6+",
      "fen_after": "3r1rk1/2p3pp/p1n1B3/1p4q1/8/2P2N2/PP3KPP/R2Q1N2 b - - 0 17"
    },
    {
      "move_number": 34,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "g8h8",
      "move_san": "Kh8",
      "fen_after": "3r1r1k/2p3pp/p1n1B3/1p4q1/8/2P2N2/PP3KPP/R2Q1N2 w - - 1 18"
    },
    {
      "move_number": 35,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1e2",
      "move_san": "Qe2",
      "fen_after": "3r1r1k/2p3pp/p1n1B3/1p4q1/8/2P2N2/PP2QKPP/R4N2 b - - 2 18"
    },
    {
      "move_number": 36,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "c6e5",
      "move_san": "Ne5",
      "fen_after": "3r1r1k/2p3pp/p3B3/1p2n1q1/8/2P2N2/PP2QKPP/R4N2 w - - 3 19"
    },
    {
      "move_number": 37,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f2g1",
      "move_san": "Kg1",
      "fen_after": "3r1r1k/2p3pp/p3B3/1p2n1q1/8/2P2N2/PP2Q1PP/R4NK1 b - - 4 19"
    },
    {
      "move_number": 38,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e5f3",
      "move_san": "Nxf3+",
      "fen_after": "3r1r1k/2p3pp/p3B3/1p4q1/8/2P2n2/PP2Q1PP/R4NK1 w - - 0 20"
    },
    {
      "move_number": 39,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1h1",
      "move_san": "Kh1",
      "fen_after": "3r1r1k/2p3pp/p3B3/1p4q1/8/2P2n2/PP2Q1PP/R4N1K b - - 1 20"
    },
    {
      "move_number": 40,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f3d2",
      "move_san": "Nd2",
      "fen_after": "3r1r1k/2p3pp/p3B3/1p4q1/8/2P5/PP1nQ1PP/R4N1K w - - 2 21"
    },
    {
      "move_number": 41,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1g3",
      "move_san": "Ng3",
      "fen_after": "3r1r1k/2p3pp/p3B3/1p4q1/8/2P3N1/PP1nQ1PP/R6K b - - 3 21"
    },
    {
      "move_number": 42,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d2c4",
      "move_san": "Nc4",
      "fen_after": "3r1r1k/2p3pp/p3B3/1p4q1/2n5/2P3N1/PP2Q1PP/R6K w - - 4 22"
    },
    {
      "move_number": 43,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e6c4",
      "move_san": "Bxc4",
      "fen_after": "3r1r1k/2p3pp/p7/1p4q1/2B5/2P3N1/PP2Q1PP/R6K b - - 0 22"
    },
    {
      "move_number": 44,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d8d2",
      "move_san": "Rd2",
      "fen_after": "5r1k/2p3pp/p7/1p4q1/2B5/2P3N1/PP1rQ1PP/R6K w - - 1 23"
    },
    {
      "move_number": 45,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e4",
      "move_san": "Qe4",
      "fen_after": "5r1k/2p3pp/p7/1p4q1/2B1Q3/2P3N1/PP1r2PP/R6K b - - 2 23"
    },
    {
      "move_number": 46,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "b5c4",
      "move_san": "bxc4",
      "fen_after": "5r1k/2p3pp/p7/6q1/2p1Q3/2P3N1/PP1r2PP/R6K w - - 0 24"
    },
    {
      "move_number": 47,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e4c4",
      "move_san": "Qxc4",
      "fen_after": "5r1k/2p3pp/p7/6q1/2Q5/2P3N1/PP1r2PP/R6K b - - 0 24"
    },
    {
      "move_number": 48,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d2b2",
      "move_san": "Rxb2",
      "fen_after": "5r1k/2p3pp/p7/6q1/2Q5/2P3N1/Pr4PP/R6K w - - 0 25"
    },
    {
      "move_number": 49,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c4c7",
      "move_san": "Qxc7",
      "fen_after": "5r1k/2Q3pp/p7/6q1/8/2P3N1/Pr4PP/R6K b - - 0 25"
    },
    {
      "move_number": 50,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "g5d2",
      "move_san": "Qd2",
      "fen_after": "5r1k/2Q3pp/p7/8/8/2P3N1/Pr1q2PP/R6K w - - 1 26"
    },
    {
      "move_number": 51,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c7c6",
      "move_san": "Qc6",
      "fen_after": "5r1k/6pp/p1Q5/8/8/2P3N1/Pr1q2PP/R6K b - - 2 26"
    },
    {
      "move_number": 52,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d2c3",
      "move_san": "Qxc3",
      "fen_after": "5r1k/6pp/p1Q5/8/8/2q3N1/Pr4PP/R6K w - - 0 27"
    },
    {
      "move_number": 53,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c6c3",
      "move_san": "Qxc3",
      "fen_after": "5r1k/6pp/p7/8/8/2Q3N1/Pr4PP/R6K b - - 0 27"
    },
    {
      "move_number": 54,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "b2b1",
      "move_san": "Rb1+",
      "fen_after": "5r1k/6pp/p7/8/8/2Q3N1/P5PP/Rr5K w - - 1 28"
    },
    {
      "move_number": 55,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a1b1",
      "move_san": "Rxb1",
      "fen_after": "5r1k/6pp/p7/8/8/2Q3N1/P5PP/1R5K b - - 0 28"
    },
    {
      "move_number": 56,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f8b8",
      "move_san": "Rb8",
      "fen_after": "1r5k/6pp/p7/8/8/2Q3N1/P5PP/1R5K w - - 1 29"
    },
    {
      "move_number": 57,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b1b8",
      "move_san": "Rxb8#",
      "fen_after": "1R5k/6pp/p7/8/8/2Q3N1/P5PP/7K b - - 0 29"
    }
  ],
  "final_fen": "1R5k/6pp/p7/8/8/2Q3N1/P5PP/7K b - - 0 29",
  "white_tokens": {
    "prompt_tokens": 6363,
    "completion_tokens": 7666,
    "total_tokens": 14029
  },
  "black_tokens": {
    "prompt_tokens": 19106,
    "completion_tokens": 30428,
    "total_tokens": 49534
  },
  "white_token_log": [
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 103,
        "completion_tokens": 549,
        "total_tokens": 652,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 109,
        "completion_tokens": 466,
        "total_tokens": 575,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 118,
        "completion_tokens": 511,
        "total_tokens": 629,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 126,
        "completion_tokens": 249,
        "total_tokens": 375,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 134,
        "completion_tokens": 640,
        "total_tokens": 774,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "length"
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 142,
        "completion_tokens": 640,
        "total_tokens": 782,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "length"
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 149,
        "completion_tokens": 168,
        "total_tokens": 317,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 157,
        "completion_tokens": 447,
        "total_tokens": 604,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 166,
        "completion_tokens": 154,
        "total_tokens": 320,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 174,
        "completion_tokens": 640,
        "total_tokens": 814,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "length"
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 183,
        "completion_tokens": 640,
        "total_tokens": 823,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "length"
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 193,
        "completion_tokens": 247,
        "total_tokens": 440,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 201,
        "completion_tokens": 216,
        "total_tokens": 417,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 209,
        "completion_tokens": 640,
        "total_tokens": 849,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "length"
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 219,
        "completion_tokens": 237,
        "total_tokens": 456,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 227,
        "completion_tokens": 309,
        "total_tokens": 536,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 237,
        "completion_tokens": 261,
        "total_tokens": 498,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 35,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 246,
        "completion_tokens": 520,
        "total_tokens": 766,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 37,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 254,
        "completion_tokens": 52,
        "total_tokens": 306,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 39,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 263,
        "completion_tokens": 7,
        "total_tokens": 270,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 41,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 271,
        "completion_tokens": 8,
        "total_tokens": 279,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 43,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 279,
        "completion_tokens": 10,
        "total_tokens": 289,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 45,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 287,
        "completion_tokens": 9,
        "total_tokens": 296,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 47,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 296,
        "completion_tokens": 10,
        "total_tokens": 306,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 49,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 305,
        "completion_tokens": 9,
        "total_tokens": 314,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 51,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 314,
        "completion_tokens": 9,
        "total_tokens": 323,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 53,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 324,
        "completion_tokens": 6,
        "total_tokens": 330,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 55,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 334,
        "completion_tokens": 6,
        "total_tokens": 340,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 57,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 343,
        "completion_tokens": 6,
        "total_tokens": 349,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    }
  ],
  "black_token_log": [
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 398,
          "total_tokens": 511,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1678,
        "total_tokens": 2019
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 398,
          "total_tokens": 511,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 640,
          "total_tokens": 761,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 365,
        "total_completion_tokens": 1920,
        "total_tokens": 2285
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 640,
          "total_tokens": 762,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 640,
          "total_tokens": 761,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 495,
          "total_tokens": 626,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 550,
          "total_tokens": 681,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 224,
          "total_tokens": 354,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 392,
        "total_completion_tokens": 1269,
        "total_tokens": 1661
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 495,
          "total_tokens": 626,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 550,
          "total_tokens": 681,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 224,
          "total_tokens": 354,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 137,
          "completion_tokens": 640,
          "total_tokens": 777,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 413,
        "total_completion_tokens": 1920,
        "total_tokens": 2333
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 138,
          "completion_tokens": 640,
          "total_tokens": 778,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 137,
          "completion_tokens": 640,
          "total_tokens": 777,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 146,
          "completion_tokens": 267,
          "total_tokens": 413,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 146,
          "completion_tokens": 470,
          "total_tokens": 616,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 145,
          "completion_tokens": 640,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 437,
        "total_completion_tokens": 1377,
        "total_tokens": 1814
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 146,
          "completion_tokens": 267,
          "total_tokens": 413,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 146,
          "completion_tokens": 470,
          "total_tokens": 616,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 145,
          "completion_tokens": 640,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 432,
          "total_tokens": 586,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 389,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 432,
          "total_tokens": 585,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 1253,
        "total_tokens": 1714
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 432,
          "total_tokens": 586,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 389,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 432,
          "total_tokens": 585,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 162,
          "completion_tokens": 393,
          "total_tokens": 555,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 162,
          "completion_tokens": 366,
          "total_tokens": 528,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 161,
          "completion_tokens": 325,
          "total_tokens": 486,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 485,
        "total_completion_tokens": 1084,
        "total_tokens": 1569
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 162,
          "completion_tokens": 393,
          "total_tokens": 555,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 162,
          "completion_tokens": 366,
          "total_tokens": 528,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 161,
          "completion_tokens": 325,
          "total_tokens": 486,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 309,
          "total_tokens": 480,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 502,
          "total_tokens": 672,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1451,
        "total_tokens": 1963
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 309,
          "total_tokens": 480,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 502,
          "total_tokens": 672,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 316,
          "total_tokens": 494,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 533,
        "total_completion_tokens": 1596,
        "total_tokens": 2129
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 316,
          "total_tokens": 494,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 399,
          "total_tokens": 586,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 300,
          "total_tokens": 487,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 188,
          "total_tokens": 374,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 560,
        "total_completion_tokens": 887,
        "total_tokens": 1447
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 399,
          "total_tokens": 586,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 300,
          "total_tokens": 487,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 188,
          "total_tokens": 374,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 308,
          "total_tokens": 504,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 587,
        "total_completion_tokens": 1588,
        "total_tokens": 2175
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 308,
          "total_tokens": 504,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 640,
          "total_tokens": 835,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 499,
          "total_tokens": 705,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 472,
          "total_tokens": 677,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 617,
        "total_completion_tokens": 1611,
        "total_tokens": 2228
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 499,
          "total_tokens": 705,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 472,
          "total_tokens": 677,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 214,
          "completion_tokens": 225,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 214,
          "completion_tokens": 274,
          "total_tokens": 488,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 213,
          "completion_tokens": 219,
          "total_tokens": 432,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 641,
        "total_completion_tokens": 718,
        "total_tokens": 1359
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 214,
          "completion_tokens": 225,
          "total_tokens": 439,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 214,
          "completion_tokens": 274,
          "total_tokens": 488,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 213,
          "completion_tokens": 219,
          "total_tokens": 432,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 665,
        "total_completion_tokens": 1920,
        "total_tokens": 2585
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 232,
          "completion_tokens": 640,
          "total_tokens": 872,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 232,
          "completion_tokens": 553,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 695,
        "total_completion_tokens": 1833,
        "total_tokens": 2528
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 232,
          "completion_tokens": 640,
          "total_tokens": 872,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 232,
          "completion_tokens": 553,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 240,
          "completion_tokens": 389,
          "total_tokens": 629,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 239,
          "completion_tokens": 76,
          "total_tokens": 315,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 719,
        "total_completion_tokens": 1105,
        "total_tokens": 1824
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 240,
          "completion_tokens": 389,
          "total_tokens": 629,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 239,
          "completion_tokens": 76,
          "total_tokens": 315,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 34,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 229,
          "total_tokens": 480,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 69,
          "total_tokens": 320,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 576,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 752,
        "total_completion_tokens": 874,
        "total_tokens": 1626
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 229,
          "total_tokens": 480,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 69,
          "total_tokens": 320,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 576,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 36,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 259,
          "completion_tokens": 202,
          "total_tokens": 461,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 259,
          "completion_tokens": 204,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 258,
          "completion_tokens": 202,
          "total_tokens": 460,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 776,
        "total_completion_tokens": 608,
        "total_tokens": 1384
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 259,
          "completion_tokens": 202,
          "total_tokens": 461,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 259,
          "completion_tokens": 204,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 258,
          "completion_tokens": 202,
          "total_tokens": 460,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 38,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 266,
          "completion_tokens": 204,
          "total_tokens": 470,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 266,
          "completion_tokens": 204,
          "total_tokens": 470,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 265,
          "completion_tokens": 66,
          "total_tokens": 331,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 797,
        "total_completion_tokens": 474,
        "total_tokens": 1271
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 266,
          "completion_tokens": 204,
          "total_tokens": 470,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 266,
          "completion_tokens": 204,
          "total_tokens": 470,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 265,
          "completion_tokens": 66,
          "total_tokens": 331,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 40,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 276,
          "completion_tokens": 65,
          "total_tokens": 341,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 276,
          "completion_tokens": 31,
          "total_tokens": 307,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 275,
          "completion_tokens": 102,
          "total_tokens": 377,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 827,
        "total_completion_tokens": 198,
        "total_tokens": 1025
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 276,
          "completion_tokens": 65,
          "total_tokens": 341,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 276,
          "completion_tokens": 31,
          "total_tokens": 307,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 275,
          "completion_tokens": 102,
          "total_tokens": 377,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 42,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 283,
          "completion_tokens": 103,
          "total_tokens": 386,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 283,
          "completion_tokens": 103,
          "total_tokens": 386,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 282,
          "completion_tokens": 102,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 848,
        "total_completion_tokens": 308,
        "total_tokens": 1156
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 283,
          "completion_tokens": 103,
          "total_tokens": 386,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 283,
          "completion_tokens": 103,
          "total_tokens": 386,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 282,
          "completion_tokens": 102,
          "total_tokens": 384,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 44,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 292,
          "completion_tokens": 151,
          "total_tokens": 443,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 292,
          "completion_tokens": 151,
          "total_tokens": 443,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 291,
          "completion_tokens": 67,
          "total_tokens": 358,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 875,
        "total_completion_tokens": 369,
        "total_tokens": 1244
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 292,
          "completion_tokens": 151,
          "total_tokens": 443,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 292,
          "completion_tokens": 151,
          "total_tokens": 443,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 291,
          "completion_tokens": 67,
          "total_tokens": 358,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 46,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 300,
          "completion_tokens": 355,
          "total_tokens": 655,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 300,
          "completion_tokens": 640,
          "total_tokens": 940,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 299,
          "completion_tokens": 112,
          "total_tokens": 411,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 899,
        "total_completion_tokens": 1107,
        "total_tokens": 2006
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 300,
          "completion_tokens": 355,
          "total_tokens": 655,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 300,
          "completion_tokens": 640,
          "total_tokens": 940,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 299,
          "completion_tokens": 112,
          "total_tokens": 411,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 48,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 309,
          "completion_tokens": 563,
          "total_tokens": 872,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 309,
          "completion_tokens": 473,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 308,
          "completion_tokens": 351,
          "total_tokens": 659,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 926,
        "total_completion_tokens": 1387,
        "total_tokens": 2313
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 309,
          "completion_tokens": 563,
          "total_tokens": 872,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 309,
          "completion_tokens": 473,
          "total_tokens": 782,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 308,
          "completion_tokens": 351,
          "total_tokens": 659,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 50,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 318,
          "completion_tokens": 262,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 318,
          "completion_tokens": 245,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 317,
          "completion_tokens": 245,
          "total_tokens": 562,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 953,
        "total_completion_tokens": 752,
        "total_tokens": 1705
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 318,
          "completion_tokens": 262,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 318,
          "completion_tokens": 245,
          "total_tokens": 563,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 317,
          "completion_tokens": 245,
          "total_tokens": 562,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 52,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 327,
          "completion_tokens": 32,
          "total_tokens": 359,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 327,
          "completion_tokens": 31,
          "total_tokens": 358,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 326,
          "completion_tokens": 30,
          "total_tokens": 356,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 980,
        "total_completion_tokens": 93,
        "total_tokens": 1073
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 327,
          "completion_tokens": 32,
          "total_tokens": 359,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 327,
          "completion_tokens": 31,
          "total_tokens": 358,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 326,
          "completion_tokens": 30,
          "total_tokens": 356,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 54,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 337,
          "completion_tokens": 24,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 337,
          "completion_tokens": 24,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 336,
          "completion_tokens": 249,
          "total_tokens": 585,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1010,
        "total_completion_tokens": 297,
        "total_tokens": 1307
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 337,
          "completion_tokens": 24,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 337,
          "completion_tokens": 24,
          "total_tokens": 361,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 336,
          "completion_tokens": 249,
          "total_tokens": 585,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 56,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 347,
          "completion_tokens": 248,
          "total_tokens": 595,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 347,
          "completion_tokens": 255,
          "total_tokens": 602,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 346,
          "completion_tokens": 248,
          "total_tokens": 594,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1040,
        "total_completion_tokens": 751,
        "total_tokens": 1791
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 347,
          "completion_tokens": 248,
          "total_tokens": 595,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 347,
          "completion_tokens": 255,
          "total_tokens": 602,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 346,
          "completion_tokens": 248,
          "total_tokens": 594,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    }
  ],
  "white_responses": [
    {
      "turn": 1,
      "attempt": 1,
      "raw_response": "1. e4 e5\n2. Nf3 Nc6\n3. Bb5 a6\n4. Ba4 Nf6\n5. O-O Be7\n6. Re1 b5\n7. Bb3 d6\n8. c3 O-O\n9. h3 Na5\n10. Bc2 c5\n11. d4 Qc7\n12. Nbd2 cxd4\n13. cxd4 Nc6\n14. Nb3 a5\n15. Be3 a4\n16. Nbd2 Bd7\n17. Rc1 Qb7\n18. Bb1 Rfc8\n19. Nf1 Bd8\n20. Ng3 Bb6\n21. Qd2 Ba5\n22. Qe2 Bxe1\n23. Rxe1 Re8\n24. d5 Ne7\n25. Nh4 Rac8\n26. Bg5 Kh8\n27. Bxf6 gxf6\n28. Qh5 Rg8\n29. Qxf7 Rg7\n30. Qxf6 Ng8\n31. Qxd6 Re8\n32. Nhf5 Rg6\n33. Qb4 Qb6\n34. Bd3 Nf6\n35. Rc1 Bxf5\n36. Nxf5 Reg8\n37. Bf1 Nh5\n38. Rc6 Rxc6\n39. dxc6 Qxc6\n40. Ne7 Qc1\n41. Nxg8 Kxg8\n42. Qxb5 Nf4\n43. Qc4+ Qxc4\n44. Bxc4+ Kg7\n45. b4 axb3\n46. axb3 Kf6\n47. Kh2 Ke7\n48. g3 Ng6\n49. Kg2 Kd6\n50. Kf3 Kc5\n51. Kg4 Kd4\n52. Kf5 Ne7+\n53. Ke6 Nc6\n54. Bd5 Nb4\n55. f4 exf4\n56. gxf4 Nd3\n57. f5 Nf4+\n58. Kd6 Nxh3\n59. b4 Nf4\n60. b5 Nd3\n61. b6 Nc5\n62. b7 Nxb7+\n63. Bxb7 h5\n64. Ke6 h4\n65. Kxf6 h3\n66. e5 h2\n67. e6 1-0\n\nBlack to move: h7",
      "predicted_san": "e4",
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "raw_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Bb7\n10. d4 Re8 11. Nbd2 Bf8 12. a4 h6\n13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5\n16. d5 Nd7 17. Ra3 c4 18. Nd4 Qf6\n19. N2f3 Nc5 20. axb5 Nbd3 21. Bxd3 Nxd3\n22. Rxd3 cxd3 23. Qxd3 axb5 24. Qxb5 Ba6\n25. Qb3 Reb8 26. Qe3 Bc4 27. b3 Bb5\n28. Bb2 Bd7 29. Bc3 Qd8 30. Nd2 Qb6\n31. Qg3 Rc8 32. Nc4 Qc5 33. Nc6 Bxc6\n34. dxc6 Rxc6 35. Rd1 Qb5 36. Bb2 Rb8\n37. Rd3 Qa6 38. Kh2 Qa2 39. Bd4 Qb1\n40. Nd2 Qc2 41. Nc4 Rb5 42. Na3 Rg5\n43. Nxc2 Rxg3 44. Rxg3 Rxc2 45. Rc3 Rb2\n46. Kg3 f6 47. Kf3 Kf7 48. Ke3 Ke6\n49. Kd3 d5 50. Rc6+ Kd7 51. exd5 Rxb3+\n52. Ke4 Bd6 53. Ra6 Rb7 54. Kf5 Ke7\n55. Kg6 Kf8 56. Rxd6 1-0\n56... Rb4",
      "predicted_san": "Nf3",
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "raw_response": "3. Bb5 Nf6 4. O-O Nxe4 5. d4 Nd6 6. Bxc6 dxc6 7. dxe5 Nf5 8. Qxd8+ Kxd8 9. Nc3 Ke8 10. h3 h5 11. Bf4 Be7 12. Rad1 Be6 13. Ng5 Rh6 14. Nxe6 Rxe6 15. g4 hxg4 16. hxg4 Nh4 17. Rd3 Rd8 18. Rfd1 Rxd3 19. Rxd3 Ng6 20. Bg3 Nxe5 21. Bxe5 Rxe5 22. Kg2 Bb4 23. Kf3 Bxc3 24. Rxc3 Ke7 25. Kf4 Re2 26. f3 f6 27. Kf5 Kf7 28. Kf4 g5+ 29. Kg3 Ke6 30. f4 gxf4+ 31. Kxf4 Re5 32. Rh3 Re2 33. Rc3 Kd5 34. Kf5 Rf2+ 35. Kg6 c5 36. Rd3+ Kc6 37. Rc3 b5 38. b4 c4 39. a4 a6 40. axb5+ axb5 41. Kf7 Kd5 42. Ke7 Kd4 43. Rh3 Rxc2 44. Kxf6 Rf2+ 45. Ke6 c3 46. g5 c2 47. Rh1 Kc3 48. g6 Rg2 49. Kf7 Kb2 50. g7 c1=Q 51. Rxc1 Kxc1 52. g8=Q Rxg8 53. Kxg8 Kc2 54. Kf7 Kc3 55. Ke6 Kxb4 56. Kd5 c5 57. Ke4 Kc3 58. Kd5 c4 59. Kc5 b4 60. Kb5 b3 61. Ka4 b2 62. Ka3 b1=Q 63. Ka4 Qb4#\n64. Ka5 Kd4+",
      "predicted_san": "Bb5",
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "raw_response": "4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1#",
      "predicted_san": "Ba4",
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "raw_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Nb4 17. Bb1 Bd7 18. a3 Nc6 19. Bd3 Qb7 20. Rc1 Rfc8 21. Qe2 Rab8 22. d5 Na5 23. Nh2 Bd8 24. f4 Bb6 25. fxe5 dxe5 26. Nhf3 Bxe3+ 27. Qxe3 Re8 28. Rc5 Qb6 29. Rec1 Nb7 30. R5c3 Qxe3+ 31. Kh1 Qb6 32. Rc7 Rbc8 33. Rxc8 Rxc8 34. Rxc8+ Bxc8 35. Nxe5 Qd4 36. Ndf3 Qxb2 37. Nc6 Bd7 38. Ne7+ Kf8 39. Nc6 Bxc6 40. dxc6 Nd6 41. e5 Qc1+ 42. Kh2 Qxc6 43. exf6 gxf6 44. Bxh7 f5 45. Nh4 Qe4 46. Nf3 Kg7 47. Ng5 Qf4+ 48. g3 Qxg5 49. Bxf5 Qxf5 50. h4 Qf2+ 51. Kh3 Ne4 52. Kg4 f5+ 53. Kh5 Nxg3+ 54. Kg5 Qe3# 55. h5 Qh6+ 56. Kh4 Qxh5+ 57. Kxg3 Qg4+ 58. Kf2 f4 59. Ke1 Qg2 60. Kd1 f3 61. Kc1 f2 62. Kd1 f1=Q# 63. Kc2 Qc4+ 64. Kd1 Qgf1# 65. Kd2 Qfe2# 66. Kc1 Qe1# 67. Kc2 Qc3+ 68. Kb1 Q4b3# 69. Kc1 Qxa3+ 70. Kd1 Qab3+ 71. Kc1 Qbc3+ 72. Kb1 Qb3+ 73. Kc1 Qa3+ 74. Kd1 Qab3+ 75. Kc1 Qc3+ 76. Kb1 Qb3+ 77. Kc1 Qa3+ 78. Kd",
      "predicted_san": "O-O",
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "raw_response": "6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Qb6 19. Kh1 c5 20. Nb3 Nxf3 21. Qxd5+ Kh8 22. gxf3 Bxf3+ 23. Qxf3 Rxf3 24. Rg1 Qc6 25. Rg2 Rf1# 26. Kh2 Qd6+ 27. Kh3 Rh1+ 28. Kg4 h5+ 29. Kf3 Rf1+ 30. Rf2 Qd5+ 31. Kg3 Qxg5+ 32. Kh3 Rh1+ 33. Rh2 Qg4# 34. Kh4 Rxh2# 35. Kg3 Qh4+ 36. Kf3 Rf2# 37. Kg3 Qf4+ 38. Kh3 Rh2# 39. Kg3 h4# 40. Kg4 Rg2+ 41. Kh5 Qg5# 42. Bg6 Qxg6+ 43. Kxh4 Qg4# 44. Kh3 Qg3# 45. Kh4 Qg4# 46. Kh3 Qg3# 47. Kh4 Qg4# 48. Kh3 Qg3# 49. Kh4 Qg4# 50. Kh3 Qg3# 51. Kh4 Qg4# 52. Kh3 Qg3# 53. Kh4 Qg4# 54. Kh3 Qg3# 55. Kh4 Qg4# 56. Kh3 Qg3# 57. Kh4 Qg4# 58. Kh3 Qg3# 59. Kh4 Qg4# 60. Kh3 Qg3# 61. Kh4 Qg4# 62. Kh3 Qg3# 63. Kh4 Qg4# 64. Kh3 Qg3# 65. Kh4 Qg4# 66. Kh3 Qg3# 67. Kh4 Qg4# 68. Kh3 Qg3# 69. Kh4 Qg4# 70. Kh3 Qg3# 71. Kh4 Qg4# 72. Kh3 Qg3# 73. Kh4 Qg4# 74. Kh3 Qg3# 75. Kh4 Qg4# 76. Kh3 Qg3# 77. Kh4 Qg4#",
      "predicted_san": "d4",
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n5/4p3/B3n3/5N2/PPPP1PPP/RNBQ1RK1 w kq - 0 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "raw_response": "7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Be3 Qxg2# 0-1\n25. Qxe2 Qxe2",
      "predicted_san": "Bb3",
      "board_fen": "r1bqkb1r/2pp1ppp/p1n5/1p2p3/B2Pn3/5N2/PPP2PPP/RNBQ1RK1 w kq - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "raw_response": "8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Bxf3 21. gxf3 Qf2 22. Qxd5+ Kh8 23. Be4 Qxb2 24. Rg1 Qxc3 25. Bd2 Qe5 26. Qd3 Rd8 27. Qc2 Qd4 28. Bc3 Qd7 29. Bxg7+ Qxg7 30. Rxg7 Kxg7 31. Qxc7+ Kf6 32. Qxh7 Ke5 33. Qg7+ Kf4 34. Qh6+ Ke5 35. Qxa6 Rg8 36. Qxb5+ Kf4 37. Qf5+ Ke3 38. Qc5+ Kf4 39. Qc1+ Ke5 40. a4 Rc8 41. Qe3 Rcd8 42. Bh7+ Kf6 43. Bxg8 Rxg8 44. a5 Rg5 45. Qxg5+ Kxg5 46. a6 Kf4 47. a7 Kxf3 48. a8=Q+ Kf2 49. Qg2+ Ke3 50. h4 Kf4 51. h5 Ke3 52. h6 Kf4 53. h7 Ke3 54. h8=Q Kf4 55. Qf6+ Ke3 56. Qgf2+ Ke4 57. Q6d4# Qe5",
      "predicted_san": "dxe5",
      "board_fen": "r1bqkb1r/2p2ppp/p1n5/1p1pp3/3Pn3/1B3N2/PPP2PPP/RNBQ1RK1 w kq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "raw_response": "9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Qb6 19. Kh1 c5 20. Nb3 Nxf3 21. Qxd5+ Kh8 22. gxf3 Bxf3+ 23. Qxf3 Rxf3 24. Rg1 Qc6 25. Rg2 Rf1# 26. Bg1 Re2",
      "predicted_san": "c3",
      "board_fen": "r2qkb1r/2p2ppp/p1n1b3/1p1pP3/4n3/1B3N2/PPP2PPP/RNBQ1RK1 w kq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "raw_response": "10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Qb6 19. Kh1 c5 20. Nb3 Nxf3 21. Qxd5+ Kh8 22. gxf3 Bxf3+ 23. Qxf3 Rxf3 24. Rg1 Qc6 25. Rg2 Rf1# 26. Kh2 Qd6+ 27. Kh3 Rh1+ 28. Kg4 h5+ 29. Kf3 Rf1+ 30. Rf2 Qd5+ 31. Kg3 Qxg5+ 32. Kh3 Rh1+ 33. Rh2 Qg4# 34. Kh4 Rxh2# 35. Kg5 Re5# 36. Kg6 Qg4+ 37. Kf7 Rf2+ 38. Bf5 Rfxf5# 39. Nxc5 Rxf5# 40. Ne6 Rxf5# 41. Ke7 Rxe6+ 42. Kxe6 Qe4+ 43. Kd6 Rd5+ 44. Kc6 Qe6+ 45. Kb7 Rd7+ 46. Kc8 Qe8# 47. Bd8 Qxd8# 48. Kb7 Qc7+ 49. Kxa6 Qc6+ 50. Ka5 Ra7# 51. Kb4 Ra4# 52. Kb3 Qc4# 53. Kc2 Qe2+ 54. Kb3 Qd1# 55. Ka3 b4# 56. cxb4 cxb4# 57. Kxb4 Rb8+ 58. Ka5 Qd5+ 59. Kxa6 Qb5+ 60. Ka7 Qb6# 61. Ka8 Qb7# 62. Ka7 Qa8# 63. Kb6 Qb7# 64. Ka5 Qb5# 65. axb5 Rxb5+ 66. Ka4 Rxb2 67. Ka3 Rb8 68. Ka4 h4 69. Ka5 h3 70. Ka6 h2 71. Ka7 Rb1 72. Ka6 h1=Q 73. Ka5 Qa8# 74. Kb4 Qc6 75. Ka3 Qxc3+ 76. Ka4 Qb4# 77. Ka6 Qb6# 78. axb6 Rxb6+ 79. Kxb6 h1=Q 80. Kc5 Qd1 81. Kc4 g",
      "predicted_san": "Nbd2",
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/4n3/1BP2N2/PP3PPP/RNBQ1RK1 w kq - 1 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "raw_response": "11. Rxf2 O-O 12. Bc2 f6 13. exf6 Qxf6 14. Nb3 Bxf2+ 15. Kxf2 Ne5 16. Nd4 Bg4 17. Kg1 c5 18. Nb3 Nxf3+ 19. gxf3 Bxf3 20. Qd2 Rae8 21. Qf2 Re2 22. Qg3 Rg2+ 23. Qxg2 Bxg2 24. Kxg2 Qf3+ 25. Kg1 Qf1# 26. Kh2 Rf2+ 27. Kg3 Qg2+ 28. Kh4 Qxh2+ 29. Kg4 Qg1+ 30. Kh5 Rh2# 31. Bxh7+ Kxh7 32. Bf4 g6# 33. Kh4 g5+ 34. Kh5 gxf4# 35. Rxg1 f3 36. Rf1 f2 37. Nxc5 Kg7 38. Nxa6 Kf6 39. Nc7 Ke5 40. Nxb5 Ke4 41. Nd4 Ke3 42. Kg4 Rg2+ 43. Kh3 Rg1 44. Nf5+ Ke2 45. Ng3+ Kf3 46. Kh2 Rxg3 47. Rxf2+ Kxf2 48. a4 Rg4 49. Kh3 Rxa4 50. b4 Ra3 51. Kg4 Rxc3 52. Kf5 d4 53. Ke4 d3 54. Kd4 d2 55. Kxc3 d1=Q 56. Kc4 Qd6 57. Kb5 Ke3 58. Ka5 Kd4 59. b5 Kc5 60. Ka4 Qd3 61. b6 Qb5+ 62. Ka3 Kc4 63. Ka2 Kc3 64. Ka1 Qb2# 65. b7 Qa3+ 66. Kb1 Qb3+ 67. Ka1 Qxb7 68. Ka2 Qb2# 69. Ka1 Qa3+ 70. Kb1 Qb3+ 71. Ka1 Qb2# 72. Kb1 Qa3 73. Kb1 Qb3+ 74. Ka1 Qb2# 75. Kb1 Qa3 76. Kb1 Qb3+ 77. Ka1 Qb2# 78. Kb1 Qa3 79. Kb1 Qb3+ 80. Ka1 Qb2# 81. Kb1 Qa3 82. Kb1 Qb3+ 83. Ka1 Qb2# 84. Kb1 Qa3 85. Kb",
      "predicted_san": "Rxf2",
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/8/1BP2N2/PP1N1nPP/R1BQ1RK1 w kq - 0 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "raw_response": "12. Kxf2 O-O 13. Nf1 f6 14. exf6 Qxf6 15. Kg1 Ne5 16. Bxd5 Rad8 17. Bxe6+ Qxe6 18. Qe2 Nxf3+ 19. Qxf3 Rxf3 20. gxf3 Rd1 21. Kf2 Qe1+ 22. Kg2 Qxf1+ 23. Kg3 Rxc1 24. Rxc1 Qxc1 25. b3 Qxc3 26. h4 Qb2 27. a4 Qxb3 28. axb5 axb5 29. h5 Qd5 30. h6 gxh6 31. f4 b4 32. f5 b3 33. f6 b2 34. f7+ Kxf7 35. Kf4 b1=Q 36. Ke3 Qbe4+ 37. Kf2 Qdf5+ 38. Kg3 Qeg4+ 39. Kh2 Qfh5#\n40. Kh1 Qhh3",
      "predicted_san": "Kxf2",
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1bPP/R1BQ2K1 w kq - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "raw_response": "13. Nf1 f6 14. exf6 Qxf6 15. Kg1 Ne5 16. Bxd5 Rad8 17. Bxe6+ Qxe6 18. Qe2 Nxf3+ 19. Qxf3 Rxf3 20. gxf3 Rd1 21. Kf2 Qe1+ 22. Kg2 Qxf1+ 23. Kg3 Rxc1 24. Rxc1 Qxc1 25. b3 Qxc3 26. h4 Qb2 27. a4 Qxb3 28. axb5 axb5 29. h5 Qd5 30. Kg4 b4 31. f4 b3 32. f5 b2 33. h6 b1=Q 34. hxg7 Qbxf5+ 35. Kg3 Qdf3+ 36. Kh2 Q5h3+ 37. Kg1 Qff1#",
      "predicted_san": "Nf1",
      "board_fen": "r2q1rk1/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1KPP/R1BQ4 w - - 1 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "raw_response": "14. exf6 Qxf6 15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Rd1 Rxd1 22. Kxd1 Kf7 23. Ke2 Ke6 24. Nd2 Kd5 25. Nf3 Re8 26. Kd3 c5 27. b3 c4+ 28. bxc4+ bxc4+ 29. Kd2 Rb8 30. Kc2 Re8 31. Kd2 Rb8 32. Kc2 Re8 33. Bd4 Re2+ 34. Nd2 Rxg2 35. h4 g6 36. Kd1 Rh2 37. Bf6 Rh1+ 38. Kc2 Ra1 39. Kb2 Rd1 40. Kc2 Ra1 41. Kb2 Rd1 42. Kc2 Ra1 43. Kb2 Rd1 44. Kc2 Ra1 45. Kb2 Rd1 46. Kc2 Ra1 47. Kb2 Rd1 48. Kc2 Ra1 49. Kb2 Rd1 50. Kc2 Ra1 51. Kb2 Rd1 52. Kc2 Ra1 53. Kb2 Rd1 54. Kc2 Ra1 55. Kb2 Rd1 56. Kc2 Ra1 57. Kb2 Rd1 58. Kc2 Ra1 59. Kb2 Rd1 60. Kc2 Ra1 61. Kb2 Rd1 62. Kc2 Ra1 63. Kb2 Rd1 64. Kc2 Ra1 65. Kb2 Rd1 66. Kc2 Ra1 67. Kb2 Rd1 68. Kc2 Ra1 69. Kb2 Rd1 70. Kc2 Ra1 71. Kb2 Rd1 72. Kc2 Ra1 73. Kb2 Rd1 74. Kc2 Ra1 75. Kb2 Rd1 76. Kc2 Ra1 77. Kb2 Rd1 78. Kc2 Ra1 79. Kb2 Rd1 80. Kc2 Ra1 81. Kb2 Rd1 82. Kc2 Ra1 83. Kb2 Rd1 84. Kc2 Ra1 85. Kb2 Rd1 86. Kc2 Ra1 87. Kb2 Rd1 88. Kc2 Ra1 89. Kb2 Rd1 90. Kc2 Ra1 91. Kb2 Rd1 92. Kc2 Ra1 93. Kb2 Rd1 94. Kc2 Ra1 95. Kb2 Rd1",
      "predicted_san": "exf6",
      "board_fen": "r2q1rk1/2p3pp/p1n1bp2/1p1pP3/8/1BP2N2/PP3KPP/R1BQ1N2 w - - 0 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "raw_response": "15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Rd1 Rxd1 22. Kxd1 c5 23. Kd2 c4 24. Ng3 Kf7 25. Bd4 Re6 26. Nf5 g6 27. Ne3 h5 28. b3 cxb3 29. axb3 a5 30. c4 bxc4 31. Nxc4 Ra6 32. Bc3 a4 33. b4 a3 34. Kc2 a2 35. Ba1 Ke6 36. Kb3 Kd5 37. Na5 Re6 38. Kxa2 Re2+ 39. Kb3 Rxg2 40. b5 Rxh2 41. b6 Rh1 42. b7 Rb1+ 43. Bb2 * Rxb2+",
      "predicted_san": "Bxd5",
      "board_fen": "r4rk1/2p3pp/p1n1bq2/1p1p4/8/1BP2N2/PP3KPP/R1BQ1N2 w - - 0 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "raw_response": "16. Bg5 Qf7 17. Bxd8 Rxd8 18. Bxe6 Qxe6 19. Qe2 Qf6 20. Re1 h6 21. Qe6+ Qxe6\n22. Rxe6 Rd6 23. Rxd6 cxd6 24. Ne3 Kf7 25. Nd4 Ne5 26. Ke2 Kf6 27. Nd5+ Kg5 28. Nc7\nNc4 29. b3 Ne5 30. Nxa6 Kf4 31. Nxb5 d5 32. Nac7 Ke4 33. Nd6+ Kf4 34. Nxd5+ Kg5\n35. a4 Nc6 36. b4 Kg6 37. b5 Na5 38. b6 Kh7 39. b7 Nxb7 40. Nxb7 g5 41. a5 Kg6\n42. a6 Kf5 43. a7 Ke5 44. a8=Q Kxd5 45. Qa5+ Kc6 46. Qc5+ Kxb7 47. Kd3 Ka6\n48. Qb4 Ka7 49. Kc4 Ka6 50. Kc5 Ka7 51. Kc6 Ka8 52. Qb7# B1b3",
      "predicted_san": "Bg5",
      "board_fen": "3r1rk1/2p3pp/p1n1bq2/1p1B4/8/2P2N2/PP3KPP/R1BQ1N2 w - - 1 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "raw_response": "17. Bxe6+ Kh8 18. Qe2 Rde8 19. Re1 Qc5+ 20. Qe3 Qd6 21. Kg1 Rf6 22. Ng5 Nd8 23. Qh3\nh6 24. Ne4 Rfxe6 25. Nxd6 Rxe1 26. Nxe8 Rxe8 27. Qd7 Rf8 28. Qxc7 Ne6 29. Qd6\nRf6 30. Qxa6 Nf4 31. Qxb5 Kh7 32. a4 Rg6 33. g3 Nh3+ 34. Kg2 Ng5 35. a5 Rf6\n36. a6 Ne4 37. a7 Rf2+ 38. Kg1 Rf8 39. Qd3 Re8 40. a8=Q Rxa8 41. Qxe4+ g6\n42. Qxa8 h5 43. Qf8 g5 44. Ne3 h4 45. Nf5 Kg6 46. g4 h3 47. Qg7# Qg8",
      "predicted_san": "Bxe6+",
      "board_fen": "3r1rk1/2p3pp/p1n1b3/1p1B2q1/8/2P2N2/PP3KPP/R2Q1N2 w - - 0 17"
    },
    {
      "turn": 35,
      "attempt": 1,
      "raw_response": "18. Qe2 Qc5+ 19. Qe3 Qd6 20. Re1 Rde8 21. Kg1 Nd8 22. Ng5 h6 23. Qh3 Qc5+ 24. Kh1\nQxg5 25. Qd3 Rxe6 26. Rd1 Rd6 27. Qe2 Rxd1 28. Qxd1 Qf4 29. Ng3 Ne6 30. Qe1 Ng5\n31. Kg1 Qd6 32. Kh1 Qd3 33. Kg1 Rd8 34. Nf1 Qd1 35. Qe7 Qd6 36. Qe3 Qb6 37. Qxb6\ncxb6 38. Kf2 Ne4+ 39. Ke3 Nc5 40. Nd2 Na4 41. b3 Nxc3 42. a3 Nd5+ 43. Ke2 Nf4+\n44. Ke3 Nxg2+ 45. Ke2 Nf4+ 46. Ke3 Rxd2 47. Kxd2 g5 48. Ke3 Kg7 49. Kf3 Kf6 50.\nKe4 Ke6 51. Kd4 h5 52. Ke4 Nd5 53. Kd4 g4 54. Ke4 h4 55. Kd3 g3 56. hxg3 hxg3\n57. Ke2 Ke5 58. Kf3 Kd4 59. Kxg3 Kc3 60. Kf3 Kxb3 61. Ke4 Kxa3 62. Kxd5 b4 63.\nKc4 b3 64. Kc3 b2 65. Kc2 Ka2 66. Kc3 b1=Q 67. Kd4 Qb5 68. Ke4 Qc5 69. Kd3 Kb3\n70. Ke4 Kc3 71. Kf4 Kd3 72. Kf3 Qf5+ 73. Kg3 Ke3 74. Kg2 Qg4+ 75. Kf1 Qg5 76.\nKe1 Qg1# 77. Ke2 Qg2+ 78. Kd1 Qd2# 79. Kxd2 b5",
      "predicted_san": "Qe2",
      "board_fen": "3r1r1k/2p3pp/p1n1B3/1p4q1/8/2P2N2/PP3KPP/R2Q1N2 w - - 1 18"
    },
    {
      "turn": 37,
      "attempt": 1,
      "raw_response": "19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1#",
      "predicted_san": "Kg1",
      "board_fen": "3r1r1k/2p3pp/p3B3/1p2n1q1/8/2P2N2/PP2QKPP/R4N2 w - - 3 19"
    },
    {
      "turn": 39,
      "attempt": 1,
      "raw_response": "20. Kh1 Nd2",
      "predicted_san": "Kh1",
      "board_fen": "3r1r1k/2p3pp/p3B3/1p4q1/8/2P2n2/PP2Q1PP/R4NK1 w - - 0 20"
    },
    {
      "turn": 41,
      "attempt": 1,
      "raw_response": "21. Ng3 Rfe8",
      "predicted_san": "Ng3",
      "board_fen": "3r1r1k/2p3pp/p3B3/1p4q1/8/2P5/PP1nQ1PP/R4N1K w - - 2 21"
    },
    {
      "turn": 43,
      "attempt": 1,
      "raw_response": "22. Bxc4 bxc4",
      "predicted_san": "Bxc4",
      "board_fen": "3r1r1k/2p3pp/p3B3/1p4q1/2n5/2P3N1/PP2Q1PP/R6K w - - 4 22"
    },
    {
      "turn": 45,
      "attempt": 1,
      "raw_response": "23. Qe4 bxc4",
      "predicted_san": "Qe4",
      "board_fen": "5r1k/2p3pp/p7/1p4q1/2B5/2P3N1/PP1rQ1PP/R6K w - - 1 23"
    },
    {
      "turn": 47,
      "attempt": 1,
      "raw_response": "24. Qxc4 Rxb2",
      "predicted_san": "Qxc4",
      "board_fen": "5r1k/2p3pp/p7/6q1/2p1Q3/2P3N1/PP1r2PP/R6K w - - 0 24"
    },
    {
      "turn": 49,
      "attempt": 1,
      "raw_response": "25. Qxc7 Qd2",
      "predicted_san": "Qxc7",
      "board_fen": "5r1k/2p3pp/p7/6q1/2Q5/2P3N1/Pr4PP/R6K w - - 0 25"
    },
    {
      "turn": 51,
      "attempt": 1,
      "raw_response": "26. Qc6 Rxa2",
      "predicted_san": "Qc6",
      "board_fen": "5r1k/2Q3pp/p7/8/8/2P3N1/Pr1q2PP/R6K w - - 1 26"
    },
    {
      "turn": 53,
      "attempt": 1,
      "raw_response": "27. Qxc3",
      "predicted_san": "Qxc3",
      "board_fen": "5r1k/6pp/p1Q5/8/8/2q3N1/Pr4PP/R6K w - - 0 27"
    },
    {
      "turn": 55,
      "attempt": 1,
      "raw_response": "28. Rxb1",
      "predicted_san": "Rxb1",
      "board_fen": "5r1k/6pp/p7/8/8/2Q3N1/P5PP/Rr5K w - - 1 28"
    },
    {
      "turn": 57,
      "attempt": 1,
      "raw_response": "29. Rxb8",
      "predicted_san": "Rxb8",
      "board_fen": "1r5k/6pp/p7/8/8/2Q3N1/P5PP/1R5K w - - 1 29"
    }
  ],
  "black_responses": [
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Bc6\n39. Rxg8+ Kxg8 40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6\n43. Nd2 Kc5 44. a3 Bd7 45. Nb1 Nc6 46. Nc3 Nd4\n47. Nd5 f5 48. Nf6 f4+ 49. Kd2 Be6 50. Nxh7 b4\n51. Ng5 Bg8 52. h4 bxa3 53. bxa3 Nb3+ 54. Kc3 Nd4\n55. h5 Nb5+ 56. Bxb5 Kxb5 57. h6 Kc5 58. h7 Bxh7\n59. Nxh7 Kd6 60. Kb4 Ke6 61. Kxa4 Kf7 62. Kb5 Kg6\n63. a4 Kxh7 64. a5 Kg6 65. a6 Kg5 66. a7 Kg4\n67. a8=Q f3 68. Qg8+ Kf4 69. Qg3+ Kxe4 70. Qxf3+ Kd4\n71. Qe3+ Kd5 72. g4 Ke6 73. g5 Kf5 74. g6 Kxg6\n75. Qxe5 Kf7 76. f4 Kg6 77. f5+ Kf7 78. f6 Kg6\n79",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Nc6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "Kd2",
            "Be6",
            "Nxh7",
            "b4",
            "Ng5",
            "Bg8",
            "h4",
            "bxa3",
            "bxa3",
            "Nb3+",
            "Kc3",
            "Nd4",
            "h5",
            "Nb5+",
            "Bxb5",
            "Kxb5",
            "h6",
            "Kc5",
            "h7",
            "Bxh7",
            "Nxh7",
            "Kd6",
            "Kb4",
            "Ke6",
            "Kxa4",
            "Kf7",
            "Kb5",
            "Kg6",
            "a4",
            "Kxh7",
            "a5",
            "Kg6",
            "a6",
            "Kg5",
            "a7",
            "Kg4",
            "a8=Q",
            "f3",
            "Qg8+",
            "Kf4",
            "Qg3+",
            "Kxe4",
            "Qxf3+",
            "Kd4",
            "Qe3+",
            "Kd5",
            "g4",
            "Ke6",
            "g5",
            "Kf5",
            "g6",
            "Kxg6",
            "Qxe5",
            "Kf7",
            "f4",
            "Kg6",
            "f5+",
            "Kf7",
            "f6",
            "Kg6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7\n6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5\n11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5\n15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1\n23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5 Kh8 26. Bxf6 gxf6\n27. Qh6 Rg8 28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7 34. Qxe7 Nxe7\n35. Rd8 Rg8 36. Nf3 f6 37. Bd3 Kg7 38. Rb8 Kf7\n39. Bxb5 Bxb5 40. Rxb5 Rc8 41. Rb4 Rc1+ 42. Kh2 Rc2\n43. Kg3 Ng6 44. Ne1 Re2 45. Nd3 Rd2 46. Nc5 Nf4\n47. Nxa4 Nd3 48. Rb7+ Kg6 49. f3 Nf4 50. Kh2 Rxg2+\n51. Kh1 Rf2 52. Nc3 Rxf3 53. a4 Rxh3+ 54. Kg1 Rd3\n55. a5 Rd6 56. Rb6 Rd7 57. a6 Ra7 58. Nb5 Ra8\n59. a7 Nd3 60. Rb8 Rxa7 61. Nxa7 Nc5 62. b4 Nxe4\n63. b5 Nd6 64. b6 Kf5 65. Rd8 Nb7 66. Rd7 Nc5\n67. Rxh7 Ke6 68. b7 Nxb7 69. Rxb7 Kd5 70. Kf2 Ke4\n71. Rb4+ Kd5 72. Ke3 f5 73. Rb5+ Ke6 74. Nc6 Kd6\n75. Nxe5 Ke6 76. Kf4 Kf6 77. Rb6+ Ke7 78. Kxf5 Kd8\n79. Rb7 Kc8",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Kf7",
            "Bxb5",
            "Bxb5",
            "Rxb5",
            "Rc8",
            "Rb4",
            "Rc1+",
            "Kh2",
            "Rc2",
            "Kg3",
            "Ng6",
            "Ne1",
            "Re2",
            "Nd3",
            "Rd2",
            "Nc5",
            "Nf4",
            "Nxa4",
            "Nd3",
            "Rb7+",
            "Kg6",
            "f3",
            "Nf4",
            "Kh2",
            "Rxg2+",
            "Kh1",
            "Rf2",
            "Nc3",
            "Rxf3",
            "a4",
            "Rxh3+",
            "Kg1",
            "Rd3",
            "a5",
            "Rd6",
            "Rb6",
            "Rd7",
            "a6",
            "Ra7",
            "Nb5",
            "Ra8",
            "a7",
            "Nd3",
            "Rb8",
            "Rxa7",
            "Nxa7",
            "Nc5",
            "b4",
            "Nxe4",
            "b5",
            "Nd6",
            "b6",
            "Kf5",
            "Rd8",
            "Nb7",
            "Rd7",
            "Nc5",
            "Rxh7",
            "Ke6",
            "b7",
            "Nxb7",
            "Rxb7",
            "Kd5",
            "Kf2",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Ke3",
            "f5",
            "Rb5+",
            "Ke6",
            "Nc6",
            "Kd6",
            "Nxe5",
            "Ke6",
            "Kf4",
            "Kf6",
            "Rb6+",
            "Ke7",
            "Kxf5",
            "Kd8",
            "Rb7",
            "Kc8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Bb7\n10. d4 Re8 11. Nbd2 Bf8 12. a4 h6\n13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5\n16. d5 Nd7 17. Ra3 c4 18. Nd4 Qf6\n19. N2f3 Nc5 20. axb5 Nbd3 21. Bxd3 Nxd3\n22. Rxd3 cxd3 23. Qxd3 axb5 24. Nxb5 Ba6\n25. Nfd4 Reb8 26. Qb3 Bxb5 27. Nxb5 Ra5\n28. Qc3 Raxb5 29. Qxf6 gxf6\n30. Re2 Rc8 31. Be3 f5 32. exf5 Rxd5\n33. g4 Bg7 34. Kg2 Rb5 35. Rd2 d5\n36. Bd4 Bxd4 37. Rxd4 Rc4 38. Rd2 Rcb4\n39. Kg3 Kg7 40. f3 Kf6 41. h4 Ke5\n42. Re2+ Kd6 43. Re8 Rxb2 44. Rh8 d4\n45. Rxh6+ Ke7 46. Kf4 d3 47. Ke3 d2\n48. Ke2 Re5+ 49. Kd1 Re1# d2 e6 f4",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 398,
            "total_tokens": 511,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Bb7",
            "d4",
            "Re8",
            "Nbd2",
            "Bf8",
            "a4",
            "h6",
            "Bc2",
            "exd4",
            "cxd4",
            "Nb4",
            "Bb1",
            "c5",
            "d5",
            "Nd7",
            "Ra3",
            "c4",
            "Nd4",
            "Qf6",
            "N2f3",
            "Nc5",
            "axb5",
            "Nbd3",
            "Bxd3",
            "Nxd3",
            "Rxd3",
            "cxd3",
            "Qxd3",
            "axb5",
            "Nxb5",
            "Ba6",
            "Nfd4",
            "Reb8",
            "Qb3",
            "Bxb5",
            "Nxb5",
            "Ra5",
            "Qc3",
            "Raxb5",
            "Qxf6",
            "gxf6",
            "Re2",
            "Rc8",
            "Be3",
            "f5",
            "exf5",
            "Rxd5",
            "g4",
            "Bg7",
            "Kg2",
            "Rb5",
            "Rd2",
            "d5",
            "Bd4",
            "Bxd4",
            "Rxd4",
            "Rc4",
            "Rd2",
            "Rcb4",
            "Kg3",
            "Kg7",
            "f3",
            "Kf6",
            "h4",
            "Ke5",
            "Re2+",
            "Kd6",
            "Re8",
            "Rxb2",
            "Rh8",
            "d4",
            "Rxh6+",
            "Ke7",
            "Kf4",
            "d3",
            "Ke3",
            "d2",
            "Ke2",
            "Re5+",
            "Kd1",
            "Re1#",
            "d2",
            "e6",
            "f4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Bd7",
              "Nb1",
              "Nc6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "f4+",
              "Kd2",
              "Be6",
              "Nxh7",
              "b4",
              "Ng5",
              "Bg8",
              "h4",
              "bxa3",
              "bxa3",
              "Nb3+",
              "Kc3",
              "Nd4",
              "h5",
              "Nb5+",
              "Bxb5",
              "Kxb5",
              "h6",
              "Kc5",
              "h7",
              "Bxh7",
              "Nxh7",
              "Kd6",
              "Kb4",
              "Ke6",
              "Kxa4",
              "Kf7",
              "Kb5",
              "Kg6",
              "a4",
              "Kxh7",
              "a5",
              "Kg6",
              "a6",
              "Kg5",
              "a7",
              "Kg4",
              "a8=Q",
              "f3",
              "Qg8+",
              "Kf4",
              "Qg3+",
              "Kxe4",
              "Qxf3+",
              "Kd4",
              "Qe3+",
              "Kd5",
              "g4",
              "Ke6",
              "g5",
              "Kf5",
              "g6",
              "Kxg6",
              "Qxe5",
              "Kf7",
              "f4",
              "Kg6",
              "f5+",
              "Kf7",
              "f6",
              "Kg6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Kf7",
              "Bxb5",
              "Bxb5",
              "Rxb5",
              "Rc8",
              "Rb4",
              "Rc1+",
              "Kh2",
              "Rc2",
              "Kg3",
              "Ng6",
              "Ne1",
              "Re2",
              "Nd3",
              "Rd2",
              "Nc5",
              "Nf4",
              "Nxa4",
              "Nd3",
              "Rb7+",
              "Kg6",
              "f3",
              "Nf4",
              "Kh2",
              "Rxg2+",
              "Kh1",
              "Rf2",
              "Nc3",
              "Rxf3",
              "a4",
              "Rxh3+",
              "Kg1",
              "Rd3",
              "a5",
              "Rd6",
              "Rb6",
              "Rd7",
              "a6",
              "Ra7",
              "Nb5",
              "Ra8",
              "a7",
              "Nd3",
              "Rb8",
              "Rxa7",
              "Nxa7",
              "Nc5",
              "b4",
              "Nxe4",
              "b5",
              "Nd6",
              "b6",
              "Kf5",
              "Rd8",
              "Nb7",
              "Rd7",
              "Nc5",
              "Rxh7",
              "Ke6",
              "b7",
              "Nxb7",
              "Rxb7",
              "Kd5",
              "Kf2",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Ke3",
              "f5",
              "Rb5+",
              "Ke6",
              "Nc6",
              "Kd6",
              "Nxe5",
              "Ke6",
              "Kf4",
              "Kf6",
              "Rb6+",
              "Ke7",
              "Kxf5",
              "Kd8",
              "Rb7",
              "Kc8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Bb7",
              "d4",
              "Re8",
              "Nbd2",
              "Bf8",
              "a4",
              "h6",
              "Bc2",
              "exd4",
              "cxd4",
              "Nb4",
              "Bb1",
              "c5",
              "d5",
              "Nd7",
              "Ra3",
              "c4",
              "Nd4",
              "Qf6",
              "N2f3",
              "Nc5",
              "axb5",
              "Nbd3",
              "Bxd3",
              "Nxd3",
              "Rxd3",
              "cxd3",
              "Qxd3",
              "axb5",
              "Nxb5",
              "Ba6",
              "Nfd4",
              "Reb8",
              "Qb3",
              "Bxb5",
              "Nxb5",
              "Ra5",
              "Qc3",
              "Raxb5",
              "Qxf6",
              "gxf6",
              "Re2",
              "Rc8",
              "Be3",
              "f5",
              "exf5",
              "Rxd5",
              "g4",
              "Bg7",
              "Kg2",
              "Rb5",
              "Rd2",
              "d5",
              "Bd4",
              "Bxd4",
              "Rxd4",
              "Rc4",
              "Rd2",
              "Rcb4",
              "Kg3",
              "Kg7",
              "f3",
              "Kf6",
              "h4",
              "Ke5",
              "Re2+",
              "Kd6",
              "Re8",
              "Rxb2",
              "Rh8",
              "d4",
              "Rxh6+",
              "Ke7",
              "Kf4",
              "d3",
              "Ke3",
              "d2",
              "Ke2",
              "Re5+",
              "Kd1",
              "Re1#",
              "d2",
              "e6",
              "f4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 398,
            "total_tokens": 511,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1678,
          "total_tokens": 2019
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 398,
            "total_tokens": 511,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Bb7 10. d4 Re8 11. Nbd2 Bf8 12. a4 h6 13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5 16. d5 Nd7 17. Ra3 c4 18. Nd4 Qf6 19. N2f3 Nc5 20. axb5 axb5 21. Nxb5 Nbd3 22. Bxd3 Nxd3 23. Rxd3 cxd3 24. Nc7 Ba6 25. Nxe8 Rxe8 26. Qa4 Ra8 27. Qc6 Qd8 28. Bd2 Qc8 29. Rc1 Qxc6 30. Rxc6 Bb5 31. Rb6 Ba4 32. Nd4 Bd1 33. f3 Ra1 34. Kf2 Rb1 35. Ke3 Bc2 36. Rb8 g6 37. Bb4 Kg7 38. Bc3 Kg8 39. Nc6 f5 40. exf5 gxf5 41. Ne7+ Kf7 42. Nxf5 h5 43. g4 hxg4 44. hxg4 Rh1 45. Rb7+ Kg6 46. Rb8 Kf7 47. Rb7+ Kg6 48. Rb8 Kf7 49. Rb7+ Kg6 50. Rb8 Kf7 51. Rb7+ Kg6 52. Rb8 Kf7 53. Rb7+ Kg6 54. Rb8 Kf7 55. Rb7+ Kg6 56. Rb8 Kf7 57. Rb7+ Kg6 58. Rb8 Kf7 59. Rb7+ Kg6 60. Rb8 Kf7 61. Rb7+ Kg6 62. Rb8 Kf7 63. Rb7+ Kg6 64. Rb8 Kf7 65. Rb7+ Kg6 66. Rb8 Kf7 67. Rb7+ Kg6 68. Rb8 Kf7 69. Rb7+ Kg6 70. Rb8 Kf7 71. Rb7+ Kg6 72. Rb8 Kf7 73. Rb7+ Kg6 74. Rb8 Kf7 75. Rb7+ Kg6 76. Rb8 Kf7 77. Rb",
          "aggressive_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f5",
            "exf5",
            "gxf5",
            "Ne7+",
            "Kf7",
            "Nxf5",
            "h5",
            "g4",
            "hxg4",
            "hxg4",
            "Rh1",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Rb8",
            "Kf7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1\nRg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ 33. Qe1 Qd3+ 34. Qe2 Bg2+ 35. Ke1 Qb1+ 36. Qd1 Re6+ 37. Be3 Qxb2 38. Qd2 Qb1+ 39. Qd1 Qe4 40. Qd2 Bf4 41. Kd1 Bxe3 42. fxe3 Qb1+ 43. Qc1 Bf3+ 44. Kd2 Qa2+ 45. Qc2 Qc4 46. Qd3 Qa2+ 47. Qc2 Qa1 48. Qc1 Qa4 49. Qc2 Qc4 50. Qd3 Qa2+ 51. Qc2 Qa1 52. Qc1 Qa4 53. Qc2 Qa3 54. Qc1 Qa2+ 55. Qc2 Qa1 56. Qc1 Qa4 57. Qc2 Qa3 58. Qc1 Qa2+ 59. Qc2 Qa1 60. Qc1 Qa4 61. Qc2 Qa3 62. Qc1 Qa2+ 63. Qc2 Qa1 64. Qc1 Qa4 65. Qc2 Qa3 66. Qc1 Qa2+ 67. Qc2 Qa1 68. Qc1 Qa4 69. Qc2 Qa3 70. Qc1 Qa2+ 71. Qc2 Qa1 72. Qc1 Qa4",
          "positional_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Qe1",
            "Qd3+",
            "Qe2",
            "Bg2+",
            "Ke1",
            "Qb1+",
            "Qd1",
            "Re6+",
            "Be3",
            "Qxb2",
            "Qd2",
            "Qb1+",
            "Qd1",
            "Qe4",
            "Qd2",
            "Bf4",
            "Kd1",
            "Bxe3",
            "fxe3",
            "Qb1+",
            "Qc1",
            "Bf3+",
            "Kd2",
            "Qa2+",
            "Qc2",
            "Qc4",
            "Qd3",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qc4",
            "Qd3",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4",
            "Qc2",
            "Qa3",
            "Qc1",
            "Qa2+",
            "Qc2",
            "Qa1",
            "Qc1",
            "Qa4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Ra6 Bf8 24. Rxc6 Bh3 25. Qh1 Rxc6 26. Qxc6 Re6\n27. Qf3 Bg4 28. Qg2 Bh3 29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3\n33. Qf3 Bg4 34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3 37. Qf3 Bg4 38. Qg2 Bh3\n39. Qf3 Bg4 40. Qg2 Bh3 41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4 44. Qg2 Bh3\n45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3 49. Qf3 Bg4 50. Qg2 Bh3\n51. Qf3 Bg4 52. Qg2 Bh3 53. Qf3 Bg4 54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3\n57. Qf3 Bg4 58. Qg2 Bh3 59. Qf3 Bg4 60. Qg2 Bh3 61. Qf3 Bg4 62. Qg2 Bh3\n63. Qf3 Bg4 64. Qg2 Bh3 65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3\n69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3 73. Qf3 Bg4 74. Qg2 Bh3\n75. Qf3 Bg4 76. Qg2 Bh3 77. Qf3 Bg4 78. Qg2",
          "neutral_tokens": {
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Ra6",
            "Bf8",
            "Rxc6",
            "Bh3",
            "Qh1",
            "Rxc6",
            "Qxc6",
            "Re6",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "f5",
              "exf5",
              "gxf5",
              "Ne7+",
              "Kf7",
              "Nxf5",
              "h5",
              "g4",
              "hxg4",
              "hxg4",
              "Rh1",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Rb8",
              "Kf7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Qe1",
              "Qd3+",
              "Qe2",
              "Bg2+",
              "Ke1",
              "Qb1+",
              "Qd1",
              "Re6+",
              "Be3",
              "Qxb2",
              "Qd2",
              "Qb1+",
              "Qd1",
              "Qe4",
              "Qd2",
              "Bf4",
              "Kd1",
              "Bxe3",
              "fxe3",
              "Qb1+",
              "Qc1",
              "Bf3+",
              "Kd2",
              "Qa2+",
              "Qc2",
              "Qc4",
              "Qd3",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qc4",
              "Qd3",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4",
              "Qc2",
              "Qa3",
              "Qc1",
              "Qa2+",
              "Qc2",
              "Qa1",
              "Qc1",
              "Qa4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Ra6",
              "Bf8",
              "Rxc6",
              "Bh3",
              "Qh1",
              "Rxc6",
              "Qxc6",
              "Re6",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 365,
          "total_completion_tokens": 1920,
          "total_tokens": 2285
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 122,
            "completion_tokens": 640,
            "total_tokens": 762,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 121,
            "completion_tokens": 640,
            "total_tokens": 761,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Bd1 Bxd1 21. Raxd1 Rfe8 22. Nf1 f5 23. Bd2 f4\n24. Rxe6 Rxe6 25. Re1 Rxe1 26. Bxe1 f3 27. Nd2 Nf4 28. Qxf3 Ne2+\n29. Kg2 Qxf3+ 30. Kxf3 Nc1 31. Ke4 Kf7 32. f4 Ke6 33. Bf2 g6\n34. Be3 h5 35. Nf3 Nb3 36. Ne5 Bxe5 37. fxe5 Na5 38. Bc1 Nc4\n39. b3 Nb6 40. Kd3 Kd5 41. Ba3 Nd7 42. c4+ bxc4+ 43. bxc4+ Ke6\n44. Ke4 Nb6 45. Kd3 Nd7 46. Bb4 Nb6 47. Ba5 Nd7 48. Ke4 Nb8\n49. d5+ cxd5+ 50. cxd5+ Ke7 51. Bb4+ Kd7 52. e6+ Ke8 53. Ke5 Na6\n54. Ba3 Nc7 55. d6 Nb5 56. d7+ Kd8 57. Bc5 Nc7 58. Bb6 Ke7\n59. Bxc7 g5 60. d8=Q# g4 61. Qd7+ Kf8 62. Qf7# g3 63. Bd6# g2",
          "aggressive_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 495,
            "total_tokens": 626,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Bd1",
            "Bxd1",
            "Raxd1",
            "Rfe8",
            "Nf1",
            "f5",
            "Bd2",
            "f4",
            "Rxe6",
            "Rxe6",
            "Re1",
            "Rxe1",
            "Bxe1",
            "f3",
            "Nd2",
            "Nf4",
            "Qxf3",
            "Ne2+",
            "Kg2",
            "Qxf3+",
            "Kxf3",
            "Nc1",
            "Ke4",
            "Kf7",
            "f4",
            "Ke6",
            "Bf2",
            "g6",
            "Be3",
            "h5",
            "Nf3",
            "Nb3",
            "Ne5",
            "Bxe5",
            "fxe5",
            "Na5",
            "Bc1",
            "Nc4",
            "b3",
            "Nb6",
            "Kd3",
            "Kd5",
            "Ba3",
            "Nd7",
            "c4+",
            "bxc4+",
            "bxc4+",
            "Ke6",
            "Ke4",
            "Nb6",
            "Kd3",
            "Nd7",
            "Bb4",
            "Nb6",
            "Ba5",
            "Nd7",
            "Ke4",
            "Nb8",
            "d5+",
            "cxd5+",
            "cxd5+",
            "Ke7",
            "Bb4+",
            "Kd7",
            "e6+",
            "Ke8",
            "Ke5",
            "Na6",
            "Ba3",
            "Nc7",
            "d6",
            "Nb5",
            "d7+",
            "Kd8",
            "Bc5",
            "Nc7",
            "Bb6",
            "Ke7",
            "Bxc7",
            "g5",
            "d8=Q#",
            "g4",
            "Qd7+",
            "Kf8",
            "Qf7#",
            "g3",
            "Bd6#",
            "g2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1# Bb8+ 33. Qe1 Qd3+ 34. Qe2 Bg2+ 35. Ke1 Qb1+ 36. Qd1 Re6+ 37. Be3 Qxb2 38. Qd2 Qb1+ 39. Qd1 Qe4 40. Qb3 Bf4 41. Qxb5 Bxe3 42. fxe3 Qxe3+ 43. Kd1 Bf3+ 44. Kc2 Qe2+ 45. Qxe2 Rxe2+ 46. Kd3 Rxh2 47. c4 Be2+ 48. Kc3 Rh3+ 49. Kb4 Rh4 50. Kc5 Bxc4 51. Kxc4 Rxd4+ 52. Kxd4 h5 53. Ke4 g5 54. Kf5 h4 55. Kg4 f5+ 56. Kh3 Kg7 57. Kg2 g4 58. Kh2 f4 59. Kg2 h3+ 60. Kh2 Kg6 61. Kg1 g3 62. Kh1 f3 63. Kg1 h2+ 64. Kh1 f2 65. Kg2 h1=Q+ 66. Kxh1 f1=Q#",
          "positional_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 550,
            "total_tokens": 681,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Rxf1+",
            "Qxf1",
            "Bf3+",
            "Qg2",
            "Bxg2+",
            "Kg1",
            "Bxa8+",
            "Kf1",
            "Qd1#",
            "Bb8+",
            "Qe1",
            "Qd3+",
            "Qe2",
            "Bg2+",
            "Ke1",
            "Qb1+",
            "Qd1",
            "Re6+",
            "Be3",
            "Qxb2",
            "Qd2",
            "Qb1+",
            "Qd1",
            "Qe4",
            "Qb3",
            "Bf4",
            "Qxb5",
            "Bxe3",
            "fxe3",
            "Qxe3+",
            "Kd1",
            "Bf3+",
            "Kc2",
            "Qe2+",
            "Qxe2",
            "Rxe2+",
            "Kd3",
            "Rxh2",
            "c4",
            "Be2+",
            "Kc3",
            "Rh3+",
            "Kb4",
            "Rh4",
            "Kc5",
            "Bxc4",
            "Kxc4",
            "Rxd4+",
            "Kxd4",
            "h5",
            "Ke4",
            "g5",
            "Kf5",
            "h4",
            "Kg4",
            "f5+",
            "Kh3",
            "Kg7",
            "Kg2",
            "g4",
            "Kh2",
            "f4",
            "Kg2",
            "h3+",
            "Kh2",
            "Kg6",
            "Kg1",
            "g3",
            "Kh1",
            "f3",
            "Kg1",
            "h2+",
            "Kh1",
            "f2",
            "Kg2",
            "h1=Q+",
            "Kxh1",
            "f1=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a7a6",
          "neutral_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bc7 21. Bxd5 Qxd5 22. c4 bxc4 23. Qxc4 Qh5\n24. Rxc6 Ba5 25. Rxe6 Bxe6 26. Qc5 Qxc5 27. dxc5 Rb8 28. Ra1 Bxd2\n29. Bxd2 Rxb2 30. Ra8+ *",
          "neutral_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 224,
            "total_tokens": 354,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bxd5",
            "Qxd5",
            "c4",
            "bxc4",
            "Qxc4",
            "Qh5",
            "Rxc6",
            "Ba5",
            "Rxe6",
            "Bxe6",
            "Qc5",
            "Qxc5",
            "dxc5",
            "Rb8",
            "Ra1",
            "Bxd2",
            "Bxd2",
            "Rxb2",
            "Ra8+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "a7a6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Bd1",
              "Bxd1",
              "Raxd1",
              "Rfe8",
              "Nf1",
              "f5",
              "Bd2",
              "f4",
              "Rxe6",
              "Rxe6",
              "Re1",
              "Rxe1",
              "Bxe1",
              "f3",
              "Nd2",
              "Nf4",
              "Qxf3",
              "Ne2+",
              "Kg2",
              "Qxf3+",
              "Kxf3",
              "Nc1",
              "Ke4",
              "Kf7",
              "f4",
              "Ke6",
              "Bf2",
              "g6",
              "Be3",
              "h5",
              "Nf3",
              "Nb3",
              "Ne5",
              "Bxe5",
              "fxe5",
              "Na5",
              "Bc1",
              "Nc4",
              "b3",
              "Nb6",
              "Kd3",
              "Kd5",
              "Ba3",
              "Nd7",
              "c4+",
              "bxc4+",
              "bxc4+",
              "Ke6",
              "Ke4",
              "Nb6",
              "Kd3",
              "Nd7",
              "Bb4",
              "Nb6",
              "Ba5",
              "Nd7",
              "Ke4",
              "Nb8",
              "d5+",
              "cxd5+",
              "cxd5+",
              "Ke7",
              "Bb4+",
              "Kd7",
              "e6+",
              "Ke8",
              "Ke5",
              "Na6",
              "Ba3",
              "Nc7",
              "d6",
              "Nb5",
              "d7+",
              "Kd8",
              "Bc5",
              "Nc7",
              "Bb6",
              "Ke7",
              "Bxc7",
              "g5",
              "d8=Q#",
              "g4",
              "Qd7+",
              "Kf8",
              "Qf7#",
              "g3",
              "Bd6#",
              "g2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Rxf1+",
              "Qxf1",
              "Bf3+",
              "Qg2",
              "Bxg2+",
              "Kg1",
              "Bxa8+",
              "Kf1",
              "Qd1#",
              "Bb8+",
              "Qe1",
              "Qd3+",
              "Qe2",
              "Bg2+",
              "Ke1",
              "Qb1+",
              "Qd1",
              "Re6+",
              "Be3",
              "Qxb2",
              "Qd2",
              "Qb1+",
              "Qd1",
              "Qe4",
              "Qb3",
              "Bf4",
              "Qxb5",
              "Bxe3",
              "fxe3",
              "Qxe3+",
              "Kd1",
              "Bf3+",
              "Kc2",
              "Qe2+",
              "Qxe2",
              "Rxe2+",
              "Kd3",
              "Rxh2",
              "c4",
              "Be2+",
              "Kc3",
              "Rh3+",
              "Kb4",
              "Rh4",
              "Kc5",
              "Bxc4",
              "Kxc4",
              "Rxd4+",
              "Kxd4",
              "h5",
              "Ke4",
              "g5",
              "Kf5",
              "h4",
              "Kg4",
              "f5+",
              "Kh3",
              "Kg7",
              "Kg2",
              "g4",
              "Kh2",
              "f4",
              "Kg2",
              "h3+",
              "Kh2",
              "Kg6",
              "Kg1",
              "g3",
              "Kh1",
              "f3",
              "Kg1",
              "h2+",
              "Kh1",
              "f2",
              "Kg2",
              "h1=Q+",
              "Kxh1",
              "f1=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bxd5",
              "Qxd5",
              "c4",
              "bxc4",
              "Qxc4",
              "Qh5",
              "Rxc6",
              "Ba5",
              "Rxe6",
              "Bxe6",
              "Qc5",
              "Qxc5",
              "dxc5",
              "Rb8",
              "Ra1",
              "Bxd2",
              "Bxd2",
              "Rxb2",
              "Ra8+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 131,
            "completion_tokens": 495,
            "total_tokens": 626,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 131,
            "completion_tokens": 550,
            "total_tokens": 681,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 130,
            "completion_tokens": 224,
            "total_tokens": 354,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 392,
          "total_completion_tokens": 1269,
          "total_tokens": 1661
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 131,
            "completion_tokens": 495,
            "total_tokens": 626,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 131,
            "completion_tokens": 550,
            "total_tokens": 681,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 130,
            "completion_tokens": 224,
            "total_tokens": 354,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "4... Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6\n13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8\n17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Ra6 Bf8 24. Rxc6 Bh3\n25. Qf3 Bg4 26. Qg2 Bh3 27. Qf3 Bg4 28. Qg2 Bh3\n29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3\n33. Qf3 Bg4 34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3\n37. Qf3 Bg4 38. Qg2 Bh3 39. Qf3 Bg4 40. Qg2 Bh3\n41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4 44. Qg2 Bh3\n45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3\n49. Qf3 Bg4 50. Qg2 Bh3 51. Qf3 Bg4 52. Qg2 Bh3\n53. Qf3 Bg4 54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3\n57. Qf3 Bg4 58. Qg2 Bh3 59. Qf3 Bg4 60. Qg2 Bh3\n61. Qf3 Bg4 62. Qg2 Bh3 63. Qf3 Bg4 64. Qg2 Bh3\n65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3\n69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3\n73. Qf3 Bg4 74. Qg2 Bh3 75. Qf3 Bg4 76. Qg2 Bh3\n77. Qf3 Bg4 78. Qg2 Bh3 79. Qf3 Bg4 80. Qg",
          "aggressive_tokens": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Ra6",
            "Bf8",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "4... Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Bb7 10. d4 Re8 11. Nbd2 Bf8 12. a4 h6 13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5 16. d5 Nd7 17. Ra3 c4 18. Nd4 Qf6 19. N2f3 Nc5 20. axb5 axb5 21. Nxb5 Nbd3 22. Bxd3 Nxd3 23. Rxd3 cxd3 24. Nc7 Ba6 25. Nxe8 Rxe8 26. Qa4 Ra8 27. Qc6 Qd8 28. Bd2 Qc8 29. Rc1 Qxc6 30. Rxc6 Bb5 31. Rb6 Ra1+ 32. Kh2 Ba4 33. Rb8 f6 34. Nd4 Kf7 35. Ne6 Be7 36. Rb7 g5 37. Nd8+ Ke8 38. Nc6 Bf8 39. Nd4 Rd1 40. Nf3 Bc2 41. Kg3 h5 42. h4 g4 43. Nd4 Rxd2 44. Rb8+ Kf7 45. Rb7+ Kg6 46. Ne6 Bh6 47. f4 gxf3 48. gxf3 Rd1 49. f4 Rg1+ 50. Kf2 d2 51. f5# d1=Q 52. Nf8# d1=Q 53. Nh7# d1=Q 54. Nf8# d1=Q 55. Nh7# d1=Q 56. Nf8# d1=Q 57. Nh7# d1=Q 58. Nf8# d1=Q 59. Nh7# d1=Q 60. Nf8# d1=Q 61. Nh7# d1=Q 62. Nf8# d1=Q 63. Nh7# d1=Q 64. Nf8# d1=Q 65. Nh7# d1=Q 66. Nf8# d1=Q 67. Nh7# d1=Q 68. Nf8# d1=Q 69. Nh7# d1=Q 70. Nf8# d1=Q 71. Nh7# d1=Q 72. Nf8# d1=Q 73. Nh7# d1=Q 74. Nf8# d1=Q 75. Nh7# d1=",
          "positional_tokens": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Bb7",
            "d4",
            "Re8",
            "Nbd2",
            "Bf8",
            "a4",
            "h6",
            "Bc2",
            "exd4",
            "cxd4",
            "Nb4",
            "Bb1",
            "c5",
            "d5",
            "Nd7",
            "Ra3",
            "c4",
            "Nd4",
            "Qf6",
            "N2f3",
            "Nc5",
            "axb5",
            "axb5",
            "Nxb5",
            "Nbd3",
            "Bxd3",
            "Nxd3",
            "Rxd3",
            "cxd3",
            "Nc7",
            "Ba6",
            "Nxe8",
            "Rxe8",
            "Qa4",
            "Ra8",
            "Qc6",
            "Qd8",
            "Bd2",
            "Qc8",
            "Rc1",
            "Qxc6",
            "Rxc6",
            "Bb5",
            "Rb6",
            "Ra1+",
            "Kh2",
            "Ba4",
            "Rb8",
            "f6",
            "Nd4",
            "Kf7",
            "Ne6",
            "Be7",
            "Rb7",
            "g5",
            "Nd8+",
            "Ke8",
            "Nc6",
            "Bf8",
            "Nd4",
            "Rd1",
            "Nf3",
            "Bc2",
            "Kg3",
            "h5",
            "h4",
            "g4",
            "Nd4",
            "Rxd2",
            "Rb8+",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Ne6",
            "Bh6",
            "f4",
            "gxf3",
            "gxf3",
            "Rd1",
            "f4",
            "Rg1+",
            "Kf2",
            "d2",
            "f5#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1=Q",
            "Nf8#",
            "d1=Q",
            "Nh7#",
            "d1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "4... Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5 19. axb5 axb5 20. Ra6 Bb8 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5 24. Rxc6 Bh3 25. Qf3 Bg4 26. Qg2 Bh3 27. Qf3 Bg4 28. Qg2 Bh3 29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3 33. Qf3 Bg4 34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3 37. Qf3 Bg4 38. Qg2 Bh3 39. Qf3 Bg4 40. Qg2 Bh3 41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4 44. Qg2 Bh3 45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3 49. Qf3 Bg4 50. Qg2 Bh3 51. Qf3 Bg4 52. Qg2 Bh3 53. Qf3 Bg4 54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3 57. Qf3 Bg4 58. Qg2 Bh3 59. Qf3 Bg4 60. Qg2 Bh3 61. Qf3 Bg4 62. Qg2 Bh3 63. Qf3 Bg4 64. Qg2 Bh3 65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3 69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3 73. Qf3 Bg4 74. Qg2 Bh3 75. Qf3 Bg4 76. Qg2 Bh3 77. Qf3 Bg4 78. Qg2 Bh3 79. Qf3 Bg4 80. Qg",
          "neutral_tokens": {
            "prompt_tokens": 137,
            "completion_tokens": 640,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Ra6",
              "Bf8",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Bb7",
              "d4",
              "Re8",
              "Nbd2",
              "Bf8",
              "a4",
              "h6",
              "Bc2",
              "exd4",
              "cxd4",
              "Nb4",
              "Bb1",
              "c5",
              "d5",
              "Nd7",
              "Ra3",
              "c4",
              "Nd4",
              "Qf6",
              "N2f3",
              "Nc5",
              "axb5",
              "axb5",
              "Nxb5",
              "Nbd3",
              "Bxd3",
              "Nxd3",
              "Rxd3",
              "cxd3",
              "Nc7",
              "Ba6",
              "Nxe8",
              "Rxe8",
              "Qa4",
              "Ra8",
              "Qc6",
              "Qd8",
              "Bd2",
              "Qc8",
              "Rc1",
              "Qxc6",
              "Rxc6",
              "Bb5",
              "Rb6",
              "Ra1+",
              "Kh2",
              "Ba4",
              "Rb8",
              "f6",
              "Nd4",
              "Kf7",
              "Ne6",
              "Be7",
              "Rb7",
              "g5",
              "Nd8+",
              "Ke8",
              "Nc6",
              "Bf8",
              "Nd4",
              "Rd1",
              "Nf3",
              "Bc2",
              "Kg3",
              "h5",
              "h4",
              "g4",
              "Nd4",
              "Rxd2",
              "Rb8+",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Ne6",
              "Bh6",
              "f4",
              "gxf3",
              "gxf3",
              "Rd1",
              "f4",
              "Rg1+",
              "Kf2",
              "d2",
              "f5#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1=Q",
              "Nf8#",
              "d1=Q",
              "Nh7#",
              "d1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 137,
            "completion_tokens": 640,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 413,
          "total_completion_tokens": 1920,
          "total_tokens": 2333
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 138,
            "completion_tokens": 640,
            "total_tokens": 778,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 137,
            "completion_tokens": 640,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe4",
          "aggressive_uci": "f6e4",
          "aggressive_response": "5... Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. Nbd2 Nc5 10. c3 d4 11. Ng5 dxc3 12. Nxe6 Nxe6 13. bxc3 Nxe5 14. Qe2 Bd6 15. f4 Nc4 16. Nxc4 bxc4 17. Ba4+ Kf8 18. Qxc4 Nc5 19. Bc6 Rb8 20. Be3 Qe7 21. Rae1 Ne6 22. f5 Nd8 23. Ba7 Nxc6 24. Rxe7 Nxe7 25. Bxb8 h5 26. Bxc7 Bxc7 27. Qxc7 f6 28. Qd8+ Kf7 29. Qxh8 Ng8 30. Qxh5+ Kf8 31. Re1 Ne7 32. Qh8+ Kf7 33. Qd8 Nxf5 34. Qe8# Nxe8 g6 Qxe8+ Kg7 Qxe8+ Kg8",
          "aggressive_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 267,
            "total_tokens": 413,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4",
            "b5",
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "Nbd2",
            "Nc5",
            "c3",
            "d4",
            "Ng5",
            "dxc3",
            "Nxe6",
            "Nxe6",
            "bxc3",
            "Nxe5",
            "Qe2",
            "Bd6",
            "f4",
            "Nc4",
            "Nxc4",
            "bxc4",
            "Ba4+",
            "Kf8",
            "Qxc4",
            "Nc5",
            "Bc6",
            "Rb8",
            "Be3",
            "Qe7",
            "Rae1",
            "Ne6",
            "f5",
            "Nd8",
            "Ba7",
            "Nxc6",
            "Rxe7",
            "Nxe7",
            "Bxb8",
            "h5",
            "Bxc7",
            "Bxc7",
            "Qxc7",
            "f6",
            "Qd8+",
            "Kf7",
            "Qxh8",
            "Ng8",
            "Qxh5+",
            "Kf8",
            "Re1",
            "Ne7",
            "Qh8+",
            "Kf7",
            "Qd8",
            "Nxf5",
            "Qe8#",
            "Nxe8",
            "g6",
            "Qxe8+",
            "Kg7",
            "Qxe8+",
            "Kg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe4",
          "positional_uci": "f6e4",
          "positional_response": "5... Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. Nbd2 Nc5 10. c3 Be7 11. Bc2 d4 12. Nb3 d3 13. Bb1 Bf5 14. Be3 Nxb3 15. axb3 O-O 16. Nd4 Nxd4 17. cxd4 c5 18. Bxd3 Bxd3 19. Qxd3 cxd4 20. Qxd4 Qxd4 21. Bxd4 Rfd8 22. Rfd1 Rd5 23. Bc3 Rxd1+ 24. Rxd1 Rd8 25. Rxd8+ Bxd8 26. f4 Bb6+ 27. Kf1 Kf8 28. Ke2 Ke7 29. Kd3 Ke6 30. Ke4 g6 31. g4 Bg1 32. h3 Bb6 33. f5+ gxf5+ 34. gxf5+ Ke7 35. Kd5 Kd7 36. e6+ fxe6+ 37. fxe6+ Ke7 38. Bb4+ Ke8 39. Kc6 Bd4 40. Kb7 Bxb2 41. Kxa6 Bf6 42. Kxb5 Bd8 43. Kc6 Bf6 44. Bd6 Bd8 45. b4 Bf6 46. b5 Bd8 47. b6 Bxb6 48. Kxb6 Kd8 49. Kc6 Ke8 50. Kd5 Kd8 51. Ke5 Ke8 52. Kf6 Kd8 53. Kf7 Kc8 54. e7 Kb7 55. e8=Q Kb6 56. Qc8 Kb5 57. Qc5+ Ka6 58. Qb4 Ka7 59. Bc7 Ka6 60. Qb6# e4 d5 e6",
          "positional_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 470,
            "total_tokens": 616,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4",
            "b5",
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "Nbd2",
            "Nc5",
            "c3",
            "Be7",
            "Bc2",
            "d4",
            "Nb3",
            "d3",
            "Bb1",
            "Bf5",
            "Be3",
            "Nxb3",
            "axb3",
            "O-O",
            "Nd4",
            "Nxd4",
            "cxd4",
            "c5",
            "Bxd3",
            "Bxd3",
            "Qxd3",
            "cxd4",
            "Qxd4",
            "Qxd4",
            "Bxd4",
            "Rfd8",
            "Rfd1",
            "Rd5",
            "Bc3",
            "Rxd1+",
            "Rxd1",
            "Rd8",
            "Rxd8+",
            "Bxd8",
            "f4",
            "Bb6+",
            "Kf1",
            "Kf8",
            "Ke2",
            "Ke7",
            "Kd3",
            "Ke6",
            "Ke4",
            "g6",
            "g4",
            "Bg1",
            "h3",
            "Bb6",
            "f5+",
            "gxf5+",
            "gxf5+",
            "Ke7",
            "Kd5",
            "Kd7",
            "e6+",
            "fxe6+",
            "fxe6+",
            "Ke7",
            "Bb4+",
            "Ke8",
            "Kc6",
            "Bd4",
            "Kb7",
            "Bxb2",
            "Kxa6",
            "Bf6",
            "Kxb5",
            "Bd8",
            "Kc6",
            "Bf6",
            "Bd6",
            "Bd8",
            "b4",
            "Bf6",
            "b5",
            "Bd8",
            "b6",
            "Bxb6",
            "Kxb6",
            "Kd8",
            "Kc6",
            "Ke8",
            "Kd5",
            "Kd8",
            "Ke5",
            "Ke8",
            "Kf6",
            "Kd8",
            "Kf7",
            "Kc8",
            "e7",
            "Kb7",
            "e8=Q",
            "Kb6",
            "Qc8",
            "Kb5",
            "Qc5+",
            "Ka6",
            "Qb4",
            "Ka7",
            "Bc7",
            "Ka6",
            "Qb6#",
            "e4",
            "d5",
            "e6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe4",
          "neutral_uci": "f6e4",
          "neutral_response": "5... Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Be7 10. Nbd2 O-O 11. Bc2 f5 12. exf6 Nxf6 13. Re1 Bg4 14. h3 Bh5 15. Qe2 Re8 16. Qe6+ Bf7 17. Qxc6 Bd6 18. Rxe8+ Bxe8 19. Qb7 c6 20. Nd4 Rb8 21. Qxa6 Rb6 22. Qa7 Bb8 23. Qa8 Bh2+ 24. Kxh2 Qxa8 25. N2f3 c5 26. Nf5 Bg6 27. Ne7+ Kf7 28. Nxg6 hxg6 29. Ne5+ Ke6 30. Nxg6 Ne4 31. f3 Kf7 32. Ne5+ Ke6 33. Ng6 Kf7 34. Ne5+ Ke6 35. Ng6 Kf7 36. Ne5+ Ke6 37. Ng6 Kf7 38. Ne5+ Ke6 39. Ng6 Kf7 40. Ne5+ Ke6 41. Ng6 Kf7 42. Ne5+ Ke6 43. Ng6 Kf7 44. Ne5+ Ke6 45. Ng6 Kf7 46. Ne5+ Ke6 47. Ng6 Kf7 48. Ne5+ Ke6 49. Ng6 Kf7 50. Ne5+ Ke6 51. Ng6 Kf7 52. Ne5+ Ke6 53. Ng6 Kf7 54. Ne5+ Ke6 55. Ng6 Kf7 56. Ne5+ Ke6 57. Ng6 Kf7 58. Ne5+ Ke6 59. Ng6 Kf7 60. Ne5+ Ke6 61. Ng6 Kf7 62. Ne5+ Ke6 63. Ng6 Kf7 64. Ne5+ Ke6 65. Ng6 Kf7 66. Ne5+ Ke6 67. Ng6 Kf7 68. Ne5+ Ke6 69. Ng6 Kf7 70. Ne5+ Ke6 71. Ng6 Kf7 72. Ne5+ Ke6 73. Ng6 Kf7 74. Ne5+ Ke6 75. Ng6 Kf7 76. Ne5+ Ke6 77. Ng6 Kf7 78. Ne5+ Ke6 79. Ng6 Kf7 80. Ne5+ Ke6 81. Ng6 Kf7 82. Ne5+ Ke6 83. Ng6 Kf",
          "neutral_tokens": {
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "b5",
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "c3",
            "Be7",
            "Nbd2",
            "O-O",
            "Bc2",
            "f5",
            "exf6",
            "Nxf6",
            "Re1",
            "Bg4",
            "h3",
            "Bh5",
            "Qe2",
            "Re8",
            "Qe6+",
            "Bf7",
            "Qxc6",
            "Bd6",
            "Rxe8+",
            "Bxe8",
            "Qb7",
            "c6",
            "Nd4",
            "Rb8",
            "Qxa6",
            "Rb6",
            "Qa7",
            "Bb8",
            "Qa8",
            "Bh2+",
            "Kxh2",
            "Qxa8",
            "N2f3",
            "c5",
            "Nf5",
            "Bg6",
            "Ne7+",
            "Kf7",
            "Nxg6",
            "hxg6",
            "Ne5+",
            "Ke6",
            "Nxg6",
            "Ne4",
            "f3",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6",
            "Kf7",
            "Ne5+",
            "Ke6",
            "Ng6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f6e4",
          "positional_uci": "f6e4",
          "neutral_uci": "f6e4",
          "consensus_move": "f6e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d4",
              "b5",
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "Nbd2",
              "Nc5",
              "c3",
              "d4",
              "Ng5",
              "dxc3",
              "Nxe6",
              "Nxe6",
              "bxc3",
              "Nxe5",
              "Qe2",
              "Bd6",
              "f4",
              "Nc4",
              "Nxc4",
              "bxc4",
              "Ba4+",
              "Kf8",
              "Qxc4",
              "Nc5",
              "Bc6",
              "Rb8",
              "Be3",
              "Qe7",
              "Rae1",
              "Ne6",
              "f5",
              "Nd8",
              "Ba7",
              "Nxc6",
              "Rxe7",
              "Nxe7",
              "Bxb8",
              "h5",
              "Bxc7",
              "Bxc7",
              "Qxc7",
              "f6",
              "Qd8+",
              "Kf7",
              "Qxh8",
              "Ng8",
              "Qxh5+",
              "Kf8",
              "Re1",
              "Ne7",
              "Qh8+",
              "Kf7",
              "Qd8",
              "Nxf5",
              "Qe8#",
              "Nxe8",
              "g6",
              "Qxe8+",
              "Kg7",
              "Qxe8+",
              "Kg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d4",
              "b5",
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "Nbd2",
              "Nc5",
              "c3",
              "Be7",
              "Bc2",
              "d4",
              "Nb3",
              "d3",
              "Bb1",
              "Bf5",
              "Be3",
              "Nxb3",
              "axb3",
              "O-O",
              "Nd4",
              "Nxd4",
              "cxd4",
              "c5",
              "Bxd3",
              "Bxd3",
              "Qxd3",
              "cxd4",
              "Qxd4",
              "Qxd4",
              "Bxd4",
              "Rfd8",
              "Rfd1",
              "Rd5",
              "Bc3",
              "Rxd1+",
              "Rxd1",
              "Rd8",
              "Rxd8+",
              "Bxd8",
              "f4",
              "Bb6+",
              "Kf1",
              "Kf8",
              "Ke2",
              "Ke7",
              "Kd3",
              "Ke6",
              "Ke4",
              "g6",
              "g4",
              "Bg1",
              "h3",
              "Bb6",
              "f5+",
              "gxf5+",
              "gxf5+",
              "Ke7",
              "Kd5",
              "Kd7",
              "e6+",
              "fxe6+",
              "fxe6+",
              "Ke7",
              "Bb4+",
              "Ke8",
              "Kc6",
              "Bd4",
              "Kb7",
              "Bxb2",
              "Kxa6",
              "Bf6",
              "Kxb5",
              "Bd8",
              "Kc6",
              "Bf6",
              "Bd6",
              "Bd8",
              "b4",
              "Bf6",
              "b5",
              "Bd8",
              "b6",
              "Bxb6",
              "Kxb6",
              "Kd8",
              "Kc6",
              "Ke8",
              "Kd5",
              "Kd8",
              "Ke5",
              "Ke8",
              "Kf6",
              "Kd8",
              "Kf7",
              "Kc8",
              "e7",
              "Kb7",
              "e8=Q",
              "Kb6",
              "Qc8",
              "Kb5",
              "Qc5+",
              "Ka6",
              "Qb4",
              "Ka7",
              "Bc7",
              "Ka6",
              "Qb6#",
              "e4",
              "d5",
              "e6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d4",
              "b5",
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "c3",
              "Be7",
              "Nbd2",
              "O-O",
              "Bc2",
              "f5",
              "exf6",
              "Nxf6",
              "Re1",
              "Bg4",
              "h3",
              "Bh5",
              "Qe2",
              "Re8",
              "Qe6+",
              "Bf7",
              "Qxc6",
              "Bd6",
              "Rxe8+",
              "Bxe8",
              "Qb7",
              "c6",
              "Nd4",
              "Rb8",
              "Qxa6",
              "Rb6",
              "Qa7",
              "Bb8",
              "Qa8",
              "Bh2+",
              "Kxh2",
              "Qxa8",
              "N2f3",
              "c5",
              "Nf5",
              "Bg6",
              "Ne7+",
              "Kf7",
              "Nxg6",
              "hxg6",
              "Ne5+",
              "Ke6",
              "Nxg6",
              "Ne4",
              "f3",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6",
              "Kf7",
              "Ne5+",
              "Ke6",
              "Ng6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 146,
            "completion_tokens": 267,
            "total_tokens": 413,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 146,
            "completion_tokens": 470,
            "total_tokens": 616,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 437,
          "total_completion_tokens": 1377,
          "total_tokens": 1814
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 146,
            "completion_tokens": 267,
            "total_tokens": 413,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 146,
            "completion_tokens": 470,
            "total_tokens": 616,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 b kq - 3 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b5",
          "aggressive_uci": "b7b5",
          "aggressive_response": "6... b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# 0-1\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 *\n6... b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# 0-1 28. Ng1",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 432,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "c3",
            "Bc5",
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Qb6+",
            "Kh1",
            "Qf2",
            "Qxd5+",
            "Kh8",
            "Qd3",
            "Bf5",
            "Qd2",
            "Re2",
            "Qxe2",
            "Qxe2",
            "Bxf5",
            "Rxf5",
            "Re1",
            "Qxe1+",
            "Nxe1",
            "Rf1#",
            "Ng1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b5",
          "positional_uci": "b7b5",
          "positional_response": "6... b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Be2 c3 34. Kd1 Rd2+ 35. Ke1 Rxe2+ 36. Kxe2 h5 37. Kd3 h4 38. Kxc3 h3 39. Kd3 h2 40. Ke3 h1=Q 41. Kf2 Qh3 42. Ke2 Qg3 43. Kd2 Qf3 44. Kc2 Qe3 45. Kb2 Qd3 46. Ka2 Qc3 47. Kb1 Qd2 48. Ka1 c5 49. Kb1 c4 50. Ka1 c3 51. Kb1 Qb2# c3 c2 c1=Q",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 389,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "c3",
            "Bc5",
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxh2",
            "b3",
            "Rb2",
            "Rxb2",
            "Rxb2",
            "c4",
            "bxc4",
            "bxc4",
            "dxc4",
            "Be2",
            "c3",
            "Kd1",
            "Rd2+",
            "Ke1",
            "Rxe2+",
            "Kxe2",
            "h5",
            "Kd3",
            "h4",
            "Kxc3",
            "h3",
            "Kd3",
            "h2",
            "Ke3",
            "h1=Q",
            "Kf2",
            "Qh3",
            "Ke2",
            "Qg3",
            "Kd2",
            "Qf3",
            "Kc2",
            "Qe3",
            "Kb2",
            "Qd3",
            "Ka2",
            "Qc3",
            "Kb1",
            "Qd2",
            "Ka1",
            "c5",
            "Kb1",
            "c4",
            "Ka1",
            "c3",
            "Kb1",
            "Qb2#",
            "c3",
            "c2",
            "c1=Q"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "b5",
          "neutral_uci": "b7b5",
          "neutral_response": "6... b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd2 Re2 23. Be3 Qxg2# 0-1\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 * b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd2 Re2 23. Be3 Qxg2# 0-1 d5 Bc5 O-O Nxf2 Rxf2 f6 exf6 Bxf2+ Kxf2 Qxf6 Kg1 Rae8 Nb3 Ne5 Nbd4 Bg4 Bg5 Nxf3+ Nxf3 Qb6+ Kh1 Qf2 Qxd5+ Kh8 Qd2 Re2 Be3 Qxg2#",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 432,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "c3",
            "Bc5",
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Qb6+",
            "Kh1",
            "Qf2",
            "Qxd5+",
            "Kh8",
            "Qd2",
            "Re2",
            "Be3",
            "Qxg2#",
            "d5",
            "Bc5",
            "O-O",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Qb6+",
            "Kh1",
            "Qf2",
            "Qxd5+",
            "Kh8",
            "Qd2",
            "Re2",
            "Be3",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b7b5",
          "positional_uci": "b7b5",
          "neutral_uci": "b7b5",
          "consensus_move": "b7b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "c3",
              "Bc5",
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Qb6+",
              "Kh1",
              "Qf2",
              "Qxd5+",
              "Kh8",
              "Qd3",
              "Bf5",
              "Qd2",
              "Re2",
              "Qxe2",
              "Qxe2",
              "Bxf5",
              "Rxf5",
              "Re1",
              "Qxe1+",
              "Nxe1",
              "Rf1#",
              "Ng1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "c3",
              "Bc5",
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxh2",
              "b3",
              "Rb2",
              "Rxb2",
              "Rxb2",
              "c4",
              "bxc4",
              "bxc4",
              "dxc4",
              "Be2",
              "c3",
              "Kd1",
              "Rd2+",
              "Ke1",
              "Rxe2+",
              "Kxe2",
              "h5",
              "Kd3",
              "h4",
              "Kxc3",
              "h3",
              "Kd3",
              "h2",
              "Ke3",
              "h1=Q",
              "Kf2",
              "Qh3",
              "Ke2",
              "Qg3",
              "Kd2",
              "Qf3",
              "Kc2",
              "Qe3",
              "Kb2",
              "Qd3",
              "Ka2",
              "Qc3",
              "Kb1",
              "Qd2",
              "Ka1",
              "c5",
              "Kb1",
              "c4",
              "Ka1",
              "c3",
              "Kb1",
              "Qb2#",
              "c3",
              "c2",
              "c1=Q"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "c3",
              "Bc5",
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Qb6+",
              "Kh1",
              "Qf2",
              "Qxd5+",
              "Kh8",
              "Qd2",
              "Re2",
              "Be3",
              "Qxg2#",
              "d5",
              "Bc5",
              "O-O",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Qb6+",
              "Kh1",
              "Qf2",
              "Qxd5+",
              "Kh8",
              "Qd2",
              "Re2",
              "Be3",
              "Qxg2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 432,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 389,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 432,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 1253,
          "total_tokens": 1714
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 432,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 389,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 432,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n5/4p3/B2Pn3/5N2/PPP2PPP/RNBQ1RK1 b kq - 0 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "7... d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxb2 29. Rxb2 Rxb2 30. h4 Kf7 31. Bg4 Kf6 32. Bd7 c5 33. Bc6 Ke5 34. Kd1 b4 35. cxb4 Rxb4 36. h5 Rh4 37. Be8 Kd4 38. Kd2 Rh2+ 39. Kd1 Kd3 40. Bb5+ c4 41. Ke1 Rxh5 42. Kf2 d4 43. Ba6 Ra5 44. Bb7 c3 45. Kf3 c2 46. Be4+ Kd2 47. Bxc2 Kxc2 48. Ke4 d3 49. Kd4 d2 50. Kc4 d1=Q 51. Kb4 Qd2+ 52. Kc4 Qc3# d5 cxd5 cxd5",
          "aggressive_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 393,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "cxd5",
            "cxd5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d5",
          "positional_uci": "d7d5",
          "positional_response": "7... d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Be3 Qxg2# 0-1\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 * 7... d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Be3 Qxg2# 0-1",
          "positional_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 366,
            "total_tokens": 528,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Be6",
            "c3",
            "Bc5",
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Qb6+",
            "Kh1",
            "Qf2",
            "Qxd5+",
            "Kh8",
            "Qd3",
            "Bf5",
            "Qd2",
            "Re2",
            "Be3",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d5",
          "neutral_uci": "d7d5",
          "neutral_response": "7... d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Bf3 c3 34. Bxc6 c2 35. Kd2 h5 36. Kc1 Ra2 37. Bd5+ Kh7 38. Bxa2 g5 39. Kxc2 h4 40. Kd2 h3 41. Ke2 h2 42. Bd5 g4 43. Kf2 g3+ 44. Kxg3 h1=Q 45. Bxh1 *",
          "neutral_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 325,
            "total_tokens": 486,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Be6",
            "c3",
            "Bc5",
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxh2",
            "b3",
            "Rb2",
            "Rxb2",
            "Rxb2",
            "c4",
            "bxc4",
            "bxc4",
            "dxc4",
            "Bf3",
            "c3",
            "Bxc6",
            "c2",
            "Kd2",
            "h5",
            "Kc1",
            "Ra2",
            "Bd5+",
            "Kh7",
            "Bxa2",
            "g5",
            "Kxc2",
            "h4",
            "Kd2",
            "h3",
            "Ke2",
            "h2",
            "Bd5",
            "g4",
            "Kf2",
            "g3+",
            "Kxg3",
            "h1=Q",
            "Bxh1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": "d7d5",
          "neutral_uci": "d7d5",
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "cxd5",
              "cxd5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxe5",
              "Be6",
              "c3",
              "Bc5",
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Qb6+",
              "Kh1",
              "Qf2",
              "Qxd5+",
              "Kh8",
              "Qd3",
              "Bf5",
              "Qd2",
              "Re2",
              "Be3",
              "Qxg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxe5",
              "Be6",
              "c3",
              "Bc5",
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxh2",
              "b3",
              "Rb2",
              "Rxb2",
              "Rxb2",
              "c4",
              "bxc4",
              "bxc4",
              "dxc4",
              "Bf3",
              "c3",
              "Bxc6",
              "c2",
              "Kd2",
              "h5",
              "Kc1",
              "Ra2",
              "Bd5+",
              "Kh7",
              "Bxa2",
              "g5",
              "Kxc2",
              "h4",
              "Kd2",
              "h3",
              "Ke2",
              "h2",
              "Bd5",
              "g4",
              "Kf2",
              "g3+",
              "Kxg3",
              "h1=Q",
              "Bxh1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 162,
            "completion_tokens": 393,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 162,
            "completion_tokens": 366,
            "total_tokens": 528,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 161,
            "completion_tokens": 325,
            "total_tokens": 486,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 485,
          "total_completion_tokens": 1084,
          "total_tokens": 1569
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 162,
            "completion_tokens": 393,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 162,
            "completion_tokens": 366,
            "total_tokens": 528,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 161,
            "completion_tokens": 325,
            "total_tokens": 486,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/2pp1ppp/p1n5/1p2p3/3Pn3/1B3N2/PPP2PPP/RNBQ1RK1 b kq - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be6",
          "aggressive_uci": "c8e6",
          "aggressive_response": "8... Be6 9. Nbd2 Nc5 10. c3 Be7 11. Bc2 d4 12. Nb3 d3 13. Bb1 Bf5 14. Be3 Nxb3 15. axb3 O-O 16. Nd4 Nxd4 17. cxd4 c5 18. Bxd3 Bxd3 19. Qxd3 cxd4 20. Qxd4 Qxd4 21. Bxd4 Rfd8 22. Rfd1 Rd5 23. Bc3 Rxd1+ 24. Rxd1 Rd8 25. Rxd8+ Bxd8 26. f4 Bb6+ 27. Kf1 Kf8 28. Ke2 Ke7 29. Kd3 Ke6 30. Ke4 g6 31. g4 Bg1 32. h3 Bh2 33. f5+ gxf5+ 34. gxf5+ Ke7 35. Kd5 Kd7 36. e6+ fxe6+ 37. fxe6+ Ke7 38. Bb4+ Ke8 39. Kc6 Be5 40. Kb6 Bxb2 41. Kxa6 Be5 42. Kxb5 Bf6 43. Kc6 Bd8 44. Bd6 Ba5 45. b4 Bd8 46. b5 Ba5 47. b6 Bxb6 48. Kxb6 Kd8 49. Kc6 Ke8 50. Kd5 Kd8 51. Ke5 Ke8 52. Kf6 Kd8 53. Kf7 Kc8 54. e7 Kb7 55. e8=Q Kb6 56. Qc8 Kb5 57. Qc5+ Ka4 58. Qb4#\n* 58... Ka6 59. Bc7 Ka7 60. Qb6+ Ka8 61. Qb8# Kd7 62. Qd8+ Kc6 63. Qd6+ Kb7 64. Qb6+ Kc8 65. Ke7 h5 66. Qb8# Kd7 67. Qd8+ Kc6 68. Qd6+ Kb7 69. Qb6+ Kc8 70. Qb8# Kd7 71. Qd8+ Kc6 72. Qd6+ Kb7 73. Qb6+ Kc8 74. Qb8# Kd7 75. Qd8+ Kc6 76. Qd6+ Kb7 77. Qb6+ Kc8 78. Qb8# Kd7 79. Qd8+ Kc6 80. Qd6+ Kb7 81.",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd2",
            "Nc5",
            "c3",
            "Be7",
            "Bc2",
            "d4",
            "Nb3",
            "d3",
            "Bb1",
            "Bf5",
            "Be3",
            "Nxb3",
            "axb3",
            "O-O",
            "Nd4",
            "Nxd4",
            "cxd4",
            "c5",
            "Bxd3",
            "Bxd3",
            "Qxd3",
            "cxd4",
            "Qxd4",
            "Qxd4",
            "Bxd4",
            "Rfd8",
            "Rfd1",
            "Rd5",
            "Bc3",
            "Rxd1+",
            "Rxd1",
            "Rd8",
            "Rxd8+",
            "Bxd8",
            "f4",
            "Bb6+",
            "Kf1",
            "Kf8",
            "Ke2",
            "Ke7",
            "Kd3",
            "Ke6",
            "Ke4",
            "g6",
            "g4",
            "Bg1",
            "h3",
            "Bh2",
            "f5+",
            "gxf5+",
            "gxf5+",
            "Ke7",
            "Kd5",
            "Kd7",
            "e6+",
            "fxe6+",
            "fxe6+",
            "Ke7",
            "Bb4+",
            "Ke8",
            "Kc6",
            "Be5",
            "Kb6",
            "Bxb2",
            "Kxa6",
            "Be5",
            "Kxb5",
            "Bf6",
            "Kc6",
            "Bd8",
            "Bd6",
            "Ba5",
            "b4",
            "Bd8",
            "b5",
            "Ba5",
            "b6",
            "Bxb6",
            "Kxb6",
            "Kd8",
            "Kc6",
            "Ke8",
            "Kd5",
            "Kd8",
            "Ke5",
            "Ke8",
            "Kf6",
            "Kd8",
            "Kf7",
            "Kc8",
            "e7",
            "Kb7",
            "e8=Q",
            "Kb6",
            "Qc8",
            "Kb5",
            "Qc5+",
            "Ka4",
            "Qb4#",
            "Ka6",
            "Bc7",
            "Ka7",
            "Qb6+",
            "Ka8",
            "Qb8#",
            "Kd7",
            "Qd8+",
            "Kc6",
            "Qd6+",
            "Kb7",
            "Qb6+",
            "Kc8",
            "Ke7",
            "h5",
            "Qb8#",
            "Kd7",
            "Qd8+",
            "Kc6",
            "Qd6+",
            "Kb7",
            "Qb6+",
            "Kc8",
            "Qb8#",
            "Kd7",
            "Qd8+",
            "Kc6",
            "Qd6+",
            "Kb7",
            "Qb6+",
            "Kc8",
            "Qb8#",
            "Kd7",
            "Qd8+",
            "Kc6",
            "Qd6+",
            "Kb7",
            "Qb6+",
            "Kc8",
            "Qb8#",
            "Kd7",
            "Qd8+",
            "Kc6",
            "Qd6+",
            "Kb7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be6",
          "positional_uci": "c8e6",
          "positional_response": "8... Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxb2 29. Rxb2 Rxb2 30. h4 Kf7 31. h5 Kf6 32. Bg4 Ke5 33. Bd7 Kd6 34. Bf5 h6 35. Kd1 c5 36. Kc1 Rf2 37. Bg6 b4 38. cxb4 cxb4 39. Kb1 Kc5 40. Kc1 Kc4 41. Kb1 Kc3 42. Ka1 b3 43. Bb1 Rf1\n* 44. 1-0",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 309,
            "total_tokens": 480,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c3",
            "Bc5",
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxb2",
            "Rxb2",
            "Rxb2",
            "h4",
            "Kf7",
            "h5",
            "Kf6",
            "Bg4",
            "Ke5",
            "Bd7",
            "Kd6",
            "Bf5",
            "h6",
            "Kd1",
            "c5",
            "Kc1",
            "Rf2",
            "Bg6",
            "b4",
            "cxb4",
            "cxb4",
            "Kb1",
            "Kc5",
            "Kc1",
            "Kc4",
            "Kb1",
            "Kc3",
            "Ka1",
            "b3",
            "Bb1",
            "Rf1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be6",
          "neutral_uci": "c8e6",
          "neutral_response": "8... Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6\n* 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6\n* 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxb2\n* 29. Rxb2 Rxb2 30. h3 Kf7 31. Bg4 Kf6 32. Bd7 c5 33. Bc6 Ke5 34. Kd1 d4 35. cxd4+ Kxd4\n* 36. Kc1 Kc3 37. Be4 Re2 38. Bf3 Re1+ 39. Bd1 b4 40. h4 b3 41. h5 b2+ 42. Kb1 Rxd1+ 43. Ka2 Ra1# e4 e5 Nf3 Nc6 Bb5 d5 dxe5 Be6 c3 Bc5 Nbd2 O-O Bc2 Nxf2 Rxf2 f6 exf6 Bxf2 Kxf2 Qxf6 Kg1 Rae8 Nb3 Ne5 Nbd4 Bg4 Bg5 Nxf3+ Nxf3 Bxf3 Bxf6 Bxd1 Rxd1 Rxf6 Bb3 c6 a4 Re2 axb5 axb5 Rb1 Rff2 Bd1 Rxg2+ Kf1 Ref2+ Ke1 Rxb2 Rxb2 Rxb2 h3 Kf7 Bg4 Kf6 Bd7 c5 Bc6 Ke5 Kd1 d4 cxd4+ Kxd4 Kc1 c4 Bc6 Kc3 Be4 b3+ Kb1 Rxd1+ Ka2 Ra1#",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 502,
            "total_tokens": 672,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c3",
            "Bc5",
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxb2",
            "Rxb2",
            "Rxb2",
            "h3",
            "Kf7",
            "Bg4",
            "Kf6",
            "Bd7",
            "c5",
            "Bc6",
            "Ke5",
            "Kd1",
            "d4",
            "cxd4+",
            "Kxd4",
            "Kc1",
            "c4",
            "Bc6",
            "Kc3",
            "Be4",
            "b3+",
            "Kb1",
            "Rxd1+",
            "Ka2",
            "Ra1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8e6",
          "positional_uci": "c8e6",
          "neutral_uci": "c8e6",
          "consensus_move": "c8e6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd2",
              "Nc5",
              "c3",
              "Be7",
              "Bc2",
              "d4",
              "Nb3",
              "d3",
              "Bb1",
              "Bf5",
              "Be3",
              "Nxb3",
              "axb3",
              "O-O",
              "Nd4",
              "Nxd4",
              "cxd4",
              "c5",
              "Bxd3",
              "Bxd3",
              "Qxd3",
              "cxd4",
              "Qxd4",
              "Qxd4",
              "Bxd4",
              "Rfd8",
              "Rfd1",
              "Rd5",
              "Bc3",
              "Rxd1+",
              "Rxd1",
              "Rd8",
              "Rxd8+",
              "Bxd8",
              "f4",
              "Bb6+",
              "Kf1",
              "Kf8",
              "Ke2",
              "Ke7",
              "Kd3",
              "Ke6",
              "Ke4",
              "g6",
              "g4",
              "Bg1",
              "h3",
              "Bh2",
              "f5+",
              "gxf5+",
              "gxf5+",
              "Ke7",
              "Kd5",
              "Kd7",
              "e6+",
              "fxe6+",
              "fxe6+",
              "Ke7",
              "Bb4+",
              "Ke8",
              "Kc6",
              "Be5",
              "Kb6",
              "Bxb2",
              "Kxa6",
              "Be5",
              "Kxb5",
              "Bf6",
              "Kc6",
              "Bd8",
              "Bd6",
              "Ba5",
              "b4",
              "Bd8",
              "b5",
              "Ba5",
              "b6",
              "Bxb6",
              "Kxb6",
              "Kd8",
              "Kc6",
              "Ke8",
              "Kd5",
              "Kd8",
              "Ke5",
              "Ke8",
              "Kf6",
              "Kd8",
              "Kf7",
              "Kc8",
              "e7",
              "Kb7",
              "e8=Q",
              "Kb6",
              "Qc8",
              "Kb5",
              "Qc5+",
              "Ka4",
              "Qb4#",
              "Ka6",
              "Bc7",
              "Ka7",
              "Qb6+",
              "Ka8",
              "Qb8#",
              "Kd7",
              "Qd8+",
              "Kc6",
              "Qd6+",
              "Kb7",
              "Qb6+",
              "Kc8",
              "Ke7",
              "h5",
              "Qb8#",
              "Kd7",
              "Qd8+",
              "Kc6",
              "Qd6+",
              "Kb7",
              "Qb6+",
              "Kc8",
              "Qb8#",
              "Kd7",
              "Qd8+",
              "Kc6",
              "Qd6+",
              "Kb7",
              "Qb6+",
              "Kc8",
              "Qb8#",
              "Kd7",
              "Qd8+",
              "Kc6",
              "Qd6+",
              "Kb7",
              "Qb6+",
              "Kc8",
              "Qb8#",
              "Kd7",
              "Qd8+",
              "Kc6",
              "Qd6+",
              "Kb7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "c3",
              "Bc5",
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxb2",
              "Rxb2",
              "Rxb2",
              "h4",
              "Kf7",
              "h5",
              "Kf6",
              "Bg4",
              "Ke5",
              "Bd7",
              "Kd6",
              "Bf5",
              "h6",
              "Kd1",
              "c5",
              "Kc1",
              "Rf2",
              "Bg6",
              "b4",
              "cxb4",
              "cxb4",
              "Kb1",
              "Kc5",
              "Kc1",
              "Kc4",
              "Kb1",
              "Kc3",
              "Ka1",
              "b3",
              "Bb1",
              "Rf1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c3",
              "Bc5",
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxb2",
              "Rxb2",
              "Rxb2",
              "h3",
              "Kf7",
              "Bg4",
              "Kf6",
              "Bd7",
              "c5",
              "Bc6",
              "Ke5",
              "Kd1",
              "d4",
              "cxd4+",
              "Kxd4",
              "Kc1",
              "c4",
              "Bc6",
              "Kc3",
              "Be4",
              "b3+",
              "Kb1",
              "Rxd1+",
              "Ka2",
              "Ra1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 309,
            "total_tokens": 480,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 502,
            "total_tokens": 672,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1451,
          "total_tokens": 1963
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 309,
            "total_tokens": 480,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 502,
            "total_tokens": 672,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/2p2ppp/p1n5/1p1pP3/4n3/1B3N2/PPP2PPP/RNBQ1RK1 b kq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc5",
          "aggressive_uci": "f8c5",
          "aggressive_response": "9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Bf3 c3 34. Bxc6 c2 35. Kd2 h5 36. Kc1 Ra2 37. Bd5+ Kh7 38. Bxa2 g5 39. Kxc2 h4 40. Kd2 g4 41. Ke2 h3 42. Kf2 h2 43. Kg2 g3 44. Bd5 Kg6 45. Kxg3 h1=Q 46. Bxh1 *",
          "aggressive_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 316,
            "total_tokens": 494,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxh2",
            "b3",
            "Rb2",
            "Rxb2",
            "Rxb2",
            "c4",
            "bxc4",
            "bxc4",
            "dxc4",
            "Bf3",
            "c3",
            "Bxc6",
            "c2",
            "Kd2",
            "h5",
            "Kc1",
            "Ra2",
            "Bd5+",
            "Kh7",
            "Bxa2",
            "g5",
            "Kxc2",
            "h4",
            "Kd2",
            "g4",
            "Ke2",
            "h3",
            "Kf2",
            "h2",
            "Kg2",
            "g3",
            "Bd5",
            "Kg6",
            "Kxg3",
            "h1=Q",
            "Bxh1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bc5",
          "positional_uci": "f8c5",
          "positional_response": "9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Be2 c3 34. Kd1 Rd2+ 35. Ke1 Rxe2+ 36. Kxe2 h5 37. Kd3 h4 38. Kxc3 h3 39. Kd3 h2 40. Ke3 h1=Q 41. Kf2 Qh3 42. Ke2 Qg3 43. Kd2 Qf3 44. Kc2 Qe3 45. Kb2 Qd3 46. Ka2 Qc3 47. Kb1 Qd2 48. Ka1 c5 49. Kb1 c4 50. Ka1 c3 51. Kb1 Qb2# 0-1\n9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Be2 c3 34. Kd1 Rd2+ 35. Ke1 Rxe2+ 36. Kxe2 h5 37. Kd3 h4 38. Kxc3 h3 39. Kd3 h2 40. Ke3 h1=Q 41. Kf2 Qh3",
          "positional_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxh2",
            "b3",
            "Rb2",
            "Rxb2",
            "Rxb2",
            "c4",
            "bxc4",
            "bxc4",
            "dxc4",
            "Be2",
            "c3",
            "Kd1",
            "Rd2+",
            "Ke1",
            "Rxe2+",
            "Kxe2",
            "h5",
            "Kd3",
            "h4",
            "Kxc3",
            "h3",
            "Kd3",
            "h2",
            "Ke3",
            "h1=Q",
            "Kf2",
            "Qh3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bc5",
          "neutral_uci": "f8c5",
          "neutral_response": "9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxb2 29. Rxb2 Rxb2 30. h4 Kf7 31. Bg4 Kf6 32. Bd7 c5 33. Bc6 Ke5 34. Kd1 b4 35. cxb4 Rxb4 36. h5 Rh4 37. Be8 Kd4 38. Kd2 Rh2+ 39. Kd1 Kd3 40. Ke1 c4 41. Bf7 d4 42. Kf1 c3 43. Kg1 Rb2 44. Bg8 c2 45. Bxh7+ Ke3 46. Bxc2 Rxc2 47. Kf1 d3 48. h6 gxh6 49. Kg1 Kf3 50. Kh1 Kg3 51. Kg1 Rc1# 0-1\n9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxb2 29. Rxb2 Rxb2 30. h4 Kf7 31. Bg4 Kf6 32. Bd7 c5 33. Bc6 Ke5 34. Kd1 b4 35. cxb4 Rxb4 36. h5 Rh4 37. Be8 Kd4 38. Kd2 Rh2+ 39. Kd1 Kd3 40. Ke1 c4 41. Bf7 d4 42. K",
          "neutral_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxb2",
            "Rxb2",
            "Rxb2",
            "h4",
            "Kf7",
            "Bg4",
            "Kf6",
            "Bd7",
            "c5",
            "Bc6",
            "Ke5",
            "Kd1",
            "b4",
            "cxb4",
            "Rxb4",
            "h5",
            "Rh4",
            "Be8",
            "Kd4",
            "Kd2",
            "Rh2+",
            "Kd1",
            "Kd3",
            "Ke1",
            "c4",
            "Bf7",
            "d4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8c5",
          "positional_uci": "f8c5",
          "neutral_uci": "f8c5",
          "consensus_move": "f8c5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxh2",
              "b3",
              "Rb2",
              "Rxb2",
              "Rxb2",
              "c4",
              "bxc4",
              "bxc4",
              "dxc4",
              "Bf3",
              "c3",
              "Bxc6",
              "c2",
              "Kd2",
              "h5",
              "Kc1",
              "Ra2",
              "Bd5+",
              "Kh7",
              "Bxa2",
              "g5",
              "Kxc2",
              "h4",
              "Kd2",
              "g4",
              "Ke2",
              "h3",
              "Kf2",
              "h2",
              "Kg2",
              "g3",
              "Bd5",
              "Kg6",
              "Kxg3",
              "h1=Q",
              "Bxh1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxh2",
              "b3",
              "Rb2",
              "Rxb2",
              "Rxb2",
              "c4",
              "bxc4",
              "bxc4",
              "dxc4",
              "Be2",
              "c3",
              "Kd1",
              "Rd2+",
              "Ke1",
              "Rxe2+",
              "Kxe2",
              "h5",
              "Kd3",
              "h4",
              "Kxc3",
              "h3",
              "Kd3",
              "h2",
              "Ke3",
              "h1=Q",
              "Kf2",
              "Qh3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxb2",
              "Rxb2",
              "Rxb2",
              "h4",
              "Kf7",
              "Bg4",
              "Kf6",
              "Bd7",
              "c5",
              "Bc6",
              "Ke5",
              "Kd1",
              "b4",
              "cxb4",
              "Rxb4",
              "h5",
              "Rh4",
              "Be8",
              "Kd4",
              "Kd2",
              "Rh2+",
              "Kd1",
              "Kd3",
              "Ke1",
              "c4",
              "Bf7",
              "d4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 178,
            "completion_tokens": 316,
            "total_tokens": 494,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 533,
          "total_completion_tokens": 1596,
          "total_tokens": 2129
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 178,
            "completion_tokens": 316,
            "total_tokens": 494,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2qkb1r/2p2ppp/p1n1b3/1p1pP3/4n3/1BP2N2/PP3PPP/RNBQ1RK1 b kq - 0 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxf2",
          "aggressive_uci": "e4f2",
          "aggressive_response": "10... Nxf2 11. Rxf2 O-O 12. Nf1 Bxf2+ 13. Kxf2 f6 14. exf6 Qxf6 15. Be3 Ne5 16. Kg1 Nxf3+ 17. Qxf3 Qxf3 18. gxf3 Rxf3 19. Re1 c6 20. Bd1 Rf6 21. Ng3 Re8 22. Bd4 Rff8 23. Bh5 Bf7 24. Rxe8 Rxe8 25. Bxf7+ Kxf7 26. Kf2 g6 27. Ne2 Ke6 28. Nf4+ Kf5 29. Nd3 Ke4 30. Nc5+ Kf4 31. Nxa6 Ra8 32. Nb4 Ke4 33. a3 Rc8 34. Bc5 g5 35. Nc2 Kd3 36. Nd4 Kc4 37. Be7 c5 38. Nf5 Kb3 39. Nd6 Rc6 40. Nxb5 Kxb2 41. a4 Kb3 42. a5 Ka4 43. Na7 Rc7 44. Bxg5 Rxa7 45. Be3 Rxa5 46. Ke2 Kb3 47. Kd3 Ra2 48. Bxc5 Rxh2 49. Bd6 Rh3+ 50. Kd4 Rxc3 51. Kxd5 Rd3+ 52. Ke6 Rxd6+ 53. Kxd6 h5 54. Ke5 h4 55. Kf4 h3 56. Kg3 h2 57. Kxh2 1/2-1/2 e4 d4",
          "aggressive_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 399,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf2",
            "O-O",
            "Nf1",
            "Bxf2+",
            "Kxf2",
            "f6",
            "exf6",
            "Qxf6",
            "Be3",
            "Ne5",
            "Kg1",
            "Nxf3+",
            "Qxf3",
            "Qxf3",
            "gxf3",
            "Rxf3",
            "Re1",
            "c6",
            "Bd1",
            "Rf6",
            "Ng3",
            "Re8",
            "Bd4",
            "Rff8",
            "Bh5",
            "Bf7",
            "Rxe8",
            "Rxe8",
            "Bxf7+",
            "Kxf7",
            "Kf2",
            "g6",
            "Ne2",
            "Ke6",
            "Nf4+",
            "Kf5",
            "Nd3",
            "Ke4",
            "Nc5+",
            "Kf4",
            "Nxa6",
            "Ra8",
            "Nb4",
            "Ke4",
            "a3",
            "Rc8",
            "Bc5",
            "g5",
            "Nc2",
            "Kd3",
            "Nd4",
            "Kc4",
            "Be7",
            "c5",
            "Nf5",
            "Kb3",
            "Nd6",
            "Rc6",
            "Nxb5",
            "Kxb2",
            "a4",
            "Kb3",
            "a5",
            "Ka4",
            "Na7",
            "Rc7",
            "Bxg5",
            "Rxa7",
            "Be3",
            "Rxa5",
            "Ke2",
            "Kb3",
            "Kd3",
            "Ra2",
            "Bxc5",
            "Rxh2",
            "Bd6",
            "Rh3+",
            "Kd4",
            "Rxc3",
            "Kxd5",
            "Rd3+",
            "Ke6",
            "Rxd6+",
            "Kxd6",
            "h5",
            "Ke5",
            "h4",
            "Kf4",
            "h3",
            "Kg3",
            "h2",
            "Kxh2",
            "e4",
            "d4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxf2",
          "positional_uci": "e4f2",
          "positional_response": "10... Nxf2 11. Rxf2 O-O 12. Bc2 Bxf2+ 13. Kxf2 f6 14. exf6 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# 0-1\n10 Nxf2 11 Rxf2 O-O 12 Bc2 Bxf2+ 13 Kxf2 f6 14 exf6 Qxf6 15 Kg1 Rae8 16 Nb3 Ne5 17 Nbd4 Bg4 18 Bg5 Nxf3+ 19 Nxf3 Qb6+ 20 Kh1 Qf2 21 Qxd5+ Kh8 22 Qd3 Bf5 23 Qd2 Re2 24 Qxe2 Qxe2 25 Bxf5 Rxf5 26 Re1 Qxe1+ 27 Nxe1 Rf1# 0-1",
          "positional_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 300,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf2",
            "O-O",
            "Bc2",
            "Bxf2+",
            "Kxf2",
            "f6",
            "exf6",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Qb6+",
            "Kh1",
            "Qf2",
            "Qxd5+",
            "Kh8",
            "Qd3",
            "Bf5",
            "Qd2",
            "Re2",
            "Qxe2",
            "Qxe2",
            "Bxf5",
            "Rxf5",
            "Re1",
            "Qxe1+",
            "Nxe1",
            "Rf1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 11. Bc2 Nxf2 12. Rxf2 Bxf2+ 13. Kxf2 f6 14. exf6 Qxf6\n15. Kg1 Bg4 16. Qf1 Rf8 17. Qd3 Bf5 18. Qxd5+ Kh8 19. Bxf5 Qxf5 20. Qxc6 Rae8\n21. Nf1 Re1 22. Be3 Rxa1 23. Bd4 Qd3 24. h3 Rxf1+ 25. Kh2 R1xf3 26. gxf3 Qxf3\n27. Qxc7 Qe2+ 28. Kg3 Rf3+ 29. Kh4 Qe4+ 30. Kg5 Rf5# Rf8+ Kg8 Qg7#",
          "neutral_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 188,
            "total_tokens": 374,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "Nxf2",
            "Rxf2",
            "Bxf2+",
            "Kxf2",
            "f6",
            "exf6",
            "Qxf6",
            "Kg1",
            "Bg4",
            "Qf1",
            "Rf8",
            "Qd3",
            "Bf5",
            "Qxd5+",
            "Kh8",
            "Bxf5",
            "Qxf5",
            "Qxc6",
            "Rae8",
            "Nf1",
            "Re1",
            "Be3",
            "Rxa1",
            "Bd4",
            "Qd3",
            "h3",
            "Rxf1+",
            "Kh2",
            "R1xf3",
            "gxf3",
            "Qxf3",
            "Qxc7",
            "Qe2+",
            "Kg3",
            "Rf3+",
            "Kh4",
            "Qe4+",
            "Kg5",
            "Rf5#",
            "Rf8+",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4f2",
          "positional_uci": "e4f2",
          "neutral_uci": null,
          "consensus_move": "e4f2",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxf2",
              "O-O",
              "Nf1",
              "Bxf2+",
              "Kxf2",
              "f6",
              "exf6",
              "Qxf6",
              "Be3",
              "Ne5",
              "Kg1",
              "Nxf3+",
              "Qxf3",
              "Qxf3",
              "gxf3",
              "Rxf3",
              "Re1",
              "c6",
              "Bd1",
              "Rf6",
              "Ng3",
              "Re8",
              "Bd4",
              "Rff8",
              "Bh5",
              "Bf7",
              "Rxe8",
              "Rxe8",
              "Bxf7+",
              "Kxf7",
              "Kf2",
              "g6",
              "Ne2",
              "Ke6",
              "Nf4+",
              "Kf5",
              "Nd3",
              "Ke4",
              "Nc5+",
              "Kf4",
              "Nxa6",
              "Ra8",
              "Nb4",
              "Ke4",
              "a3",
              "Rc8",
              "Bc5",
              "g5",
              "Nc2",
              "Kd3",
              "Nd4",
              "Kc4",
              "Be7",
              "c5",
              "Nf5",
              "Kb3",
              "Nd6",
              "Rc6",
              "Nxb5",
              "Kxb2",
              "a4",
              "Kb3",
              "a5",
              "Ka4",
              "Na7",
              "Rc7",
              "Bxg5",
              "Rxa7",
              "Be3",
              "Rxa5",
              "Ke2",
              "Kb3",
              "Kd3",
              "Ra2",
              "Bxc5",
              "Rxh2",
              "Bd6",
              "Rh3+",
              "Kd4",
              "Rxc3",
              "Kxd5",
              "Rd3+",
              "Ke6",
              "Rxd6+",
              "Kxd6",
              "h5",
              "Ke5",
              "h4",
              "Kf4",
              "h3",
              "Kg3",
              "h2",
              "Kxh2",
              "e4",
              "d4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxf2",
              "O-O",
              "Bc2",
              "Bxf2+",
              "Kxf2",
              "f6",
              "exf6",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Qb6+",
              "Kh1",
              "Qf2",
              "Qxd5+",
              "Kh8",
              "Qd3",
              "Bf5",
              "Qd2",
              "Re2",
              "Qxe2",
              "Qxe2",
              "Bxf5",
              "Rxf5",
              "Re1",
              "Qxe1+",
              "Nxe1",
              "Rf1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bc2",
              "Nxf2",
              "Rxf2",
              "Bxf2+",
              "Kxf2",
              "f6",
              "exf6",
              "Qxf6",
              "Kg1",
              "Bg4",
              "Qf1",
              "Rf8",
              "Qd3",
              "Bf5",
              "Qxd5+",
              "Kh8",
              "Bxf5",
              "Qxf5",
              "Qxc6",
              "Rae8",
              "Nf1",
              "Re1",
              "Be3",
              "Rxa1",
              "Bd4",
              "Qd3",
              "h3",
              "Rxf1+",
              "Kh2",
              "R1xf3",
              "gxf3",
              "Qxf3",
              "Qxc7",
              "Qe2+",
              "Kg3",
              "Rf3+",
              "Kh4",
              "Qe4+",
              "Kg5",
              "Rf5#",
              "Rf8+",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 187,
            "completion_tokens": 399,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 187,
            "completion_tokens": 300,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 186,
            "completion_tokens": 188,
            "total_tokens": 374,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 560,
          "total_completion_tokens": 887,
          "total_tokens": 1447
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 187,
            "completion_tokens": 399,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 187,
            "completion_tokens": 300,
            "total_tokens": 487,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 186,
            "completion_tokens": 188,
            "total_tokens": 374,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/4n3/1BP2N2/PP1N1PPP/R1BQ1RK1 b kq - 2 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf2+",
          "aggressive_uci": "c5f2",
          "aggressive_response": "11... Bxf2+ 12. Kxf2 O-O 13. Nf1 Qd7 14. Ne3 Rad8 15. Kg1 d4 16. cxd4 Nxd4 17. Nxd4 Qxd4 18. Qxd4 Rxd4 19. Bxe6 fxe6 20. b3 Re4 21. Bd2 Rxe5 22. Rc1 Rd8 23. Nf1 c5 24. Bf4 Re2 25. Rxc5 Rxa2 26. Rc7 Rd1 27. Be5 g6 28. Rg7+ Kf8 29. Rxh7 Re2 30. Bg3 Rb2 31. Ra7 Ra1 32. Bd6+ Kg8 33. Be5 Rxf1+ 34. Kxf1 Rxb3 35. Rxa6 Kf7 36. Ra7+ Ke8 37. Rg7 Re3 38. Bd4 Re4 39. Bc5 Rc4 40. Bd6 Rd4 41. Bc5 Rc4 42. Bd6 Rd4 43. Bc5 Rd5 44. Bb4 Rd4 45. Bc5 Rd5 46. Bb4 Rd4 47. Bc5 Rd5 48. Bb4 Rd4 49. Bc5 Rd5 50. Bb4 Rd4 51. Bc5 Rd5 52. Bb4 Rd4 53. Bc5 Rd5 54. Bb4 Rd4 55. Bc5 Rd5 56. Bb4 Rd4 57. Bc5 Rd5 58. Bb4 Rd4 59. Bc5 Rd5 60. Bb4 Rd4 61. Bc5 Rd5 62. Bb4 Rd4 63. Bc5 Rd5 64. Bb4 Rd4 65. Bc5 Rd5 66. Bb4 Rd4 67. Bc5 Rd5 68. Bb4 Rd4 69. Bc5 Rd5 70. Bb4 Rd4 71. Bc5 Rd5 72. Bb4 Rd4 73. Bc5 Rd5 74. Bb4 Rd4 75. Bc5 Rd5 76. Bb4 Rd4 77. Bc5 Rd5 78. Bb4 Rd4 79. Bc5 Rd5 80. Bb4 Rd4 81. Bc5 Rd5 82. Bb4 Rd4 83. Bc5 Rd5 84. Bb4 Rd4 85. Bc5 Rd5 86. Bb4 Rd4 87. Bc5 Rd5 88. Bb4 Rd4 89. Bc5 Rd5 90. Bb4 Rd",
          "aggressive_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxf2",
            "O-O",
            "Nf1",
            "Qd7",
            "Ne3",
            "Rad8",
            "Kg1",
            "d4",
            "cxd4",
            "Nxd4",
            "Nxd4",
            "Qxd4",
            "Qxd4",
            "Rxd4",
            "Bxe6",
            "fxe6",
            "b3",
            "Re4",
            "Bd2",
            "Rxe5",
            "Rc1",
            "Rd8",
            "Nf1",
            "c5",
            "Bf4",
            "Re2",
            "Rxc5",
            "Rxa2",
            "Rc7",
            "Rd1",
            "Be5",
            "g6",
            "Rg7+",
            "Kf8",
            "Rxh7",
            "Re2",
            "Bg3",
            "Rb2",
            "Ra7",
            "Ra1",
            "Bd6+",
            "Kg8",
            "Be5",
            "Rxf1+",
            "Kxf1",
            "Rxb3",
            "Rxa6",
            "Kf7",
            "Ra7+",
            "Ke8",
            "Rg7",
            "Re3",
            "Bd4",
            "Re4",
            "Bc5",
            "Rc4",
            "Bd6",
            "Rd4",
            "Bc5",
            "Rc4",
            "Bd6",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4",
            "Rd4",
            "Bc5",
            "Rd5",
            "Bb4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "Repeated game: 1. e4 e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2\n11. Rxf2 O-O 12. Bc2 f6 13. Nb3 Bxf2+ 14. Kxf2 fxe5 15. Kg1 Bg4 16. Be3 e4 17. h3\nBh5 18. g4 Rxf3 19. gxh5 Rxe3 20. Qg4 Qd6 21. Kg2 Ne5 22. Qg5 Re2+ 23. Kf1 Rxc2\n24. Nd4 Rf8+ 25. Ke1 Nd3+ 26. Kd1 Rxb2 27. Nf5 Rxf5 28. Qxf5 Qc6 29. Qc8+ Kf7\n30. Qf5+ Ke7 31. Qg5+ Kd6 32. Qg3+ Kc5 33. Qe3+ Kc4 34. Qd4# * 33...Kc4 34.\nQd4#",
          "positional_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 308,
            "total_tokens": 504,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc2",
            "f6",
            "Nb3",
            "Bxf2+",
            "Kxf2",
            "fxe5",
            "Kg1",
            "Bg4",
            "Be3",
            "e4",
            "h3",
            "Bh5",
            "g4",
            "Rxf3",
            "gxh5",
            "Rxe3",
            "Qg4",
            "Qd6",
            "Kg2",
            "Ne5",
            "Qg5",
            "Re2+",
            "Kf1",
            "Rxc2",
            "Nd4",
            "Rf8+",
            "Ke1",
            "Nd3+",
            "Kd1",
            "Rxb2",
            "Nf5",
            "Rxf5",
            "Qxf5",
            "Qc6",
            "Qc8+",
            "Kf7",
            "Qf5+",
            "Ke7",
            "Qg5+",
            "Kd6",
            "Qg3+",
            "Kc5",
            "Qe3+",
            "Kc4",
            "Qd4#",
            "Kc4",
            "Qd4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf2+",
          "neutral_uci": "c5f2",
          "neutral_response": "11... Bxf2+ 12. Kxf2 O-O 13. Nf1 Qd7 14. Be3 Rfe8 15. Ng3 Rad8 16. Bc2 Bg4 17. Qd3 g6 18. Bg5 Rc8 19. Re1 Bxf3 20. Qxf3 Nxe5 21. Qf4 Ng4+ 22. Kf1 Nxh2+ 23. Kf2 Ng4+ 24. Kf1 Rxe1+ 25. Kxe1 Re8+ 26. Kd2 Ne3 27. Bd3 Nc4+ 28. Kc2 Ne3+ 29. Kd2 Nc4+ 30. Kc2 Ne3+ 31. Kd2 Nc4+ 32. Kc2 Ne3+ 33. Kd2 Nc4+ 34. Kc2 Ne3+ 35. Kd2 Nc4+ 36. Kc2 Ne3+ 37. Kd2 Nc4+ 38. Kc2 Ne3+ 39. Kd2 Nc4+ 40. Kc2 Ne3+ 41. Kd2 Nc4+ 42. Kc2 Ne3+ 43. Kd2 Nc4+ 44. Kc2 Ne3+ 45. Kd2 Nc4+ 46. Kc2 Ne3+ 47. Kd2 Nc4+ 48. Kc2 Ne3+ 49. Kd2 Nc4+ 50. Kc2 Ne3+ 51. Kd2 Nc4+ 52. Kc2 Ne3+ 53. Kd2 Nc4+ 54. Kc2 Ne3+ 55. Kd2 Nc4+ 56. Kc2 Ne3+ 57. Kd2 Nc4+ 58. Kc2 Ne3+ 59. Kd2 Nc4+ 60. Kc2 Ne3+ 61. Kd2 Nc4+ 62. Kc2 Ne3+ 63. Kd2 Nc4+ 64. Kc2 Ne3+ 65. Kd2 Nc4+ 66. Kc2 Ne3+ 67. Kd2 Nc4+ 68. Kc2 Ne3+ 69. Kd2 Nc4+ 70. Kc2 Ne3+ 71. Kd2 Nc4+ 72. Kc2 Ne3+ 73. Kd2 Nc4+ 74. Kc2 Ne3+ 75. Kd2 Nc4+ 76. Kc2 Ne3+ 77. Kd2 Nc4+ 78. Kc2 Ne3+ 79. Kd2 Nc4+",
          "neutral_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxf2",
            "O-O",
            "Nf1",
            "Qd7",
            "Be3",
            "Rfe8",
            "Ng3",
            "Rad8",
            "Bc2",
            "Bg4",
            "Qd3",
            "g6",
            "Bg5",
            "Rc8",
            "Re1",
            "Bxf3",
            "Qxf3",
            "Nxe5",
            "Qf4",
            "Ng4+",
            "Kf1",
            "Nxh2+",
            "Kf2",
            "Ng4+",
            "Kf1",
            "Rxe1+",
            "Kxe1",
            "Re8+",
            "Kd2",
            "Ne3",
            "Bd3",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd2",
            "Nc4+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c5f2",
          "positional_uci": "e8g8",
          "neutral_uci": "c5f2",
          "consensus_move": "c5f2",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxf2",
              "O-O",
              "Nf1",
              "Qd7",
              "Ne3",
              "Rad8",
              "Kg1",
              "d4",
              "cxd4",
              "Nxd4",
              "Nxd4",
              "Qxd4",
              "Qxd4",
              "Rxd4",
              "Bxe6",
              "fxe6",
              "b3",
              "Re4",
              "Bd2",
              "Rxe5",
              "Rc1",
              "Rd8",
              "Nf1",
              "c5",
              "Bf4",
              "Re2",
              "Rxc5",
              "Rxa2",
              "Rc7",
              "Rd1",
              "Be5",
              "g6",
              "Rg7+",
              "Kf8",
              "Rxh7",
              "Re2",
              "Bg3",
              "Rb2",
              "Ra7",
              "Ra1",
              "Bd6+",
              "Kg8",
              "Be5",
              "Rxf1+",
              "Kxf1",
              "Rxb3",
              "Rxa6",
              "Kf7",
              "Ra7+",
              "Ke8",
              "Rg7",
              "Re3",
              "Bd4",
              "Re4",
              "Bc5",
              "Rc4",
              "Bd6",
              "Rd4",
              "Bc5",
              "Rc4",
              "Bd6",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4",
              "Rd4",
              "Bc5",
              "Rd5",
              "Bb4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bc2",
              "f6",
              "Nb3",
              "Bxf2+",
              "Kxf2",
              "fxe5",
              "Kg1",
              "Bg4",
              "Be3",
              "e4",
              "h3",
              "Bh5",
              "g4",
              "Rxf3",
              "gxh5",
              "Rxe3",
              "Qg4",
              "Qd6",
              "Kg2",
              "Ne5",
              "Qg5",
              "Re2+",
              "Kf1",
              "Rxc2",
              "Nd4",
              "Rf8+",
              "Ke1",
              "Nd3+",
              "Kd1",
              "Rxb2",
              "Nf5",
              "Rxf5",
              "Qxf5",
              "Qc6",
              "Qc8+",
              "Kf7",
              "Qf5+",
              "Ke7",
              "Qg5+",
              "Kd6",
              "Qg3+",
              "Kc5",
              "Qe3+",
              "Kc4",
              "Qd4#",
              "Kc4",
              "Qd4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxf2",
              "O-O",
              "Nf1",
              "Qd7",
              "Be3",
              "Rfe8",
              "Ng3",
              "Rad8",
              "Bc2",
              "Bg4",
              "Qd3",
              "g6",
              "Bg5",
              "Rc8",
              "Re1",
              "Bxf3",
              "Qxf3",
              "Nxe5",
              "Qf4",
              "Ng4+",
              "Kf1",
              "Nxh2+",
              "Kf2",
              "Ng4+",
              "Kf1",
              "Rxe1+",
              "Kxe1",
              "Re8+",
              "Kd2",
              "Ne3",
              "Bd3",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd2",
              "Nc4+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 196,
            "completion_tokens": 308,
            "total_tokens": 504,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 587,
          "total_completion_tokens": 1588,
          "total_tokens": 2175
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 196,
            "completion_tokens": 308,
            "total_tokens": 504,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 195,
            "completion_tokens": 640,
            "total_tokens": 835,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/8/1BP2N2/PP1N1RPP/R1BQ2K1 b kq - 0 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e8g8",
          "aggressive_response": "12... O-O 13. Nf1 f6 14. exf6 Qxf6 15. Bg5 Qf7 16. Kg1 h6 17. Be3 Rad8 18. Bc5 Rfe8\n19. Qd2 Na5 20. Ne5 Qf6 21. Bd4 Nxb3 22. axb3 c5 23. Nc6 cxd4 24. Nxd8 Rxd8 25.\nQxd4 Qxd4+ 26. cxd4 Rd6 27. Ne3 Rc6 28. Kf2 Kf7 29. Ke2 Ke7 30. Kd2 Kd6 31. b4\nBc8 32. Rf1 Rc7 33. Rf8 Be6 34. Ra8 Bc8 35. Nd1 Rc4 36. Nc3 Rxd4+ 37. Ke3 Rc4\n38. Kd3 Bf5+ 39. Kd2 d4 40. Rxa6+ Ke5 41. Nxb5 Rc2+ 42. Kd1 Rxb2 43. Ra7 Rxb4\n44. Na3 g6 45. Ra5+ Ke4 46. Nc2 Rb1+ 47. Kd2 Rg1 48. Ne1 Rh1 49. h3 Rf1 50.\nKe2 Rf4 51. Nd3 Rh4 52. Re5# O-O-O 53. Rc5+ Kb7 54. Rb5+ Kc6 55. Rc5+ Kd6 56.\nRa5 Re4+ 57. Kd2 Re3 58. Ra6+ Kd5 59. Nf4+ Ke4 60. Nxg6 Rg3 61. Nh4 Bxh3 62.\ngxh3 Rxh3 63. Rxh6 Rh2+ 64. Kd1 Kd3 65. Ke1 Kc2 66. Rc6+ Kd3 67. Nf3 Rh1+\n68. Kf2 Rh5 69. Rd6 Kc3 70. Rxd4 Rf5 71. Rd8 Rf7 72. Ke3 Re7+ 73. Kf4 Rf7+\n74. Ke4 Re7+ 75. Ne5 Rh7 76. Rc8+ Kd2 77. Nf3+ Ke2 78. Rc2+ Kd1 79. Rd2+ Kc1\n80. Rd8 Re7+ 81. Ne5 Rh7 82. Kd3 Rh3+ 83. Kc4 Rh4+ 84. Kc3 Rh3+ 85. Nd3+ Kd1\n86. Re8 Rh2 87. Re1# e5 d5 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf1",
            "f6",
            "exf6",
            "Qxf6",
            "Bg5",
            "Qf7",
            "Kg1",
            "h6",
            "Be3",
            "Rad8",
            "Bc5",
            "Rfe8",
            "Qd2",
            "Na5",
            "Ne5",
            "Qf6",
            "Bd4",
            "Nxb3",
            "axb3",
            "c5",
            "Nc6",
            "cxd4",
            "Nxd8",
            "Rxd8",
            "Qxd4",
            "Qxd4+",
            "cxd4",
            "Rd6",
            "Ne3",
            "Rc6",
            "Kf2",
            "Kf7",
            "Ke2",
            "Ke7",
            "Kd2",
            "Kd6",
            "b4",
            "Bc8",
            "Rf1",
            "Rc7",
            "Rf8",
            "Be6",
            "Ra8",
            "Bc8",
            "Nd1",
            "Rc4",
            "Nc3",
            "Rxd4+",
            "Ke3",
            "Rc4",
            "Kd3",
            "Bf5+",
            "Kd2",
            "d4",
            "Rxa6+",
            "Ke5",
            "Nxb5",
            "Rc2+",
            "Kd1",
            "Rxb2",
            "Ra7",
            "Rxb4",
            "Na3",
            "g6",
            "Ra5+",
            "Ke4",
            "Nc2",
            "Rb1+",
            "Kd2",
            "Rg1",
            "Ne1",
            "Rh1",
            "h3",
            "Rf1",
            "Ke2",
            "Rf4",
            "Nd3",
            "Rh4",
            "Re5#",
            "O-O-O",
            "Rc5+",
            "Kb7",
            "Rb5+",
            "Kc6",
            "Rc5+",
            "Kd6",
            "Ra5",
            "Re4+",
            "Kd2",
            "Re3",
            "Ra6+",
            "Kd5",
            "Nf4+",
            "Ke4",
            "Nxg6",
            "Rg3",
            "Nh4",
            "Bxh3",
            "gxh3",
            "Rxh3",
            "Rxh6",
            "Rh2+",
            "Kd1",
            "Kd3",
            "Ke1",
            "Kc2",
            "Rc6+",
            "Kd3",
            "Nf3",
            "Rh1+",
            "Kf2",
            "Rh5",
            "Rd6",
            "Kc3",
            "Rxd4",
            "Rf5",
            "Rd8",
            "Rf7",
            "Ke3",
            "Re7+",
            "Kf4",
            "Rf7+",
            "Ke4",
            "Re7+",
            "Ne5",
            "Rh7",
            "Rc8+",
            "Kd2",
            "Nf3+",
            "Ke2",
            "Rc2+",
            "Kd1",
            "Rd2+",
            "Kc1",
            "Rd8",
            "Re7+",
            "Ne5",
            "Rh7",
            "Kd3",
            "Rh3+",
            "Kc4",
            "Rh4+",
            "Kc3",
            "Rh3+",
            "Nd3+",
            "Kd1",
            "Re8",
            "Rh2",
            "Re1#",
            "e5",
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "12... O-O 13. Nf1 f6 14. exf6 Qxf6 15. Bg5 Qf7 16. Kg1 Rae8 17. Ne3 h6 18. Bh4 g5 19. Bg3 g4 20. Nd4 Nxd4 21. Qxd4 c6 22. Rf1 Qg6 23. Bc2 Rxf1+ 24. Kxf1 Qf7+ 25. Kg1 Rf8 26. Bd3 h5 27. Qe5 Qf6 28. Qxh5 Rf7 29. Be5 Qf2+ 30. Kh1 Qe1+ 31. Nf1 Rxf1+ 32. Bxf1 Qxf1# 33. Kh2 Qf5 34. Qh8+ Kf7 35. Qg7+ Ke8 36. Bd6 Qf7 37. Qh8+ Kd7 38. Qb8 Bf5 39. Qc7+ Ke6 40. Qxc6 Qd7 41. Qxd7+ Kxd7 42. Bf4 Ke6 43. Kg3 Kf6 44. Kh4 Kg6 45. Be3 Be6 46. Kg3 Kf5 47. h4 gxh3 48. gxh3 Ke4 49. Bd4 Kd3 50. h4 Kc2 51. b4 Kb2 52. h5 Kxa2 53. h6 Bf5 54. Kf4 Bh7 55. Ke5 Kb3 56. Kxd5 Ka4 57. Kc5 a5 58. bxa5 Kxa5 59. Kd6 Ka4 60. Ke7 Kb3 61. Kf7 Kc4 62. Kg7 Bf5 63. h7 Bxh7 64. Kxh7 b4 65. cxb4 Kxd4 66. b5 Kc5 67. b6 Kxb6 68. 0-1 69. Kg3 Kc5 70. Kf3 Kc4 71. Ke2 Kc3",
          "positional_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 499,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf1",
            "f6",
            "exf6",
            "Qxf6",
            "Bg5",
            "Qf7",
            "Kg1",
            "Rae8",
            "Ne3",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "g4",
            "Nd4",
            "Nxd4",
            "Qxd4",
            "c6",
            "Rf1",
            "Qg6",
            "Bc2",
            "Rxf1+",
            "Kxf1",
            "Qf7+",
            "Kg1",
            "Rf8",
            "Bd3",
            "h5",
            "Qe5",
            "Qf6",
            "Qxh5",
            "Rf7",
            "Be5",
            "Qf2+",
            "Kh1",
            "Qe1+",
            "Nf1",
            "Rxf1+",
            "Bxf1",
            "Qxf1#",
            "Kh2",
            "Qf5",
            "Qh8+",
            "Kf7",
            "Qg7+",
            "Ke8",
            "Bd6",
            "Qf7",
            "Qh8+",
            "Kd7",
            "Qb8",
            "Bf5",
            "Qc7+",
            "Ke6",
            "Qxc6",
            "Qd7",
            "Qxd7+",
            "Kxd7",
            "Bf4",
            "Ke6",
            "Kg3",
            "Kf6",
            "Kh4",
            "Kg6",
            "Be3",
            "Be6",
            "Kg3",
            "Kf5",
            "h4",
            "gxh3",
            "gxh3",
            "Ke4",
            "Bd4",
            "Kd3",
            "h4",
            "Kc2",
            "b4",
            "Kb2",
            "h5",
            "Kxa2",
            "h6",
            "Bf5",
            "Kf4",
            "Bh7",
            "Ke5",
            "Kb3",
            "Kxd5",
            "Ka4",
            "Kc5",
            "a5",
            "bxa5",
            "Kxa5",
            "Kd6",
            "Ka4",
            "Ke7",
            "Kb3",
            "Kf7",
            "Kc4",
            "Kg7",
            "Bf5",
            "h7",
            "Bxh7",
            "Kxh7",
            "b4",
            "cxb4",
            "Kxd4",
            "b5",
            "Kc5",
            "b6",
            "Kxb6",
            "Kg3",
            "Kc5",
            "Kf3",
            "Kc4",
            "Ke2",
            "Kc3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e8g8",
          "neutral_response": "12... O-O 13. Nf1 f6 14. exf6 Qxf6 15. Bg5 Qf7 16. Kg1 Rae8 17. Be3 Bxe3+ 18. Nxe3 Ne7 19. Qd3 c6 20. Rf1 Qh5 21. Bc2 Ng6 22. Nd4 Rxf1+ 23. Nxf1 Bd7 24. Ng3 Qe5 25. Nf3 Qe3+ 26. Qxe3 Rxe3 27. Kf2 Re8 28. Nd4 Ne5 29. h3 g6 30. b4 Nc4 31. Nge2 Kg7 32. Nb3 Bf5 33. Bxf5 gxf5 34. Ned4 Kf6 35. Nxc6 Re3 36. Nb8 Rxc3 37. Nxa6 Rc2+ 38. Kf3 Rxa2 39. Nc7 Ke5 40. Nxb5 Rb2 41. N3d4 Nd2+ 42. Ke3 Nf1+ 43. Kf3 Rxb4 44. Nc6+ Kf6 45. Nxb4 Nd2+ 46. Ke3 Nc4+ 47. Kd4 Kg5 48. Nxd5 Nd2 49. Ke3 Nc4+ 50. Kf3 Ne5+ 51. Kg3 h5 52. h4+ Kg6 53. Nf4+ Kh6 54. Nd4 Ng4 55. Nxf5+ Kh7 56. Nxh5 Ne5 57. Nf4 Nf7 58. Kg4 Ne5+ 59. Kg5 Nf7+ 60. Kf6 Nh6 61. Nxh6 Kxh6 62. g4 Kh7 63. g5 Kg8 64. g6 Kh8 65. g7+ Kg8 66. h5 Kh7 67. Kf7 Kh6 68. g8=Q *",
          "neutral_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 472,
            "total_tokens": 677,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf1",
            "f6",
            "exf6",
            "Qxf6",
            "Bg5",
            "Qf7",
            "Kg1",
            "Rae8",
            "Be3",
            "Bxe3+",
            "Nxe3",
            "Ne7",
            "Qd3",
            "c6",
            "Rf1",
            "Qh5",
            "Bc2",
            "Ng6",
            "Nd4",
            "Rxf1+",
            "Nxf1",
            "Bd7",
            "Ng3",
            "Qe5",
            "Nf3",
            "Qe3+",
            "Qxe3",
            "Rxe3",
            "Kf2",
            "Re8",
            "Nd4",
            "Ne5",
            "h3",
            "g6",
            "b4",
            "Nc4",
            "Nge2",
            "Kg7",
            "Nb3",
            "Bf5",
            "Bxf5",
            "gxf5",
            "Ned4",
            "Kf6",
            "Nxc6",
            "Re3",
            "Nb8",
            "Rxc3",
            "Nxa6",
            "Rc2+",
            "Kf3",
            "Rxa2",
            "Nc7",
            "Ke5",
            "Nxb5",
            "Rb2",
            "N3d4",
            "Nd2+",
            "Ke3",
            "Nf1+",
            "Kf3",
            "Rxb4",
            "Nc6+",
            "Kf6",
            "Nxb4",
            "Nd2+",
            "Ke3",
            "Nc4+",
            "Kd4",
            "Kg5",
            "Nxd5",
            "Nd2",
            "Ke3",
            "Nc4+",
            "Kf3",
            "Ne5+",
            "Kg3",
            "h5",
            "h4+",
            "Kg6",
            "Nf4+",
            "Kh6",
            "Nd4",
            "Ng4",
            "Nxf5+",
            "Kh7",
            "Nxh5",
            "Ne5",
            "Nf4",
            "Nf7",
            "Kg4",
            "Ne5+",
            "Kg5",
            "Nf7+",
            "Kf6",
            "Nh6",
            "Nxh6",
            "Kxh6",
            "g4",
            "Kh7",
            "g5",
            "Kg8",
            "g6",
            "Kh8",
            "g7+",
            "Kg8",
            "h5",
            "Kh7",
            "Kf7",
            "Kh6",
            "g8=Q"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e8g8",
          "positional_uci": "e8g8",
          "neutral_uci": "e8g8",
          "consensus_move": "e8g8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf1",
              "f6",
              "exf6",
              "Qxf6",
              "Bg5",
              "Qf7",
              "Kg1",
              "h6",
              "Be3",
              "Rad8",
              "Bc5",
              "Rfe8",
              "Qd2",
              "Na5",
              "Ne5",
              "Qf6",
              "Bd4",
              "Nxb3",
              "axb3",
              "c5",
              "Nc6",
              "cxd4",
              "Nxd8",
              "Rxd8",
              "Qxd4",
              "Qxd4+",
              "cxd4",
              "Rd6",
              "Ne3",
              "Rc6",
              "Kf2",
              "Kf7",
              "Ke2",
              "Ke7",
              "Kd2",
              "Kd6",
              "b4",
              "Bc8",
              "Rf1",
              "Rc7",
              "Rf8",
              "Be6",
              "Ra8",
              "Bc8",
              "Nd1",
              "Rc4",
              "Nc3",
              "Rxd4+",
              "Ke3",
              "Rc4",
              "Kd3",
              "Bf5+",
              "Kd2",
              "d4",
              "Rxa6+",
              "Ke5",
              "Nxb5",
              "Rc2+",
              "Kd1",
              "Rxb2",
              "Ra7",
              "Rxb4",
              "Na3",
              "g6",
              "Ra5+",
              "Ke4",
              "Nc2",
              "Rb1+",
              "Kd2",
              "Rg1",
              "Ne1",
              "Rh1",
              "h3",
              "Rf1",
              "Ke2",
              "Rf4",
              "Nd3",
              "Rh4",
              "Re5#",
              "O-O-O",
              "Rc5+",
              "Kb7",
              "Rb5+",
              "Kc6",
              "Rc5+",
              "Kd6",
              "Ra5",
              "Re4+",
              "Kd2",
              "Re3",
              "Ra6+",
              "Kd5",
              "Nf4+",
              "Ke4",
              "Nxg6",
              "Rg3",
              "Nh4",
              "Bxh3",
              "gxh3",
              "Rxh3",
              "Rxh6",
              "Rh2+",
              "Kd1",
              "Kd3",
              "Ke1",
              "Kc2",
              "Rc6+",
              "Kd3",
              "Nf3",
              "Rh1+",
              "Kf2",
              "Rh5",
              "Rd6",
              "Kc3",
              "Rxd4",
              "Rf5",
              "Rd8",
              "Rf7",
              "Ke3",
              "Re7+",
              "Kf4",
              "Rf7+",
              "Ke4",
              "Re7+",
              "Ne5",
              "Rh7",
              "Rc8+",
              "Kd2",
              "Nf3+",
              "Ke2",
              "Rc2+",
              "Kd1",
              "Rd2+",
              "Kc1",
              "Rd8",
              "Re7+",
              "Ne5",
              "Rh7",
              "Kd3",
              "Rh3+",
              "Kc4",
              "Rh4+",
              "Kc3",
              "Rh3+",
              "Nd3+",
              "Kd1",
              "Re8",
              "Rh2",
              "Re1#",
              "e5",
              "d5",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf1",
              "f6",
              "exf6",
              "Qxf6",
              "Bg5",
              "Qf7",
              "Kg1",
              "Rae8",
              "Ne3",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "g4",
              "Nd4",
              "Nxd4",
              "Qxd4",
              "c6",
              "Rf1",
              "Qg6",
              "Bc2",
              "Rxf1+",
              "Kxf1",
              "Qf7+",
              "Kg1",
              "Rf8",
              "Bd3",
              "h5",
              "Qe5",
              "Qf6",
              "Qxh5",
              "Rf7",
              "Be5",
              "Qf2+",
              "Kh1",
              "Qe1+",
              "Nf1",
              "Rxf1+",
              "Bxf1",
              "Qxf1#",
              "Kh2",
              "Qf5",
              "Qh8+",
              "Kf7",
              "Qg7+",
              "Ke8",
              "Bd6",
              "Qf7",
              "Qh8+",
              "Kd7",
              "Qb8",
              "Bf5",
              "Qc7+",
              "Ke6",
              "Qxc6",
              "Qd7",
              "Qxd7+",
              "Kxd7",
              "Bf4",
              "Ke6",
              "Kg3",
              "Kf6",
              "Kh4",
              "Kg6",
              "Be3",
              "Be6",
              "Kg3",
              "Kf5",
              "h4",
              "gxh3",
              "gxh3",
              "Ke4",
              "Bd4",
              "Kd3",
              "h4",
              "Kc2",
              "b4",
              "Kb2",
              "h5",
              "Kxa2",
              "h6",
              "Bf5",
              "Kf4",
              "Bh7",
              "Ke5",
              "Kb3",
              "Kxd5",
              "Ka4",
              "Kc5",
              "a5",
              "bxa5",
              "Kxa5",
              "Kd6",
              "Ka4",
              "Ke7",
              "Kb3",
              "Kf7",
              "Kc4",
              "Kg7",
              "Bf5",
              "h7",
              "Bxh7",
              "Kxh7",
              "b4",
              "cxb4",
              "Kxd4",
              "b5",
              "Kc5",
              "b6",
              "Kxb6",
              "Kg3",
              "Kc5",
              "Kf3",
              "Kc4",
              "Ke2",
              "Kc3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf1",
              "f6",
              "exf6",
              "Qxf6",
              "Bg5",
              "Qf7",
              "Kg1",
              "Rae8",
              "Be3",
              "Bxe3+",
              "Nxe3",
              "Ne7",
              "Qd3",
              "c6",
              "Rf1",
              "Qh5",
              "Bc2",
              "Ng6",
              "Nd4",
              "Rxf1+",
              "Nxf1",
              "Bd7",
              "Ng3",
              "Qe5",
              "Nf3",
              "Qe3+",
              "Qxe3",
              "Rxe3",
              "Kf2",
              "Re8",
              "Nd4",
              "Ne5",
              "h3",
              "g6",
              "b4",
              "Nc4",
              "Nge2",
              "Kg7",
              "Nb3",
              "Bf5",
              "Bxf5",
              "gxf5",
              "Ned4",
              "Kf6",
              "Nxc6",
              "Re3",
              "Nb8",
              "Rxc3",
              "Nxa6",
              "Rc2+",
              "Kf3",
              "Rxa2",
              "Nc7",
              "Ke5",
              "Nxb5",
              "Rb2",
              "N3d4",
              "Nd2+",
              "Ke3",
              "Nf1+",
              "Kf3",
              "Rxb4",
              "Nc6+",
              "Kf6",
              "Nxb4",
              "Nd2+",
              "Ke3",
              "Nc4+",
              "Kd4",
              "Kg5",
              "Nxd5",
              "Nd2",
              "Ke3",
              "Nc4+",
              "Kf3",
              "Ne5+",
              "Kg3",
              "h5",
              "h4+",
              "Kg6",
              "Nf4+",
              "Kh6",
              "Nd4",
              "Ng4",
              "Nxf5+",
              "Kh7",
              "Nxh5",
              "Ne5",
              "Nf4",
              "Nf7",
              "Kg4",
              "Ne5+",
              "Kg5",
              "Nf7+",
              "Kf6",
              "Nh6",
              "Nxh6",
              "Kxh6",
              "g4",
              "Kh7",
              "g5",
              "Kg8",
              "g6",
              "Kh8",
              "g7+",
              "Kg8",
              "h5",
              "Kh7",
              "Kf7",
              "Kh6",
              "g8=Q"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 206,
            "completion_tokens": 499,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 205,
            "completion_tokens": 472,
            "total_tokens": 677,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 617,
          "total_completion_tokens": 1611,
          "total_tokens": 2228
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 206,
            "completion_tokens": 499,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 205,
            "completion_tokens": 472,
            "total_tokens": 677,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1KPP/R1BQ4 b kq - 0 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "f6",
          "aggressive_uci": "f7f6",
          "aggressive_response": "13... f6 14. exf6 Qxf6 15. Kg1 Ne5 16. Bxd5 Rad8 17. Bxe6+ Qxe6 18. Qe2 Nxf3+ 19. Qxf3 Rxf3 20. gxf3 Rd1 21. Kf2 Qe1+ 22. Kg2 Qxf1+ 23. Kg3 Rxc1 24. Rxc1 Qxc1 25. b3 Qxc3 26. h4 Qb2 27. a4 Qxb3 28. axb5 axb5 29. h5 Qd5 30. Kg4 b4 31. f4 b3 32. f5 b2 33. Kg5 b1=Q 34. h6 Qbxf5+ 35. Kh4 Qde4+ 36. Kg3 Qff3+ 37. Kh2 Qee2+ 38. Kg1 Qff1# f6 b6 g5",
          "aggressive_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 225,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b6",
            "g5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "f6",
          "positional_uci": "f7f6",
          "positional_response": "13... f6 14. exf6 Qxf6 15. Bg5 Qf7 16. Kg1 Rae8 17. Ne3 h6 18. Bh4 g5 19. Bg3 Rd8 20. Nd4 Nxd4 21. Qxd4 c6 22. Rf1 Qg7 23. Be5 Rxf1+ 24. Nxf1 Qf7 25. Ng3 Rf8 26. h3 h5 27. Bd1 h4 28. Nh5 Qf1+ 29. Kh2 Rf2 30. Bf3 Rxf3 31. gxf3 Qxh3+ 32. Kg1 Qxf3 33. Nf6+ Kf7 34. Qf2 Qxf2+ 35. Kxf2 Kg6 36. Ne8 Kf5 37. Bd4 g4 38. Nc7 Bc8 39. Ne8 Kf4 40. Nd6 g3+ 41. Kg2 h3+ 42. Kg1 Bg4 43. Nf7 h2+ 44. Kg2 Bf3+ 45. Kh3 h1=Q#",
          "positional_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 274,
            "total_tokens": 488,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exf6",
            "Qxf6",
            "Bg5",
            "Qf7",
            "Kg1",
            "Rae8",
            "Ne3",
            "h6",
            "Bh4",
            "g5",
            "Bg3",
            "Rd8",
            "Nd4",
            "Nxd4",
            "Qxd4",
            "c6",
            "Rf1",
            "Qg7",
            "Be5",
            "Rxf1+",
            "Nxf1",
            "Qf7",
            "Ng3",
            "Rf8",
            "h3",
            "h5",
            "Bd1",
            "h4",
            "Nh5",
            "Qf1+",
            "Kh2",
            "Rf2",
            "Bf3",
            "Rxf3",
            "gxf3",
            "Qxh3+",
            "Kg1",
            "Qxf3",
            "Nf6+",
            "Kf7",
            "Qf2",
            "Qxf2+",
            "Kxf2",
            "Kg6",
            "Ne8",
            "Kf5",
            "Bd4",
            "g4",
            "Nc7",
            "Bc8",
            "Ne8",
            "Kf4",
            "Nd6",
            "g3+",
            "Kg2",
            "h3+",
            "Kg1",
            "Bg4",
            "Nf7",
            "h2+",
            "Kg2",
            "Bf3+",
            "Kh3",
            "h1=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "f6",
          "neutral_uci": "f7f6",
          "neutral_response": "13... f6 14. exf6 Qxf6 15. Kg1 Ne5 16. Bxd5 Rad8 17. Bxe6+ Qxe6 18. Qe2 Nxf3+ 19. Qxf3 Rxf3 20. gxf3 Rd1 21. Kf2 Qe1+ 22. Kg2 Qxf1+ 23. Kg3 Rxc1 24. Rxc1 Qxc1 25. b3 Qxc3 26. h4 Qb2 27. a4 Qxb3 28. axb5 axb5 29. h5 Qd5 30. Kg4 b4 31. f4 b3 32. f5 b2 33. Kg5 b1=Q 34. h6 Qbxf5+ 35. Kh4 Qde4+ 36. Kg3 Qff3+ 37. Kh2 Qee2+ 38. Kg1 Qff1#",
          "neutral_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 219,
            "total_tokens": 432,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exf6",
            "Qxf6",
            "Kg1",
            "Ne5",
            "Bxd5",
            "Rad8",
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Nxf3+",
            "Qxf3",
            "Rxf3",
            "gxf3",
            "Rd1",
            "Kf2",
            "Qe1+",
            "Kg2",
            "Qxf1+",
            "Kg3",
            "Rxc1",
            "Rxc1",
            "Qxc1",
            "b3",
            "Qxc3",
            "h4",
            "Qb2",
            "a4",
            "Qxb3",
            "axb5",
            "axb5",
            "h5",
            "Qd5",
            "Kg4",
            "b4",
            "f4",
            "b3",
            "f5",
            "b2",
            "Kg5",
            "b1=Q",
            "h6",
            "Qbxf5+",
            "Kh4",
            "Qde4+",
            "Kg3",
            "Qff3+",
            "Kh2",
            "Qee2+",
            "Kg1",
            "Qff1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f7f6",
          "positional_uci": "f7f6",
          "neutral_uci": "f7f6",
          "consensus_move": "f7f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b6",
              "g5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "exf6",
              "Qxf6",
              "Bg5",
              "Qf7",
              "Kg1",
              "Rae8",
              "Ne3",
              "h6",
              "Bh4",
              "g5",
              "Bg3",
              "Rd8",
              "Nd4",
              "Nxd4",
              "Qxd4",
              "c6",
              "Rf1",
              "Qg7",
              "Be5",
              "Rxf1+",
              "Nxf1",
              "Qf7",
              "Ng3",
              "Rf8",
              "h3",
              "h5",
              "Bd1",
              "h4",
              "Nh5",
              "Qf1+",
              "Kh2",
              "Rf2",
              "Bf3",
              "Rxf3",
              "gxf3",
              "Qxh3+",
              "Kg1",
              "Qxf3",
              "Nf6+",
              "Kf7",
              "Qf2",
              "Qxf2+",
              "Kxf2",
              "Kg6",
              "Ne8",
              "Kf5",
              "Bd4",
              "g4",
              "Nc7",
              "Bc8",
              "Ne8",
              "Kf4",
              "Nd6",
              "g3+",
              "Kg2",
              "h3+",
              "Kg1",
              "Bg4",
              "Nf7",
              "h2+",
              "Kg2",
              "Bf3+",
              "Kh3",
              "h1=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "exf6",
              "Qxf6",
              "Kg1",
              "Ne5",
              "Bxd5",
              "Rad8",
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Nxf3+",
              "Qxf3",
              "Rxf3",
              "gxf3",
              "Rd1",
              "Kf2",
              "Qe1+",
              "Kg2",
              "Qxf1+",
              "Kg3",
              "Rxc1",
              "Rxc1",
              "Qxc1",
              "b3",
              "Qxc3",
              "h4",
              "Qb2",
              "a4",
              "Qxb3",
              "axb5",
              "axb5",
              "h5",
              "Qd5",
              "Kg4",
              "b4",
              "f4",
              "b3",
              "f5",
              "b2",
              "Kg5",
              "b1=Q",
              "h6",
              "Qbxf5+",
              "Kh4",
              "Qde4+",
              "Kg3",
              "Qff3+",
              "Kh2",
              "Qee2+",
              "Kg1",
              "Qff1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 214,
            "completion_tokens": 225,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 214,
            "completion_tokens": 274,
            "total_tokens": 488,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 213,
            "completion_tokens": 219,
            "total_tokens": 432,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 641,
          "total_completion_tokens": 718,
          "total_tokens": 1359
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 214,
            "completion_tokens": 225,
            "total_tokens": 439,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 214,
            "completion_tokens": 274,
            "total_tokens": 488,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 213,
            "completion_tokens": 219,
            "total_tokens": 432,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2q1rk1/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP3KPP/R1BQ1N2 b - - 2 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxf6",
          "aggressive_uci": "d8f6",
          "aggressive_response": "14...Qxf6 15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Rd1 Rxd1 22. Kxd1 Kf7 23. Ke2 Ke6 24. Nd2 Kd5 25. Nf3 Re8 26. Kd3 c5 27. b3 c4+ 28. bxc4+ bxc4+ 29. Kd2 Rb8 30. Kc2 Re8 31. Kd2 Rb8 32. Kc2 Re8 33. Kd2 Rb8 34. Kc2 Re8 35. Kd2 Rb8 36. Kc2 Re8 37. Kd2 Rb8 38. Kc2 Re8 39. Kd2 Rb8 40. Kc2 Re8 41. Kd2 Rb8 42. Kc2 Re8 43. Kd2 Rb8 44. Kc2 Re8 45. Kd2 Rb8 46. Kc2 Re8 47. Kd2 Rb8 48. Kc2 Re8 49. Kd2 Rb8 50. Kc2 Re8 51. Kd2 Rb8 52. Kc2 Re8 53. Kd2 Rb8 54. Kc2 Re8 55. Kd2 Rb8 56. Kc2 Re8 57. Kd2 Rb8 58. Kc2 Re8 59. Kd2 Rb8 60. Kc2 Re8 61. Kd2 Rb8 62. Kc2 Re8 63. Kd2 Rb8 64. Kc2 Re8 65. Kd2 Rb8 66. Kc2 Re8 67. Kd2 Rb8 68. Kc2 Re8 69. Kd2 Rb8 70. Kc2 Re8 71. Kd2 Rb8 72. Kc2 Re8 73. Kd2 Rb8 74. Kc2 Re8 75. Kd2 Rb8 76. Kc2 Re8 77. Kd2 Rb8 78. Kc2 Re8 79. Kd2 Rb8 80. Kc2 Re8 81. Kd2 Rb8 82. Kc2 Re8 83. Kd2 Rb8 84. Kc2 Re8 85. Kd2 Rb8 86. Kc2 Re8 87. Kd2 Rb8 88. Kc2 Re8 89.",
          "aggressive_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxd5",
            "Rad8",
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Rd1",
            "Rxd1",
            "Kxd1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Nd2",
            "Kd5",
            "Nf3",
            "Re8",
            "Kd3",
            "c5",
            "b3",
            "c4+",
            "bxc4+",
            "bxc4+",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxf6",
          "positional_uci": "d8f6",
          "positional_response": "14...Qxf6 15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Rd1 Rxd1 22. Kxd1 c5 23. Kd2 c4 24. Ng3 Kf7 25. Bd4 Rd5 26. Ke3 g6 27. Ke4 Ke6 28. Ne2 Rd8 29. Nf4+ Kd6 30. Nd5 Re8+ 31. Ne3 Rf8 32. Ng4 Rf1 33. Nf6 h5 34. Ne8+ Kd7 35. Nf6+ Kd6 36. Ne8+ Kd7 37. Nf6+ Kd6 38. Ne8+ Kd7 39. Nf6+ Kd6 40. Ne8+ Kd7 41. Nf6+ Kd6 42. Ne8+ Kd7 43. Nf6+ Kd6 44. Ne8+ Kd7 45. Nf6+ Kd6 46. Ne8+ Kd7 47. Nf6+ Kd6 48. Ne8+ Kd7 49. Nf6+ Kd6 50. Ne8+ Kd7 51. Nf6+ Kd6 52. Ne8+ Kd7 53. Nf6+ Kd6 54. Ne8+ Kd7 55. Nf6+ Kd6 56. Ne8+ Kd7 57. Nf6+ Kd6 58. Ne8+ Kd7 59. Nf6+ Kd6 60. Ne8+ Kd7 61. Nf6+ Kd6 62. Ne8+ Kd7 63. Nf6+ Kd6 64. Ne8+ Kd7 65. Nf6+ Kd6 66. Ne8+ Kd7 67. Nf6+ Kd6 68. Ne8+ Kd7 69. Nf6+ Kd6 70. Ne8+ Kd7 71. Nf6+ Kd6 72. Ne8+ Kd7 73. Nf6+ Kd6 74. Ne8+ Kd7 75. Nf6+ Kd6 76. Ne8+ Kd7 77. Nf6+ Kd6 78. Ne8+ Kd7 79. Nf6+ Kd6 80. Ne8+ Kd7 81. Nf6+ Kd6 82. Ne8+ Kd7 83. Nf6+ Kd6 84.",
          "positional_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxd5",
            "Rad8",
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Rd1",
            "Rxd1",
            "Kxd1",
            "c5",
            "Kd2",
            "c4",
            "Ng3",
            "Kf7",
            "Bd4",
            "Rd5",
            "Ke3",
            "g6",
            "Ke4",
            "Ke6",
            "Ne2",
            "Rd8",
            "Nf4+",
            "Kd6",
            "Nd5",
            "Re8+",
            "Ne3",
            "Rf8",
            "Ng4",
            "Rf1",
            "Nf6",
            "h5",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6",
            "Ne8+",
            "Kd7",
            "Nf6+",
            "Kd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxf6",
          "neutral_uci": "d8f6",
          "neutral_response": "14...Qxf6 15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Rd1 Rxd1 22. Kxd1 Kf7 23. Ke2 Ke6 24. Nd2 Kd5 25. Nf3 Re8 26. Kd3 c5 27. b3 c4+ 28. bxc4+ bxc4+ 29. Kd2 Rb8 30. Kc2 Re8 31. Kd2 Rb8 32. Kc2 Re8 33. Kd2 Rb8 34. Kc2 Re8 35. Kd2 Rb8 36. Kc2 Re8 37. Kd2 Rb8 38. Kc2 Re8 39. Kd2 Rb8 40. Kc2 Re8 41. Kd2 Rb8 42. Kc2 Re8 43. Kd2 Rb8 44. Kc2 Re8 45. Kd2 Rb8 46. Kc2 Re8 47. Kd2 Rb8 48. Kc2 Re8 49. Kd2 Rb8 50. Kc2 Re8 51. Kd2 Rb8 52. Kc2 Re8 53. Kd2 Rb8 54. Kc2 Re8 55. Kd2 Rb8 56. Kc2 Re8 57. Kd2 Rb8 58. Kc2 Re8 59. Kd2 Rb8 60. Kc2 Re8 61. Kd2 Rb8 62. Kc2 Re8 63. Kd2 Rb8 64. Kc2 Re8 65. Kd2 Rb8 66. Kc2 Re8 67. Kd2 Rb8 68. Kc2 Re8 69. Kd2 Rb8 70. Kc2 Re8 71. Kd2 Rb8 72. Kc2 Re8 73. Kd2 Rb8 74. Kc2 Re8 75. Kd2 Rb8 76. Kc2 Re8 77. Kd2 Rb8 78. Kc2 Re8 79. Kd2 Rb8 80. Kc2 Re8 81. Kd2 Rb8 82. Kc2 Re8 83. Kd2 Rb8 84. Kc2 Re8 85. Kd2 Rb8 86. Kc2 Re8 87. Kd2 Rb8 88. Kc2 Re8 89.",
          "neutral_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxd5",
            "Rad8",
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Rd1",
            "Rxd1",
            "Kxd1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Nd2",
            "Kd5",
            "Nf3",
            "Re8",
            "Kd3",
            "c5",
            "b3",
            "c4+",
            "bxc4+",
            "bxc4+",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8f6",
          "positional_uci": "d8f6",
          "neutral_uci": "d8f6",
          "consensus_move": "d8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxd5",
              "Rad8",
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Rd1",
              "Rxd1",
              "Kxd1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Nd2",
              "Kd5",
              "Nf3",
              "Re8",
              "Kd3",
              "c5",
              "b3",
              "c4+",
              "bxc4+",
              "bxc4+",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxd5",
              "Rad8",
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Rd1",
              "Rxd1",
              "Kxd1",
              "c5",
              "Kd2",
              "c4",
              "Ng3",
              "Kf7",
              "Bd4",
              "Rd5",
              "Ke3",
              "g6",
              "Ke4",
              "Ke6",
              "Ne2",
              "Rd8",
              "Nf4+",
              "Kd6",
              "Nd5",
              "Re8+",
              "Ne3",
              "Rf8",
              "Ng4",
              "Rf1",
              "Nf6",
              "h5",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6",
              "Ne8+",
              "Kd7",
              "Nf6+",
              "Kd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxd5",
              "Rad8",
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Rd1",
              "Rxd1",
              "Kxd1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Nd2",
              "Kd5",
              "Nf3",
              "Re8",
              "Kd3",
              "c5",
              "b3",
              "c4+",
              "bxc4+",
              "bxc4+",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 665,
          "total_completion_tokens": 1920,
          "total_tokens": 2585
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2q1rk1/2p3pp/p1n1bP2/1p1p4/8/1BP2N2/PP3KPP/R1BQ1N2 b - - 0 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rad8",
          "aggressive_uci": "a8d8",
          "aggressive_response": "15... Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Nd2 Rde8 22. Nf1 c5 23. Rd1 c4 24. Rd6 R5e6 25. Rxe6 Rxe6 26. Nd2 Kf7 27. Nf3 h6 28. Nd4 Re8 29. Nc6 Ke6 30. Nb4 a5 31. Nc6 Ra8 32. Nd4+ Kd5 33. Nxb5 Rb8 34. a4 Kc6 35. Bd4 g6 36. Kd2 h5 37. Kc2 Re8 38. Kd2 Rb8 39. Be5 Rd8+ 40. Nd4+ Kd5 41. Bc7 Ra8 42. Bb6 Ra6 43. Bd8 Ra8 44. Bg5 Rb8 45. Kc2 Rf8 46. Nf3 Re8 47. Kd2 Rb8 48. Kc2 Re8 49. Kd2 Rb8 50. Kc2 Re8 51. Kd2 Rb8 52. Kc2 Re8 53. Kd2 Rb8 54. Kc2 Re8 55. Kd2 Rb8 56. Kc2 Re8 57. Kd2 Rb8 58. Kc2 Re8 59. Kd2 Rb8 60. Kc2 Re8 61. Kd2 Rb8 62. Kc2 Re8 63. Kd2 Rb8 64. Kc2 Re8 65. Kd2 Rb8 66. Kc2 Re8 67. Kd2 Rb8 68. Kc2 Re8 69. Kd2 Rb8 70. Kc2 Re8 71. Kd2 Rb8 72. Kc2 Re8 73. Kd2 Rb8 74. Kc2 Re8 75. Kd2 Rb8 76. Kc2 Re8 77. Kd2 Rb8 78. Kc2 Re8 79. Kd2 Rb8 80. Kc2 Re8 81. Kd2 Rb8 82. Kc2 Re8 83. Kd2 Rb8 84. Kc2 Re8 85. Kd2 Rb8 86. Kc2 Re8 87. Kd2 Rb8 88. Kc2 Re8 89. Kd2 Rb8 90. Kc2 Re8 91. K",
          "aggressive_tokens": {
            "prompt_tokens": 232,
            "completion_tokens": 640,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Nd2",
            "Rde8",
            "Nf1",
            "c5",
            "Rd1",
            "c4",
            "Rd6",
            "R5e6",
            "Rxe6",
            "Rxe6",
            "Nd2",
            "Kf7",
            "Nf3",
            "h6",
            "Nd4",
            "Re8",
            "Nc6",
            "Ke6",
            "Nb4",
            "a5",
            "Nc6",
            "Ra8",
            "Nd4+",
            "Kd5",
            "Nxb5",
            "Rb8",
            "a4",
            "Kc6",
            "Bd4",
            "g6",
            "Kd2",
            "h5",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Be5",
            "Rd8+",
            "Nd4+",
            "Kd5",
            "Bc7",
            "Ra8",
            "Bb6",
            "Ra6",
            "Bd8",
            "Ra8",
            "Bg5",
            "Rb8",
            "Kc2",
            "Rf8",
            "Nf3",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rad8",
          "positional_uci": "a8d8",
          "positional_response": "15... Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Nd2 Rde8 22. Nf1 c5 23. Rd1 b4 24. cxb4 cxb4 25. Rd4 a5 26. Nd2 Rxe3+ 27. Kf2 Re2+ 28. Kf3 R8e3+ 29. Kf4 g5+ 30. Kxg5 Rxg2+ 31. Kf4 Ree2 32. Nf3 Rxb2 33. Rd8+ Kf7 34. Rd7+ Ke6 35. Rxh7 Rxa2 36. Rh6+ Kd5 37. Rh5+ Kc4 38. Ne5+ Kc3 39. Rh3+ Kc2 40. Nc4 b3 41. Ne3+ Kc1 42. Nxg2 Rxg2 43. Rxb3 Rxh2 44. Ra3 Rh5 45. Ke4 Kb2 46. Ra4 Kb3 47. Ra1 a4 48. Kd3 a3 49. Rb1+ Ka2 50. Rb8 Rh3+ 51. Kc2 Rh2+ 52. Kc1 Rb2 53. Ra8 Rb3 54. Kc2 Rb2+ 55. Kc1 Rb1+ 56. Kc2 Rb3 57. Ra7 Rb2+ 58. Kc1 Rb3 59. Ra8 Ka1 60. Kc2 Rb2+ 61. Kc1 a2 62. Ra7 Rb1+ 63. Kc2 Rb2+ 64. Kc1 Rb3 65. Ra8 Rc3+ 66. Kd2 Kb2 67. Rb8+ Rb3 68. Ra8 a1=Q 69. Rxa1 Kxa1 70. Kc2 Rh3 71. Kd2 Kb2 72. Ke2 Kc2 73. Kf2 Kd2 74. Kg2 Re3 75. Kf2 Kd3 76. Kg2 Ke2 77. Kh2 Kf2 78. Kh1 Rh3# 0-1",
          "positional_tokens": {
            "prompt_tokens": 232,
            "completion_tokens": 553,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Nd2",
            "Rde8",
            "Nf1",
            "c5",
            "Rd1",
            "b4",
            "cxb4",
            "cxb4",
            "Rd4",
            "a5",
            "Nd2",
            "Rxe3+",
            "Kf2",
            "Re2+",
            "Kf3",
            "R8e3+",
            "Kf4",
            "g5+",
            "Kxg5",
            "Rxg2+",
            "Kf4",
            "Ree2",
            "Nf3",
            "Rxb2",
            "Rd8+",
            "Kf7",
            "Rd7+",
            "Ke6",
            "Rxh7",
            "Rxa2",
            "Rh6+",
            "Kd5",
            "Rh5+",
            "Kc4",
            "Ne5+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Nc4",
            "b3",
            "Ne3+",
            "Kc1",
            "Nxg2",
            "Rxg2",
            "Rxb3",
            "Rxh2",
            "Ra3",
            "Rh5",
            "Ke4",
            "Kb2",
            "Ra4",
            "Kb3",
            "Ra1",
            "a4",
            "Kd3",
            "a3",
            "Rb1+",
            "Ka2",
            "Rb8",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc1",
            "Rb2",
            "Ra8",
            "Rb3",
            "Kc2",
            "Rb2+",
            "Kc1",
            "Rb1+",
            "Kc2",
            "Rb3",
            "Ra7",
            "Rb2+",
            "Kc1",
            "Rb3",
            "Ra8",
            "Ka1",
            "Kc2",
            "Rb2+",
            "Kc1",
            "a2",
            "Ra7",
            "Rb1+",
            "Kc2",
            "Rb2+",
            "Kc1",
            "Rb3",
            "Ra8",
            "Rc3+",
            "Kd2",
            "Kb2",
            "Rb8+",
            "Rb3",
            "Ra8",
            "a1=Q",
            "Rxa1",
            "Kxa1",
            "Kc2",
            "Rh3",
            "Kd2",
            "Kb2",
            "Ke2",
            "Kc2",
            "Kf2",
            "Kd2",
            "Kg2",
            "Re3",
            "Kf2",
            "Kd3",
            "Kg2",
            "Ke2",
            "Kh2",
            "Kf2",
            "Kh1",
            "Rh3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rad8",
          "neutral_uci": "a8d8",
          "neutral_response": "15... Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Nd2 Rde8 22. Nf1 c5 23. Rd1 b4 24. cxb4 cxb4 25. Rd4 a5 26. Nd2 Rxe3+ 27. Kf2 Re2+ 28. Kf3 R8e3+ 29. Kf4 g5+ 30. Kxg5 Rxg2+ 31. Kf4 Ree2 32. Nf3 Rxb2 33. Rd8+ Kf7 34. Rd7+ Ke6 35. Rxh7 Rxa2 36. Rh6+ Kd5 37. Rh5+ Kc4 38. Ne5+ Kc3 39. Rh3+ Kc2 40. Nc4 b3 41. Ne3+ Kc1 42. Nxg2 Rxg2 43. Rxb3 Rxh2 44. Ra3 Rh5 45. Ke4 Kb2 46. Ra4 Kb3 47. Ra1 a4 48. Kd3 a3 49. Rb1+ Ka2 50. Rb4 Rh3+ 51. Kc2 Rh2+ 52. Kc1 Rb2 53. Ra4 Kb3 54. Ra8 a2 55. Rb8+ Kc3 56. Rc8+ Kd3 57. Rd8+ Kc3 58. Rc8+ Kd3 59. Rd8+ Kc3 60. Rc8+ Kd3 61. Rd8+ Kc3 62. Rc8+ Kd3 63. Rd8+ Kc3 64. Rc8+ Kd3 65. Rd8+ Kc3 66. Rc8+ Kd3 67. Rd8+ Kc3 68. Rc8+ Kd3 69. Rd8+ Kc3 70. Rc8+ Kd3 71. Rd8+ Kc3 72. Rc8+ Kd3 73. Rd8+ Kc3 74. Rc8+ Kd3 75. Rd8+ Kc3 76. Rc8+ Kd3 77. Rd8+ Kc3 78. Rc8+ Kd3 79. Rd8+ Kc3 80. Rc8+ Kd3 81. Rd8+ Kc3 82. Rc8+ Kd3 83. Rd8+ Kc3 84. Rc8+ Kd3 85. Rd8+ Kc3 86. Rc8+ Kd3 87. Rd8+ Kc3 88.",
          "neutral_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Nd2",
            "Rde8",
            "Nf1",
            "c5",
            "Rd1",
            "b4",
            "cxb4",
            "cxb4",
            "Rd4",
            "a5",
            "Nd2",
            "Rxe3+",
            "Kf2",
            "Re2+",
            "Kf3",
            "R8e3+",
            "Kf4",
            "g5+",
            "Kxg5",
            "Rxg2+",
            "Kf4",
            "Ree2",
            "Nf3",
            "Rxb2",
            "Rd8+",
            "Kf7",
            "Rd7+",
            "Ke6",
            "Rxh7",
            "Rxa2",
            "Rh6+",
            "Kd5",
            "Rh5+",
            "Kc4",
            "Ne5+",
            "Kc3",
            "Rh3+",
            "Kc2",
            "Nc4",
            "b3",
            "Ne3+",
            "Kc1",
            "Nxg2",
            "Rxg2",
            "Rxb3",
            "Rxh2",
            "Ra3",
            "Rh5",
            "Ke4",
            "Kb2",
            "Ra4",
            "Kb3",
            "Ra1",
            "a4",
            "Kd3",
            "a3",
            "Rb1+",
            "Ka2",
            "Rb4",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kc1",
            "Rb2",
            "Ra4",
            "Kb3",
            "Ra8",
            "a2",
            "Rb8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3",
            "Rc8+",
            "Kd3",
            "Rd8+",
            "Kc3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a8d8",
          "positional_uci": "a8d8",
          "neutral_uci": "a8d8",
          "consensus_move": "a8d8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Nd2",
              "Rde8",
              "Nf1",
              "c5",
              "Rd1",
              "c4",
              "Rd6",
              "R5e6",
              "Rxe6",
              "Rxe6",
              "Nd2",
              "Kf7",
              "Nf3",
              "h6",
              "Nd4",
              "Re8",
              "Nc6",
              "Ke6",
              "Nb4",
              "a5",
              "Nc6",
              "Ra8",
              "Nd4+",
              "Kd5",
              "Nxb5",
              "Rb8",
              "a4",
              "Kc6",
              "Bd4",
              "g6",
              "Kd2",
              "h5",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Be5",
              "Rd8+",
              "Nd4+",
              "Kd5",
              "Bc7",
              "Ra8",
              "Bb6",
              "Ra6",
              "Bd8",
              "Ra8",
              "Bg5",
              "Rb8",
              "Kc2",
              "Rf8",
              "Nf3",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Nd2",
              "Rde8",
              "Nf1",
              "c5",
              "Rd1",
              "b4",
              "cxb4",
              "cxb4",
              "Rd4",
              "a5",
              "Nd2",
              "Rxe3+",
              "Kf2",
              "Re2+",
              "Kf3",
              "R8e3+",
              "Kf4",
              "g5+",
              "Kxg5",
              "Rxg2+",
              "Kf4",
              "Ree2",
              "Nf3",
              "Rxb2",
              "Rd8+",
              "Kf7",
              "Rd7+",
              "Ke6",
              "Rxh7",
              "Rxa2",
              "Rh6+",
              "Kd5",
              "Rh5+",
              "Kc4",
              "Ne5+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Nc4",
              "b3",
              "Ne3+",
              "Kc1",
              "Nxg2",
              "Rxg2",
              "Rxb3",
              "Rxh2",
              "Ra3",
              "Rh5",
              "Ke4",
              "Kb2",
              "Ra4",
              "Kb3",
              "Ra1",
              "a4",
              "Kd3",
              "a3",
              "Rb1+",
              "Ka2",
              "Rb8",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc1",
              "Rb2",
              "Ra8",
              "Rb3",
              "Kc2",
              "Rb2+",
              "Kc1",
              "Rb1+",
              "Kc2",
              "Rb3",
              "Ra7",
              "Rb2+",
              "Kc1",
              "Rb3",
              "Ra8",
              "Ka1",
              "Kc2",
              "Rb2+",
              "Kc1",
              "a2",
              "Ra7",
              "Rb1+",
              "Kc2",
              "Rb2+",
              "Kc1",
              "Rb3",
              "Ra8",
              "Rc3+",
              "Kd2",
              "Kb2",
              "Rb8+",
              "Rb3",
              "Ra8",
              "a1=Q",
              "Rxa1",
              "Kxa1",
              "Kc2",
              "Rh3",
              "Kd2",
              "Kb2",
              "Ke2",
              "Kc2",
              "Kf2",
              "Kd2",
              "Kg2",
              "Re3",
              "Kf2",
              "Kd3",
              "Kg2",
              "Ke2",
              "Kh2",
              "Kf2",
              "Kh1",
              "Rh3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Nd2",
              "Rde8",
              "Nf1",
              "c5",
              "Rd1",
              "b4",
              "cxb4",
              "cxb4",
              "Rd4",
              "a5",
              "Nd2",
              "Rxe3+",
              "Kf2",
              "Re2+",
              "Kf3",
              "R8e3+",
              "Kf4",
              "g5+",
              "Kxg5",
              "Rxg2+",
              "Kf4",
              "Ree2",
              "Nf3",
              "Rxb2",
              "Rd8+",
              "Kf7",
              "Rd7+",
              "Ke6",
              "Rxh7",
              "Rxa2",
              "Rh6+",
              "Kd5",
              "Rh5+",
              "Kc4",
              "Ne5+",
              "Kc3",
              "Rh3+",
              "Kc2",
              "Nc4",
              "b3",
              "Ne3+",
              "Kc1",
              "Nxg2",
              "Rxg2",
              "Rxb3",
              "Rxh2",
              "Ra3",
              "Rh5",
              "Ke4",
              "Kb2",
              "Ra4",
              "Kb3",
              "Ra1",
              "a4",
              "Kd3",
              "a3",
              "Rb1+",
              "Ka2",
              "Rb4",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kc1",
              "Rb2",
              "Ra4",
              "Kb3",
              "Ra8",
              "a2",
              "Rb8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3",
              "Rc8+",
              "Kd3",
              "Rd8+",
              "Kc3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 232,
            "completion_tokens": 640,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 232,
            "completion_tokens": 553,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 695,
          "total_completion_tokens": 1833,
          "total_tokens": 2528
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 232,
            "completion_tokens": 640,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 232,
            "completion_tokens": 553,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r4rk1/2p3pp/p1n1bq2/1p1B4/8/2P2N2/PP3KPP/R1BQ1N2 b - - 0 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kxf3",
          "aggressive_uci": null,
          "aggressive_response": "Bxd5 17. Bxf6 Bxf3 18. Qxf3 Rxf6 19. Qxf6 gxf6 20. Re1 Kf7 21. Re2 Ne5 22. Ne3\nNd3+ 23. Kf3 Nc1 24. Rc2 Nxa2 25. b3 Nxc3 26. Rxc3 Rd7 27. Rc6 a5 28. Rc5 a4\n29. bxa4 bxa4 30. Ra5 Rd4 31. Ra7 Kg6 32. Rxc7 a3 33. Ra7 Rd3 34. Ke4 Rb3 35. Nc4 Rb4 36. Kd3 Rb3+ 37. Kc2 Rb4 38. Kc3 Rb1 39. Rxa3 Rg1 40. Ra2 Rh1 41. h3 Kg5 42. Kd3 Kh4 43. Ke3 Kg3 44. Nd6 Re1+ 45. Re2 Rxe2+ 46. Kxe2 Kxg2 47. h4 Kg3 48. Nf5+ Kg4 49. Ne3+ Kxh4 50. Kf3 Kg5 51. Kg3 h5 52. Ng2 f5 53. Nh4 f4+ 54. Kh3 Kf6 55. Nf3 Kf5 56. Kh4 Ke4 57. Ng5+ Ke3 58. Kxh5 f3 59. Nxf3 Kxf3 *\nKxf3 Kg2 Kg4 Kxh2 Kf3 Kg3 Kg4 Kf3 Kg3 Kg4 Kf3 Kg3 *",
          "aggressive_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 389,
            "total_tokens": 629,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg2",
            "Kg4",
            "Kxh2",
            "Kf3",
            "Kg3",
            "Kg4",
            "Kf3",
            "Kg3",
            "Kg4",
            "Kf3",
            "Kg3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxd5",
          "positional_uci": "e6d5",
          "positional_response": "Bxd5 17. Bxf6 Bxf3 18. Qxf3 Rxf6 19. Qxf6 gxf6 20. Re1 Kf7 21. Re2 Ne5 22. Ne3\nNd3+ 23. Kf3 Ne5+ 24. Kf2 Nd3+ 25. Kf3 Ne5+ 26. Kf2 Nd3+ 27. Kf3 Ne5+ 28. Kf2\nNd3+ 29. Kf3 Ne5+ 30. Kf2 Nd3+ 31. Kf3 Ne5+ 32. Kf2 Nd3+ 33. Kf3 Ne5+ 34. Kf2\nNd3+ 35. Kf3 Ne5+ 36. Kf2 Nd3+ 37. Kf3 Ne5+ 38. Kf2 Nd3+ 39. Kf3 Ne5+ 40. Kf2\nNd3+ 41. Kf3 Ne5+ 42. Kf2 Nd3+ 43. Kf3 Ne5+ 44. Kf2 Nd3+ 45. Kf3 Ne5+ 46. Kf2\nNd3+ 47. Kf3 Ne5+ 48. Kf2 Nd3+ 49. Kf3 Ne5+ 50. Kf2 Nd3+ 51. Kf3 Ne5+ 52. Kf2\nNd3+ 53. Kf3 Ne5+ 54. Kf2 Nd3+ 55. Kf3 Ne5+ 56. Kf2 Nd3+ 57. Kf3 Ne5+ 58. Kf2\nNd3+ 59. Kf3 Ne5+ 60. Kf2 Nd3+ 61. Kf3 Ne5+ 62. Kf2 Nd3+ 63. Kf3 Ne5+ 64. Kf2\nNd3+ 65. Kf3 Ne5+ 66. Kf2 Nd3+ 67. Kf3 Ne5+ 68. Kf2 Nd3+ 69. Kf3 Ne5+ 70. Kf2\nNd3+ 71. Kf3 Ne5+ 72. Kf2 Nd3+ 73. Kf3 Ne5+ 74. Kf2 Nd3+ 75. Kf3 Ne5+ 76. Kf2\nNd3+ 77. Kf3 Ne5+ 78. Kf2 Nd3+ 79. Kf3 Ne5+ 80. Kf2 Nd3+ 81. Kf3 Ne5+ 82. Kf2\nNd3+ 83. Kf3 Ne5+ 84. Kf2 Nd3+ 85. Kf3 Ne5+ 86. Kf2 Nd3",
          "positional_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxf6",
            "Bxf3",
            "Qxf3",
            "Rxf6",
            "Qxf6",
            "gxf6",
            "Re1",
            "Kf7",
            "Re2",
            "Ne5",
            "Ne3",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3+",
            "Kf3",
            "Ne5+",
            "Kf2",
            "Nd3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxg5",
          "neutral_uci": "f6g5",
          "neutral_response": "16...Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1#",
          "neutral_tokens": {
            "prompt_tokens": 239,
            "completion_tokens": 76,
            "total_tokens": 315,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe6+",
            "Kh8",
            "Qe2",
            "Ne5",
            "Kg1",
            "Nxf3+",
            "Kh1",
            "Nh4",
            "Ng3",
            "Rd2",
            "Qe4",
            "Rxg2",
            "Rf1",
            "Rxf1+",
            "Nxf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "e6d5",
          "neutral_uci": "f6g5",
          "consensus_move": "f6g5",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg2",
              "Kg4",
              "Kxh2",
              "Kf3",
              "Kg3",
              "Kg4",
              "Kf3",
              "Kg3",
              "Kg4",
              "Kf3",
              "Kg3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf6",
              "Bxf3",
              "Qxf3",
              "Rxf6",
              "Qxf6",
              "gxf6",
              "Re1",
              "Kf7",
              "Re2",
              "Ne5",
              "Ne3",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3+",
              "Kf3",
              "Ne5+",
              "Kf2",
              "Nd3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxe6+",
              "Kh8",
              "Qe2",
              "Ne5",
              "Kg1",
              "Nxf3+",
              "Kh1",
              "Nh4",
              "Ng3",
              "Rd2",
              "Qe4",
              "Rxg2",
              "Rf1",
              "Rxf1+",
              "Nxf1",
              "Rg1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 240,
            "completion_tokens": 389,
            "total_tokens": 629,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 239,
            "completion_tokens": 76,
            "total_tokens": 315,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 719,
          "total_completion_tokens": 1105,
          "total_tokens": 1824
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 240,
            "completion_tokens": 389,
            "total_tokens": 629,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 239,
            "completion_tokens": 76,
            "total_tokens": 315,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r1rk1/2p3pp/p1n1bq2/1p1B2B1/8/2P2N2/PP3KPP/R2Q1N2 b - - 2 16"
    },
    {
      "turn": 34,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne5",
          "aggressive_uci": null,
          "aggressive_response": "17... Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1# 1-0\n17... Ne5 18. Kg1 Nxf3+ 19. Kh1 Nh4 20. Ng3 Rf2 21. Qe4 Rxg2 22. Rf1 Rf2 23. Rxf2 Qxf2 24. Qxh4 Rd1+ 25. Nf1 Rxf1# 1-0\n17... Ne5 18. Kg1 Nxf3+ 19. Kh1 Nh4 20. Ng3 Rf2 21. Qe4 Rxg2 22. Rf1 Rf2 23. Rxf2 Qxf2 24. Qxh4 Rd1+ 25. Nf1 Rxf1# 1-0",
          "aggressive_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 229,
            "total_tokens": 480,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg1",
            "Nxf3+",
            "Kh1",
            "Nh4",
            "Ng3",
            "Rf2",
            "Qe4",
            "Rxg2",
            "Rf1",
            "Rf2",
            "Rxf2",
            "Qxf2",
            "Qxh4",
            "Rd1+",
            "Nf1",
            "Rxf1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kh8",
          "positional_uci": "g8h8",
          "positional_response": "17... Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1# 1-0",
          "positional_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 69,
            "total_tokens": 320,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Ne5",
            "Kg1",
            "Nxf3+",
            "Kh1",
            "Nh4",
            "Ng3",
            "Rd2",
            "Qe4",
            "Rxg2",
            "Rf1",
            "Rxf1+",
            "Nxf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne5",
          "neutral_uci": null,
          "neutral_response": "17... Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1# 1-0\n17... Ne5 18. Kg1 Nxf3+ 19. Kh1 Nh4 20. Ng3 Rf2 21. Qe4 Rxg2 22. Rf1 Rf8 23. Rxf8+ Kxf8 24. Qa8+ Ke7 25. Qe4+ Kd7 26. Qd5+ Qxd5 27. Bxd5 Rxb2 28. Kg1 c6 29. Be4 Rxa2 30. Bxh7 Nf3+ 31. Kf1 Nxh2+ 32. Ke1 Nf3+ 33. Kd1 Rg2 34. Ne4 Rh2 35. Bf5+ Kc7 36. Nc5 Kb6 37. Nd7+ Ka5 38. Nb8 c5 39. Nc6+ Ka4 40. Bc2+ Ka3 41. Be4 Ng5 42. Bd5 b4 43. cxb4 cxb4 44. Nd4 a5 45. Nb5+ Kb2 46. Nd4 a4 47. Ne2 a3 48. Nc1 a2 49. Bxa2 Rh1+ 50. Kd2 Rxc1 51. Bd5 Rc2+ 52. Kd3 Rc3+ 53. Kd2 Nf3+ 54. Ke2 Nd4+ 55. Kd2 Nb3+ 56. Ke2 Kc2 57. Be4+ Kc1 58. Bg6 Nd4+ 59. Kf2 b3 60. Kg2 b2 61. Kf2 Nc2 62. Bxc2 Kxc2 63. Ke2 b1=Q 64. Kf2 Qb2 65. Ke2 Kb3+ 66. Kd1 Rc1# 0-1\n17... Ne5 18. Kg1 Nxf3+ 19. Kh1 Nh4 20. Ng3 Rf2 21. Qe4 Rxg2 22. Rf1 Rf2 23. Rxf2 Qxf2 24. Qxh4 Rd1+ 25. Nf1 Rxf1# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 250,
            "completion_tokens": 576,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg1",
            "Nxf3+",
            "Kh1",
            "Nh4",
            "Ng3",
            "Rf2",
            "Qe4",
            "Rxg2",
            "Rf1",
            "Rf2",
            "Rxf2",
            "Qxf2",
            "Qxh4",
            "Rd1+",
            "Nf1",
            "Rxf1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g8h8",
          "neutral_uci": null,
          "consensus_move": "g8h8",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg1",
              "Nxf3+",
              "Kh1",
              "Nh4",
              "Ng3",
              "Rf2",
              "Qe4",
              "Rxg2",
              "Rf1",
              "Rf2",
              "Rxf2",
              "Qxf2",
              "Qxh4",
              "Rd1+",
              "Nf1",
              "Rxf1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe2",
              "Ne5",
              "Kg1",
              "Nxf3+",
              "Kh1",
              "Nh4",
              "Ng3",
              "Rd2",
              "Qe4",
              "Rxg2",
              "Rf1",
              "Rxf1+",
              "Nxf1",
              "Rg1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg1",
              "Nxf3+",
              "Kh1",
              "Nh4",
              "Ng3",
              "Rf2",
              "Qe4",
              "Rxg2",
              "Rf1",
              "Rf2",
              "Rxf2",
              "Qxf2",
              "Qxh4",
              "Rd1+",
              "Nf1",
              "Rxf1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 251,
            "completion_tokens": 229,
            "total_tokens": 480,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 251,
            "completion_tokens": 69,
            "total_tokens": 320,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 250,
            "completion_tokens": 576,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 752,
          "total_completion_tokens": 874,
          "total_tokens": 1626
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 251,
            "completion_tokens": 229,
            "total_tokens": 480,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 251,
            "completion_tokens": 69,
            "total_tokens": 320,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 250,
            "completion_tokens": 576,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r1rk1/2p3pp/p1n1B3/1p4q1/8/2P2N2/PP3KPP/R2Q1N2 b - - 0 17"
    },
    {
      "turn": 36,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne5",
          "aggressive_uci": "c6e5",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6 Qxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1#",
          "aggressive_tokens": {
            "prompt_tokens": 259,
            "completion_tokens": 202,
            "total_tokens": 461,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg1",
            "Nxf3+",
            "Kh1",
            "Nh4",
            "Ng3",
            "Rd2",
            "Qe4",
            "Rxg2",
            "Rf1",
            "Rxf1+",
            "Nxf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne5",
          "positional_uci": "c6e5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1#",
          "positional_tokens": {
            "prompt_tokens": 259,
            "completion_tokens": 204,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg1",
            "Nxf3+",
            "Kh1",
            "Nh4",
            "Ng3",
            "Rd2",
            "Qe4",
            "Rxg2",
            "Rf1",
            "Rxf1+",
            "Nxf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne5",
          "neutral_uci": "c6e5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6 Qxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1#",
          "neutral_tokens": {
            "prompt_tokens": 258,
            "completion_tokens": 202,
            "total_tokens": 460,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg1",
            "Nxf3+",
            "Kh1",
            "Nh4",
            "Ng3",
            "Rd2",
            "Qe4",
            "Rxg2",
            "Rf1",
            "Rxf1+",
            "Nxf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c6e5",
          "positional_uci": "c6e5",
          "neutral_uci": "c6e5",
          "consensus_move": "c6e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg1",
              "Nxf3+",
              "Kh1",
              "Nh4",
              "Ng3",
              "Rd2",
              "Qe4",
              "Rxg2",
              "Rf1",
              "Rxf1+",
              "Nxf1",
              "Rg1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg1",
              "Nxf3+",
              "Kh1",
              "Nh4",
              "Ng3",
              "Rd2",
              "Qe4",
              "Rxg2",
              "Rf1",
              "Rxf1+",
              "Nxf1",
              "Rg1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg1",
              "Nxf3+",
              "Kh1",
              "Nh4",
              "Ng3",
              "Rd2",
              "Qe4",
              "Rxg2",
              "Rf1",
              "Rxf1+",
              "Nxf1",
              "Rg1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 259,
            "completion_tokens": 202,
            "total_tokens": 461,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 259,
            "completion_tokens": 204,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 258,
            "completion_tokens": 202,
            "total_tokens": 460,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 776,
          "total_completion_tokens": 608,
          "total_tokens": 1384
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 259,
            "completion_tokens": 202,
            "total_tokens": 461,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 259,
            "completion_tokens": 204,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 258,
            "completion_tokens": 202,
            "total_tokens": 460,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r1r1k/2p3pp/p1n1B3/1p4q1/8/2P2N2/PP2QKPP/R4N2 b - - 2 18"
    },
    {
      "turn": 38,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxf3+",
          "aggressive_uci": "e5f3",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1#",
          "aggressive_tokens": {
            "prompt_tokens": 266,
            "completion_tokens": 204,
            "total_tokens": 470,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kh1",
            "Nh4",
            "Ng3",
            "Rd2",
            "Qe4",
            "Rxg2",
            "Rf1",
            "Rxf1+",
            "Nxf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxf3+",
          "positional_uci": "e5f3",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1 Nh4 21. Ng3 Rd2 22. Qe4 Rxg2 23. Rf1 Rxf1+ 24. Nxf1 Rg1#",
          "positional_tokens": {
            "prompt_tokens": 266,
            "completion_tokens": 204,
            "total_tokens": 470,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kh1",
            "Nh4",
            "Ng3",
            "Rd2",
            "Qe4",
            "Rxg2",
            "Rf1",
            "Rxf1+",
            "Nxf1",
            "Rg1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxf3+",
          "neutral_uci": "e5f3",
          "neutral_response": "19... Nxf3+ 20. Kh1 Ne5 21. Re1 Nd3 22. Rd1 Nf2+ 23. Kg1 Rxd1 24. Bb3 Nh3+ 25. Kh1 Rdxf1+ 26. Qxf1 Rxf1#",
          "neutral_tokens": {
            "prompt_tokens": 265,
            "completion_tokens": 66,
            "total_tokens": 331,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kh1",
            "Ne5",
            "Re1",
            "Nd3",
            "Rd1",
            "Nf2+",
            "Kg1",
            "Rxd1",
            "Bb3",
            "Nh3+",
            "Kh1",
            "Rdxf1+",
            "Qxf1",
            "Rxf1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5f3",
          "positional_uci": "e5f3",
          "neutral_uci": "e5f3",
          "consensus_move": "e5f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kh1",
              "Nh4",
              "Ng3",
              "Rd2",
              "Qe4",
              "Rxg2",
              "Rf1",
              "Rxf1+",
              "Nxf1",
              "Rg1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kh1",
              "Nh4",
              "Ng3",
              "Rd2",
              "Qe4",
              "Rxg2",
              "Rf1",
              "Rxf1+",
              "Nxf1",
              "Rg1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kh1",
              "Ne5",
              "Re1",
              "Nd3",
              "Rd1",
              "Nf2+",
              "Kg1",
              "Rxd1",
              "Bb3",
              "Nh3+",
              "Kh1",
              "Rdxf1+",
              "Qxf1",
              "Rxf1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 266,
            "completion_tokens": 204,
            "total_tokens": 470,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 266,
            "completion_tokens": 204,
            "total_tokens": 470,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 265,
            "completion_tokens": 66,
            "total_tokens": 331,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 797,
          "total_completion_tokens": 474,
          "total_tokens": 1271
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 266,
            "completion_tokens": 204,
            "total_tokens": 470,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 266,
            "completion_tokens": 204,
            "total_tokens": 470,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 265,
            "completion_tokens": 66,
            "total_tokens": 331,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r1r1k/2p3pp/p3B3/1p2n1q1/8/2P2N2/PP2Q1PP/R4NK1 b - - 4 19"
    },
    {
      "turn": 40,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxe5",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 Nf3 Bg4 Bb4 Nge7 O-O Nxe5 dxe5 Qxd1 Rxd1 Ng6 Nc3 Nxe5 Nxe5 Rxe5 Bf4 Re7\nBxe5 Rxe5 Rd8+ Re8 Rxe8#",
          "aggressive_tokens": {
            "prompt_tokens": 276,
            "completion_tokens": 65,
            "total_tokens": 341,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe5",
            "Rd8+",
            "Re8",
            "Rxe8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nd2",
          "positional_uci": "f3d2",
          "positional_response": "20... Nd2 21. Nxd2 Rxd2 22. Qe4 Rdf2 23. h3 Qg3",
          "positional_tokens": {
            "prompt_tokens": 276,
            "completion_tokens": 31,
            "total_tokens": 307,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxd2",
            "Rxd2",
            "Qe4",
            "Rdf2",
            "h3",
            "Qg3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Nxe4 d4 b5 Bb3 d5 dxe5 Be6 c3 Bc5 Nbd2 Nxf2 Rxf2 Bxf2 Kxf2 O-O Nf1 f6 exf6 Qxf6 Bxd5 Rad8 Bg5 Qxg5 Bxe6+ Kh8 Qe2 Ne5 Kg1 Nxf3 Kh1",
          "neutral_tokens": {
            "prompt_tokens": 275,
            "completion_tokens": 102,
            "total_tokens": 377,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Nxe4",
            "d4",
            "b5",
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "c3",
            "Bc5",
            "Nbd2",
            "Nxf2",
            "Rxf2",
            "Bxf2",
            "Kxf2",
            "O-O",
            "Nf1",
            "f6",
            "exf6",
            "Qxf6",
            "Bxd5",
            "Rad8",
            "Bg5",
            "Qxg5",
            "Bxe6+",
            "Kh8",
            "Qe2",
            "Ne5",
            "Kg1",
            "Nxf3",
            "Kh1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "f3d2",
          "neutral_uci": null,
          "consensus_move": "f3d2",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxe5",
              "Rd8+",
              "Re8",
              "Rxe8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxd2",
              "Rxd2",
              "Qe4",
              "Rdf2",
              "h3",
              "Qg3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Nxe4",
              "d4",
              "b5",
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "c3",
              "Bc5",
              "Nbd2",
              "Nxf2",
              "Rxf2",
              "Bxf2",
              "Kxf2",
              "O-O",
              "Nf1",
              "f6",
              "exf6",
              "Qxf6",
              "Bxd5",
              "Rad8",
              "Bg5",
              "Qxg5",
              "Bxe6+",
              "Kh8",
              "Qe2",
              "Ne5",
              "Kg1",
              "Nxf3",
              "Kh1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 276,
            "completion_tokens": 65,
            "total_tokens": 341,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 276,
            "completion_tokens": 31,
            "total_tokens": 307,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 275,
            "completion_tokens": 102,
            "total_tokens": 377,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 827,
          "total_completion_tokens": 198,
          "total_tokens": 1025
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 276,
            "completion_tokens": 65,
            "total_tokens": 341,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 276,
            "completion_tokens": 31,
            "total_tokens": 307,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 275,
            "completion_tokens": 102,
            "total_tokens": 377,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r1r1k/2p3pp/p3B3/1p4q1/8/2P2n2/PP2Q1PP/R4N1K b - - 1 20"
    },
    {
      "turn": 42,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc4",
          "aggressive_uci": "d2c4",
          "aggressive_response": "21... Nc4 22. Bxc4 bxc4 23. Qxc4 Rd2 24. Qxc7 Qd5 25. Rg1 Rxg2 26. Rxg2\nQd1+ 27. Rg1 Qf3+ 28. Rg2 Qd1+ 29. Rg1 Qd5+ 30. Rg2 Rf1+ 31. Nxf1 Qxg2#",
          "aggressive_tokens": {
            "prompt_tokens": 283,
            "completion_tokens": 103,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxc4",
            "bxc4",
            "Qxc4",
            "Rd2",
            "Qxc7",
            "Qd5",
            "Rg1",
            "Rxg2",
            "Rxg2",
            "Qd1+",
            "Rg1",
            "Qf3+",
            "Rg2",
            "Qd1+",
            "Rg1",
            "Qd5+",
            "Rg2",
            "Rf1+",
            "Nxf1",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": "d2c4",
          "positional_response": "21... Nc4 22. Bxc4 bxc4 23. Qxc4 Rd2 24. Qxc7 Qd5 25. Rg1 Rxg2 26. Rxg2\nQd1+ 27. Rg1 Qf3+ 28. Rg2 Qd1+ 29. Rg1 Qd5+ 30. Rg2 Rf1+ 31. Nxf1 Qxg2#",
          "positional_tokens": {
            "prompt_tokens": 283,
            "completion_tokens": 103,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxc4",
            "bxc4",
            "Qxc4",
            "Rd2",
            "Qxc7",
            "Qd5",
            "Rg1",
            "Rxg2",
            "Rxg2",
            "Qd1+",
            "Rg1",
            "Qf3+",
            "Rg2",
            "Qd1+",
            "Rg1",
            "Qd5+",
            "Rg2",
            "Rf1+",
            "Nxf1",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc4",
          "neutral_uci": "d2c4",
          "neutral_response": "21... Nc4 22. Bxc4 bxc4 23. Qxc4 Rd2 24. Qxc7 Qd5 25. Rg1 Rxg2 26. Rxg2 Qd1+ 27. Rg1 Qf3+ 28. Rg2 Qd1+ 29. Rg1 Qd5+ 30. Rg2 Rf1+ 31. Nxf1 Qxg2#",
          "neutral_tokens": {
            "prompt_tokens": 282,
            "completion_tokens": 102,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxc4",
            "bxc4",
            "Qxc4",
            "Rd2",
            "Qxc7",
            "Qd5",
            "Rg1",
            "Rxg2",
            "Rxg2",
            "Qd1+",
            "Rg1",
            "Qf3+",
            "Rg2",
            "Qd1+",
            "Rg1",
            "Qd5+",
            "Rg2",
            "Rf1+",
            "Nxf1",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2c4",
          "positional_uci": "d2c4",
          "neutral_uci": "d2c4",
          "consensus_move": "d2c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxc4",
              "bxc4",
              "Qxc4",
              "Rd2",
              "Qxc7",
              "Qd5",
              "Rg1",
              "Rxg2",
              "Rxg2",
              "Qd1+",
              "Rg1",
              "Qf3+",
              "Rg2",
              "Qd1+",
              "Rg1",
              "Qd5+",
              "Rg2",
              "Rf1+",
              "Nxf1",
              "Qxg2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxc4",
              "bxc4",
              "Qxc4",
              "Rd2",
              "Qxc7",
              "Qd5",
              "Rg1",
              "Rxg2",
              "Rxg2",
              "Qd1+",
              "Rg1",
              "Qf3+",
              "Rg2",
              "Qd1+",
              "Rg1",
              "Qd5+",
              "Rg2",
              "Rf1+",
              "Nxf1",
              "Qxg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxc4",
              "bxc4",
              "Qxc4",
              "Rd2",
              "Qxc7",
              "Qd5",
              "Rg1",
              "Rxg2",
              "Rxg2",
              "Qd1+",
              "Rg1",
              "Qf3+",
              "Rg2",
              "Qd1+",
              "Rg1",
              "Qd5+",
              "Rg2",
              "Rf1+",
              "Nxf1",
              "Qxg2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 283,
            "completion_tokens": 103,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 283,
            "completion_tokens": 103,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 282,
            "completion_tokens": 102,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 848,
          "total_completion_tokens": 308,
          "total_tokens": 1156
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 283,
            "completion_tokens": 103,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 283,
            "completion_tokens": 103,
            "total_tokens": 386,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 282,
            "completion_tokens": 102,
            "total_tokens": 384,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r1r1k/2p3pp/p3B3/1p4q1/8/2P3N1/PP1nQ1PP/R6K b - - 3 21"
    },
    {
      "turn": 44,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd2",
          "aggressive_uci": "d8d2",
          "aggressive_response": "22... Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxa6 Qd5 26. Rg1 Rxa2 27. Qf1 Rxf1 28. Nxf1 Qd3 29. Ng3 Qxc3 30. Ne4 Qe3 31. Ng3 c5 32. Nf5 Qf2 33. Ng3 c4 34. Ne4 Qe3 35. Ng3 c3 36. Nf5 Qf2 37. Ng3 c2 38. Ne4 Qxg1+ 39. Kxg1 c1=Q#",
          "aggressive_tokens": {
            "prompt_tokens": 292,
            "completion_tokens": 151,
            "total_tokens": 443,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe4",
            "bxc4",
            "Qxc4",
            "Rxb2",
            "Qxa6",
            "Qd5",
            "Rg1",
            "Rxa2",
            "Qf1",
            "Rxf1",
            "Nxf1",
            "Qd3",
            "Ng3",
            "Qxc3",
            "Ne4",
            "Qe3",
            "Ng3",
            "c5",
            "Nf5",
            "Qf2",
            "Ng3",
            "c4",
            "Ne4",
            "Qe3",
            "Ng3",
            "c3",
            "Nf5",
            "Qf2",
            "Ng3",
            "c2",
            "Ne4",
            "Qxg1+",
            "Kxg1",
            "c1=Q#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rd2",
          "positional_uci": "d8d2",
          "positional_response": "22... Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxa6 Qd5 26. Rg1 Rxa2 27. Qf1 Rxf1 28. Nxf1 Qd3 29. Ng3 Qxc3 30. Ne4 Qe3 31. Ng3 c5 32. Nf5 Qf2 33. Ng3 c4 34. Ne4 Qe3 35. Ng3 c3 36. Nf5 Qf2 37. Ng3 c2 38. Ne4 Qxg1+ 39. Kxg1 c1=Q#",
          "positional_tokens": {
            "prompt_tokens": 292,
            "completion_tokens": 151,
            "total_tokens": 443,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe4",
            "bxc4",
            "Qxc4",
            "Rxb2",
            "Qxa6",
            "Qd5",
            "Rg1",
            "Rxa2",
            "Qf1",
            "Rxf1",
            "Nxf1",
            "Qd3",
            "Ng3",
            "Qxc3",
            "Ne4",
            "Qe3",
            "Ng3",
            "c5",
            "Nf5",
            "Qf2",
            "Ng3",
            "c4",
            "Ne4",
            "Qe3",
            "Ng3",
            "c3",
            "Nf5",
            "Qf2",
            "Ng3",
            "c2",
            "Ne4",
            "Qxg1+",
            "Kxg1",
            "c1=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rd2",
          "neutral_uci": "d8d2",
          "neutral_response": "22... Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxa6 Qd5 26. Rg1 Rxa2 27. Qf1 Rxf1 28. Nxf1 Qd3 29. Ng3 Qxc3",
          "neutral_tokens": {
            "prompt_tokens": 291,
            "completion_tokens": 67,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe4",
            "bxc4",
            "Qxc4",
            "Rxb2",
            "Qxa6",
            "Qd5",
            "Rg1",
            "Rxa2",
            "Qf1",
            "Rxf1",
            "Nxf1",
            "Qd3",
            "Ng3",
            "Qxc3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8d2",
          "positional_uci": "d8d2",
          "neutral_uci": "d8d2",
          "consensus_move": "d8d2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qe4",
              "bxc4",
              "Qxc4",
              "Rxb2",
              "Qxa6",
              "Qd5",
              "Rg1",
              "Rxa2",
              "Qf1",
              "Rxf1",
              "Nxf1",
              "Qd3",
              "Ng3",
              "Qxc3",
              "Ne4",
              "Qe3",
              "Ng3",
              "c5",
              "Nf5",
              "Qf2",
              "Ng3",
              "c4",
              "Ne4",
              "Qe3",
              "Ng3",
              "c3",
              "Nf5",
              "Qf2",
              "Ng3",
              "c2",
              "Ne4",
              "Qxg1+",
              "Kxg1",
              "c1=Q#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe4",
              "bxc4",
              "Qxc4",
              "Rxb2",
              "Qxa6",
              "Qd5",
              "Rg1",
              "Rxa2",
              "Qf1",
              "Rxf1",
              "Nxf1",
              "Qd3",
              "Ng3",
              "Qxc3",
              "Ne4",
              "Qe3",
              "Ng3",
              "c5",
              "Nf5",
              "Qf2",
              "Ng3",
              "c4",
              "Ne4",
              "Qe3",
              "Ng3",
              "c3",
              "Nf5",
              "Qf2",
              "Ng3",
              "c2",
              "Ne4",
              "Qxg1+",
              "Kxg1",
              "c1=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe4",
              "bxc4",
              "Qxc4",
              "Rxb2",
              "Qxa6",
              "Qd5",
              "Rg1",
              "Rxa2",
              "Qf1",
              "Rxf1",
              "Nxf1",
              "Qd3",
              "Ng3",
              "Qxc3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 292,
            "completion_tokens": 151,
            "total_tokens": 443,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 292,
            "completion_tokens": 151,
            "total_tokens": 443,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 291,
            "completion_tokens": 67,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 875,
          "total_completion_tokens": 369,
          "total_tokens": 1244
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 292,
            "completion_tokens": 151,
            "total_tokens": 443,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 292,
            "completion_tokens": 151,
            "total_tokens": 443,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 291,
            "completion_tokens": 67,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r1r1k/2p3pp/p7/1p4q1/2B5/2P3N1/PP2Q1PP/R6K b - - 0 22"
    },
    {
      "turn": 46,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "bxc4",
          "aggressive_uci": "b5c4",
          "aggressive_response": "23...bxc4 24. Qxc4 Rxb2 25. Qxa6 Qd2 26. Qc6 Rxa2 27. Rg1 Qd6 28. Qc4 Raf2 29. Ne4\nR2f4 30. Nxd6 Rxc4 31. Nxc4 Rf4 32. Ne5 Re4 33. Rd1 h6 34. Nf3 Rc4 35. Rd3 Ra4\n36. h3 Ra1+ 37. Kh2 Ra3 38. Ne5 Kh7 39. c4 Ra5 40. Rd5 Ra4 41. Rc5 Ra7 42. Nc6\nRa6 43. Nb4 Ra4 44. Nd5 Ra7 45. Rxc7 Ra4 46. c5 Ra5 47. Ne7 Ra8 48. c6 Ra6 49.\nRd7 Ra8 50. c7 Re8 51. Rd8 Rxe7 52. c8=Q Rf7 53. Rh8+ Kg6 54. Qg4+ Kf6 55. Qf4+\nKe7 56. Qe5+ Kd7 57. Qe8+ Kd6 58. Qxf7 Ke5 59. Re8+ Kd4 60. Qd7+ Kc5 61. Rc8+\nKb6 62. Qc7+ Kb5 63. Rb8+ Ka6 64. Qb6# Rf7 Rf7 65. Ra8#",
          "aggressive_tokens": {
            "prompt_tokens": 300,
            "completion_tokens": 355,
            "total_tokens": 655,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc4",
            "Rxb2",
            "Qxa6",
            "Qd2",
            "Qc6",
            "Rxa2",
            "Rg1",
            "Qd6",
            "Qc4",
            "Raf2",
            "Ne4",
            "R2f4",
            "Nxd6",
            "Rxc4",
            "Nxc4",
            "Rf4",
            "Ne5",
            "Re4",
            "Rd1",
            "h6",
            "Nf3",
            "Rc4",
            "Rd3",
            "Ra4",
            "h3",
            "Ra1+",
            "Kh2",
            "Ra3",
            "Ne5",
            "Kh7",
            "c4",
            "Ra5",
            "Rd5",
            "Ra4",
            "Rc5",
            "Ra7",
            "Nc6",
            "Ra6",
            "Nb4",
            "Ra4",
            "Nd5",
            "Ra7",
            "Rxc7",
            "Ra4",
            "c5",
            "Ra5",
            "Ne7",
            "Ra8",
            "c6",
            "Ra6",
            "Rd7",
            "Ra8",
            "c7",
            "Re8",
            "Rd8",
            "Rxe7",
            "c8=Q",
            "Rf7",
            "Rh8+",
            "Kg6",
            "Qg4+",
            "Kf6",
            "Qf4+",
            "Ke7",
            "Qe5+",
            "Kd7",
            "Qe8+",
            "Kd6",
            "Qxf7",
            "Ke5",
            "Re8+",
            "Kd4",
            "Qd7+",
            "Kc5",
            "Rc8+",
            "Kb6",
            "Qc7+",
            "Kb5",
            "Rb8+",
            "Ka6",
            "Qb6#",
            "Rf7",
            "Rf7",
            "Ra8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "bxc4",
          "positional_uci": "b5c4",
          "positional_response": "23...bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Rg1 Rxa2 27. Nh5 Qg5 28. Ng3 h6 29. c4\nRff2 30. c5 Qd5 31. Qc8+ Kh7 32. Qh3 Qxc5 33. Ne4 Qf5 34. Nxf2 Qxh3 35. Nxh3\na5 36. Nf4 a4 37. Nd3 a3 38. Nb4 Rb2 39. Nd3 Rd2 40. Nb4 a2 41. Ra1 Rb2 42. Nxa2\nRb3 43. h3 Ra3 44. Kh2 Kg6 45. Kg1 Kf5 46. Kf2 Ke4 47. Ke2 Kd4 48. Kd2 Kc4\n49. Kc2 Rg3 50. Rg1 Ra3 51. Kb2 Rb3+ 52. Kc2 Ra3 53. Nc1 Rc3+ 54. Kd2 Ra3 55. Rf1\nRg3 56. Rf4+ Kd5 57. Rg4 Rxg4 58. hxg4 Ke4 59. Ke2 Kf4 60. Nd3+ Kxg4 61. Kf2\nh5 62. Ne5+ Kf5 63. Nf3 g5 64. Kg3 h4+ 65. Kh3 Kf4 66. Nh2 Kf5 67. Ng4 Kf4 68. Nf6\nKf5 69. Nd5 Ke5 70. Ne3 Kf4 71. Ng4 Kf5 72. Nf2 Kf4 73. Nd3+ Kf5 74. Nc5 Kf4\n75. Ne6+ Kf5 76. Ng7+ Kf4 77. Nh5+ Kf5 78. Ng7+ Kf4 79. Ne6+ Kf5 80. Nd4+ Kf4\n81. Nf3 Kf5 82. Nh2 Kf4 83. Nf1 Kf5 84. Ne3+ Kf4 85. Nd5+ Kf5 86. Nc3 Kf4 87. Ne2+\nKf5 88. Ng1 Kf4 89. Nf3 Kf5 90. Nh2 Kf4 91. Ng4 Kf5 92. Nf2 Kf4 93. Nd3+ Kf5\n94. Nc5 Kf4 95. Ne6+ Kf5 96. Ng7+ Kf4 97. Ne8 Kf5 98",
          "positional_tokens": {
            "prompt_tokens": 300,
            "completion_tokens": 640,
            "total_tokens": 940,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxc4",
            "Rxb2",
            "Qxc7",
            "Qd2",
            "Rg1",
            "Rxa2",
            "Nh5",
            "Qg5",
            "Ng3",
            "h6",
            "c4",
            "Rff2",
            "c5",
            "Qd5",
            "Qc8+",
            "Kh7",
            "Qh3",
            "Qxc5",
            "Ne4",
            "Qf5",
            "Nxf2",
            "Qxh3",
            "Nxh3",
            "a5",
            "Nf4",
            "a4",
            "Nd3",
            "a3",
            "Nb4",
            "Rb2",
            "Nd3",
            "Rd2",
            "Nb4",
            "a2",
            "Ra1",
            "Rb2",
            "Nxa2",
            "Rb3",
            "h3",
            "Ra3",
            "Kh2",
            "Kg6",
            "Kg1",
            "Kf5",
            "Kf2",
            "Ke4",
            "Ke2",
            "Kd4",
            "Kd2",
            "Kc4",
            "Kc2",
            "Rg3",
            "Rg1",
            "Ra3",
            "Kb2",
            "Rb3+",
            "Kc2",
            "Ra3",
            "Nc1",
            "Rc3+",
            "Kd2",
            "Ra3",
            "Rf1",
            "Rg3",
            "Rf4+",
            "Kd5",
            "Rg4",
            "Rxg4",
            "hxg4",
            "Ke4",
            "Ke2",
            "Kf4",
            "Nd3+",
            "Kxg4",
            "Kf2",
            "h5",
            "Ne5+",
            "Kf5",
            "Nf3",
            "g5",
            "Kg3",
            "h4+",
            "Kh3",
            "Kf4",
            "Nh2",
            "Kf5",
            "Ng4",
            "Kf4",
            "Nf6",
            "Kf5",
            "Nd5",
            "Ke5",
            "Ne3",
            "Kf4",
            "Ng4",
            "Kf5",
            "Nf2",
            "Kf4",
            "Nd3+",
            "Kf5",
            "Nc5",
            "Kf4",
            "Ne6+",
            "Kf5",
            "Ng7+",
            "Kf4",
            "Nh5+",
            "Kf5",
            "Ng7+",
            "Kf4",
            "Ne6+",
            "Kf5",
            "Nd4+",
            "Kf4",
            "Nf3",
            "Kf5",
            "Nh2",
            "Kf4",
            "Nf1",
            "Kf5",
            "Ne3+",
            "Kf4",
            "Nd5+",
            "Kf5",
            "Nc3",
            "Kf4",
            "Ne2+",
            "Kf5",
            "Ng1",
            "Kf4",
            "Nf3",
            "Kf5",
            "Nh2",
            "Kf4",
            "Ng4",
            "Kf5",
            "Nf2",
            "Kf4",
            "Nd3+",
            "Kf5",
            "Nc5",
            "Kf4",
            "Ne6+",
            "Kf5",
            "Ng7+",
            "Kf4",
            "Ne8",
            "Kf5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "bxc4",
          "neutral_uci": "b5c4",
          "neutral_response": "23...bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Rg1 Rxa2 27. Qe7 Qf2 28. c4 Rc2 29. Qe6\na5 30. Qd5 a4 31. Qd3 a3 32. Qxa3 Qxg1+ 33. Kxg1 Rff2 34. Qa8+ Rf8 35. Qxf8#",
          "neutral_tokens": {
            "prompt_tokens": 299,
            "completion_tokens": 112,
            "total_tokens": 411,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc4",
            "Rxb2",
            "Qxc7",
            "Qd2",
            "Rg1",
            "Rxa2",
            "Qe7",
            "Qf2",
            "c4",
            "Rc2",
            "Qe6",
            "a5",
            "Qd5",
            "a4",
            "Qd3",
            "a3",
            "Qxa3",
            "Qxg1+",
            "Kxg1",
            "Rff2",
            "Qa8+",
            "Rf8",
            "Qxf8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b5c4",
          "positional_uci": "b5c4",
          "neutral_uci": "b5c4",
          "consensus_move": "b5c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxc4",
              "Rxb2",
              "Qxa6",
              "Qd2",
              "Qc6",
              "Rxa2",
              "Rg1",
              "Qd6",
              "Qc4",
              "Raf2",
              "Ne4",
              "R2f4",
              "Nxd6",
              "Rxc4",
              "Nxc4",
              "Rf4",
              "Ne5",
              "Re4",
              "Rd1",
              "h6",
              "Nf3",
              "Rc4",
              "Rd3",
              "Ra4",
              "h3",
              "Ra1+",
              "Kh2",
              "Ra3",
              "Ne5",
              "Kh7",
              "c4",
              "Ra5",
              "Rd5",
              "Ra4",
              "Rc5",
              "Ra7",
              "Nc6",
              "Ra6",
              "Nb4",
              "Ra4",
              "Nd5",
              "Ra7",
              "Rxc7",
              "Ra4",
              "c5",
              "Ra5",
              "Ne7",
              "Ra8",
              "c6",
              "Ra6",
              "Rd7",
              "Ra8",
              "c7",
              "Re8",
              "Rd8",
              "Rxe7",
              "c8=Q",
              "Rf7",
              "Rh8+",
              "Kg6",
              "Qg4+",
              "Kf6",
              "Qf4+",
              "Ke7",
              "Qe5+",
              "Kd7",
              "Qe8+",
              "Kd6",
              "Qxf7",
              "Ke5",
              "Re8+",
              "Kd4",
              "Qd7+",
              "Kc5",
              "Rc8+",
              "Kb6",
              "Qc7+",
              "Kb5",
              "Rb8+",
              "Ka6",
              "Qb6#",
              "Rf7",
              "Rf7",
              "Ra8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxc4",
              "Rxb2",
              "Qxc7",
              "Qd2",
              "Rg1",
              "Rxa2",
              "Nh5",
              "Qg5",
              "Ng3",
              "h6",
              "c4",
              "Rff2",
              "c5",
              "Qd5",
              "Qc8+",
              "Kh7",
              "Qh3",
              "Qxc5",
              "Ne4",
              "Qf5",
              "Nxf2",
              "Qxh3",
              "Nxh3",
              "a5",
              "Nf4",
              "a4",
              "Nd3",
              "a3",
              "Nb4",
              "Rb2",
              "Nd3",
              "Rd2",
              "Nb4",
              "a2",
              "Ra1",
              "Rb2",
              "Nxa2",
              "Rb3",
              "h3",
              "Ra3",
              "Kh2",
              "Kg6",
              "Kg1",
              "Kf5",
              "Kf2",
              "Ke4",
              "Ke2",
              "Kd4",
              "Kd2",
              "Kc4",
              "Kc2",
              "Rg3",
              "Rg1",
              "Ra3",
              "Kb2",
              "Rb3+",
              "Kc2",
              "Ra3",
              "Nc1",
              "Rc3+",
              "Kd2",
              "Ra3",
              "Rf1",
              "Rg3",
              "Rf4+",
              "Kd5",
              "Rg4",
              "Rxg4",
              "hxg4",
              "Ke4",
              "Ke2",
              "Kf4",
              "Nd3+",
              "Kxg4",
              "Kf2",
              "h5",
              "Ne5+",
              "Kf5",
              "Nf3",
              "g5",
              "Kg3",
              "h4+",
              "Kh3",
              "Kf4",
              "Nh2",
              "Kf5",
              "Ng4",
              "Kf4",
              "Nf6",
              "Kf5",
              "Nd5",
              "Ke5",
              "Ne3",
              "Kf4",
              "Ng4",
              "Kf5",
              "Nf2",
              "Kf4",
              "Nd3+",
              "Kf5",
              "Nc5",
              "Kf4",
              "Ne6+",
              "Kf5",
              "Ng7+",
              "Kf4",
              "Nh5+",
              "Kf5",
              "Ng7+",
              "Kf4",
              "Ne6+",
              "Kf5",
              "Nd4+",
              "Kf4",
              "Nf3",
              "Kf5",
              "Nh2",
              "Kf4",
              "Nf1",
              "Kf5",
              "Ne3+",
              "Kf4",
              "Nd5+",
              "Kf5",
              "Nc3",
              "Kf4",
              "Ne2+",
              "Kf5",
              "Ng1",
              "Kf4",
              "Nf3",
              "Kf5",
              "Nh2",
              "Kf4",
              "Ng4",
              "Kf5",
              "Nf2",
              "Kf4",
              "Nd3+",
              "Kf5",
              "Nc5",
              "Kf4",
              "Ne6+",
              "Kf5",
              "Ng7+",
              "Kf4",
              "Ne8",
              "Kf5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxc4",
              "Rxb2",
              "Qxc7",
              "Qd2",
              "Rg1",
              "Rxa2",
              "Qe7",
              "Qf2",
              "c4",
              "Rc2",
              "Qe6",
              "a5",
              "Qd5",
              "a4",
              "Qd3",
              "a3",
              "Qxa3",
              "Qxg1+",
              "Kxg1",
              "Rff2",
              "Qa8+",
              "Rf8",
              "Qxf8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 300,
            "completion_tokens": 355,
            "total_tokens": 655,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 300,
            "completion_tokens": 640,
            "total_tokens": 940,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 299,
            "completion_tokens": 112,
            "total_tokens": 411,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 899,
          "total_completion_tokens": 1107,
          "total_tokens": 2006
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 300,
            "completion_tokens": 355,
            "total_tokens": 655,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 300,
            "completion_tokens": 640,
            "total_tokens": 940,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 299,
            "completion_tokens": 112,
            "total_tokens": 411,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5r1k/2p3pp/p7/1p4q1/2B1Q3/2P3N1/PP1r2PP/R6K b - - 2 23"
    },
    {
      "turn": 48,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxb2",
          "aggressive_uci": "d2b2",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Rg1 Rxa2 27. Nh5 Qg5 28. Ng3 a5 29. Qd6 Qf6 30. Qd5 Qf7 31. Qd4 a4 32. c4 a3 33. c5 Rb2 34. c6 Rbb8 35. Qa4 a2 36. h3 Ra8 37. Qd4 Qf6 38. Qxf6 Rxf6 39. Ra1 Rxc6 40. Ne2 Rb6 41. Nc3 Rb2 42. Kh2 Rc2 43. Nb5 Rb8 44. Nd4 Rd2 45. Nc6 Rb1 46. Rxa2 Rxa2 47. Ne5 Rbb2 48. Kg3 Rxg2+ 49. Kf4 Raf2+ 50. Ke4 Re2+ 51. Kd5 Rxe5+ 52. Kxe5 Rh2 53. Kf4 Rxh3 54. Kg4 Ra3 55. Kf4 h5 56. Kg5 g6 57. Kxg6 h4 58. Kg5 h3 59. Kg4 h2 60. Kf4 h1=Q 61. Ke5 Qh4 62. Kd5 Ra5+ 63. Kc6 Qh6+ 64. Kb7 Rg5 65. Kc7 Rg7+ 66. Kd8 Qd6+ 67. Ke8 Qe7#",
          "aggressive_tokens": {
            "prompt_tokens": 309,
            "completion_tokens": 563,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc7",
            "Qd2",
            "Rg1",
            "Rxa2",
            "Nh5",
            "Qg5",
            "Ng3",
            "a5",
            "Qd6",
            "Qf6",
            "Qd5",
            "Qf7",
            "Qd4",
            "a4",
            "c4",
            "a3",
            "c5",
            "Rb2",
            "c6",
            "Rbb8",
            "Qa4",
            "a2",
            "h3",
            "Ra8",
            "Qd4",
            "Qf6",
            "Qxf6",
            "Rxf6",
            "Ra1",
            "Rxc6",
            "Ne2",
            "Rb6",
            "Nc3",
            "Rb2",
            "Kh2",
            "Rc2",
            "Nb5",
            "Rb8",
            "Nd4",
            "Rd2",
            "Nc6",
            "Rb1",
            "Rxa2",
            "Rxa2",
            "Ne5",
            "Rbb2",
            "Kg3",
            "Rxg2+",
            "Kf4",
            "Raf2+",
            "Ke4",
            "Re2+",
            "Kd5",
            "Rxe5+",
            "Kxe5",
            "Rh2",
            "Kf4",
            "Rxh3",
            "Kg4",
            "Ra3",
            "Kf4",
            "h5",
            "Kg5",
            "g6",
            "Kxg6",
            "h4",
            "Kg5",
            "h3",
            "Kg4",
            "h2",
            "Kf4",
            "h1=Q",
            "Ke5",
            "Qh4",
            "Kd5",
            "Ra5+",
            "Kc6",
            "Qh6+",
            "Kb7",
            "Rg5",
            "Kc7",
            "Rg7+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qe7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxb2",
          "positional_uci": "d2b2",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Rg1\nRxa2 27. Nh5 Qg5 28. Ng3 a5 29. Qd6 Qf6 30. Qd5 Qf7 31. Qd4 a4 32. c4 a3 33.\nc5 Rf2 34. c6 a2 35. Qa1 Qf6 36. Qxf6 R2xf6 37. c7 Rc6 38. Ra1 Rxc7 39. h3\nRc2 40. Kh2 Rff2 41. Ne4 Rxg2+ 42. Kh1 Rh2+ 43. Kg1 Rcg2+ 44. Kf1 Rh1+ 45.\nKxg2 Rxa1 46. Nc3 Rg1+ 47. Kxg1 a1=Q+ 48. Kg2 Qxc3 49. Kh2 Qf3 50. Kg1 Qe2\n51. Kh1 g5 52. Kg1 h5 53. Kh1 g4 54. hxg4 hxg4 55. Kg1 g3 56. Kh1 Qh2#",
          "positional_tokens": {
            "prompt_tokens": 309,
            "completion_tokens": 473,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc7",
            "Qd2",
            "Rg1",
            "Rxa2",
            "Nh5",
            "Qg5",
            "Ng3",
            "a5",
            "Qd6",
            "Qf6",
            "Qd5",
            "Qf7",
            "Qd4",
            "a4",
            "c4",
            "a3",
            "c5",
            "Rf2",
            "c6",
            "a2",
            "Qa1",
            "Qf6",
            "Qxf6",
            "R2xf6",
            "c7",
            "Rc6",
            "Ra1",
            "Rxc7",
            "h3",
            "Rc2",
            "Kh2",
            "Rff2",
            "Ne4",
            "Rxg2+",
            "Kh1",
            "Rh2+",
            "Kg1",
            "Rcg2+",
            "Kf1",
            "Rh1+",
            "Kxg2",
            "Rxa1",
            "Nc3",
            "Rg1+",
            "Kxg1",
            "a1=Q+",
            "Kg2",
            "Qxc3",
            "Kh2",
            "Qf3",
            "Kg1",
            "Qe2",
            "Kh1",
            "g5",
            "Kg1",
            "h5",
            "Kh1",
            "g4",
            "hxg4",
            "hxg4",
            "Kg1",
            "g3",
            "Kh1",
            "Qh2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxb2",
          "neutral_uci": "d2b2",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Rg1\nRxa2 27. Nh5 Qg5 28. Ng3 h6 29. c4 Rff2 30. c5 Qd5 31. Qc8+ Kh7 32. Qh3 Qxc5\n33. Ne4 Qf5 34. Nxf2 Qxh3 35. Nxh3 a5 36. Nf4 a4 37. Nd3 a3 38. Nb4 Rb2 39. Nd3\nRd2 40. Nb4 a2 41. Ra1 Rb2 42. Nxa2 *",
          "neutral_tokens": {
            "prompt_tokens": 308,
            "completion_tokens": 351,
            "total_tokens": 659,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxc7",
            "Qd2",
            "Rg1",
            "Rxa2",
            "Nh5",
            "Qg5",
            "Ng3",
            "h6",
            "c4",
            "Rff2",
            "c5",
            "Qd5",
            "Qc8+",
            "Kh7",
            "Qh3",
            "Qxc5",
            "Ne4",
            "Qf5",
            "Nxf2",
            "Qxh3",
            "Nxh3",
            "a5",
            "Nf4",
            "a4",
            "Nd3",
            "a3",
            "Nb4",
            "Rb2",
            "Nd3",
            "Rd2",
            "Nb4",
            "a2",
            "Ra1",
            "Rb2",
            "Nxa2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2b2",
          "positional_uci": "d2b2",
          "neutral_uci": "d2b2",
          "consensus_move": "d2b2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxc7",
              "Qd2",
              "Rg1",
              "Rxa2",
              "Nh5",
              "Qg5",
              "Ng3",
              "a5",
              "Qd6",
              "Qf6",
              "Qd5",
              "Qf7",
              "Qd4",
              "a4",
              "c4",
              "a3",
              "c5",
              "Rb2",
              "c6",
              "Rbb8",
              "Qa4",
              "a2",
              "h3",
              "Ra8",
              "Qd4",
              "Qf6",
              "Qxf6",
              "Rxf6",
              "Ra1",
              "Rxc6",
              "Ne2",
              "Rb6",
              "Nc3",
              "Rb2",
              "Kh2",
              "Rc2",
              "Nb5",
              "Rb8",
              "Nd4",
              "Rd2",
              "Nc6",
              "Rb1",
              "Rxa2",
              "Rxa2",
              "Ne5",
              "Rbb2",
              "Kg3",
              "Rxg2+",
              "Kf4",
              "Raf2+",
              "Ke4",
              "Re2+",
              "Kd5",
              "Rxe5+",
              "Kxe5",
              "Rh2",
              "Kf4",
              "Rxh3",
              "Kg4",
              "Ra3",
              "Kf4",
              "h5",
              "Kg5",
              "g6",
              "Kxg6",
              "h4",
              "Kg5",
              "h3",
              "Kg4",
              "h2",
              "Kf4",
              "h1=Q",
              "Ke5",
              "Qh4",
              "Kd5",
              "Ra5+",
              "Kc6",
              "Qh6+",
              "Kb7",
              "Rg5",
              "Kc7",
              "Rg7+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qe7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxc7",
              "Qd2",
              "Rg1",
              "Rxa2",
              "Nh5",
              "Qg5",
              "Ng3",
              "a5",
              "Qd6",
              "Qf6",
              "Qd5",
              "Qf7",
              "Qd4",
              "a4",
              "c4",
              "a3",
              "c5",
              "Rf2",
              "c6",
              "a2",
              "Qa1",
              "Qf6",
              "Qxf6",
              "R2xf6",
              "c7",
              "Rc6",
              "Ra1",
              "Rxc7",
              "h3",
              "Rc2",
              "Kh2",
              "Rff2",
              "Ne4",
              "Rxg2+",
              "Kh1",
              "Rh2+",
              "Kg1",
              "Rcg2+",
              "Kf1",
              "Rh1+",
              "Kxg2",
              "Rxa1",
              "Nc3",
              "Rg1+",
              "Kxg1",
              "a1=Q+",
              "Kg2",
              "Qxc3",
              "Kh2",
              "Qf3",
              "Kg1",
              "Qe2",
              "Kh1",
              "g5",
              "Kg1",
              "h5",
              "Kh1",
              "g4",
              "hxg4",
              "hxg4",
              "Kg1",
              "g3",
              "Kh1",
              "Qh2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxc7",
              "Qd2",
              "Rg1",
              "Rxa2",
              "Nh5",
              "Qg5",
              "Ng3",
              "h6",
              "c4",
              "Rff2",
              "c5",
              "Qd5",
              "Qc8+",
              "Kh7",
              "Qh3",
              "Qxc5",
              "Ne4",
              "Qf5",
              "Nxf2",
              "Qxh3",
              "Nxh3",
              "a5",
              "Nf4",
              "a4",
              "Nd3",
              "a3",
              "Nb4",
              "Rb2",
              "Nd3",
              "Rd2",
              "Nb4",
              "a2",
              "Ra1",
              "Rb2",
              "Nxa2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 309,
            "completion_tokens": 563,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 309,
            "completion_tokens": 473,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 308,
            "completion_tokens": 351,
            "total_tokens": 659,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 926,
          "total_completion_tokens": 1387,
          "total_tokens": 2313
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 47,
            "turn_number": 24,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 309,
            "completion_tokens": 563,
            "total_tokens": 872,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 47,
            "turn_number": 24,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 309,
            "completion_tokens": 473,
            "total_tokens": 782,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 47,
            "turn_number": 24,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 308,
            "completion_tokens": 351,
            "total_tokens": 659,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5r1k/2p3pp/p7/6q1/2Q5/2P3N1/PP1r2PP/R6K b - - 0 24"
    },
    {
      "turn": 50,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qd2",
          "aggressive_uci": "g5d2",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Qc6 Rxa2 27. Rg1 Qf2 28. Qd6 Qxg1+ 29. Kxg1 Ra1+ 30. Nf1 Raxf1#",
          "aggressive_tokens": {
            "prompt_tokens": 318,
            "completion_tokens": 262,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc6",
            "Rxa2",
            "Rg1",
            "Qf2",
            "Qd6",
            "Qxg1+",
            "Kxg1",
            "Ra1+",
            "Nf1",
            "Raxf1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qd2",
          "positional_uci": "g5d2",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Qc6 Rxa2 27. Rg1 Qf2 28. Qd6 a5 29. c4 a4",
          "positional_tokens": {
            "prompt_tokens": 318,
            "completion_tokens": 245,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc6",
            "Rxa2",
            "Rg1",
            "Qf2",
            "Qd6",
            "a5",
            "c4",
            "a4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qd2",
          "neutral_uci": "g5d2",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Qc6 Rxa2 27. Rg1 Qf2 28. Qd6 a5 29. c4 a4",
          "neutral_tokens": {
            "prompt_tokens": 317,
            "completion_tokens": 245,
            "total_tokens": 562,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qc6",
            "Rxa2",
            "Rg1",
            "Qf2",
            "Qd6",
            "a5",
            "c4",
            "a4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5d2",
          "positional_uci": "g5d2",
          "neutral_uci": "g5d2",
          "consensus_move": "g5d2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qc6",
              "Rxa2",
              "Rg1",
              "Qf2",
              "Qd6",
              "Qxg1+",
              "Kxg1",
              "Ra1+",
              "Nf1",
              "Raxf1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qc6",
              "Rxa2",
              "Rg1",
              "Qf2",
              "Qd6",
              "a5",
              "c4",
              "a4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qc6",
              "Rxa2",
              "Rg1",
              "Qf2",
              "Qd6",
              "a5",
              "c4",
              "a4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 318,
            "completion_tokens": 262,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 318,
            "completion_tokens": 245,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 317,
            "completion_tokens": 245,
            "total_tokens": 562,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 953,
          "total_completion_tokens": 752,
          "total_tokens": 1705
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 49,
            "turn_number": 25,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 318,
            "completion_tokens": 262,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 49,
            "turn_number": 25,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 318,
            "completion_tokens": 245,
            "total_tokens": 563,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 49,
            "turn_number": 25,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 317,
            "completion_tokens": 245,
            "total_tokens": 562,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5r1k/2Q3pp/p7/6q1/8/2P3N1/Pr4PP/R6K b - - 0 25"
    },
    {
      "turn": 52,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxc3",
          "aggressive_uci": "d2c3",
          "aggressive_response": "26... Qxc3 27. Qxc3 Rxa2 28. Rxa2 Rf1+ 29. Nxf1 *",
          "aggressive_tokens": {
            "prompt_tokens": 327,
            "completion_tokens": 32,
            "total_tokens": 359,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxa2",
            "Rxa2",
            "Rf1+",
            "Nxf1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxc3",
          "positional_uci": "d2c3",
          "positional_response": "26... Qxc3 27. Qxc3 Rxa2 28. Rxa2 Rf1+ 29. Nxf1",
          "positional_tokens": {
            "prompt_tokens": 327,
            "completion_tokens": 31,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxa2",
            "Rxa2",
            "Rf1+",
            "Nxf1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxa2",
          "neutral_uci": "b2a2",
          "neutral_response": "26... Rxa2 27. Rg1 Qf2 28. Qd6 a5 29. c4 a4",
          "neutral_tokens": {
            "prompt_tokens": 326,
            "completion_tokens": 30,
            "total_tokens": 356,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg1",
            "Qf2",
            "Qd6",
            "a5",
            "c4",
            "a4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2c3",
          "positional_uci": "d2c3",
          "neutral_uci": "b2a2",
          "consensus_move": "d2c3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxa2",
              "Rxa2",
              "Rf1+",
              "Nxf1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxa2",
              "Rxa2",
              "Rf1+",
              "Nxf1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg1",
              "Qf2",
              "Qd6",
              "a5",
              "c4",
              "a4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 327,
            "completion_tokens": 32,
            "total_tokens": 359,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 327,
            "completion_tokens": 31,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 326,
            "completion_tokens": 30,
            "total_tokens": 356,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 980,
          "total_completion_tokens": 93,
          "total_tokens": 1073
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 51,
            "turn_number": 26,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 327,
            "completion_tokens": 32,
            "total_tokens": 359,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 51,
            "turn_number": 26,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 327,
            "completion_tokens": 31,
            "total_tokens": 358,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 51,
            "turn_number": 26,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 326,
            "completion_tokens": 30,
            "total_tokens": 356,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5r1k/6pp/p1Q5/8/8/2P3N1/Pr1q2PP/R6K b - - 2 26"
    },
    {
      "turn": 54,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rb1+",
          "aggressive_uci": "b2b1",
          "aggressive_response": "27... Rb1+ 28. Rxb1 Qxc3 29. Ne4 Qd3",
          "aggressive_tokens": {
            "prompt_tokens": 337,
            "completion_tokens": 24,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb1",
            "Qxc3",
            "Ne4",
            "Qd3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rb1+",
          "positional_uci": "b2b1",
          "positional_response": "27... Rb1+ 28. Rxb1 Qxc3 29. Ne4 Qd3",
          "positional_tokens": {
            "prompt_tokens": 337,
            "completion_tokens": 24,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb1",
            "Qxc3",
            "Ne4",
            "Qd3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rb1+",
          "neutral_uci": "b2b1",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Qc6\nQxc3 27. Qxc3 Rb1+ 28. Rxb1 Rf1+ 29. Rxf1 *",
          "neutral_tokens": {
            "prompt_tokens": 336,
            "completion_tokens": 249,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb1",
            "Rf1+",
            "Rxf1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b2b1",
          "positional_uci": "b2b1",
          "neutral_uci": "b2b1",
          "consensus_move": "b2b1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxb1",
              "Qxc3",
              "Ne4",
              "Qd3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxb1",
              "Qxc3",
              "Ne4",
              "Qd3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxb1",
              "Rf1+",
              "Rxf1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 337,
            "completion_tokens": 24,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 337,
            "completion_tokens": 24,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 336,
            "completion_tokens": 249,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1010,
          "total_completion_tokens": 297,
          "total_tokens": 1307
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 53,
            "turn_number": 27,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 337,
            "completion_tokens": 24,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 53,
            "turn_number": 27,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 337,
            "completion_tokens": 24,
            "total_tokens": 361,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 53,
            "turn_number": 27,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 336,
            "completion_tokens": 249,
            "total_tokens": 585,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5r1k/6pp/p7/8/8/2Q3N1/Pr4PP/R6K b - - 0 27"
    },
    {
      "turn": 56,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rb8",
          "aggressive_uci": "f8b8",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Qc6\nQxc3 27. Qxc3 Rb1+ 28. Rxb1 Rb8 29. Rxb8#",
          "aggressive_tokens": {
            "prompt_tokens": 347,
            "completion_tokens": 248,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g5",
          "positional_uci": null,
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Qc6\nQxc3 27. Qxc3 Rb1+ 28. Rxb1 g5 29. Nh5+ Kg8 30. Qg7#",
          "positional_tokens": {
            "prompt_tokens": 347,
            "completion_tokens": 255,
            "total_tokens": 602,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nh5+",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rb8",
          "neutral_uci": "f8b8",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 f6 14. exf6\nQxf6 15. Bxd5 Rad8 16. Bg5 Qxg5 17. Bxe6+ Kh8 18. Qe2 Ne5 19. Kg1 Nxf3+ 20. Kh1\nNd2 21. Ng3 Nc4 22. Bxc4 Rd2 23. Qe4 bxc4 24. Qxc4 Rxb2 25. Qxc7 Qd2 26. Qc6\nQxc3 27. Qxc3 Rb1+ 28. Rxb1 Rb8 29. Rxb8#",
          "neutral_tokens": {
            "prompt_tokens": 346,
            "completion_tokens": 248,
            "total_tokens": 594,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8b8",
          "positional_uci": null,
          "neutral_uci": "f8b8",
          "consensus_move": "f8b8",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxb8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nh5+",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxb8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 347,
            "completion_tokens": 248,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 347,
            "completion_tokens": 255,
            "total_tokens": 602,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 346,
            "completion_tokens": 248,
            "total_tokens": 594,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1040,
          "total_completion_tokens": 751,
          "total_tokens": 1791
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 55,
            "turn_number": 28,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 347,
            "completion_tokens": 248,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 55,
            "turn_number": 28,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 347,
            "completion_tokens": 255,
            "total_tokens": 602,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 55,
            "turn_number": 28,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 346,
            "completion_tokens": 248,
            "total_tokens": 594,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5r1k/6pp/p7/8/8/2Q3N1/P5PP/1R5K b - - 0 28"
    }
  ],
  "white_errors": [],
  "black_errors": [],
  "white_plan_log": [],
  "black_plan_log": [],
  "timestamp": "2025-11-29T23:44:54.524000",
  "game_id": "gpt-3.5-turbo-instruct_vs_gpt-3.5-turbo-instruct_SC_1",
  "configuration": "single"
}