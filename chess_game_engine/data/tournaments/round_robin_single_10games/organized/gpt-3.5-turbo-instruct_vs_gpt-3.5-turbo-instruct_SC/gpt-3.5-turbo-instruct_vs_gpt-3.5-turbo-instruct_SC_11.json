{
  "result": "gpt-3.5-turbo-instruct wins by checkmate",
  "white_player": "gpt-3.5-turbo-instruct",
  "black_player": "gpt-3.5-turbo-instruct_SC",
  "white_score": 1.0,
  "black_score": 0.0,
  "total_moves": 89,
  "moves": [
    "e2e4",
    "e7e5",
    "g1f3",
    "b8c6",
    "f1b5",
    "a7a6",
    "b5a4",
    "g8f6",
    "e1g1",
    "f6e4",
    "d2d4",
    "b7b5",
    "a4b3",
    "d7d5",
    "d4e5",
    "c8e6",
    "c2c3",
    "f8c5",
    "b1d2",
    "e4f2",
    "f1f2",
    "c5f2",
    "g1f2",
    "f7f6",
    "e5f6",
    "d8f6",
    "d2f1",
    "e8g8",
    "b3d5",
    "a8d8",
    "c1g5",
    "f6f7",
    "d5e6",
    "f7e6",
    "g5d8",
    "f8d8",
    "d1e2",
    "e6f7",
    "f2g1",
    "d8f8",
    "f3g5",
    "f7f5",
    "e2e6",
    "f5e6",
    "g5e6",
    "f8f7",
    "a1d1",
    "f7e7",
    "e6d8",
    "c6e5",
    "d8b7",
    "e5c4",
    "d1d8",
    "g8f7",
    "b2b3",
    "c4b6",
    "b7c5",
    "e7e2",
    "c5a6",
    "e2a2",
    "a6c7",
    "a2a3",
    "c7b5",
    "a3b3",
    "b5d4",
    "b3b2",
    "d8b8",
    "f7g6",
    "c3c4",
    "b6c4",
    "b8b2",
    "c4b2",
    "f1e3",
    "b2d3",
    "d4f3",
    "d3f4",
    "f3e5",
    "g6f6",
    "e5d7",
    "f6g6",
    "g2g3",
    "f4e6",
    "d7e5",
    "g6g5",
    "h2h4",
    "g5h5",
    "e3f5",
    "g7g5",
    "g3g4"
  ],
  "game_history": [
    {
      "move_number": 1,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e4",
      "move_san": "e4",
      "fen_after": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "move_number": 2,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e7e5",
      "move_san": "e5",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "move_number": 3,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1f3",
      "move_san": "Nf3",
      "fen_after": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "move_number": 4,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "b8c6",
      "move_san": "Nc6",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "move_number": 5,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1b5",
      "move_san": "Bb5",
      "fen_after": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "move_number": 6,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "a7a6",
      "move_san": "a6",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "move_number": 7,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b5a4",
      "move_san": "Ba4",
      "fen_after": "r1bqkbnr/1ppp1ppp/p1n5/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "move_number": 8,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "g8f6",
      "move_san": "Nf6",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "move_number": 9,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1g1",
      "move_san": "O-O",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 b kq - 3 5"
    },
    {
      "move_number": 10,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f6e4",
      "move_san": "Nxe4",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n5/4p3/B3n3/5N2/PPPP1PPP/RNBQ1RK1 w kq - 0 6"
    },
    {
      "move_number": 11,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2d4",
      "move_san": "d4",
      "fen_after": "r1bqkb1r/1ppp1ppp/p1n5/4p3/B2Pn3/5N2/PPP2PPP/RNBQ1RK1 b kq - 0 6"
    },
    {
      "move_number": 12,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "b7b5",
      "move_san": "b5",
      "fen_after": "r1bqkb1r/2pp1ppp/p1n5/1p2p3/B2Pn3/5N2/PPP2PPP/RNBQ1RK1 w kq - 0 7"
    },
    {
      "move_number": 13,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a4b3",
      "move_san": "Bb3",
      "fen_after": "r1bqkb1r/2pp1ppp/p1n5/1p2p3/3Pn3/1B3N2/PPP2PPP/RNBQ1RK1 b kq - 1 7"
    },
    {
      "move_number": 14,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d7d5",
      "move_san": "d5",
      "fen_after": "r1bqkb1r/2p2ppp/p1n5/1p1pp3/3Pn3/1B3N2/PPP2PPP/RNBQ1RK1 w kq - 0 8"
    },
    {
      "move_number": 15,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d4e5",
      "move_san": "dxe5",
      "fen_after": "r1bqkb1r/2p2ppp/p1n5/1p1pP3/4n3/1B3N2/PPP2PPP/RNBQ1RK1 b kq - 0 8"
    },
    {
      "move_number": 16,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "c8e6",
      "move_san": "Be6",
      "fen_after": "r2qkb1r/2p2ppp/p1n1b3/1p1pP3/4n3/1B3N2/PPP2PPP/RNBQ1RK1 w kq - 1 9"
    },
    {
      "move_number": 17,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c2c3",
      "move_san": "c3",
      "fen_after": "r2qkb1r/2p2ppp/p1n1b3/1p1pP3/4n3/1BP2N2/PP3PPP/RNBQ1RK1 b kq - 0 9"
    },
    {
      "move_number": 18,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f8c5",
      "move_san": "Bc5",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/4n3/1BP2N2/PP3PPP/RNBQ1RK1 w kq - 1 10"
    },
    {
      "move_number": 19,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b1d2",
      "move_san": "Nbd2",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/4n3/1BP2N2/PP1N1PPP/R1BQ1RK1 b kq - 2 10"
    },
    {
      "move_number": 20,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e4f2",
      "move_san": "Nxf2",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/8/1BP2N2/PP1N1nPP/R1BQ1RK1 w kq - 0 11"
    },
    {
      "move_number": 21,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1f2",
      "move_san": "Rxf2",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/8/1BP2N2/PP1N1RPP/R1BQ2K1 b kq - 0 11"
    },
    {
      "move_number": 22,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "c5f2",
      "move_san": "Bxf2+",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1bPP/R1BQ2K1 w kq - 0 12"
    },
    {
      "move_number": 23,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1f2",
      "move_san": "Kxf2",
      "fen_after": "r2qk2r/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1KPP/R1BQ4 b kq - 0 12"
    },
    {
      "move_number": 24,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f7f6",
      "move_san": "f6",
      "fen_after": "r2qk2r/2p3pp/p1n1bp2/1p1pP3/8/1BP2N2/PP1N1KPP/R1BQ4 w kq - 0 13"
    },
    {
      "move_number": 25,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e5f6",
      "move_san": "exf6",
      "fen_after": "r2qk2r/2p3pp/p1n1bP2/1p1p4/8/1BP2N2/PP1N1KPP/R1BQ4 b kq - 0 13"
    },
    {
      "move_number": 26,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d8f6",
      "move_san": "Qxf6",
      "fen_after": "r3k2r/2p3pp/p1n1bq2/1p1p4/8/1BP2N2/PP1N1KPP/R1BQ4 w kq - 0 14"
    },
    {
      "move_number": 27,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2f1",
      "move_san": "Nf1",
      "fen_after": "r3k2r/2p3pp/p1n1bq2/1p1p4/8/1BP2N2/PP3KPP/R1BQ1N2 b kq - 1 14"
    },
    {
      "move_number": 28,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e8g8",
      "move_san": "O-O",
      "fen_after": "r4rk1/2p3pp/p1n1bq2/1p1p4/8/1BP2N2/PP3KPP/R1BQ1N2 w - - 2 15"
    },
    {
      "move_number": 29,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b3d5",
      "move_san": "Bxd5",
      "fen_after": "r4rk1/2p3pp/p1n1bq2/1p1B4/8/2P2N2/PP3KPP/R1BQ1N2 b - - 0 15"
    },
    {
      "move_number": 30,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "a8d8",
      "move_san": "Rad8",
      "fen_after": "3r1rk1/2p3pp/p1n1bq2/1p1B4/8/2P2N2/PP3KPP/R1BQ1N2 w - - 1 16"
    },
    {
      "move_number": 31,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c1g5",
      "move_san": "Bg5",
      "fen_after": "3r1rk1/2p3pp/p1n1bq2/1p1B2B1/8/2P2N2/PP3KPP/R2Q1N2 b - - 2 16"
    },
    {
      "move_number": 32,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f6f7",
      "move_san": "Qf7",
      "fen_after": "3r1rk1/2p2qpp/p1n1b3/1p1B2B1/8/2P2N2/PP3KPP/R2Q1N2 w - - 3 17"
    },
    {
      "move_number": 33,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d5e6",
      "move_san": "Bxe6",
      "fen_after": "3r1rk1/2p2qpp/p1n1B3/1p4B1/8/2P2N2/PP3KPP/R2Q1N2 b - - 0 17"
    },
    {
      "move_number": 34,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f7e6",
      "move_san": "Qxe6",
      "fen_after": "3r1rk1/2p3pp/p1n1q3/1p4B1/8/2P2N2/PP3KPP/R2Q1N2 w - - 0 18"
    },
    {
      "move_number": 35,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g5d8",
      "move_san": "Bxd8",
      "fen_after": "3B1rk1/2p3pp/p1n1q3/1p6/8/2P2N2/PP3KPP/R2Q1N2 b - - 0 18"
    },
    {
      "move_number": 36,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f8d8",
      "move_san": "Rxd8",
      "fen_after": "3r2k1/2p3pp/p1n1q3/1p6/8/2P2N2/PP3KPP/R2Q1N2 w - - 0 19"
    },
    {
      "move_number": 37,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1e2",
      "move_san": "Qe2",
      "fen_after": "3r2k1/2p3pp/p1n1q3/1p6/8/2P2N2/PP2QKPP/R4N2 b - - 1 19"
    },
    {
      "move_number": 38,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e6f7",
      "move_san": "Qf7",
      "fen_after": "3r2k1/2p2qpp/p1n5/1p6/8/2P2N2/PP2QKPP/R4N2 w - - 2 20"
    },
    {
      "move_number": 39,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f2g1",
      "move_san": "Kg1",
      "fen_after": "3r2k1/2p2qpp/p1n5/1p6/8/2P2N2/PP2Q1PP/R4NK1 b - - 3 20"
    },
    {
      "move_number": 40,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d8f8",
      "move_san": "Rf8",
      "fen_after": "5rk1/2p2qpp/p1n5/1p6/8/2P2N2/PP2Q1PP/R4NK1 w - - 4 21"
    },
    {
      "move_number": 41,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f3g5",
      "move_san": "Ng5",
      "fen_after": "5rk1/2p2qpp/p1n5/1p4N1/8/2P5/PP2Q1PP/R4NK1 b - - 5 21"
    },
    {
      "move_number": 42,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f7f5",
      "move_san": "Qf5",
      "fen_after": "5rk1/2p3pp/p1n5/1p3qN1/8/2P5/PP2Q1PP/R4NK1 w - - 6 22"
    },
    {
      "move_number": 43,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e6",
      "move_san": "Qe6+",
      "fen_after": "5rk1/2p3pp/p1n1Q3/1p3qN1/8/2P5/PP4PP/R4NK1 b - - 7 22"
    },
    {
      "move_number": 44,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f5e6",
      "move_san": "Qxe6",
      "fen_after": "5rk1/2p3pp/p1n1q3/1p4N1/8/2P5/PP4PP/R4NK1 w - - 0 23"
    },
    {
      "move_number": 45,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g5e6",
      "move_san": "Nxe6",
      "fen_after": "5rk1/2p3pp/p1n1N3/1p6/8/2P5/PP4PP/R4NK1 b - - 0 23"
    },
    {
      "move_number": 46,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f8f7",
      "move_san": "Rf7",
      "fen_after": "6k1/2p2rpp/p1n1N3/1p6/8/2P5/PP4PP/R4NK1 w - - 1 24"
    },
    {
      "move_number": 47,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a1d1",
      "move_san": "Rd1",
      "fen_after": "6k1/2p2rpp/p1n1N3/1p6/8/2P5/PP4PP/3R1NK1 b - - 2 24"
    },
    {
      "move_number": 48,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f7e7",
      "move_san": "Re7",
      "fen_after": "6k1/2p1r1pp/p1n1N3/1p6/8/2P5/PP4PP/3R1NK1 w - - 3 25"
    },
    {
      "move_number": 49,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e6d8",
      "move_san": "Nd8",
      "fen_after": "3N2k1/2p1r1pp/p1n5/1p6/8/2P5/PP4PP/3R1NK1 b - - 4 25"
    },
    {
      "move_number": 50,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "c6e5",
      "move_san": "Ne5",
      "fen_after": "3N2k1/2p1r1pp/p7/1p2n3/8/2P5/PP4PP/3R1NK1 w - - 5 26"
    },
    {
      "move_number": 51,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d8b7",
      "move_san": "Nb7",
      "fen_after": "6k1/1Np1r1pp/p7/1p2n3/8/2P5/PP4PP/3R1NK1 b - - 6 26"
    },
    {
      "move_number": 52,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e5c4",
      "move_san": "Nc4",
      "fen_after": "6k1/1Np1r1pp/p7/1p6/2n5/2P5/PP4PP/3R1NK1 w - - 7 27"
    },
    {
      "move_number": 53,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1d8",
      "move_san": "Rd8+",
      "fen_after": "3R2k1/1Np1r1pp/p7/1p6/2n5/2P5/PP4PP/5NK1 b - - 8 27"
    },
    {
      "move_number": 54,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "g8f7",
      "move_san": "Kf7",
      "fen_after": "3R4/1Np1rkpp/p7/1p6/2n5/2P5/PP4PP/5NK1 w - - 9 28"
    },
    {
      "move_number": 55,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b2b3",
      "move_san": "b3",
      "fen_after": "3R4/1Np1rkpp/p7/1p6/2n5/1PP5/P5PP/5NK1 b - - 0 28"
    },
    {
      "move_number": 56,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "c4b6",
      "move_san": "Nb6",
      "fen_after": "3R4/1Np1rkpp/pn6/1p6/8/1PP5/P5PP/5NK1 w - - 1 29"
    },
    {
      "move_number": 57,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b7c5",
      "move_san": "Nc5",
      "fen_after": "3R4/2p1rkpp/pn6/1pN5/8/1PP5/P5PP/5NK1 b - - 2 29"
    },
    {
      "move_number": 58,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e7e2",
      "move_san": "Re2",
      "fen_after": "3R4/2p2kpp/pn6/1pN5/8/1PP5/P3r1PP/5NK1 w - - 3 30"
    },
    {
      "move_number": 59,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c5a6",
      "move_san": "Nxa6",
      "fen_after": "3R4/2p2kpp/Nn6/1p6/8/1PP5/P3r1PP/5NK1 b - - 0 30"
    },
    {
      "move_number": 60,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "e2a2",
      "move_san": "Rxa2",
      "fen_after": "3R4/2p2kpp/Nn6/1p6/8/1PP5/r5PP/5NK1 w - - 0 31"
    },
    {
      "move_number": 61,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a6c7",
      "move_san": "Nxc7",
      "fen_after": "3R4/2N2kpp/1n6/1p6/8/1PP5/r5PP/5NK1 b - - 0 31"
    },
    {
      "move_number": 62,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "a2a3",
      "move_san": "Ra3",
      "fen_after": "3R4/2N2kpp/1n6/1p6/8/rPP5/6PP/5NK1 w - - 1 32"
    },
    {
      "move_number": 63,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c7b5",
      "move_san": "Nxb5",
      "fen_after": "3R4/5kpp/1n6/1N6/8/rPP5/6PP/5NK1 b - - 0 32"
    },
    {
      "move_number": 64,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "a3b3",
      "move_san": "Rxb3",
      "fen_after": "3R4/5kpp/1n6/1N6/8/1rP5/6PP/5NK1 w - - 0 33"
    },
    {
      "move_number": 65,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b5d4",
      "move_san": "Nd4",
      "fen_after": "3R4/5kpp/1n6/8/3N4/1rP5/6PP/5NK1 b - - 1 33"
    },
    {
      "move_number": 66,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "b3b2",
      "move_san": "Rb2",
      "fen_after": "3R4/5kpp/1n6/8/3N4/2P5/1r4PP/5NK1 w - - 2 34"
    },
    {
      "move_number": 67,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d8b8",
      "move_san": "Rb8",
      "fen_after": "1R6/5kpp/1n6/8/3N4/2P5/1r4PP/5NK1 b - - 3 34"
    },
    {
      "move_number": 68,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f7g6",
      "move_san": "Kg6",
      "fen_after": "1R6/6pp/1n4k1/8/3N4/2P5/1r4PP/5NK1 w - - 4 35"
    },
    {
      "move_number": 69,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c3c4",
      "move_san": "c4",
      "fen_after": "1R6/6pp/1n4k1/8/2PN4/8/1r4PP/5NK1 b - - 0 35"
    },
    {
      "move_number": 70,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "b6c4",
      "move_san": "Nxc4",
      "fen_after": "1R6/6pp/6k1/8/2nN4/8/1r4PP/5NK1 w - - 0 36"
    },
    {
      "move_number": 71,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b8b2",
      "move_san": "Rxb2",
      "fen_after": "8/6pp/6k1/8/2nN4/8/1R4PP/5NK1 b - - 0 36"
    },
    {
      "move_number": 72,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "c4b2",
      "move_san": "Nxb2",
      "fen_after": "8/6pp/6k1/8/3N4/8/1n4PP/5NK1 w - - 0 37"
    },
    {
      "move_number": 73,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1e3",
      "move_san": "Ne3",
      "fen_after": "8/6pp/6k1/8/3N4/4N3/1n4PP/6K1 b - - 1 37"
    },
    {
      "move_number": 74,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "b2d3",
      "move_san": "Nd3",
      "fen_after": "8/6pp/6k1/8/3N4/3nN3/6PP/6K1 w - - 2 38"
    },
    {
      "move_number": 75,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d4f3",
      "move_san": "Nf3",
      "fen_after": "8/6pp/6k1/8/8/3nNN2/6PP/6K1 b - - 3 38"
    },
    {
      "move_number": 76,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "d3f4",
      "move_san": "Nf4",
      "fen_after": "8/6pp/6k1/8/5n2/4NN2/6PP/6K1 w - - 4 39"
    },
    {
      "move_number": 77,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f3e5",
      "move_san": "Ne5+",
      "fen_after": "8/6pp/6k1/4N3/5n2/4N3/6PP/6K1 b - - 5 39"
    },
    {
      "move_number": 78,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "g6f6",
      "move_san": "Kf6",
      "fen_after": "8/6pp/5k2/4N3/5n2/4N3/6PP/6K1 w - - 6 40"
    },
    {
      "move_number": 79,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e5d7",
      "move_san": "Nd7+",
      "fen_after": "8/3N2pp/5k2/8/5n2/4N3/6PP/6K1 b - - 7 40"
    },
    {
      "move_number": 80,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f6g6",
      "move_san": "Kg6",
      "fen_after": "8/3N2pp/6k1/8/5n2/4N3/6PP/6K1 w - - 8 41"
    },
    {
      "move_number": 81,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g2g3",
      "move_san": "g3",
      "fen_after": "8/3N2pp/6k1/8/5n2/4N1P1/7P/6K1 b - - 0 41"
    },
    {
      "move_number": 82,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "f4e6",
      "move_san": "Ne6",
      "fen_after": "8/3N2pp/4n1k1/8/8/4N1P1/7P/6K1 w - - 1 42"
    },
    {
      "move_number": 83,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d7e5",
      "move_san": "Ne5+",
      "fen_after": "8/6pp/4n1k1/4N3/8/4N1P1/7P/6K1 b - - 2 42"
    },
    {
      "move_number": 84,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "g6g5",
      "move_san": "Kg5",
      "fen_after": "8/6pp/4n3/4N1k1/8/4N1P1/7P/6K1 w - - 3 43"
    },
    {
      "move_number": 85,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h2h4",
      "move_san": "h4+",
      "fen_after": "8/6pp/4n3/4N1k1/7P/4N1P1/8/6K1 b - - 0 43"
    },
    {
      "move_number": 86,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "g5h5",
      "move_san": "Kh5",
      "fen_after": "8/6pp/4n3/4N2k/7P/4N1P1/8/6K1 w - - 1 44"
    },
    {
      "move_number": 87,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e3f5",
      "move_san": "Nf5",
      "fen_after": "8/6pp/4n3/4NN1k/7P/6P1/8/6K1 b - - 2 44"
    },
    {
      "move_number": 88,
      "player": "gpt-3.5-turbo-instruct_SC",
      "color": "black",
      "move_uci": "g7g5",
      "move_san": "g5",
      "fen_after": "8/7p/4n3/4NNpk/7P/6P1/8/6K1 w - - 0 45"
    },
    {
      "move_number": 89,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g3g4",
      "move_san": "g4#",
      "fen_after": "8/7p/4n3/4NNpk/6PP/8/8/6K1 b - - 0 45"
    }
  ],
  "final_fen": "8/7p/4n3/4NNpk/6PP/8/8/6K1 b - - 0 45",
  "white_tokens": {
    "prompt_tokens": 12876,
    "completion_tokens": 8722,
    "total_tokens": 21598
  },
  "black_tokens": {
    "prompt_tokens": 38851,
    "completion_tokens": 58649,
    "total_tokens": 97500
  },
  "white_token_log": [
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 103,
        "completion_tokens": 572,
        "total_tokens": 675,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 109,
        "completion_tokens": 468,
        "total_tokens": 577,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 118,
        "completion_tokens": 500,
        "total_tokens": 618,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 126,
        "completion_tokens": 249,
        "total_tokens": 375,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 134,
        "completion_tokens": 616,
        "total_tokens": 750,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 142,
        "completion_tokens": 198,
        "total_tokens": 340,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 149,
        "completion_tokens": 336,
        "total_tokens": 485,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 157,
        "completion_tokens": 183,
        "total_tokens": 340,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 166,
        "completion_tokens": 490,
        "total_tokens": 656,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 174,
        "completion_tokens": 345,
        "total_tokens": 519,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 183,
        "completion_tokens": 130,
        "total_tokens": 313,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 193,
        "completion_tokens": 275,
        "total_tokens": 468,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 201,
        "completion_tokens": 107,
        "total_tokens": 308,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 210,
        "completion_tokens": 482,
        "total_tokens": 692,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 219,
        "completion_tokens": 416,
        "total_tokens": 635,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 227,
        "completion_tokens": 640,
        "total_tokens": 867,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "length"
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 236,
        "completion_tokens": 640,
        "total_tokens": 876,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "length"
      }
    },
    {
      "turn": 35,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 245,
        "completion_tokens": 90,
        "total_tokens": 335,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 37,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 254,
        "completion_tokens": 394,
        "total_tokens": 648,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 39,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 263,
        "completion_tokens": 7,
        "total_tokens": 270,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 41,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 272,
        "completion_tokens": 126,
        "total_tokens": 398,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 43,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 280,
        "completion_tokens": 341,
        "total_tokens": 621,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 45,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 290,
        "completion_tokens": 9,
        "total_tokens": 299,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 47,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 299,
        "completion_tokens": 7,
        "total_tokens": 306,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 49,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 306,
        "completion_tokens": 5,
        "total_tokens": 311,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 51,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 313,
        "completion_tokens": 5,
        "total_tokens": 318,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 53,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 322,
        "completion_tokens": 15,
        "total_tokens": 337,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 55,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 330,
        "completion_tokens": 302,
        "total_tokens": 632,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 57,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 337,
        "completion_tokens": 8,
        "total_tokens": 345,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 59,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 345,
        "completion_tokens": 9,
        "total_tokens": 354,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 61,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 354,
        "completion_tokens": 6,
        "total_tokens": 360,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 63,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 362,
        "completion_tokens": 9,
        "total_tokens": 371,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 65,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 371,
        "completion_tokens": 153,
        "total_tokens": 524,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 67,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 379,
        "completion_tokens": 179,
        "total_tokens": 558,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 69,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 387,
        "completion_tokens": 17,
        "total_tokens": 404,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 71,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 395,
        "completion_tokens": 326,
        "total_tokens": 721,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 73,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 404,
        "completion_tokens": 7,
        "total_tokens": 411,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 75,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 411,
        "completion_tokens": 8,
        "total_tokens": 419,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 77,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 420,
        "completion_tokens": 8,
        "total_tokens": 428,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 79,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 429,
        "completion_tokens": 8,
        "total_tokens": 437,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 81,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 437,
        "completion_tokens": 7,
        "total_tokens": 444,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 83,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 444,
        "completion_tokens": 6,
        "total_tokens": 450,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 85,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 452,
        "completion_tokens": 8,
        "total_tokens": 460,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 87,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 460,
        "completion_tokens": 9,
        "total_tokens": 469,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    },
    {
      "turn": 89,
      "attempt": 1,
      "tokens": {
        "prompt_tokens": 468,
        "completion_tokens": 6,
        "total_tokens": 474,
        "model": "gpt-3.5-turbo-instruct",
        "finish_reason": "stop"
      }
    }
  ],
  "black_token_log": [
    {
      "turn": 2,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 516,
          "total_tokens": 629,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 341,
        "total_completion_tokens": 1796,
        "total_tokens": 2137
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 114,
          "completion_tokens": 640,
          "total_tokens": 754,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 113,
          "completion_tokens": 516,
          "total_tokens": 629,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 4,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 197,
          "total_tokens": 319,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 304,
          "total_tokens": 426,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 445,
          "total_tokens": 566,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 365,
        "total_completion_tokens": 946,
        "total_tokens": 1311
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 122,
          "completion_tokens": 197,
          "total_tokens": 319,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 122,
          "completion_tokens": 304,
          "total_tokens": 426,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 121,
          "completion_tokens": 445,
          "total_tokens": 566,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 6,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 392,
        "total_completion_tokens": 1920,
        "total_tokens": 2312
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 131,
          "completion_tokens": 640,
          "total_tokens": 771,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 130,
          "completion_tokens": 640,
          "total_tokens": 770,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 8,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 138,
          "completion_tokens": 593,
          "total_tokens": 731,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 138,
          "completion_tokens": 535,
          "total_tokens": 673,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 137,
          "completion_tokens": 358,
          "total_tokens": 495,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 413,
        "total_completion_tokens": 1486,
        "total_tokens": 1899
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 138,
          "completion_tokens": 593,
          "total_tokens": 731,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 138,
          "completion_tokens": 535,
          "total_tokens": 673,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 137,
          "completion_tokens": 358,
          "total_tokens": 495,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 10,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 146,
          "completion_tokens": 640,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 146,
          "completion_tokens": 204,
          "total_tokens": 350,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 145,
          "completion_tokens": 640,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 437,
        "total_completion_tokens": 1484,
        "total_tokens": 1921
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 146,
          "completion_tokens": 640,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 146,
          "completion_tokens": 204,
          "total_tokens": 350,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 145,
          "completion_tokens": 640,
          "total_tokens": 785,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 12,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 464,
          "total_tokens": 618,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 349,
          "total_tokens": 502,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 461,
        "total_completion_tokens": 1453,
        "total_tokens": 1914
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 154,
          "completion_tokens": 464,
          "total_tokens": 618,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 154,
          "completion_tokens": 640,
          "total_tokens": 794,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 153,
          "completion_tokens": 349,
          "total_tokens": 502,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 14,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 162,
          "completion_tokens": 186,
          "total_tokens": 348,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 162,
          "completion_tokens": 335,
          "total_tokens": 497,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 161,
          "completion_tokens": 454,
          "total_tokens": 615,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 485,
        "total_completion_tokens": 975,
        "total_tokens": 1460
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 162,
          "completion_tokens": 186,
          "total_tokens": 348,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 162,
          "completion_tokens": 335,
          "total_tokens": 497,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 161,
          "completion_tokens": 454,
          "total_tokens": 615,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 16,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 569,
          "total_tokens": 740,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 337,
          "total_tokens": 508,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 227,
          "total_tokens": 397,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 512,
        "total_completion_tokens": 1133,
        "total_tokens": 1645
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 171,
          "completion_tokens": 569,
          "total_tokens": 740,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 171,
          "completion_tokens": 337,
          "total_tokens": 508,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 170,
          "completion_tokens": 227,
          "total_tokens": 397,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 18,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 351,
          "total_tokens": 529,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 533,
        "total_completion_tokens": 1631,
        "total_tokens": 2164
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 178,
          "completion_tokens": 351,
          "total_tokens": 529,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 177,
          "completion_tokens": 640,
          "total_tokens": 817,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 20,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 408,
          "total_tokens": 595,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 262,
          "total_tokens": 449,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 477,
          "total_tokens": 663,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 560,
        "total_completion_tokens": 1147,
        "total_tokens": 1707
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 187,
          "completion_tokens": 408,
          "total_tokens": 595,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 187,
          "completion_tokens": 262,
          "total_tokens": 449,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 186,
          "completion_tokens": 477,
          "total_tokens": 663,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 22,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 114,
          "total_tokens": 310,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 347,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 587,
        "total_completion_tokens": 1101,
        "total_tokens": 1688
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 196,
          "completion_tokens": 640,
          "total_tokens": 836,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 196,
          "completion_tokens": 114,
          "total_tokens": 310,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 195,
          "completion_tokens": 347,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 24,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 409,
          "total_tokens": 614,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 617,
        "total_completion_tokens": 1689,
        "total_tokens": 2306
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 409,
          "total_tokens": 614,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 26,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 214,
          "completion_tokens": 640,
          "total_tokens": 854,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 214,
          "completion_tokens": 50,
          "total_tokens": 264,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 213,
          "completion_tokens": 330,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 641,
        "total_completion_tokens": 1020,
        "total_tokens": 1661
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 214,
          "completion_tokens": 640,
          "total_tokens": 854,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 214,
          "completion_tokens": 50,
          "total_tokens": 264,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 213,
          "completion_tokens": 330,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 28,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 223,
          "completion_tokens": 349,
          "total_tokens": 572,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 223,
          "completion_tokens": 367,
          "total_tokens": 590,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 668,
        "total_completion_tokens": 1356,
        "total_tokens": 2024
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 223,
          "completion_tokens": 349,
          "total_tokens": 572,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 223,
          "completion_tokens": 367,
          "total_tokens": 590,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 222,
          "completion_tokens": 640,
          "total_tokens": 862,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 30,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 232,
          "completion_tokens": 577,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 232,
          "completion_tokens": 227,
          "total_tokens": 459,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 231,
          "completion_tokens": 486,
          "total_tokens": 717,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 695,
        "total_completion_tokens": 1290,
        "total_tokens": 1985
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 232,
          "completion_tokens": 577,
          "total_tokens": 809,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 232,
          "completion_tokens": 227,
          "total_tokens": 459,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 231,
          "completion_tokens": 486,
          "total_tokens": 717,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 32,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 240,
          "completion_tokens": 320,
          "total_tokens": 560,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 239,
          "completion_tokens": 640,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 719,
        "total_completion_tokens": 1600,
        "total_tokens": 2319
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 240,
          "completion_tokens": 320,
          "total_tokens": 560,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 239,
          "completion_tokens": 640,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 34,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 249,
          "completion_tokens": 306,
          "total_tokens": 555,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 249,
          "completion_tokens": 156,
          "total_tokens": 405,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 248,
          "completion_tokens": 160,
          "total_tokens": 408,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 746,
        "total_completion_tokens": 622,
        "total_tokens": 1368
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 249,
          "completion_tokens": 306,
          "total_tokens": 555,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 249,
          "completion_tokens": 156,
          "total_tokens": 405,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 248,
          "completion_tokens": 160,
          "total_tokens": 408,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 36,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 258,
          "completion_tokens": 549,
          "total_tokens": 807,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 258,
          "completion_tokens": 328,
          "total_tokens": 586,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 257,
          "completion_tokens": 640,
          "total_tokens": 897,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 773,
        "total_completion_tokens": 1517,
        "total_tokens": 2290
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 258,
          "completion_tokens": 549,
          "total_tokens": 807,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 258,
          "completion_tokens": 328,
          "total_tokens": 586,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 257,
          "completion_tokens": 640,
          "total_tokens": 897,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 38,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 267,
          "completion_tokens": 396,
          "total_tokens": 663,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 267,
          "completion_tokens": 562,
          "total_tokens": 829,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 266,
          "completion_tokens": 475,
          "total_tokens": 741,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 800,
        "total_completion_tokens": 1433,
        "total_tokens": 2233
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 267,
          "completion_tokens": 396,
          "total_tokens": 663,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 267,
          "completion_tokens": 562,
          "total_tokens": 829,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 266,
          "completion_tokens": 475,
          "total_tokens": 741,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 40,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 275,
          "completion_tokens": 640,
          "total_tokens": 915,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 275,
          "completion_tokens": 332,
          "total_tokens": 607,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 274,
          "completion_tokens": 322,
          "total_tokens": 596,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 824,
        "total_completion_tokens": 1294,
        "total_tokens": 2118
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 275,
          "completion_tokens": 640,
          "total_tokens": 915,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 275,
          "completion_tokens": 332,
          "total_tokens": 607,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 274,
          "completion_tokens": 322,
          "total_tokens": 596,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 42,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 284,
          "completion_tokens": 333,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 284,
          "completion_tokens": 289,
          "total_tokens": 573,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 283,
          "completion_tokens": 312,
          "total_tokens": 595,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 851,
        "total_completion_tokens": 934,
        "total_tokens": 1785
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 284,
          "completion_tokens": 333,
          "total_tokens": 617,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 284,
          "completion_tokens": 289,
          "total_tokens": 573,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 283,
          "completion_tokens": 312,
          "total_tokens": 595,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 44,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 294,
          "completion_tokens": 447,
          "total_tokens": 741,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 294,
          "completion_tokens": 595,
          "total_tokens": 889,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 293,
          "completion_tokens": 458,
          "total_tokens": 751,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 881,
        "total_completion_tokens": 1500,
        "total_tokens": 2381
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 294,
          "completion_tokens": 447,
          "total_tokens": 741,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 294,
          "completion_tokens": 595,
          "total_tokens": 889,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 293,
          "completion_tokens": 458,
          "total_tokens": 751,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 46,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 303,
          "completion_tokens": 351,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 303,
          "completion_tokens": 640,
          "total_tokens": 943,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 302,
          "completion_tokens": 640,
          "total_tokens": 942,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 908,
        "total_completion_tokens": 1631,
        "total_tokens": 2539
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 303,
          "completion_tokens": 351,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 303,
          "completion_tokens": 640,
          "total_tokens": 943,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 302,
          "completion_tokens": 640,
          "total_tokens": 942,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 48,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 311,
          "completion_tokens": 221,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 311,
          "completion_tokens": 214,
          "total_tokens": 525,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 310,
          "completion_tokens": 214,
          "total_tokens": 524,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 932,
        "total_completion_tokens": 649,
        "total_tokens": 1581
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 311,
          "completion_tokens": 221,
          "total_tokens": 532,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 311,
          "completion_tokens": 214,
          "total_tokens": 525,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 310,
          "completion_tokens": 214,
          "total_tokens": 524,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 50,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 318,
          "completion_tokens": 386,
          "total_tokens": 704,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 318,
          "completion_tokens": 640,
          "total_tokens": 958,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 317,
          "completion_tokens": 640,
          "total_tokens": 957,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 953,
        "total_completion_tokens": 1666,
        "total_tokens": 2619
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 318,
          "completion_tokens": 386,
          "total_tokens": 704,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 318,
          "completion_tokens": 640,
          "total_tokens": 958,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 317,
          "completion_tokens": 640,
          "total_tokens": 957,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 52,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 325,
          "completion_tokens": 505,
          "total_tokens": 830,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 325,
          "completion_tokens": 201,
          "total_tokens": 526,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 324,
          "completion_tokens": 324,
          "total_tokens": 648,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 974,
        "total_completion_tokens": 1030,
        "total_tokens": 2004
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 325,
          "completion_tokens": 505,
          "total_tokens": 830,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 325,
          "completion_tokens": 201,
          "total_tokens": 526,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 324,
          "completion_tokens": 324,
          "total_tokens": 648,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 54,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 334,
          "completion_tokens": 640,
          "total_tokens": 974,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 334,
          "completion_tokens": 640,
          "total_tokens": 974,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 333,
          "completion_tokens": 640,
          "total_tokens": 973,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1001,
        "total_completion_tokens": 1920,
        "total_tokens": 2921
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 334,
          "completion_tokens": 640,
          "total_tokens": 974,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 334,
          "completion_tokens": 640,
          "total_tokens": 974,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 333,
          "completion_tokens": 640,
          "total_tokens": 973,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 56,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 342,
          "completion_tokens": 217,
          "total_tokens": 559,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 342,
          "completion_tokens": 295,
          "total_tokens": 637,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 341,
          "completion_tokens": 342,
          "total_tokens": 683,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1025,
        "total_completion_tokens": 854,
        "total_tokens": 1879
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 342,
          "completion_tokens": 217,
          "total_tokens": 559,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 342,
          "completion_tokens": 295,
          "total_tokens": 637,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 341,
          "completion_tokens": 342,
          "total_tokens": 683,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 58,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 350,
          "completion_tokens": 640,
          "total_tokens": 990,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 350,
          "completion_tokens": 271,
          "total_tokens": 621,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 349,
          "completion_tokens": 640,
          "total_tokens": 989,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1049,
        "total_completion_tokens": 1551,
        "total_tokens": 2600
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 350,
          "completion_tokens": 640,
          "total_tokens": 990,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 350,
          "completion_tokens": 271,
          "total_tokens": 621,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 349,
          "completion_tokens": 640,
          "total_tokens": 989,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 60,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 358,
          "completion_tokens": 339,
          "total_tokens": 697,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 358,
          "completion_tokens": 585,
          "total_tokens": 943,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 357,
          "completion_tokens": 585,
          "total_tokens": 942,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1073,
        "total_completion_tokens": 1509,
        "total_tokens": 2582
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 358,
          "completion_tokens": 339,
          "total_tokens": 697,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 358,
          "completion_tokens": 585,
          "total_tokens": 943,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 357,
          "completion_tokens": 585,
          "total_tokens": 942,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 62,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 367,
          "completion_tokens": 511,
          "total_tokens": 878,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 367,
          "completion_tokens": 405,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 366,
          "completion_tokens": 640,
          "total_tokens": 1006,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1100,
        "total_completion_tokens": 1556,
        "total_tokens": 2656
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 367,
          "completion_tokens": 511,
          "total_tokens": 878,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 367,
          "completion_tokens": 405,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 366,
          "completion_tokens": 640,
          "total_tokens": 1006,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 64,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 375,
          "completion_tokens": 277,
          "total_tokens": 652,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 375,
          "completion_tokens": 339,
          "total_tokens": 714,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 374,
          "completion_tokens": 640,
          "total_tokens": 1014,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1124,
        "total_completion_tokens": 1256,
        "total_tokens": 2380
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 375,
          "completion_tokens": 277,
          "total_tokens": 652,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 375,
          "completion_tokens": 339,
          "total_tokens": 714,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 374,
          "completion_tokens": 640,
          "total_tokens": 1014,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 66,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 383,
          "completion_tokens": 284,
          "total_tokens": 667,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 383,
          "completion_tokens": 640,
          "total_tokens": 1023,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 382,
          "completion_tokens": 444,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1148,
        "total_completion_tokens": 1368,
        "total_tokens": 2516
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 383,
          "completion_tokens": 284,
          "total_tokens": 667,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 383,
          "completion_tokens": 640,
          "total_tokens": 1023,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 382,
          "completion_tokens": 444,
          "total_tokens": 826,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 68,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 392,
          "completion_tokens": 439,
          "total_tokens": 831,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 392,
          "completion_tokens": 163,
          "total_tokens": 555,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 391,
          "completion_tokens": 556,
          "total_tokens": 947,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1175,
        "total_completion_tokens": 1158,
        "total_tokens": 2333
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 392,
          "completion_tokens": 439,
          "total_tokens": 831,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 392,
          "completion_tokens": 163,
          "total_tokens": 555,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 391,
          "completion_tokens": 556,
          "total_tokens": 947,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 70,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 399,
          "completion_tokens": 481,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 399,
          "completion_tokens": 567,
          "total_tokens": 966,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 398,
          "completion_tokens": 504,
          "total_tokens": 902,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1196,
        "total_completion_tokens": 1552,
        "total_tokens": 2748
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 399,
          "completion_tokens": 481,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 399,
          "completion_tokens": 567,
          "total_tokens": 966,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 398,
          "completion_tokens": 504,
          "total_tokens": 902,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 72,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 408,
          "completion_tokens": 640,
          "total_tokens": 1048,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 408,
          "completion_tokens": 367,
          "total_tokens": 775,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 407,
          "completion_tokens": 482,
          "total_tokens": 889,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1223,
        "total_completion_tokens": 1489,
        "total_tokens": 2712
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 408,
          "completion_tokens": 640,
          "total_tokens": 1048,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 408,
          "completion_tokens": 367,
          "total_tokens": 775,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 407,
          "completion_tokens": 482,
          "total_tokens": 889,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 74,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 416,
          "completion_tokens": 612,
          "total_tokens": 1028,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 416,
          "completion_tokens": 167,
          "total_tokens": 583,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 415,
          "completion_tokens": 640,
          "total_tokens": 1055,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1247,
        "total_completion_tokens": 1419,
        "total_tokens": 2666
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 416,
          "completion_tokens": 612,
          "total_tokens": 1028,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 416,
          "completion_tokens": 167,
          "total_tokens": 583,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 415,
          "completion_tokens": 640,
          "total_tokens": 1055,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 76,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 424,
          "completion_tokens": 429,
          "total_tokens": 853,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 424,
          "completion_tokens": 534,
          "total_tokens": 958,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 423,
          "completion_tokens": 445,
          "total_tokens": 868,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1271,
        "total_completion_tokens": 1408,
        "total_tokens": 2679
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 424,
          "completion_tokens": 429,
          "total_tokens": 853,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 424,
          "completion_tokens": 534,
          "total_tokens": 958,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 423,
          "completion_tokens": 445,
          "total_tokens": 868,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 78,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 433,
          "completion_tokens": 273,
          "total_tokens": 706,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 433,
          "completion_tokens": 113,
          "total_tokens": 546,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 432,
          "completion_tokens": 102,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1298,
        "total_completion_tokens": 488,
        "total_tokens": 1786
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 433,
          "completion_tokens": 273,
          "total_tokens": 706,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 433,
          "completion_tokens": 113,
          "total_tokens": 546,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 432,
          "completion_tokens": 102,
          "total_tokens": 534,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 80,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 442,
          "completion_tokens": 618,
          "total_tokens": 1060,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 442,
          "completion_tokens": 21,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 441,
          "completion_tokens": 640,
          "total_tokens": 1081,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1325,
        "total_completion_tokens": 1279,
        "total_tokens": 2604
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 442,
          "completion_tokens": 618,
          "total_tokens": 1060,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 442,
          "completion_tokens": 21,
          "total_tokens": 463,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 441,
          "completion_tokens": 640,
          "total_tokens": 1081,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 82,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 449,
          "completion_tokens": 640,
          "total_tokens": 1089,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 449,
          "completion_tokens": 269,
          "total_tokens": 718,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 448,
          "completion_tokens": 327,
          "total_tokens": 775,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1346,
        "total_completion_tokens": 1236,
        "total_tokens": 2582
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 449,
          "completion_tokens": 640,
          "total_tokens": 1089,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 449,
          "completion_tokens": 269,
          "total_tokens": 718,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 448,
          "completion_tokens": 327,
          "total_tokens": 775,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 84,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 457,
          "completion_tokens": 640,
          "total_tokens": 1097,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 457,
          "completion_tokens": 176,
          "total_tokens": 633,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 456,
          "completion_tokens": 640,
          "total_tokens": 1096,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1370,
        "total_completion_tokens": 1456,
        "total_tokens": 2826
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 457,
          "completion_tokens": 640,
          "total_tokens": 1097,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 457,
          "completion_tokens": 176,
          "total_tokens": 633,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 456,
          "completion_tokens": 640,
          "total_tokens": 1096,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 86,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 465,
          "completion_tokens": 640,
          "total_tokens": 1105,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 465,
          "completion_tokens": 464,
          "total_tokens": 929,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 464,
          "completion_tokens": 452,
          "total_tokens": 916,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1394,
        "total_completion_tokens": 1556,
        "total_tokens": 2950
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 465,
          "completion_tokens": 640,
          "total_tokens": 1105,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 465,
          "completion_tokens": 464,
          "total_tokens": 929,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 464,
          "completion_tokens": 452,
          "total_tokens": 916,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 88,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 473,
          "completion_tokens": 640,
          "total_tokens": 1113,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 473,
          "completion_tokens": 11,
          "total_tokens": 484,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 472,
          "completion_tokens": 640,
          "total_tokens": 1112,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1418,
        "total_completion_tokens": 1291,
        "total_tokens": 2709
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 473,
          "completion_tokens": 640,
          "total_tokens": 1113,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 473,
          "completion_tokens": 11,
          "total_tokens": 484,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 472,
          "completion_tokens": 640,
          "total_tokens": 1112,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    }
  ],
  "white_responses": [
    {
      "turn": 1,
      "attempt": 1,
      "raw_response": "1. e4 e5\n2. Nf3 Nc6\n3. Bb5 Nf6\n4. O-O Nxe4\n5. d4 Nd6\n6. Bxc6 dxc6\n7. dxe5 Nf5\n8. Qxd8+ Kxd8\n9. Nc3 Bd7\n10. Rd1 Kc8\n11. Ng5 Be8\n12. Rd3 h6\n13. Nge4 b6\n14. g4 Ne7\n15. f4 Kb7\n16. f5 c5\n17. Bf4 Bc6\n18. Rad1 Re8\n19. Rd8 Rxd8\n20. Rxd8 Nc8\n21. e6 fxe6\n22. fxe6 g5\n23. Be5 Bg7\n24. Rxh8 Bxh8\n25. Bxh8 Bxe4\n26. Nxe4 Kc6\n27. Bg7 Kd5\n28. Nc3+ Kxe6\n29. Bxh6 Kf6\n30. Ne4+ Kg6\n31. Bxg5 Nd6\n32. Nxd6 cxd6\n33. Bf4 d5\n34. h4 d4\n35. h5+ Kf6\n36. g5+ Kf5\n37. g6 Kf6\n38. Be5+ Kxe5\n39. g7 Ke4\n40. g8=Q Ke3\n41. Qg2 c4\n42. h6 d3\n43. cxd3 cxd3\n44. h7 d2\n45. Qg5+ Ke2\n46. Qe5+ Kd3\n47. Qd5+ Ke2\n48. Qe4+ Kd1\n49. h8=Q Kc1\n50. Qc3+ Kd1\n51. Qef3+ Ke1\n52. Qf1#\n53. Qe3+ Kd1\n54. Qb1# d1=Q\n55. Qxd1# Kxd1\n56. Qd3+ Kc1\n57. Qc3+ Kb1\n58. Qxd2 Kxa2\n59. b4+ Kb3\n60. b5 Ka4\n61. Qd5 Ka5\n62. Kf2 a6\n63. bxa6+ Kxa6\n64. Ke3 b5\n65. Kd4 Ka5\n66. Kc5 Ka4\n67. Qa2#\n\nBc8",
      "predicted_san": "e4",
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "raw_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Bb7\n10. d4 Re8 11. Nbd2 Bf8 12. a4 h6\n13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5\n16. d5 Nd7 17. Ra3 c4 18. Nd4 Qf6\n19. N2f3 Nc5 20. axb5 Nbd3 21. Bxd3 Nxd3\n22. Rxd3 cxd3 23. Qxd3 axb5 24. Nxb5 Ba6\n25. Nfd4 Reb8 26. Qb3 Bxb5 27. Nxb5 Ra5\n28. Qc3 Raxb5 29. Qxf6 gxf6 30. Re2 f5\n31. f3 Bg7 32. Bf4 Rxb2 33. Rxb2 Rxb2\n34. Bxd6 fxe4 35. fxe4 Re2 36. Bc5 Rxe4\n37. Kf2 Bd4+ 38. Bxd4 Rxd4 39. Ke3 Rxd5\n40. Ke4 Rd2 41. Kf3 Kg7 42. g4 Kg6\n43. h4 h5 44. gxh5+ Kxh5 45. Kg3 Rd4\n46. Kh3 Rxh4+ 47. Kg3 Kg5 48. Kf3 f5\n49. Kg3 f4+ 50. Kf3 Kf5 51. Kg2 Kg4\n52. Kf2 Rh2+ 53. Kg1 Kg3 54. Kf1 f3\n55. Kg1 Ra2 56. Kf1 Ra1# 0-1\n57. Ke2 f2",
      "predicted_san": "Nf3",
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "raw_response": "3. Bb5 Nf6 4. O-O Nxe4 5. d4 Nd6 6. Bxc6 dxc6 7. dxe5 Nf5 8. Qxd8+ Kxd8 9. Nc3 Ke8 10. h3 h5 11. Bf4 Be7 12. Rad1 Be6 13. Ng5 Rh6 14. Nxe6 Rxe6 15. g4 hxg4 16. hxg4 Nh4 17. Bg3 Nf3+ 18. Kg2 Nxe5 19. Rfe1 Bd6 20. Ne4 Rd8 21. Nxd6+ cxd6 22. f4 Nxg4 23. Rxe6+ fxe6 24. Kf3 Nf6 25. Bh4 Kf7 26. c4 d5 27. cxd5 exd5 28. Bf2 b6 29. b4 Ne4 30. Bd4 c5 31. bxc5 bxc5 32. Be5 Nf6 33. Rb1 Rd7 34. Rb5 c4 35. Rc5 Ne4 36. Rc6 Nd2+ 37. Ke3 Nf1+ 38. Kf2 Nd2 39. Ke3 Ne4 40. Kd4 Nf6 41. a4 Rb7 42. a5 Rb5 43. Rc7+ Kg6 44. Rxa7 Rb3 45. a6 Rd3+ 46. Kc5 c3 47. Rc7 c2 48. Kb4 Rd2 49. a7 Ne8 50. Rc6+ Kf5 51. a8=Q c1=Q 52. Rxc1 Rb2+ 53. Bxb2 Nd6 54. Qxd5+ Kg4 55. Qxd6 Kf3 56. Qg6 Ke3 57. Qxg7 Kd2 58. Qc3+ Ke2 59. Re1+ Kf2 60. Qe3+ Kg2 61. Rg1+ Kh2 62. Qg3# d4",
      "predicted_san": "Bb5",
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "raw_response": "4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Rxf1+ 29. Qxf1 Bf3+ 30. Qg2 Bxg2+ 31. Kg1 Bxa8+ 32. Kf1 Qd1#",
      "predicted_san": "Ba4",
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "raw_response": "5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. d5 Ne7 25. Nh4 Rac8 26. Bg5 Kh8 27. Bxf6 gxf6 28. Qh5 Ng6 29. Nhf5 Qb6 30. Qh6 Rg8 31. Nh5 Qd8 32. Nxd6 Qe7 33. Nxc8 Bxc8 34. Rc1 Bd7 35. Rc7 Nf8 36. Nxf6 Rg6 37. Qxf8+ Qxf8 38. Nxd7 Qd6 39. Rc8+ Kg7 40. Nc5 Qf6 41. Bd3 Qf3 42. Bf1 Qxh3 43. Rc7 Qh4 44. Ne6+ Kh6 45. Nf8 Rf6 46. g3 Qxe4 47. Rc6 Rxc6 48. dxc6 Qxc6 49. Bg2 Qc1+ 50. Kh2 Qxb2 51. Nd7 Qxa2 52. Nxe5 Qxf2 53. Ng4+ Kg5 54. Nxf2 a3 55. Bd5 b4 56. Bxf7 Kf6 57. Bb3 Ke5 58. Nd3+ Kd4 59. Nxb4 Kc3 60. Bg8 Kxb4 61. Kh3 Kc5 62. Kh4 Kd6 63. Kh5 Ke7 64. Kh6 Kf8 65. Ba2 Ke7 66. Kxh7 Kf6 67. Kh6 Kf5 68. Kh5 Kf6 69. g4 Kg7 70. g5 Kh7 71. g6+ Kg7 72. Kg5 Kh8 73. Kf5 Kg7 74. Bb1 Kh8 75. Kf6 Kg8 76. Ba2+ Kh8 77. g7+ Kh7 78. g8=Q+ Kh6 79. Qg6# Qg7",
      "predicted_san": "O-O",
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "raw_response": "6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# 0-1\n\n28. Ng1",
      "predicted_san": "d4",
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n5/4p3/B3n3/5N2/PPPP1PPP/RNBQ1RK1 w kq - 0 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "raw_response": "7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. h3 Re2 24. Rb1 Rff2 25. g4 Rg2+ 26. Kf1 Ref2+ 27. Ke1 Rxb2 28. Rxb2 Rxb2 29. Kf1 Kf7 30. Kg1 Ke6 31. Kf1 Ke5 32. Kg1 Kf4 33. Kf1 Kf3 34. Ke1 Ke3 35. Kd1 Kd3 36. Kc1 Kxc3 37. h4 Rh2 38. h5 Rh1+ 39. Bd1 d4 40. g5 d3 41. g6 d2+ 42. Kb1 Rxd1#\n43. Ka2 Ra1+ 44. Kxa1 d1=Q+ 45. Ka2 Qc2+ 46. Ka1 Qb2#",
      "predicted_san": "Bb3",
      "board_fen": "r1bqkb1r/2pp1ppp/p1n5/1p2p3/B2Pn3/5N2/PPP2PPP/RNBQ1RK1 w kq - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "raw_response": "8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# 0-1\n28. Ng1",
      "predicted_san": "dxe5",
      "board_fen": "r1bqkb1r/2p2ppp/p1n5/1p1pp3/3Pn3/1B3N2/PPP2PPP/RNBQ1RK1 w kq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "raw_response": "9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# 28. Kh2 Rxe1 29. Bd8 c6 30. Bb6 Re2 31. b4 Rxa2 32. Bd4 Kg8 33. Kg3 Kf7 34. Kf3 g6 35. h4 Ke6 36. g4 Kd5 37. Kf4 a5 38. bxa5 Rxa5 39. Kg5 c5 40. Bg7 Ra7 41. Kh6 Rxg7 42. Kxg7 b4 43. cxb4 cxb4 44. Kxh7 b3 45. Kxg6 b2 46. h5 b1=Q+ 47. Kg7 Ke6 48. h6 Qb7+ 49. Kg8 Kf6 50. g5+ Kg6 51. Kf8 Qf7# 52. Ke8 Kxg5 53. h7 Qxh7 54. Kd8 Kf6 55. Kc8 Ke6 56. Kb8 Kd6 57. Ka8 Kc6 58. Kb8 Qb7# 59. Kd8 Qd7# 60. Ke8 Kd6+ 61. Kf8 Ke6 62. Kg8 Kf6 63. Kh8 Qg7# 64. Kg8 Qg8# 65. Kxg8 *\nQg8#",
      "predicted_san": "c3",
      "board_fen": "r2qkb1r/2p2ppp/p1n1b3/1p1pP3/4n3/1B3N2/PPP2PPP/RNBQ1RK1 w kq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "raw_response": "10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Bxf3 21. gxf3 Qf2 22. Qxd5+ Kh8 23. Be4 Qxb2 24. Rg1 Qxc3 25. Bd2 Qe5 26. Qd3 Rd8 27. Qc2 Qd4 28. Bc3 Qxg1+ 29. Kxg1 c5 30. Qg2 Rf7 31. Qh3 Kg8 32. Qxh7+ Kf8 33. Qh8+ Ke7 34. Qh4+ Kd7 35. Qg4+ Kc7 36. Be5+ Kb6 37. Qe6+ Ka5 38. Qxf7 Rd1+ 39. Kg2 Rd2+ 40. Kg3 c4 41. Bc3+ Ka4 42. Bxd2 Ka3 43. Qe7+ Kxa2 44. Qb4 a5 45. Qxa5+ Kb3 46. Qb4+ Ka2 47. Bc3 g5 48. Qb2# B1c3",
      "predicted_san": "Nbd2",
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/4n3/1BP2N2/PP3PPP/RNBQ1RK1 w kq - 1 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "raw_response": "11. Rxf2 O-O 12. Bc2 f6 13. exf6 Qxf6 14. Nb3 Bxf2+ 15. Kxf2 Ne5 16. Nd4 Bg4 17. Kg1 c5 18. Nb3 Nxf3+ 19. gxf3 Bxf3 20. Qd2 Rae8 21. Nxc5 Re2 22. Qd3 Rg2+ 23. Kh1 Rg3+ 24. Qxf3 Qxf3# 25. hxg3 Qf1+",
      "predicted_san": "Rxf2",
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/8/1BP2N2/PP1N1nPP/R1BQ1RK1 w kq - 0 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "raw_response": "12. Kxf2 O-O 13. Nf1 f6 14. exf6 Qxf6 15. Kg1 Ne5 16. Bxd5 Rad8 17. Bxe6+ Qxe6 18.\nNd4 Qf6 19. Qe2 c5 20. Nc2 Nd3 21. Be3 Nxb2 22. Bxc5 Rfe8 23. Qf2 Qxc3 24. Bd4\nQc4 25. Bxb2 Re2 26. Qg3 g6 27. Nfe3 Qc5 28. Qf3 Rxc2 29. Qf6 Qxe3+ 30. Kh1 Rxb2\n31. Qxd8+ Kg7 32. Qd7+ Kh6 33. Qd6 Qf2 34. Qd5 Rxa2 35. Rg1 b4 36. h3 a5 37. Qd8\nb3 38. Qd5 a4 39. Qd8 b2 40. Qd5 Ra1 41. Rxa1 bxa1=Q+ 42. Kh2 Qag1#\n43. Kh3 Qh1#",
      "predicted_san": "Kxf2",
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1bPP/R1BQ2K1 w kq - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "raw_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6",
      "predicted_san": "exf6",
      "board_fen": "r2qk2r/2p3pp/p1n1bp2/1p1pP3/8/1BP2N2/PP1N1KPP/R1BQ4 w kq - 0 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "raw_response": "14. Nf1 O-O 15. Bg5 Qf7 16. Kg1 Rae8 17. Ne3 h6 18. Bh4 g5 19. Bg3 Rd8 20. Nd4 Nxd4\n21. Qxd4 c6 22. Rf1 Qg7 23. Be5 Rxf1+ 24. Nxf1 Qf7 25. Ng3 Rf8 26. h3 h5 27. Bd1 h4\n28. Nh5 Qf1+ 29. Kh2 Rf2 30. Bf3 Rxf3 31. gxf3 Qxh3+ 32. Kg1 Qxf3 33. Nf6+ Kf7\n34. Qf2 Qxf2+ 35. Kxf2 Kg6 36. Ne8 Kf5 37. Bd4 g4 38. Nc7 Bc8 39. Ne8 Kf4 40. Nd6\ng3+ 41. Kg1 Bg4 42. Nf7 h3 43. Be5+ Kf3 44. Ng5+ Ke3 45. Bxg3 Kd2 46. Be5 Kc2\n47. b4 Kb2 48. Kh2 Kxa2 49. Nxh3 Kb3 50. Nf4 Kc4 51. Kg3 Bf5 52. Kf2 c5 53. bxc5\nKxc5 54. Ke3 a5 55. Bd4+ Kc4 56. Kd2 b4 57. Ne2 b3 58. Kc1 a4 59. Kb2 Kd3 60. Nf4+\nKe4 61. Ne2 Kd3 62. Nc1+ Kc4 63. Ka3 Bd7 64. Ne2 Kd3 65. Nf4+ Ke4 66. Ng6 Kd3\n67. Ne5+ Kc2 68. Nxd7 b2 69. c4 b1=Q 70. cxd5 Qb3#\n71. Kxa4",
      "predicted_san": "Nf1",
      "board_fen": "r3k2r/2p3pp/p1n1bq2/1p1p4/8/1BP2N2/PP1N1KPP/R1BQ4 w kq - 0 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "raw_response": "15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5\nRxe5 21. Rd1 Rxd1 22. Kxd1 c5 23. Kd2 Kf7 24. Ng3 Ke6 25. Ne2 Kd5 26. Nf4+ Ke4\n27. Nd3 Rd5 28. Ke2 Rxd3 29. Bxc5 Rd5 30. Bd4 g6 31. b3 b4 32. Bg7 bxc3 33. Bxc3\nRc5 34. Kd2 Rf5 35. Ke2 Rg5 36. g3 Rh5 37. h4 Rc5 38. Kd2 Kf3 39. Bd4 Rd5 40.\nKc3 Kxg3 41. Kc4 Rd7 42. Bf6 Rf7 43. Bg5 Rf5 44. b4 Rxg5 45. hxg5 Kf4 46. a4\nKe5 47. Kc5 Ke6 48. Kc6 Ke7 49. b5 axb5 50. axb5 Kd8 51. Kb7 Kd7 52. b6 Kd8 53.\nKa7 Kc8 54. b7+ Kc7 55. b8=Q+ Kc6 56. Qh8 Kd5 57. Qxh7 Ke5 58. Qxg6 Kf4 59.\nQf6+ Kg4 60. g6 Kh5 61. g7 Kg4 62. g8=Q+ Kh5 63. Qfh8# Bf8",
      "predicted_san": "Bxd5",
      "board_fen": "r4rk1/2p3pp/p1n1bq2/1p1p4/8/1BP2N2/PP3KPP/R1BQ1N2 w - - 2 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "raw_response": "16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf6 20. Rd1 Rf8 21. Kg1\nNe7 22. Rd7 Ng6 23. Rxc7 Nf4 24. Qe7 Qg6 25. Ng3 Qb1+ 26. Nf1 Qg6 27. Ng3 Qb1+\n28. Qe1 Qxb2 29. Qd2 Qb1+ 30. Nf1 Qg6 31. Ng3 Qb1+ 32. Qe1 Qxa2 33. Qd2 Qb1+\n34. Qe1 Qa2 35. Qd2 Qb1+ 36. Qe1 Qa2 37. Qd2 Qb1+ 38. Qe1 Qa2 39. Qd2 Qb1+\n40. Qe1 Qa2 41. Qd2 Qb1+ 42. Qe1 Qa2 43. Qd2 Qb1+ 44. Qe1 Qa2 45. Qd2 Qb1+\n46. Qe1 Qa2 47. Qd2 Qb1+ 48. Qe1 Qa2 49. Qd2 Qb1+ 50. Qe1 Qa2 51. Qd2 Qb1+\n52. Qe1 Qa2 53. Qd2 Qb1+ 54. Qe1 Qa2 55. Qd2 Qb1+ 56. Qe1 Qa2 57. Qd2 Qb1+\n58. Qe1 Qa2 59. Qd2 Qb1+ 60. Qe1 Qa2 61. Qd2 Qb1+ 62. Qe1 Qa2 63. Qd2 Qb1+\n64. Qe1 Qa2 65. Qd2 Qb1+ 66. Qe1 Qa2 67. Qd2 Qb1+ 68. Qe1 Qa2 69. Qd2 Qb1+\n70. Qe1 Qa2 71. Qd2 Qb1+ 72. Qe1 Qa2 73. Qd2 Qb1+ 74. Qe1 Qa2 75. Qd2 Qb1+\n76. Qe1 Qa2 77. Qd2 Qb1+ 78. Qe1 Qa2 79. Qd2 Qb1+ 80. Qe1 Qa2 81. Qd2 Qb1+\n82. Qe1 Qa2 83. Qd2 Qb1+ 84. Qe1 Qa2 85. Qd",
      "predicted_san": "Bg5",
      "board_fen": "3r1rk1/2p3pp/p1n1bq2/1p1B4/8/2P2N2/PP3KPP/R1BQ1N2 w - - 1 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "raw_response": "17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf6 20. Rd1 Rf8 21. Kg1 h6 22. Ng3 Kh8 23. Rd7 Qf4 24. Nh5 Qc1+ 25. Kf2 g6 26. Ng3 Qf4 27. Qe3 Qxe3+ 28. Kxe3 Re8+ 29. Kf2 Rc8 30. Ne4 Kg8 31. Nf6+ Kf8 32. Nh4 Ne7 33. Rxe7 Kxe7 34. Nd5+ Kf7 35. Nf3 c6 36. Ne5+ Ke6 37. Nb6 Rf8+ 38. Nf3 g5 39. Ke3 c5 40. b4 cxb4 41. cxb4 Rf4 42. Nd4+ Kd6 43. a4 bxa4 44. Nxa4 Kd5 45. Nb6+ Kd6 46. Nc4+ Kd5 47. Nb6+ Kd6 48. Nc4+ Kd5 49. Nb6+ Kd6 50. Nc4+ Kd5 51. Nb6+ Kd6 52. Nc4+ Kd5 53. Nb6+ Kd6 54. Nc4+ Kd5 55. Nb6+ Kd6 56. Nc4+ Kd5 57. Nb6+ Kd6 58. Nc4+ Kd5 59. Nb6+ Kd6 60. Nc4+ Kd5 61. Nb6+ Kd6 62. Nc4+ Kd5 63. Nb6+ Kd6 64. Nc4+ Kd5 65. Nb6+ Kd6 66. Nc4+ Kd5 67. Nb6+ Kd6 68. Nc4+ Kd5 69. Nb6+ Kd6 70. Nc4+ Kd5 71. Nb6+ Kd6 72. Nc4+ Kd5 73. Nb6+ Kd6 74. Nc4+ Kd5 75. Nb6+ Kd6 76. Nc4+ Kd5 77. Nb6+ Kd6 78. Nc4+ Kd5 79. Nb6+ Kd6 80. Nc4+ Kd5 81. Nb6+ Kd6 82. Nc4+ Kd5 83. Nb6+ Kd6 84. Nc4+ Kd5 85. Nb6+ Kd6 86. Nc4+ Kd5 87. Nb6+ K",
      "predicted_san": "Bxe6",
      "board_fen": "3r1rk1/2p2qpp/p1n1b3/1p1B2B1/8/2P2N2/PP3KPP/R2Q1N2 w - - 3 17"
    },
    {
      "turn": 35,
      "attempt": 1,
      "raw_response": "18. Bxd8 Rxd8 19. Qe2 Qf6 20. Re1 Kh8 21. Qe6 Qxe6 22. Rxe6 Nb8 23. Ne3 Kg8 24. Re7 Rc8 25. Nf5 g6 26. Nh6+ Kh8 27. Ng5 Nc6 28. Rxh7# Qe8",
      "predicted_san": "Bxd8",
      "board_fen": "3r1rk1/2p3pp/p1n1q3/1p4B1/8/2P2N2/PP3KPP/R2Q1N2 w - - 0 18"
    },
    {
      "turn": 37,
      "attempt": 1,
      "raw_response": "19. Qe2 Qf7 20. Rd1 Re8 21. Qd3 Ne5 22. Qd5 Ng4+ 23. Kg1 Qxd5 24. Rxd5 Re2 25. Rd2 Re7 26. h3 Nf6 27. Ng3 c5 28. Re2 Rd7 29. Ne5 Rd1+ 30. Kf2 h6 31. Ne4 Nd5 32. Rd2 Rxd2+ 33. Nxd2 c4 34. Kf3 Kf8 35. Ke4 Nf6+ 36. Kd4 Ke7 37. Ne4 Nh5 38. g3 Ke6 39. Nc5+ Kd6 40. Nxa6 Nxg3 41. Nf7+ Kc6 42. Nb4+ Kb6 43. Nd5+ Kc6 44. Ne5+ Kd6 45. Nf7+ Kc6 46. Nb4+ Kb6 47. Kd5 Nf5 48. Ke6 Ne3 49. Nd5+ Nxd5 50. Kxd5 Ka5 51. Kc5 Ka4 52. Nd6 g5 53. Nxb5 h5 54. Nd4 g4 55. hxg4 hxg4 56. Kxc4 g3 57. Nf3 g2 58. b3+ Ka3 59. b4 Kxa2 60. b5 Kb2 61. b6 Kc2 62. b7 Kd1 63. b8=Q Ke2 64. Qg3 Kf1 65. Kd3 g1=Q 66. Qxg1#",
      "predicted_san": "Qe2",
      "board_fen": "3r2k1/2p3pp/p1n1q3/1p6/8/2P2N2/PP3KPP/R2Q1N2 w - - 0 19"
    },
    {
      "turn": 39,
      "attempt": 1,
      "raw_response": "20. Kg1 Re8",
      "predicted_san": "Kg1",
      "board_fen": "3r2k1/2p2qpp/p1n5/1p6/8/2P2N2/PP2QKPP/R4N2 w - - 2 20"
    },
    {
      "turn": 41,
      "attempt": 1,
      "raw_response": "21. Ng5 Qg6 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 h6 25. Nd8 Nxd8 26. Rxd8+ Kh7\n27. Ra8 Rf6 28. Ra7 c5 29. Rc7 c4 30. Rd7 Re6 31. Rd2 Kg6 32. Ng3 Kg5 33. Re2\nRd6 34. Ne4+ Kf4 35. Nxd6 g5 36. Re4#",
      "predicted_san": "Ng5",
      "board_fen": "5rk1/2p2qpp/p1n5/1p6/8/2P2N2/PP2Q1PP/R4NK1 w - - 4 21"
    },
    {
      "turn": 43,
      "attempt": 1,
      "raw_response": "22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 h6 25. Ne3 Re7 26. Nd4 Rxe3 27. Nxc6 Re2\n28. Rb1 Kf7 29. Nb4 a5 30. Nd5 c6 31. Nf4 Rd2 32. Kf1 g5 33. Ne2 c5 34. Ke1 Rd6\n35. Rd1 Re6 36. Rd5 Rc6 37. Ng3 Ke6 38. Rd8 Ke5 39. Ke2 b4 40. c4 a4 41. Rd5+ Kf4\n42. Kf2 b3 43. h3 g4 44. Rf5# gxf5 45. Ne2+ Ke5 46. axb3 axb3 47. Nc1 Rb6 48.\nNd3+ Kd4 49. Ke2 Kxc4 50. Kd2 Rd6 51. Ke2 Rxd3 52. Kf2 Rd2+ 53. Kg3 Rxb2 54.\nKf4 Rxg2 55. Kxf5 gxh3 56. Kf4 h2 57. Kf3 h1=Q 58. Kf4 Qf1+ 59. Ke5 Re2+ 60.\nKd6 Qf6+ 61. Kc7 Re7+ 62. Kd8 Qf8# Qd8#",
      "predicted_san": "Qe6+",
      "board_fen": "5rk1/2p3pp/p1n5/1p3qN1/8/2P5/PP2Q1PP/R4NK1 w - - 6 22"
    },
    {
      "turn": 45,
      "attempt": 1,
      "raw_response": "23. Nxe6 Rf7",
      "predicted_san": "Nxe6",
      "board_fen": "5rk1/2p3pp/p1n1q3/1p4N1/8/2P5/PP4PP/R4NK1 w - - 0 23"
    },
    {
      "turn": 47,
      "attempt": 1,
      "raw_response": "24. Rd1 h6",
      "predicted_san": "Rd1",
      "board_fen": "6k1/2p2rpp/p1n1N3/1p6/8/2P5/PP4PP/R4NK1 w - - 1 24"
    },
    {
      "turn": 49,
      "attempt": 1,
      "raw_response": "25. Nd8",
      "predicted_san": "Nd8",
      "board_fen": "6k1/2p1r1pp/p1n1N3/1p6/8/2P5/PP4PP/3R1NK1 w - - 3 25"
    },
    {
      "turn": 51,
      "attempt": 1,
      "raw_response": "26. Nb7",
      "predicted_san": "Nb7",
      "board_fen": "3N2k1/2p1r1pp/p7/1p2n3/8/2P5/PP4PP/3R1NK1 w - - 5 26"
    },
    {
      "turn": 53,
      "attempt": 1,
      "raw_response": "27. Rd8+ Kf7 28. b3 Na3",
      "predicted_san": "Rd8+",
      "board_fen": "6k1/1Np1r1pp/p7/1p6/2n5/2P5/PP4PP/3R1NK1 w - - 7 27"
    },
    {
      "turn": 55,
      "attempt": 1,
      "raw_response": "28. b3 Nb6 29. Nc5 a5 30. Kf2 a4 31. Ne3 axb3 32. axb3 Re5 33. Nd3 Re7 34. Nd5\nNxd5 35. Rxd5 c6 36. Rd6 Rc7 37. Ne5+ Ke7 38. Rxc6 Rxc6 39. Nxc6+ Kd6 40. Nd4 Kc5\n41. Ke3 b4 42. c4 g6 43. Ke4 h6 44. Ke5 h5 45. Ne6+ Kc6 46. Kf6 Kd6 47. Nf4 g5\n48. Kxg5 Ke5 49. Nxh5 Kd4 50. Nf4 Kc3 51. c5 Kxb3 52. c6 Ka2 53. c7 b3 54. c8=Q\nb2 55. Qa6+ Kb1 56. Nd3 Kc2 57. Nxb2 Kxb2 58. Qc4 Ka3 59. Qb5 Ka2 60. Kf4 Ka3\n61. Ke3 Ka2 62. Kd3 Ka3 63. Kc3 Ka2 64. Qb2#\nQb8",
      "predicted_san": "b3",
      "board_fen": "3R4/1Np1rkpp/p7/1p6/2n5/2P5/PP4PP/5NK1 w - - 9 28"
    },
    {
      "turn": 57,
      "attempt": 1,
      "raw_response": "29. Nc5 Re2",
      "predicted_san": "Nc5",
      "board_fen": "3R4/1Np1rkpp/pn6/1p6/8/1PP5/P5PP/5NK1 w - - 1 29"
    },
    {
      "turn": 59,
      "attempt": 1,
      "raw_response": "30. Nxa6 Rxa2",
      "predicted_san": "Nxa6",
      "board_fen": "3R4/2p2kpp/pn6/1pN5/8/1PP5/P3r1PP/5NK1 w - - 3 30"
    },
    {
      "turn": 61,
      "attempt": 1,
      "raw_response": "31. Nxc7",
      "predicted_san": "Nxc7",
      "board_fen": "3R4/2p2kpp/Nn6/1p6/8/1PP5/r5PP/5NK1 w - - 0 31"
    },
    {
      "turn": 63,
      "attempt": 1,
      "raw_response": "32. Nxb5 Rxb3",
      "predicted_san": "Nxb5",
      "board_fen": "3R4/2N2kpp/1n6/1p6/8/rPP5/6PP/5NK1 w - - 1 32"
    },
    {
      "turn": 65,
      "attempt": 1,
      "raw_response": "33. Nd4 Rxc3 34. Rd6 Nc4 35. Rc6 Rc1 36. Ne2 Rc2 37. Nd4 Rc1 38. Kf2 Ke7 39. Ne3\nKd7 40. Rxc4 Rxc4 41. Nxc4 Ke7 42. Ke3 Kf6 43. Kf4 g5+ 44. Kg4 Kg6 45. Ne5+ Kf6\n46. Ndf3 h6 47. Kh5 Kg7 48. Ng4 Kh7 49. Nxh6 Kg7 50. Nxg5 Kh8 51. Kg6 *\nNf8+",
      "predicted_san": "Nd4",
      "board_fen": "3R4/5kpp/1n6/1N6/8/1rP5/6PP/5NK1 w - - 0 33"
    },
    {
      "turn": 67,
      "attempt": 1,
      "raw_response": "34. Rb8 Nc4 35. Rxb2 Nxb2 36. Ne3 Kf6 37. Kf2 Ke5 38. Ke2 Ke4 39. Nf3 h6 40. Nd2+ Ke5 41. Nec4+ Nxc4 42. Nxc4+ Kd5 43. Kd3 g5 44. Ne3+ Ke5 45. c4 h5 46. c5 g4 47. g3 Ke6 48. Kd4 Kd7 49. Kd5 Kc7 50. c6 Kc8 51. Kd6 Kd8 52. c7+ Kc8 53. Nd5 h4 54. Kc6 hxg3 55. Nb6#",
      "predicted_san": "Rb8",
      "board_fen": "3R4/5kpp/1n6/8/3N4/2P5/1r4PP/5NK1 w - - 2 34"
    },
    {
      "turn": 69,
      "attempt": 1,
      "raw_response": "35. c4 Nxc4 36. Rxb2 Nxb2",
      "predicted_san": "c4",
      "board_fen": "1R6/6pp/1n4k1/8/3N4/2P5/1r4PP/5NK1 w - - 4 35"
    },
    {
      "turn": 71,
      "attempt": 1,
      "raw_response": "36. Rxb2 Nxb2 37. Ne3 Nd3 38. Kf1 Ne5 39. Ke2 Kf6 40. Nf3 Nxf3 41. Kxf3 Ke5 42. Kg4\nKf6 43. Nd5+ Kg6 44. Nf4+ Kf6 45. h4 g6 46. Nd5+ Kg7 47. Kg5 h6+ 48. Kf4 Kf7\n49. Ke5 Kg7 50. Ke6 g5 51. h5 g4 52. Kf5 g3 53. Kg4 Kf7 54. Kxg3 Ke6 55. Nf4+ Kf5\n56. Kf3 Kg5 57. g4 Kf6 58. Ke4 Kg5 59. Kf3 Kf6 60. Nh3 Ke5 61. g5 hxg5 62. Kg4\nKf6 63. Nxg5 Kg7 64. Ne6+ Kh6 65. Nf4 Kg7 66. Kg5 Kh7 67. h6 Kg8 68. Kg6 Kh8\n69. Ne6 Kg8 70. Ng5 Kh8 71. Nf7+ Kg8 72. h7+ Kf8 73. h8=Q+ Ke7 74. Qd8+ Ke6\n75. Qd6# Qd8",
      "predicted_san": "Rxb2",
      "board_fen": "1R6/6pp/6k1/8/2nN4/8/1r4PP/5NK1 w - - 0 36"
    },
    {
      "turn": 73,
      "attempt": 1,
      "raw_response": "37. Ne3 Nd3",
      "predicted_san": "Ne3",
      "board_fen": "8/6pp/6k1/8/3N4/8/1n4PP/5NK1 w - - 0 37"
    },
    {
      "turn": 75,
      "attempt": 1,
      "raw_response": "38. Nf3 h6",
      "predicted_san": "Nf3",
      "board_fen": "8/6pp/6k1/8/3N4/3nN3/6PP/6K1 w - - 2 38"
    },
    {
      "turn": 77,
      "attempt": 1,
      "raw_response": "39. Ne5+ Kh5",
      "predicted_san": "Ne5+",
      "board_fen": "8/6pp/6k1/8/5n2/4NN2/6PP/6K1 w - - 4 39"
    },
    {
      "turn": 79,
      "attempt": 1,
      "raw_response": "40. Nd7+ Ke7",
      "predicted_san": "Nd7+",
      "board_fen": "8/6pp/5k2/4N3/5n2/4N3/6PP/6K1 w - - 6 40"
    },
    {
      "turn": 81,
      "attempt": 1,
      "raw_response": "41. g3 Ne6",
      "predicted_san": "g3",
      "board_fen": "8/3N2pp/6k1/8/5n2/4N3/6PP/6K1 w - - 8 41"
    },
    {
      "turn": 83,
      "attempt": 1,
      "raw_response": "42. Ne5+",
      "predicted_san": "Ne5+",
      "board_fen": "8/3N2pp/4n1k1/8/8/4N1P1/7P/6K1 w - - 1 42"
    },
    {
      "turn": 85,
      "attempt": 1,
      "raw_response": "43. h4+ Kh5",
      "predicted_san": "h4+",
      "board_fen": "8/6pp/4n3/4N1k1/8/4N1P1/7P/6K1 w - - 3 43"
    },
    {
      "turn": 87,
      "attempt": 1,
      "raw_response": "44. Nf5 g5",
      "predicted_san": "Nf5",
      "board_fen": "8/6pp/4n3/4N2k/7P/4N1P1/8/6K1 w - - 1 44"
    },
    {
      "turn": 89,
      "attempt": 1,
      "raw_response": "45. g4#",
      "predicted_san": "g4#",
      "board_fen": "8/7p/4n3/4NNpk/7P/6P1/8/6K1 w - - 0 45"
    }
  ],
  "black_responses": [
    {
      "turn": 2,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e5",
          "aggressive_uci": "e7e5",
          "aggressive_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Na5\n10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4\n13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4\n16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5\n22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8\n25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8\n28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7\n34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6\n37. Bd3 Kg7 38. Rb8 Bf7 39. Rxb5 Bxa2\n40. Ra5 Bb3 41. Nd2 Nc6 42. Ra6 Nb4\n43. Ra7+ Kh6 44. Bc4 Rd8 45. Bxb3 Rxd2\n46. Bxa4 Rxb2 47. Bd7 Nd3 48. Bf5 Nxf2\n49. Rxh7+ Kg5 50. g3 Nxh3+ 51. Rxh3 Rb1+\n52. Kf2 Rb2+ 53. Ke3 Rb3+ 54. Kd2 Rb2+\n55. Kc3 Rb3+ 56. Kc4 Rb4+ 57. Kd5 Rb5+\n58. Ke6 Rb6+ 59. Kf7 Rb7+ 60. Kg8 Rb8+\n61. Kh7 Rb7+ 62. Kh8 Rb8+ 63. Kg7 Rb7+\n64. Kf8 Rb8+ 65. Ke7 Rb7+ 66. Kd6 Rb6+\n67. Kc5 Rb5+ 68. Kc4 Rb4+ 69. Kc3 Rb3+\n70. Kd2 Rb2+ 71. Ke3 Rb3+ 72. Kf2 Rb2+\n73. Kg1 Rb1+ 74. Kh2 Rb2+ 75. Kh1 Rb1+",
          "aggressive_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bf7",
            "Rxb5",
            "Bxa2",
            "Ra5",
            "Bb3",
            "Nd2",
            "Nc6",
            "Ra6",
            "Nb4",
            "Ra7+",
            "Kh6",
            "Bc4",
            "Rd8",
            "Bxb3",
            "Rxd2",
            "Bxa4",
            "Rxb2",
            "Bd7",
            "Nd3",
            "Bf5",
            "Nxf2",
            "Rxh7+",
            "Kg5",
            "g3",
            "Nxh3+",
            "Rxh3",
            "Rb1+",
            "Kf2",
            "Rb2+",
            "Ke3",
            "Rb3+",
            "Kd2",
            "Rb2+",
            "Kc3",
            "Rb3+",
            "Kc4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke6",
            "Rb6+",
            "Kf7",
            "Rb7+",
            "Kg8",
            "Rb8+",
            "Kh7",
            "Rb7+",
            "Kh8",
            "Rb8+",
            "Kg7",
            "Rb7+",
            "Kf8",
            "Rb8+",
            "Ke7",
            "Rb7+",
            "Kd6",
            "Rb6+",
            "Kc5",
            "Rb5+",
            "Kc4",
            "Rb4+",
            "Kc3",
            "Rb3+",
            "Kd2",
            "Rb2+",
            "Ke3",
            "Rb3+",
            "Kf2",
            "Rb2+",
            "Kg1",
            "Rb1+",
            "Kh2",
            "Rb2+",
            "Kh1",
            "Rb1+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e5",
          "positional_uci": "e7e5",
          "positional_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Na5\n10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4\n13. cxd4 Nc6 14. Nb3 a5 15. Be3 a4\n16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8\n19. Nf1 Bd8 20. Ng3 Bb6 21. Qd2 Ba5\n22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8\n25. Bg5 Kh8 26. Bxf6 gxf6 27. Qh6 Rg8\n28. Qxf6+ Rg7 29. Nh5 Rg8 30. Ng5 Be8\n31. Nxg7 Rxg7 32. dxe5 dxe5 33. Rd1 Qe7\n34. Qxe7 Nxe7 35. Rd8 Rg8 36. Nf3 f6\n37. Bd3 Kg7 38. Rb8 Bc6 39. Rxg8+ Kxg8\n40. Kf1 Kf7 41. Ke2 Ke6 42. Ke3 Kd6\n43. Nd2 Kc5 44. a3 Bd7 45. Nb1 Nc6\n46. Nc3 Nd4 47. Nd5 f5 48. Nf6 f4+\n49. Kd2 Be6 50. Nxh7 b4 51. Ng5 Bg8\n52. h4 bxa3 53. bxa3 Nb3+ 54. Kc3 Nd4\n55. h5 Nb5+ 56. Bxb5 Kxb5 57. h6 Kc5\n58. h7 Bxh7 59. Nxh7 Kd6 60. Kb4 Ke6\n61. Kxa4 Kf7 62. Kb5 Kg6 63. a4 Kxh7\n64. a5 Kg6 65. a6 Kg5 66. a7 Kg4\n67. a8=Q f3 68. Qg8+ Kf4 69. Qg3+ Kxe4\n70. Qxf3+ Kd4 71. Qe3+ Kd5 72. f3 Ke6\n73. Qe4 Kf6 74. Kc5 Ke6 75. g4 Kf6\n76. Kd5 Kg5 77. Qxe5+ Kh4 78. Qh2+ Kg5",
          "positional_tokens": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Na5",
            "Bc2",
            "c5",
            "d4",
            "Qc7",
            "Nbd2",
            "cxd4",
            "cxd4",
            "Nc6",
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Kh8",
            "Bxf6",
            "gxf6",
            "Qh6",
            "Rg8",
            "Qxf6+",
            "Rg7",
            "Nh5",
            "Rg8",
            "Ng5",
            "Be8",
            "Nxg7",
            "Rxg7",
            "dxe5",
            "dxe5",
            "Rd1",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Rd8",
            "Rg8",
            "Nf3",
            "f6",
            "Bd3",
            "Kg7",
            "Rb8",
            "Bc6",
            "Rxg8+",
            "Kxg8",
            "Kf1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Ke3",
            "Kd6",
            "Nd2",
            "Kc5",
            "a3",
            "Bd7",
            "Nb1",
            "Nc6",
            "Nc3",
            "Nd4",
            "Nd5",
            "f5",
            "Nf6",
            "f4+",
            "Kd2",
            "Be6",
            "Nxh7",
            "b4",
            "Ng5",
            "Bg8",
            "h4",
            "bxa3",
            "bxa3",
            "Nb3+",
            "Kc3",
            "Nd4",
            "h5",
            "Nb5+",
            "Bxb5",
            "Kxb5",
            "h6",
            "Kc5",
            "h7",
            "Bxh7",
            "Nxh7",
            "Kd6",
            "Kb4",
            "Ke6",
            "Kxa4",
            "Kf7",
            "Kb5",
            "Kg6",
            "a4",
            "Kxh7",
            "a5",
            "Kg6",
            "a6",
            "Kg5",
            "a7",
            "Kg4",
            "a8=Q",
            "f3",
            "Qg8+",
            "Kf4",
            "Qg3+",
            "Kxe4",
            "Qxf3+",
            "Kd4",
            "Qe3+",
            "Kd5",
            "f3",
            "Ke6",
            "Qe4",
            "Kf6",
            "Kc5",
            "Ke6",
            "g4",
            "Kf6",
            "Kd5",
            "Kg5",
            "Qxe5+",
            "Kh4",
            "Qh2+",
            "Kg5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": "e7e5",
          "neutral_response": "1... e5 2. Nf3 Nc6 3. Bb5 a6\n4. Ba4 Nf6 5. O-O Be7 6. Re1 b5\n7. Bb3 d6 8. c3 O-O 9. h3 Bb7\n10. d4 Re8 11. Nbd2 Bf8 12. a4 h6\n13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5\n16. d5 Nd7 17. Ra3 f5 18. Rae3 fxe4\n19. Nxe4 Nxd5 20. Ba2 c4 21. Nxd6 Rxe3\n22. Nxb7 Rxe1+ 23. Nxe1 Qe7 24. Qxd5+ Kh8\n25. Nf3 Nf6 26. Qc6 Qe4 27. Qxe4 Nxe4\n28. Bb1 Nf6 29. Bf4 Nd5 30. Be5 Re8\n31. Bg6 Re6 32. Bf7 Re7 33. Bxd5 Rd7\n34. Be4 Rd1+ 35. Kh2 Ra1 36. axb5 axb5\n37. Nd6 Bxd6 38. Bxd6 Ra2 39. Be5 b4\n40. Bd5 Ra5 41. Bxc4 Rc5 42. b3 Kh7\n43. Bd6 Rc6 44. Bxb4 Rb6 45. Bc3 Rb7\n46. Ne5 Re7 47. f4 g5 48. f5 Kg7\n49. Ng4+ Kf8 50. f6 Rb7 51. Nxh6 Rh7\n52. Nf5 g4 53. Bb4+ Ke8 54. Ng7+ Kd7\n55. f7 Rxg7 56. f8=Q g3+ 57. Kg1 Rg5\n58. Qe7+ Kc6 59. Qxg5 Kb6 60. Qc5+ Kb7\n61. Bd5+ Kb8 62. Qb6+ Kc8 63. Be6# d4 e6 dxe6",
          "neutral_tokens": {
            "prompt_tokens": 113,
            "completion_tokens": 516,
            "total_tokens": 629,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Bb7",
            "d4",
            "Re8",
            "Nbd2",
            "Bf8",
            "a4",
            "h6",
            "Bc2",
            "exd4",
            "cxd4",
            "Nb4",
            "Bb1",
            "c5",
            "d5",
            "Nd7",
            "Ra3",
            "f5",
            "Rae3",
            "fxe4",
            "Nxe4",
            "Nxd5",
            "Ba2",
            "c4",
            "Nxd6",
            "Rxe3",
            "Nxb7",
            "Rxe1+",
            "Nxe1",
            "Qe7",
            "Qxd5+",
            "Kh8",
            "Nf3",
            "Nf6",
            "Qc6",
            "Qe4",
            "Qxe4",
            "Nxe4",
            "Bb1",
            "Nf6",
            "Bf4",
            "Nd5",
            "Be5",
            "Re8",
            "Bg6",
            "Re6",
            "Bf7",
            "Re7",
            "Bxd5",
            "Rd7",
            "Be4",
            "Rd1+",
            "Kh2",
            "Ra1",
            "axb5",
            "axb5",
            "Nd6",
            "Bxd6",
            "Bxd6",
            "Ra2",
            "Be5",
            "b4",
            "Bd5",
            "Ra5",
            "Bxc4",
            "Rc5",
            "b3",
            "Kh7",
            "Bd6",
            "Rc6",
            "Bxb4",
            "Rb6",
            "Bc3",
            "Rb7",
            "Ne5",
            "Re7",
            "f4",
            "g5",
            "f5",
            "Kg7",
            "Ng4+",
            "Kf8",
            "f6",
            "Rb7",
            "Nxh6",
            "Rh7",
            "Nf5",
            "g4",
            "Bb4+",
            "Ke8",
            "Ng7+",
            "Kd7",
            "f7",
            "Rxg7",
            "f8=Q",
            "g3+",
            "Kg1",
            "Rg5",
            "Qe7+",
            "Kc6",
            "Qxg5",
            "Kb6",
            "Qc5+",
            "Kb7",
            "Bd5+",
            "Kb8",
            "Qb6+",
            "Kc8",
            "Be6#",
            "d4",
            "e6",
            "dxe6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e5",
          "positional_uci": "e7e5",
          "neutral_uci": "e7e5",
          "consensus_move": "e7e5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bf7",
              "Rxb5",
              "Bxa2",
              "Ra5",
              "Bb3",
              "Nd2",
              "Nc6",
              "Ra6",
              "Nb4",
              "Ra7+",
              "Kh6",
              "Bc4",
              "Rd8",
              "Bxb3",
              "Rxd2",
              "Bxa4",
              "Rxb2",
              "Bd7",
              "Nd3",
              "Bf5",
              "Nxf2",
              "Rxh7+",
              "Kg5",
              "g3",
              "Nxh3+",
              "Rxh3",
              "Rb1+",
              "Kf2",
              "Rb2+",
              "Ke3",
              "Rb3+",
              "Kd2",
              "Rb2+",
              "Kc3",
              "Rb3+",
              "Kc4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke6",
              "Rb6+",
              "Kf7",
              "Rb7+",
              "Kg8",
              "Rb8+",
              "Kh7",
              "Rb7+",
              "Kh8",
              "Rb8+",
              "Kg7",
              "Rb7+",
              "Kf8",
              "Rb8+",
              "Ke7",
              "Rb7+",
              "Kd6",
              "Rb6+",
              "Kc5",
              "Rb5+",
              "Kc4",
              "Rb4+",
              "Kc3",
              "Rb3+",
              "Kd2",
              "Rb2+",
              "Ke3",
              "Rb3+",
              "Kf2",
              "Rb2+",
              "Kg1",
              "Rb1+",
              "Kh2",
              "Rb2+",
              "Kh1",
              "Rb1+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Na5",
              "Bc2",
              "c5",
              "d4",
              "Qc7",
              "Nbd2",
              "cxd4",
              "cxd4",
              "Nc6",
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Kh8",
              "Bxf6",
              "gxf6",
              "Qh6",
              "Rg8",
              "Qxf6+",
              "Rg7",
              "Nh5",
              "Rg8",
              "Ng5",
              "Be8",
              "Nxg7",
              "Rxg7",
              "dxe5",
              "dxe5",
              "Rd1",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Rd8",
              "Rg8",
              "Nf3",
              "f6",
              "Bd3",
              "Kg7",
              "Rb8",
              "Bc6",
              "Rxg8+",
              "Kxg8",
              "Kf1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Ke3",
              "Kd6",
              "Nd2",
              "Kc5",
              "a3",
              "Bd7",
              "Nb1",
              "Nc6",
              "Nc3",
              "Nd4",
              "Nd5",
              "f5",
              "Nf6",
              "f4+",
              "Kd2",
              "Be6",
              "Nxh7",
              "b4",
              "Ng5",
              "Bg8",
              "h4",
              "bxa3",
              "bxa3",
              "Nb3+",
              "Kc3",
              "Nd4",
              "h5",
              "Nb5+",
              "Bxb5",
              "Kxb5",
              "h6",
              "Kc5",
              "h7",
              "Bxh7",
              "Nxh7",
              "Kd6",
              "Kb4",
              "Ke6",
              "Kxa4",
              "Kf7",
              "Kb5",
              "Kg6",
              "a4",
              "Kxh7",
              "a5",
              "Kg6",
              "a6",
              "Kg5",
              "a7",
              "Kg4",
              "a8=Q",
              "f3",
              "Qg8+",
              "Kf4",
              "Qg3+",
              "Kxe4",
              "Qxf3+",
              "Kd4",
              "Qe3+",
              "Kd5",
              "f3",
              "Ke6",
              "Qe4",
              "Kf6",
              "Kc5",
              "Ke6",
              "g4",
              "Kf6",
              "Kd5",
              "Kg5",
              "Qxe5+",
              "Kh4",
              "Qh2+",
              "Kg5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Bb7",
              "d4",
              "Re8",
              "Nbd2",
              "Bf8",
              "a4",
              "h6",
              "Bc2",
              "exd4",
              "cxd4",
              "Nb4",
              "Bb1",
              "c5",
              "d5",
              "Nd7",
              "Ra3",
              "f5",
              "Rae3",
              "fxe4",
              "Nxe4",
              "Nxd5",
              "Ba2",
              "c4",
              "Nxd6",
              "Rxe3",
              "Nxb7",
              "Rxe1+",
              "Nxe1",
              "Qe7",
              "Qxd5+",
              "Kh8",
              "Nf3",
              "Nf6",
              "Qc6",
              "Qe4",
              "Qxe4",
              "Nxe4",
              "Bb1",
              "Nf6",
              "Bf4",
              "Nd5",
              "Be5",
              "Re8",
              "Bg6",
              "Re6",
              "Bf7",
              "Re7",
              "Bxd5",
              "Rd7",
              "Be4",
              "Rd1+",
              "Kh2",
              "Ra1",
              "axb5",
              "axb5",
              "Nd6",
              "Bxd6",
              "Bxd6",
              "Ra2",
              "Be5",
              "b4",
              "Bd5",
              "Ra5",
              "Bxc4",
              "Rc5",
              "b3",
              "Kh7",
              "Bd6",
              "Rc6",
              "Bxb4",
              "Rb6",
              "Bc3",
              "Rb7",
              "Ne5",
              "Re7",
              "f4",
              "g5",
              "f5",
              "Kg7",
              "Ng4+",
              "Kf8",
              "f6",
              "Rb7",
              "Nxh6",
              "Rh7",
              "Nf5",
              "g4",
              "Bb4+",
              "Ke8",
              "Ng7+",
              "Kd7",
              "f7",
              "Rxg7",
              "f8=Q",
              "g3+",
              "Kg1",
              "Rg5",
              "Qe7+",
              "Kc6",
              "Qxg5",
              "Kb6",
              "Qc5+",
              "Kb7",
              "Bd5+",
              "Kb8",
              "Qb6+",
              "Kc8",
              "Be6#",
              "d4",
              "e6",
              "dxe6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 113,
            "completion_tokens": 516,
            "total_tokens": 629,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 341,
          "total_completion_tokens": 1796,
          "total_tokens": 2137
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 114,
            "completion_tokens": 640,
            "total_tokens": 754,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 1,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 113,
            "completion_tokens": 516,
            "total_tokens": 629,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "turn": 4,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc6",
          "aggressive_uci": "b8c6",
          "aggressive_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6\n8. c3 O-O 9. h3 Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 cxd4 13. cxd4 Nc6\n14. Nb3 a5 15. Be3 a4 16. Nbd2 Bd7 17. Rc1 Qb7 18. Bb1 Rfc8 19. Nf1 Bd8\n20. Ng3 Bb6 21. Qd2 Ba5 22. Qe2 Bxe1 23. Rxe1 Re8 24. Qd2 Rac8 25. Bg5\n25... Re6 26. d5 *",
          "aggressive_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 197,
            "total_tokens": 319,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nb3",
            "a5",
            "Be3",
            "a4",
            "Nbd2",
            "Bd7",
            "Rc1",
            "Qb7",
            "Bb1",
            "Rfc8",
            "Nf1",
            "Bd8",
            "Ng3",
            "Bb6",
            "Qd2",
            "Ba5",
            "Qe2",
            "Bxe1",
            "Rxe1",
            "Re8",
            "Qd2",
            "Rac8",
            "Bg5",
            "Re6",
            "d5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc6",
          "positional_uci": "b8c6",
          "positional_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1\nRg6 27. Bf4 Rxe1+ 28. Nf1 Bf3 29. Rxb8+ Re8 30. Rxe8# Bxg2+ 31. Kg1 Bc6+ 32. Ng3 Bxe8\n33. Kf1 Qd1+ 34. Kg2 Bc6+ 35. Kh3 Qg4# Bb7 37. Be3 Bc8# Bg4#",
          "positional_tokens": {
            "prompt_tokens": 122,
            "completion_tokens": 304,
            "total_tokens": 426,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "Bxg2+",
            "Kg1",
            "Bc6+",
            "Ng3",
            "Bxe8",
            "Kf1",
            "Qd1+",
            "Kg2",
            "Bc6+",
            "Kh3",
            "Qg4#",
            "Bb7",
            "Be3",
            "Bc8#",
            "Bg4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc6",
          "neutral_uci": "b8c6",
          "neutral_response": "2... Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3\n15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5 19. a4 Rfe8 20. axb5 axb5\n21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3 24. Qg2 Bf4 25. Ra8 Bb8 26. Rea1\n26... Bh3 27. Qf3 Rg6+ 28. Kh1 Bg2+ 29. Qxg2 Rxg2 30. Kxg2 Qxh2+ 31. Kf1\n31... Qh1+ 32. Ke2 Qh5+ 33. Kd3 Qf5+ 34. Ke2 Qg4+ 35. Kd3 Qg6+ 36. Ke2\n36... f5 37. R1a6 Qh5+ 38. Kd3 f4 39. Rb6 fxe3 40. fxe3 Qf5+ 41. Ke2 Qg4+\n42. Kd3 Qg3 43. Ne4 Qf3 44. Raxb8 Qxe4+ 45. Kd2 Qxe3+ 46. Kc2 Qe2+ 47. Kb3\n47... Qc4+ 48. Kc2 Qa4+ 49. Kd3 Qd1# Qd1+ Qd1+ Qd1+",
          "neutral_tokens": {
            "prompt_tokens": 121,
            "completion_tokens": 445,
            "total_tokens": 566,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Rea1",
            "Bh3",
            "Qf3",
            "Rg6+",
            "Kh1",
            "Bg2+",
            "Qxg2",
            "Rxg2",
            "Kxg2",
            "Qxh2+",
            "Kf1",
            "Qh1+",
            "Ke2",
            "Qh5+",
            "Kd3",
            "Qf5+",
            "Ke2",
            "Qg4+",
            "Kd3",
            "Qg6+",
            "Ke2",
            "f5",
            "R1a6",
            "Qh5+",
            "Kd3",
            "f4",
            "Rb6",
            "fxe3",
            "fxe3",
            "Qf5+",
            "Ke2",
            "Qg4+",
            "Kd3",
            "Qg3",
            "Ne4",
            "Qf3",
            "Raxb8",
            "Qxe4+",
            "Kd2",
            "Qxe3+",
            "Kc2",
            "Qe2+",
            "Kb3",
            "Qc4+",
            "Kc2",
            "Qa4+",
            "Kd3",
            "Qd1#",
            "Qd1+",
            "Qd1+",
            "Qd1+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b8c6",
          "positional_uci": "b8c6",
          "neutral_uci": "b8c6",
          "consensus_move": "b8c6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nb3",
              "a5",
              "Be3",
              "a4",
              "Nbd2",
              "Bd7",
              "Rc1",
              "Qb7",
              "Bb1",
              "Rfc8",
              "Nf1",
              "Bd8",
              "Ng3",
              "Bb6",
              "Qd2",
              "Ba5",
              "Qe2",
              "Bxe1",
              "Rxe1",
              "Re8",
              "Qd2",
              "Rac8",
              "Bg5",
              "Re6",
              "d5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "Bxg2+",
              "Kg1",
              "Bc6+",
              "Ng3",
              "Bxe8",
              "Kf1",
              "Qd1+",
              "Kg2",
              "Bc6+",
              "Kh3",
              "Qg4#",
              "Bb7",
              "Be3",
              "Bc8#",
              "Bg4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Rea1",
              "Bh3",
              "Qf3",
              "Rg6+",
              "Kh1",
              "Bg2+",
              "Qxg2",
              "Rxg2",
              "Kxg2",
              "Qxh2+",
              "Kf1",
              "Qh1+",
              "Ke2",
              "Qh5+",
              "Kd3",
              "Qf5+",
              "Ke2",
              "Qg4+",
              "Kd3",
              "Qg6+",
              "Ke2",
              "f5",
              "R1a6",
              "Qh5+",
              "Kd3",
              "f4",
              "Rb6",
              "fxe3",
              "fxe3",
              "Qf5+",
              "Ke2",
              "Qg4+",
              "Kd3",
              "Qg3",
              "Ne4",
              "Qf3",
              "Raxb8",
              "Qxe4+",
              "Kd2",
              "Qxe3+",
              "Kc2",
              "Qe2+",
              "Kb3",
              "Qc4+",
              "Kc2",
              "Qa4+",
              "Kd3",
              "Qd1#",
              "Qd1+",
              "Qd1+",
              "Qd1+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 122,
            "completion_tokens": 197,
            "total_tokens": 319,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 122,
            "completion_tokens": 304,
            "total_tokens": 426,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 121,
            "completion_tokens": 445,
            "total_tokens": 566,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 365,
          "total_completion_tokens": 946,
          "total_tokens": 1311
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 122,
            "completion_tokens": 197,
            "total_tokens": 319,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 122,
            "completion_tokens": 304,
            "total_tokens": 426,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 3,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 121,
            "completion_tokens": 445,
            "total_tokens": 566,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "turn": 6,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. a4 Qh5\n19. axb5 axb5 20. Ra6 Bb8 21. Qf1 Rfe8 22. Bxd5 Qxd5 23. Qg2 Qh5\n24. Rxc6 Bh3 25. Qf3 Bg4 26. Qg2 Bh3 27. Qf3 Bg4 28. Qg2 Bh3\n29. Qf3 Bg4 30. Qg2 Bh3 31. Qf3 Bg4 32. Qg2 Bh3 33. Qf3 Bg4\n34. Qg2 Bh3 35. Qf3 Bg4 36. Qg2 Bh3 37. Qf3 Bg4 38. Qg2 Bh3\n39. Qf3 Bg4 40. Qg2 Bh3 41. Qf3 Bg4 42. Qg2 Bh3 43. Qf3 Bg4\n44. Qg2 Bh3 45. Qf3 Bg4 46. Qg2 Bh3 47. Qf3 Bg4 48. Qg2 Bh3\n49. Qf3 Bg4 50. Qg2 Bh3 51. Qf3 Bg4 52. Qg2 Bh3 53. Qf3 Bg4\n54. Qg2 Bh3 55. Qf3 Bg4 56. Qg2 Bh3 57. Qf3 Bg4 58. Qg2 Bh3\n59. Qf3 Bg4 60. Qg2 Bh3 61. Qf3 Bg4 62. Qg2 Bh3 63. Qf3 Bg4\n64. Qg2 Bh3 65. Qf3 Bg4 66. Qg2 Bh3 67. Qf3 Bg4 68. Qg2 Bh3\n69. Qf3 Bg4 70. Qg2 Bh3 71. Qf3 Bg4 72. Qg2 Bh3 73. Qf3 Bg4\n74. Qg2 Bh3 75. Qf3 Bg4 76. Qg2 Bh3 77. Qf3 Bg4 78. Qg2 Bh3\n79. Qf3 B",
          "aggressive_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "a4",
            "Qh5",
            "axb5",
            "axb5",
            "Ra6",
            "Bb8",
            "Qf1",
            "Rfe8",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Rxc6",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3",
            "Bg4",
            "Qg2",
            "Bh3",
            "Qf3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a7a6",
          "positional_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5 9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4 14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Qh5 18. a4 Re6 19. axb5 axb5 20. Ra6 Bc7 21. Bd1 Bxd1 22. Rxd1 Qxd1+ 23. Kg2 Nxe3+ 24. fxe3 Rfe8 25. e4 Rxe4 26. Qxe4 Qxd2+ 27. Kh3 Qh6+ 28. Kg2 Qe6 29. Qxe6 fxe6 30. Rxc6 Re7 31. Rc5 b4 32. cxb4 Bb6 33. Rc4 Rd7 34. Rc6 Bxd4 35. Rxe6 Bxb2 36. b5 Rb7 37. b6 Kf7 38. Rc6 Be5 39. Kf3 Ke7 40. Ke4 Bd6 41. Kd5 Rd7 42. Kc4 Bb8 43. Kb5 Rd5+ 44. Ka6 Kd7 45. Rc2 Rd6 46. Kb7 Rd4 47. Kxb8 Rb4 48. b7 g5 49. Rc7+ Kd8 50. Rxh7 g4 51. Rh8+ Kd7 52. Rh7+ Kd8 53. Rh8+ Kd7 54. Rh7+ Kd8 55. Rh8+ Kd7 56. Rh7+ Kd8 57. Rh8+ Kd7 58. Rh7+ Kd8 59. Rh8+ Kd7 60. Rh7+ Kd8 61. Rh8+ Kd7 62. Rh7+ Kd8 63. Rh8+ Kd7 64. Rh7+ Kd8 65. Rh8+ Kd7 66. Rh7+ Kd8 67. Rh8+ Kd7 68. Rh7+ Kd8 69. Rh8+ Kd7 70. Rh7+ Kd8 71. Rh8+ Kd7 72. Rh7+ Kd8 73. Rh8+ Kd7 74. Rh7+ Kd8 75. Rh8+ Kd7 76. Rh7+ Kd8 77. Rh8+ Kd7 78. Rh7+ Kd8 79.",
          "positional_tokens": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Qh5",
            "a4",
            "Re6",
            "axb5",
            "axb5",
            "Ra6",
            "Bc7",
            "Bd1",
            "Bxd1",
            "Rxd1",
            "Qxd1+",
            "Kg2",
            "Nxe3+",
            "fxe3",
            "Rfe8",
            "e4",
            "Rxe4",
            "Qxe4",
            "Qxd2+",
            "Kh3",
            "Qh6+",
            "Kg2",
            "Qe6",
            "Qxe6",
            "fxe6",
            "Rxc6",
            "Re7",
            "Rc5",
            "b4",
            "cxb4",
            "Bb6",
            "Rc4",
            "Rd7",
            "Rc6",
            "Bxd4",
            "Rxe6",
            "Bxb2",
            "b5",
            "Rb7",
            "b6",
            "Kf7",
            "Rc6",
            "Be5",
            "Kf3",
            "Ke7",
            "Ke4",
            "Bd6",
            "Kd5",
            "Rd7",
            "Kc4",
            "Bb8",
            "Kb5",
            "Rd5+",
            "Ka6",
            "Kd7",
            "Rc2",
            "Rd6",
            "Kb7",
            "Rd4",
            "Kxb8",
            "Rb4",
            "b7",
            "g5",
            "Rc7+",
            "Kd8",
            "Rxh7",
            "g4",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Rh8+",
            "Kd7",
            "Rh7+",
            "Kd8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a7a6",
          "neutral_response": "3... a6 4. Ba4 Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 O-O 8. c3 d5\n9. exd5 Nxd5 10. Nxe5 Nxe5 11. Rxe5 c6 12. d4 Bd6 13. Re1 Qh4\n14. g3 Qh3 15. Be3 Bg4 16. Qd3 Rae8 17. Nd2 Re6 18. Qf1 Qh5\n19. a4 Rfe8 20. axb5 axb5 21. Bxd5 Qxd5 22. Qg2 Qh5 23. Qxc6 Bxg3\n24. Qg2 Bf4 25. Ra8 Bb8 26. Kh1 Rg6 27. Bf4 Rxe1+ 28. Nf1 Bf3\n29. Rxb8+ Re8 30. Rxe8# Bxg2+ 31. Kg1 Bc6+ 32. Ng3 Bxe8 33. Kf1 Qd1+ 34. Kg2 Bc6+ 35. Kh3 Qg4# Bxg3 37. hxg3 Qh5# Bxh3 39. Kxh3 Qh1# Bxh3 41. Kxh3 Qh1# Bxh3 43. Kxh3 Qh1# Bxh3 45. Kxh3 Qh1# Bxh3 47. Kxh3 Qh1# Bxh3 49. Kxh3 Qh1# Bxh3 51. Kxh3 Qh1# Bxh3 53. Kxh3 Qh1# Bxh3 55. Kxh3 Qh1# Bxh3 57. Kxh3 Qh1# Bxh3 59. Kxh3 Qh1# Bxh3 61. Kxh3 Qh1# Bxh3 63. Kxh3 Qh1# Bxh3 65. Kxh3 Qh1# Bxh3 67. Kxh3 Qh1# Bxh3 69. Kxh3 Qh1# Bxh3 71. Kxh3 Qh1# Bxh3 73. Kxh3 Qh1# Bxh3 75. Kxh3 Qh1# Bxh3 77. Kxh3 Qh1# Bxh3 79. Kxh3 Qh1# Bxh3 81. Kxh3 Qh1# Bxh3 83. Kxh3 Qh1# Bxh",
          "neutral_tokens": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ba4",
            "Nf6",
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "O-O",
            "c3",
            "d5",
            "exd5",
            "Nxd5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "c6",
            "d4",
            "Bd6",
            "Re1",
            "Qh4",
            "g3",
            "Qh3",
            "Be3",
            "Bg4",
            "Qd3",
            "Rae8",
            "Nd2",
            "Re6",
            "Qf1",
            "Qh5",
            "a4",
            "Rfe8",
            "axb5",
            "axb5",
            "Bxd5",
            "Qxd5",
            "Qg2",
            "Qh5",
            "Qxc6",
            "Bxg3",
            "Qg2",
            "Bf4",
            "Ra8",
            "Bb8",
            "Kh1",
            "Rg6",
            "Bf4",
            "Rxe1+",
            "Nf1",
            "Bf3",
            "Rxb8+",
            "Re8",
            "Rxe8#",
            "Bxg2+",
            "Kg1",
            "Bc6+",
            "Ng3",
            "Bxe8",
            "Kf1",
            "Qd1+",
            "Kg2",
            "Bc6+",
            "Kh3",
            "Qg4#",
            "Bxg3",
            "hxg3",
            "Qh5#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#",
            "Bxh3",
            "Kxh3",
            "Qh1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": "a7a6",
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "a4",
              "Qh5",
              "axb5",
              "axb5",
              "Ra6",
              "Bb8",
              "Qf1",
              "Rfe8",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Rxc6",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3",
              "Bg4",
              "Qg2",
              "Bh3",
              "Qf3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Qh5",
              "a4",
              "Re6",
              "axb5",
              "axb5",
              "Ra6",
              "Bc7",
              "Bd1",
              "Bxd1",
              "Rxd1",
              "Qxd1+",
              "Kg2",
              "Nxe3+",
              "fxe3",
              "Rfe8",
              "e4",
              "Rxe4",
              "Qxe4",
              "Qxd2+",
              "Kh3",
              "Qh6+",
              "Kg2",
              "Qe6",
              "Qxe6",
              "fxe6",
              "Rxc6",
              "Re7",
              "Rc5",
              "b4",
              "cxb4",
              "Bb6",
              "Rc4",
              "Rd7",
              "Rc6",
              "Bxd4",
              "Rxe6",
              "Bxb2",
              "b5",
              "Rb7",
              "b6",
              "Kf7",
              "Rc6",
              "Be5",
              "Kf3",
              "Ke7",
              "Ke4",
              "Bd6",
              "Kd5",
              "Rd7",
              "Kc4",
              "Bb8",
              "Kb5",
              "Rd5+",
              "Ka6",
              "Kd7",
              "Rc2",
              "Rd6",
              "Kb7",
              "Rd4",
              "Kxb8",
              "Rb4",
              "b7",
              "g5",
              "Rc7+",
              "Kd8",
              "Rxh7",
              "g4",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Rh8+",
              "Kd7",
              "Rh7+",
              "Kd8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ba4",
              "Nf6",
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "O-O",
              "c3",
              "d5",
              "exd5",
              "Nxd5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "c6",
              "d4",
              "Bd6",
              "Re1",
              "Qh4",
              "g3",
              "Qh3",
              "Be3",
              "Bg4",
              "Qd3",
              "Rae8",
              "Nd2",
              "Re6",
              "Qf1",
              "Qh5",
              "a4",
              "Rfe8",
              "axb5",
              "axb5",
              "Bxd5",
              "Qxd5",
              "Qg2",
              "Qh5",
              "Qxc6",
              "Bxg3",
              "Qg2",
              "Bf4",
              "Ra8",
              "Bb8",
              "Kh1",
              "Rg6",
              "Bf4",
              "Rxe1+",
              "Nf1",
              "Bf3",
              "Rxb8+",
              "Re8",
              "Rxe8#",
              "Bxg2+",
              "Kg1",
              "Bc6+",
              "Ng3",
              "Bxe8",
              "Kf1",
              "Qd1+",
              "Kg2",
              "Bc6+",
              "Kh3",
              "Qg4#",
              "Bxg3",
              "hxg3",
              "Qh5#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#",
              "Bxh3",
              "Kxh3",
              "Qh1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 392,
          "total_completion_tokens": 1920,
          "total_tokens": 2312
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 131,
            "completion_tokens": 640,
            "total_tokens": 771,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 5,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 130,
            "completion_tokens": 640,
            "total_tokens": 770,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3"
    },
    {
      "turn": 8,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf6",
          "aggressive_uci": "g8f6",
          "aggressive_response": "4... Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 *\n9... Na5 10. Bc2 c5 11. d4 Qc7 12. Nbd2 *\n12... cxd4 13. cxd4 Nc6 14. Nb3 *\n14... a5 15. Be3 a4 16. Nbd2 *\n16... Nb4 17. Bb1 a3 18. bxa3 Rxa3 19. Nb3 *\n19... Be6 20. d5 Bd7 21. Bc1 *\n21... Ra4 22. a3 Na6 23. Bb2 *\n23... Rc8 24. Bd3 Nc5 25. Rc1 *\n25... Qb7 26. Nxc5 dxc5 27. Nxe5 *\n27... c4 28. Bc2 Ra6 29. Nxd7 Nxd7 *\n30. e5 Bxa3 31. Bxa3 Rxa3 32. e6 Nf6 *\n33. d6 fxe6 34. Rxe6 Qd5 35. Qe2 *\n35... Rd8 36. Rd1 Qg5 37. Re5 Qf4 *\n38. Rxb5 Rxd6 39. Rb8+ Kf7 40. Rb7+ Kf8 *\n41. Qe7+ Kg8 42. Qxg7# *\n42... Kh8 43. Qf8+ Ng8 44. Qxg7# *\n44... Ng8 45. Qxg7# *\n45... Ng8 46. Qxg8# *\n46... Kxg8 47. Rxd6 Qxd6 48. Rb1 *\n48... Qd2 49. Be4 c3 50. Rb8+ Kf7 *\n51. Rb7+ Kf6 52. Rb6+ Ke5 53. Bxh7 *\n53... Nf6 54. Rb5+ Kd4 55. Rb4+ Kc5 *\n56. Rb7 Nxh7 57. Rxg7 c2 58. Rc7+ Kd6 *\n59. Rxh7 c1=Q+ 60. Kh2 Qf4+ 61. g3 Qxf2# *\n61... Qxf2# 62. Kh1 Qc1# 63. Kh2 Qcg1#",
          "aggressive_tokens": {
            "prompt_tokens": 138,
            "completion_tokens": 593,
            "total_tokens": 731,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rb5+",
            "Kd4",
            "Rb4+",
            "Kc5",
            "Rb7",
            "Nxh7",
            "Rxg7",
            "c2",
            "Rc7+",
            "Kd6",
            "Rxh7",
            "c1=Q+",
            "Kh2",
            "Qf4+",
            "g3",
            "Qxf2#",
            "Qxf2#",
            "Kh1",
            "Qc1#",
            "Kh2",
            "Qcg1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": "g8f6",
          "positional_response": "4... Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Bb7 10. d4 Re8 11. Nbd2 Bf8 12. a4 h6 13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5 16. d5 Nd7 17. Ra3 c4 18. Nd4 Qf6 19. N2f3 Nc5 20. axb5 axb5 21. Nxb5 Rxa3 22. Nxa3 Nbd3 23. Bxd3 Nxd3 24. Re2 Ba6 25. Qa4 Ra8 26. Be3 Nxb2 27. Qc6 Qd8 28. Rxb2 c3 29. Qxc3 Rc8 30. Qd2 Qf6 31. Bd4 Qg6 32. Qe3 Re8 33. Nd2 f5 34. f3 fxe4 35. fxe4 Be7 36. Rb6 Bc8 37. Nb5 Bg5 38. Qe2 Bxd2 39. Qxd2 Qxe4 40. Nxd6 Qe1+ 41. Qxe1 Rxe1+ 42. Kf2 Rd1 43. Nxc8 Rxd4 44. d6 Kf7 45. Rb7+ Ke6 46. Rxg7 Rd2+ 47. Kg3 Rd3+ 48. Kh4 Rd4+ 49. g4 Rd3 50. Rg6+ Kd7 51. Nb6+ Kc6 52. d7+ Kc7 53. Rxh6 Rd4 54. Kh5 Rd3 55. h4 Rd4 56. g5 Rd3 57. Rf6 Rd4 58. g6 Rd3 59. g7 Rg3 60. Rg6 Rxg6 61. Kxg6 Kxb6 62. d8=Q+ Kc5 63. g8=Q Kb4 64. Qgd5 Kc3 65. Qc7+ Kb2 66. Qb5+ Ka3 67. Qa7# e4 d5 e6",
          "positional_tokens": {
            "prompt_tokens": 138,
            "completion_tokens": 535,
            "total_tokens": 673,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Bb7",
            "d4",
            "Re8",
            "Nbd2",
            "Bf8",
            "a4",
            "h6",
            "Bc2",
            "exd4",
            "cxd4",
            "Nb4",
            "Bb1",
            "c5",
            "d5",
            "Nd7",
            "Ra3",
            "c4",
            "Nd4",
            "Qf6",
            "N2f3",
            "Nc5",
            "axb5",
            "axb5",
            "Nxb5",
            "Rxa3",
            "Nxa3",
            "Nbd3",
            "Bxd3",
            "Nxd3",
            "Re2",
            "Ba6",
            "Qa4",
            "Ra8",
            "Be3",
            "Nxb2",
            "Qc6",
            "Qd8",
            "Rxb2",
            "c3",
            "Qxc3",
            "Rc8",
            "Qd2",
            "Qf6",
            "Bd4",
            "Qg6",
            "Qe3",
            "Re8",
            "Nd2",
            "f5",
            "f3",
            "fxe4",
            "fxe4",
            "Be7",
            "Rb6",
            "Bc8",
            "Nb5",
            "Bg5",
            "Qe2",
            "Bxd2",
            "Qxd2",
            "Qxe4",
            "Nxd6",
            "Qe1+",
            "Qxe1",
            "Rxe1+",
            "Kf2",
            "Rd1",
            "Nxc8",
            "Rxd4",
            "d6",
            "Kf7",
            "Rb7+",
            "Ke6",
            "Rxg7",
            "Rd2+",
            "Kg3",
            "Rd3+",
            "Kh4",
            "Rd4+",
            "g4",
            "Rd3",
            "Rg6+",
            "Kd7",
            "Nb6+",
            "Kc6",
            "d7+",
            "Kc7",
            "Rxh6",
            "Rd4",
            "Kh5",
            "Rd3",
            "h4",
            "Rd4",
            "g5",
            "Rd3",
            "Rf6",
            "Rd4",
            "g6",
            "Rd3",
            "g7",
            "Rg3",
            "Rg6",
            "Rxg6",
            "Kxg6",
            "Kxb6",
            "d8=Q+",
            "Kc5",
            "g8=Q",
            "Kb4",
            "Qgd5",
            "Kc3",
            "Qc7+",
            "Kb2",
            "Qb5+",
            "Ka3",
            "Qa7#",
            "e4",
            "d5",
            "e6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf6",
          "neutral_uci": "g8f6",
          "neutral_response": "4... Nf6 5. O-O Be7 6. Re1 b5 7. Bb3 d6 8. c3 O-O 9. h3 Bb7 10. d4 Re8 11. Nbd2 Bf8 12. a4 h6 13. Bc2 exd4 14. cxd4 Nb4 15. Bb1 c5 16. d5 Nd7 17. Ra3 c4 18. Nd4 Qf6 19. N2f3 Nc5 20. axb5 axb5 21. Nxb5 Nbd3 22. Bxd3 Nxd3 23. Rxd3 cxd3 24. Nc7 Ba6 25. Nxe8 Rxe8 26. Qa4 Ra8 27. Qc6 Qd8 28. Bd2 Qb8 29. Bc3 Bb5 30. Nd4 Bxc6 31. Nxc6 Qb3 32. Nd4 Qc4 33. Rd1 g6 34. f3 Bg7 35. Nc6 Bxc3 36. bxc3 Qxc3 37. Kh2 Ra1 38. Rxa1 Qxa1 39. Ne7+ Kf8 40. Nc8 d2 41. Nxd6 d1=Q 42. Nc4 Qg1+ 43. Kg3 Qae1+ 44. Kf4 Qh2+ 45. Kg4 Qeg3# d2 Nxd2 Qg3#",
          "neutral_tokens": {
            "prompt_tokens": 137,
            "completion_tokens": 358,
            "total_tokens": 495,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Be7",
            "Re1",
            "b5",
            "Bb3",
            "d6",
            "c3",
            "O-O",
            "h3",
            "Bb7",
            "d4",
            "Re8",
            "Nbd2",
            "Bf8",
            "a4",
            "h6",
            "Bc2",
            "exd4",
            "cxd4",
            "Nb4",
            "Bb1",
            "c5",
            "d5",
            "Nd7",
            "Ra3",
            "c4",
            "Nd4",
            "Qf6",
            "N2f3",
            "Nc5",
            "axb5",
            "axb5",
            "Nxb5",
            "Nbd3",
            "Bxd3",
            "Nxd3",
            "Rxd3",
            "cxd3",
            "Nc7",
            "Ba6",
            "Nxe8",
            "Rxe8",
            "Qa4",
            "Ra8",
            "Qc6",
            "Qd8",
            "Bd2",
            "Qb8",
            "Bc3",
            "Bb5",
            "Nd4",
            "Bxc6",
            "Nxc6",
            "Qb3",
            "Nd4",
            "Qc4",
            "Rd1",
            "g6",
            "f3",
            "Bg7",
            "Nc6",
            "Bxc3",
            "bxc3",
            "Qxc3",
            "Kh2",
            "Ra1",
            "Rxa1",
            "Qxa1",
            "Ne7+",
            "Kf8",
            "Nc8",
            "d2",
            "Nxd6",
            "d1=Q",
            "Nc4",
            "Qg1+",
            "Kg3",
            "Qae1+",
            "Kf4",
            "Qh2+",
            "Kg4",
            "Qeg3#",
            "d2",
            "Nxd2",
            "Qg3#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f6",
          "positional_uci": "g8f6",
          "neutral_uci": "g8f6",
          "consensus_move": "g8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rb5+",
              "Kd4",
              "Rb4+",
              "Kc5",
              "Rb7",
              "Nxh7",
              "Rxg7",
              "c2",
              "Rc7+",
              "Kd6",
              "Rxh7",
              "c1=Q+",
              "Kh2",
              "Qf4+",
              "g3",
              "Qxf2#",
              "Qxf2#",
              "Kh1",
              "Qc1#",
              "Kh2",
              "Qcg1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Bb7",
              "d4",
              "Re8",
              "Nbd2",
              "Bf8",
              "a4",
              "h6",
              "Bc2",
              "exd4",
              "cxd4",
              "Nb4",
              "Bb1",
              "c5",
              "d5",
              "Nd7",
              "Ra3",
              "c4",
              "Nd4",
              "Qf6",
              "N2f3",
              "Nc5",
              "axb5",
              "axb5",
              "Nxb5",
              "Rxa3",
              "Nxa3",
              "Nbd3",
              "Bxd3",
              "Nxd3",
              "Re2",
              "Ba6",
              "Qa4",
              "Ra8",
              "Be3",
              "Nxb2",
              "Qc6",
              "Qd8",
              "Rxb2",
              "c3",
              "Qxc3",
              "Rc8",
              "Qd2",
              "Qf6",
              "Bd4",
              "Qg6",
              "Qe3",
              "Re8",
              "Nd2",
              "f5",
              "f3",
              "fxe4",
              "fxe4",
              "Be7",
              "Rb6",
              "Bc8",
              "Nb5",
              "Bg5",
              "Qe2",
              "Bxd2",
              "Qxd2",
              "Qxe4",
              "Nxd6",
              "Qe1+",
              "Qxe1",
              "Rxe1+",
              "Kf2",
              "Rd1",
              "Nxc8",
              "Rxd4",
              "d6",
              "Kf7",
              "Rb7+",
              "Ke6",
              "Rxg7",
              "Rd2+",
              "Kg3",
              "Rd3+",
              "Kh4",
              "Rd4+",
              "g4",
              "Rd3",
              "Rg6+",
              "Kd7",
              "Nb6+",
              "Kc6",
              "d7+",
              "Kc7",
              "Rxh6",
              "Rd4",
              "Kh5",
              "Rd3",
              "h4",
              "Rd4",
              "g5",
              "Rd3",
              "Rf6",
              "Rd4",
              "g6",
              "Rd3",
              "g7",
              "Rg3",
              "Rg6",
              "Rxg6",
              "Kxg6",
              "Kxb6",
              "d8=Q+",
              "Kc5",
              "g8=Q",
              "Kb4",
              "Qgd5",
              "Kc3",
              "Qc7+",
              "Kb2",
              "Qb5+",
              "Ka3",
              "Qa7#",
              "e4",
              "d5",
              "e6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Be7",
              "Re1",
              "b5",
              "Bb3",
              "d6",
              "c3",
              "O-O",
              "h3",
              "Bb7",
              "d4",
              "Re8",
              "Nbd2",
              "Bf8",
              "a4",
              "h6",
              "Bc2",
              "exd4",
              "cxd4",
              "Nb4",
              "Bb1",
              "c5",
              "d5",
              "Nd7",
              "Ra3",
              "c4",
              "Nd4",
              "Qf6",
              "N2f3",
              "Nc5",
              "axb5",
              "axb5",
              "Nxb5",
              "Nbd3",
              "Bxd3",
              "Nxd3",
              "Rxd3",
              "cxd3",
              "Nc7",
              "Ba6",
              "Nxe8",
              "Rxe8",
              "Qa4",
              "Ra8",
              "Qc6",
              "Qd8",
              "Bd2",
              "Qb8",
              "Bc3",
              "Bb5",
              "Nd4",
              "Bxc6",
              "Nxc6",
              "Qb3",
              "Nd4",
              "Qc4",
              "Rd1",
              "g6",
              "f3",
              "Bg7",
              "Nc6",
              "Bxc3",
              "bxc3",
              "Qxc3",
              "Kh2",
              "Ra1",
              "Rxa1",
              "Qxa1",
              "Ne7+",
              "Kf8",
              "Nc8",
              "d2",
              "Nxd6",
              "d1=Q",
              "Nc4",
              "Qg1+",
              "Kg3",
              "Qae1+",
              "Kf4",
              "Qh2+",
              "Kg4",
              "Qeg3#",
              "d2",
              "Nxd2",
              "Qg3#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 138,
            "completion_tokens": 593,
            "total_tokens": 731,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 138,
            "completion_tokens": 535,
            "total_tokens": 673,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 137,
            "completion_tokens": 358,
            "total_tokens": 495,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 413,
          "total_completion_tokens": 1486,
          "total_tokens": 1899
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 138,
            "completion_tokens": 593,
            "total_tokens": 731,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 138,
            "completion_tokens": 535,
            "total_tokens": 673,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 7,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 137,
            "completion_tokens": 358,
            "total_tokens": 495,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkbnr/1ppp1ppp/p1n5/4p3/B3P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 4"
    },
    {
      "turn": 10,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe4",
          "aggressive_uci": "f6e4",
          "aggressive_response": "5... Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. Nbd2 Nc5 10. c3 d4 11. Ng5 dxc3 12. Nxe6 fxe6 13. bxc3 Qd3 14. Bc2 Qxc3 15. Rb1 O-O-O 16. Bb2 Qxd2 17. Qf3 Qd5 18. Qg3 Nd4 19. Bxd4 Qxd4 20. Rfd1 Qc4 21. Rxd8+ Kxd8 22. Rd1+ Kc8 23. Qf3 Nb7 24. Be4 c6 25. Bxc6 Nc5 26. Qf7 Qc2 27. Qe8+ Kc7 28. Qd8+ Kxc6 29. Qc8+ Kb6 30. Qd8+ Kc6 31. Qc8+ Kb6 32. Qd8+ Kc6 33. Qc8+ Kb6 34. Qd8+ Kc6 35. Qc8+ Kb6 36. Qd8+ Kc6 37. Qc8+ Kb6 38. Qd8+ Kc6 39. Qc8+ Kb6 40. Qd8+ Kc6 41. Qc8+ Kb6 42. Qd8+ Kc6 43. Qc8+ Kb6 44. Qd8+ Kc6 45. Qc8+ Kb6 46. Qd8+ Kc6 47. Qc8+ Kb6 48. Qd8+ Kc6 49. Qc8+ Kb6 50. Qd8+ Kc6 51. Qc8+ Kb6 52. Qd8+ Kc6 53. Qc8+ Kb6 54. Qd8+ Kc6 55. Qc8+ Kb6 56. Qd8+ Kc6 57. Qc8+ Kb6 58. Qd8+ Kc6 59. Qc8+ Kb6 60. Qd8+ Kc6 61. Qc8+ Kb6 62. Qd8+ Kc6 63. Qc8+ Kb6 64. Qd8+ Kc6 65. Qc8+ Kb6 66. Qd8+ Kc6 67. Qc8+ Kb6 68. Qd8+ Kc6 69. Qc8+ Kb6 70. Qd8+ Kc6 71. Qc8+ Kb6 72. Qd8+ Kc6 73. Qc8+ Kb6 74. Qd8+ K",
          "aggressive_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "b5",
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "Nbd2",
            "Nc5",
            "c3",
            "d4",
            "Ng5",
            "dxc3",
            "Nxe6",
            "fxe6",
            "bxc3",
            "Qd3",
            "Bc2",
            "Qxc3",
            "Rb1",
            "O-O-O",
            "Bb2",
            "Qxd2",
            "Qf3",
            "Qd5",
            "Qg3",
            "Nd4",
            "Bxd4",
            "Qxd4",
            "Rfd1",
            "Qc4",
            "Rxd8+",
            "Kxd8",
            "Rd1+",
            "Kc8",
            "Qf3",
            "Nb7",
            "Be4",
            "c6",
            "Bxc6",
            "Nc5",
            "Qf7",
            "Qc2",
            "Qe8+",
            "Kc7",
            "Qd8+",
            "Kxc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+",
            "Kc6",
            "Qc8+",
            "Kb6",
            "Qd8+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe4",
          "positional_uci": "f6e4",
          "positional_response": "5... Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. Nbd2 Nc5 10. c3 d4 11. Ng5 dxc3 12. Nxe6 Nxe6 13. bxc3 Nxe5 14. Qe2 Bd6 15. f4 Bc5+ 16. Kh1 Nd3 17. f5 Nef4 18. Qe4+ Kf8 19. Rxf4 Nxf4 20. Qxf4 Qd3 21. Qxc7 Be7 22. Ba3 Re8 23. Re1 Qd8 24. Rxe7 Qxc7 25. Rxc7+ Kg8 26. Bxf7# 1-0\n26... h6 27. Bxe8 Kh7 28. Bxf7 Rd8",
          "positional_tokens": {
            "prompt_tokens": 146,
            "completion_tokens": 204,
            "total_tokens": 350,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4",
            "b5",
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "Nbd2",
            "Nc5",
            "c3",
            "d4",
            "Ng5",
            "dxc3",
            "Nxe6",
            "Nxe6",
            "bxc3",
            "Nxe5",
            "Qe2",
            "Bd6",
            "f4",
            "Bc5+",
            "Kh1",
            "Nd3",
            "f5",
            "Nef4",
            "Qe4+",
            "Kf8",
            "Rxf4",
            "Nxf4",
            "Qxf4",
            "Qd3",
            "Qxc7",
            "Be7",
            "Ba3",
            "Re8",
            "Re1",
            "Qd8",
            "Rxe7",
            "Qxc7",
            "Rxc7+",
            "Kg8",
            "Bxf7#",
            "h6",
            "Bxe8",
            "Kh7",
            "Bxf7",
            "Rd8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe4",
          "neutral_uci": "f6e4",
          "neutral_response": "5... Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. Nbd2 Nc5 10. c3 d4 11. Ng5 dxc3 12. Nxe6 Nxe6 13. bxc3 Nxe5 14. Qe2 Bd6 15. f4 Nc6 16. f5 O-O 17. fxe6 fxe6 18. Qxe6+ Kh8 19. Rxf8+ Qxf8 20. Ne4 Re8 21. Qd5 Ne7 22. Qd3 Nf5 23. Bd2 Rd8 24. Nxd6 Nxd6 25. Rf1 Qe7 26. Bc2 g6 27. Qd4+ Kg8 28. Bb3+ Nc4 29. Bxc4+ bxc4 30. Qxc4+ Kg7 31. Bf4 c5 32. Qxa6 g5 33. Bg3 Qe3+ 34. Kh1 Qxc3 35. Qb7+ Kh6 36. Qc6+ Kh5 37. Qc7 Qd3 38. Qf7+ Kh6 39. Rf6+ Qg6 40. Rxg6+ hxg6 41. h3 Rd1+ 42. Kh2 Rd2 43. Qg8 g4 44. Bf4+ g5 45. Bxd2 gxh3 46. Qxg5+ Kh7 47. Bc3 hxg2 48. Qg7# Nxe4 dxc3 Qxc3 Qxc3 c2 Qxc2+ Kh3 Qc3+ Kg4 Qc1+ Kf5 Qf1+ Ke5 Qe1+ Kd5 Qd1+ Kc5 Qc1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1+ Ka5 Qa1+ Kb5 Qb1",
          "neutral_tokens": {
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "dxc3",
            "Qxc3",
            "Qxc3",
            "c2",
            "Qxc2+",
            "Kh3",
            "Qc3+",
            "Kg4",
            "Qc1+",
            "Kf5",
            "Qf1+",
            "Ke5",
            "Qe1+",
            "Kd5",
            "Qd1+",
            "Kc5",
            "Qc1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1+",
            "Ka5",
            "Qa1+",
            "Kb5",
            "Qb1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f6e4",
          "positional_uci": "f6e4",
          "neutral_uci": "f6e4",
          "consensus_move": "f6e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d4",
              "b5",
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "Nbd2",
              "Nc5",
              "c3",
              "d4",
              "Ng5",
              "dxc3",
              "Nxe6",
              "fxe6",
              "bxc3",
              "Qd3",
              "Bc2",
              "Qxc3",
              "Rb1",
              "O-O-O",
              "Bb2",
              "Qxd2",
              "Qf3",
              "Qd5",
              "Qg3",
              "Nd4",
              "Bxd4",
              "Qxd4",
              "Rfd1",
              "Qc4",
              "Rxd8+",
              "Kxd8",
              "Rd1+",
              "Kc8",
              "Qf3",
              "Nb7",
              "Be4",
              "c6",
              "Bxc6",
              "Nc5",
              "Qf7",
              "Qc2",
              "Qe8+",
              "Kc7",
              "Qd8+",
              "Kxc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+",
              "Kc6",
              "Qc8+",
              "Kb6",
              "Qd8+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d4",
              "b5",
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "Nbd2",
              "Nc5",
              "c3",
              "d4",
              "Ng5",
              "dxc3",
              "Nxe6",
              "Nxe6",
              "bxc3",
              "Nxe5",
              "Qe2",
              "Bd6",
              "f4",
              "Bc5+",
              "Kh1",
              "Nd3",
              "f5",
              "Nef4",
              "Qe4+",
              "Kf8",
              "Rxf4",
              "Nxf4",
              "Qxf4",
              "Qd3",
              "Qxc7",
              "Be7",
              "Ba3",
              "Re8",
              "Re1",
              "Qd8",
              "Rxe7",
              "Qxc7",
              "Rxc7+",
              "Kg8",
              "Bxf7#",
              "h6",
              "Bxe8",
              "Kh7",
              "Bxf7",
              "Rd8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "dxc3",
              "Qxc3",
              "Qxc3",
              "c2",
              "Qxc2+",
              "Kh3",
              "Qc3+",
              "Kg4",
              "Qc1+",
              "Kf5",
              "Qf1+",
              "Ke5",
              "Qe1+",
              "Kd5",
              "Qd1+",
              "Kc5",
              "Qc1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1+",
              "Ka5",
              "Qa1+",
              "Kb5",
              "Qb1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 146,
            "completion_tokens": 204,
            "total_tokens": 350,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 437,
          "total_completion_tokens": 1484,
          "total_tokens": 1921
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 146,
            "completion_tokens": 640,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 146,
            "completion_tokens": 204,
            "total_tokens": 350,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 9,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 145,
            "completion_tokens": 640,
            "total_tokens": 785,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n2n2/4p3/B3P3/5N2/PPPP1PPP/RNBQ1RK1 b kq - 3 5"
    },
    {
      "turn": 12,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "b5",
          "aggressive_uci": "b7b5",
          "aggressive_response": "6... b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Be7 10. Nbd2 Nc5 11. Bc2 d4 12. Nb3 d3 13. Bb1 Bf5 14. Be3 Nxb3 15. axb3 O-O 16. Nd4 Nxd4 17. cxd4 c5 18. Bxd3 Bxd3 19. Qxd3 cxd4 20. Qxd4 Qxd4 21. Bxd4 Rfd8 22. Rfd1 Rd5 23. Bc3 Rxd1+ 24. Rxd1 Rd8 25. Rxd8+ Bxd8 26. f4 Bb6+ 27. Kf1 Kf8 28. Ke2 Ke7 29. Kd3 Ke6 30. Ke4 g6 31. g4 Bg1 32. h3 Bb6 33. f5+ gxf5+ 34. gxf5+ Ke7 35. Kd5 Kd7 36. e6+ fxe6+ 37. fxe6+ Ke7 38. Bb4+ Ke8 39. Kc6 Bd4 40. Kb7 Bxb2 41. Kxa6 Bf6 42. Kxb5 Bd8 43. Kc6 Bf6 44. Bd6 Bd8 45. b4 Bf6 46. b5 Bd8 47. b6 Bxb6 48. Kxb6 Kd8 49. Kc6 Ke8 50. Kd5 Kd8 51. Ke5 Ke8 52. Kf6 Kd8 53. Kf7 Kc8 54. e7 Kb7 55. e8=Q Kb6 56. Qc8 Kb5 57. Qc5+ Ka6 58. Qb4 Ka7 59. Bc7 Ka6 60. Qb6# d3 d2 d1=Q",
          "aggressive_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 464,
            "total_tokens": 618,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd8",
            "b6",
            "Bxb6",
            "Kxb6",
            "Kd8",
            "Kc6",
            "Ke8",
            "Kd5",
            "Kd8",
            "Ke5",
            "Ke8",
            "Kf6",
            "Kd8",
            "Kf7",
            "Kc8",
            "e7",
            "Kb7",
            "e8=Q",
            "Kb6",
            "Qc8",
            "Kb5",
            "Qc5+",
            "Ka6",
            "Qb4",
            "Ka7",
            "Bc7",
            "Ka6",
            "Qb6#",
            "d3",
            "d2",
            "d1=Q"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b5",
          "positional_uci": "b7b5",
          "positional_response": "6... b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Be7 10. Nbd2 O-O 11. Bc2 f5 12. exf6 Nxf6 13. Re1 Bg4 14. h3 Bh5 15. Qe2 Qd7 16. Qe6+ Qxe6 17. Rxe6 Be8 18. Nb3 Bd7 19. Re1 Bd6 20. Be3 Rae8 21. Nc5 Bc8 22. Rad1 Ne5 23. Nxe5 Rxe5 24. Bd4 Rxe1+ 25. Rxe1 Kf7 26. b4 Re8 27. Rxe8 Nxe8 28. a4 Nf6 29. axb5 axb5 30. Bd3 c6 31. Nb3 Ne4 32. f3 Ng3 33. Kf2 Nf5 34. Bc5 Bg3+ 35. Ke2 Be5 36. Nd4 Nxd4+ 37. Bxd4 Bxd4 38. cxd4 g6 39. Ke3 Kf6 40. h4 Bf5 41. Be2 h6 42. g4 Bc2 43. f4 Be4 44. g5+ hxg5 45. fxg5+ Kf5 46. Bd1 Bb1 47. Kf3 Be4+ 48. Kg3 Bd3 49. Bg4+ Ke4 50. h5 gxh5 51. Bxh5 Kxd4 52. g6 Ke5 53. g7 Bh7 54. Bf7 Kd4 55. Kf4 Kc4 56. Ke5 Kxb4 57. Kd4 Ka3 58. Kc5 b4 59. Kxc6 b3 60. Bxd5 b2 61. g8=Q Bxg8 62. Bxg8 b1=Q 63. Bd5 Qb4 64. Kd7 Qc5 65. Ke6 Kb4 66. Ke5 Kc3 67. Ke4 Qd4+ 68. Kf5 Qxd5+ 69. Kf4 Kd4 70. Kg3 Qf5 71. Kg2 Ke3 72. Kg3 Qg5+ 73. Kh2 Kf2 74. Kh3 Qg3# e4 Nxe4 d4 b5 Bb3 d5 dxe5 Be6 Nbd2 O-O Bc2 f5 exf6 Nxf6 Re1 Bg4 h3 Bh5 Qe2 Qd7 Qe6+ Qxe6 Rxe6 Be8 Nb3 Bd7 Re1 Bd6 Nc",
          "positional_tokens": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "Nbd2",
            "O-O",
            "Bc2",
            "f5",
            "exf6",
            "Nxf6",
            "Re1",
            "Bg4",
            "h3",
            "Bh5",
            "Qe2",
            "Qd7",
            "Qe6+",
            "Qxe6",
            "Rxe6",
            "Be8",
            "Nb3",
            "Bd7",
            "Re1",
            "Bd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "b5",
          "neutral_uci": "b7b5",
          "neutral_response": "6... b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Be7 10. Nbd2 O-O 11. Bc2 f5 12. exf6 Nxf6 13. Re1 Bg4 14. h3 Bh5 15. g4 Bf7 16. Ng5 Bc5 17. Ndf3 Qd6 18. Kg2 Rae8 19. Rxe8 Bxe8 20. b4 Bb6 21. a4 h6 22. axb5 axb5 23. Qd3 hxg5 24. Nxg5 Ne5 25. Qg3 Ne4 26. Nxe4 dxe4 27. Bf4 Rxf4 28. Qxf4 Bc6 29. Bxe4 Bxe4+ 30. Qxe4 Qc6 31. Qxc6 Nxc6 32. f4 Kf7 33. Kf3 Ne7 34. Rd1 Ke6 35. Ke4 c6 36. f5+ Kf7 37. Rd7 Ke8 38. Rb7 Bf2 39. g5 Nd5 40. Rxg7 Nxc3+ 41. Ke5 Nd5 42. f6 Nxb4 43. g6 Nd3+ 44. Kd6 Bc5+ 45. Kxc6 Bd4 46. Rg8# 1-0\n46... Kf8 47. Rd8#",
          "neutral_tokens": {
            "prompt_tokens": 153,
            "completion_tokens": 349,
            "total_tokens": 502,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "c3",
            "Be7",
            "Nbd2",
            "O-O",
            "Bc2",
            "f5",
            "exf6",
            "Nxf6",
            "Re1",
            "Bg4",
            "h3",
            "Bh5",
            "g4",
            "Bf7",
            "Ng5",
            "Bc5",
            "Ndf3",
            "Qd6",
            "Kg2",
            "Rae8",
            "Rxe8",
            "Bxe8",
            "b4",
            "Bb6",
            "a4",
            "h6",
            "axb5",
            "axb5",
            "Qd3",
            "hxg5",
            "Nxg5",
            "Ne5",
            "Qg3",
            "Ne4",
            "Nxe4",
            "dxe4",
            "Bf4",
            "Rxf4",
            "Qxf4",
            "Bc6",
            "Bxe4",
            "Bxe4+",
            "Qxe4",
            "Qc6",
            "Qxc6",
            "Nxc6",
            "f4",
            "Kf7",
            "Kf3",
            "Ne7",
            "Rd1",
            "Ke6",
            "Ke4",
            "c6",
            "f5+",
            "Kf7",
            "Rd7",
            "Ke8",
            "Rb7",
            "Bf2",
            "g5",
            "Nd5",
            "Rxg7",
            "Nxc3+",
            "Ke5",
            "Nd5",
            "f6",
            "Nxb4",
            "g6",
            "Nd3+",
            "Kd6",
            "Bc5+",
            "Kxc6",
            "Bd4",
            "Rg8#",
            "Kf8",
            "Rd8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b7b5",
          "positional_uci": "b7b5",
          "neutral_uci": "b7b5",
          "consensus_move": "b7b5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd8",
              "b6",
              "Bxb6",
              "Kxb6",
              "Kd8",
              "Kc6",
              "Ke8",
              "Kd5",
              "Kd8",
              "Ke5",
              "Ke8",
              "Kf6",
              "Kd8",
              "Kf7",
              "Kc8",
              "e7",
              "Kb7",
              "e8=Q",
              "Kb6",
              "Qc8",
              "Kb5",
              "Qc5+",
              "Ka6",
              "Qb4",
              "Ka7",
              "Bc7",
              "Ka6",
              "Qb6#",
              "d3",
              "d2",
              "d1=Q"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "Nbd2",
              "O-O",
              "Bc2",
              "f5",
              "exf6",
              "Nxf6",
              "Re1",
              "Bg4",
              "h3",
              "Bh5",
              "Qe2",
              "Qd7",
              "Qe6+",
              "Qxe6",
              "Rxe6",
              "Be8",
              "Nb3",
              "Bd7",
              "Re1",
              "Bd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "c3",
              "Be7",
              "Nbd2",
              "O-O",
              "Bc2",
              "f5",
              "exf6",
              "Nxf6",
              "Re1",
              "Bg4",
              "h3",
              "Bh5",
              "g4",
              "Bf7",
              "Ng5",
              "Bc5",
              "Ndf3",
              "Qd6",
              "Kg2",
              "Rae8",
              "Rxe8",
              "Bxe8",
              "b4",
              "Bb6",
              "a4",
              "h6",
              "axb5",
              "axb5",
              "Qd3",
              "hxg5",
              "Nxg5",
              "Ne5",
              "Qg3",
              "Ne4",
              "Nxe4",
              "dxe4",
              "Bf4",
              "Rxf4",
              "Qxf4",
              "Bc6",
              "Bxe4",
              "Bxe4+",
              "Qxe4",
              "Qc6",
              "Qxc6",
              "Nxc6",
              "f4",
              "Kf7",
              "Kf3",
              "Ne7",
              "Rd1",
              "Ke6",
              "Ke4",
              "c6",
              "f5+",
              "Kf7",
              "Rd7",
              "Ke8",
              "Rb7",
              "Bf2",
              "g5",
              "Nd5",
              "Rxg7",
              "Nxc3+",
              "Ke5",
              "Nd5",
              "f6",
              "Nxb4",
              "g6",
              "Nd3+",
              "Kd6",
              "Bc5+",
              "Kxc6",
              "Bd4",
              "Rg8#",
              "Kf8",
              "Rd8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 154,
            "completion_tokens": 464,
            "total_tokens": 618,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 153,
            "completion_tokens": 349,
            "total_tokens": 502,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 461,
          "total_completion_tokens": 1453,
          "total_tokens": 1914
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 154,
            "completion_tokens": 464,
            "total_tokens": 618,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 154,
            "completion_tokens": 640,
            "total_tokens": 794,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 11,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 153,
            "completion_tokens": 349,
            "total_tokens": 502,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/1ppp1ppp/p1n5/4p3/B2Pn3/5N2/PPP2PPP/RNBQ1RK1 b kq - 0 6"
    },
    {
      "turn": 14,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d5",
          "aggressive_uci": "d7d5",
          "aggressive_response": "7... d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# d4 d5 Nxd5",
          "aggressive_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 186,
            "total_tokens": 348,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxd5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d5",
          "positional_uci": "d7d5",
          "positional_response": "7... d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxb2 29. Rxb2 Rxb2 30. h4 Kf7 31. h5 Kf6 32. Bg4 Ke5 33. Bd7 Kd6 34. Bf5 h6 35. Kd1 c5 36. Kc1 Rf2 37. Bg6 b4 38. cxb4 cxb4 39. Kb1 Kc5 40. Kc1 Kc4 41. Kb1 Kc3 42. Ka1 b3 43. Bb1 b2+ 44. Ka2 Rf1 45. Bg6 Ra1# 0-1\n45... Ra1#",
          "positional_tokens": {
            "prompt_tokens": 162,
            "completion_tokens": 335,
            "total_tokens": 497,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "dxe5",
            "Be6",
            "c3",
            "Bc5",
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxb2",
            "Rxb2",
            "Rxb2",
            "h4",
            "Kf7",
            "h5",
            "Kf6",
            "Bg4",
            "Ke5",
            "Bd7",
            "Kd6",
            "Bf5",
            "h6",
            "Kd1",
            "c5",
            "Kc1",
            "Rf2",
            "Bg6",
            "b4",
            "cxb4",
            "cxb4",
            "Kb1",
            "Kc5",
            "Kc1",
            "Kc4",
            "Kb1",
            "Kc3",
            "Ka1",
            "b3",
            "Bb1",
            "b2+",
            "Ka2",
            "Rf1",
            "Bg6",
            "Ra1#",
            "Ra1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d5",
          "neutral_uci": "d7d5",
          "neutral_response": "7... d5 8. dxe5 Be6 9. Nbd2 Nc5 10. c3 Be7 11. Bc2 d4 12. Nb3 d3 13. Bb1 Bf5 14. Be3 Nxb3 15. axb3 O-O 16. Nd4 Nxd4 17. cxd4 c5 18. Bxd3 Bxd3 19. Qxd3 cxd4 20. Qxd4 Qxd4 21. Bxd4 Rfd8 22. Rfd1 Rd5 23. Bc3 Rxd1+ 24. Rxd1 Rd8 25. Rxd8+ Bxd8 26. f4 Bb6+ 27. Kf1 Kf8 28. Ke2 Ke7 29. Kd3 Ke6 30. Ke4 g6 31. g4 Bg1 32. h3 Bb6 33. f5+ gxf5+ 34. gxf5+ Ke7 35. Kd5 Kd7 36. e6+ fxe6+ 37. fxe6+ Ke7 38. Bb4+ Ke8 39. Kc6 Bd4 40. Kb7 Bxb2 41. Kxa6 Bf6 42. Kxb5 Bd8 43. Kc6 Bf6 44. Bd6 Bd8 45. b4 Bf6 46. b5 Bd8 47. b6 Bxb6 48. Kxb6 Kd8 49. Kc6 Ke8 50. Kd5 Kd8 51. Ke5 Ke8 52. Kf6 Kd8 53. Kf7 Kc8 54. e7 Kb7 55. e8=Q Kb6 56. Qc8 Kb5 57. Qc5+ Ka6 58. Qb4 Ka7 59. Bc7 Ka6 60. Qb6# d5 d4 d3",
          "neutral_tokens": {
            "prompt_tokens": 161,
            "completion_tokens": 454,
            "total_tokens": 615,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d4",
            "d3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d7d5",
          "positional_uci": "d7d5",
          "neutral_uci": "d7d5",
          "consensus_move": "d7d5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxd5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "dxe5",
              "Be6",
              "c3",
              "Bc5",
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxb2",
              "Rxb2",
              "Rxb2",
              "h4",
              "Kf7",
              "h5",
              "Kf6",
              "Bg4",
              "Ke5",
              "Bd7",
              "Kd6",
              "Bf5",
              "h6",
              "Kd1",
              "c5",
              "Kc1",
              "Rf2",
              "Bg6",
              "b4",
              "cxb4",
              "cxb4",
              "Kb1",
              "Kc5",
              "Kc1",
              "Kc4",
              "Kb1",
              "Kc3",
              "Ka1",
              "b3",
              "Bb1",
              "b2+",
              "Ka2",
              "Rf1",
              "Bg6",
              "Ra1#",
              "Ra1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d4",
              "d3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 162,
            "completion_tokens": 186,
            "total_tokens": 348,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 162,
            "completion_tokens": 335,
            "total_tokens": 497,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 161,
            "completion_tokens": 454,
            "total_tokens": 615,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 485,
          "total_completion_tokens": 975,
          "total_tokens": 1460
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 162,
            "completion_tokens": 186,
            "total_tokens": 348,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 162,
            "completion_tokens": 335,
            "total_tokens": 497,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 13,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 161,
            "completion_tokens": 454,
            "total_tokens": 615,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/2pp1ppp/p1n5/1p2p3/3Pn3/1B3N2/PPP2PPP/RNBQ1RK1 b kq - 1 7"
    },
    {
      "turn": 16,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Be6",
          "aggressive_uci": "c8e6",
          "aggressive_response": "8... Be6 9. Nbd2 Nc5 10. c3 d4 11. Ng5 dxc3 12. Nxe6 Nxe6 13. bxc3 Nxe5 14. Qe2 Bd6 15. f4 Nc6 16. f5 O-O 17. fxe6 fxe6 18. Qxe6+ Kh8 19. Rxf8+ Qxf8 20. Ne4 Re8 21. Qd5 Ne7 22. Qd3 Nf5 23. Bd2 Qe7 24. Nxd6 Nxd6 25. Re1 Qd7 26. Rxe8+ Qxe8 27. Qe3 Qxe3+ 28. Bxe3 Nf5 29. Bf4 c5 30. Be6 Ne7 31. Bd6 Ng6 32. Bxc5 Nf4 33. Bc8 a5 34. Ba6 b4 35. cxb4 axb4 36. Bxb4 Nd5 37. Bd2 Nc7 38. Bc4 h6 39. a4 Kh7 40. a5 Kg6 41. a6 Kf6 42. a7 Ke7 43. Bf4 Na8 44. Bd5 Nb6 45. Be3 Nxd5 46. Bc5+ Kd7 47. a8=Q Nc7 48. Qb7 Kd8 49. Bb6 Ke8 50. Qxc7 Kf8 51. Bd4 Ke8 52. Bxg7 h5 53. Bf6 Kf8 54. Qe7+ Kg8 55. Qg7# e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 Nxe4 b5 Bb3 d5 dxe5 Be6 Nbd2 Nc5 c3 d4 Ng5 dxc3 Nxe6 Nxe6 bxc3 Nxe5 Qe2 Bd6 f4 Nc6 f5 Nc5 fxe6 Nxe6 Qxe6+ Kh8 Rxf8+ Qxf8 Ne4 Re8 Qd5 Ne7 Qd3 Nf5 Bd2 Qe7 Re1 Qe5 Nxd6 Qxe1+ Bxe1 Nxd6 Bg3 c5 Qxd6 c4 Be5 Rg8 Qe7 h6 Qf7 Kh7 Qf5+ Kh8 Qg6 a5 Qxh6#",
          "aggressive_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 569,
            "total_tokens": 740,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Nc5",
            "c3",
            "d4",
            "Ng5",
            "dxc3",
            "Nxe6",
            "Nxe6",
            "bxc3",
            "Nxe5",
            "Qe2",
            "Bd6",
            "f4",
            "Nc6",
            "f5",
            "Nc5",
            "fxe6",
            "Nxe6",
            "Qxe6+",
            "Kh8",
            "Rxf8+",
            "Qxf8",
            "Ne4",
            "Re8",
            "Qd5",
            "Ne7",
            "Qd3",
            "Nf5",
            "Bd2",
            "Qe7",
            "Re1",
            "Qe5",
            "Nxd6",
            "Qxe1+",
            "Bxe1",
            "Nxd6",
            "Bg3",
            "c5",
            "Qxd6",
            "c4",
            "Be5",
            "Rg8",
            "Qe7",
            "h6",
            "Qf7",
            "Kh7",
            "Qf5+",
            "Kh8",
            "Qg6",
            "a5",
            "Qxh6#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Be6",
          "positional_uci": "c8e6",
          "positional_response": "8... Be6 9. c3 Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxb2 29. Rxb2 Rxb2 30. h3 Kf7 31. Bg4 Kf6 32. Bd7 c5 33. Bc6 Ke5 34. Kd1 b4 35. cxb4 Rxb4 36. Kc2 Rh4 37. Bd7 Kd4 38. Kd2 c4 39. Kc2 Rf4 40. Kd2 Rf2+ 41. Ke1 Ke3 42. Bc6 c3 43. Bxd5 c2 44. Bb3 c1=Q+ 45. Bd1 Qd2# 0-1\n* 45... Qd2# 0-1",
          "positional_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 337,
            "total_tokens": 508,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "c3",
            "Bc5",
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxb2",
            "Rxb2",
            "Rxb2",
            "h3",
            "Kf7",
            "Bg4",
            "Kf6",
            "Bd7",
            "c5",
            "Bc6",
            "Ke5",
            "Kd1",
            "b4",
            "cxb4",
            "Rxb4",
            "Kc2",
            "Rh4",
            "Bd7",
            "Kd4",
            "Kd2",
            "c4",
            "Kc2",
            "Rf4",
            "Kd2",
            "Rf2+",
            "Ke1",
            "Ke3",
            "Bc6",
            "c3",
            "Bxd5",
            "c2",
            "Bb3",
            "c1=Q+",
            "Bd1",
            "Qd2#",
            "Qd2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Be6",
          "neutral_uci": "c8e6",
          "neutral_response": "8... Be6 9. Nbd2 Nc5 10. c3 Be7 11. Bc2 d4 12. Nb3 d3 13. Bb1 Bf5 14. Be3 Nxb3\n* 15. Qxb3 O-O 16. a4 Na5 17. Qd1 Nc4 18. Nd4 Nxe3 19. fxe3 Be4 20. Bxd3 Bxd3\n* 21. Qxd3 c5 22. axb5 cxd4 23. exd4 axb5 24. Qxb5 Rb8 25. Qe2 Qb6 26. b4 Bxb4\n* 27. cxb4 Qxd4+ 28. Kh1 Rxb4 29. e6 fxe6 30. Qxe6+ Kh8 31. Rxf8# Bc5 32. Qg8#\n* 32... Rxg8 33. Nf7#",
          "neutral_tokens": {
            "prompt_tokens": 170,
            "completion_tokens": 227,
            "total_tokens": 397,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "Nc5",
            "c3",
            "Be7",
            "Bc2",
            "d4",
            "Nb3",
            "d3",
            "Bb1",
            "Bf5",
            "Be3",
            "Nxb3",
            "Qxb3",
            "O-O",
            "a4",
            "Na5",
            "Qd1",
            "Nc4",
            "Nd4",
            "Nxe3",
            "fxe3",
            "Be4",
            "Bxd3",
            "Bxd3",
            "Qxd3",
            "c5",
            "axb5",
            "cxd4",
            "exd4",
            "axb5",
            "Qxb5",
            "Rb8",
            "Qe2",
            "Qb6",
            "b4",
            "Bxb4",
            "cxb4",
            "Qxd4+",
            "Kh1",
            "Rxb4",
            "e6",
            "fxe6",
            "Qxe6+",
            "Kh8",
            "Rxf8#",
            "Bc5",
            "Qg8#",
            "Rxg8",
            "Nf7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c8e6",
          "positional_uci": "c8e6",
          "neutral_uci": "c8e6",
          "consensus_move": "c8e6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd2",
              "Nc5",
              "c3",
              "d4",
              "Ng5",
              "dxc3",
              "Nxe6",
              "Nxe6",
              "bxc3",
              "Nxe5",
              "Qe2",
              "Bd6",
              "f4",
              "Nc6",
              "f5",
              "Nc5",
              "fxe6",
              "Nxe6",
              "Qxe6+",
              "Kh8",
              "Rxf8+",
              "Qxf8",
              "Ne4",
              "Re8",
              "Qd5",
              "Ne7",
              "Qd3",
              "Nf5",
              "Bd2",
              "Qe7",
              "Re1",
              "Qe5",
              "Nxd6",
              "Qxe1+",
              "Bxe1",
              "Nxd6",
              "Bg3",
              "c5",
              "Qxd6",
              "c4",
              "Be5",
              "Rg8",
              "Qe7",
              "h6",
              "Qf7",
              "Kh7",
              "Qf5+",
              "Kh8",
              "Qg6",
              "a5",
              "Qxh6#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "c3",
              "Bc5",
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxb2",
              "Rxb2",
              "Rxb2",
              "h3",
              "Kf7",
              "Bg4",
              "Kf6",
              "Bd7",
              "c5",
              "Bc6",
              "Ke5",
              "Kd1",
              "b4",
              "cxb4",
              "Rxb4",
              "Kc2",
              "Rh4",
              "Bd7",
              "Kd4",
              "Kd2",
              "c4",
              "Kc2",
              "Rf4",
              "Kd2",
              "Rf2+",
              "Ke1",
              "Ke3",
              "Bc6",
              "c3",
              "Bxd5",
              "c2",
              "Bb3",
              "c1=Q+",
              "Bd1",
              "Qd2#",
              "Qd2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd2",
              "Nc5",
              "c3",
              "Be7",
              "Bc2",
              "d4",
              "Nb3",
              "d3",
              "Bb1",
              "Bf5",
              "Be3",
              "Nxb3",
              "Qxb3",
              "O-O",
              "a4",
              "Na5",
              "Qd1",
              "Nc4",
              "Nd4",
              "Nxe3",
              "fxe3",
              "Be4",
              "Bxd3",
              "Bxd3",
              "Qxd3",
              "c5",
              "axb5",
              "cxd4",
              "exd4",
              "axb5",
              "Qxb5",
              "Rb8",
              "Qe2",
              "Qb6",
              "b4",
              "Bxb4",
              "cxb4",
              "Qxd4+",
              "Kh1",
              "Rxb4",
              "e6",
              "fxe6",
              "Qxe6+",
              "Kh8",
              "Rxf8#",
              "Bc5",
              "Qg8#",
              "Rxg8",
              "Nf7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 171,
            "completion_tokens": 569,
            "total_tokens": 740,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 171,
            "completion_tokens": 337,
            "total_tokens": 508,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 170,
            "completion_tokens": 227,
            "total_tokens": 397,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 512,
          "total_completion_tokens": 1133,
          "total_tokens": 1645
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 171,
            "completion_tokens": 569,
            "total_tokens": 740,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 171,
            "completion_tokens": 337,
            "total_tokens": 508,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 15,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 170,
            "completion_tokens": 227,
            "total_tokens": 397,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bqkb1r/2p2ppp/p1n5/1p1pP3/4n3/1B3N2/PPP2PPP/RNBQ1RK1 b kq - 0 8"
    },
    {
      "turn": 18,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bc5",
          "aggressive_uci": "f8c5",
          "aggressive_response": "9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Be2 c3 34. Kd1 Rd2+ 35. Ke1 Rxe2+ 36. Kxe2 h5 37. Kd3 h4 38. Kxc3 h3 39. Kd3 h2 40. Ke3 h1=Q 41. Kf2 Qh3 42. Ke2 Qg3 43. Kd2 Qf3 44. Kc2 Qe3 45. Kb2 Qd3 46. Ka2 Qc3 47. Kb1 Qd2 48. Ka1 c5 49. Kb1 c4 50. Ka1 c3 51. Kb1 Qb2# 0-1\n9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Be2 c3 34. Kd1 Rd2+ 35. Ke1 Rxe2+ 36. Kxe2 h5 37. Kd3 h4 38. Kxc3 h3 39. Kd3 h2 40. Ke3 h1=Q 41. Kf2 Qh3",
          "aggressive_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxh2",
            "b3",
            "Rb2",
            "Rxb2",
            "Rxb2",
            "c4",
            "bxc4",
            "bxc4",
            "dxc4",
            "Be2",
            "c3",
            "Kd1",
            "Rd2+",
            "Ke1",
            "Rxe2+",
            "Kxe2",
            "h5",
            "Kd3",
            "h4",
            "Kxc3",
            "h3",
            "Kd3",
            "h2",
            "Ke3",
            "h1=Q",
            "Kf2",
            "Qh3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bc5",
          "positional_uci": "f8c5",
          "positional_response": "9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Be2 c3 34. Kd1 Rd2+ 35. Ke1 Rxe2+ 36. Kxe2 h5 37. Kd3 h4 38. Kxc3 h3 39. Kd3 h2 40. Ke3 h1=Q 41. Kf2 Qe4 42. Kg3 c5 43. Kf2 c4 44. Kg3 c3 45. Kf2 c2 46. Kg3 c1=Q 47. Kf2 Qcf4+ 48. Kg1 Qg6+ 49. Kh1 Qfh6# e4 d5 c4",
          "positional_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 351,
            "total_tokens": 529,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxh2",
            "b3",
            "Rb2",
            "Rxb2",
            "Rxb2",
            "c4",
            "bxc4",
            "bxc4",
            "dxc4",
            "Be2",
            "c3",
            "Kd1",
            "Rd2+",
            "Ke1",
            "Rxe2+",
            "Kxe2",
            "h5",
            "Kd3",
            "h4",
            "Kxc3",
            "h3",
            "Kd3",
            "h2",
            "Ke3",
            "h1=Q",
            "Kf2",
            "Qe4",
            "Kg3",
            "c5",
            "Kf2",
            "c4",
            "Kg3",
            "c3",
            "Kf2",
            "c2",
            "Kg3",
            "c1=Q",
            "Kf2",
            "Qcf4+",
            "Kg1",
            "Qg6+",
            "Kh1",
            "Qfh6#",
            "e4",
            "d5",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bc5",
          "neutral_uci": "f8c5",
          "neutral_response": "9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Be2 c3 34. Kd1 Rd2+ 35. Ke1 Rxe2+ 36. Kxe2 h5 37. Kd3 h4 38. Kxc3 h3 39. Kd3 h2 40. Ke3 h1=Q 41. Kf2 Qh3 42. Ke2 Qg3 43. Kd2 Qf3 44. Kc2 Qe3 45. Kb2 Qd3 46. Ka2 Qc3 47. Kb1 Qd2 48. Ka1 c5 49. Kb1 c4 50. Ka1 c3 51. Kb1 Qb2# 0-1\n9... Bc5 10. Nbd2 O-O 11. Bc2 Nxf2 12. Rxf2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Bxf3 20. Bxf6 Bxd1 21. Rxd1 Rxf6 22. Bb3 c6 23. a4 Re2 24. axb5 axb5 25. Rb1 Rff2 26. Bd1 Rxg2+ 27. Kf1 Ref2+ 28. Ke1 Rxh2 29. b3 Rb2 30. Rxb2 Rxb2 31. c4 bxc4 32. bxc4 dxc4 33. Be2 c3 34. Kd1 Rd2+ 35. Ke1 Rxe2+ 36. Kxe2 h5 37. Kd3 h4 38. Kxc3 h3 39. Kd3 h2 40. Ke3 h1=Q 41. Kf2 Qh3",
          "neutral_tokens": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nbd2",
            "O-O",
            "Bc2",
            "Nxf2",
            "Rxf2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Bxf3",
            "Bxf6",
            "Bxd1",
            "Rxd1",
            "Rxf6",
            "Bb3",
            "c6",
            "a4",
            "Re2",
            "axb5",
            "axb5",
            "Rb1",
            "Rff2",
            "Bd1",
            "Rxg2+",
            "Kf1",
            "Ref2+",
            "Ke1",
            "Rxh2",
            "b3",
            "Rb2",
            "Rxb2",
            "Rxb2",
            "c4",
            "bxc4",
            "bxc4",
            "dxc4",
            "Be2",
            "c3",
            "Kd1",
            "Rd2+",
            "Ke1",
            "Rxe2+",
            "Kxe2",
            "h5",
            "Kd3",
            "h4",
            "Kxc3",
            "h3",
            "Kd3",
            "h2",
            "Ke3",
            "h1=Q",
            "Kf2",
            "Qh3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8c5",
          "positional_uci": "f8c5",
          "neutral_uci": "f8c5",
          "consensus_move": "f8c5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxh2",
              "b3",
              "Rb2",
              "Rxb2",
              "Rxb2",
              "c4",
              "bxc4",
              "bxc4",
              "dxc4",
              "Be2",
              "c3",
              "Kd1",
              "Rd2+",
              "Ke1",
              "Rxe2+",
              "Kxe2",
              "h5",
              "Kd3",
              "h4",
              "Kxc3",
              "h3",
              "Kd3",
              "h2",
              "Ke3",
              "h1=Q",
              "Kf2",
              "Qh3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxh2",
              "b3",
              "Rb2",
              "Rxb2",
              "Rxb2",
              "c4",
              "bxc4",
              "bxc4",
              "dxc4",
              "Be2",
              "c3",
              "Kd1",
              "Rd2+",
              "Ke1",
              "Rxe2+",
              "Kxe2",
              "h5",
              "Kd3",
              "h4",
              "Kxc3",
              "h3",
              "Kd3",
              "h2",
              "Ke3",
              "h1=Q",
              "Kf2",
              "Qe4",
              "Kg3",
              "c5",
              "Kf2",
              "c4",
              "Kg3",
              "c3",
              "Kf2",
              "c2",
              "Kg3",
              "c1=Q",
              "Kf2",
              "Qcf4+",
              "Kg1",
              "Qg6+",
              "Kh1",
              "Qfh6#",
              "e4",
              "d5",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nbd2",
              "O-O",
              "Bc2",
              "Nxf2",
              "Rxf2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Bxf3",
              "Bxf6",
              "Bxd1",
              "Rxd1",
              "Rxf6",
              "Bb3",
              "c6",
              "a4",
              "Re2",
              "axb5",
              "axb5",
              "Rb1",
              "Rff2",
              "Bd1",
              "Rxg2+",
              "Kf1",
              "Ref2+",
              "Ke1",
              "Rxh2",
              "b3",
              "Rb2",
              "Rxb2",
              "Rxb2",
              "c4",
              "bxc4",
              "bxc4",
              "dxc4",
              "Be2",
              "c3",
              "Kd1",
              "Rd2+",
              "Ke1",
              "Rxe2+",
              "Kxe2",
              "h5",
              "Kd3",
              "h4",
              "Kxc3",
              "h3",
              "Kd3",
              "h2",
              "Ke3",
              "h1=Q",
              "Kf2",
              "Qh3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 178,
            "completion_tokens": 351,
            "total_tokens": 529,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 533,
          "total_completion_tokens": 1631,
          "total_tokens": 2164
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 178,
            "completion_tokens": 351,
            "total_tokens": 529,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 17,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 177,
            "completion_tokens": 640,
            "total_tokens": 817,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2qkb1r/2p2ppp/p1n1b3/1p1pP3/4n3/1BP2N2/PP3PPP/RNBQ1RK1 b kq - 0 9"
    },
    {
      "turn": 20,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxf2",
          "aggressive_uci": "e4f2",
          "aggressive_response": "10... Nxf2 11. Rxf2 O-O 12. Nf1 Bxf2+ 13. Kxf2 f6 14. exf6 Qxf6 15. Be3 Ne5 16. Kg1 Nxf3+ 17. Qxf3 Qxf3 18. gxf3 Rxf3 19. Re1 c6 20. Bd1 Rf6 21. Bd4 Rg6+ 22. Ng3 Re8 23. Bh5 Bf7 24. Rxe8+ Bxe8 25. Bxg6 Bxg6 26. Kf2 Kf7 27. Ke3 Bb1 28. a3 g6 29. Kf4 Ke6 30. Kg5 Kd6 31. b4 Ke6 32. Kh6 Kf7 33. Kxh7 g5+ 34. Kh6 g4 35. Kg5 Ke6 36. Kxg4 Kf7 37. h4 Kg6 38. h5+ Kh6 39. Be3+ Kh7 40. Kg5 Kg7 41. h6+ Kh7 42. Nh5 Bg6 43. Nf6+ Kh8 44. Kxg6 d4 45. Bxd4 c5 46. Bxc5 a5 47. Bf8 axb4 48. Bg7# Nxf7 49. Kxf7 bxa3 50. Bf8 a2 51. Bg7# Nxf7 52. Kxf7 b4 53. cxb4 a1=Q 54. Bxa1# Nxf7 55. Kxf7# Nxf7 56. Kxf7# Nxf7 57. Kxf7# Nxf7",
          "aggressive_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 408,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf2",
            "O-O",
            "Nf1",
            "Bxf2+",
            "Kxf2",
            "f6",
            "exf6",
            "Qxf6",
            "Be3",
            "Ne5",
            "Kg1",
            "Nxf3+",
            "Qxf3",
            "Qxf3",
            "gxf3",
            "Rxf3",
            "Re1",
            "c6",
            "Bd1",
            "Rf6",
            "Bd4",
            "Rg6+",
            "Ng3",
            "Re8",
            "Bh5",
            "Bf7",
            "Rxe8+",
            "Bxe8",
            "Bxg6",
            "Bxg6",
            "Kf2",
            "Kf7",
            "Ke3",
            "Bb1",
            "a3",
            "g6",
            "Kf4",
            "Ke6",
            "Kg5",
            "Kd6",
            "b4",
            "Ke6",
            "Kh6",
            "Kf7",
            "Kxh7",
            "g5+",
            "Kh6",
            "g4",
            "Kg5",
            "Ke6",
            "Kxg4",
            "Kf7",
            "h4",
            "Kg6",
            "h5+",
            "Kh6",
            "Be3+",
            "Kh7",
            "Kg5",
            "Kg7",
            "h6+",
            "Kh7",
            "Nh5",
            "Bg6",
            "Nf6+",
            "Kh8",
            "Kxg6",
            "d4",
            "Bxd4",
            "c5",
            "Bxc5",
            "a5",
            "Bf8",
            "axb4",
            "Bg7#",
            "Nxf7",
            "Kxf7",
            "bxa3",
            "Bf8",
            "a2",
            "Bg7#",
            "Nxf7",
            "Kxf7",
            "b4",
            "cxb4",
            "a1=Q",
            "Bxa1#",
            "Nxf7",
            "Kxf7#",
            "Nxf7",
            "Kxf7#",
            "Nxf7",
            "Kxf7#",
            "Nxf7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxf2",
          "positional_uci": "e4f2",
          "positional_response": "10... Nxf2 11. Rxf2 O-O 12. Bc2 Bxf2+ 13. Kxf2 f6 14. exf6 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Qb6 19. Kh1 c5 20. Nb3 Nxf3 21. Qxd5+ Kh8 22. gxf3 Bxf3+ 23. Qxf3 Rxf3 24. Rg1 Qc6 25. Rg2 Rf1# 0-1\n10 Nxf2 11 Rxf2 O-O 12 Bc2 Bxf2+ 13 Kxf2 f6 14 exf6 Qxf6 15 Kg1 Rae8 16 Nb3 Ne5 17 Nbd4 Bg4 18 Bg5 Qb6 19 Kh1 c5 20 Nb3 Nxf3 21 Qxd5+ Kh8 22 gxf3 Bxf3+ 23 Qxf3 Rxf3 24 Rg1 Qc6 25 Rg2 Rf1# 0-1",
          "positional_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 262,
            "total_tokens": 449,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf2",
            "O-O",
            "Bc2",
            "Bxf2+",
            "Kxf2",
            "f6",
            "exf6",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Qb6",
            "Kh1",
            "c5",
            "Nb3",
            "Nxf3",
            "Qxd5+",
            "Kh8",
            "gxf3",
            "Bxf3+",
            "Qxf3",
            "Rxf3",
            "Rg1",
            "Qc6",
            "Rg2",
            "Rf1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxf2",
          "neutral_uci": "e4f2",
          "neutral_response": "10... Nxf2 11. Rxf2 O-O 12. Bc2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# 0-1\n10... Nxf2 11. Rxf2 O-O 12. Bc2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# 0-1\n10... Nxf2 11. Rxf2 O-O 12. Bc2 f6 13. exf6 Bxf2+ 14. Kxf2 Qxf6 15. Kg1 Rae8 16. Nb3 Ne5 17. Nbd4 Bg4 18. Bg5 Nxf3+ 19. Nxf3 Qb6+ 20. Kh1 Qf2 21. Qxd5+ Kh8 22. Qd3 Bf5 23. Qd2 Re2 24. Qxe2 Qxe2 25. Bxf5 Rxf5 26. Re1 Qxe1+ 27. Nxe1 Rf1# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 186,
            "completion_tokens": 477,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf2",
            "O-O",
            "Bc2",
            "f6",
            "exf6",
            "Bxf2+",
            "Kxf2",
            "Qxf6",
            "Kg1",
            "Rae8",
            "Nb3",
            "Ne5",
            "Nbd4",
            "Bg4",
            "Bg5",
            "Nxf3+",
            "Nxf3",
            "Qb6+",
            "Kh1",
            "Qf2",
            "Qxd5+",
            "Kh8",
            "Qd3",
            "Bf5",
            "Qd2",
            "Re2",
            "Qxe2",
            "Qxe2",
            "Bxf5",
            "Rxf5",
            "Re1",
            "Qxe1+",
            "Nxe1",
            "Rf1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4f2",
          "positional_uci": "e4f2",
          "neutral_uci": "e4f2",
          "consensus_move": "e4f2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxf2",
              "O-O",
              "Nf1",
              "Bxf2+",
              "Kxf2",
              "f6",
              "exf6",
              "Qxf6",
              "Be3",
              "Ne5",
              "Kg1",
              "Nxf3+",
              "Qxf3",
              "Qxf3",
              "gxf3",
              "Rxf3",
              "Re1",
              "c6",
              "Bd1",
              "Rf6",
              "Bd4",
              "Rg6+",
              "Ng3",
              "Re8",
              "Bh5",
              "Bf7",
              "Rxe8+",
              "Bxe8",
              "Bxg6",
              "Bxg6",
              "Kf2",
              "Kf7",
              "Ke3",
              "Bb1",
              "a3",
              "g6",
              "Kf4",
              "Ke6",
              "Kg5",
              "Kd6",
              "b4",
              "Ke6",
              "Kh6",
              "Kf7",
              "Kxh7",
              "g5+",
              "Kh6",
              "g4",
              "Kg5",
              "Ke6",
              "Kxg4",
              "Kf7",
              "h4",
              "Kg6",
              "h5+",
              "Kh6",
              "Be3+",
              "Kh7",
              "Kg5",
              "Kg7",
              "h6+",
              "Kh7",
              "Nh5",
              "Bg6",
              "Nf6+",
              "Kh8",
              "Kxg6",
              "d4",
              "Bxd4",
              "c5",
              "Bxc5",
              "a5",
              "Bf8",
              "axb4",
              "Bg7#",
              "Nxf7",
              "Kxf7",
              "bxa3",
              "Bf8",
              "a2",
              "Bg7#",
              "Nxf7",
              "Kxf7",
              "b4",
              "cxb4",
              "a1=Q",
              "Bxa1#",
              "Nxf7",
              "Kxf7#",
              "Nxf7",
              "Kxf7#",
              "Nxf7",
              "Kxf7#",
              "Nxf7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxf2",
              "O-O",
              "Bc2",
              "Bxf2+",
              "Kxf2",
              "f6",
              "exf6",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Qb6",
              "Kh1",
              "c5",
              "Nb3",
              "Nxf3",
              "Qxd5+",
              "Kh8",
              "gxf3",
              "Bxf3+",
              "Qxf3",
              "Rxf3",
              "Rg1",
              "Qc6",
              "Rg2",
              "Rf1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxf2",
              "O-O",
              "Bc2",
              "f6",
              "exf6",
              "Bxf2+",
              "Kxf2",
              "Qxf6",
              "Kg1",
              "Rae8",
              "Nb3",
              "Ne5",
              "Nbd4",
              "Bg4",
              "Bg5",
              "Nxf3+",
              "Nxf3",
              "Qb6+",
              "Kh1",
              "Qf2",
              "Qxd5+",
              "Kh8",
              "Qd3",
              "Bf5",
              "Qd2",
              "Re2",
              "Qxe2",
              "Qxe2",
              "Bxf5",
              "Rxf5",
              "Re1",
              "Qxe1+",
              "Nxe1",
              "Rf1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 187,
            "completion_tokens": 408,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 187,
            "completion_tokens": 262,
            "total_tokens": 449,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 186,
            "completion_tokens": 477,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 560,
          "total_completion_tokens": 1147,
          "total_tokens": 1707
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 187,
            "completion_tokens": 408,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 187,
            "completion_tokens": 262,
            "total_tokens": 449,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 19,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 186,
            "completion_tokens": 477,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/4n3/1BP2N2/PP1N1PPP/R1BQ1RK1 b kq - 2 10"
    },
    {
      "turn": 22,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf2+",
          "aggressive_uci": "c5f2",
          "aggressive_response": "11... Bxf2+ 12. Kxf2 O-O 13. Nf1 Qd7 14. Ne3 Rad8 15. Bc2 d4 16. cxd4 Nxd4 17. Nxd4 Qxd4 18. Qxd4 Rxd4 19. b3 Rfd8 20. Ke2 c5 21. Nf1 c4 22. Be3 R4d7 23. b4 c3 24. Bb6 Rb8 25. Bc5 Bc4+ 26. Ke3 Re8 27. Kf4 f6 28. exf6 Rf7 29. Bd4 gxf6 30. Ne3 Rd8 31. Bxc3 Bd3 32. Bb3 Bc4 33. Nxc4 bxc4 34. Bxc4 Rc8 35. Bxf7+ Kxf7 36. Rc1 Rc4+ 37. Ke3 Ke6 38. Kd3 Rg4 39. g3 h5 40. Re1+ Kf7 41. Re4 Rg5 42. Rf4 Rd5+ 43. Kc4 Rd6 44. Rxf6+ Rxf6 45. Bxf6 Kxf6 46. a4 Ke6 47. b5 axb5+ 48. axb5 Kd6 49. h3 Kc7 50. g4 hxg4 51. hxg4 Kb6 52. g5 Kc7 53. g6 Kd7 54. g7 Ke7 55. g8=Q Kd7 56. Qg6 Kc7 57. Kc5 Kb7 58. Qf7+ Kc8 59. Kc6 Kd8 60. Qd7# Bxf7 61. Kxf7 Kc7 62. g4 Kb6 63. g5 Kxb5 64. g6 Kc6 65. g7 Kd7 66. g8=Q Kd6 67. Qg5 Kd7 68. Qd5+ Kc7 69. Ke7 Kb6 70. Kd7 Ka6 71. Qb3 Ka5 72. Kc6 Ka6 73. Qa4# Kxb7 74. Qb5+ Kc8 75. Qb7+ Kd8 76. Qd7# Kxd7 77. Kd5 Kc7 78. Kc5 Kd7 79. Kd5 Kc7 80. Kc5 Kd7 81. Kd5 Kc7 82. Kc5 Kd7 83. Kd5 Kc7 84. Kc5 Kd7 85. Kd5 Kc7",
          "aggressive_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxf2",
            "O-O",
            "Nf1",
            "Qd7",
            "Ne3",
            "Rad8",
            "Bc2",
            "d4",
            "cxd4",
            "Nxd4",
            "Nxd4",
            "Qxd4",
            "Qxd4",
            "Rxd4",
            "b3",
            "Rfd8",
            "Ke2",
            "c5",
            "Nf1",
            "c4",
            "Be3",
            "R4d7",
            "b4",
            "c3",
            "Bb6",
            "Rb8",
            "Bc5",
            "Bc4+",
            "Ke3",
            "Re8",
            "Kf4",
            "f6",
            "exf6",
            "Rf7",
            "Bd4",
            "gxf6",
            "Ne3",
            "Rd8",
            "Bxc3",
            "Bd3",
            "Bb3",
            "Bc4",
            "Nxc4",
            "bxc4",
            "Bxc4",
            "Rc8",
            "Bxf7+",
            "Kxf7",
            "Rc1",
            "Rc4+",
            "Ke3",
            "Ke6",
            "Kd3",
            "Rg4",
            "g3",
            "h5",
            "Re1+",
            "Kf7",
            "Re4",
            "Rg5",
            "Rf4",
            "Rd5+",
            "Kc4",
            "Rd6",
            "Rxf6+",
            "Rxf6",
            "Bxf6",
            "Kxf6",
            "a4",
            "Ke6",
            "b5",
            "axb5+",
            "axb5",
            "Kd6",
            "h3",
            "Kc7",
            "g4",
            "hxg4",
            "hxg4",
            "Kb6",
            "g5",
            "Kc7",
            "g6",
            "Kd7",
            "g7",
            "Ke7",
            "g8=Q",
            "Kd7",
            "Qg6",
            "Kc7",
            "Kc5",
            "Kb7",
            "Qf7+",
            "Kc8",
            "Kc6",
            "Kd8",
            "Qd7#",
            "Bxf7",
            "Kxf7",
            "Kc7",
            "g4",
            "Kb6",
            "g5",
            "Kxb5",
            "g6",
            "Kc6",
            "g7",
            "Kd7",
            "g8=Q",
            "Kd6",
            "Qg5",
            "Kd7",
            "Qd5+",
            "Kc7",
            "Ke7",
            "Kb6",
            "Kd7",
            "Ka6",
            "Qb3",
            "Ka5",
            "Kc6",
            "Ka6",
            "Qa4#",
            "Kxb7",
            "Qb5+",
            "Kc8",
            "Qb7+",
            "Kd8",
            "Qd7#",
            "Kxd7",
            "Kd5",
            "Kc7",
            "Kc5",
            "Kd7",
            "Kd5",
            "Kc7",
            "Kc5",
            "Kd7",
            "Kd5",
            "Kc7",
            "Kc5",
            "Kd7",
            "Kd5",
            "Kc7",
            "Kc5",
            "Kd7",
            "Kd5",
            "Kc7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf2+",
          "positional_uci": "c5f2",
          "positional_response": "Repeated moves: 1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 * Next moves: 11... Bxf2+ 12. Kxf2 O-O 13. Kg1",
          "positional_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 114,
            "total_tokens": 310,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxf2",
            "O-O",
            "Kg1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf2+",
          "neutral_uci": "c5f2",
          "neutral_response": "11... Bxf2+ 12. Kxf2 O-O 13. Nf1 Qd7 14. Ne3 Rad8 15. Nc2 Bg4 16. Bf4 Na5 17. Ne3 Nxb3 18. axb3 Bxf3 19. Qxf3 d4 20. Rd1 dxe3+ 21. Bxe3 Qxd1 22. Qxd1 Rxd1 23. Ke2 Rb1 24. Kd3 Rxb2 25. b4 Rxg2 26. Bf4 Rd8+ 27. Ke4 Rc2 28. Kf5 Rxc3 29. e6 fxe6+ 30. Kxe6 Rc4 31. Bg5 Re8+ 32. Kd7 Re5 33. Bd8 Rd5+ 34. Kc8 Rxd8+ 35. Kxd8 Rxb4 36. Kxc7 a5 37. Kb6 a4 38. Ka5 Rb3 39. Kb6 a3 40. Kc5 a2 41. Kd4 a1=Q+ 42. Kc5 Qc3+ 43. Kb6 Qd4+ 44. Ka5 Ra3+ 45. Kxb5 Rb3+ 46. Kc6 Rc3+ 47. Kb5 Qc4+ 48. Kb6 Rb3+ 49. Ka5 Qb5# 0-1\nBxf2+ O-O Qd7",
          "neutral_tokens": {
            "prompt_tokens": 195,
            "completion_tokens": 347,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Qd7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c5f2",
          "positional_uci": "c5f2",
          "neutral_uci": "c5f2",
          "consensus_move": "c5f2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxf2",
              "O-O",
              "Nf1",
              "Qd7",
              "Ne3",
              "Rad8",
              "Bc2",
              "d4",
              "cxd4",
              "Nxd4",
              "Nxd4",
              "Qxd4",
              "Qxd4",
              "Rxd4",
              "b3",
              "Rfd8",
              "Ke2",
              "c5",
              "Nf1",
              "c4",
              "Be3",
              "R4d7",
              "b4",
              "c3",
              "Bb6",
              "Rb8",
              "Bc5",
              "Bc4+",
              "Ke3",
              "Re8",
              "Kf4",
              "f6",
              "exf6",
              "Rf7",
              "Bd4",
              "gxf6",
              "Ne3",
              "Rd8",
              "Bxc3",
              "Bd3",
              "Bb3",
              "Bc4",
              "Nxc4",
              "bxc4",
              "Bxc4",
              "Rc8",
              "Bxf7+",
              "Kxf7",
              "Rc1",
              "Rc4+",
              "Ke3",
              "Ke6",
              "Kd3",
              "Rg4",
              "g3",
              "h5",
              "Re1+",
              "Kf7",
              "Re4",
              "Rg5",
              "Rf4",
              "Rd5+",
              "Kc4",
              "Rd6",
              "Rxf6+",
              "Rxf6",
              "Bxf6",
              "Kxf6",
              "a4",
              "Ke6",
              "b5",
              "axb5+",
              "axb5",
              "Kd6",
              "h3",
              "Kc7",
              "g4",
              "hxg4",
              "hxg4",
              "Kb6",
              "g5",
              "Kc7",
              "g6",
              "Kd7",
              "g7",
              "Ke7",
              "g8=Q",
              "Kd7",
              "Qg6",
              "Kc7",
              "Kc5",
              "Kb7",
              "Qf7+",
              "Kc8",
              "Kc6",
              "Kd8",
              "Qd7#",
              "Bxf7",
              "Kxf7",
              "Kc7",
              "g4",
              "Kb6",
              "g5",
              "Kxb5",
              "g6",
              "Kc6",
              "g7",
              "Kd7",
              "g8=Q",
              "Kd6",
              "Qg5",
              "Kd7",
              "Qd5+",
              "Kc7",
              "Ke7",
              "Kb6",
              "Kd7",
              "Ka6",
              "Qb3",
              "Ka5",
              "Kc6",
              "Ka6",
              "Qa4#",
              "Kxb7",
              "Qb5+",
              "Kc8",
              "Qb7+",
              "Kd8",
              "Qd7#",
              "Kxd7",
              "Kd5",
              "Kc7",
              "Kc5",
              "Kd7",
              "Kd5",
              "Kc7",
              "Kc5",
              "Kd7",
              "Kd5",
              "Kc7",
              "Kc5",
              "Kd7",
              "Kd5",
              "Kc7",
              "Kc5",
              "Kd7",
              "Kd5",
              "Kc7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxf2",
              "O-O",
              "Kg1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Qd7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 196,
            "completion_tokens": 114,
            "total_tokens": 310,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 195,
            "completion_tokens": 347,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 587,
          "total_completion_tokens": 1101,
          "total_tokens": 1688
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 196,
            "completion_tokens": 640,
            "total_tokens": 836,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 196,
            "completion_tokens": 114,
            "total_tokens": 310,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 21,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 195,
            "completion_tokens": 347,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1pbpP3/8/1BP2N2/PP1N1RPP/R1BQ2K1 b kq - 0 11"
    },
    {
      "turn": 24,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e8g8",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 O-O 13. Nf1 Qd7 14. Be3 Rad8\n15. Bc5 Rfe8 16. Ng3 Bg4 17. Bd4 Nxe5 18. Bxe5 Rxe5 19. Nxe5 Bxd1 20. Nxd7 Bxb3\n21. axb3 Rxd7 22. Rxa6 g6 23. Rc6 d4 24. cxd4 Rxd4 25. Rxc7 Rd2+ 26. Kf3 Rxb2\n27. Rc3 b4 28. Rd3 Kg7 29. Ne4 f5 30. Nc5 Kf6 31. Rd6+ Ke5 32. Rd7 h5 33. Nd3+ Ke6\n34. Nxb2 Kxd7 35. Nd3 Kd6 36. Nxb4 Kc5 37. Nd3+ Kd4 38. Nf4 Kc3 39. Nxg6 Kxb3\n40. Kf4 Kc4 41. Kxf5 Kd5 42. Kg5 Ke6 43. Kxh5 Kf7 44. Kh6 Kg8 45. g4 Kf7 46. Kh7\nKf6 47. h4 Kf7 48. g5 Ke6 49. Kg7 Kf5 50. Kf7 Kg4 51. Kf6 Kh5 52. Nf4+ Kxh4\n53. g6 Kg4 54. g7 Kxf4 55. g8=Q Ke4 56. Qg5 Kd4 57. Qe5+ Kc4 58. Ke6 Kd3\n59. Kd5 Kc2 60. Qd4 Kb3 61. Qc4+ Kb2 62. Kd4 Ka3 63. Qb5 Ka2 64. Kc3 Ka1 65. Qb2# Kd1 66. Qd2# 1-0\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. R",
          "aggressive_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe4",
            "d4",
            "b5",
            "Bb3",
            "d5",
            "dxe5",
            "Be6",
            "c3",
            "Bc5",
            "Nbd2",
            "Nxf2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "f6",
          "positional_uci": "f7f6",
          "positional_response": "12... f6 13. exf6 Qxf6 14. Nf1 O-O-O 15. Bg5 Qf7 16. Bxd8 Rxd8 17. Kg1 h6 18. a4 b4 19. Qd3 Kb7 20. Re1 Bf5 21. Qd2 Be4 22. Nd4 Nxd4 23. Qxd4 Qg6 24. Ng3 bxc3 25. bxc3 Re8 26. Bxd5+ Bxd5 27. Qxd5+ c6 28. Qd7+ Kb6 29. Qxe8 Qd3 30. Qe3+ Qxe3+ 31. Rxe3 Kc5 32. Re4 Kd5 33. Kf2 c5 34. Ke3 c4 35. Nf5 g6 36. Ne7+ Kd6 37. Nxg6 Kd5 38. Nf4+ Kd6 39. Kd4 Kc6 40. Re6+ Kd7 41. Kd5 Kc7 42. Re7+ Kb6 43. Ne6 Ka5 44. Kc5 Kxa4 45. Kxc4 Ka3 46. Ra7 Kb2 47. Rxa6 Kc2 48. Ra2+ Kd1 49. Kd3 Ke1 50. Ke3 Kd1 51. Nd4 Kc1 52. Kd3 Kb1 53. Rf2 Ka1 54. Kc4 Kb1 55. Kb3 Kc1 56. c4 Kd1 57. Kc3 Ke1 58. Re2+ Kf1 59. Kd3 Kg1 60. Ke3 Kxh2 61. Kf3 Kg1 62. g4 Kh1 63. Kg3 Kg1 64. Re1# fxe1=Q+ 65. Kf3 Qf2+ 66. Ke4 Qg2+ 67. Kf4 Qxh2+ 68. Kf5 Qf2+ 69. Ke4 Qg2+ 70. Kf5 Qd5+ 71. Kf4 Qc4 72. Ke4 Qxc3 73. Nf3+ Kf2 74. Nd4 Qe3+ 75. Kd5 Qg5+ 76. Ke4 Qxg4+ 77. Kd5 Qd7+ 78. Ke4 Qxa4 79. Kd5 Qxd4+ 80. Kxd4 h5 81. Ke4 h4 82. Kf4 h3 83. Kg4 h2 84. Kf4 h1=Q 85. Ke5 Qh4 86. Kd",
          "positional_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "exf6",
            "Qxf6",
            "Nf1",
            "O-O-O",
            "Bg5",
            "Qf7",
            "Bxd8",
            "Rxd8",
            "Kg1",
            "h6",
            "a4",
            "b4",
            "Qd3",
            "Kb7",
            "Re1",
            "Bf5",
            "Qd2",
            "Be4",
            "Nd4",
            "Nxd4",
            "Qxd4",
            "Qg6",
            "Ng3",
            "bxc3",
            "bxc3",
            "Re8",
            "Bxd5+",
            "Bxd5",
            "Qxd5+",
            "c6",
            "Qd7+",
            "Kb6",
            "Qxe8",
            "Qd3",
            "Qe3+",
            "Qxe3+",
            "Rxe3",
            "Kc5",
            "Re4",
            "Kd5",
            "Kf2",
            "c5",
            "Ke3",
            "c4",
            "Nf5",
            "g6",
            "Ne7+",
            "Kd6",
            "Nxg6",
            "Kd5",
            "Nf4+",
            "Kd6",
            "Kd4",
            "Kc6",
            "Re6+",
            "Kd7",
            "Kd5",
            "Kc7",
            "Re7+",
            "Kb6",
            "Ne6",
            "Ka5",
            "Kc5",
            "Kxa4",
            "Kxc4",
            "Ka3",
            "Ra7",
            "Kb2",
            "Rxa6",
            "Kc2",
            "Ra2+",
            "Kd1",
            "Kd3",
            "Ke1",
            "Ke3",
            "Kd1",
            "Nd4",
            "Kc1",
            "Kd3",
            "Kb1",
            "Rf2",
            "Ka1",
            "Kc4",
            "Kb1",
            "Kb3",
            "Kc1",
            "c4",
            "Kd1",
            "Kc3",
            "Ke1",
            "Re2+",
            "Kf1",
            "Kd3",
            "Kg1",
            "Ke3",
            "Kxh2",
            "Kf3",
            "Kg1",
            "g4",
            "Kh1",
            "Kg3",
            "Kg1",
            "Re1#",
            "fxe1=Q+",
            "Kf3",
            "Qf2+",
            "Ke4",
            "Qg2+",
            "Kf4",
            "Qxh2+",
            "Kf5",
            "Qf2+",
            "Ke4",
            "Qg2+",
            "Kf5",
            "Qd5+",
            "Kf4",
            "Qc4",
            "Ke4",
            "Qxc3",
            "Nf3+",
            "Kf2",
            "Nd4",
            "Qe3+",
            "Kd5",
            "Qg5+",
            "Ke4",
            "Qxg4+",
            "Kd5",
            "Qd7+",
            "Ke4",
            "Qxa4",
            "Kd5",
            "Qxd4+",
            "Kxd4",
            "h5",
            "Ke4",
            "h4",
            "Kf4",
            "h3",
            "Kg4",
            "h2",
            "Kf4",
            "h1=Q",
            "Ke5",
            "Qh4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "f6",
          "neutral_uci": "f7f6",
          "neutral_response": "12... f6 13. exf6 Qxf6 14. Nf1 O-O 15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qb3 Qxb3 18. axb3 Ne5 19. Be3 Nd3+ 20. Kg1 Nxb2 21. Rxa6 Rd3 22. Bd4 Nd1 23. Rc6 b4 24. Rxc7 bxc3 25. Rxg7+ Kh8 26. Rg4+ Rxd4 27. Nxd4 Nf2 28. Rg3 Ne4 29. Re3 Nd2 30. Ng3 Rc8 31. Nge2 c2 32. Rc3 Rxc3 33. Nxc3 c1=Q+ 34. Kf2 Qxc3 35. Ne2 Ne4+ 36. Kf1 Qa1+ 37. Nc1 Qxc1+ 38. Ke2 Qd2+ 39. Kf3 Ng5+ 40. Kg4 Qxg2+ 41. Kf5 Qxh2 42. Kxg5 Qb2 43. Kf5 Qxb3 44. Ke5 h5 45. Kf5 h4 46. Kg4 h3 47. Kf4 h2 48. Ke4 h1=Q+ 49. Kd4 Qh4+ 50. Kc5 Qbc4+ 51. Kd6 Qf6+ 52. Kd7 Qcc6# f6 gxf6 h5 h4 h3 h2 h1=Q# f6 gxf6 h5 h4 h3 h2 h1=Q# f6 gxf6 h5 h4 h3 h2 h1=Q#",
          "neutral_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 409,
            "total_tokens": 614,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "gxf6",
            "h5",
            "h4",
            "h3",
            "h2",
            "h1=Q#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e8g8",
          "positional_uci": "f7f6",
          "neutral_uci": "f7f6",
          "consensus_move": "f7f6",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxe4",
              "d4",
              "b5",
              "Bb3",
              "d5",
              "dxe5",
              "Be6",
              "c3",
              "Bc5",
              "Nbd2",
              "Nxf2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "exf6",
              "Qxf6",
              "Nf1",
              "O-O-O",
              "Bg5",
              "Qf7",
              "Bxd8",
              "Rxd8",
              "Kg1",
              "h6",
              "a4",
              "b4",
              "Qd3",
              "Kb7",
              "Re1",
              "Bf5",
              "Qd2",
              "Be4",
              "Nd4",
              "Nxd4",
              "Qxd4",
              "Qg6",
              "Ng3",
              "bxc3",
              "bxc3",
              "Re8",
              "Bxd5+",
              "Bxd5",
              "Qxd5+",
              "c6",
              "Qd7+",
              "Kb6",
              "Qxe8",
              "Qd3",
              "Qe3+",
              "Qxe3+",
              "Rxe3",
              "Kc5",
              "Re4",
              "Kd5",
              "Kf2",
              "c5",
              "Ke3",
              "c4",
              "Nf5",
              "g6",
              "Ne7+",
              "Kd6",
              "Nxg6",
              "Kd5",
              "Nf4+",
              "Kd6",
              "Kd4",
              "Kc6",
              "Re6+",
              "Kd7",
              "Kd5",
              "Kc7",
              "Re7+",
              "Kb6",
              "Ne6",
              "Ka5",
              "Kc5",
              "Kxa4",
              "Kxc4",
              "Ka3",
              "Ra7",
              "Kb2",
              "Rxa6",
              "Kc2",
              "Ra2+",
              "Kd1",
              "Kd3",
              "Ke1",
              "Ke3",
              "Kd1",
              "Nd4",
              "Kc1",
              "Kd3",
              "Kb1",
              "Rf2",
              "Ka1",
              "Kc4",
              "Kb1",
              "Kb3",
              "Kc1",
              "c4",
              "Kd1",
              "Kc3",
              "Ke1",
              "Re2+",
              "Kf1",
              "Kd3",
              "Kg1",
              "Ke3",
              "Kxh2",
              "Kf3",
              "Kg1",
              "g4",
              "Kh1",
              "Kg3",
              "Kg1",
              "Re1#",
              "fxe1=Q+",
              "Kf3",
              "Qf2+",
              "Ke4",
              "Qg2+",
              "Kf4",
              "Qxh2+",
              "Kf5",
              "Qf2+",
              "Ke4",
              "Qg2+",
              "Kf5",
              "Qd5+",
              "Kf4",
              "Qc4",
              "Ke4",
              "Qxc3",
              "Nf3+",
              "Kf2",
              "Nd4",
              "Qe3+",
              "Kd5",
              "Qg5+",
              "Ke4",
              "Qxg4+",
              "Kd5",
              "Qd7+",
              "Ke4",
              "Qxa4",
              "Kd5",
              "Qxd4+",
              "Kxd4",
              "h5",
              "Ke4",
              "h4",
              "Kf4",
              "h3",
              "Kg4",
              "h2",
              "Kf4",
              "h1=Q",
              "Ke5",
              "Qh4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "gxf6",
              "h5",
              "h4",
              "h3",
              "h2",
              "h1=Q#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 205,
            "completion_tokens": 409,
            "total_tokens": 614,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 617,
          "total_completion_tokens": 1689,
          "total_tokens": 2306
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 23,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 205,
            "completion_tokens": 409,
            "total_tokens": 614,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2qk2r/2p2ppp/p1n1b3/1p1pP3/8/1BP2N2/PP1N1KPP/R1BQ4 b kq - 0 12"
    },
    {
      "turn": 26,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxf6",
          "aggressive_uci": "d8f6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1 O-O 15. Bg5 Qf7 16. Kg1 Rae8 17. Ne3 h6 18. Bh4 Na5 19. Bc2 Nc4 20. Nxc4 dxc4 21. Ne5 Qf4 22. Bg3 Qe3+ 23. Kh1 Rd8 24. Qh5 Rd2 25. Qg6 Rxc2 26. Qxc2 Bf5 27. Qf2 Qxf2 28. Bxf2 Be4 29. Kg1 Re8 30. Bd4 c5 31. Bxc5 Rxe5 32. Bd4 Rg5 33. g3 Rf5 34. Re1 Bd3 35. Re7 Rf7 36. Re8+ Kh7 37. Ra8 Rf1+ 38. Kg2 Rb1 39. Ra7 Rxb2+ 40. Kf3 Kg6 41. Rxg7+ Kf5 42. g4+ Ke6 43. Ra7 Rxa2 44. h4 Be2+ 45. Kf4 Bd3 46. g5 hxg5+ 47. hxg5 a5 48. Ra6+ Kf7 49. g6+ Bxg6 50. Rf6+ Ke7 51. Rxg6 b4 52. cxb4 axb4 53. Bc5+ Kf7 54. Rb6 b3 55. Bd4 Rd2 56. Ke4 Rd3 57. Rc6 Rd1 58. Rxc4 Re1+ 59. Kd3 Rd1+ 60. Ke2 Rh1 61. Rb4 Rh2+ 62. Kd3 Rh3+ 63. Be3 Ke6 64. Rxb3 Kd5 65. Rb5+ Kc6 66. Rc5+ Kd6 67. Rg5 Ke6 68. Ke4 Rh4+ 69. Bf4 Rh1 70. Rg6+ Kf7 71. Ra6 Re1+ 72. Kf5 Rf1 73. Ra7+ Ke8 74. Ke6 Re1+ 75. Be5 Rd1 76. Rh7 Rf1 77. Rh8+ Rf8",
          "aggressive_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf1",
            "O-O",
            "Bg5",
            "Qf7",
            "Kg1",
            "Rae8",
            "Ne3",
            "h6",
            "Bh4",
            "Na5",
            "Bc2",
            "Nc4",
            "Nxc4",
            "dxc4",
            "Ne5",
            "Qf4",
            "Bg3",
            "Qe3+",
            "Kh1",
            "Rd8",
            "Qh5",
            "Rd2",
            "Qg6",
            "Rxc2",
            "Qxc2",
            "Bf5",
            "Qf2",
            "Qxf2",
            "Bxf2",
            "Be4",
            "Kg1",
            "Re8",
            "Bd4",
            "c5",
            "Bxc5",
            "Rxe5",
            "Bd4",
            "Rg5",
            "g3",
            "Rf5",
            "Re1",
            "Bd3",
            "Re7",
            "Rf7",
            "Re8+",
            "Kh7",
            "Ra8",
            "Rf1+",
            "Kg2",
            "Rb1",
            "Ra7",
            "Rxb2+",
            "Kf3",
            "Kg6",
            "Rxg7+",
            "Kf5",
            "g4+",
            "Ke6",
            "Ra7",
            "Rxa2",
            "h4",
            "Be2+",
            "Kf4",
            "Bd3",
            "g5",
            "hxg5+",
            "hxg5",
            "a5",
            "Ra6+",
            "Kf7",
            "g6+",
            "Bxg6",
            "Rf6+",
            "Ke7",
            "Rxg6",
            "b4",
            "cxb4",
            "axb4",
            "Bc5+",
            "Kf7",
            "Rb6",
            "b3",
            "Bd4",
            "Rd2",
            "Ke4",
            "Rd3",
            "Rc6",
            "Rd1",
            "Rxc4",
            "Re1+",
            "Kd3",
            "Rd1+",
            "Ke2",
            "Rh1",
            "Rb4",
            "Rh2+",
            "Kd3",
            "Rh3+",
            "Be3",
            "Ke6",
            "Rxb3",
            "Kd5",
            "Rb5+",
            "Kc6",
            "Rc5+",
            "Kd6",
            "Rg5",
            "Ke6",
            "Ke4",
            "Rh4+",
            "Bf4",
            "Rh1",
            "Rg6+",
            "Kf7",
            "Ra6",
            "Re1+",
            "Kf5",
            "Rf1",
            "Ra7+",
            "Ke8",
            "Ke6",
            "Re1+",
            "Be5",
            "Rd1",
            "Rh7",
            "Rf1",
            "Rh8+",
            "Rf8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxf6",
          "positional_uci": "d8f6",
          "positional_response": "13... Qxf6 14. Kg1 O-O 15. Nf1 Ne5 16. Nxe5 Qf2+ 17. Kh1 Qxf1+ 18. Qxf1 Rxf1#",
          "positional_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 50,
            "total_tokens": 264,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg1",
            "O-O",
            "Nf1",
            "Ne5",
            "Nxe5",
            "Qf2+",
            "Kh1",
            "Qxf1+",
            "Qxf1",
            "Rxf1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxf6",
          "neutral_uci": "d8f6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1 O-O 15. Bg5 Qf7 16. Kg1 Rae8 17. Be3 h6 18. Bc5 Ne7 19. Ne5 Qf6 20. Qe2 c6 21. Re1 Bf5 22. Ng3 Bh7 23. Nd7 Qf7 24. Nxf8 Kxf8 25. Rf1 Kg8 26. Rxf7 Kxf7 27. Qf3+ Kg8 28. Qe3 Kf7 29. Qf4+ Kg8 30. Qe5 Kf7 31. Nh5 Nf5 32. Qc7+ Kg6 33. Nf4+ Kg5 34. g3 Re1+ 35. Kf2 Rb1 36. Qd8+ Kg4 37. h3# 1-0\n14... O-O 15. Bg5 Qf7 16. Kg1 Rae8",
          "neutral_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 330,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf1",
            "O-O",
            "Bg5",
            "Qf7",
            "Kg1",
            "Rae8",
            "Be3",
            "h6",
            "Bc5",
            "Ne7",
            "Ne5",
            "Qf6",
            "Qe2",
            "c6",
            "Re1",
            "Bf5",
            "Ng3",
            "Bh7",
            "Nd7",
            "Qf7",
            "Nxf8",
            "Kxf8",
            "Rf1",
            "Kg8",
            "Rxf7",
            "Kxf7",
            "Qf3+",
            "Kg8",
            "Qe3",
            "Kf7",
            "Qf4+",
            "Kg8",
            "Qe5",
            "Kf7",
            "Nh5",
            "Nf5",
            "Qc7+",
            "Kg6",
            "Nf4+",
            "Kg5",
            "g3",
            "Re1+",
            "Kf2",
            "Rb1",
            "Qd8+",
            "Kg4",
            "h3#",
            "O-O",
            "Bg5",
            "Qf7",
            "Kg1",
            "Rae8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8f6",
          "positional_uci": "d8f6",
          "neutral_uci": "d8f6",
          "consensus_move": "d8f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf1",
              "O-O",
              "Bg5",
              "Qf7",
              "Kg1",
              "Rae8",
              "Ne3",
              "h6",
              "Bh4",
              "Na5",
              "Bc2",
              "Nc4",
              "Nxc4",
              "dxc4",
              "Ne5",
              "Qf4",
              "Bg3",
              "Qe3+",
              "Kh1",
              "Rd8",
              "Qh5",
              "Rd2",
              "Qg6",
              "Rxc2",
              "Qxc2",
              "Bf5",
              "Qf2",
              "Qxf2",
              "Bxf2",
              "Be4",
              "Kg1",
              "Re8",
              "Bd4",
              "c5",
              "Bxc5",
              "Rxe5",
              "Bd4",
              "Rg5",
              "g3",
              "Rf5",
              "Re1",
              "Bd3",
              "Re7",
              "Rf7",
              "Re8+",
              "Kh7",
              "Ra8",
              "Rf1+",
              "Kg2",
              "Rb1",
              "Ra7",
              "Rxb2+",
              "Kf3",
              "Kg6",
              "Rxg7+",
              "Kf5",
              "g4+",
              "Ke6",
              "Ra7",
              "Rxa2",
              "h4",
              "Be2+",
              "Kf4",
              "Bd3",
              "g5",
              "hxg5+",
              "hxg5",
              "a5",
              "Ra6+",
              "Kf7",
              "g6+",
              "Bxg6",
              "Rf6+",
              "Ke7",
              "Rxg6",
              "b4",
              "cxb4",
              "axb4",
              "Bc5+",
              "Kf7",
              "Rb6",
              "b3",
              "Bd4",
              "Rd2",
              "Ke4",
              "Rd3",
              "Rc6",
              "Rd1",
              "Rxc4",
              "Re1+",
              "Kd3",
              "Rd1+",
              "Ke2",
              "Rh1",
              "Rb4",
              "Rh2+",
              "Kd3",
              "Rh3+",
              "Be3",
              "Ke6",
              "Rxb3",
              "Kd5",
              "Rb5+",
              "Kc6",
              "Rc5+",
              "Kd6",
              "Rg5",
              "Ke6",
              "Ke4",
              "Rh4+",
              "Bf4",
              "Rh1",
              "Rg6+",
              "Kf7",
              "Ra6",
              "Re1+",
              "Kf5",
              "Rf1",
              "Ra7+",
              "Ke8",
              "Ke6",
              "Re1+",
              "Be5",
              "Rd1",
              "Rh7",
              "Rf1",
              "Rh8+",
              "Rf8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg1",
              "O-O",
              "Nf1",
              "Ne5",
              "Nxe5",
              "Qf2+",
              "Kh1",
              "Qxf1+",
              "Qxf1",
              "Rxf1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf1",
              "O-O",
              "Bg5",
              "Qf7",
              "Kg1",
              "Rae8",
              "Be3",
              "h6",
              "Bc5",
              "Ne7",
              "Ne5",
              "Qf6",
              "Qe2",
              "c6",
              "Re1",
              "Bf5",
              "Ng3",
              "Bh7",
              "Nd7",
              "Qf7",
              "Nxf8",
              "Kxf8",
              "Rf1",
              "Kg8",
              "Rxf7",
              "Kxf7",
              "Qf3+",
              "Kg8",
              "Qe3",
              "Kf7",
              "Qf4+",
              "Kg8",
              "Qe5",
              "Kf7",
              "Nh5",
              "Nf5",
              "Qc7+",
              "Kg6",
              "Nf4+",
              "Kg5",
              "g3",
              "Re1+",
              "Kf2",
              "Rb1",
              "Qd8+",
              "Kg4",
              "h3#",
              "O-O",
              "Bg5",
              "Qf7",
              "Kg1",
              "Rae8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 214,
            "completion_tokens": 50,
            "total_tokens": 264,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 213,
            "completion_tokens": 330,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 641,
          "total_completion_tokens": 1020,
          "total_tokens": 1661
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 214,
            "completion_tokens": 50,
            "total_tokens": 264,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 25,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 213,
            "completion_tokens": 330,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r2qk2r/2p3pp/p1n1bP2/1p1p4/8/1BP2N2/PP1N1KPP/R1BQ4 b kq - 0 13"
    },
    {
      "turn": 28,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O",
          "aggressive_uci": "e8g8",
          "aggressive_response": "14... O-O 15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Rd1 Rxd1 22. Kxd1 Kf7 23. Ke2 Ke6 24. Nd2 Kd5 25. Nf3 Re8 26. Kd3 c5 27. b3 c4+ 28. bxc4+ bxc4+ 29. Kd2 Rb8 30. Kc2 Re8 31. Kd2 Rb8 32. Kc2 Re8 33. Bd4 Re2+ 34. Nd2 Rxg2 35. h4 g6 36. Kd1 Rh2 37. Bf6 Rh1+ 38. Kc2 Ra1 39. Kb2 Rd1 40. Nf3 Rf1 41. Nd2 Rxf6 42. Kc2 Rf2 43. Kd1 Rh2 44. Nf3 Rxa2 45. Ng5 h6 46. Nf7 h5 47. Nh8 Rg2 48. Nf7 a5 49. Ng5 a4 50. Nf3 a3 51. Nd2 a2 52. Kc2 a1=Q 53. h5 Qa2+ 54. Kc1 Qxd2+ 55. Kb1 Qb2#",
          "aggressive_tokens": {
            "prompt_tokens": 223,
            "completion_tokens": 349,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxd5",
            "Rad8",
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Rd1",
            "Rxd1",
            "Kxd1",
            "Kf7",
            "Ke2",
            "Ke6",
            "Nd2",
            "Kd5",
            "Nf3",
            "Re8",
            "Kd3",
            "c5",
            "b3",
            "c4+",
            "bxc4+",
            "bxc4+",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Kd2",
            "Rb8",
            "Kc2",
            "Re8",
            "Bd4",
            "Re2+",
            "Nd2",
            "Rxg2",
            "h4",
            "g6",
            "Kd1",
            "Rh2",
            "Bf6",
            "Rh1+",
            "Kc2",
            "Ra1",
            "Kb2",
            "Rd1",
            "Nf3",
            "Rf1",
            "Nd2",
            "Rxf6",
            "Kc2",
            "Rf2",
            "Kd1",
            "Rh2",
            "Nf3",
            "Rxa2",
            "Ng5",
            "h6",
            "Nf7",
            "h5",
            "Nh8",
            "Rg2",
            "Nf7",
            "a5",
            "Ng5",
            "a4",
            "Nf3",
            "a3",
            "Nd2",
            "a2",
            "Kc2",
            "a1=Q",
            "h5",
            "Qa2+",
            "Kc1",
            "Qxd2+",
            "Kb1",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O",
          "positional_uci": "e8g8",
          "positional_response": "14... O-O 15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Rd1 Rxd1 22. Kxd1 c5 23. Kd2 Kf7 24. Ng3 Ke6 25. Ne2 Kd5 26. Nf4+ Kc6 27. Nd3 Rd5 28. Ke2 a5 29. Nf4 Re5 30. Kf3 b4 31. c4 a4 32. Nd3 Rf5+ 33. Ke4 Rh5 34. h3 Rh4+ 35. Bf4 g5 36. Ne5+ Kb6 37. Nd7+ Kc6 38. Ne5+ Kb6 39. Nd3 gxf4 40. Nxf4 Rh6 41. g4 Rd6 42. Nd5+ Kc6 43. h4 Re6+ 44. Kf5 Re2 45. g5 Rxb2 46. h5 Rxa2 47. g6 hxg6+ 48. hxg6 Rg2 49. Kf6 a3 50. g7 a2 51. Ne7+ Kd7 52. Ng6 a1=Q+ 53. Kf7 Rf2+ 54. Kg8 Qf6 55. Nf8+ Ke8 56. Kh7 Rh2+ 57. Kg8 Qf7# 0-1",
          "positional_tokens": {
            "prompt_tokens": 223,
            "completion_tokens": 367,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxd5",
            "Rad8",
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Rd1",
            "Rxd1",
            "Kxd1",
            "c5",
            "Kd2",
            "Kf7",
            "Ng3",
            "Ke6",
            "Ne2",
            "Kd5",
            "Nf4+",
            "Kc6",
            "Nd3",
            "Rd5",
            "Ke2",
            "a5",
            "Nf4",
            "Re5",
            "Kf3",
            "b4",
            "c4",
            "a4",
            "Nd3",
            "Rf5+",
            "Ke4",
            "Rh5",
            "h3",
            "Rh4+",
            "Bf4",
            "g5",
            "Ne5+",
            "Kb6",
            "Nd7+",
            "Kc6",
            "Ne5+",
            "Kb6",
            "Nd3",
            "gxf4",
            "Nxf4",
            "Rh6",
            "g4",
            "Rd6",
            "Nd5+",
            "Kc6",
            "h4",
            "Re6+",
            "Kf5",
            "Re2",
            "g5",
            "Rxb2",
            "h5",
            "Rxa2",
            "g6",
            "hxg6+",
            "hxg6",
            "Rg2",
            "Kf6",
            "a3",
            "g7",
            "a2",
            "Ne7+",
            "Kd7",
            "Ng6",
            "a1=Q+",
            "Kf7",
            "Rf2+",
            "Kg8",
            "Qf6",
            "Nf8+",
            "Ke8",
            "Kh7",
            "Rh2+",
            "Kg8",
            "Qf7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O",
          "neutral_uci": "e8g8",
          "neutral_response": "14... O-O 15. Bxd5 Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5 Rxe5 21. Rd1 Rxd1 22. Kxd1 c5 23. Kd2 Kf7 24. Kd3 Ke6 25. Nd2 Rd5+ 26. Ke4 Re5+ 27. Kf3 Rf5+ 28. Ke2 Kd5 29. b3 c4 30. bxc4+ bxc4 31. Nf3 Rf8 32. Bd4 g6 33. Ng5 h6 34. Nf3 Rb8 35. a3 Rb2+ 36. Nd2 Ra2 37. Bg7 h5 38. Bf8 a5 39. Ke3 Rc2 40. Bg7 Ra2 41. Bf8 Rc2 42. Bg7 Ra2 43. Bf8 Rc2 44. Bg7 Ra2 45. Bf8 Rc2 46. Bg7 Ra2 47. Bf8 Rc2 48. Bg7 Ra2 49. Bf8 Rc2 50. Bg7 Ra2 51. Bf8 Rc2 52. Bg7 Ra2 53. Bf8 Rc2 54. Bg7 Ra2 55. Bf8 Rc2 56. Bg7 Ra2 57. Bf8 Rc2 58. Bg7 Ra2 59. Bf8 Rc2 60. Bg7 Ra2 61. Bf8 Rc2 62. Bg7 Ra2 63. Bf8 Rc2 64. Bg7 Ra2 65. Bf8 Rc2 66. Bg7 Ra2 67. Bf8 Rc2 68. Bg7 Ra2 69. Bf8 Rc2 70. Bg7 Ra2 71. Bf8 Rc2 72. Bg7 Ra2 73. Bf8 Rc2 74. Bg7 Ra2 75. Bf8 Rc2 76. Bg7 Ra2 77. Bf8 Rc2 78. Bg7 Ra2 79. Bf8 Rc2 80. Bg7 Ra2 81. Bf8 Rc2 82. Bg7 Ra2 83. Bf8 Rc2 84. Bg7 Ra2 85. Bf8 Rc2 86. Bg7 Ra2 87. Bf8 Rc2 88. Bg7 Ra2 89. Bf8 Rc2 90. Bg7 Ra2 91. Bf8 Rc2 92. Bg7 Ra2 93",
          "neutral_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxd5",
            "Rad8",
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Rd1",
            "Rxd1",
            "Kxd1",
            "c5",
            "Kd2",
            "Kf7",
            "Kd3",
            "Ke6",
            "Nd2",
            "Rd5+",
            "Ke4",
            "Re5+",
            "Kf3",
            "Rf5+",
            "Ke2",
            "Kd5",
            "b3",
            "c4",
            "bxc4+",
            "bxc4",
            "Nf3",
            "Rf8",
            "Bd4",
            "g6",
            "Ng5",
            "h6",
            "Nf3",
            "Rb8",
            "a3",
            "Rb2+",
            "Nd2",
            "Ra2",
            "Bg7",
            "h5",
            "Bf8",
            "a5",
            "Ke3",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2",
            "Bf8",
            "Rc2",
            "Bg7",
            "Ra2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e8g8",
          "positional_uci": "e8g8",
          "neutral_uci": "e8g8",
          "consensus_move": "e8g8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxd5",
              "Rad8",
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Rd1",
              "Rxd1",
              "Kxd1",
              "Kf7",
              "Ke2",
              "Ke6",
              "Nd2",
              "Kd5",
              "Nf3",
              "Re8",
              "Kd3",
              "c5",
              "b3",
              "c4+",
              "bxc4+",
              "bxc4+",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Kd2",
              "Rb8",
              "Kc2",
              "Re8",
              "Bd4",
              "Re2+",
              "Nd2",
              "Rxg2",
              "h4",
              "g6",
              "Kd1",
              "Rh2",
              "Bf6",
              "Rh1+",
              "Kc2",
              "Ra1",
              "Kb2",
              "Rd1",
              "Nf3",
              "Rf1",
              "Nd2",
              "Rxf6",
              "Kc2",
              "Rf2",
              "Kd1",
              "Rh2",
              "Nf3",
              "Rxa2",
              "Ng5",
              "h6",
              "Nf7",
              "h5",
              "Nh8",
              "Rg2",
              "Nf7",
              "a5",
              "Ng5",
              "a4",
              "Nf3",
              "a3",
              "Nd2",
              "a2",
              "Kc2",
              "a1=Q",
              "h5",
              "Qa2+",
              "Kc1",
              "Qxd2+",
              "Kb1",
              "Qb2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxd5",
              "Rad8",
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Rd1",
              "Rxd1",
              "Kxd1",
              "c5",
              "Kd2",
              "Kf7",
              "Ng3",
              "Ke6",
              "Ne2",
              "Kd5",
              "Nf4+",
              "Kc6",
              "Nd3",
              "Rd5",
              "Ke2",
              "a5",
              "Nf4",
              "Re5",
              "Kf3",
              "b4",
              "c4",
              "a4",
              "Nd3",
              "Rf5+",
              "Ke4",
              "Rh5",
              "h3",
              "Rh4+",
              "Bf4",
              "g5",
              "Ne5+",
              "Kb6",
              "Nd7+",
              "Kc6",
              "Ne5+",
              "Kb6",
              "Nd3",
              "gxf4",
              "Nxf4",
              "Rh6",
              "g4",
              "Rd6",
              "Nd5+",
              "Kc6",
              "h4",
              "Re6+",
              "Kf5",
              "Re2",
              "g5",
              "Rxb2",
              "h5",
              "Rxa2",
              "g6",
              "hxg6+",
              "hxg6",
              "Rg2",
              "Kf6",
              "a3",
              "g7",
              "a2",
              "Ne7+",
              "Kd7",
              "Ng6",
              "a1=Q+",
              "Kf7",
              "Rf2+",
              "Kg8",
              "Qf6",
              "Nf8+",
              "Ke8",
              "Kh7",
              "Rh2+",
              "Kg8",
              "Qf7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxd5",
              "Rad8",
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Rd1",
              "Rxd1",
              "Kxd1",
              "c5",
              "Kd2",
              "Kf7",
              "Kd3",
              "Ke6",
              "Nd2",
              "Rd5+",
              "Ke4",
              "Re5+",
              "Kf3",
              "Rf5+",
              "Ke2",
              "Kd5",
              "b3",
              "c4",
              "bxc4+",
              "bxc4",
              "Nf3",
              "Rf8",
              "Bd4",
              "g6",
              "Ng5",
              "h6",
              "Nf3",
              "Rb8",
              "a3",
              "Rb2+",
              "Nd2",
              "Ra2",
              "Bg7",
              "h5",
              "Bf8",
              "a5",
              "Ke3",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2",
              "Bf8",
              "Rc2",
              "Bg7",
              "Ra2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 223,
            "completion_tokens": 349,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 223,
            "completion_tokens": 367,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 668,
          "total_completion_tokens": 1356,
          "total_tokens": 2024
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 223,
            "completion_tokens": 349,
            "total_tokens": 572,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 223,
            "completion_tokens": 367,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 27,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 222,
            "completion_tokens": 640,
            "total_tokens": 862,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r3k2r/2p3pp/p1n1bq2/1p1p4/8/1BP2N2/PP3KPP/R1BQ1N2 b kq - 1 14"
    },
    {
      "turn": 30,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rad8",
          "aggressive_uci": "a8d8",
          "aggressive_response": "15... Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5\nRxe5 21. Rd1 Rxd1 22. Kxd1 c5 23. Kd2 Kf7 24. Ng3 Ke6 25. Ne2 Kd5 26. Nf4+ Kc6\n27. Nd3 Rd5 28. Ke2 a5 29. b3 c4 30. bxc4 bxc4 31. Nb2 Kb5 32. a4+ Kc6 33. Nxc4\nRh5 34. h3 Rh4 35. Kd3 Kd5 36. Nb6+ Kc6 37. c4 Rh5 38. Nd5 Rh4 39. Bd4 g6 40.\nNe3 Rf4 41. Ng4 Rf1 42. Ne5+ Kd6 43. c5+ Kd5 44. c6 Rd1+ 45. Ke3 Rc1 46. Nd3\nRc4 47. Nf4+ Kxc6 48. Kd3 Rxa4 49. Ne6 Ra3+ 50. Kc4 Ra2 51. g4 Rh2 52. Ng5 h6\n53. Nf7 Rxh3 54. Ne5+ Kd6 55. Nxg6 Rg3 56. Be5+ Ke6 57. Bxg3 Kf6 58. Nf4 Kg5\n59. Ne2 Kxg4 60. Bc7 h5 61. Bxa5 h4 62. Bc7 Kf3 63. Nd4+ Kg2 64. Nf5 h3 65. Ne3+\nKf3 66. Kd3 Kf2 67. Ng4+ Kf3 68. Nh2+ Kg2 69. Ke2 Kg1 70. Kf3 Kh1 71. Ng4 Kg1\n72. Bh2+ Kh1 73. Nf2+ Kxh2 74. Ng4+ Kg1 75. Kg3 h2 76. Nxh2 * 76... Kh1 77. Nf2+ Kg1 78. Nh3+ Kh1 79. Nf4 Kg1 80. Ne2+ Kh1 81. Kf2 Kh2 82. Ng1 Kh1 83. Ne2 Kh2 84. Ng3 *",
          "aggressive_tokens": {
            "prompt_tokens": 232,
            "completion_tokens": 577,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Rd1",
            "Rxd1",
            "Kxd1",
            "c5",
            "Kd2",
            "Kf7",
            "Ng3",
            "Ke6",
            "Ne2",
            "Kd5",
            "Nf4+",
            "Kc6",
            "Nd3",
            "Rd5",
            "Ke2",
            "a5",
            "b3",
            "c4",
            "bxc4",
            "bxc4",
            "Nb2",
            "Kb5",
            "a4+",
            "Kc6",
            "Nxc4",
            "Rh5",
            "h3",
            "Rh4",
            "Kd3",
            "Kd5",
            "Nb6+",
            "Kc6",
            "c4",
            "Rh5",
            "Nd5",
            "Rh4",
            "Bd4",
            "g6",
            "Ne3",
            "Rf4",
            "Ng4",
            "Rf1",
            "Ne5+",
            "Kd6",
            "c5+",
            "Kd5",
            "c6",
            "Rd1+",
            "Ke3",
            "Rc1",
            "Nd3",
            "Rc4",
            "Nf4+",
            "Kxc6",
            "Kd3",
            "Rxa4",
            "Ne6",
            "Ra3+",
            "Kc4",
            "Ra2",
            "g4",
            "Rh2",
            "Ng5",
            "h6",
            "Nf7",
            "Rxh3",
            "Ne5+",
            "Kd6",
            "Nxg6",
            "Rg3",
            "Be5+",
            "Ke6",
            "Bxg3",
            "Kf6",
            "Nf4",
            "Kg5",
            "Ne2",
            "Kxg4",
            "Bc7",
            "h5",
            "Bxa5",
            "h4",
            "Bc7",
            "Kf3",
            "Nd4+",
            "Kg2",
            "Nf5",
            "h3",
            "Ne3+",
            "Kf3",
            "Kd3",
            "Kf2",
            "Ng4+",
            "Kf3",
            "Nh2+",
            "Kg2",
            "Ke2",
            "Kg1",
            "Kf3",
            "Kh1",
            "Ng4",
            "Kg1",
            "Bh2+",
            "Kh1",
            "Nf2+",
            "Kxh2",
            "Ng4+",
            "Kg1",
            "Kg3",
            "h2",
            "Nxh2",
            "Kh1",
            "Nf2+",
            "Kg1",
            "Nh3+",
            "Kh1",
            "Nf4",
            "Kg1",
            "Ne2+",
            "Kh1",
            "Kf2",
            "Kh2",
            "Ng1",
            "Kh1",
            "Ne2",
            "Kh2",
            "Ng3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rad8",
          "positional_uci": "a8d8",
          "positional_response": "15... Rad8 16. Bxe6+ Qxe6 17. Qe2 Qd5 18. Be3 Ne5 19. Kg1 Nxf3+ 20. gxf3 Rxf3 21. Ng3 Re8 22. Nf1 Re6 23. Rd1 Rg6+ 24. Ng3 Rfxg3+ 25. hxg3 Rxg3+ 26. Kf1 Qh1+ 27. Kf2 Rg2+ 28. Kf3 Qh3+ 29. Ke4 Rxe2 30. Rd8+ Kf7 31. Rd7+ Qxd7 32. Kf3 Qd3 33. Kf4 Qxe3+ 34. Kf5 Rf2+ 35. Kg4 Qf3+ 36. Kh4 Rh2+ 37. Kg5 Rh5# 1-0\n37... h6 38. c4 g5 39. cxb5 Kg7",
          "positional_tokens": {
            "prompt_tokens": 232,
            "completion_tokens": 227,
            "total_tokens": 459,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qd5",
            "Be3",
            "Ne5",
            "Kg1",
            "Nxf3+",
            "gxf3",
            "Rxf3",
            "Ng3",
            "Re8",
            "Nf1",
            "Re6",
            "Rd1",
            "Rg6+",
            "Ng3",
            "Rfxg3+",
            "hxg3",
            "Rxg3+",
            "Kf1",
            "Qh1+",
            "Kf2",
            "Rg2+",
            "Kf3",
            "Qh3+",
            "Ke4",
            "Rxe2",
            "Rd8+",
            "Kf7",
            "Rd7+",
            "Qxd7",
            "Kf3",
            "Qd3",
            "Kf4",
            "Qxe3+",
            "Kf5",
            "Rf2+",
            "Kg4",
            "Qf3+",
            "Kh4",
            "Rh2+",
            "Kg5",
            "Rh5#",
            "h6",
            "c4",
            "g5",
            "cxb5",
            "Kg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rad8",
          "neutral_uci": "a8d8",
          "neutral_response": "15... Rad8 16. Bxe6+ Qxe6 17. Qe2 Qxe2+ 18. Kxe2 Rfe8+ 19. Be3 Ne5 20. Nxe5\nRxe5 21. Nd2 Rde8 22. Nf1 c5 23. Rd1 Kf7 24. Rd7+ R8e7 25. Rxe7+ Kxe7 26. Nd2\nKd6 27. Kd3 Kd5 28. b3 c4+ 29. bxc4+ bxc4+ 30. Nxc4 Re8 31. Bd4 g6 32. Ne3+ Kc6\n33. c4 Rb8 34. Kc2 Rf8 35. Nd5 Rf1 36. Nb4+ Kb7 37. c5 a5 38. c6+ Kc7 39. Be5+\nKc8 40. Nd5 Rf2+ 41. Kd3 Rxa2 42. Nb6+ Kd8 43. c7+ Ke7 44. c8=Q Rxg2 45. Qd7+\nKf8 46. Bd6+ Kg8 47. Qe8+ Kg7 48. Qf8# R1e8 49. Qf6+ Kg8 50. Be5 R2xe5 51. Qxe5\nRxe5 52. Kd4 Rh5 53. Nd5 Rxh2 54. Kc5 a4 55. Kb4 Rh4+ 56. Ka3 Kf7 57. Nb6 g5 58.\nNxa4 Rxa4+ 59. Kxa4 g4 60. Kb3 g3 61. Kc2 g2 62. Kd2 g1=Q 63. Ke2 Qg3 64. Kf1\nQh2 65. Ke1 Ke6 66. Kf1 Ke5 67. Ke1 Ke4 68. Kf1 Ke3 69. Ke1 Qe2# B1d2 B1e2 B1f3",
          "neutral_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 486,
            "total_tokens": 717,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe6+",
            "Qxe6",
            "Qe2",
            "Qxe2+",
            "Kxe2",
            "Rfe8+",
            "Be3",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "Nd2",
            "Rde8",
            "Nf1",
            "c5",
            "Rd1",
            "Kf7",
            "Rd7+",
            "R8e7",
            "Rxe7+",
            "Kxe7",
            "Nd2",
            "Kd6",
            "Kd3",
            "Kd5",
            "b3",
            "c4+",
            "bxc4+",
            "bxc4+",
            "Nxc4",
            "Re8",
            "Bd4",
            "g6",
            "Ne3+",
            "Kc6",
            "c4",
            "Rb8",
            "Kc2",
            "Rf8",
            "Nd5",
            "Rf1",
            "Nb4+",
            "Kb7",
            "c5",
            "a5",
            "c6+",
            "Kc7",
            "Be5+",
            "Kc8",
            "Nd5",
            "Rf2+",
            "Kd3",
            "Rxa2",
            "Nb6+",
            "Kd8",
            "c7+",
            "Ke7",
            "c8=Q",
            "Rxg2",
            "Qd7+",
            "Kf8",
            "Bd6+",
            "Kg8",
            "Qe8+",
            "Kg7",
            "Qf8#",
            "R1e8",
            "Qf6+",
            "Kg8",
            "Be5",
            "R2xe5",
            "Qxe5",
            "Rxe5",
            "Kd4",
            "Rh5",
            "Nd5",
            "Rxh2",
            "Kc5",
            "a4",
            "Kb4",
            "Rh4+",
            "Ka3",
            "Kf7",
            "Nb6",
            "g5",
            "Nxa4",
            "Rxa4+",
            "Kxa4",
            "g4",
            "Kb3",
            "g3",
            "Kc2",
            "g2",
            "Kd2",
            "g1=Q",
            "Ke2",
            "Qg3",
            "Kf1",
            "Qh2",
            "Ke1",
            "Ke6",
            "Kf1",
            "Ke5",
            "Ke1",
            "Ke4",
            "Kf1",
            "Ke3",
            "Ke1",
            "Qe2#",
            "B1d2",
            "B1e2",
            "B1f3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a8d8",
          "positional_uci": "a8d8",
          "neutral_uci": "a8d8",
          "consensus_move": "a8d8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Rd1",
              "Rxd1",
              "Kxd1",
              "c5",
              "Kd2",
              "Kf7",
              "Ng3",
              "Ke6",
              "Ne2",
              "Kd5",
              "Nf4+",
              "Kc6",
              "Nd3",
              "Rd5",
              "Ke2",
              "a5",
              "b3",
              "c4",
              "bxc4",
              "bxc4",
              "Nb2",
              "Kb5",
              "a4+",
              "Kc6",
              "Nxc4",
              "Rh5",
              "h3",
              "Rh4",
              "Kd3",
              "Kd5",
              "Nb6+",
              "Kc6",
              "c4",
              "Rh5",
              "Nd5",
              "Rh4",
              "Bd4",
              "g6",
              "Ne3",
              "Rf4",
              "Ng4",
              "Rf1",
              "Ne5+",
              "Kd6",
              "c5+",
              "Kd5",
              "c6",
              "Rd1+",
              "Ke3",
              "Rc1",
              "Nd3",
              "Rc4",
              "Nf4+",
              "Kxc6",
              "Kd3",
              "Rxa4",
              "Ne6",
              "Ra3+",
              "Kc4",
              "Ra2",
              "g4",
              "Rh2",
              "Ng5",
              "h6",
              "Nf7",
              "Rxh3",
              "Ne5+",
              "Kd6",
              "Nxg6",
              "Rg3",
              "Be5+",
              "Ke6",
              "Bxg3",
              "Kf6",
              "Nf4",
              "Kg5",
              "Ne2",
              "Kxg4",
              "Bc7",
              "h5",
              "Bxa5",
              "h4",
              "Bc7",
              "Kf3",
              "Nd4+",
              "Kg2",
              "Nf5",
              "h3",
              "Ne3+",
              "Kf3",
              "Kd3",
              "Kf2",
              "Ng4+",
              "Kf3",
              "Nh2+",
              "Kg2",
              "Ke2",
              "Kg1",
              "Kf3",
              "Kh1",
              "Ng4",
              "Kg1",
              "Bh2+",
              "Kh1",
              "Nf2+",
              "Kxh2",
              "Ng4+",
              "Kg1",
              "Kg3",
              "h2",
              "Nxh2",
              "Kh1",
              "Nf2+",
              "Kg1",
              "Nh3+",
              "Kh1",
              "Nf4",
              "Kg1",
              "Ne2+",
              "Kh1",
              "Kf2",
              "Kh2",
              "Ng1",
              "Kh1",
              "Ne2",
              "Kh2",
              "Ng3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qd5",
              "Be3",
              "Ne5",
              "Kg1",
              "Nxf3+",
              "gxf3",
              "Rxf3",
              "Ng3",
              "Re8",
              "Nf1",
              "Re6",
              "Rd1",
              "Rg6+",
              "Ng3",
              "Rfxg3+",
              "hxg3",
              "Rxg3+",
              "Kf1",
              "Qh1+",
              "Kf2",
              "Rg2+",
              "Kf3",
              "Qh3+",
              "Ke4",
              "Rxe2",
              "Rd8+",
              "Kf7",
              "Rd7+",
              "Qxd7",
              "Kf3",
              "Qd3",
              "Kf4",
              "Qxe3+",
              "Kf5",
              "Rf2+",
              "Kg4",
              "Qf3+",
              "Kh4",
              "Rh2+",
              "Kg5",
              "Rh5#",
              "h6",
              "c4",
              "g5",
              "cxb5",
              "Kg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxe6+",
              "Qxe6",
              "Qe2",
              "Qxe2+",
              "Kxe2",
              "Rfe8+",
              "Be3",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "Nd2",
              "Rde8",
              "Nf1",
              "c5",
              "Rd1",
              "Kf7",
              "Rd7+",
              "R8e7",
              "Rxe7+",
              "Kxe7",
              "Nd2",
              "Kd6",
              "Kd3",
              "Kd5",
              "b3",
              "c4+",
              "bxc4+",
              "bxc4+",
              "Nxc4",
              "Re8",
              "Bd4",
              "g6",
              "Ne3+",
              "Kc6",
              "c4",
              "Rb8",
              "Kc2",
              "Rf8",
              "Nd5",
              "Rf1",
              "Nb4+",
              "Kb7",
              "c5",
              "a5",
              "c6+",
              "Kc7",
              "Be5+",
              "Kc8",
              "Nd5",
              "Rf2+",
              "Kd3",
              "Rxa2",
              "Nb6+",
              "Kd8",
              "c7+",
              "Ke7",
              "c8=Q",
              "Rxg2",
              "Qd7+",
              "Kf8",
              "Bd6+",
              "Kg8",
              "Qe8+",
              "Kg7",
              "Qf8#",
              "R1e8",
              "Qf6+",
              "Kg8",
              "Be5",
              "R2xe5",
              "Qxe5",
              "Rxe5",
              "Kd4",
              "Rh5",
              "Nd5",
              "Rxh2",
              "Kc5",
              "a4",
              "Kb4",
              "Rh4+",
              "Ka3",
              "Kf7",
              "Nb6",
              "g5",
              "Nxa4",
              "Rxa4+",
              "Kxa4",
              "g4",
              "Kb3",
              "g3",
              "Kc2",
              "g2",
              "Kd2",
              "g1=Q",
              "Ke2",
              "Qg3",
              "Kf1",
              "Qh2",
              "Ke1",
              "Ke6",
              "Kf1",
              "Ke5",
              "Ke1",
              "Ke4",
              "Kf1",
              "Ke3",
              "Ke1",
              "Qe2#",
              "B1d2",
              "B1e2",
              "B1f3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 232,
            "completion_tokens": 577,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 232,
            "completion_tokens": 227,
            "total_tokens": 459,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 231,
            "completion_tokens": 486,
            "total_tokens": 717,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 695,
          "total_completion_tokens": 1290,
          "total_tokens": 1985
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 232,
            "completion_tokens": 577,
            "total_tokens": 809,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 232,
            "completion_tokens": 227,
            "total_tokens": 459,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 29,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 231,
            "completion_tokens": 486,
            "total_tokens": 717,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r4rk1/2p3pp/p1n1bq2/1p1B4/8/2P2N2/PP3KPP/R1BQ1N2 b - - 0 15"
    },
    {
      "turn": 32,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qf7",
          "aggressive_uci": "f6f7",
          "aggressive_response": "16...Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf6 20. Re1 h6 21. Qe6+ Qxe6 22. Rxe6 Rd6 23. Rxd6 cxd6 24. Ne3 Kf7 25. Nd4 Ne5 26. Ke2 Kf6 27. Nd5+ Kg5 28. Nc7 Nc4 29. b3 Ne5 30. Nxa6 Kf4 31. Nxb5 d5 32. Nac7 Ke4 33. Nd6+ Kf4 34. Nxd5+ Kg5 35. a4 Nc6 36. b4 Kg6 37. b5 Na5 38. b6 Kh7 39. b7 Nxb7 40. Nxb7 g5 41. a5 Kg6 42. a6 Kf5 43. a7 Ke5 44. a8=Q Kxd5 45. Qa5+ Kc6 46. Qc5+ Kxb7 47. Kd3 g4 48. Kd4 h5 49. Kd5 h4 50. Kd6 g3 51. Qc6+ Ka7 52. Kc7 gxh2 53. Qb7# e4 d4 Qd3#",
          "aggressive_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 320,
            "total_tokens": 560,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxe6",
            "Qxe6",
            "Bxd8",
            "Rxd8",
            "Qe2",
            "Qf6",
            "Re1",
            "h6",
            "Qe6+",
            "Qxe6",
            "Rxe6",
            "Rd6",
            "Rxd6",
            "cxd6",
            "Ne3",
            "Kf7",
            "Nd4",
            "Ne5",
            "Ke2",
            "Kf6",
            "Nd5+",
            "Kg5",
            "Nc7",
            "Nc4",
            "b3",
            "Ne5",
            "Nxa6",
            "Kf4",
            "Nxb5",
            "d5",
            "Nac7",
            "Ke4",
            "Nd6+",
            "Kf4",
            "Nxd5+",
            "Kg5",
            "a4",
            "Nc6",
            "b4",
            "Kg6",
            "b5",
            "Na5",
            "b6",
            "Kh7",
            "b7",
            "Nxb7",
            "Nxb7",
            "g5",
            "a5",
            "Kg6",
            "a6",
            "Kf5",
            "a7",
            "Ke5",
            "a8=Q",
            "Kxd5",
            "Qa5+",
            "Kc6",
            "Qc5+",
            "Kxb7",
            "Kd3",
            "g4",
            "Kd4",
            "h5",
            "Kd5",
            "h4",
            "Kd6",
            "g3",
            "Qc6+",
            "Ka7",
            "Kc7",
            "gxh2",
            "Qb7#",
            "e4",
            "d4",
            "Qd3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qf7",
          "positional_uci": "f6f7",
          "positional_response": "16...Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf6 20. Re1 Kh8 21. Qe6 Qxe6 22.\nRxe6 Nb8 23. Ne3 h6 24. Ne5 Kg8 25. Re7 c5 26. Nf5 Rf8 27. Rxg7+ Kh8 28. Ng6# Bxg7\n29. Nxf8 Bxf8 30. Ke3 Kg8 31. Ke4 Kf7 32. Kd5 Kf6 33. Nd6 Nd7 34. Ne4+ Kf5 35. Nd6+\nKf6 36. Ne4+ Kf5 37. Nd6+ Kf6 38. Ne4+ Kf5 39. Nd6+ Kf6 40. Ne4+ Kf5 41. Nd6+\nKf6 42. Ne4+ Kf5 43. Nd6+ Kf6 44. Ne4+ Kf5 45. Nd6+ Kf6 46. Ne4+ Kf5 47. Nd6+\nKf6 48. Ne4+ Kf5 49. Nd6+ Kf6 50. Ne4+ Kf5 51. Nd6+ Kf6 52. Ne4+ Kf5 53. Nd6+\nKf6 54. Ne4+ Kf5 55. Nd6+ Kf6 56. Ne4+ Kf5 57. Nd6+ Kf6 58. Ne4+ Kf5 59. Nd6+\nKf6 60. Ne4+ Kf5 61. Nd6+ Kf6 62. Ne4+ Kf5 63. Nd6+ Kf6 64. Ne4+ Kf5 65. Nd6+\nKf6 66. Ne4+ Kf5 67. Nd6+ Kf6 68. Ne4+ Kf5 69. Nd6+ Kf6 70. Ne4+ Kf5 71. Nd6+\nKf6 72. Ne4+ Kf5 73. Nd6+ Kf6 74. Ne4+ Kf5 75. Nd6+ Kf6 76. Ne4+ Kf5 77. Nd6+\nKf6 78. Ne4+ Kf5 79. Nd6+ Kf6 80. Ne4+ Kf5 81. Nd6+ Kf6 82. Ne4+ Kf5 83. Nd6+\nKf6 84. Ne4+ Kf5 85. Nd6+ Kf6 86. Ne4+ Kf5 87. Nd6+ Kf6 88. Ne4+ Kf",
          "positional_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxe6",
            "Qxe6",
            "Bxd8",
            "Rxd8",
            "Qe2",
            "Qf6",
            "Re1",
            "Kh8",
            "Qe6",
            "Qxe6",
            "Rxe6",
            "Nb8",
            "Ne3",
            "h6",
            "Ne5",
            "Kg8",
            "Re7",
            "c5",
            "Nf5",
            "Rf8",
            "Rxg7+",
            "Kh8",
            "Ng6#",
            "Bxg7",
            "Nxf8",
            "Bxf8",
            "Ke3",
            "Kg8",
            "Ke4",
            "Kf7",
            "Kd5",
            "Kf6",
            "Nd6",
            "Nd7",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+",
            "Kf5",
            "Nd6+",
            "Kf6",
            "Ne4+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qf7",
          "neutral_uci": "f6f7",
          "neutral_response": "16...Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf6 20. Rd1 Rf8 21. Kg1 h6 22. Ng3\nNe7 23. Qe5 Qf7 24. Rd7 Re8 25. Nf5 Kf8 26. Nxe7 Rxe7 27. Rxe7 Qxe7 28. Qxe7+\nKxe7 29. Kf2 Kd6 30. Ke3 Kd5 31. Kd3 c5 32. b3 c4+ 33. bxc4+ bxc4+ 34. Ke3 g5\n35. Nd2 a5 36. a4 h5 37. g3 g4 38. Kf4 Kc5 39. Ke5 Kc6 40. Nxc4 Kc5 41. Nxa5\nKb6 42. Nb3 Kc6 43. c4 Kb6 44. c5+ Kc6 45. Ke6 Kc7 46. Kd5 Kb7 47. c6+ Kc7\n48. Kc5 Kc8 49. Kd6 Kd8 50. c7+ Kc8 51. Kc6 h4 52. Nc5 hxg3 53. Nb7 gxh2\n54. Nd6# Kd7 55. c8=Q+ Ke7 56. Qe8+ Kf6 57. Qf7+ Kg5 58. Qf5+ Kh4 59. Qf2+\ng3 60. Qg2 Kg4 61. Ne4 Kf4 62. Nxg3 Ke5 63. Qe4+ Kf6 64. Qf5+ Ke7 65. Qg6\nKd8 66. Qf7 Kc8 67. Qc7# Kxc7 68. a5 Kb7 69. Kb5 Ka7 70. a6 Ka8 71. Kb6 Kb8\n72. a7+ Ka8 73. Ne4 h1=Q 74. Nc5 Qb1+ 75. Ka6 Qa2+ 76. Kb6 Qxa7+ 77. Kc6 Qa1\n78. Kb6 Qb2+ 79. Kc6 Qc3 80. Kb6 Qb4+ 81. Kc6 Ka7 82. Kd6 Kb6 83. Kd5 Qxc5+\n84. Ke4 Kc6 85. Kd3 Kd5 86. Ke2 Ke4 87. Kd2 Qc4 88. Kd1 Ke3 89. Ke1 Qc1# Kd3\n90. Kf",
          "neutral_tokens": {
            "prompt_tokens": 239,
            "completion_tokens": 640,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kc8",
            "Qc7#",
            "Kxc7",
            "a5",
            "Kb7",
            "Kb5",
            "Ka7",
            "a6",
            "Ka8",
            "Kb6",
            "Kb8",
            "a7+",
            "Ka8",
            "Ne4",
            "h1=Q",
            "Nc5",
            "Qb1+",
            "Ka6",
            "Qa2+",
            "Kb6",
            "Qxa7+",
            "Kc6",
            "Qa1",
            "Kb6",
            "Qb2+",
            "Kc6",
            "Qc3",
            "Kb6",
            "Qb4+",
            "Kc6",
            "Ka7",
            "Kd6",
            "Kb6",
            "Kd5",
            "Qxc5+",
            "Ke4",
            "Kc6",
            "Kd3",
            "Kd5",
            "Ke2",
            "Ke4",
            "Kd2",
            "Qc4",
            "Kd1",
            "Ke3",
            "Ke1",
            "Qc1#",
            "Kd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f6f7",
          "positional_uci": "f6f7",
          "neutral_uci": "f6f7",
          "consensus_move": "f6f7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxe6",
              "Qxe6",
              "Bxd8",
              "Rxd8",
              "Qe2",
              "Qf6",
              "Re1",
              "h6",
              "Qe6+",
              "Qxe6",
              "Rxe6",
              "Rd6",
              "Rxd6",
              "cxd6",
              "Ne3",
              "Kf7",
              "Nd4",
              "Ne5",
              "Ke2",
              "Kf6",
              "Nd5+",
              "Kg5",
              "Nc7",
              "Nc4",
              "b3",
              "Ne5",
              "Nxa6",
              "Kf4",
              "Nxb5",
              "d5",
              "Nac7",
              "Ke4",
              "Nd6+",
              "Kf4",
              "Nxd5+",
              "Kg5",
              "a4",
              "Nc6",
              "b4",
              "Kg6",
              "b5",
              "Na5",
              "b6",
              "Kh7",
              "b7",
              "Nxb7",
              "Nxb7",
              "g5",
              "a5",
              "Kg6",
              "a6",
              "Kf5",
              "a7",
              "Ke5",
              "a8=Q",
              "Kxd5",
              "Qa5+",
              "Kc6",
              "Qc5+",
              "Kxb7",
              "Kd3",
              "g4",
              "Kd4",
              "h5",
              "Kd5",
              "h4",
              "Kd6",
              "g3",
              "Qc6+",
              "Ka7",
              "Kc7",
              "gxh2",
              "Qb7#",
              "e4",
              "d4",
              "Qd3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxe6",
              "Qxe6",
              "Bxd8",
              "Rxd8",
              "Qe2",
              "Qf6",
              "Re1",
              "Kh8",
              "Qe6",
              "Qxe6",
              "Rxe6",
              "Nb8",
              "Ne3",
              "h6",
              "Ne5",
              "Kg8",
              "Re7",
              "c5",
              "Nf5",
              "Rf8",
              "Rxg7+",
              "Kh8",
              "Ng6#",
              "Bxg7",
              "Nxf8",
              "Bxf8",
              "Ke3",
              "Kg8",
              "Ke4",
              "Kf7",
              "Kd5",
              "Kf6",
              "Nd6",
              "Nd7",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+",
              "Kf5",
              "Nd6+",
              "Kf6",
              "Ne4+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kc8",
              "Qc7#",
              "Kxc7",
              "a5",
              "Kb7",
              "Kb5",
              "Ka7",
              "a6",
              "Ka8",
              "Kb6",
              "Kb8",
              "a7+",
              "Ka8",
              "Ne4",
              "h1=Q",
              "Nc5",
              "Qb1+",
              "Ka6",
              "Qa2+",
              "Kb6",
              "Qxa7+",
              "Kc6",
              "Qa1",
              "Kb6",
              "Qb2+",
              "Kc6",
              "Qc3",
              "Kb6",
              "Qb4+",
              "Kc6",
              "Ka7",
              "Kd6",
              "Kb6",
              "Kd5",
              "Qxc5+",
              "Ke4",
              "Kc6",
              "Kd3",
              "Kd5",
              "Ke2",
              "Ke4",
              "Kd2",
              "Qc4",
              "Kd1",
              "Ke3",
              "Ke1",
              "Qc1#",
              "Kd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 240,
            "completion_tokens": 320,
            "total_tokens": 560,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 239,
            "completion_tokens": 640,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 719,
          "total_completion_tokens": 1600,
          "total_tokens": 2319
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 240,
            "completion_tokens": 320,
            "total_tokens": 560,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 31,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 239,
            "completion_tokens": 640,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "3r1rk1/2p3pp/p1n1bq2/1p1B2B1/8/2P2N2/PP3KPP/R2Q1N2 b - - 2 16"
    },
    {
      "turn": 34,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe6",
          "aggressive_uci": "f7e6",
          "aggressive_response": "17... Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf6 20. Re1 Rd6 21. Qe8+ Qf8 22. Qxf8+ Kxf8 23. Ng3\nh6 24. Ne4 Rd5 25. Ke3 Kf7 26. Nd4 Ne5 27. Rf1+ Ke7 28. Nf5+ Kd7 29. Nxg7 Nc4+ 30. Ke2 Nxb2 31. Nf6+ Kd6 32. Nxd5 Kxd5 33. Rf6 c5 34. Rxa6 Kc4 35. Rxh6 Kxc3 36. Rh5 Kb4 37. Ne6 c4 38. Nd4 c3 39. Rxb5+ Kc4 40. Rxb2 cxb2 41. Nc2 Kc3 42. Na3 Kb4 43. Nb1 Kc4 44. h4 Kd4 45. h5 Ke5 46. a4 Kf6 47. a5 Kg5 48. a6 Kxh5 49. a7 Kg4 50. a8=Q Kg3 51. Qf3+ Kh2 52. Kf2 Kh1 53. Qh3#",
          "aggressive_tokens": {
            "prompt_tokens": 249,
            "completion_tokens": 306,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxd8",
            "Rxd8",
            "Qe2",
            "Qf6",
            "Re1",
            "Rd6",
            "Qe8+",
            "Qf8",
            "Qxf8+",
            "Kxf8",
            "Ng3",
            "h6",
            "Ne4",
            "Rd5",
            "Ke3",
            "Kf7",
            "Nd4",
            "Ne5",
            "Rf1+",
            "Ke7",
            "Nf5+",
            "Kd7",
            "Nxg7",
            "Nc4+",
            "Ke2",
            "Nxb2",
            "Nf6+",
            "Kd6",
            "Nxd5",
            "Kxd5",
            "Rf6",
            "c5",
            "Rxa6",
            "Kc4",
            "Rxh6",
            "Kxc3",
            "Rh5",
            "Kb4",
            "Ne6",
            "c4",
            "Nd4",
            "c3",
            "Rxb5+",
            "Kc4",
            "Rxb2",
            "cxb2",
            "Nc2",
            "Kc3",
            "Na3",
            "Kb4",
            "Nb1",
            "Kc4",
            "h4",
            "Kd4",
            "h5",
            "Ke5",
            "a4",
            "Kf6",
            "a5",
            "Kg5",
            "a6",
            "Kxh5",
            "a7",
            "Kg4",
            "a8=Q",
            "Kg3",
            "Qf3+",
            "Kh2",
            "Kf2",
            "Kh1",
            "Qh3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 18. Bxf7+ Rxf7 19. Qd5 Ne5 20. Re1\nNg4+ 21. Kg1 Rxe1 22. Nxe1 h6 23. Bd8 Kf8 24. Qc5+ Ke8 25. Bxc7 Nf6 26. Qc6+ Kf8\n27. Bd6+ Kg8 28. Qxa6 Ne4 29. Qa8+ Kh7 30. Qxe4+ Kg8 31. Qe8+ Kh7 32. Qxf7 b4\n33. Be5 bxc3 34. Qxg7# e4 Nf6 Qg6",
          "positional_tokens": {
            "prompt_tokens": 249,
            "completion_tokens": 156,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf7+",
            "Rxf7",
            "Qd5",
            "Ne5",
            "Re1",
            "Ng4+",
            "Kg1",
            "Rxe1",
            "Nxe1",
            "h6",
            "Bd8",
            "Kf8",
            "Qc5+",
            "Ke8",
            "Bxc7",
            "Nf6",
            "Qc6+",
            "Kf8",
            "Bd6+",
            "Kg8",
            "Qxa6",
            "Ne4",
            "Qa8+",
            "Kh7",
            "Qxe4+",
            "Kg8",
            "Qe8+",
            "Kh7",
            "Qxf7",
            "b4",
            "Be5",
            "bxc3",
            "Qxg7#",
            "e4",
            "Nf6",
            "Qg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e5",
          "neutral_uci": null,
          "neutral_response": "Repeating the entire game so far: 1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1 O-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 * e5 d5 19. Bxd5+ Kh8",
          "neutral_tokens": {
            "prompt_tokens": 248,
            "completion_tokens": 160,
            "total_tokens": 408,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Bxd5+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f7e6",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "f7e6",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxd8",
              "Rxd8",
              "Qe2",
              "Qf6",
              "Re1",
              "Rd6",
              "Qe8+",
              "Qf8",
              "Qxf8+",
              "Kxf8",
              "Ng3",
              "h6",
              "Ne4",
              "Rd5",
              "Ke3",
              "Kf7",
              "Nd4",
              "Ne5",
              "Rf1+",
              "Ke7",
              "Nf5+",
              "Kd7",
              "Nxg7",
              "Nc4+",
              "Ke2",
              "Nxb2",
              "Nf6+",
              "Kd6",
              "Nxd5",
              "Kxd5",
              "Rf6",
              "c5",
              "Rxa6",
              "Kc4",
              "Rxh6",
              "Kxc3",
              "Rh5",
              "Kb4",
              "Ne6",
              "c4",
              "Nd4",
              "c3",
              "Rxb5+",
              "Kc4",
              "Rxb2",
              "cxb2",
              "Nc2",
              "Kc3",
              "Na3",
              "Kb4",
              "Nb1",
              "Kc4",
              "h4",
              "Kd4",
              "h5",
              "Ke5",
              "a4",
              "Kf6",
              "a5",
              "Kg5",
              "a6",
              "Kxh5",
              "a7",
              "Kg4",
              "a8=Q",
              "Kg3",
              "Qf3+",
              "Kh2",
              "Kf2",
              "Kh1",
              "Qh3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf7+",
              "Rxf7",
              "Qd5",
              "Ne5",
              "Re1",
              "Ng4+",
              "Kg1",
              "Rxe1",
              "Nxe1",
              "h6",
              "Bd8",
              "Kf8",
              "Qc5+",
              "Ke8",
              "Bxc7",
              "Nf6",
              "Qc6+",
              "Kf8",
              "Bd6+",
              "Kg8",
              "Qxa6",
              "Ne4",
              "Qa8+",
              "Kh7",
              "Qxe4+",
              "Kg8",
              "Qe8+",
              "Kh7",
              "Qxf7",
              "b4",
              "Be5",
              "bxc3",
              "Qxg7#",
              "e4",
              "Nf6",
              "Qg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Bxd5+",
              "Kh8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 249,
            "completion_tokens": 306,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 249,
            "completion_tokens": 156,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 248,
            "completion_tokens": 160,
            "total_tokens": 408,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 746,
          "total_completion_tokens": 622,
          "total_tokens": 1368
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 249,
            "completion_tokens": 306,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 249,
            "completion_tokens": 156,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 33,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 248,
            "completion_tokens": 160,
            "total_tokens": 408,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r1rk1/2p2qpp/p1n1B3/1p4B1/8/2P2N2/PP3KPP/R2Q1N2 b - - 0 17"
    },
    {
      "turn": 36,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxd8",
          "aggressive_uci": "f8d8",
          "aggressive_response": "18... Rxd8 19. Qe2 Qf7 20. Kg1 Re8 21. Qf2 Qc4 22. Ne3 Qc5 23. Re1 b4 24. cxb4\nNxb4 25. Ng4 Rxe1+ 26. Nxe1 Qc1 27. Qe2 h6 28. a3 Nc6 29. Qe8+ Kh7 30. Qe4+\nKh8 31. Qe3 Qxb2 32. Qe8+ Kh7 33. Qxc6 Qd4+ 34. Nf2 Qe3 35. Qe4+ Qxe4 36.\nNxe4 Kg6 37. Nc5 a5 38. Nb3 a4 39. Nc5 Kf5 40. Nxa4 Ke4 41. Kf2 Kd4 42. Ke2\nKc4 43. Kd2 Kb3 44. Nc5+ Kxa3 45. Ne6 Kb4 46. Nxc7 Kc5 47. Ne6+ Kd5 48. Nxg7\nKe5 49. Ke3 Kf6 50. Nh5+ Kg5 51. Ng3 Kg4 52. Ke4 h5 53. Nxh5 Kxh5 54. Kf5 Kh6\n55. g4 Kg7 56. Kg5 Kh7 57. Kf6 Kg8 58. Kg6 Kh8 59. Kf7 Kh7 60. g5 Kh8 61. h4\nKh7 62. g6+ Kh6 63. g7 Kh5 64. g8=Q Kxh4 65. Kf6 Kh3 66. Kf5 Kh2 67. Kf4\nKh1 68. Kf3 Kh2 69. Qg2# e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 d5 dxe5 Be6 Bc5 Nxf2 Rxf2 Bxf2 Kxf2 f6 exf6 Qxf6 Nf1 O-O Bxd5 Rad8 Bg5 Qf7 Kg1 Re8 Qf2 Qc4 Ne3 Qc5 Ne3 Qc1+ Nf1 Qc5 Ne3 Qc1+ Nf1 Qc5 Ne3 Qc1+ Nf1 Qc5",
          "aggressive_tokens": {
            "prompt_tokens": 258,
            "completion_tokens": 549,
            "total_tokens": 807,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Qf7",
            "Kg1",
            "Re8",
            "Qf2",
            "Qc4",
            "Ne3",
            "Qc5",
            "Re1",
            "b4",
            "cxb4",
            "Nxb4",
            "Ng4",
            "Rxe1+",
            "Nxe1",
            "Qc1",
            "Qe2",
            "h6",
            "a3",
            "Nc6",
            "Qe8+",
            "Kh7",
            "Qe4+",
            "Kh8",
            "Qe3",
            "Qxb2",
            "Qe8+",
            "Kh7",
            "Qxc6",
            "Qd4+",
            "Nf2",
            "Qe3",
            "Qe4+",
            "Qxe4",
            "Nxe4",
            "Kg6",
            "Nc5",
            "a5",
            "Nb3",
            "a4",
            "Nc5",
            "Kf5",
            "Nxa4",
            "Ke4",
            "Kf2",
            "Kd4",
            "Ke2",
            "Kc4",
            "Kd2",
            "Kb3",
            "Nc5+",
            "Kxa3",
            "Ne6",
            "Kb4",
            "Nxc7",
            "Kc5",
            "Ne6+",
            "Kd5",
            "Nxg7",
            "Ke5",
            "Ke3",
            "Kf6",
            "Nh5+",
            "Kg5",
            "Ng3",
            "Kg4",
            "Ke4",
            "h5",
            "Nxh5",
            "Kxh5",
            "Kf5",
            "Kh6",
            "g4",
            "Kg7",
            "Kg5",
            "Kh7",
            "Kf6",
            "Kg8",
            "Kg6",
            "Kh8",
            "Kf7",
            "Kh7",
            "g5",
            "Kh8",
            "h4",
            "Kh7",
            "g6+",
            "Kh6",
            "g7",
            "Kh5",
            "g8=Q",
            "Kxh4",
            "Kf6",
            "Kh3",
            "Kf5",
            "Kh2",
            "Kf4",
            "Kh1",
            "Kf3",
            "Kh2",
            "Qg2#",
            "e4",
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "a6",
            "Ba4",
            "Nf6",
            "d5",
            "dxe5",
            "Be6",
            "Bc5",
            "Nxf2",
            "Rxf2",
            "Bxf2",
            "Kxf2",
            "f6",
            "exf6",
            "Qxf6",
            "Nf1",
            "O-O",
            "Bxd5",
            "Rad8",
            "Bg5",
            "Qf7",
            "Kg1",
            "Re8",
            "Qf2",
            "Qc4",
            "Ne3",
            "Qc5",
            "Ne3",
            "Qc1+",
            "Nf1",
            "Qc5",
            "Ne3",
            "Qc1+",
            "Nf1",
            "Qc5",
            "Ne3",
            "Qc1+",
            "Nf1",
            "Qc5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxd8",
          "positional_uci": "c6d8",
          "positional_response": "Repeated game: 1. e4 e5\n2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6\n9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Nxd8 19. Qe2 Qb6+ 20. Qe3\nQxe3+ 21. Nxe3 Ne6 22. Rd1 Nc5 23. Ke2 Re8 24. Rd5 Na4 25. Rd2 Nb6 26. b3 c5\n27. Rd6 Nc8 28. Rxa6 c4 29. bxc4 bxc4 30. Rc6 Ne7 31. Rxc4 Nd5 32. Kd2 Nxe3\n33. Rd4 Nxg2 34. a4 Rf8 35. Ne5 Rf2+ 36. Kd3 Nf4+ 37. Ke3 Rf1 38. Rd8# e4 Nc6\nNxe3#",
          "positional_tokens": {
            "prompt_tokens": 258,
            "completion_tokens": 328,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe2",
            "Qb6+",
            "Qe3",
            "Qxe3+",
            "Nxe3",
            "Ne6",
            "Rd1",
            "Nc5",
            "Ke2",
            "Re8",
            "Rd5",
            "Na4",
            "Rd2",
            "Nb6",
            "b3",
            "c5",
            "Rd6",
            "Nc8",
            "Rxa6",
            "c4",
            "bxc4",
            "bxc4",
            "Rc6",
            "Ne7",
            "Rxc4",
            "Nd5",
            "Kd2",
            "Nxe3",
            "Rd4",
            "Nxg2",
            "a4",
            "Rf8",
            "Ne5",
            "Rf2+",
            "Kd3",
            "Nf4+",
            "Ke3",
            "Rf1",
            "Rd8#",
            "e4",
            "Nc6",
            "Nxe3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxd8",
          "neutral_uci": "f8d8",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Rd1\nRf8 21. Kg1 Qxa2 22. Rd7 Qa5 23. Qe6+ Kh8 24. Qxc6 Qa1 25. Qxc7 Qxb2 26. Rxg7\nQc2 27. Qe5 Qf5 28. Qxf5 Rxf5 29. Ra7 Rf6 30. Ne3 Rc6 31. Nd5 Rd6 32. Nb4\nRd1+ 33. Kf2 Rc1 34. Nd5 Ra1 35. Nf6 Ra2+ 36. Kg3 Rxg2+ 37. Kxg2 h5 38. Rh7# e4\n39. Ng5 e3 40. Ne6 e2 41. Kf2 e1=Q+ 42. Kxe1 b4 43. cxb4 a5 44. b5 a4 45. b6\na3 46. b7 a2 47. b8=Q# e5 48. Qf8# e4 49. Qg7# e3 50. Qg8# e2 51. Qh7# e1=Q+\n52. Kxe1 a5 53. Kd2 a4 54. Kc3 a3 55. Kb3 a2 56. Kb4 a1=Q 57. Qg7# e2 58. Qh6# e1=Q+ 59. Kc5 Qc3+ 60. Kd6 Qd3+ 61. Ke7 Qe4+ 62. Kf8 Qf5+ 63. Nf7+ Qxf7+ 64. Kxf7# e3 65. Qg7# e2 66. Qh6# e1=Q 67. Qg7# e2 68. Qh6# e1=Q 69. Qg7# e2 70. Qh6# e1=Q 71. Qg7# e2 72. Qh6# e1=Q 73. Qg",
          "neutral_tokens": {
            "prompt_tokens": 257,
            "completion_tokens": 640,
            "total_tokens": 897,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qe2",
            "Qf7",
            "Rd1",
            "Rf8",
            "Kg1",
            "Qxa2",
            "Rd7",
            "Qa5",
            "Qe6+",
            "Kh8",
            "Qxc6",
            "Qa1",
            "Qxc7",
            "Qxb2",
            "Rxg7",
            "Qc2",
            "Qe5",
            "Qf5",
            "Qxf5",
            "Rxf5",
            "Ra7",
            "Rf6",
            "Ne3",
            "Rc6",
            "Nd5",
            "Rd6",
            "Nb4",
            "Rd1+",
            "Kf2",
            "Rc1",
            "Nd5",
            "Ra1",
            "Nf6",
            "Ra2+",
            "Kg3",
            "Rxg2+",
            "Kxg2",
            "h5",
            "Rh7#",
            "e4",
            "Ng5",
            "e3",
            "Ne6",
            "e2",
            "Kf2",
            "e1=Q+",
            "Kxe1",
            "b4",
            "cxb4",
            "a5",
            "b5",
            "a4",
            "b6",
            "a3",
            "b7",
            "a2",
            "b8=Q#",
            "e5",
            "Qf8#",
            "e4",
            "Qg7#",
            "e3",
            "Qg8#",
            "e2",
            "Qh7#",
            "e1=Q+",
            "Kxe1",
            "a5",
            "Kd2",
            "a4",
            "Kc3",
            "a3",
            "Kb3",
            "a2",
            "Kb4",
            "a1=Q",
            "Qg7#",
            "e2",
            "Qh6#",
            "e1=Q+",
            "Kc5",
            "Qc3+",
            "Kd6",
            "Qd3+",
            "Ke7",
            "Qe4+",
            "Kf8",
            "Qf5+",
            "Nf7+",
            "Qxf7+",
            "Kxf7#",
            "e3",
            "Qg7#",
            "e2",
            "Qh6#",
            "e1=Q",
            "Qg7#",
            "e2",
            "Qh6#",
            "e1=Q",
            "Qg7#",
            "e2",
            "Qh6#",
            "e1=Q",
            "Qg7#",
            "e2",
            "Qh6#",
            "e1=Q"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8d8",
          "positional_uci": "c6d8",
          "neutral_uci": "f8d8",
          "consensus_move": "f8d8",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qe2",
              "Qf7",
              "Kg1",
              "Re8",
              "Qf2",
              "Qc4",
              "Ne3",
              "Qc5",
              "Re1",
              "b4",
              "cxb4",
              "Nxb4",
              "Ng4",
              "Rxe1+",
              "Nxe1",
              "Qc1",
              "Qe2",
              "h6",
              "a3",
              "Nc6",
              "Qe8+",
              "Kh7",
              "Qe4+",
              "Kh8",
              "Qe3",
              "Qxb2",
              "Qe8+",
              "Kh7",
              "Qxc6",
              "Qd4+",
              "Nf2",
              "Qe3",
              "Qe4+",
              "Qxe4",
              "Nxe4",
              "Kg6",
              "Nc5",
              "a5",
              "Nb3",
              "a4",
              "Nc5",
              "Kf5",
              "Nxa4",
              "Ke4",
              "Kf2",
              "Kd4",
              "Ke2",
              "Kc4",
              "Kd2",
              "Kb3",
              "Nc5+",
              "Kxa3",
              "Ne6",
              "Kb4",
              "Nxc7",
              "Kc5",
              "Ne6+",
              "Kd5",
              "Nxg7",
              "Ke5",
              "Ke3",
              "Kf6",
              "Nh5+",
              "Kg5",
              "Ng3",
              "Kg4",
              "Ke4",
              "h5",
              "Nxh5",
              "Kxh5",
              "Kf5",
              "Kh6",
              "g4",
              "Kg7",
              "Kg5",
              "Kh7",
              "Kf6",
              "Kg8",
              "Kg6",
              "Kh8",
              "Kf7",
              "Kh7",
              "g5",
              "Kh8",
              "h4",
              "Kh7",
              "g6+",
              "Kh6",
              "g7",
              "Kh5",
              "g8=Q",
              "Kxh4",
              "Kf6",
              "Kh3",
              "Kf5",
              "Kh2",
              "Kf4",
              "Kh1",
              "Kf3",
              "Kh2",
              "Qg2#",
              "e4",
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "a6",
              "Ba4",
              "Nf6",
              "d5",
              "dxe5",
              "Be6",
              "Bc5",
              "Nxf2",
              "Rxf2",
              "Bxf2",
              "Kxf2",
              "f6",
              "exf6",
              "Qxf6",
              "Nf1",
              "O-O",
              "Bxd5",
              "Rad8",
              "Bg5",
              "Qf7",
              "Kg1",
              "Re8",
              "Qf2",
              "Qc4",
              "Ne3",
              "Qc5",
              "Ne3",
              "Qc1+",
              "Nf1",
              "Qc5",
              "Ne3",
              "Qc1+",
              "Nf1",
              "Qc5",
              "Ne3",
              "Qc1+",
              "Nf1",
              "Qc5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe2",
              "Qb6+",
              "Qe3",
              "Qxe3+",
              "Nxe3",
              "Ne6",
              "Rd1",
              "Nc5",
              "Ke2",
              "Re8",
              "Rd5",
              "Na4",
              "Rd2",
              "Nb6",
              "b3",
              "c5",
              "Rd6",
              "Nc8",
              "Rxa6",
              "c4",
              "bxc4",
              "bxc4",
              "Rc6",
              "Ne7",
              "Rxc4",
              "Nd5",
              "Kd2",
              "Nxe3",
              "Rd4",
              "Nxg2",
              "a4",
              "Rf8",
              "Ne5",
              "Rf2+",
              "Kd3",
              "Nf4+",
              "Ke3",
              "Rf1",
              "Rd8#",
              "e4",
              "Nc6",
              "Nxe3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe2",
              "Qf7",
              "Rd1",
              "Rf8",
              "Kg1",
              "Qxa2",
              "Rd7",
              "Qa5",
              "Qe6+",
              "Kh8",
              "Qxc6",
              "Qa1",
              "Qxc7",
              "Qxb2",
              "Rxg7",
              "Qc2",
              "Qe5",
              "Qf5",
              "Qxf5",
              "Rxf5",
              "Ra7",
              "Rf6",
              "Ne3",
              "Rc6",
              "Nd5",
              "Rd6",
              "Nb4",
              "Rd1+",
              "Kf2",
              "Rc1",
              "Nd5",
              "Ra1",
              "Nf6",
              "Ra2+",
              "Kg3",
              "Rxg2+",
              "Kxg2",
              "h5",
              "Rh7#",
              "e4",
              "Ng5",
              "e3",
              "Ne6",
              "e2",
              "Kf2",
              "e1=Q+",
              "Kxe1",
              "b4",
              "cxb4",
              "a5",
              "b5",
              "a4",
              "b6",
              "a3",
              "b7",
              "a2",
              "b8=Q#",
              "e5",
              "Qf8#",
              "e4",
              "Qg7#",
              "e3",
              "Qg8#",
              "e2",
              "Qh7#",
              "e1=Q+",
              "Kxe1",
              "a5",
              "Kd2",
              "a4",
              "Kc3",
              "a3",
              "Kb3",
              "a2",
              "Kb4",
              "a1=Q",
              "Qg7#",
              "e2",
              "Qh6#",
              "e1=Q+",
              "Kc5",
              "Qc3+",
              "Kd6",
              "Qd3+",
              "Ke7",
              "Qe4+",
              "Kf8",
              "Qf5+",
              "Nf7+",
              "Qxf7+",
              "Kxf7#",
              "e3",
              "Qg7#",
              "e2",
              "Qh6#",
              "e1=Q",
              "Qg7#",
              "e2",
              "Qh6#",
              "e1=Q",
              "Qg7#",
              "e2",
              "Qh6#",
              "e1=Q",
              "Qg7#",
              "e2",
              "Qh6#",
              "e1=Q"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 258,
            "completion_tokens": 549,
            "total_tokens": 807,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 258,
            "completion_tokens": 328,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 257,
            "completion_tokens": 640,
            "total_tokens": 897,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 773,
          "total_completion_tokens": 1517,
          "total_tokens": 2290
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 258,
            "completion_tokens": 549,
            "total_tokens": 807,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 258,
            "completion_tokens": 328,
            "total_tokens": 586,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 35,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 257,
            "completion_tokens": 640,
            "total_tokens": 897,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "3B1rk1/2p3pp/p1n1q3/1p6/8/2P2N2/PP3KPP/R2Q1N2 b - - 0 18"
    },
    {
      "turn": 38,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qf7",
          "aggressive_uci": "e6f7",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Rd1\nRxd1 21. Qxd1 Qxa2 22. Qd2 Qe6 23. Ne3 Ne7 24. Qd8+ Kf7 25. Ng5+ Kf6 26. Nxe6\nKxe6 27. Qxc7 Kf6 28. Qd6+ Kf7 29. Nd5 Nxd5 30. Qxd5+ Kf6 31. Qc6+ Kf7 32. Qxa6\nKg8 33. Qxb5 Kf7 34. Qd7+ Kf6 35. c4 Kg6 36. c5 Kf6 37. c6 Kg6 38. c7 Kf6 39.\nc8=Q Kg6 40. Qf5+ Kh6 41. Qce6+ g6 42. Qf8+ Kh5 43. Qh3+ Kg5 44. Qhh6+ Kg4 45.\nh3# e5 e6 e7",
          "aggressive_tokens": {
            "prompt_tokens": 267,
            "completion_tokens": 396,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd1",
            "Rxd1",
            "Qxd1",
            "Qxa2",
            "Qd2",
            "Qe6",
            "Ne3",
            "Ne7",
            "Qd8+",
            "Kf7",
            "Ng5+",
            "Kf6",
            "Nxe6",
            "Kxe6",
            "Qxc7",
            "Kf6",
            "Qd6+",
            "Kf7",
            "Nd5",
            "Nxd5",
            "Qxd5+",
            "Kf6",
            "Qc6+",
            "Kf7",
            "Qxa6",
            "Kg8",
            "Qxb5",
            "Kf7",
            "Qd7+",
            "Kf6",
            "c4",
            "Kg6",
            "c5",
            "Kf6",
            "c6",
            "Kg6",
            "c7",
            "Kf6",
            "c8=Q",
            "Kg6",
            "Qf5+",
            "Kh6",
            "Qce6+",
            "g6",
            "Qf8+",
            "Kh5",
            "Qh3+",
            "Kg5",
            "Qhh6+",
            "Kg4",
            "h3#",
            "e5",
            "e6",
            "e7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qf7",
          "positional_uci": "e6f7",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Rd1\nRxd1 21. Qxd1 Qxa2 22. Qd2 h6 23. Ne3 Qe6 24. Qd5 Qxd5 25. Nxd5 Na5 26. Nxc7 Nc4\n27. b3 Na5 28. Nd4 Kf7 29. Nxa6 Kf6 30. Nc5 Ke5 31. Ke3 Kd5 32. Nd3 g5 33. Nb4+\nKc5 34. Kd3 Nb7 35. Nf5 h5 36. Ng3 h4 37. Ne4+ Kb6 38. Nxg5 Nc5+ 39. Kc2 Nd7\n40. Nf3 Nf6 41. Nxh4 Ng4 42. h3 Ne3+ 43. Kd3 Nd1 44. Nf3 Nf2+ 45. Kd4 Nd1\n46. h4 Nf2 47. h5 Ng4 48. Ne5 Nh6 49. g4 Kc7 50. g5 Nf5+ 51. Kc5 Ng3 52. h6\nNe4+ 53. Kxb5 Nxg5 54. Nd5+ Kd6 55. Nf6 Kxe5 56. h7 Nf7 57. Ng4+ Kd6 58. c4\nKc7 59. c5 Kb7 60. b4 Kc7 61. Ka6 Kb8 62. b5 Ka8 63. b6 Kb8 64. c6 Ka8 65. b7+\nKb8 66. Kb6 Nd6 67. h8=Q+ Ne8 68. Qxe8#",
          "positional_tokens": {
            "prompt_tokens": 267,
            "completion_tokens": 562,
            "total_tokens": 829,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd1",
            "Rxd1",
            "Qxd1",
            "Qxa2",
            "Qd2",
            "h6",
            "Ne3",
            "Qe6",
            "Qd5",
            "Qxd5",
            "Nxd5",
            "Na5",
            "Nxc7",
            "Nc4",
            "b3",
            "Na5",
            "Nd4",
            "Kf7",
            "Nxa6",
            "Kf6",
            "Nc5",
            "Ke5",
            "Ke3",
            "Kd5",
            "Nd3",
            "g5",
            "Nb4+",
            "Kc5",
            "Kd3",
            "Nb7",
            "Nf5",
            "h5",
            "Ng3",
            "h4",
            "Ne4+",
            "Kb6",
            "Nxg5",
            "Nc5+",
            "Kc2",
            "Nd7",
            "Nf3",
            "Nf6",
            "Nxh4",
            "Ng4",
            "h3",
            "Ne3+",
            "Kd3",
            "Nd1",
            "Nf3",
            "Nf2+",
            "Kd4",
            "Nd1",
            "h4",
            "Nf2",
            "h5",
            "Ng4",
            "Ne5",
            "Nh6",
            "g4",
            "Kc7",
            "g5",
            "Nf5+",
            "Kc5",
            "Ng3",
            "h6",
            "Ne4+",
            "Kxb5",
            "Nxg5",
            "Nd5+",
            "Kd6",
            "Nf6",
            "Kxe5",
            "h7",
            "Nf7",
            "Ng4+",
            "Kd6",
            "c4",
            "Kc7",
            "c5",
            "Kb7",
            "b4",
            "Kc7",
            "Ka6",
            "Kb8",
            "b5",
            "Ka8",
            "b6",
            "Kb8",
            "c6",
            "Ka8",
            "b7+",
            "Kb8",
            "Kb6",
            "Nd6",
            "h8=Q+",
            "Ne8",
            "Qxe8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qf7",
          "neutral_uci": "e6f7",
          "neutral_response": "19... Qf7 20. Rd1 Re8 21. Qd3 Ne5 22. Qd5 Nxf3 23. Qxf7+ Kxf7 24. gxf3 Re7 25. Ne3 g6 26. Nd5 Rd7 27. Ne3 Re7 28. Rd4 c5 29. Rd6 a5 30. Rb6 b4 31. cxb4 axb4 32. Rc6 Re5 33. Nc4 Rd5 34. Ke3 Rh5 35. Nd6+ Ke7 36. Ne4 Rxh2 37. Rxc5 Rxb2 38. Ra5 h5 39. Kf4 Rg2 40. Ra4 h4 41. Rxb4 Rxa2 42. Kg4 Rh2 43. Rb6 Kf7 44. Ng5+ Kg7 45. Rb7+ Kf6 46. Rf7+ Ke5 47. f4+ Kd5 48. Rf6 Rg2+ 49. Kxh4 Rh2+ 50. Kg3 Rh6 51. Nf7 Rh7 52. Ne5 g5 53. Ng4 gxf4+ 54. Kxf4 Rh1 55. Ne3+ Kc5 56. Rf5+ Kd6 57. Rd5+ Ke6 58. Re5+ Kd6 59. Nf5+ Kc6 60. Nd4+ Kd6 61. Re6+ Kd5 62. Re4 Rh4+ 63. Ke3 Rxe4+ 64. Kd3 Rxd4+ 65. Ke3 Ke5 66. Kf3 Re4 67. Kg3 Rf4 68. Kh3 Kf5 69. Kg3 Kg5 70. Kh3 Rg4 71. Kh2 Kf4 72. Kh3 Kf3 73. Kh2 Rg3 74. Kh1 Kf2 75. Kh2 Rf3 76. Kh1 Rh3#",
          "neutral_tokens": {
            "prompt_tokens": 266,
            "completion_tokens": 475,
            "total_tokens": 741,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd1",
            "Re8",
            "Qd3",
            "Ne5",
            "Qd5",
            "Nxf3",
            "Qxf7+",
            "Kxf7",
            "gxf3",
            "Re7",
            "Ne3",
            "g6",
            "Nd5",
            "Rd7",
            "Ne3",
            "Re7",
            "Rd4",
            "c5",
            "Rd6",
            "a5",
            "Rb6",
            "b4",
            "cxb4",
            "axb4",
            "Rc6",
            "Re5",
            "Nc4",
            "Rd5",
            "Ke3",
            "Rh5",
            "Nd6+",
            "Ke7",
            "Ne4",
            "Rxh2",
            "Rxc5",
            "Rxb2",
            "Ra5",
            "h5",
            "Kf4",
            "Rg2",
            "Ra4",
            "h4",
            "Rxb4",
            "Rxa2",
            "Kg4",
            "Rh2",
            "Rb6",
            "Kf7",
            "Ng5+",
            "Kg7",
            "Rb7+",
            "Kf6",
            "Rf7+",
            "Ke5",
            "f4+",
            "Kd5",
            "Rf6",
            "Rg2+",
            "Kxh4",
            "Rh2+",
            "Kg3",
            "Rh6",
            "Nf7",
            "Rh7",
            "Ne5",
            "g5",
            "Ng4",
            "gxf4+",
            "Kxf4",
            "Rh1",
            "Ne3+",
            "Kc5",
            "Rf5+",
            "Kd6",
            "Rd5+",
            "Ke6",
            "Re5+",
            "Kd6",
            "Nf5+",
            "Kc6",
            "Nd4+",
            "Kd6",
            "Re6+",
            "Kd5",
            "Re4",
            "Rh4+",
            "Ke3",
            "Rxe4+",
            "Kd3",
            "Rxd4+",
            "Ke3",
            "Ke5",
            "Kf3",
            "Re4",
            "Kg3",
            "Rf4",
            "Kh3",
            "Kf5",
            "Kg3",
            "Kg5",
            "Kh3",
            "Rg4",
            "Kh2",
            "Kf4",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rg3",
            "Kh1",
            "Kf2",
            "Kh2",
            "Rf3",
            "Kh1",
            "Rh3#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e6f7",
          "positional_uci": "e6f7",
          "neutral_uci": "e6f7",
          "consensus_move": "e6f7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rd1",
              "Rxd1",
              "Qxd1",
              "Qxa2",
              "Qd2",
              "Qe6",
              "Ne3",
              "Ne7",
              "Qd8+",
              "Kf7",
              "Ng5+",
              "Kf6",
              "Nxe6",
              "Kxe6",
              "Qxc7",
              "Kf6",
              "Qd6+",
              "Kf7",
              "Nd5",
              "Nxd5",
              "Qxd5+",
              "Kf6",
              "Qc6+",
              "Kf7",
              "Qxa6",
              "Kg8",
              "Qxb5",
              "Kf7",
              "Qd7+",
              "Kf6",
              "c4",
              "Kg6",
              "c5",
              "Kf6",
              "c6",
              "Kg6",
              "c7",
              "Kf6",
              "c8=Q",
              "Kg6",
              "Qf5+",
              "Kh6",
              "Qce6+",
              "g6",
              "Qf8+",
              "Kh5",
              "Qh3+",
              "Kg5",
              "Qhh6+",
              "Kg4",
              "h3#",
              "e5",
              "e6",
              "e7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rd1",
              "Rxd1",
              "Qxd1",
              "Qxa2",
              "Qd2",
              "h6",
              "Ne3",
              "Qe6",
              "Qd5",
              "Qxd5",
              "Nxd5",
              "Na5",
              "Nxc7",
              "Nc4",
              "b3",
              "Na5",
              "Nd4",
              "Kf7",
              "Nxa6",
              "Kf6",
              "Nc5",
              "Ke5",
              "Ke3",
              "Kd5",
              "Nd3",
              "g5",
              "Nb4+",
              "Kc5",
              "Kd3",
              "Nb7",
              "Nf5",
              "h5",
              "Ng3",
              "h4",
              "Ne4+",
              "Kb6",
              "Nxg5",
              "Nc5+",
              "Kc2",
              "Nd7",
              "Nf3",
              "Nf6",
              "Nxh4",
              "Ng4",
              "h3",
              "Ne3+",
              "Kd3",
              "Nd1",
              "Nf3",
              "Nf2+",
              "Kd4",
              "Nd1",
              "h4",
              "Nf2",
              "h5",
              "Ng4",
              "Ne5",
              "Nh6",
              "g4",
              "Kc7",
              "g5",
              "Nf5+",
              "Kc5",
              "Ng3",
              "h6",
              "Ne4+",
              "Kxb5",
              "Nxg5",
              "Nd5+",
              "Kd6",
              "Nf6",
              "Kxe5",
              "h7",
              "Nf7",
              "Ng4+",
              "Kd6",
              "c4",
              "Kc7",
              "c5",
              "Kb7",
              "b4",
              "Kc7",
              "Ka6",
              "Kb8",
              "b5",
              "Ka8",
              "b6",
              "Kb8",
              "c6",
              "Ka8",
              "b7+",
              "Kb8",
              "Kb6",
              "Nd6",
              "h8=Q+",
              "Ne8",
              "Qxe8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rd1",
              "Re8",
              "Qd3",
              "Ne5",
              "Qd5",
              "Nxf3",
              "Qxf7+",
              "Kxf7",
              "gxf3",
              "Re7",
              "Ne3",
              "g6",
              "Nd5",
              "Rd7",
              "Ne3",
              "Re7",
              "Rd4",
              "c5",
              "Rd6",
              "a5",
              "Rb6",
              "b4",
              "cxb4",
              "axb4",
              "Rc6",
              "Re5",
              "Nc4",
              "Rd5",
              "Ke3",
              "Rh5",
              "Nd6+",
              "Ke7",
              "Ne4",
              "Rxh2",
              "Rxc5",
              "Rxb2",
              "Ra5",
              "h5",
              "Kf4",
              "Rg2",
              "Ra4",
              "h4",
              "Rxb4",
              "Rxa2",
              "Kg4",
              "Rh2",
              "Rb6",
              "Kf7",
              "Ng5+",
              "Kg7",
              "Rb7+",
              "Kf6",
              "Rf7+",
              "Ke5",
              "f4+",
              "Kd5",
              "Rf6",
              "Rg2+",
              "Kxh4",
              "Rh2+",
              "Kg3",
              "Rh6",
              "Nf7",
              "Rh7",
              "Ne5",
              "g5",
              "Ng4",
              "gxf4+",
              "Kxf4",
              "Rh1",
              "Ne3+",
              "Kc5",
              "Rf5+",
              "Kd6",
              "Rd5+",
              "Ke6",
              "Re5+",
              "Kd6",
              "Nf5+",
              "Kc6",
              "Nd4+",
              "Kd6",
              "Re6+",
              "Kd5",
              "Re4",
              "Rh4+",
              "Ke3",
              "Rxe4+",
              "Kd3",
              "Rxd4+",
              "Ke3",
              "Ke5",
              "Kf3",
              "Re4",
              "Kg3",
              "Rf4",
              "Kh3",
              "Kf5",
              "Kg3",
              "Kg5",
              "Kh3",
              "Rg4",
              "Kh2",
              "Kf4",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rg3",
              "Kh1",
              "Kf2",
              "Kh2",
              "Rf3",
              "Kh1",
              "Rh3#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 267,
            "completion_tokens": 396,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 267,
            "completion_tokens": 562,
            "total_tokens": 829,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 266,
            "completion_tokens": 475,
            "total_tokens": 741,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 800,
          "total_completion_tokens": 1433,
          "total_tokens": 2233
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 267,
            "completion_tokens": 396,
            "total_tokens": 663,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 267,
            "completion_tokens": 562,
            "total_tokens": 829,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 37,
            "turn_number": 19,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 266,
            "completion_tokens": 475,
            "total_tokens": 741,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r2k1/2p3pp/p1n1q3/1p6/8/2P2N2/PP2QKPP/R4N2 b - - 1 19"
    },
    {
      "turn": 40,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rd6",
          "aggressive_uci": "d8d6",
          "aggressive_response": "20...Rd6 21. Ng3 Re6 22. Qd3 Rd6 23. Qe4 Re6 24. Qd5 Rd6 25. Qxf7+ Kxf7 26. Ne4 Rd8 27. Rf1 Kg8 28. Nc5 a5 29. Ne6 Rd7 30. Nfd4 Nxd4 31. Rf8# Kf7 32. Nxd4+ Kxf8 33. Nxb5 Rd1+ 34. Kf2 Rd2+ 35. Kf3 Rxb2 36. Nxc7 Rxa2 37. Nb5 a4 38. c4 a3 39. c5 Ra1 40. c6 a2 41. c7 Rc1 42. Nd4 a1=Q 43. Nb3 Qc3+ 44. Kg4 Qxb3 45. c8=Q+ Rxc8 46. h4 Rc4+ 47. Kh5 Qb5# Rg4 49. g3 Qf5# Rg5 51. hxg5 Qh3# Rg4 53. g6 hxg6# Rg5 55. g4 Qxg4# Rg5 57. g3 Qxg3# Rg5 59. g4 Qxg4# Rg5 61. g3 Qxg3# Rg5 63. g4 Qxg4# Rg5 65. g3 Qxg3# Rg5 67. g4 Qxg4# Rg5 69. g3 Qxg3# Rg5 71. g4 Qxg4# Rg5 73. g3 Qxg3# Rg5 75. g4 Qxg4# Rg5 77. g3 Qxg3# Rg5 79. g4 Qxg4# Rg5 81. g3 Qxg3# Rg5 83. g4 Qxg4# Rg5 85. g3 Qxg3# Rg5 87. g4 Qxg4# Rg5 89. g3 Qxg3# Rg5 91. g4 Qxg4# Rg5 93. g3 Qxg3# Rg5 95. g4 Qxg4# Rg5 97. g3 Qxg3# Rg5 99. g4 Qxg4# Rg5 101. g3 Qxg3# Rg5 103. g4 Qxg4# Rg5 105. g3 Qxg3# Rg5 107. g4 Qxg4# Rg5 109. g3 Qxg3# Rg5 111. g",
          "aggressive_tokens": {
            "prompt_tokens": 275,
            "completion_tokens": 640,
            "total_tokens": 915,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf7+",
            "Kxf7",
            "Ne4",
            "Rd8",
            "Rf1",
            "Kg8",
            "Nc5",
            "a5",
            "Ne6",
            "Rd7",
            "Nfd4",
            "Nxd4",
            "Rf8#",
            "Kf7",
            "Nxd4+",
            "Kxf8",
            "Nxb5",
            "Rd1+",
            "Kf2",
            "Rd2+",
            "Kf3",
            "Rxb2",
            "Nxc7",
            "Rxa2",
            "Nb5",
            "a4",
            "c4",
            "a3",
            "c5",
            "Ra1",
            "c6",
            "a2",
            "c7",
            "Rc1",
            "Nd4",
            "a1=Q",
            "Nb3",
            "Qc3+",
            "Kg4",
            "Qxb3",
            "c8=Q+",
            "Rxc8",
            "h4",
            "Rc4+",
            "Kh5",
            "Qb5#",
            "Rg4",
            "g3",
            "Qf5#",
            "Rg5",
            "hxg5",
            "Qh3#",
            "Rg4",
            "g6",
            "hxg6#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5",
            "g4",
            "Qxg4#",
            "Rg5",
            "g3",
            "Qxg3#",
            "Rg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf6",
          "positional_uci": null,
          "positional_response": "O-O 21. Ng5 Qg6 22. Qe6+ Qxe6 23. Nxe6 Rd7 24. Nc5 Rd5 25. Nxa6 Rd7 26. Nc5 Rd5\n27. Ne6 Rd7 28. a4 bxa4 29. Rxa4 Kf7 30. Ng5+ Kg6 31. Ra6 Rd6 32. Ne4 Re6 33. Nc5\nRd6 34. b4 Kf5 35. Ne3+ Kf4 36. Kf2 Rd2+ 37. Ke1 Kxe3 38. Rxc6 Rxg2 39. Re6+ Kf4\n40. Re4+ Kf5 41. Re2 Rg1+ 42. Kd2 Rg6 43. Rf2+ Ke5 44. Kd3 Rd6+ 45. Kc4 c6 46.\nNd3+ Ke4 47. Re2+ Kf3 48. Re7 Rg6 49. Ne5+ Kf4 50. Nxg6+ hxg6 51. Rxg7 Kf5 52.\nRc7 g5 53. Rxc6 g4 54. b5 Kf4 55. b6 Kf3 56. b7 Kg2 57. b8=Q Kh3 58. Qg3# e4\nNf6 Qg6#",
          "positional_tokens": {
            "prompt_tokens": 275,
            "completion_tokens": 332,
            "total_tokens": 607,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qg6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rf8",
          "neutral_uci": "d8f8",
          "neutral_response": "20...Rf8 21. Re1 Nd8 22. Ng5 Qf6 23. Qe3 h6 24. Ne4 Qf7 25. Nfg3 Qxa2 26. Qd2\nQf7 27. Rf1 Qe7 28. Rxf8+ Qxf8 29. Qd5+ Kh8 30. Nf5 c6 31. Qe5 Nf7 32. Qe7 Qxe7\n33. Nxe7 Ne5 34. Nc5 a5 35. Kf2 g5 36. Ke3 Kg7 37. Ke4 Kf6 38. Ng8+ Kg7 39. Kxe5\nKxg8 40. Kd6 Kf7 41. Kxc6 b4 42. cxb4 axb4 43. Kb5 Kf6 44. Kxb4 Kf5 45. Kc4 Kf4\n46. b4 Ke3 47. b5 Kf2 48. b6 Kxg2 49. b7 Kxh2 50. b8=Q+ Kh3 51. Qh8 g4 52. Qxh6+ Kg2\n53. Qd2+ Kh3 54. Ne4 g3 55. Qe3 Kh2 56. Qxg3+ Kh1 57. Nf2#",
          "neutral_tokens": {
            "prompt_tokens": 274,
            "completion_tokens": 322,
            "total_tokens": 596,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re1",
            "Nd8",
            "Ng5",
            "Qf6",
            "Qe3",
            "h6",
            "Ne4",
            "Qf7",
            "Nfg3",
            "Qxa2",
            "Qd2",
            "Qf7",
            "Rf1",
            "Qe7",
            "Rxf8+",
            "Qxf8",
            "Qd5+",
            "Kh8",
            "Nf5",
            "c6",
            "Qe5",
            "Nf7",
            "Qe7",
            "Qxe7",
            "Nxe7",
            "Ne5",
            "Nc5",
            "a5",
            "Kf2",
            "g5",
            "Ke3",
            "Kg7",
            "Ke4",
            "Kf6",
            "Ng8+",
            "Kg7",
            "Kxe5",
            "Kxg8",
            "Kd6",
            "Kf7",
            "Kxc6",
            "b4",
            "cxb4",
            "axb4",
            "Kb5",
            "Kf6",
            "Kxb4",
            "Kf5",
            "Kc4",
            "Kf4",
            "b4",
            "Ke3",
            "b5",
            "Kf2",
            "b6",
            "Kxg2",
            "b7",
            "Kxh2",
            "b8=Q+",
            "Kh3",
            "Qh8",
            "g4",
            "Qxh6+",
            "Kg2",
            "Qd2+",
            "Kh3",
            "Ne4",
            "g3",
            "Qe3",
            "Kh2",
            "Qxg3+",
            "Kh1",
            "Nf2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d8d6",
          "positional_uci": null,
          "neutral_uci": "d8f8",
          "consensus_move": "d8f8",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxf7+",
              "Kxf7",
              "Ne4",
              "Rd8",
              "Rf1",
              "Kg8",
              "Nc5",
              "a5",
              "Ne6",
              "Rd7",
              "Nfd4",
              "Nxd4",
              "Rf8#",
              "Kf7",
              "Nxd4+",
              "Kxf8",
              "Nxb5",
              "Rd1+",
              "Kf2",
              "Rd2+",
              "Kf3",
              "Rxb2",
              "Nxc7",
              "Rxa2",
              "Nb5",
              "a4",
              "c4",
              "a3",
              "c5",
              "Ra1",
              "c6",
              "a2",
              "c7",
              "Rc1",
              "Nd4",
              "a1=Q",
              "Nb3",
              "Qc3+",
              "Kg4",
              "Qxb3",
              "c8=Q+",
              "Rxc8",
              "h4",
              "Rc4+",
              "Kh5",
              "Qb5#",
              "Rg4",
              "g3",
              "Qf5#",
              "Rg5",
              "hxg5",
              "Qh3#",
              "Rg4",
              "g6",
              "hxg6#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5",
              "g4",
              "Qxg4#",
              "Rg5",
              "g3",
              "Qxg3#",
              "Rg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qg6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re1",
              "Nd8",
              "Ng5",
              "Qf6",
              "Qe3",
              "h6",
              "Ne4",
              "Qf7",
              "Nfg3",
              "Qxa2",
              "Qd2",
              "Qf7",
              "Rf1",
              "Qe7",
              "Rxf8+",
              "Qxf8",
              "Qd5+",
              "Kh8",
              "Nf5",
              "c6",
              "Qe5",
              "Nf7",
              "Qe7",
              "Qxe7",
              "Nxe7",
              "Ne5",
              "Nc5",
              "a5",
              "Kf2",
              "g5",
              "Ke3",
              "Kg7",
              "Ke4",
              "Kf6",
              "Ng8+",
              "Kg7",
              "Kxe5",
              "Kxg8",
              "Kd6",
              "Kf7",
              "Kxc6",
              "b4",
              "cxb4",
              "axb4",
              "Kb5",
              "Kf6",
              "Kxb4",
              "Kf5",
              "Kc4",
              "Kf4",
              "b4",
              "Ke3",
              "b5",
              "Kf2",
              "b6",
              "Kxg2",
              "b7",
              "Kxh2",
              "b8=Q+",
              "Kh3",
              "Qh8",
              "g4",
              "Qxh6+",
              "Kg2",
              "Qd2+",
              "Kh3",
              "Ne4",
              "g3",
              "Qe3",
              "Kh2",
              "Qxg3+",
              "Kh1",
              "Nf2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 275,
            "completion_tokens": 640,
            "total_tokens": 915,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 275,
            "completion_tokens": 332,
            "total_tokens": 607,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 274,
            "completion_tokens": 322,
            "total_tokens": 596,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 824,
          "total_completion_tokens": 1294,
          "total_tokens": 2118
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 275,
            "completion_tokens": 640,
            "total_tokens": 915,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 275,
            "completion_tokens": 332,
            "total_tokens": 607,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 39,
            "turn_number": 20,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 274,
            "completion_tokens": 322,
            "total_tokens": 596,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3r2k1/2p2qpp/p1n5/1p6/8/2P2N2/PP2Q1PP/R4NK1 b - - 3 20"
    },
    {
      "turn": 42,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qg6",
          "aggressive_uci": "f7g6",
          "aggressive_response": "21... Qg6 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4 27. b3 Nb6 28. Nc5 a5 29. Ng3 g6 30. Nge4 Kg7 31. Ng5 Re2 32. Nge6+ Kh6 33. Rd3 g5 34. Rh3+ Kg6 35. Nf8+ Kg7 36. Nce6+ Kf7 37. Rxh7+ Ke8 38. Nxc7+ Kxf8 39. Kxe2 Kg8 40. Rh5 Kf7 41. Rxg5 Kf6 42. Rxb5 Nd7 43. Rxa5 Ke7 44. Nd5+ Kd6 45. c4 Nc5 46. Rxc5 Kxc5 47. h4 Kd6 48. h5 Ke6 49. h6 Kf7 50. g4 Kg6 51. g5 Kh7 52. c5 Kg6 53. c6 Kh7 54. c7 Kg6 55. c8=Q Kh7 56. Qf5+ Kg8 57. Ne7+ Kh8 58. Qf8+ Kh7 59. Qg7# Qg6 60. Qxg6+ Kh8 61. Qg7#",
          "aggressive_tokens": {
            "prompt_tokens": 284,
            "completion_tokens": 333,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxg6+",
            "Kh8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qf5",
          "positional_uci": "f7f5",
          "positional_response": "21... Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 h6 25. Ne3 Re7 26. Nd4 Rxe3 27. Nxc6 Re2 28. Rb1 Kf7 29. Nb4 a5 30. Nd5 c6 31. Nf4 Rd2 32. Kf1 g5 33. Ne2 c5 34. Ke1 Rd6 35. Rd1 Re6 36. Rd5 Rc6 37. Ng3 Ke6 38. Rd8 Ke5 39. Ke2 b4 40. c4 a4 41. Rd5+ Ke6 42. Ne4 b3 43. a3 Rc8 44. Nxc5+ Kf6 45. Kd3 Re8 46. Ne4+ Kg6 47. c5 Rf8 48. c6 Rf1 49. c7 Rd1+ 50. Nd2 Rc1 51. Nc4 Rd1+ 52. Ke4 Re1+ 53. Kd4 Rd1+ 54. Kc5 Rxd5+ 55. Kxd5 Kh5 56. c8=Q Kh4 57. Qh3#",
          "positional_tokens": {
            "prompt_tokens": 284,
            "completion_tokens": 289,
            "total_tokens": 573,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe6+",
            "Qxe6",
            "Nxe6",
            "Rf7",
            "Rd1",
            "h6",
            "Ne3",
            "Re7",
            "Nd4",
            "Rxe3",
            "Nxc6",
            "Re2",
            "Rb1",
            "Kf7",
            "Nb4",
            "a5",
            "Nd5",
            "c6",
            "Nf4",
            "Rd2",
            "Kf1",
            "g5",
            "Ne2",
            "c5",
            "Ke1",
            "Rd6",
            "Rd1",
            "Re6",
            "Rd5",
            "Rc6",
            "Ng3",
            "Ke6",
            "Rd8",
            "Ke5",
            "Ke2",
            "b4",
            "c4",
            "a4",
            "Rd5+",
            "Ke6",
            "Ne4",
            "b3",
            "a3",
            "Rc8",
            "Nxc5+",
            "Kf6",
            "Kd3",
            "Re8",
            "Ne4+",
            "Kg6",
            "c5",
            "Rf8",
            "c6",
            "Rf1",
            "c7",
            "Rd1+",
            "Nd2",
            "Rc1",
            "Nc4",
            "Rd1+",
            "Ke4",
            "Re1+",
            "Kd4",
            "Rd1+",
            "Kc5",
            "Rxd5+",
            "Kxd5",
            "Kh5",
            "c8=Q",
            "Kh4",
            "Qh3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qf5",
          "neutral_uci": "f7f5",
          "neutral_response": "21... Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4 27. b3 Nb6 28. Nc5 a5 29. Ng3 g6 30. Nge4 Kg7 31. Ng5 Re2 32. Nge6+ Kh6 33. Rd3 g5 34. Rh3+ Kg6 35. Nf8+ Kg7 36. Nce6+ Kf7 37. Rxh7+ Ke8 38. Nxc7+ Kxf8 39. Kxe2 1-0\n39... Kg8 40. Re7 Kf8 41. Re5 Nd7 42. Rxg5 b4 43. cxb4 axb4 44. Nd5 Kf7 45. Nxb4 Kf6 46. h4 Ne5 47. Rxe5 Kxe5 48. a4 Kd4 49. a5 Kc5 50. a6 Kb6 51. h5 Ka7 52. h6 Kb6 53. h7 Ka7 54. h8=Q Kb6 55. Qd4+ Kb5 56. a7 Ka5 57. a8=Q+ Kb5 58. Qa6#",
          "neutral_tokens": {
            "prompt_tokens": 283,
            "completion_tokens": 312,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qe6+",
            "Qxe6",
            "Nxe6",
            "Rf7",
            "Rd1",
            "Re7",
            "Nd8",
            "Ne5",
            "Nb7",
            "Nc4",
            "b3",
            "Nb6",
            "Nc5",
            "a5",
            "Ng3",
            "g6",
            "Nge4",
            "Kg7",
            "Ng5",
            "Re2",
            "Nge6+",
            "Kh6",
            "Rd3",
            "g5",
            "Rh3+",
            "Kg6",
            "Nf8+",
            "Kg7",
            "Nce6+",
            "Kf7",
            "Rxh7+",
            "Ke8",
            "Nxc7+",
            "Kxf8",
            "Kxe2",
            "Kg8",
            "Re7",
            "Kf8",
            "Re5",
            "Nd7",
            "Rxg5",
            "b4",
            "cxb4",
            "axb4",
            "Nd5",
            "Kf7",
            "Nxb4",
            "Kf6",
            "h4",
            "Ne5",
            "Rxe5",
            "Kxe5",
            "a4",
            "Kd4",
            "a5",
            "Kc5",
            "a6",
            "Kb6",
            "h5",
            "Ka7",
            "h6",
            "Kb6",
            "h7",
            "Ka7",
            "h8=Q",
            "Kb6",
            "Qd4+",
            "Kb5",
            "a7",
            "Ka5",
            "a8=Q+",
            "Kb5",
            "Qa6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f7g6",
          "positional_uci": "f7f5",
          "neutral_uci": "f7f5",
          "consensus_move": "f7f5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxg6+",
              "Kh8",
              "Qg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qe6+",
              "Qxe6",
              "Nxe6",
              "Rf7",
              "Rd1",
              "h6",
              "Ne3",
              "Re7",
              "Nd4",
              "Rxe3",
              "Nxc6",
              "Re2",
              "Rb1",
              "Kf7",
              "Nb4",
              "a5",
              "Nd5",
              "c6",
              "Nf4",
              "Rd2",
              "Kf1",
              "g5",
              "Ne2",
              "c5",
              "Ke1",
              "Rd6",
              "Rd1",
              "Re6",
              "Rd5",
              "Rc6",
              "Ng3",
              "Ke6",
              "Rd8",
              "Ke5",
              "Ke2",
              "b4",
              "c4",
              "a4",
              "Rd5+",
              "Ke6",
              "Ne4",
              "b3",
              "a3",
              "Rc8",
              "Nxc5+",
              "Kf6",
              "Kd3",
              "Re8",
              "Ne4+",
              "Kg6",
              "c5",
              "Rf8",
              "c6",
              "Rf1",
              "c7",
              "Rd1+",
              "Nd2",
              "Rc1",
              "Nc4",
              "Rd1+",
              "Ke4",
              "Re1+",
              "Kd4",
              "Rd1+",
              "Kc5",
              "Rxd5+",
              "Kxd5",
              "Kh5",
              "c8=Q",
              "Kh4",
              "Qh3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qe6+",
              "Qxe6",
              "Nxe6",
              "Rf7",
              "Rd1",
              "Re7",
              "Nd8",
              "Ne5",
              "Nb7",
              "Nc4",
              "b3",
              "Nb6",
              "Nc5",
              "a5",
              "Ng3",
              "g6",
              "Nge4",
              "Kg7",
              "Ng5",
              "Re2",
              "Nge6+",
              "Kh6",
              "Rd3",
              "g5",
              "Rh3+",
              "Kg6",
              "Nf8+",
              "Kg7",
              "Nce6+",
              "Kf7",
              "Rxh7+",
              "Ke8",
              "Nxc7+",
              "Kxf8",
              "Kxe2",
              "Kg8",
              "Re7",
              "Kf8",
              "Re5",
              "Nd7",
              "Rxg5",
              "b4",
              "cxb4",
              "axb4",
              "Nd5",
              "Kf7",
              "Nxb4",
              "Kf6",
              "h4",
              "Ne5",
              "Rxe5",
              "Kxe5",
              "a4",
              "Kd4",
              "a5",
              "Kc5",
              "a6",
              "Kb6",
              "h5",
              "Ka7",
              "h6",
              "Kb6",
              "h7",
              "Ka7",
              "h8=Q",
              "Kb6",
              "Qd4+",
              "Kb5",
              "a7",
              "Ka5",
              "a8=Q+",
              "Kb5",
              "Qa6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 284,
            "completion_tokens": 333,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 284,
            "completion_tokens": 289,
            "total_tokens": 573,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 283,
            "completion_tokens": 312,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 851,
          "total_completion_tokens": 934,
          "total_tokens": 1785
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 284,
            "completion_tokens": 333,
            "total_tokens": 617,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 284,
            "completion_tokens": 289,
            "total_tokens": 573,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 41,
            "turn_number": 21,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 283,
            "completion_tokens": 312,
            "total_tokens": 595,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5rk1/2p2qpp/p1n5/1p4N1/8/2P5/PP2Q1PP/R4NK1 b - - 5 21"
    },
    {
      "turn": 44,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qxe6",
          "aggressive_uci": "f5e6",
          "aggressive_response": "22... Qxe6 23. Nxe6 Rf7 24. Rd1 h6 25. Ne3 Re7 26. Nd8 Rxe3 27. Nxc6 Re2 28. Rb1 Kf7 29. Nb4 a5 30. Nd5 c6 31. Nf4 Rd2 32. Kf1 g5 33. Ne2 c5 34. Ke1 Rd6 35. Rd1 Re6 36. Rd5 Rc6 37. Ng3 Ke6 38. Rd8 Ke5 39. Ke2 b4 40. c4 a4 41. Rd5+ Kf4 42. Rf5+ Kg4 43. Kf2 Kh4 44. h3 b3 45. a3 Rd6 46. Rd5 Rf6+ 47. Nf5+ Kh5 48. g4+ Kg6 49. Rd6 Rxd6 50. Nxd6 Kf6 51. Ne4+ Ke5 52. Nxc5 Kd4 53. Nxa4 Kxc4 54. Ke3 Kb5 55. Nc3+ Kc4 56. Ke4 Kc5 57. Kd3 Kd6 58. Kc4 Ke5 59. Kxb3 Kf4 60. a4 Kg3 61. a5 Kxh3 62. a6 Kxg4 63. a7 h5 64. a8=Q h4 65. Qg2+ Kh5 66. Ne4 g4 67. Nf6+ Kg5 68. Nxg4 Kf4 69. Kc4 Kg5 70. b4 Kf4 71. b5 Kg5 72. b6 Kf4 73. b7 Kg5 74. b8=Q Kh5 75. Qe5+ Kg6 76. Qf6+ Kh5 77. Qh6#",
          "aggressive_tokens": {
            "prompt_tokens": 294,
            "completion_tokens": 447,
            "total_tokens": 741,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe6",
            "Rf7",
            "Rd1",
            "h6",
            "Ne3",
            "Re7",
            "Nd8",
            "Rxe3",
            "Nxc6",
            "Re2",
            "Rb1",
            "Kf7",
            "Nb4",
            "a5",
            "Nd5",
            "c6",
            "Nf4",
            "Rd2",
            "Kf1",
            "g5",
            "Ne2",
            "c5",
            "Ke1",
            "Rd6",
            "Rd1",
            "Re6",
            "Rd5",
            "Rc6",
            "Ng3",
            "Ke6",
            "Rd8",
            "Ke5",
            "Ke2",
            "b4",
            "c4",
            "a4",
            "Rd5+",
            "Kf4",
            "Rf5+",
            "Kg4",
            "Kf2",
            "Kh4",
            "h3",
            "b3",
            "a3",
            "Rd6",
            "Rd5",
            "Rf6+",
            "Nf5+",
            "Kh5",
            "g4+",
            "Kg6",
            "Rd6",
            "Rxd6",
            "Nxd6",
            "Kf6",
            "Ne4+",
            "Ke5",
            "Nxc5",
            "Kd4",
            "Nxa4",
            "Kxc4",
            "Ke3",
            "Kb5",
            "Nc3+",
            "Kc4",
            "Ke4",
            "Kc5",
            "Kd3",
            "Kd6",
            "Kc4",
            "Ke5",
            "Kxb3",
            "Kf4",
            "a4",
            "Kg3",
            "a5",
            "Kxh3",
            "a6",
            "Kxg4",
            "a7",
            "h5",
            "a8=Q",
            "h4",
            "Qg2+",
            "Kh5",
            "Ne4",
            "g4",
            "Nf6+",
            "Kg5",
            "Nxg4",
            "Kf4",
            "Kc4",
            "Kg5",
            "b4",
            "Kf4",
            "b5",
            "Kg5",
            "b6",
            "Kf4",
            "b7",
            "Kg5",
            "b8=Q",
            "Kh5",
            "Qe5+",
            "Kg6",
            "Qf6+",
            "Kh5",
            "Qh6#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qxe6",
          "positional_uci": "f5e6",
          "positional_response": "22... Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4 27. b3 Nb6 28. Nc5\na5 29. Ng3 g6 30. Nge4 Kg7 31. Ng5 Re5 32. Nce6+ Kf6 33. Rf1+ Ke7 34. Rf7+ Kd6\n35. Rxc7 h6 36. Nf7+ Kxe6 37. Nxe5 Kxe5 38. Rc5+ Kd6 39. Rxb5 Kc6 40. Rxa5\nNd5 41. Ra6+ Kc5 42. Ra5+ Kc6 43. Rxd5 Kxd5 44. Kf2 Ke4 45. Ke2 g5 46. a4 h5\n47. a5 Kd5 48. b4 Kc6 49. c4 g4 50. b5+ Kb7 51. c5 h4 52. c6+ Kc7 53. a6 Kb6\n54. Ke3 g3 55. hxg3 hxg3 56. Kf3 Kxb5 57. c7 Kxa6 58. c8=Q+ Kb6 59. Kxg3 Kb5\n60. Kf4 Kb4 61. Ke4 Kb3 62. Kd3 Kb4 63. Qc4+ Ka5 64. Qb3 Ka6 65. Kc4 Ka7 66. Kc5\nKa8 67. Kc6 Ka7 68. Qb7# Bb3 cxb3 69. axb3 Ka8 70. Kc7 Ka7 71. b4 Ka6 72. Kc6\nKa7 73. b5 Kb8 74. Kb6 Ka8 75. Kc7 Ka7 76. b6+ Ka6 77. b7 Kb5 78. b8=Q+ Kc4\n79. Qb6 Kd3 80. Qxb3+ Ke4 81. Qc3 Kf5 82. Qd4 Ke6 83. Qc5 Kf6 84. Qd5 Kg6 85.\nQe5 Kf7 86. Qd6 Kg7 87. Qe6 Kh7 88. Qf6 Kg8 89. Qe7 Kh8 90. Kd6 Kg8 91. Ke6\nKh8 92. Kf6 Kg8 93. Qg7#",
          "positional_tokens": {
            "prompt_tokens": 294,
            "completion_tokens": 595,
            "total_tokens": 889,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe6",
            "Rf7",
            "Rd1",
            "Re7",
            "Nd8",
            "Ne5",
            "Nb7",
            "Nc4",
            "b3",
            "Nb6",
            "Nc5",
            "a5",
            "Ng3",
            "g6",
            "Nge4",
            "Kg7",
            "Ng5",
            "Re5",
            "Nce6+",
            "Kf6",
            "Rf1+",
            "Ke7",
            "Rf7+",
            "Kd6",
            "Rxc7",
            "h6",
            "Nf7+",
            "Kxe6",
            "Nxe5",
            "Kxe5",
            "Rc5+",
            "Kd6",
            "Rxb5",
            "Kc6",
            "Rxa5",
            "Nd5",
            "Ra6+",
            "Kc5",
            "Ra5+",
            "Kc6",
            "Rxd5",
            "Kxd5",
            "Kf2",
            "Ke4",
            "Ke2",
            "g5",
            "a4",
            "h5",
            "a5",
            "Kd5",
            "b4",
            "Kc6",
            "c4",
            "g4",
            "b5+",
            "Kb7",
            "c5",
            "h4",
            "c6+",
            "Kc7",
            "a6",
            "Kb6",
            "Ke3",
            "g3",
            "hxg3",
            "hxg3",
            "Kf3",
            "Kxb5",
            "c7",
            "Kxa6",
            "c8=Q+",
            "Kb6",
            "Kxg3",
            "Kb5",
            "Kf4",
            "Kb4",
            "Ke4",
            "Kb3",
            "Kd3",
            "Kb4",
            "Qc4+",
            "Ka5",
            "Qb3",
            "Ka6",
            "Kc4",
            "Ka7",
            "Kc5",
            "Ka8",
            "Kc6",
            "Ka7",
            "Qb7#",
            "Bb3",
            "cxb3",
            "axb3",
            "Ka8",
            "Kc7",
            "Ka7",
            "b4",
            "Ka6",
            "Kc6",
            "Ka7",
            "b5",
            "Kb8",
            "Kb6",
            "Ka8",
            "Kc7",
            "Ka7",
            "b6+",
            "Ka6",
            "b7",
            "Kb5",
            "b8=Q+",
            "Kc4",
            "Qb6",
            "Kd3",
            "Qxb3+",
            "Ke4",
            "Qc3",
            "Kf5",
            "Qd4",
            "Ke6",
            "Qc5",
            "Kf6",
            "Qd5",
            "Kg6",
            "Qe5",
            "Kf7",
            "Qd6",
            "Kg7",
            "Qe6",
            "Kh7",
            "Qf6",
            "Kg8",
            "Qe7",
            "Kh8",
            "Kd6",
            "Kg8",
            "Ke6",
            "Kh8",
            "Kf6",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qxe6",
          "neutral_uci": "f5e6",
          "neutral_response": "22... Qxe6 23. Nxe6 Rf7 24. Rd1 h6 25. Ne3 Re7 26. Nd8 Rxe3 27. Nxc6 Re2 28. Rb1 Kf7 29. Nb4 a5 30. Nd5 c6 31. Nf4 Rd2 32. Kf1 g5 33. Ne2 c5 34. Ke1 Rd5 35. Rd1 Re5 36. Rd6 h5 37. Ra6 a4 38. Rb6 c4 39. Kf2 Rf5+ 40. Ke3 Re5+ 41. Kf3 Rf5+ 42. Ke4 Rf2 43. Nd4 Rxb2 44. Rxb5 Rxa2 45. Rxg5 a3 46. Rxh5 Rxg2 47. Ra5 a2 48. Kd5 Rxh2 49. Kxc4 Ke7 50. Kb3 Kd6 51. Rxa2 Rh3 52. Ra5 Kc7 53. Kb4 Kb6 54. Rg5 Rh4 55. Rg6+ Kc7 56. Kc5 Rh5+ 57. Kc4 Rh4 58. Kd5 Rh5+ 59. Ke6 Rc5 60. Rg3 Kb6 61. Kd6 Rc4 62. Kd5 Rc5+ 63. Ke4 Rc4 64. Kd3 Rc5 65. Rg6+ Kc7 66. Ne6+ Kd6 67. Nxc5+ Kxc5 68. Rg5+ Kd6 69. Kd4 Kc6 70. c4 Kd6 71. Rg6+ Kc7 72. Kd5 Kd7 73. Rg7+ Kc8 74. Kd6 Kb8 75. Kc6 Ka8 76. Kb6 Kb8 77. Rg8#",
          "neutral_tokens": {
            "prompt_tokens": 293,
            "completion_tokens": 458,
            "total_tokens": 751,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe6",
            "Rf7",
            "Rd1",
            "h6",
            "Ne3",
            "Re7",
            "Nd8",
            "Rxe3",
            "Nxc6",
            "Re2",
            "Rb1",
            "Kf7",
            "Nb4",
            "a5",
            "Nd5",
            "c6",
            "Nf4",
            "Rd2",
            "Kf1",
            "g5",
            "Ne2",
            "c5",
            "Ke1",
            "Rd5",
            "Rd1",
            "Re5",
            "Rd6",
            "h5",
            "Ra6",
            "a4",
            "Rb6",
            "c4",
            "Kf2",
            "Rf5+",
            "Ke3",
            "Re5+",
            "Kf3",
            "Rf5+",
            "Ke4",
            "Rf2",
            "Nd4",
            "Rxb2",
            "Rxb5",
            "Rxa2",
            "Rxg5",
            "a3",
            "Rxh5",
            "Rxg2",
            "Ra5",
            "a2",
            "Kd5",
            "Rxh2",
            "Kxc4",
            "Ke7",
            "Kb3",
            "Kd6",
            "Rxa2",
            "Rh3",
            "Ra5",
            "Kc7",
            "Kb4",
            "Kb6",
            "Rg5",
            "Rh4",
            "Rg6+",
            "Kc7",
            "Kc5",
            "Rh5+",
            "Kc4",
            "Rh4",
            "Kd5",
            "Rh5+",
            "Ke6",
            "Rc5",
            "Rg3",
            "Kb6",
            "Kd6",
            "Rc4",
            "Kd5",
            "Rc5+",
            "Ke4",
            "Rc4",
            "Kd3",
            "Rc5",
            "Rg6+",
            "Kc7",
            "Ne6+",
            "Kd6",
            "Nxc5+",
            "Kxc5",
            "Rg5+",
            "Kd6",
            "Kd4",
            "Kc6",
            "c4",
            "Kd6",
            "Rg6+",
            "Kc7",
            "Kd5",
            "Kd7",
            "Rg7+",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Kb6",
            "Kb8",
            "Rg8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f5e6",
          "positional_uci": "f5e6",
          "neutral_uci": "f5e6",
          "consensus_move": "f5e6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxe6",
              "Rf7",
              "Rd1",
              "h6",
              "Ne3",
              "Re7",
              "Nd8",
              "Rxe3",
              "Nxc6",
              "Re2",
              "Rb1",
              "Kf7",
              "Nb4",
              "a5",
              "Nd5",
              "c6",
              "Nf4",
              "Rd2",
              "Kf1",
              "g5",
              "Ne2",
              "c5",
              "Ke1",
              "Rd6",
              "Rd1",
              "Re6",
              "Rd5",
              "Rc6",
              "Ng3",
              "Ke6",
              "Rd8",
              "Ke5",
              "Ke2",
              "b4",
              "c4",
              "a4",
              "Rd5+",
              "Kf4",
              "Rf5+",
              "Kg4",
              "Kf2",
              "Kh4",
              "h3",
              "b3",
              "a3",
              "Rd6",
              "Rd5",
              "Rf6+",
              "Nf5+",
              "Kh5",
              "g4+",
              "Kg6",
              "Rd6",
              "Rxd6",
              "Nxd6",
              "Kf6",
              "Ne4+",
              "Ke5",
              "Nxc5",
              "Kd4",
              "Nxa4",
              "Kxc4",
              "Ke3",
              "Kb5",
              "Nc3+",
              "Kc4",
              "Ke4",
              "Kc5",
              "Kd3",
              "Kd6",
              "Kc4",
              "Ke5",
              "Kxb3",
              "Kf4",
              "a4",
              "Kg3",
              "a5",
              "Kxh3",
              "a6",
              "Kxg4",
              "a7",
              "h5",
              "a8=Q",
              "h4",
              "Qg2+",
              "Kh5",
              "Ne4",
              "g4",
              "Nf6+",
              "Kg5",
              "Nxg4",
              "Kf4",
              "Kc4",
              "Kg5",
              "b4",
              "Kf4",
              "b5",
              "Kg5",
              "b6",
              "Kf4",
              "b7",
              "Kg5",
              "b8=Q",
              "Kh5",
              "Qe5+",
              "Kg6",
              "Qf6+",
              "Kh5",
              "Qh6#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxe6",
              "Rf7",
              "Rd1",
              "Re7",
              "Nd8",
              "Ne5",
              "Nb7",
              "Nc4",
              "b3",
              "Nb6",
              "Nc5",
              "a5",
              "Ng3",
              "g6",
              "Nge4",
              "Kg7",
              "Ng5",
              "Re5",
              "Nce6+",
              "Kf6",
              "Rf1+",
              "Ke7",
              "Rf7+",
              "Kd6",
              "Rxc7",
              "h6",
              "Nf7+",
              "Kxe6",
              "Nxe5",
              "Kxe5",
              "Rc5+",
              "Kd6",
              "Rxb5",
              "Kc6",
              "Rxa5",
              "Nd5",
              "Ra6+",
              "Kc5",
              "Ra5+",
              "Kc6",
              "Rxd5",
              "Kxd5",
              "Kf2",
              "Ke4",
              "Ke2",
              "g5",
              "a4",
              "h5",
              "a5",
              "Kd5",
              "b4",
              "Kc6",
              "c4",
              "g4",
              "b5+",
              "Kb7",
              "c5",
              "h4",
              "c6+",
              "Kc7",
              "a6",
              "Kb6",
              "Ke3",
              "g3",
              "hxg3",
              "hxg3",
              "Kf3",
              "Kxb5",
              "c7",
              "Kxa6",
              "c8=Q+",
              "Kb6",
              "Kxg3",
              "Kb5",
              "Kf4",
              "Kb4",
              "Ke4",
              "Kb3",
              "Kd3",
              "Kb4",
              "Qc4+",
              "Ka5",
              "Qb3",
              "Ka6",
              "Kc4",
              "Ka7",
              "Kc5",
              "Ka8",
              "Kc6",
              "Ka7",
              "Qb7#",
              "Bb3",
              "cxb3",
              "axb3",
              "Ka8",
              "Kc7",
              "Ka7",
              "b4",
              "Ka6",
              "Kc6",
              "Ka7",
              "b5",
              "Kb8",
              "Kb6",
              "Ka8",
              "Kc7",
              "Ka7",
              "b6+",
              "Ka6",
              "b7",
              "Kb5",
              "b8=Q+",
              "Kc4",
              "Qb6",
              "Kd3",
              "Qxb3+",
              "Ke4",
              "Qc3",
              "Kf5",
              "Qd4",
              "Ke6",
              "Qc5",
              "Kf6",
              "Qd5",
              "Kg6",
              "Qe5",
              "Kf7",
              "Qd6",
              "Kg7",
              "Qe6",
              "Kh7",
              "Qf6",
              "Kg8",
              "Qe7",
              "Kh8",
              "Kd6",
              "Kg8",
              "Ke6",
              "Kh8",
              "Kf6",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxe6",
              "Rf7",
              "Rd1",
              "h6",
              "Ne3",
              "Re7",
              "Nd8",
              "Rxe3",
              "Nxc6",
              "Re2",
              "Rb1",
              "Kf7",
              "Nb4",
              "a5",
              "Nd5",
              "c6",
              "Nf4",
              "Rd2",
              "Kf1",
              "g5",
              "Ne2",
              "c5",
              "Ke1",
              "Rd5",
              "Rd1",
              "Re5",
              "Rd6",
              "h5",
              "Ra6",
              "a4",
              "Rb6",
              "c4",
              "Kf2",
              "Rf5+",
              "Ke3",
              "Re5+",
              "Kf3",
              "Rf5+",
              "Ke4",
              "Rf2",
              "Nd4",
              "Rxb2",
              "Rxb5",
              "Rxa2",
              "Rxg5",
              "a3",
              "Rxh5",
              "Rxg2",
              "Ra5",
              "a2",
              "Kd5",
              "Rxh2",
              "Kxc4",
              "Ke7",
              "Kb3",
              "Kd6",
              "Rxa2",
              "Rh3",
              "Ra5",
              "Kc7",
              "Kb4",
              "Kb6",
              "Rg5",
              "Rh4",
              "Rg6+",
              "Kc7",
              "Kc5",
              "Rh5+",
              "Kc4",
              "Rh4",
              "Kd5",
              "Rh5+",
              "Ke6",
              "Rc5",
              "Rg3",
              "Kb6",
              "Kd6",
              "Rc4",
              "Kd5",
              "Rc5+",
              "Ke4",
              "Rc4",
              "Kd3",
              "Rc5",
              "Rg6+",
              "Kc7",
              "Ne6+",
              "Kd6",
              "Nxc5+",
              "Kxc5",
              "Rg5+",
              "Kd6",
              "Kd4",
              "Kc6",
              "c4",
              "Kd6",
              "Rg6+",
              "Kc7",
              "Kd5",
              "Kd7",
              "Rg7+",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Kb6",
              "Kb8",
              "Rg8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 294,
            "completion_tokens": 447,
            "total_tokens": 741,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 294,
            "completion_tokens": 595,
            "total_tokens": 889,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 293,
            "completion_tokens": 458,
            "total_tokens": 751,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 881,
          "total_completion_tokens": 1500,
          "total_tokens": 2381
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 294,
            "completion_tokens": 447,
            "total_tokens": 741,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 294,
            "completion_tokens": 595,
            "total_tokens": 889,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 43,
            "turn_number": 22,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 293,
            "completion_tokens": 458,
            "total_tokens": 751,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5rk1/2p3pp/p1n1Q3/1p3qN1/8/2P5/PP4PP/R4NK1 b - - 7 22"
    },
    {
      "turn": 46,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rf7",
          "aggressive_uci": "f8f7",
          "aggressive_response": "23... Rf7 24. Rd1 h6 25. Nd8 Nxd8 26. Rxd8+ Kh7 27. Ra8 Rf6 28. Ra7 c5 29. Rc7\nc4 30. Ne3 Re6 31. Kf2 Rf6+ 32. Ke2 Re6 33. Kd2 Rd6+ 34. Kc2 Re6 35. Nf5 Re2+ 36.\nKd1 Rxg2 37. Rxg7+ Rxg7 38. Nxg7 Kxg7 39. Ke2 Kf6 40. Ke3 Ke5 41. h3 h5 42. h4\nKf5 43. Kf3 Ke5 44. b3 cxb3 45. axb3 a5 46. Ke3 a4 47. bxa4 bxa4 48. Kd3 Kd5 49.\nc4+ Kc5 50. Kc3 a3 51. Kb3 a2 52. Kxa2 Kxc4 53. Kb2 Kd4 54. Kc2 Ke4 55. Kd2 Kf4\n56. Ke2 Kg4 57. Kf2 Kxh4 58. Kg2 Kg4 59. Kh2 h4 60. Kg2 h3+ 61. Kh2 Kh4 62. Kh1\nKg3 63. Kg1 h2+ 64. Kh1 Kh3 65. 1/2-1/2",
          "aggressive_tokens": {
            "prompt_tokens": 303,
            "completion_tokens": 351,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd1",
            "h6",
            "Nd8",
            "Nxd8",
            "Rxd8+",
            "Kh7",
            "Ra8",
            "Rf6",
            "Ra7",
            "c5",
            "Rc7",
            "c4",
            "Ne3",
            "Re6",
            "Kf2",
            "Rf6+",
            "Ke2",
            "Re6",
            "Kd2",
            "Rd6+",
            "Kc2",
            "Re6",
            "Nf5",
            "Re2+",
            "Kd1",
            "Rxg2",
            "Rxg7+",
            "Rxg7",
            "Nxg7",
            "Kxg7",
            "Ke2",
            "Kf6",
            "Ke3",
            "Ke5",
            "h3",
            "h5",
            "h4",
            "Kf5",
            "Kf3",
            "Ke5",
            "b3",
            "cxb3",
            "axb3",
            "a5",
            "Ke3",
            "a4",
            "bxa4",
            "bxa4",
            "Kd3",
            "Kd5",
            "c4+",
            "Kc5",
            "Kc3",
            "a3",
            "Kb3",
            "a2",
            "Kxa2",
            "Kxc4",
            "Kb2",
            "Kd4",
            "Kc2",
            "Ke4",
            "Kd2",
            "Kf4",
            "Ke2",
            "Kg4",
            "Kf2",
            "Kxh4",
            "Kg2",
            "Kg4",
            "Kh2",
            "h4",
            "Kg2",
            "h3+",
            "Kh2",
            "Kh4",
            "Kh1",
            "Kg3",
            "Kg1",
            "h2+",
            "Kh1",
            "Kh3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rf7",
          "positional_uci": "f8f7",
          "positional_response": "23... Rf7 24. Rd1 h6 25. Nd8 Nxd8 26. Rxd8+ Kh7 27. Ra8 Rf6 28. Ra7 c5 29. Rc7\nc4 30. b3 cxb3 31. axb3 a5 32. Rc5 Rb6 33. Ne3 a4 34. bxa4 bxa4 35. Ra5 Rb3\n36. Nd5 a3 37. c4 Rb1+ 38. Kf2 Rb2+ 39. Kf3 a2 40. c5 Rc2 41. Nb4 Rxc5 42. Rxa2\nRc3+ 43. Ke4 Rc4+ 44. Kd5 Rxb4 45. Rf2 Rb5+ 46. Ke4 Rb4+ 47. Kd5 Rb5+ 48. Ke4\nRb4+ 49. Kd5 Rb5+ 50. Ke4 Rb4+ 51. Kd5 Rb5+ 52. Ke4 Rb4+ 53. Kd5 Rb5+ 54. Ke4\nRb4+ 55. Kd5 Rb5+ 56. Ke4 Rb4+ 57. Kd5 Rb5+ 58. Ke4 Rb4+ 59. Kd5 Rb5+ 60. Ke4\nRb4+ 61. Kd5 Rb5+ 62. Ke4 Rb4+ 63. Kd5 Rb5+ 64. Ke4 Rb4+ 65. Kd5 Rb5+ 66. Ke4\nRb4+ 67. Kd5 Rb5+ 68. Ke4 Rb4+ 69. Kd5 Rb5+ 70. Ke4 Rb4+ 71. Kd5 Rb5+ 72. Ke4\nRb4+ 73. Kd5 Rb5+ 74. Ke4 Rb4+ 75. Kd5 Rb5+ 76. Ke4 Rb4+ 77. Kd5 Rb5+ 78. Ke4\nRb4+ 79. Kd5 Rb5+ 80. Ke4 Rb4+ 81. Kd5 Rb5+ 82. Ke4 Rb4+ 83. Kd5 Rb5+ 84. Ke4\nRb4+ 85. Kd5 Rb5+ 86. Ke4 Rb4+ 87. Kd5 Rb5+ 88. Ke4 Rb4+ 89. Kd5 Rb5+ 90. Ke4\nRb4+ 91. Kd5 Rb5+ 92. Ke4 Rb",
          "positional_tokens": {
            "prompt_tokens": 303,
            "completion_tokens": 640,
            "total_tokens": 943,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rd1",
            "h6",
            "Nd8",
            "Nxd8",
            "Rxd8+",
            "Kh7",
            "Ra8",
            "Rf6",
            "Ra7",
            "c5",
            "Rc7",
            "c4",
            "b3",
            "cxb3",
            "axb3",
            "a5",
            "Rc5",
            "Rb6",
            "Ne3",
            "a4",
            "bxa4",
            "bxa4",
            "Ra5",
            "Rb3",
            "Nd5",
            "a3",
            "c4",
            "Rb1+",
            "Kf2",
            "Rb2+",
            "Kf3",
            "a2",
            "c5",
            "Rc2",
            "Nb4",
            "Rxc5",
            "Rxa2",
            "Rc3+",
            "Ke4",
            "Rc4+",
            "Kd5",
            "Rxb4",
            "Rf2",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4",
            "Rb4+",
            "Kd5",
            "Rb5+",
            "Ke4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": "f8e8",
          "neutral_response": "Re8 24. Nxc7 Re2 25. Rb1 Ne5 26. Nxa6\nNd3 27. Nc7 Nxb2 28. Nxb5 Nd3 29. a4 Nf4 30. g3 Nh3+ 31. Kh1 Nf2+ 32. Kg2 Nd3+\n33. Kf3 Ra2 34. Ke3 Nc5 35. Nd2 Rxa4 36. Nd6 h6 37. Rb8+ Kh7 38. N2e4 Ne6 39.\nRb7 Ra3 40. Re7 Nf8 41. Nf5 Kg6 42. g4 h5 43. Rxg7# Nf6+ Nxf6 45. Rg6+ Kf7 46.\nRxf6+ Kg8 47. gxh5 Rxc3+ 48. Nxc3 *\n1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 * Re8 24. Nxc7 Re2 25. Rb1 Ne5 26. Nxa6\nNd3 27. Nc7 Nxb2 28. Nxb5 Nd3 29. a4 Nf4 30. g3 Nh3+ 31. Kh1 Nf2+ 32. Kg2 Nd3+\n33. Kf3 Ra2 34. Ke3 Nc5 35. Nd2 Rxa4 36. Nd6 h6 37. Rb8+ Kh7 38. N2e4 Ne6 39.\nRb7 Ra3 40. Re7 Nf8 41. Nf5 Kg6 42. g4 h5 43. Rxg7# Nf6+ Nxf6 45. Rg6+ Kf7 46.\nRxf6+ Kg8 47. gxh5 Rxc3+ 48. Nxc3 * Nf6+ Nxf6 50. Rg6+ Kf7 51. Rxf6+ Kg8 52.\nh6 Kh7",
          "neutral_tokens": {
            "prompt_tokens": 302,
            "completion_tokens": 640,
            "total_tokens": 942,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxc7",
            "Re2",
            "Rb1",
            "Ne5",
            "Nxa6",
            "Nd3",
            "Nc7",
            "Nxb2",
            "Nxb5",
            "Nd3",
            "a4",
            "Nf4",
            "g3",
            "Nh3+",
            "Kh1",
            "Nf2+",
            "Kg2",
            "Nd3+",
            "Kf3",
            "Ra2",
            "Ke3",
            "Nc5",
            "Nd2",
            "Rxa4",
            "Nd6",
            "h6",
            "Rb8+",
            "Kh7",
            "N2e4",
            "Ne6",
            "Rb7",
            "Ra3",
            "Re7",
            "Nf8",
            "Nf5",
            "Kg6",
            "g4",
            "h5",
            "Rxg7#",
            "Nf6+",
            "Nxf6",
            "Rg6+",
            "Kf7",
            "Rxf6+",
            "Kg8",
            "gxh5",
            "Rxc3+",
            "Nxc3",
            "Nf6+",
            "Nxf6",
            "Rg6+",
            "Kf7",
            "Rxf6+",
            "Kg8",
            "h6",
            "Kh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8f7",
          "positional_uci": "f8f7",
          "neutral_uci": "f8e8",
          "consensus_move": "f8f7",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rd1",
              "h6",
              "Nd8",
              "Nxd8",
              "Rxd8+",
              "Kh7",
              "Ra8",
              "Rf6",
              "Ra7",
              "c5",
              "Rc7",
              "c4",
              "Ne3",
              "Re6",
              "Kf2",
              "Rf6+",
              "Ke2",
              "Re6",
              "Kd2",
              "Rd6+",
              "Kc2",
              "Re6",
              "Nf5",
              "Re2+",
              "Kd1",
              "Rxg2",
              "Rxg7+",
              "Rxg7",
              "Nxg7",
              "Kxg7",
              "Ke2",
              "Kf6",
              "Ke3",
              "Ke5",
              "h3",
              "h5",
              "h4",
              "Kf5",
              "Kf3",
              "Ke5",
              "b3",
              "cxb3",
              "axb3",
              "a5",
              "Ke3",
              "a4",
              "bxa4",
              "bxa4",
              "Kd3",
              "Kd5",
              "c4+",
              "Kc5",
              "Kc3",
              "a3",
              "Kb3",
              "a2",
              "Kxa2",
              "Kxc4",
              "Kb2",
              "Kd4",
              "Kc2",
              "Ke4",
              "Kd2",
              "Kf4",
              "Ke2",
              "Kg4",
              "Kf2",
              "Kxh4",
              "Kg2",
              "Kg4",
              "Kh2",
              "h4",
              "Kg2",
              "h3+",
              "Kh2",
              "Kh4",
              "Kh1",
              "Kg3",
              "Kg1",
              "h2+",
              "Kh1",
              "Kh3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rd1",
              "h6",
              "Nd8",
              "Nxd8",
              "Rxd8+",
              "Kh7",
              "Ra8",
              "Rf6",
              "Ra7",
              "c5",
              "Rc7",
              "c4",
              "b3",
              "cxb3",
              "axb3",
              "a5",
              "Rc5",
              "Rb6",
              "Ne3",
              "a4",
              "bxa4",
              "bxa4",
              "Ra5",
              "Rb3",
              "Nd5",
              "a3",
              "c4",
              "Rb1+",
              "Kf2",
              "Rb2+",
              "Kf3",
              "a2",
              "c5",
              "Rc2",
              "Nb4",
              "Rxc5",
              "Rxa2",
              "Rc3+",
              "Ke4",
              "Rc4+",
              "Kd5",
              "Rxb4",
              "Rf2",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4",
              "Rb4+",
              "Kd5",
              "Rb5+",
              "Ke4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxc7",
              "Re2",
              "Rb1",
              "Ne5",
              "Nxa6",
              "Nd3",
              "Nc7",
              "Nxb2",
              "Nxb5",
              "Nd3",
              "a4",
              "Nf4",
              "g3",
              "Nh3+",
              "Kh1",
              "Nf2+",
              "Kg2",
              "Nd3+",
              "Kf3",
              "Ra2",
              "Ke3",
              "Nc5",
              "Nd2",
              "Rxa4",
              "Nd6",
              "h6",
              "Rb8+",
              "Kh7",
              "N2e4",
              "Ne6",
              "Rb7",
              "Ra3",
              "Re7",
              "Nf8",
              "Nf5",
              "Kg6",
              "g4",
              "h5",
              "Rxg7#",
              "Nf6+",
              "Nxf6",
              "Rg6+",
              "Kf7",
              "Rxf6+",
              "Kg8",
              "gxh5",
              "Rxc3+",
              "Nxc3",
              "Nf6+",
              "Nxf6",
              "Rg6+",
              "Kf7",
              "Rxf6+",
              "Kg8",
              "h6",
              "Kh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 303,
            "completion_tokens": 351,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 303,
            "completion_tokens": 640,
            "total_tokens": 943,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 302,
            "completion_tokens": 640,
            "total_tokens": 942,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 908,
          "total_completion_tokens": 1631,
          "total_tokens": 2539
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 303,
            "completion_tokens": 351,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 303,
            "completion_tokens": 640,
            "total_tokens": 943,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 45,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 302,
            "completion_tokens": 640,
            "total_tokens": 942,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "5rk1/2p3pp/p1n1N3/1p6/8/2P5/PP4PP/R4NK1 b - - 0 23"
    },
    {
      "turn": 48,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re7",
          "aggressive_uci": "f7e7",
          "aggressive_response": "24... Re7 25. Nd4 Ne5 26. Re1 Kf7 27. Ng3 c5 28. Ndf5 Re6 29. Ne4 Nd3 30. Ng5+ Kf6 31. Rxe6+ Kxf5 32. Rxa6 Kxg5 33. b3 Kf5 34. Ra5 b4 35. cxb4 Nxb4 36. Rxc5+ Ke4 37. Rc4+ Kd3 38. Rxb4 Kc3 39. Rb7 Kb2 40. a4 Ka3 41. a5 Kb2 42. a6 Kc3 43. a7 Kd4 44. a8=Q Ke5 45. Qe8+ Kf6 46. Rf7+ Kg6 47. Qe6+ Kg5 48. Rf5+ Kg4 49. Qe4# e4 Nc6 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 311,
            "completion_tokens": 221,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd4",
            "Ne5",
            "Re1",
            "Kf7",
            "Ng3",
            "c5",
            "Ndf5",
            "Re6",
            "Ne4",
            "Nd3",
            "Ng5+",
            "Kf6",
            "Rxe6+",
            "Kxf5",
            "Rxa6",
            "Kxg5",
            "b3",
            "Kf5",
            "Ra5",
            "b4",
            "cxb4",
            "Nxb4",
            "Rxc5+",
            "Ke4",
            "Rc4+",
            "Kd3",
            "Rxb4",
            "Kc3",
            "Rb7",
            "Kb2",
            "a4",
            "Ka3",
            "a5",
            "Kb2",
            "a6",
            "Kc3",
            "a7",
            "Kd4",
            "a8=Q",
            "Ke5",
            "Qe8+",
            "Kf6",
            "Rf7+",
            "Kg6",
            "Qe6+",
            "Kg5",
            "Rf5+",
            "Kg4",
            "Qe4#",
            "e4",
            "Nc6",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re7",
          "positional_uci": "f7e7",
          "positional_response": "24... Re7 25. Nd4 Ne5 26. Re1 Kf7 27. Nd2 c5 28. N4f3 Nxf3+ 29. Nxf3 Rd7 30. Ne5+ Ke6 31. Nxd7+ Kxd7 32. Kf2 Kd6 33. Kf3 Kd5 34. Kf4 Kc4 35. Re3 b4 36. b3+ Kb5 37. c4+ Ka5 38. Re5 Kb6 39. Ke4 a5 40. Kd5 a4 41. Re6+ Ka5 42. Kxc5 axb3 43. axb3 g5 44. Re7 Ka6 45. Rxh7 g4 46. Rg7 g3 47. Rxg3 Ka5 48. Rg8 Ka6 49. Rg7 Ka5 50. Ra7#",
          "positional_tokens": {
            "prompt_tokens": 311,
            "completion_tokens": 214,
            "total_tokens": 525,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ka6",
            "Rxh7",
            "g4",
            "Rg7",
            "g3",
            "Rxg3",
            "Ka5",
            "Rg8",
            "Ka6",
            "Rg7",
            "Ka5",
            "Ra7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re7",
          "neutral_uci": "f7e7",
          "neutral_response": "24... Re7 25. Nd4 Ne5 26. Re1 Kf7 27. Nd2 c5 28. N4f3 Nxf3+ 29. Nxf3 Rd7 30. Ne5+ Ke6 31. Nxd7+ Kxd7 32. Kf2 Kd6 33. Kf3 Kd5 34. Kf4 Kc4 35. Re3 b4 36. b3+ Kb5 37. c4+ Ka5 38. Re5 Kb6 39. Ke4 a5 40. Kd5 a4 41. Re6+ Ka5 42. Kxc5 axb3 43. axb3 g5 44. Re7 Ka6 45. Rxh7 g4 46. Rg7 g3 47. Rxg3 Ka5 48. Rg8 Ka6 49. Rg7 Ka5 50. Ra7#",
          "neutral_tokens": {
            "prompt_tokens": 310,
            "completion_tokens": 214,
            "total_tokens": 524,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ka6",
            "Rxh7",
            "g4",
            "Rg7",
            "g3",
            "Rxg3",
            "Ka5",
            "Rg8",
            "Ka6",
            "Rg7",
            "Ka5",
            "Ra7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f7e7",
          "positional_uci": "f7e7",
          "neutral_uci": "f7e7",
          "consensus_move": "f7e7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nd4",
              "Ne5",
              "Re1",
              "Kf7",
              "Ng3",
              "c5",
              "Ndf5",
              "Re6",
              "Ne4",
              "Nd3",
              "Ng5+",
              "Kf6",
              "Rxe6+",
              "Kxf5",
              "Rxa6",
              "Kxg5",
              "b3",
              "Kf5",
              "Ra5",
              "b4",
              "cxb4",
              "Nxb4",
              "Rxc5+",
              "Ke4",
              "Rc4+",
              "Kd3",
              "Rxb4",
              "Kc3",
              "Rb7",
              "Kb2",
              "a4",
              "Ka3",
              "a5",
              "Kb2",
              "a6",
              "Kc3",
              "a7",
              "Kd4",
              "a8=Q",
              "Ke5",
              "Qe8+",
              "Kf6",
              "Rf7+",
              "Kg6",
              "Qe6+",
              "Kg5",
              "Rf5+",
              "Kg4",
              "Qe4#",
              "e4",
              "Nc6",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ka6",
              "Rxh7",
              "g4",
              "Rg7",
              "g3",
              "Rxg3",
              "Ka5",
              "Rg8",
              "Ka6",
              "Rg7",
              "Ka5",
              "Ra7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ka6",
              "Rxh7",
              "g4",
              "Rg7",
              "g3",
              "Rxg3",
              "Ka5",
              "Rg8",
              "Ka6",
              "Rg7",
              "Ka5",
              "Ra7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 311,
            "completion_tokens": 221,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 311,
            "completion_tokens": 214,
            "total_tokens": 525,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 310,
            "completion_tokens": 214,
            "total_tokens": 524,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 932,
          "total_completion_tokens": 649,
          "total_tokens": 1581
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 47,
            "turn_number": 24,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 311,
            "completion_tokens": 221,
            "total_tokens": 532,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 47,
            "turn_number": 24,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 311,
            "completion_tokens": 214,
            "total_tokens": 525,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 47,
            "turn_number": 24,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 310,
            "completion_tokens": 214,
            "total_tokens": 524,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6k1/2p2rpp/p1n1N3/1p6/8/2P5/PP4PP/3R1NK1 b - - 2 24"
    },
    {
      "turn": 50,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ne5",
          "aggressive_uci": "c6e5",
          "aggressive_response": "25... Ne5 26. Nb7 Nc4 27. b3 Nb6 28. Nc5 a5 29. Ng3 Re5 30. Nge4 Nd5 31. c4 bxc4\n32. bxc4 Ne3 33. Rd8+ Kf7 34. Rd7+ Kg6 35. Rxc7 Nxc4 36. Rc6+ Kf5 37. Ng3+ Kf4\n38. Nd3+ Ke3 39. Nxe5 Nxe5 40. Rc5 Nd3 41. Rxa5 Kd2 42. Rd5 Kc3 43. Rxd3+ Kxd3\n44. Nf5 g6 45. Nd6 Kc3 46. Kf2 Kb4 47. Kg3 Ka3 48. Kg4 Kxa2 49. Kg5 Kb3 50. Kh6\nKc3 51. Kxh7 Kd4 52. Kxg6 Ke5 53. Nf7+ Kf4 54. h4 Kg4 55. h5 Kg3 56. h6 Kxg2\n57. h7 Kf3 58. h8=Q Ke4 59. Qe5+ Kd3 60. Qf4 Kc3 61. Qe4 Kb3 62. Qd4 Kc2\n63. Qe3 Kb2 64. Qd3 Ka2 65. Qc3 Kb1 66. Qd2 Ka1 67. Kf5 Kb1 68. Ke4 Ka1 69. Kd3\nKb1 70. Kc3 Ka1 71. Qb2#",
          "aggressive_tokens": {
            "prompt_tokens": 318,
            "completion_tokens": 386,
            "total_tokens": 704,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nb7",
            "Nc4",
            "b3",
            "Nb6",
            "Nc5",
            "a5",
            "Ng3",
            "Re5",
            "Nge4",
            "Nd5",
            "c4",
            "bxc4",
            "bxc4",
            "Ne3",
            "Rd8+",
            "Kf7",
            "Rd7+",
            "Kg6",
            "Rxc7",
            "Nxc4",
            "Rc6+",
            "Kf5",
            "Ng3+",
            "Kf4",
            "Nd3+",
            "Ke3",
            "Nxe5",
            "Nxe5",
            "Rc5",
            "Nd3",
            "Rxa5",
            "Kd2",
            "Rd5",
            "Kc3",
            "Rxd3+",
            "Kxd3",
            "Nf5",
            "g6",
            "Nd6",
            "Kc3",
            "Kf2",
            "Kb4",
            "Kg3",
            "Ka3",
            "Kg4",
            "Kxa2",
            "Kg5",
            "Kb3",
            "Kh6",
            "Kc3",
            "Kxh7",
            "Kd4",
            "Kxg6",
            "Ke5",
            "Nf7+",
            "Kf4",
            "h4",
            "Kg4",
            "h5",
            "Kg3",
            "h6",
            "Kxg2",
            "h7",
            "Kf3",
            "h8=Q",
            "Ke4",
            "Qe5+",
            "Kd3",
            "Qf4",
            "Kc3",
            "Qe4",
            "Kb3",
            "Qd4",
            "Kc2",
            "Qe3",
            "Kb2",
            "Qd3",
            "Ka2",
            "Qc3",
            "Kb1",
            "Qd2",
            "Ka1",
            "Kf5",
            "Kb1",
            "Ke4",
            "Ka1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne5",
          "positional_uci": "c6e5",
          "positional_response": "25... Ne5 26. Re1 Kf8 27. Rxe5 Rxe5 28. Nc6 Re2 29. Nb4 a5 30. Nd5 c6 31. Nf4\nRxb2 32. Ne6+ Kf7 33. Nd8+ Ke8 34. Nxc6 Rxa2 35. Nd4 b4 36. cxb4 axb4 37. Ne3\nRa3 38. Nec2 Ra4 39. Kf2 Kd7 40. Ke3 Kd6 41. Kd3 Kd5 42. Ne3+ Kc5 43. Nb3+ Kb5\n44. Nd4+ Kc5 45. Nb3+ Kb5 46. Nd4+ Kc5 47. Nb3+ Kb5 48. Nd4+ Kc5 49. Nb3+ Kb5\n50. Nd4+ Kc5 51. Nb3+ Kb5 52. Nd4+ Kc5 53. Nb3+ Kb5 54. Nd4+ Kc5 55. Nb3+ Kb5\n56. Nd4+ Kc5 57. Nb3+ Kb5 58. Nd4+ Kc5 59. Nb3+ Kb5 60. Nd4+ Kc5 61. Nb3+ Kb5\n62. Nd4+ Kc5 63. Nb3+ Kb5 64. Nd4+ Kc5 65. Nb3+ Kb5 66. Nd4+ Kc5 67. Nb3+ Kb5\n68. Nd4+ Kc5 69. Nb3+ Kb5 70. Nd4+ Kc5 71. Nb3+ Kb5 72. Nd4+ Kc5 73. Nb3+ Kb5\n74. Nd4+ Kc5 75. Nb3+ Kb5 76. Nd4+ Kc5 77. Nb3+ Kb5 78. Nd4+ Kc5 79. Nb3+ Kb5\n80. Nd4+ Kc5 81. Nb3+ Kb5 82. Nd4+ Kc5 83. Nb3+ Kb5 84. Nd4+ Kc5 85. Nb3+ Kb5\n86. Nd4+ Kc5 87. Nb3+ Kb5 88. Nd4+ Kc5 89. Nb3+ Kb5 90. Nd4+ Kc5 91. Nb3+ Kb5\n92. Nd4+ Kc5 93. Nb3+ Kb5 94. Nd4+ Kc5 95. Nb3+ Kb5 96. Nd4+ Kc5 97. Nb3+ Kb5\n98. Nd4+ Kc5 99. Nb3+ Kb5 100. Nd4+ Kc5",
          "positional_tokens": {
            "prompt_tokens": 318,
            "completion_tokens": 640,
            "total_tokens": 958,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re1",
            "Kf8",
            "Rxe5",
            "Rxe5",
            "Nc6",
            "Re2",
            "Nb4",
            "a5",
            "Nd5",
            "c6",
            "Nf4",
            "Rxb2",
            "Ne6+",
            "Kf7",
            "Nd8+",
            "Ke8",
            "Nxc6",
            "Rxa2",
            "Nd4",
            "b4",
            "cxb4",
            "axb4",
            "Ne3",
            "Ra3",
            "Nec2",
            "Ra4",
            "Kf2",
            "Kd7",
            "Ke3",
            "Kd6",
            "Kd3",
            "Kd5",
            "Ne3+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5",
            "Nb3+",
            "Kb5",
            "Nd4+",
            "Kc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re7",
          "neutral_uci": null,
          "neutral_response": "Repeating the entire game so far: 1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1 O-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1 Rf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 * Repeating the entire game so far: 1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1 O-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1 Rf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 * Repeating the entire game so far: 1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5 Be6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1 O-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1 Rf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7",
          "neutral_tokens": {
            "prompt_tokens": 317,
            "completion_tokens": 640,
            "total_tokens": 957,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c6e5",
          "positional_uci": "c6e5",
          "neutral_uci": null,
          "consensus_move": "c6e5",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nb7",
              "Nc4",
              "b3",
              "Nb6",
              "Nc5",
              "a5",
              "Ng3",
              "Re5",
              "Nge4",
              "Nd5",
              "c4",
              "bxc4",
              "bxc4",
              "Ne3",
              "Rd8+",
              "Kf7",
              "Rd7+",
              "Kg6",
              "Rxc7",
              "Nxc4",
              "Rc6+",
              "Kf5",
              "Ng3+",
              "Kf4",
              "Nd3+",
              "Ke3",
              "Nxe5",
              "Nxe5",
              "Rc5",
              "Nd3",
              "Rxa5",
              "Kd2",
              "Rd5",
              "Kc3",
              "Rxd3+",
              "Kxd3",
              "Nf5",
              "g6",
              "Nd6",
              "Kc3",
              "Kf2",
              "Kb4",
              "Kg3",
              "Ka3",
              "Kg4",
              "Kxa2",
              "Kg5",
              "Kb3",
              "Kh6",
              "Kc3",
              "Kxh7",
              "Kd4",
              "Kxg6",
              "Ke5",
              "Nf7+",
              "Kf4",
              "h4",
              "Kg4",
              "h5",
              "Kg3",
              "h6",
              "Kxg2",
              "h7",
              "Kf3",
              "h8=Q",
              "Ke4",
              "Qe5+",
              "Kd3",
              "Qf4",
              "Kc3",
              "Qe4",
              "Kb3",
              "Qd4",
              "Kc2",
              "Qe3",
              "Kb2",
              "Qd3",
              "Ka2",
              "Qc3",
              "Kb1",
              "Qd2",
              "Ka1",
              "Kf5",
              "Kb1",
              "Ke4",
              "Ka1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Qb2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re1",
              "Kf8",
              "Rxe5",
              "Rxe5",
              "Nc6",
              "Re2",
              "Nb4",
              "a5",
              "Nd5",
              "c6",
              "Nf4",
              "Rxb2",
              "Ne6+",
              "Kf7",
              "Nd8+",
              "Ke8",
              "Nxc6",
              "Rxa2",
              "Nd4",
              "b4",
              "cxb4",
              "axb4",
              "Ne3",
              "Ra3",
              "Nec2",
              "Ra4",
              "Kf2",
              "Kd7",
              "Ke3",
              "Kd6",
              "Kd3",
              "Kd5",
              "Ne3+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5",
              "Nb3+",
              "Kb5",
              "Nd4+",
              "Kc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 318,
            "completion_tokens": 386,
            "total_tokens": 704,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 318,
            "completion_tokens": 640,
            "total_tokens": 958,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 317,
            "completion_tokens": 640,
            "total_tokens": 957,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 953,
          "total_completion_tokens": 1666,
          "total_tokens": 2619
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 49,
            "turn_number": 25,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 318,
            "completion_tokens": 386,
            "total_tokens": 704,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 49,
            "turn_number": 25,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 318,
            "completion_tokens": 640,
            "total_tokens": 958,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 49,
            "turn_number": 25,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 317,
            "completion_tokens": 640,
            "total_tokens": 957,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "3N2k1/2p1r1pp/p1n5/1p6/8/2P5/PP4PP/3R1NK1 b - - 4 25"
    },
    {
      "turn": 52,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nc4",
          "aggressive_uci": "e5c4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. b3 Nb6 28. Nc5 a5 29. Ng3 g6 30. Nge4 Kg7 31. Ng5 Re5 32. Nge6+ Kf6 33. Rf1+ Ke7 34. Rf8 Nd5 35. Rh8 Nxc3 36. Rxh7+ Kd6 37. Rd7+ Kc6 38. Rxc7+ Kd6 39. Rd7+ Kc6 40. Rc7+ Kd6 41. Nb7+ Kxe6 42. Rxc3 b4 43. Rc5 Re2 44. Rxa5 Kd7 45. Nc5+ Kc6 46. Nd3 Kb6 47. Ra4 Kb5 48. Rxb4+ Ka5 49. Ra4+ Kb5 50. Nf4 Rd2 51. Nxg6 Kc5 52. h4 Kd5 53. h5 Ke6 54. h6 Kf6 55. h7 Kxg6 56. h8=Q Kf5 57. Qh5+ Ke6 58. Ra6+ Kd7 59. Qh7+ Kc8 60. Ra8#",
          "aggressive_tokens": {
            "prompt_tokens": 325,
            "completion_tokens": 505,
            "total_tokens": 830,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Nb6",
            "Nc5",
            "a5",
            "Ng3",
            "g6",
            "Nge4",
            "Kg7",
            "Ng5",
            "Re5",
            "Nge6+",
            "Kf6",
            "Rf1+",
            "Ke7",
            "Rf8",
            "Nd5",
            "Rh8",
            "Nxc3",
            "Rxh7+",
            "Kd6",
            "Rd7+",
            "Kc6",
            "Rxc7+",
            "Kd6",
            "Rd7+",
            "Kc6",
            "Rc7+",
            "Kd6",
            "Nb7+",
            "Kxe6",
            "Rxc3",
            "b4",
            "Rc5",
            "Re2",
            "Rxa5",
            "Kd7",
            "Nc5+",
            "Kc6",
            "Nd3",
            "Kb6",
            "Ra4",
            "Kb5",
            "Rxb4+",
            "Ka5",
            "Ra4+",
            "Kb5",
            "Nf4",
            "Rd2",
            "Nxg6",
            "Kc5",
            "h4",
            "Kd5",
            "h5",
            "Ke6",
            "h6",
            "Kf6",
            "h7",
            "Kxg6",
            "h8=Q",
            "Kf5",
            "Qh5+",
            "Ke6",
            "Ra6+",
            "Kd7",
            "Qh7+",
            "Kc8",
            "Ra8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re1",
          "positional_uci": null,
          "positional_response": "Re1\n27. Rxe1 Nd3 28. Re2 Nc1 29. Rc2 Nxa2 30. Nc5 b4 31. Nxa6 b3 32. Re2 Nc1 33. Re7\nNd3 34. Nxc7 Nxb2 35. Ne6 Nd3 36. Rxg7+ Kh8 37. Rd7 b2 38. Rd8# Rxd8 39. Nxd8\nb1=Q 40. Nf7+ Kg7 41. Ng5 Qb6+ 42. Kh1 Nf2+ 43. Kg1 Nh3+ 44. Kh1 Qg1# Nf2+ 46.\nKg1 Nh3+ 47. Kh1 Qg1# 0-1 Nf2+ 49. Kg1 Nh3+ 50. Kh1 Qg1#",
          "positional_tokens": {
            "prompt_tokens": 325,
            "completion_tokens": 201,
            "total_tokens": 526,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe1",
            "Nd3",
            "Re2",
            "Nc1",
            "Rc2",
            "Nxa2",
            "Nc5",
            "b4",
            "Nxa6",
            "b3",
            "Re2",
            "Nc1",
            "Re7",
            "Nd3",
            "Nxc7",
            "Nxb2",
            "Ne6",
            "Nd3",
            "Rxg7+",
            "Kh8",
            "Rd7",
            "b2",
            "Rd8#",
            "Rxd8",
            "Nxd8",
            "b1=Q",
            "Nf7+",
            "Kg7",
            "Ng5",
            "Qb6+",
            "Kh1",
            "Nf2+",
            "Kg1",
            "Nh3+",
            "Kh1",
            "Qg1#",
            "Nf2+",
            "Kg1",
            "Nh3+",
            "Kh1",
            "Qg1#",
            "Nf2+",
            "Kg1",
            "Nh3+",
            "Kh1",
            "Qg1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nc4",
          "neutral_uci": "e5c4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. b3 Nb6 28. Nc5 a5 29. Ng3 g6 30. Nge4 Kg7 31. Ng5 Re2 32. Nge6+ Kh6 33. Rd3\ng5 34. Rh3+ Kg6 35. Nf8+ Kg7 36. Nce6+ Kf7 37. Rxh7+ Kg8 38. Rg7+ Kh8 39. Ng6#",
          "neutral_tokens": {
            "prompt_tokens": 324,
            "completion_tokens": 324,
            "total_tokens": 648,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "Nb6",
            "Nc5",
            "a5",
            "Ng3",
            "g6",
            "Nge4",
            "Kg7",
            "Ng5",
            "Re2",
            "Nge6+",
            "Kh6",
            "Rd3",
            "g5",
            "Rh3+",
            "Kg6",
            "Nf8+",
            "Kg7",
            "Nce6+",
            "Kf7",
            "Rxh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Ng6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e5c4",
          "positional_uci": null,
          "neutral_uci": "e5c4",
          "consensus_move": "e5c4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b3",
              "Nb6",
              "Nc5",
              "a5",
              "Ng3",
              "g6",
              "Nge4",
              "Kg7",
              "Ng5",
              "Re5",
              "Nge6+",
              "Kf6",
              "Rf1+",
              "Ke7",
              "Rf8",
              "Nd5",
              "Rh8",
              "Nxc3",
              "Rxh7+",
              "Kd6",
              "Rd7+",
              "Kc6",
              "Rxc7+",
              "Kd6",
              "Rd7+",
              "Kc6",
              "Rc7+",
              "Kd6",
              "Nb7+",
              "Kxe6",
              "Rxc3",
              "b4",
              "Rc5",
              "Re2",
              "Rxa5",
              "Kd7",
              "Nc5+",
              "Kc6",
              "Nd3",
              "Kb6",
              "Ra4",
              "Kb5",
              "Rxb4+",
              "Ka5",
              "Ra4+",
              "Kb5",
              "Nf4",
              "Rd2",
              "Nxg6",
              "Kc5",
              "h4",
              "Kd5",
              "h5",
              "Ke6",
              "h6",
              "Kf6",
              "h7",
              "Kxg6",
              "h8=Q",
              "Kf5",
              "Qh5+",
              "Ke6",
              "Ra6+",
              "Kd7",
              "Qh7+",
              "Kc8",
              "Ra8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxe1",
              "Nd3",
              "Re2",
              "Nc1",
              "Rc2",
              "Nxa2",
              "Nc5",
              "b4",
              "Nxa6",
              "b3",
              "Re2",
              "Nc1",
              "Re7",
              "Nd3",
              "Nxc7",
              "Nxb2",
              "Ne6",
              "Nd3",
              "Rxg7+",
              "Kh8",
              "Rd7",
              "b2",
              "Rd8#",
              "Rxd8",
              "Nxd8",
              "b1=Q",
              "Nf7+",
              "Kg7",
              "Ng5",
              "Qb6+",
              "Kh1",
              "Nf2+",
              "Kg1",
              "Nh3+",
              "Kh1",
              "Qg1#",
              "Nf2+",
              "Kg1",
              "Nh3+",
              "Kh1",
              "Qg1#",
              "Nf2+",
              "Kg1",
              "Nh3+",
              "Kh1",
              "Qg1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "b3",
              "Nb6",
              "Nc5",
              "a5",
              "Ng3",
              "g6",
              "Nge4",
              "Kg7",
              "Ng5",
              "Re2",
              "Nge6+",
              "Kh6",
              "Rd3",
              "g5",
              "Rh3+",
              "Kg6",
              "Nf8+",
              "Kg7",
              "Nce6+",
              "Kf7",
              "Rxh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Ng6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 325,
            "completion_tokens": 505,
            "total_tokens": 830,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 325,
            "completion_tokens": 201,
            "total_tokens": 526,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 324,
            "completion_tokens": 324,
            "total_tokens": 648,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 974,
          "total_completion_tokens": 1030,
          "total_tokens": 2004
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 51,
            "turn_number": 26,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 325,
            "completion_tokens": 505,
            "total_tokens": 830,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 51,
            "turn_number": 26,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 325,
            "completion_tokens": 201,
            "total_tokens": 526,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 51,
            "turn_number": 26,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 324,
            "completion_tokens": 324,
            "total_tokens": 648,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6k1/1Np1r1pp/p7/1p2n3/8/2P5/PP4PP/3R1NK1 b - - 6 26"
    },
    {
      "turn": 54,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf7",
          "aggressive_uci": "g8f7",
          "aggressive_response": "27... Kf7 28. b3 Ne5 29. Nc5 a5 30. Ra8 Nc6 31. Ra6 Ne5 32. Rxa5 c6 33. Ra6\nKg6 34. a4 bxa4 35. bxa4 Kf5 36. Ne3+ Kf4 37. Kf2 g5 38. g3# Kf3 39. Nf5 Ng4+\n40. Kf1 Nxh2+ 41. Kg1 Re2 42. Nd4+ Kxg3 43. Nxe2+ Kh3 44. Rxc6 Nf3+ 45. Kf2\ng4 46. Rh6+ Nh4 47. Rxh7 g3+ 48. Nxg3 Kg4 49. Rxh4+ Kxh4 50. a5 Kg4 51. a6\nKf4 52. a7 Ke5 53. a8=Q Kd6 54. Qa5 Kc6 55. Ke3 Kd6 56. Kd4 Kc6 57. Qc5+ Kd7\n58. Qb6 Ke7 59. Ke5 Kd7 60. Qd6+ Kc8 61. Qe7 Kb8 62. Kd6 Ka8 63. Kc6 Kb8 64.\nQb7# Kd8 65. Qd7# Kf8 66. Kd6 Kg8 67. Ke6 Kh8 68. Kf6 Kg8 69. Qg7# Kf8 70.\nQf7# Kg8 71. Qg7# Kf8 72. Qf7# Kg8 73. Qg7# Kf8 74. Qf7# Kg8 75. Qg7# Kf8\n76. Qf7# Kg8 77. Qg7# Kf8 78. Qf7# Kg8 79. Qg7# Kf8 80. Qf7# Kg8 81. Qg7# Kf8\n82. Qf7# Kg8 83. Qg7# Kf8 84. Qf7# Kg8 85. Qg7# Kf8 86. Qf7# Kg8 87. Qg7# Kf8\n88. Qf7# Kg8 89. Qg7# Kf8 90. Qf7# Kg8 91. Qg7# Kf8 92. Qf7# Kg8 93. Qg7# Kf8\n94. Qf7# Kg8 95. Qg7# Kf8 96. Qf7# Kg8 97. Qg7# Kf8 98. Qf7#",
          "aggressive_tokens": {
            "prompt_tokens": 334,
            "completion_tokens": 640,
            "total_tokens": 974,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "b3",
            "Ne5",
            "Nc5",
            "a5",
            "Ra8",
            "Nc6",
            "Ra6",
            "Ne5",
            "Rxa5",
            "c6",
            "Ra6",
            "Kg6",
            "a4",
            "bxa4",
            "bxa4",
            "Kf5",
            "Ne3+",
            "Kf4",
            "Kf2",
            "g5",
            "g3#",
            "Kf3",
            "Nf5",
            "Ng4+",
            "Kf1",
            "Nxh2+",
            "Kg1",
            "Re2",
            "Nd4+",
            "Kxg3",
            "Nxe2+",
            "Kh3",
            "Rxc6",
            "Nf3+",
            "Kf2",
            "g4",
            "Rh6+",
            "Nh4",
            "Rxh7",
            "g3+",
            "Nxg3",
            "Kg4",
            "Rxh4+",
            "Kxh4",
            "a5",
            "Kg4",
            "a6",
            "Kf4",
            "a7",
            "Ke5",
            "a8=Q",
            "Kd6",
            "Qa5",
            "Kc6",
            "Ke3",
            "Kd6",
            "Kd4",
            "Kc6",
            "Qc5+",
            "Kd7",
            "Qb6",
            "Ke7",
            "Ke5",
            "Kd7",
            "Qd6+",
            "Kc8",
            "Qe7",
            "Kb8",
            "Kd6",
            "Ka8",
            "Kc6",
            "Kb8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kf8",
            "Kd6",
            "Kg8",
            "Ke6",
            "Kh8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#",
            "Kf8",
            "Qf7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kf7",
          "positional_uci": "g8f7",
          "positional_response": "27... Kf7 28. b3 Ne5 29. Nc5 a5 30. Ra8 Nc6 31. Ra6 Ne5 32. Rxa5 c6 33. Ra6\nKg6 34. a4 bxa4 35. bxa4 Kf5 36. a5 Nc4 37. Ra8 Re5 38. Rf8+ Kg6 39. Nd7 Rxa5\n40. Rf4 Nd6 41. Nf8+ Kh6 42. Rh4+ Kg5 43. Rxh7 Kf6 44. Nd7+ Kg6 45. Rh3 Ne4 46.\nRe3 Kf5 47. g4+ Kf4 48. Rd3 Ra1 49. Kg2 Ra2+ 50. Kg1 Ra1 51. Kg2 Ra2+ 52. Kg1\nRa1 53. Kg2 Ra2+ 54. Kg1 Ra1 55. Kg2 Ra2+ 56. Kg1 Ra1 57. Kg2 Ra2+ 58. Kg1\nRa1 59. Kg2 Ra2+ 60. Kg1 Ra1 61. Kg2 Ra2+ 62. Kg1 Ra1 63. Kg2 Ra2+ 64. Kg1\nRa1 65. Kg2 Ra2+ 66. Kg1 Ra1 67. Kg2 Ra2+ 68. Kg1 Ra1 69. Kg2 Ra2+ 70. Kg1\nRa1 71. Kg2 Ra2+ 72. Kg1 Ra1 73. Kg2 Ra2+ 74. Kg1 Ra1 75. Kg2 Ra2+ 76. Kg1\nRa1 77. Kg2 Ra2+ 78. Kg1 Ra1 79. Kg2 Ra2+ 80. Kg1 Ra1 81. Kg2 Ra2+ 82. Kg1\nRa1 83. Kg2 Ra2+ 84. Kg1 Ra1 85. Kg2 Ra2+ 86. Kg1 Ra1 87. Kg2 Ra2+ 88. Kg1\nRa1 89. Kg2 Ra2+ 90. Kg1 Ra1 91. Kg2 Ra2+ 92. Kg1 Ra1 93. Kg2 Ra2+ 94. Kg1\nRa1 95. Kg2 Ra2+ 96. Kg1 Ra1 97. Kg2 Ra2+ 98. Kg1 Ra1 99. Kg2 Ra2+ 100. Kg1\nRa1 101. Kg2 Ra2+ 102. Kg1 Ra1 103. Kg2 Ra2+ 104. Kg1 Ra1 105. Kg2 Ra2+ 106. Kg1\nRa1 107. Kg2 Ra2+ 108. Kg1 Ra1 109. Kg2",
          "positional_tokens": {
            "prompt_tokens": 334,
            "completion_tokens": 640,
            "total_tokens": 974,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "b3",
            "Ne5",
            "Nc5",
            "a5",
            "Ra8",
            "Nc6",
            "Ra6",
            "Ne5",
            "Rxa5",
            "c6",
            "Ra6",
            "Kg6",
            "a4",
            "bxa4",
            "bxa4",
            "Kf5",
            "a5",
            "Nc4",
            "Ra8",
            "Re5",
            "Rf8+",
            "Kg6",
            "Nd7",
            "Rxa5",
            "Rf4",
            "Nd6",
            "Nf8+",
            "Kh6",
            "Rh4+",
            "Kg5",
            "Rxh7",
            "Kf6",
            "Nd7+",
            "Kg6",
            "Rh3",
            "Ne4",
            "Re3",
            "Kf5",
            "g4+",
            "Kf4",
            "Rd3",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2",
            "Ra2+",
            "Kg1",
            "Ra1",
            "Kg2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kd7",
          "neutral_uci": null,
          "neutral_response": "Re7 28. Nc5+ Kf7 29. b3 Ne3 30. Nxe3 Rxe3 31. Rd7+ Re7 32. Rxe7+ Kxe7\n33. Nxa6 Kd6 34. Kf2 c5 35. Ke3 Kc6 36. b4 cxb4 37. Nxb4+ Kc5 38. Kd3 g6 39. g4\nh6 40. h4 g5 41. hxg5 hxg5 42. Ke4 Kc4 43. Nd5 Kc5 44. Ke5 Kc4 45. Kd6 Kd3 46.\nKc5 Ke4 47. Nf6+ Kf4 48. Kxb5 Ke5 49. Nh7 Kf4 50. Nxg5 Kxg5 51. c4 Kxg4 52.\nc5 Kf5 53. c6 Ke6 54. Kb6 Kd6 55. Kb7 Kc5 56. c7 Kb4 57. c8=Q Ka3 58. Qc4 Kb2\n59. Qb3+ Ka1 60. Qc3+ Kxa2 61. Kb6 Kb1 62. Kb5 Ka2 63. Kb4 Kb1 64. Qd2 Ka1 65.\nKb3 Kb1 66. Qb2# Kc1 Kd1 Kc2 Kd2 Kc3 Kd3 Kc4 Kd5 Kc6 Kd7 Kc8 Kd8 Kc7 Kd7 Kc8\nKd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7\nKc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8\nKd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8\nKd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8\nKd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc8 K",
          "neutral_tokens": {
            "prompt_tokens": 333,
            "completion_tokens": 640,
            "total_tokens": 973,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kc8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g8f7",
          "positional_uci": "g8f7",
          "neutral_uci": null,
          "consensus_move": "g8f7",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "b3",
              "Ne5",
              "Nc5",
              "a5",
              "Ra8",
              "Nc6",
              "Ra6",
              "Ne5",
              "Rxa5",
              "c6",
              "Ra6",
              "Kg6",
              "a4",
              "bxa4",
              "bxa4",
              "Kf5",
              "Ne3+",
              "Kf4",
              "Kf2",
              "g5",
              "g3#",
              "Kf3",
              "Nf5",
              "Ng4+",
              "Kf1",
              "Nxh2+",
              "Kg1",
              "Re2",
              "Nd4+",
              "Kxg3",
              "Nxe2+",
              "Kh3",
              "Rxc6",
              "Nf3+",
              "Kf2",
              "g4",
              "Rh6+",
              "Nh4",
              "Rxh7",
              "g3+",
              "Nxg3",
              "Kg4",
              "Rxh4+",
              "Kxh4",
              "a5",
              "Kg4",
              "a6",
              "Kf4",
              "a7",
              "Ke5",
              "a8=Q",
              "Kd6",
              "Qa5",
              "Kc6",
              "Ke3",
              "Kd6",
              "Kd4",
              "Kc6",
              "Qc5+",
              "Kd7",
              "Qb6",
              "Ke7",
              "Ke5",
              "Kd7",
              "Qd6+",
              "Kc8",
              "Qe7",
              "Kb8",
              "Kd6",
              "Ka8",
              "Kc6",
              "Kb8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kf8",
              "Kd6",
              "Kg8",
              "Ke6",
              "Kh8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#",
              "Kf8",
              "Qf7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "b3",
              "Ne5",
              "Nc5",
              "a5",
              "Ra8",
              "Nc6",
              "Ra6",
              "Ne5",
              "Rxa5",
              "c6",
              "Ra6",
              "Kg6",
              "a4",
              "bxa4",
              "bxa4",
              "Kf5",
              "a5",
              "Nc4",
              "Ra8",
              "Re5",
              "Rf8+",
              "Kg6",
              "Nd7",
              "Rxa5",
              "Rf4",
              "Nd6",
              "Nf8+",
              "Kh6",
              "Rh4+",
              "Kg5",
              "Rxh7",
              "Kf6",
              "Nd7+",
              "Kg6",
              "Rh3",
              "Ne4",
              "Re3",
              "Kf5",
              "g4+",
              "Kf4",
              "Rd3",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2",
              "Ra2+",
              "Kg1",
              "Ra1",
              "Kg2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kc8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 334,
            "completion_tokens": 640,
            "total_tokens": 974,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 334,
            "completion_tokens": 640,
            "total_tokens": 974,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 333,
            "completion_tokens": 640,
            "total_tokens": 973,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1001,
          "total_completion_tokens": 1920,
          "total_tokens": 2921
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 53,
            "turn_number": 27,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 334,
            "completion_tokens": 640,
            "total_tokens": 974,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 53,
            "turn_number": 27,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 334,
            "completion_tokens": 640,
            "total_tokens": 974,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 53,
            "turn_number": 27,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 333,
            "completion_tokens": 640,
            "total_tokens": 973,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "3R2k1/1Np1r1pp/p7/1p6/2n5/2P5/PP4PP/5NK1 b - - 8 27"
    },
    {
      "turn": 56,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nb6",
          "aggressive_uci": "c4b6",
          "aggressive_response": "28... Nb6 29. Nc5 a5 30. Kf2 a4 31. Ne3 axb3 32. axb3 Re5 33. Nd3 Re7 34. Nd5 Nxd5 35. Rxd5 c6 36. Rd6 Rc7 37. Ne5+ Ke7 38. Rxc6 Rxc6 39. Nxc6+ Kd6 40. Nd4 Kc5 41. Ke3 b4 42. c4 g6 43. Ke4 h6 44. Ke5 h5 45. h4 Kb6 46. Kd6 Ka5 47. c5 Ka6 48. c6 Kb6 49. c7 Kb7 50. Kd7 Kb6 51. c8=Q Ka5 52. Qc5+ Ka6 53. Qb5+ Ka7 54. Nc6+ Ka8 55. Qb8#",
          "aggressive_tokens": {
            "prompt_tokens": 342,
            "completion_tokens": 217,
            "total_tokens": 559,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "a5",
            "Kf2",
            "a4",
            "Ne3",
            "axb3",
            "axb3",
            "Re5",
            "Nd3",
            "Re7",
            "Nd5",
            "Nxd5",
            "Rxd5",
            "c6",
            "Rd6",
            "Rc7",
            "Ne5+",
            "Ke7",
            "Rxc6",
            "Rxc6",
            "Nxc6+",
            "Kd6",
            "Nd4",
            "Kc5",
            "Ke3",
            "b4",
            "c4",
            "g6",
            "Ke4",
            "h6",
            "Ke5",
            "h5",
            "h4",
            "Kb6",
            "Kd6",
            "Ka5",
            "c5",
            "Ka6",
            "c6",
            "Kb6",
            "c7",
            "Kb7",
            "Kd7",
            "Kb6",
            "c8=Q",
            "Ka5",
            "Qc5+",
            "Ka6",
            "Qb5+",
            "Ka7",
            "Nc6+",
            "Ka8",
            "Qb8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nb6",
          "positional_uci": "c4b6",
          "positional_response": "28... Nb6 29. Nc5 a5 30. Rb8 b4 31. cxb4 axb4 32. Na6 Nd5 33. Rb5 c6 34. Rc5 Re6\n35. Nb8 Ne7 36. Rc4 Re2 37. Nxc6 Nxc6 38. Rxc6 Rxa2 39. Rb6 Rb2 40. Rxb4 Ke6\n41. Rb7 Kf6 42. b4 h5 43. b5 g5 44. b6 Ke6 45. Rb8 Kd7 46. b7 Kc7 47. Rg8\nRxb7 48. Rxg5 h4 49. Rg4 h3 50. gxh3 Kd6 51. h4 Ke5 52. h5 Kf5 53. Rg3 Rh7\n54. Rh3 Kg4 55. Kg2 Rxh5 56. Rxh5 Kxh5 57. Kg3 Kg5 58. h4+ Kh5 59. Kh3 Kg6\n60. Kg4 Kh6 61. h5 Kg7 62. Kg5 Kh7 63. h6 Kg8 64. Kg6 Kh8 65. h7 *",
          "positional_tokens": {
            "prompt_tokens": 342,
            "completion_tokens": 295,
            "total_tokens": 637,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "a5",
            "Rb8",
            "b4",
            "cxb4",
            "axb4",
            "Na6",
            "Nd5",
            "Rb5",
            "c6",
            "Rc5",
            "Re6",
            "Nb8",
            "Ne7",
            "Rc4",
            "Re2",
            "Nxc6",
            "Nxc6",
            "Rxc6",
            "Rxa2",
            "Rb6",
            "Rb2",
            "Rxb4",
            "Ke6",
            "Rb7",
            "Kf6",
            "b4",
            "h5",
            "b5",
            "g5",
            "b6",
            "Ke6",
            "Rb8",
            "Kd7",
            "b7",
            "Kc7",
            "Rg8",
            "Rxb7",
            "Rxg5",
            "h4",
            "Rg4",
            "h3",
            "gxh3",
            "Kd6",
            "h4",
            "Ke5",
            "h5",
            "Kf5",
            "Rg3",
            "Rh7",
            "Rh3",
            "Kg4",
            "Kg2",
            "Rxh5",
            "Rxh5",
            "Kxh5",
            "Kg3",
            "Kg5",
            "h4+",
            "Kh5",
            "Kh3",
            "Kg6",
            "Kg4",
            "Kh6",
            "h5",
            "Kg7",
            "Kg5",
            "Kh7",
            "h6",
            "Kg8",
            "Kg6",
            "Kh8",
            "h7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nb6",
          "neutral_uci": "c4b6",
          "neutral_response": "28... Nb6 29. Nc5 a5 30. Kf2 a4 31. Ne3 axb3 32. axb3 Re5 33. b4 Ke7 34. Rg8\nKf7 35. Rb8 Ke7 36. Rb7 Kd6 37. Rb8 Ke7 38. Rh8 h6 39. Rg8 Kf7 40. Rd8 Ke7 41.\nRd4 c6 42. Re4 Rxe4 43. Nxe4 Ke6 44. Kf3 Ke5 45. Nc5 Kd6 46. Ke4 g6 47. g4 Nc8\n48. h4 Ne7 49. h5 gxh5 50. gxh5 Ng8 51. Nf5+ Kc7 52. Ke5 Kb6 53. Kd6 Nf6 54.\nNd7+ Nxd7 55. Kxd7 c5 56. Nxh6 cxb4 57. cxb4 Kb7 58. Nf5 Kb6 59. h6 Kb7 60.\nh7 Kb6 61. h8=Q Kb7 62. Qc8+ Kb6 63. Qc7+ Ka6 64. Qc6+ Ka7 65. Qxb5 Ka8 66. Kc7\nKa7 67. Qb7# Nf6 68. Qb6+ Ka8 69. Qb8#",
          "neutral_tokens": {
            "prompt_tokens": 341,
            "completion_tokens": 342,
            "total_tokens": 683,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nc5",
            "a5",
            "Kf2",
            "a4",
            "Ne3",
            "axb3",
            "axb3",
            "Re5",
            "b4",
            "Ke7",
            "Rg8",
            "Kf7",
            "Rb8",
            "Ke7",
            "Rb7",
            "Kd6",
            "Rb8",
            "Ke7",
            "Rh8",
            "h6",
            "Rg8",
            "Kf7",
            "Rd8",
            "Ke7",
            "Rd4",
            "c6",
            "Re4",
            "Rxe4",
            "Nxe4",
            "Ke6",
            "Kf3",
            "Ke5",
            "Nc5",
            "Kd6",
            "Ke4",
            "g6",
            "g4",
            "Nc8",
            "h4",
            "Ne7",
            "h5",
            "gxh5",
            "gxh5",
            "Ng8",
            "Nf5+",
            "Kc7",
            "Ke5",
            "Kb6",
            "Kd6",
            "Nf6",
            "Nd7+",
            "Nxd7",
            "Kxd7",
            "c5",
            "Nxh6",
            "cxb4",
            "cxb4",
            "Kb7",
            "Nf5",
            "Kb6",
            "h6",
            "Kb7",
            "h7",
            "Kb6",
            "h8=Q",
            "Kb7",
            "Qc8+",
            "Kb6",
            "Qc7+",
            "Ka6",
            "Qc6+",
            "Ka7",
            "Qxb5",
            "Ka8",
            "Kc7",
            "Ka7",
            "Qb7#",
            "Nf6",
            "Qb6+",
            "Ka8",
            "Qb8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c4b6",
          "positional_uci": "c4b6",
          "neutral_uci": "c4b6",
          "consensus_move": "c4b6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nc5",
              "a5",
              "Kf2",
              "a4",
              "Ne3",
              "axb3",
              "axb3",
              "Re5",
              "Nd3",
              "Re7",
              "Nd5",
              "Nxd5",
              "Rxd5",
              "c6",
              "Rd6",
              "Rc7",
              "Ne5+",
              "Ke7",
              "Rxc6",
              "Rxc6",
              "Nxc6+",
              "Kd6",
              "Nd4",
              "Kc5",
              "Ke3",
              "b4",
              "c4",
              "g6",
              "Ke4",
              "h6",
              "Ke5",
              "h5",
              "h4",
              "Kb6",
              "Kd6",
              "Ka5",
              "c5",
              "Ka6",
              "c6",
              "Kb6",
              "c7",
              "Kb7",
              "Kd7",
              "Kb6",
              "c8=Q",
              "Ka5",
              "Qc5+",
              "Ka6",
              "Qb5+",
              "Ka7",
              "Nc6+",
              "Ka8",
              "Qb8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nc5",
              "a5",
              "Rb8",
              "b4",
              "cxb4",
              "axb4",
              "Na6",
              "Nd5",
              "Rb5",
              "c6",
              "Rc5",
              "Re6",
              "Nb8",
              "Ne7",
              "Rc4",
              "Re2",
              "Nxc6",
              "Nxc6",
              "Rxc6",
              "Rxa2",
              "Rb6",
              "Rb2",
              "Rxb4",
              "Ke6",
              "Rb7",
              "Kf6",
              "b4",
              "h5",
              "b5",
              "g5",
              "b6",
              "Ke6",
              "Rb8",
              "Kd7",
              "b7",
              "Kc7",
              "Rg8",
              "Rxb7",
              "Rxg5",
              "h4",
              "Rg4",
              "h3",
              "gxh3",
              "Kd6",
              "h4",
              "Ke5",
              "h5",
              "Kf5",
              "Rg3",
              "Rh7",
              "Rh3",
              "Kg4",
              "Kg2",
              "Rxh5",
              "Rxh5",
              "Kxh5",
              "Kg3",
              "Kg5",
              "h4+",
              "Kh5",
              "Kh3",
              "Kg6",
              "Kg4",
              "Kh6",
              "h5",
              "Kg7",
              "Kg5",
              "Kh7",
              "h6",
              "Kg8",
              "Kg6",
              "Kh8",
              "h7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nc5",
              "a5",
              "Kf2",
              "a4",
              "Ne3",
              "axb3",
              "axb3",
              "Re5",
              "b4",
              "Ke7",
              "Rg8",
              "Kf7",
              "Rb8",
              "Ke7",
              "Rb7",
              "Kd6",
              "Rb8",
              "Ke7",
              "Rh8",
              "h6",
              "Rg8",
              "Kf7",
              "Rd8",
              "Ke7",
              "Rd4",
              "c6",
              "Re4",
              "Rxe4",
              "Nxe4",
              "Ke6",
              "Kf3",
              "Ke5",
              "Nc5",
              "Kd6",
              "Ke4",
              "g6",
              "g4",
              "Nc8",
              "h4",
              "Ne7",
              "h5",
              "gxh5",
              "gxh5",
              "Ng8",
              "Nf5+",
              "Kc7",
              "Ke5",
              "Kb6",
              "Kd6",
              "Nf6",
              "Nd7+",
              "Nxd7",
              "Kxd7",
              "c5",
              "Nxh6",
              "cxb4",
              "cxb4",
              "Kb7",
              "Nf5",
              "Kb6",
              "h6",
              "Kb7",
              "h7",
              "Kb6",
              "h8=Q",
              "Kb7",
              "Qc8+",
              "Kb6",
              "Qc7+",
              "Ka6",
              "Qc6+",
              "Ka7",
              "Qxb5",
              "Ka8",
              "Kc7",
              "Ka7",
              "Qb7#",
              "Nf6",
              "Qb6+",
              "Ka8",
              "Qb8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 342,
            "completion_tokens": 217,
            "total_tokens": 559,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 342,
            "completion_tokens": 295,
            "total_tokens": 637,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 341,
            "completion_tokens": 342,
            "total_tokens": 683,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1025,
          "total_completion_tokens": 854,
          "total_tokens": 1879
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 55,
            "turn_number": 28,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 342,
            "completion_tokens": 217,
            "total_tokens": 559,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 55,
            "turn_number": 28,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 342,
            "completion_tokens": 295,
            "total_tokens": 637,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 55,
            "turn_number": 28,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 341,
            "completion_tokens": 342,
            "total_tokens": 683,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3R4/1Np1rkpp/p7/1p6/2n5/1PP5/P5PP/5NK1 b - - 0 28"
    },
    {
      "turn": 58,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re2",
          "aggressive_uci": "e7e2",
          "aggressive_response": "29... Re2 30. Rd2 Re5 31. Nxa6 Nd5 32. c4 bxc4 33. bxc4 Nc3 34. Nxc7 Rc5 35. Rd7+\nKg6 36. Rxg7+ Kh6 37. Ne6 Rxc4 38. Ng3 Rc6 39. Nf5+ Kh5 40. g4# e5 Nf4+ Kg5\nNxf5 Kxf5 Rf7+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5+ Ke6 Rf6+ Ke5 Rf5",
          "aggressive_tokens": {
            "prompt_tokens": 350,
            "completion_tokens": 640,
            "total_tokens": 990,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rd2",
            "Re5",
            "Nxa6",
            "Nd5",
            "c4",
            "bxc4",
            "bxc4",
            "Nc3",
            "Nxc7",
            "Rc5",
            "Rd7+",
            "Kg6",
            "Rxg7+",
            "Kh6",
            "Ne6",
            "Rxc4",
            "Ng3",
            "Rc6",
            "Nf5+",
            "Kh5",
            "g4#",
            "e5",
            "Nf4+",
            "Kg5",
            "Nxf5",
            "Kxf5",
            "Rf7+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Ke6",
            "Rf6+",
            "Ke5",
            "Rf5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re2",
          "positional_uci": "e7e2",
          "positional_response": "29... Re2 30. Rd2 Re5 31. Nxa6 Nd5 32. c4 bxc4 33. bxc4 Nc3 34. Nxc7 Rc5 35. Rd7+\nKf6 36. Ne8+ Ke6 37. Rxg7 Rxc4 38. Rxh7 Nxa2 39. h4 Nb4 40. h5 Nd5 41. h6 Rh4\n42. Ng7+ Kf6 43. Ne8+ Kg6 44. Rd7 Nf4 45. Rd6+ Kh7 46. g3 Rg4 47. Nf6+ Kxh6\n48. Nxg4+ Kg5 49. gxf4+ Kxg4 50. Rd4 Kf5 51. Ne3+ Kf6 52. Rd5 Ke6 53. f5+ Kf6\n54. Ng4+ Kg5 55. f6+ Kg6 56. Rd7 Kf5 57. f7 Kxg4 58. f8=Q Kg5 59. Rg7+ Kh6\n60. Qh8# e4 e5 e6",
          "positional_tokens": {
            "prompt_tokens": 350,
            "completion_tokens": 271,
            "total_tokens": 621,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rd2",
            "Re5",
            "Nxa6",
            "Nd5",
            "c4",
            "bxc4",
            "bxc4",
            "Nc3",
            "Nxc7",
            "Rc5",
            "Rd7+",
            "Kf6",
            "Ne8+",
            "Ke6",
            "Rxg7",
            "Rxc4",
            "Rxh7",
            "Nxa2",
            "h4",
            "Nb4",
            "h5",
            "Nd5",
            "h6",
            "Rh4",
            "Ng7+",
            "Kf6",
            "Ne8+",
            "Kg6",
            "Rd7",
            "Nf4",
            "Rd6+",
            "Kh7",
            "g3",
            "Rg4",
            "Nf6+",
            "Kxh6",
            "Nxg4+",
            "Kg5",
            "gxf4+",
            "Kxg4",
            "Rd4",
            "Kf5",
            "Ne3+",
            "Kf6",
            "Rd5",
            "Ke6",
            "f5+",
            "Kf6",
            "Ng4+",
            "Kg5",
            "f6+",
            "Kg6",
            "Rd7",
            "Kf5",
            "f7",
            "Kxg4",
            "f8=Q",
            "Kg5",
            "Rg7+",
            "Kh6",
            "Qh8#",
            "e4",
            "e5",
            "e6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re2",
          "neutral_uci": "e7e2",
          "neutral_response": "29... Re2 30. Rd2 Re5 31. Nxa6 Nd5 32. c4 bxc4 33. bxc4 Nc3 34. Nxc7 Rc5 35. Rd7+\nKg6 36. Rxg7+ Kh6 37. Ne6 Rxc4 38. Ng3 Rc6 39. Nf5+ Kh5 40. g4# e5 Nf4+ Kg5\nNxf5 Kxf5 Rf7+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5+ Kg6 Rf6+ Kg5 Rf5",
          "neutral_tokens": {
            "prompt_tokens": 349,
            "completion_tokens": 640,
            "total_tokens": 989,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rd2",
            "Re5",
            "Nxa6",
            "Nd5",
            "c4",
            "bxc4",
            "bxc4",
            "Nc3",
            "Nxc7",
            "Rc5",
            "Rd7+",
            "Kg6",
            "Rxg7+",
            "Kh6",
            "Ne6",
            "Rxc4",
            "Ng3",
            "Rc6",
            "Nf5+",
            "Kh5",
            "g4#",
            "e5",
            "Nf4+",
            "Kg5",
            "Nxf5",
            "Kxf5",
            "Rf7+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5+",
            "Kg6",
            "Rf6+",
            "Kg5",
            "Rf5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e7e2",
          "positional_uci": "e7e2",
          "neutral_uci": "e7e2",
          "consensus_move": "e7e2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rd2",
              "Re5",
              "Nxa6",
              "Nd5",
              "c4",
              "bxc4",
              "bxc4",
              "Nc3",
              "Nxc7",
              "Rc5",
              "Rd7+",
              "Kg6",
              "Rxg7+",
              "Kh6",
              "Ne6",
              "Rxc4",
              "Ng3",
              "Rc6",
              "Nf5+",
              "Kh5",
              "g4#",
              "e5",
              "Nf4+",
              "Kg5",
              "Nxf5",
              "Kxf5",
              "Rf7+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Ke6",
              "Rf6+",
              "Ke5",
              "Rf5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rd2",
              "Re5",
              "Nxa6",
              "Nd5",
              "c4",
              "bxc4",
              "bxc4",
              "Nc3",
              "Nxc7",
              "Rc5",
              "Rd7+",
              "Kf6",
              "Ne8+",
              "Ke6",
              "Rxg7",
              "Rxc4",
              "Rxh7",
              "Nxa2",
              "h4",
              "Nb4",
              "h5",
              "Nd5",
              "h6",
              "Rh4",
              "Ng7+",
              "Kf6",
              "Ne8+",
              "Kg6",
              "Rd7",
              "Nf4",
              "Rd6+",
              "Kh7",
              "g3",
              "Rg4",
              "Nf6+",
              "Kxh6",
              "Nxg4+",
              "Kg5",
              "gxf4+",
              "Kxg4",
              "Rd4",
              "Kf5",
              "Ne3+",
              "Kf6",
              "Rd5",
              "Ke6",
              "f5+",
              "Kf6",
              "Ng4+",
              "Kg5",
              "f6+",
              "Kg6",
              "Rd7",
              "Kf5",
              "f7",
              "Kxg4",
              "f8=Q",
              "Kg5",
              "Rg7+",
              "Kh6",
              "Qh8#",
              "e4",
              "e5",
              "e6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rd2",
              "Re5",
              "Nxa6",
              "Nd5",
              "c4",
              "bxc4",
              "bxc4",
              "Nc3",
              "Nxc7",
              "Rc5",
              "Rd7+",
              "Kg6",
              "Rxg7+",
              "Kh6",
              "Ne6",
              "Rxc4",
              "Ng3",
              "Rc6",
              "Nf5+",
              "Kh5",
              "g4#",
              "e5",
              "Nf4+",
              "Kg5",
              "Nxf5",
              "Kxf5",
              "Rf7+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5+",
              "Kg6",
              "Rf6+",
              "Kg5",
              "Rf5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 350,
            "completion_tokens": 640,
            "total_tokens": 990,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 350,
            "completion_tokens": 271,
            "total_tokens": 621,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 349,
            "completion_tokens": 640,
            "total_tokens": 989,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1049,
          "total_completion_tokens": 1551,
          "total_tokens": 2600
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 57,
            "turn_number": 29,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 350,
            "completion_tokens": 640,
            "total_tokens": 990,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 57,
            "turn_number": 29,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 350,
            "completion_tokens": 271,
            "total_tokens": 621,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 57,
            "turn_number": 29,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 349,
            "completion_tokens": 640,
            "total_tokens": 989,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "3R4/2p1rkpp/pn6/1pN5/8/1PP5/P5PP/5NK1 b - - 2 29"
    },
    {
      "turn": 60,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxa2",
          "aggressive_uci": "e2a2",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rxc3 34. Rd6 Nc4 35. Rc6 Rc1 36. Ne2 Rc2 37. Nd4 Rc1 38. Kf2 Ke7 39. Ne3\nKd7 40. Rxc4 Rxc4 41. Nxc4 *",
          "aggressive_tokens": {
            "prompt_tokens": 358,
            "completion_tokens": 339,
            "total_tokens": 697,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxc7",
            "Ra3",
            "Nxb5",
            "Rxb3",
            "Nd4",
            "Rxc3",
            "Rd6",
            "Nc4",
            "Rc6",
            "Rc1",
            "Ne2",
            "Rc2",
            "Nd4",
            "Rc1",
            "Kf2",
            "Ke7",
            "Ne3",
            "Kd7",
            "Rxc4",
            "Rxc4",
            "Nxc4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxa2",
          "positional_uci": "e2a2",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rxc3 34. Rd6 Nc4 35. Rc6 Rc1 36. Ne2 Rc2 37. Nd4 Rc1 38. Kf2 Ke7 39. Ne3\nKd7 40. Rxc4 Rxc4 41. Nxc4 Ke7 42. Ke3 Kf6 43. Kf4 g5+ 44. Kg4 Kg6 45. Ne5+ Kf6\n46. Ndf3 h6 47. Kh5 Kf5 48. Kxh6 g4 49. Nxg4 Kxg4 50. Kg6 Kf4 51. h4 Kg3 52. h5\nKxg2 53. h6 Kxf3 54. h7 Ke4 55. h8=Q Kd5 56. Qf6 Ke4 57. Qf5+ Kd4 58. Kf6 Kc4\n59. Qe5 Kd3 60. Qf4 Kc3 61. Qe4 Kd2 62. Qf3 Kc2 63. Qe3 Kb2 64. Qd3 Ka2 65. Qc3\nKb1 66. Qd2 Ka1 67. Ke5 Kb1 68. Kd4 Ka1 69. Kc3 Kb1 70. Qb2#",
          "positional_tokens": {
            "prompt_tokens": 358,
            "completion_tokens": 585,
            "total_tokens": 943,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxc7",
            "Ra3",
            "Nxb5",
            "Rxb3",
            "Nd4",
            "Rxc3",
            "Rd6",
            "Nc4",
            "Rc6",
            "Rc1",
            "Ne2",
            "Rc2",
            "Nd4",
            "Rc1",
            "Kf2",
            "Ke7",
            "Ne3",
            "Kd7",
            "Rxc4",
            "Rxc4",
            "Nxc4",
            "Ke7",
            "Ke3",
            "Kf6",
            "Kf4",
            "g5+",
            "Kg4",
            "Kg6",
            "Ne5+",
            "Kf6",
            "Ndf3",
            "h6",
            "Kh5",
            "Kf5",
            "Kxh6",
            "g4",
            "Nxg4",
            "Kxg4",
            "Kg6",
            "Kf4",
            "h4",
            "Kg3",
            "h5",
            "Kxg2",
            "h6",
            "Kxf3",
            "h7",
            "Ke4",
            "h8=Q",
            "Kd5",
            "Qf6",
            "Ke4",
            "Qf5+",
            "Kd4",
            "Kf6",
            "Kc4",
            "Qe5",
            "Kd3",
            "Qf4",
            "Kc3",
            "Qe4",
            "Kd2",
            "Qf3",
            "Kc2",
            "Qe3",
            "Kb2",
            "Qd3",
            "Ka2",
            "Qc3",
            "Kb1",
            "Qd2",
            "Ka1",
            "Ke5",
            "Kb1",
            "Kd4",
            "Ka1",
            "Kc3",
            "Kb1",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxa2",
          "neutral_uci": "e2a2",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rxc3 34. Rd6 Nc4 35. Rc6 Rc1 36. Ne2 Rc2 37. Nd4 Rc1 38. Kf2 Ke7 39. Ne3\nKd7 40. Rxc4 Rxc4 41. Nxc4 Ke7 42. Ke3 Kf6 43. Kf4 g5+ 44. Kg4 Kg6 45. Ne5+ Kf6\n46. Ndf3 h6 47. Kh5 Kf5 48. Kxh6 g4 49. Nxg4 Kxg4 50. Kg6 Kf4 51. h4 Kg3 52. h5\nKxg2 53. h6 Kxf3 54. h7 Ke4 55. h8=Q Kd5 56. Qf6 Ke4 57. Qf5+ Kd4 58. Kf6 Kc4\n59. Qe5 Kd3 60. Qf4 Kc3 61. Qe4 Kd2 62. Qf3 Kc2 63. Qe3 Kb2 64. Qd3 Ka2 65. Qc3\nKb1 66. Qd2 Ka1 67. Ke5 Kb1 68. Kd4 Ka1 69. Kc3 Kb1 70. Qb2#",
          "neutral_tokens": {
            "prompt_tokens": 357,
            "completion_tokens": 585,
            "total_tokens": 942,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxc7",
            "Ra3",
            "Nxb5",
            "Rxb3",
            "Nd4",
            "Rxc3",
            "Rd6",
            "Nc4",
            "Rc6",
            "Rc1",
            "Ne2",
            "Rc2",
            "Nd4",
            "Rc1",
            "Kf2",
            "Ke7",
            "Ne3",
            "Kd7",
            "Rxc4",
            "Rxc4",
            "Nxc4",
            "Ke7",
            "Ke3",
            "Kf6",
            "Kf4",
            "g5+",
            "Kg4",
            "Kg6",
            "Ne5+",
            "Kf6",
            "Ndf3",
            "h6",
            "Kh5",
            "Kf5",
            "Kxh6",
            "g4",
            "Nxg4",
            "Kxg4",
            "Kg6",
            "Kf4",
            "h4",
            "Kg3",
            "h5",
            "Kxg2",
            "h6",
            "Kxf3",
            "h7",
            "Ke4",
            "h8=Q",
            "Kd5",
            "Qf6",
            "Ke4",
            "Qf5+",
            "Kd4",
            "Kf6",
            "Kc4",
            "Qe5",
            "Kd3",
            "Qf4",
            "Kc3",
            "Qe4",
            "Kd2",
            "Qf3",
            "Kc2",
            "Qe3",
            "Kb2",
            "Qd3",
            "Ka2",
            "Qc3",
            "Kb1",
            "Qd2",
            "Ka1",
            "Ke5",
            "Kb1",
            "Kd4",
            "Ka1",
            "Kc3",
            "Kb1",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2a2",
          "positional_uci": "e2a2",
          "neutral_uci": "e2a2",
          "consensus_move": "e2a2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxc7",
              "Ra3",
              "Nxb5",
              "Rxb3",
              "Nd4",
              "Rxc3",
              "Rd6",
              "Nc4",
              "Rc6",
              "Rc1",
              "Ne2",
              "Rc2",
              "Nd4",
              "Rc1",
              "Kf2",
              "Ke7",
              "Ne3",
              "Kd7",
              "Rxc4",
              "Rxc4",
              "Nxc4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxc7",
              "Ra3",
              "Nxb5",
              "Rxb3",
              "Nd4",
              "Rxc3",
              "Rd6",
              "Nc4",
              "Rc6",
              "Rc1",
              "Ne2",
              "Rc2",
              "Nd4",
              "Rc1",
              "Kf2",
              "Ke7",
              "Ne3",
              "Kd7",
              "Rxc4",
              "Rxc4",
              "Nxc4",
              "Ke7",
              "Ke3",
              "Kf6",
              "Kf4",
              "g5+",
              "Kg4",
              "Kg6",
              "Ne5+",
              "Kf6",
              "Ndf3",
              "h6",
              "Kh5",
              "Kf5",
              "Kxh6",
              "g4",
              "Nxg4",
              "Kxg4",
              "Kg6",
              "Kf4",
              "h4",
              "Kg3",
              "h5",
              "Kxg2",
              "h6",
              "Kxf3",
              "h7",
              "Ke4",
              "h8=Q",
              "Kd5",
              "Qf6",
              "Ke4",
              "Qf5+",
              "Kd4",
              "Kf6",
              "Kc4",
              "Qe5",
              "Kd3",
              "Qf4",
              "Kc3",
              "Qe4",
              "Kd2",
              "Qf3",
              "Kc2",
              "Qe3",
              "Kb2",
              "Qd3",
              "Ka2",
              "Qc3",
              "Kb1",
              "Qd2",
              "Ka1",
              "Ke5",
              "Kb1",
              "Kd4",
              "Ka1",
              "Kc3",
              "Kb1",
              "Qb2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxc7",
              "Ra3",
              "Nxb5",
              "Rxb3",
              "Nd4",
              "Rxc3",
              "Rd6",
              "Nc4",
              "Rc6",
              "Rc1",
              "Ne2",
              "Rc2",
              "Nd4",
              "Rc1",
              "Kf2",
              "Ke7",
              "Ne3",
              "Kd7",
              "Rxc4",
              "Rxc4",
              "Nxc4",
              "Ke7",
              "Ke3",
              "Kf6",
              "Kf4",
              "g5+",
              "Kg4",
              "Kg6",
              "Ne5+",
              "Kf6",
              "Ndf3",
              "h6",
              "Kh5",
              "Kf5",
              "Kxh6",
              "g4",
              "Nxg4",
              "Kxg4",
              "Kg6",
              "Kf4",
              "h4",
              "Kg3",
              "h5",
              "Kxg2",
              "h6",
              "Kxf3",
              "h7",
              "Ke4",
              "h8=Q",
              "Kd5",
              "Qf6",
              "Ke4",
              "Qf5+",
              "Kd4",
              "Kf6",
              "Kc4",
              "Qe5",
              "Kd3",
              "Qf4",
              "Kc3",
              "Qe4",
              "Kd2",
              "Qf3",
              "Kc2",
              "Qe3",
              "Kb2",
              "Qd3",
              "Ka2",
              "Qc3",
              "Kb1",
              "Qd2",
              "Ka1",
              "Ke5",
              "Kb1",
              "Kd4",
              "Ka1",
              "Kc3",
              "Kb1",
              "Qb2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 358,
            "completion_tokens": 339,
            "total_tokens": 697,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 358,
            "completion_tokens": 585,
            "total_tokens": 943,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 357,
            "completion_tokens": 585,
            "total_tokens": 942,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1073,
          "total_completion_tokens": 1509,
          "total_tokens": 2582
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 59,
            "turn_number": 30,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 358,
            "completion_tokens": 339,
            "total_tokens": 697,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 59,
            "turn_number": 30,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 358,
            "completion_tokens": 585,
            "total_tokens": 943,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 59,
            "turn_number": 30,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 357,
            "completion_tokens": 585,
            "total_tokens": 942,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3R4/2p2kpp/Nn6/1p6/8/1PP5/P3r1PP/5NK1 b - - 0 30"
    },
    {
      "turn": 62,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ra3",
          "aggressive_uci": "a2a3",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3 33. Nd4 Rxc3 34. Rd6 Nc4 35. Rc6 Rc1 36. Ne2 Rc2 37. Nd4 Rc1 38. Kf2 Ke7 39. Ne3 Kd7 40. Rxc4 Rxc4 41. Nxc4 Ke7 42. Ke3 Kf6 43. Kf4 g5+ 44. Ke4 h5 45. Ne3 Kg6 46. Ke5 g4 47. Kf4 Kh6 48. Kf5 Kg7 49. Kg5 Kh7 50. Kxh5 Kg7 51. Kxg4 Kh7 52. Kg5 Kg7 53. h4 Kh7 54. h5 Kg7 55. h6+ Kh7 56. Kh5 Kg8 57. Kg6 Kh8 58. Nef5 Kg8 59. Nd6 Kh8 60. Nf7+ Kg8 61. h7+ Kf8 62. h8=Q+ Ke7 63. Qd8#",
          "aggressive_tokens": {
            "prompt_tokens": 367,
            "completion_tokens": 511,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxb5",
            "Rxb3",
            "Nd4",
            "Rxc3",
            "Rd6",
            "Nc4",
            "Rc6",
            "Rc1",
            "Ne2",
            "Rc2",
            "Nd4",
            "Rc1",
            "Kf2",
            "Ke7",
            "Ne3",
            "Kd7",
            "Rxc4",
            "Rxc4",
            "Nxc4",
            "Ke7",
            "Ke3",
            "Kf6",
            "Kf4",
            "g5+",
            "Ke4",
            "h5",
            "Ne3",
            "Kg6",
            "Ke5",
            "g4",
            "Kf4",
            "Kh6",
            "Kf5",
            "Kg7",
            "Kg5",
            "Kh7",
            "Kxh5",
            "Kg7",
            "Kxg4",
            "Kh7",
            "Kg5",
            "Kg7",
            "h4",
            "Kh7",
            "h5",
            "Kg7",
            "h6+",
            "Kh7",
            "Kh5",
            "Kg8",
            "Kg6",
            "Kh8",
            "Nef5",
            "Kg8",
            "Nd6",
            "Kh8",
            "Nf7+",
            "Kg8",
            "h7+",
            "Kf8",
            "h8=Q+",
            "Ke7",
            "Qd8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ra3",
          "positional_uci": "a2a3",
          "positional_response": "Repeating moves\n31... Ra3 32. Nxb5 Rxb3 33. Nxc7 Rxc3 34. Nd5 Nxd5 35. Rxd5 Rc7 36. Kf2 Re7 37.\nNe3 g6 38. Kf3 Kg7 39. Rd6 Rf7+ 40. Ke4 Re7+ 41. Kd4 Rf7 42. Nd5 Rf2 43. Ne3\nRf7 44. Ke5 Re7+ 45. Re6 Rf7 46. Nd5 Rf2 47. Re7+ Kh6 48. Nf6 Rxg2 49. Rxh7+\nKg5 50. Ne4+ Kg4 51. h3+ Kf3 52. Rf7+ Ke3 53. Rf6 Rh2 54. Ng5 Rg2 55. Rxg6\nRh2 56. Kf5 Rf2+ 57. Kg4 Rg2+ 58. Kh4 Kf4 59. Ne6+ Kf3 60. Rxg2 Kxg2 61. Kg4\nKf2 62. h4 Ke3 63. h5 Ke4 64. h6 Ke5 65. h7 Kxe6 66. h8=Q Kd5 67. Qe8 Kd6\n68. Kf5 Kd5 69. Qd7+ Kc4 70. Ke4 Kc5 71. Qc7+ Kb4 72. Kd4 Kb5 73. Qb7+ Ka4\n74. Kc4 Ka3 75. Qb3# Repeating moves 75... Ka2 76. Kc3+ Ka1 77. Qb2#",
          "positional_tokens": {
            "prompt_tokens": 367,
            "completion_tokens": 405,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxb5",
            "Rxb3",
            "Nxc7",
            "Rxc3",
            "Nd5",
            "Nxd5",
            "Rxd5",
            "Rc7",
            "Kf2",
            "Re7",
            "Ne3",
            "g6",
            "Kf3",
            "Kg7",
            "Rd6",
            "Rf7+",
            "Ke4",
            "Re7+",
            "Kd4",
            "Rf7",
            "Nd5",
            "Rf2",
            "Ne3",
            "Rf7",
            "Ke5",
            "Re7+",
            "Re6",
            "Rf7",
            "Nd5",
            "Rf2",
            "Re7+",
            "Kh6",
            "Nf6",
            "Rxg2",
            "Rxh7+",
            "Kg5",
            "Ne4+",
            "Kg4",
            "h3+",
            "Kf3",
            "Rf7+",
            "Ke3",
            "Rf6",
            "Rh2",
            "Ng5",
            "Rg2",
            "Rxg6",
            "Rh2",
            "Kf5",
            "Rf2+",
            "Kg4",
            "Rg2+",
            "Kh4",
            "Kf4",
            "Ne6+",
            "Kf3",
            "Rxg2",
            "Kxg2",
            "Kg4",
            "Kf2",
            "h4",
            "Ke3",
            "h5",
            "Ke4",
            "h6",
            "Ke5",
            "h7",
            "Kxe6",
            "h8=Q",
            "Kd5",
            "Qe8",
            "Kd6",
            "Kf5",
            "Kd5",
            "Qd7+",
            "Kc4",
            "Ke4",
            "Kc5",
            "Qc7+",
            "Kb4",
            "Kd4",
            "Kb5",
            "Qb7+",
            "Ka4",
            "Kc4",
            "Ka3",
            "Qb3#",
            "Ka2",
            "Kc3+",
            "Ka1",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ra3",
          "neutral_uci": "a2a3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3 33. Nd4 Rxc3 34. Rd6 Nc4 35. Rc6 Rc1 36. Kf2 Ke7 37. Ne3 Nxe3 38. Kxe3 Rxc6 39. Nxc6+ Kd6 40. Nd4 Ke5 41. Nf3+ Kf5 42. h3 h5 43. g3 g5 44. Nd4+ Ke5 45. Nc6+ Kf5 46. Kd4 h4 47. g4+ Kf4 48. Ne5 Kg3 49. Ke4 Kxh3 50. Kf3 Kh2 51. Nf7 Kg1 52. Nxg5 Kh2 53. Kf4 Kg2 54. Nf3 h3 55. g5 h2 56. Nxh2 Kxh2 57. g6 Kh3 58. g7 Kh4 59. g8=Q Kh5 60. Qg5# e5 e6 e7 e8=Q+ Kf7 Qe7+ Kf8 Qe8+ Kf7 Qe7+ Kf8 Qe8+ Kf7 Qe7+ Kf8 Qe8+ Kf7 Qe7+ Kf8 Qe8+ Kf7 Qe7+ Kf8 Qe8+ Kf7 Qe7+ Kf8 Qe8+ Kf7 Qe7+ Kf8 Qe8+ Kf7 Qe7+ Kf8 Qe8+ Kf7 Qe7+ Kf8 Qe8+ Kf7 Qe7+",
          "neutral_tokens": {
            "prompt_tokens": 366,
            "completion_tokens": 640,
            "total_tokens": 1006,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxb5",
            "Rxb3",
            "Nd4",
            "Rxc3",
            "Rd6",
            "Nc4",
            "Rc6",
            "Rc1",
            "Kf2",
            "Ke7",
            "Ne3",
            "Nxe3",
            "Kxe3",
            "Rxc6",
            "Nxc6+",
            "Kd6",
            "Nd4",
            "Ke5",
            "Nf3+",
            "Kf5",
            "h3",
            "h5",
            "g3",
            "g5",
            "Nd4+",
            "Ke5",
            "Nc6+",
            "Kf5",
            "Kd4",
            "h4",
            "g4+",
            "Kf4",
            "Ne5",
            "Kg3",
            "Ke4",
            "Kxh3",
            "Kf3",
            "Kh2",
            "Nf7",
            "Kg1",
            "Nxg5",
            "Kh2",
            "Kf4",
            "Kg2",
            "Nf3",
            "h3",
            "g5",
            "h2",
            "Nxh2",
            "Kxh2",
            "g6",
            "Kh3",
            "g7",
            "Kh4",
            "g8=Q",
            "Kh5",
            "Qg5#",
            "e5",
            "e6",
            "e7",
            "e8=Q+",
            "Kf7",
            "Qe7+",
            "Kf8",
            "Qe8+",
            "Kf7",
            "Qe7+",
            "Kf8",
            "Qe8+",
            "Kf7",
            "Qe7+",
            "Kf8",
            "Qe8+",
            "Kf7",
            "Qe7+",
            "Kf8",
            "Qe8+",
            "Kf7",
            "Qe7+",
            "Kf8",
            "Qe8+",
            "Kf7",
            "Qe7+",
            "Kf8",
            "Qe8+",
            "Kf7",
            "Qe7+",
            "Kf8",
            "Qe8+",
            "Kf7",
            "Qe7+",
            "Kf8",
            "Qe8+",
            "Kf7",
            "Qe7+",
            "Kf8",
            "Qe8+",
            "Kf7",
            "Qe7+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a2a3",
          "positional_uci": "a2a3",
          "neutral_uci": "a2a3",
          "consensus_move": "a2a3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxb5",
              "Rxb3",
              "Nd4",
              "Rxc3",
              "Rd6",
              "Nc4",
              "Rc6",
              "Rc1",
              "Ne2",
              "Rc2",
              "Nd4",
              "Rc1",
              "Kf2",
              "Ke7",
              "Ne3",
              "Kd7",
              "Rxc4",
              "Rxc4",
              "Nxc4",
              "Ke7",
              "Ke3",
              "Kf6",
              "Kf4",
              "g5+",
              "Ke4",
              "h5",
              "Ne3",
              "Kg6",
              "Ke5",
              "g4",
              "Kf4",
              "Kh6",
              "Kf5",
              "Kg7",
              "Kg5",
              "Kh7",
              "Kxh5",
              "Kg7",
              "Kxg4",
              "Kh7",
              "Kg5",
              "Kg7",
              "h4",
              "Kh7",
              "h5",
              "Kg7",
              "h6+",
              "Kh7",
              "Kh5",
              "Kg8",
              "Kg6",
              "Kh8",
              "Nef5",
              "Kg8",
              "Nd6",
              "Kh8",
              "Nf7+",
              "Kg8",
              "h7+",
              "Kf8",
              "h8=Q+",
              "Ke7",
              "Qd8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxb5",
              "Rxb3",
              "Nxc7",
              "Rxc3",
              "Nd5",
              "Nxd5",
              "Rxd5",
              "Rc7",
              "Kf2",
              "Re7",
              "Ne3",
              "g6",
              "Kf3",
              "Kg7",
              "Rd6",
              "Rf7+",
              "Ke4",
              "Re7+",
              "Kd4",
              "Rf7",
              "Nd5",
              "Rf2",
              "Ne3",
              "Rf7",
              "Ke5",
              "Re7+",
              "Re6",
              "Rf7",
              "Nd5",
              "Rf2",
              "Re7+",
              "Kh6",
              "Nf6",
              "Rxg2",
              "Rxh7+",
              "Kg5",
              "Ne4+",
              "Kg4",
              "h3+",
              "Kf3",
              "Rf7+",
              "Ke3",
              "Rf6",
              "Rh2",
              "Ng5",
              "Rg2",
              "Rxg6",
              "Rh2",
              "Kf5",
              "Rf2+",
              "Kg4",
              "Rg2+",
              "Kh4",
              "Kf4",
              "Ne6+",
              "Kf3",
              "Rxg2",
              "Kxg2",
              "Kg4",
              "Kf2",
              "h4",
              "Ke3",
              "h5",
              "Ke4",
              "h6",
              "Ke5",
              "h7",
              "Kxe6",
              "h8=Q",
              "Kd5",
              "Qe8",
              "Kd6",
              "Kf5",
              "Kd5",
              "Qd7+",
              "Kc4",
              "Ke4",
              "Kc5",
              "Qc7+",
              "Kb4",
              "Kd4",
              "Kb5",
              "Qb7+",
              "Ka4",
              "Kc4",
              "Ka3",
              "Qb3#",
              "Ka2",
              "Kc3+",
              "Ka1",
              "Qb2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxb5",
              "Rxb3",
              "Nd4",
              "Rxc3",
              "Rd6",
              "Nc4",
              "Rc6",
              "Rc1",
              "Kf2",
              "Ke7",
              "Ne3",
              "Nxe3",
              "Kxe3",
              "Rxc6",
              "Nxc6+",
              "Kd6",
              "Nd4",
              "Ke5",
              "Nf3+",
              "Kf5",
              "h3",
              "h5",
              "g3",
              "g5",
              "Nd4+",
              "Ke5",
              "Nc6+",
              "Kf5",
              "Kd4",
              "h4",
              "g4+",
              "Kf4",
              "Ne5",
              "Kg3",
              "Ke4",
              "Kxh3",
              "Kf3",
              "Kh2",
              "Nf7",
              "Kg1",
              "Nxg5",
              "Kh2",
              "Kf4",
              "Kg2",
              "Nf3",
              "h3",
              "g5",
              "h2",
              "Nxh2",
              "Kxh2",
              "g6",
              "Kh3",
              "g7",
              "Kh4",
              "g8=Q",
              "Kh5",
              "Qg5#",
              "e5",
              "e6",
              "e7",
              "e8=Q+",
              "Kf7",
              "Qe7+",
              "Kf8",
              "Qe8+",
              "Kf7",
              "Qe7+",
              "Kf8",
              "Qe8+",
              "Kf7",
              "Qe7+",
              "Kf8",
              "Qe8+",
              "Kf7",
              "Qe7+",
              "Kf8",
              "Qe8+",
              "Kf7",
              "Qe7+",
              "Kf8",
              "Qe8+",
              "Kf7",
              "Qe7+",
              "Kf8",
              "Qe8+",
              "Kf7",
              "Qe7+",
              "Kf8",
              "Qe8+",
              "Kf7",
              "Qe7+",
              "Kf8",
              "Qe8+",
              "Kf7",
              "Qe7+",
              "Kf8",
              "Qe8+",
              "Kf7",
              "Qe7+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 367,
            "completion_tokens": 511,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 367,
            "completion_tokens": 405,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 366,
            "completion_tokens": 640,
            "total_tokens": 1006,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1100,
          "total_completion_tokens": 1556,
          "total_tokens": 2656
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 61,
            "turn_number": 31,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 367,
            "completion_tokens": 511,
            "total_tokens": 878,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 61,
            "turn_number": 31,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 367,
            "completion_tokens": 405,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 61,
            "turn_number": 31,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 366,
            "completion_tokens": 640,
            "total_tokens": 1006,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "3R4/2N2kpp/1n6/1p6/8/1PP5/r5PP/5NK1 b - - 0 31"
    },
    {
      "turn": 64,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxb3",
          "aggressive_uci": "a3b3",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3 33. Nd4 Rxc3",
          "aggressive_tokens": {
            "prompt_tokens": 375,
            "completion_tokens": 277,
            "total_tokens": 652,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd4",
            "Rxc3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxb3",
          "positional_uci": "a3b3",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rxc3 34. Rd6 Nc4 35. Rc6 Rc1 36. Ne2 Rc2 37. Nd4 Rc1 38. Kf2 Ke7 39. Ne3\nKd7 40. Rxc4 Rxc4 41. Nxc4 *",
          "positional_tokens": {
            "prompt_tokens": 375,
            "completion_tokens": 339,
            "total_tokens": 714,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nd4",
            "Rxc3",
            "Rd6",
            "Nc4",
            "Rc6",
            "Rc1",
            "Ne2",
            "Rc2",
            "Nd4",
            "Rc1",
            "Kf2",
            "Ke7",
            "Ne3",
            "Kd7",
            "Rxc4",
            "Rxc4",
            "Nxc4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxb3",
          "neutral_uci": "a3b3",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3 33. Nd4 Rxc3 34. Rb8 Nd5 35. Rb7+ Kg6 36. Rd7 Nf6 37. Rd6 Kf7 38. Rc6 Rd3 39. Nf3 Rd1 40. Ne5+ Ke7 41. Rc7+ Kd6 42. Rxg7 Kxe5 43. Re7+ Kf5 44. Re2 Kg6 45. Kf2 Ng4+ 46. Kg3 Nf6 47. Ne3 Rd3 48. Kf2 Ne4+ 49. Kf3 Ng5+ 50. Kf2 Ne4+ 51. Kf3 Ng5+ 52. Kf2 Ne4+ 53. Kf3 Ng5+ 54. Kf2 Ne4+ 55. Kf3 Ng5+ 56. Kf2 Ne4+ 57. Kf3 Ng5+ 58. Kf2 Ne4+ 59. Kf3 Ng5+ 60. Kf2 Ne4+ 61. Kf3 Ng5+ 62. Kf2 Ne4+ 63. Kf3 Ng5+ 64. Kf2 Ne4+ 65. Kf3 Ng5+ 66. Kf2 Ne4+ 67. Kf3 Ng5+ 68. Kf2 Ne4+ 69. Kf3 Ng5+ 70. Kf2 Ne4+ 71. Kf3 Ng5+ 72. Kf2 Ne4+ 73. Kf3 Ng5+ 74. Kf2 Ne4+ 75. Kf3",
          "neutral_tokens": {
            "prompt_tokens": 374,
            "completion_tokens": 640,
            "total_tokens": 1014,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nd4",
            "Rxc3",
            "Rb8",
            "Nd5",
            "Rb7+",
            "Kg6",
            "Rd7",
            "Nf6",
            "Rd6",
            "Kf7",
            "Rc6",
            "Rd3",
            "Nf3",
            "Rd1",
            "Ne5+",
            "Ke7",
            "Rc7+",
            "Kd6",
            "Rxg7",
            "Kxe5",
            "Re7+",
            "Kf5",
            "Re2",
            "Kg6",
            "Kf2",
            "Ng4+",
            "Kg3",
            "Nf6",
            "Ne3",
            "Rd3",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3",
            "Ng5+",
            "Kf2",
            "Ne4+",
            "Kf3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a3b3",
          "positional_uci": "a3b3",
          "neutral_uci": "a3b3",
          "consensus_move": "a3b3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nd4",
              "Rxc3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nd4",
              "Rxc3",
              "Rd6",
              "Nc4",
              "Rc6",
              "Rc1",
              "Ne2",
              "Rc2",
              "Nd4",
              "Rc1",
              "Kf2",
              "Ke7",
              "Ne3",
              "Kd7",
              "Rxc4",
              "Rxc4",
              "Nxc4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nd4",
              "Rxc3",
              "Rb8",
              "Nd5",
              "Rb7+",
              "Kg6",
              "Rd7",
              "Nf6",
              "Rd6",
              "Kf7",
              "Rc6",
              "Rd3",
              "Nf3",
              "Rd1",
              "Ne5+",
              "Ke7",
              "Rc7+",
              "Kd6",
              "Rxg7",
              "Kxe5",
              "Re7+",
              "Kf5",
              "Re2",
              "Kg6",
              "Kf2",
              "Ng4+",
              "Kg3",
              "Nf6",
              "Ne3",
              "Rd3",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3",
              "Ng5+",
              "Kf2",
              "Ne4+",
              "Kf3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 375,
            "completion_tokens": 277,
            "total_tokens": 652,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 375,
            "completion_tokens": 339,
            "total_tokens": 714,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 374,
            "completion_tokens": 640,
            "total_tokens": 1014,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1124,
          "total_completion_tokens": 1256,
          "total_tokens": 2380
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 63,
            "turn_number": 32,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 375,
            "completion_tokens": 277,
            "total_tokens": 652,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 63,
            "turn_number": 32,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 375,
            "completion_tokens": 339,
            "total_tokens": 714,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 63,
            "turn_number": 32,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 374,
            "completion_tokens": 640,
            "total_tokens": 1014,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "3R4/5kpp/1n6/1N6/8/rPP5/6PP/5NK1 b - - 0 32"
    },
    {
      "turn": 66,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc3",
          "aggressive_uci": "b3c3",
          "aggressive_response": "33... Rxc3 34. Nxc3 Nc4 35. Rd7+ Kf6 36. Nd5+ Ke5 37. Nf3+ Ke6 38. Rd8 h6 39. Nf4+ Kf5 40. Rf8+ Ke4 41. Kf2 g5 42. Re8+ Kxf4 43. g3+ Kf5 44. Nd4+ Kf6 45. Re6+ Kg7 46. Nf5+ Kf7 47. Rxh6 Ne5 48. Nd6+ Kg7 49. Re6 Ng4+ 50. Kg2 Nf6 51. Ne8+ Nxe8 52. Rxe8 Kf7 53. Re5 Kf6 54. Ra5 Kg6 55. Kf3 Kh5 56. h3 Kg6 57. Kg4 Kf6 58. Rxg5 Ke6 59. h4 Kf6 60. h5 Kf7 61. h6 Kf6 62. h7 Kf7 63. h8=Q Ke6 64. Qh6+ Kf7 65. Rg7+ Kf8 66. Qh8#",
          "aggressive_tokens": {
            "prompt_tokens": 383,
            "completion_tokens": 284,
            "total_tokens": 667,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxc3",
            "Nc4",
            "Rd7+",
            "Kf6",
            "Nd5+",
            "Ke5",
            "Nf3+",
            "Ke6",
            "Rd8",
            "h6",
            "Nf4+",
            "Kf5",
            "Rf8+",
            "Ke4",
            "Kf2",
            "g5",
            "Re8+",
            "Kxf4",
            "g3+",
            "Kf5",
            "Nd4+",
            "Kf6",
            "Re6+",
            "Kg7",
            "Nf5+",
            "Kf7",
            "Rxh6",
            "Ne5",
            "Nd6+",
            "Kg7",
            "Re6",
            "Ng4+",
            "Kg2",
            "Nf6",
            "Ne8+",
            "Nxe8",
            "Rxe8",
            "Kf7",
            "Re5",
            "Kf6",
            "Ra5",
            "Kg6",
            "Kf3",
            "Kh5",
            "h3",
            "Kg6",
            "Kg4",
            "Kf6",
            "Rxg5",
            "Ke6",
            "h4",
            "Kf6",
            "h5",
            "Kf7",
            "h6",
            "Kf6",
            "h7",
            "Kf7",
            "h8=Q",
            "Ke6",
            "Qh6+",
            "Kf7",
            "Rg7+",
            "Kf8",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re2",
          "positional_uci": null,
          "positional_response": "Re2 34. Nxe2 Ke7 35. Rb8 Nd7 36. Rb7 Kd6 37. Rxd7+ Kxd7 38. Kf2 Kd6\n39. Ke3 Kd5 40. Kd3 Kc5 41. Ne3 Kd6 42. Kd4 Kc6 43. c4 Kd6 44. c5+ Kc6 45. Kc4\nKc7 46. Kd5 Kd7 47. c6+ Kc7 48. Kc5 Kc8 49. Kd6 Kd8 50. c7+ Kc8 51. Kc6 g5\n52. Nd5 g4 53. Nb6# g3 54. Nd4 gxh2 55. Nf5 h1=Q 56. Nd6# g3 57. Nd5# g2\n58. Nb6# g1=Q 59. Nd5# g2 60. Nb6# g1=Q 61. Nd5# g2 62. Nb6# g1=Q 63. Nd5# g2\n64. Nb6# g1=Q 65. Nd5# g2 66. Nb6# g1=Q 67. Nd5# g2 68. Nb6# g1=Q 69. Nd5# g2\n70. Nb6# g1=Q 71. Nd5# g2 72. Nb6# g1=Q 73. Nd5# g2 74. Nb6# g1=Q 75. Nd5# g2\n76. Nb6# g1=Q 77. Nd5# g2 78. Nb6# g1=Q 79. Nd5# g2 80. Nb6# g1=Q 81. Nd5# g2\n82. Nb6# g1=Q 83. Nd5# g2 84. Nb6# g1=Q 85. Nd5# g2 86. Nb6# g1=Q 87. Nd5# g2\n88. Nb6# g1=Q 89. Nd5# g2 90. Nb6# g1=Q 91. Nd5# g2 92. Nb6# g1=Q 93. Nd5# g2\n94. Nb6# g1=Q 95. Nd5# g2 96. Nb6# g1=Q 97. Nd5# g2 98. Nb6# g1=Q 99. Nd5# g2\n100. Nb6# g1=Q 101. Nd5# g2 102. Nb6# g1=Q 103. Nd5# g2 104. Nb6# g1=Q 105. Nd5# g",
          "positional_tokens": {
            "prompt_tokens": 383,
            "completion_tokens": 640,
            "total_tokens": 1023,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxe2",
            "Ke7",
            "Rb8",
            "Nd7",
            "Rb7",
            "Kd6",
            "Rxd7+",
            "Kxd7",
            "Kf2",
            "Kd6",
            "Ke3",
            "Kd5",
            "Kd3",
            "Kc5",
            "Ne3",
            "Kd6",
            "Kd4",
            "Kc6",
            "c4",
            "Kd6",
            "c5+",
            "Kc6",
            "Kc4",
            "Kc7",
            "Kd5",
            "Kd7",
            "c6+",
            "Kc7",
            "Kc5",
            "Kc8",
            "Kd6",
            "Kd8",
            "c7+",
            "Kc8",
            "Kc6",
            "g5",
            "Nd5",
            "g4",
            "Nb6#",
            "g3",
            "Nd4",
            "gxh2",
            "Nf5",
            "h1=Q",
            "Nd6#",
            "g3",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#",
            "g2",
            "Nb6#",
            "g1=Q",
            "Nd5#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rb2",
          "neutral_uci": "b3b2",
          "neutral_response": "Re2 Rb2 35. Rb8 Nc4 36. Rxb2 Nxb2 37. Kf2 Nd1+ 38. Kf3 Nxc3 39. Ne3\nKf6 40. Ne2 Nb5 41. Ke4 Nd6+ 42. Kd5 Nf7 43. Ng3 g6 44. Ne4+ Ke7 45. Nc4 h6\n46. Ne5 Nxe5 47. Kxe5 Kf7 48. Nd6+ Kg7 49. Ke6 h5 50. h4 Kh6 51. Kf6 Kh7\n52. Nf7 g5 53. Nxg5+ Kh6 54. Ne6 Kh7 55. Kg5 Kg8 56. Kxh5 Kf7 57. Ng5+ Kg7\n58. g4 Kf6 59. Kh6 Ke7 60. Kg7 Kd6 61. h5 Ke5 62. h6 Kf4 63. h7 Kxg5\n64. h8=Q Kxg4 65. Qh6 Kf5 66. Qf6+ Ke4 67. Qg5 Kd4 68. Qf5 Kc4 69. Qe5 Kd3\n70. Qf4 Kc3 71. Qe4 Kd2 72. Qf3 Kc2 73. Qe3 Kb2 74. Qd3 Kc1 75. Qe2 Kb1\n76. Qd2 Ka1 77. Kf6 Kb1 78. Ke5 Ka1 79. Kd4 Kb1 80. Kc3 Ka1 81. Qb2# Kd1\n82. Qd2# Kxd2 83. Kxd2 * Kxd2 84. Kxd2 * Kd2 85. Kxd2 * Kd2 86. Kxd2 *",
          "neutral_tokens": {
            "prompt_tokens": 382,
            "completion_tokens": 444,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rb8",
            "Nc4",
            "Rxb2",
            "Nxb2",
            "Kf2",
            "Nd1+",
            "Kf3",
            "Nxc3",
            "Ne3",
            "Kf6",
            "Ne2",
            "Nb5",
            "Ke4",
            "Nd6+",
            "Kd5",
            "Nf7",
            "Ng3",
            "g6",
            "Ne4+",
            "Ke7",
            "Nc4",
            "h6",
            "Ne5",
            "Nxe5",
            "Kxe5",
            "Kf7",
            "Nd6+",
            "Kg7",
            "Ke6",
            "h5",
            "h4",
            "Kh6",
            "Kf6",
            "Kh7",
            "Nf7",
            "g5",
            "Nxg5+",
            "Kh6",
            "Ne6",
            "Kh7",
            "Kg5",
            "Kg8",
            "Kxh5",
            "Kf7",
            "Ng5+",
            "Kg7",
            "g4",
            "Kf6",
            "Kh6",
            "Ke7",
            "Kg7",
            "Kd6",
            "h5",
            "Ke5",
            "h6",
            "Kf4",
            "h7",
            "Kxg5",
            "h8=Q",
            "Kxg4",
            "Qh6",
            "Kf5",
            "Qf6+",
            "Ke4",
            "Qg5",
            "Kd4",
            "Qf5",
            "Kc4",
            "Qe5",
            "Kd3",
            "Qf4",
            "Kc3",
            "Qe4",
            "Kd2",
            "Qf3",
            "Kc2",
            "Qe3",
            "Kb2",
            "Qd3",
            "Kc1",
            "Qe2",
            "Kb1",
            "Qd2",
            "Ka1",
            "Kf6",
            "Kb1",
            "Ke5",
            "Ka1",
            "Kd4",
            "Kb1",
            "Kc3",
            "Ka1",
            "Qb2#",
            "Kd1",
            "Qd2#",
            "Kxd2",
            "Kxd2",
            "Kxd2",
            "Kxd2",
            "Kd2",
            "Kxd2",
            "Kd2",
            "Kxd2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b3c3",
          "positional_uci": null,
          "neutral_uci": "b3b2",
          "consensus_move": "b3b2",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nxc3",
              "Nc4",
              "Rd7+",
              "Kf6",
              "Nd5+",
              "Ke5",
              "Nf3+",
              "Ke6",
              "Rd8",
              "h6",
              "Nf4+",
              "Kf5",
              "Rf8+",
              "Ke4",
              "Kf2",
              "g5",
              "Re8+",
              "Kxf4",
              "g3+",
              "Kf5",
              "Nd4+",
              "Kf6",
              "Re6+",
              "Kg7",
              "Nf5+",
              "Kf7",
              "Rxh6",
              "Ne5",
              "Nd6+",
              "Kg7",
              "Re6",
              "Ng4+",
              "Kg2",
              "Nf6",
              "Ne8+",
              "Nxe8",
              "Rxe8",
              "Kf7",
              "Re5",
              "Kf6",
              "Ra5",
              "Kg6",
              "Kf3",
              "Kh5",
              "h3",
              "Kg6",
              "Kg4",
              "Kf6",
              "Rxg5",
              "Ke6",
              "h4",
              "Kf6",
              "h5",
              "Kf7",
              "h6",
              "Kf6",
              "h7",
              "Kf7",
              "h8=Q",
              "Ke6",
              "Qh6+",
              "Kf7",
              "Rg7+",
              "Kf8",
              "Qh8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxe2",
              "Ke7",
              "Rb8",
              "Nd7",
              "Rb7",
              "Kd6",
              "Rxd7+",
              "Kxd7",
              "Kf2",
              "Kd6",
              "Ke3",
              "Kd5",
              "Kd3",
              "Kc5",
              "Ne3",
              "Kd6",
              "Kd4",
              "Kc6",
              "c4",
              "Kd6",
              "c5+",
              "Kc6",
              "Kc4",
              "Kc7",
              "Kd5",
              "Kd7",
              "c6+",
              "Kc7",
              "Kc5",
              "Kc8",
              "Kd6",
              "Kd8",
              "c7+",
              "Kc8",
              "Kc6",
              "g5",
              "Nd5",
              "g4",
              "Nb6#",
              "g3",
              "Nd4",
              "gxh2",
              "Nf5",
              "h1=Q",
              "Nd6#",
              "g3",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#",
              "g2",
              "Nb6#",
              "g1=Q",
              "Nd5#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rb8",
              "Nc4",
              "Rxb2",
              "Nxb2",
              "Kf2",
              "Nd1+",
              "Kf3",
              "Nxc3",
              "Ne3",
              "Kf6",
              "Ne2",
              "Nb5",
              "Ke4",
              "Nd6+",
              "Kd5",
              "Nf7",
              "Ng3",
              "g6",
              "Ne4+",
              "Ke7",
              "Nc4",
              "h6",
              "Ne5",
              "Nxe5",
              "Kxe5",
              "Kf7",
              "Nd6+",
              "Kg7",
              "Ke6",
              "h5",
              "h4",
              "Kh6",
              "Kf6",
              "Kh7",
              "Nf7",
              "g5",
              "Nxg5+",
              "Kh6",
              "Ne6",
              "Kh7",
              "Kg5",
              "Kg8",
              "Kxh5",
              "Kf7",
              "Ng5+",
              "Kg7",
              "g4",
              "Kf6",
              "Kh6",
              "Ke7",
              "Kg7",
              "Kd6",
              "h5",
              "Ke5",
              "h6",
              "Kf4",
              "h7",
              "Kxg5",
              "h8=Q",
              "Kxg4",
              "Qh6",
              "Kf5",
              "Qf6+",
              "Ke4",
              "Qg5",
              "Kd4",
              "Qf5",
              "Kc4",
              "Qe5",
              "Kd3",
              "Qf4",
              "Kc3",
              "Qe4",
              "Kd2",
              "Qf3",
              "Kc2",
              "Qe3",
              "Kb2",
              "Qd3",
              "Kc1",
              "Qe2",
              "Kb1",
              "Qd2",
              "Ka1",
              "Kf6",
              "Kb1",
              "Ke5",
              "Ka1",
              "Kd4",
              "Kb1",
              "Kc3",
              "Ka1",
              "Qb2#",
              "Kd1",
              "Qd2#",
              "Kxd2",
              "Kxd2",
              "Kxd2",
              "Kxd2",
              "Kd2",
              "Kxd2",
              "Kd2",
              "Kxd2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 383,
            "completion_tokens": 284,
            "total_tokens": 667,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 383,
            "completion_tokens": 640,
            "total_tokens": 1023,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 382,
            "completion_tokens": 444,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1148,
          "total_completion_tokens": 1368,
          "total_tokens": 2516
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 65,
            "turn_number": 33,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 383,
            "completion_tokens": 284,
            "total_tokens": 667,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 65,
            "turn_number": 33,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 383,
            "completion_tokens": 640,
            "total_tokens": 1023,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 65,
            "turn_number": 33,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 382,
            "completion_tokens": 444,
            "total_tokens": 826,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "3R4/5kpp/1n6/8/3N4/1rP5/6PP/5NK1 b - - 1 33"
    },
    {
      "turn": 68,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kg6",
          "aggressive_uci": "f7g6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. Ne3 Kf6 36. Nd5+ Ke5 37. Rxb6 Rxb6 38. Nxb6 Ke4 39. Kf2 Kd3 40. Ne2 Ke4 41. c4 Ke5 42. c5 Ke6 43. c6 Kd6 44. Nd4 Kc7 45. Nd5+ Kd6 46. c7 Kd7 47. Nb5 Kc8 48. Nb6+ Kb7 49. c8=Q+ Kxb6 50. Nd4 Ka5 51. Qb7 Ka4 52. Qb5+ Ka3 53. Qb3#",
          "aggressive_tokens": {
            "prompt_tokens": 392,
            "completion_tokens": 439,
            "total_tokens": 831,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ne3",
            "Kf6",
            "Nd5+",
            "Ke5",
            "Rxb6",
            "Rxb6",
            "Nxb6",
            "Ke4",
            "Kf2",
            "Kd3",
            "Ne2",
            "Ke4",
            "c4",
            "Ke5",
            "c5",
            "Ke6",
            "c6",
            "Kd6",
            "Nd4",
            "Kc7",
            "Nd5+",
            "Kd6",
            "c7",
            "Kd7",
            "Nb5",
            "Kc8",
            "Nb6+",
            "Kb7",
            "c8=Q+",
            "Kxb6",
            "Nd4",
            "Ka5",
            "Qb7",
            "Ka4",
            "Qb5+",
            "Ka3",
            "Qb3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": "b6c4",
          "positional_response": "34... Nc4 35. Rxb2 Nxb2 36. Ne3 Na4 37. c4 Ke7 38. Kf2 Kd6 39. Ndf5+ Kc5 40. Nxg7 Nb6 41. Ne6+ Kd6 42. c5+ Kxe6 43. cxb6 Kd6 44. Nc4+ Kc6 45. Ke3 Kb7 46. Kd4 Kc6 47. g4 Kb7 48. Kc5 Kb8 49. Kc6 Kc8 50. b7+ Kb8 51. Kb6 h5 52. Ne5 hxg4 53. Nc6#",
          "positional_tokens": {
            "prompt_tokens": 392,
            "completion_tokens": 163,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kc6",
            "Ke3",
            "Kb7",
            "Kd4",
            "Kc6",
            "g4",
            "Kb7",
            "Kc5",
            "Kb8",
            "Kc6",
            "Kc8",
            "b7+",
            "Kb8",
            "Kb6",
            "h5",
            "Ne5",
            "hxg4",
            "Nc6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kg6",
          "neutral_uci": "f7g6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. Ne3 Kf6 36. Nc4 Nxc4 37. Rxb2 Nxb2 38. Kf2 Ke5 39. Ke3\nKd5 40. Nf5 g6 41. Ne7+ Kc4 42. Kd2 Na4 43. Ng8 Nxc3 44. Nf6 h6 45. Ng4 h5 46.\nNe5+ Kd4 47. Nxg6 Ne4+ 48. Ke2 Nf6 49. Kf3 Kd5 50. Kf4 Ke6 51. Kg5 Kf7 52. Nf4\nKg7 53. Nxh5+ Nxh5 54. Kxh5 Kh7 55. g4 Kg7 56. g5 Kh7 57. g6+ Kg7 58. Kg5 Kg8\n59. h4 Kg7 60. h5 Kg8 61. h6 Kh8 62. Kf6 Kg8 63. g7 Kh7 64. Kf7 Kxh6 65. g8=Q\nKh5 66. Qg3 Kh6 67. Qg6#",
          "neutral_tokens": {
            "prompt_tokens": 391,
            "completion_tokens": 556,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ne3",
            "Kf6",
            "Nc4",
            "Nxc4",
            "Rxb2",
            "Nxb2",
            "Kf2",
            "Ke5",
            "Ke3",
            "Kd5",
            "Nf5",
            "g6",
            "Ne7+",
            "Kc4",
            "Kd2",
            "Na4",
            "Ng8",
            "Nxc3",
            "Nf6",
            "h6",
            "Ng4",
            "h5",
            "Ne5+",
            "Kd4",
            "Nxg6",
            "Ne4+",
            "Ke2",
            "Nf6",
            "Kf3",
            "Kd5",
            "Kf4",
            "Ke6",
            "Kg5",
            "Kf7",
            "Nf4",
            "Kg7",
            "Nxh5+",
            "Nxh5",
            "Kxh5",
            "Kh7",
            "g4",
            "Kg7",
            "g5",
            "Kh7",
            "g6+",
            "Kg7",
            "Kg5",
            "Kg8",
            "h4",
            "Kg7",
            "h5",
            "Kg8",
            "h6",
            "Kh8",
            "Kf6",
            "Kg8",
            "g7",
            "Kh7",
            "Kf7",
            "Kxh6",
            "g8=Q",
            "Kh5",
            "Qg3",
            "Kh6",
            "Qg6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f7g6",
          "positional_uci": "b6c4",
          "neutral_uci": "f7g6",
          "consensus_move": "f7g6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ne3",
              "Kf6",
              "Nd5+",
              "Ke5",
              "Rxb6",
              "Rxb6",
              "Nxb6",
              "Ke4",
              "Kf2",
              "Kd3",
              "Ne2",
              "Ke4",
              "c4",
              "Ke5",
              "c5",
              "Ke6",
              "c6",
              "Kd6",
              "Nd4",
              "Kc7",
              "Nd5+",
              "Kd6",
              "c7",
              "Kd7",
              "Nb5",
              "Kc8",
              "Nb6+",
              "Kb7",
              "c8=Q+",
              "Kxb6",
              "Nd4",
              "Ka5",
              "Qb7",
              "Ka4",
              "Qb5+",
              "Ka3",
              "Qb3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kc6",
              "Ke3",
              "Kb7",
              "Kd4",
              "Kc6",
              "g4",
              "Kb7",
              "Kc5",
              "Kb8",
              "Kc6",
              "Kc8",
              "b7+",
              "Kb8",
              "Kb6",
              "h5",
              "Ne5",
              "hxg4",
              "Nc6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ne3",
              "Kf6",
              "Nc4",
              "Nxc4",
              "Rxb2",
              "Nxb2",
              "Kf2",
              "Ke5",
              "Ke3",
              "Kd5",
              "Nf5",
              "g6",
              "Ne7+",
              "Kc4",
              "Kd2",
              "Na4",
              "Ng8",
              "Nxc3",
              "Nf6",
              "h6",
              "Ng4",
              "h5",
              "Ne5+",
              "Kd4",
              "Nxg6",
              "Ne4+",
              "Ke2",
              "Nf6",
              "Kf3",
              "Kd5",
              "Kf4",
              "Ke6",
              "Kg5",
              "Kf7",
              "Nf4",
              "Kg7",
              "Nxh5+",
              "Nxh5",
              "Kxh5",
              "Kh7",
              "g4",
              "Kg7",
              "g5",
              "Kh7",
              "g6+",
              "Kg7",
              "Kg5",
              "Kg8",
              "h4",
              "Kg7",
              "h5",
              "Kg8",
              "h6",
              "Kh8",
              "Kf6",
              "Kg8",
              "g7",
              "Kh7",
              "Kf7",
              "Kxh6",
              "g8=Q",
              "Kh5",
              "Qg3",
              "Kh6",
              "Qg6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 392,
            "completion_tokens": 439,
            "total_tokens": 831,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 392,
            "completion_tokens": 163,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 391,
            "completion_tokens": 556,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1175,
          "total_completion_tokens": 1158,
          "total_tokens": 2333
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 67,
            "turn_number": 34,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 392,
            "completion_tokens": 439,
            "total_tokens": 831,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 67,
            "turn_number": 34,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 392,
            "completion_tokens": 163,
            "total_tokens": 555,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 67,
            "turn_number": 34,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 391,
            "completion_tokens": 556,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1R6/5kpp/1n6/8/3N4/2P5/1r4PP/5NK1 b - - 3 34"
    },
    {
      "turn": 70,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxc4",
          "aggressive_uci": "b6c4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Kf1 Ne5 39. Ke2 Kf6 40. Nf3 Nxf3 41. Kxf3 g5 42. Kg4 Kg6 43. Nf5 h5+ 44. Kf3 Kxf5 45. h3 g4+ 46. hxg4+ hxg4+ 47. Kg3 Kg5 48. Kf2 Kf4 49. g3+ Ke4 50. Kg2 Ke3 51. Kh2 Kf3 52. Kg1 Kxg3 53. Kh1 Kf2 54. Kh2 g3+ 55. Kh1 g2+ 56. Kh2 g1=Q+ 57. Kh3 Qg3# 0-1",
          "aggressive_tokens": {
            "prompt_tokens": 399,
            "completion_tokens": 481,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb2",
            "Nxb2",
            "Ne3",
            "Nd3",
            "Kf1",
            "Ne5",
            "Ke2",
            "Kf6",
            "Nf3",
            "Nxf3",
            "Kxf3",
            "g5",
            "Kg4",
            "Kg6",
            "Nf5",
            "h5+",
            "Kf3",
            "Kxf5",
            "h3",
            "g4+",
            "hxg4+",
            "hxg4+",
            "Kg3",
            "Kg5",
            "Kf2",
            "Kf4",
            "g3+",
            "Ke4",
            "Kg2",
            "Ke3",
            "Kh2",
            "Kf3",
            "Kg1",
            "Kxg3",
            "Kh1",
            "Kf2",
            "Kh2",
            "g3+",
            "Kh1",
            "g2+",
            "Kh2",
            "g1=Q+",
            "Kh3",
            "Qg3#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxc4",
          "positional_uci": "b6c4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Kf1 Kf6 39. Ke2 Ne5 40. Nf3 Nxf3 41. Kxf3 g5 42. Kg4 Kg6 43. Nd5 h5+ 44. Kf3 Kf5 45. Ne3+ Ke5 46. g3 Kf6 47. Ke4 Ke6 48. Nd5 h4 49. g4 Kf7 50. Kf5 Kg7 51. Kxg5 Kh7 52. Kxh4 Kg6 53. g5 Kh7 54. Kh5 Kg7 55. g6 Kh8 56. Kh6 Kg8 57. g7 Kf7 58. Kh7 Ke6 59. g8=Q+ Ke5 60. Kg6 Kd4 61. Kf5 Kc5 62. Ke5 Kc4 63. Qc8+ Kd3 64. Qc3+ Ke2 65. Ke4 Kf2 66. Qf3+ Kg1 67. Qe2 Kh1 68. Kf3 Kg1 69. Qg2#",
          "positional_tokens": {
            "prompt_tokens": 399,
            "completion_tokens": 567,
            "total_tokens": 966,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb2",
            "Nxb2",
            "Ne3",
            "Nd3",
            "Kf1",
            "Kf6",
            "Ke2",
            "Ne5",
            "Nf3",
            "Nxf3",
            "Kxf3",
            "g5",
            "Kg4",
            "Kg6",
            "Nd5",
            "h5+",
            "Kf3",
            "Kf5",
            "Ne3+",
            "Ke5",
            "g3",
            "Kf6",
            "Ke4",
            "Ke6",
            "Nd5",
            "h4",
            "g4",
            "Kf7",
            "Kf5",
            "Kg7",
            "Kxg5",
            "Kh7",
            "Kxh4",
            "Kg6",
            "g5",
            "Kh7",
            "Kh5",
            "Kg7",
            "g6",
            "Kh8",
            "Kh6",
            "Kg8",
            "g7",
            "Kf7",
            "Kh7",
            "Ke6",
            "g8=Q+",
            "Ke5",
            "Kg6",
            "Kd4",
            "Kf5",
            "Kc5",
            "Ke5",
            "Kc4",
            "Qc8+",
            "Kd3",
            "Qc3+",
            "Ke2",
            "Ke4",
            "Kf2",
            "Qf3+",
            "Kg1",
            "Qe2",
            "Kh1",
            "Kf3",
            "Kg1",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxc4",
          "neutral_uci": "b6c4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Kf1 Kf6 39. Ke2 Ne5 40. Nf3 Nxf3 41. Kxf3 Kg5 42. g3 h5 43. h4+ Kh6 44. Kf4 Kg6 45. Nf5 Kf6 46. Nd6 Kg6 47. Ke5 Kh6 48. Kf5 Kh7 49. Kg5 g6 50. Ne8 Kg8 51. Kxg6 Kf8 52. Nf6 Ke7 53. Nxh5 Kf8 54. Nf6 Ke7 55. h5 Kf8 56. h6 Ke7 57. h7 Kf8 58. h8=Q+ Ke7 59. Qe8+ Kd6 60. Qd7+ Ke5 61. Qd5#",
          "neutral_tokens": {
            "prompt_tokens": 398,
            "completion_tokens": 504,
            "total_tokens": 902,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxb2",
            "Nxb2",
            "Ne3",
            "Nd3",
            "Kf1",
            "Kf6",
            "Ke2",
            "Ne5",
            "Nf3",
            "Nxf3",
            "Kxf3",
            "Kg5",
            "g3",
            "h5",
            "h4+",
            "Kh6",
            "Kf4",
            "Kg6",
            "Nf5",
            "Kf6",
            "Nd6",
            "Kg6",
            "Ke5",
            "Kh6",
            "Kf5",
            "Kh7",
            "Kg5",
            "g6",
            "Ne8",
            "Kg8",
            "Kxg6",
            "Kf8",
            "Nf6",
            "Ke7",
            "Nxh5",
            "Kf8",
            "Nf6",
            "Ke7",
            "h5",
            "Kf8",
            "h6",
            "Ke7",
            "h7",
            "Kf8",
            "h8=Q+",
            "Ke7",
            "Qe8+",
            "Kd6",
            "Qd7+",
            "Ke5",
            "Qd5#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b6c4",
          "positional_uci": "b6c4",
          "neutral_uci": "b6c4",
          "consensus_move": "b6c4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxb2",
              "Nxb2",
              "Ne3",
              "Nd3",
              "Kf1",
              "Ne5",
              "Ke2",
              "Kf6",
              "Nf3",
              "Nxf3",
              "Kxf3",
              "g5",
              "Kg4",
              "Kg6",
              "Nf5",
              "h5+",
              "Kf3",
              "Kxf5",
              "h3",
              "g4+",
              "hxg4+",
              "hxg4+",
              "Kg3",
              "Kg5",
              "Kf2",
              "Kf4",
              "g3+",
              "Ke4",
              "Kg2",
              "Ke3",
              "Kh2",
              "Kf3",
              "Kg1",
              "Kxg3",
              "Kh1",
              "Kf2",
              "Kh2",
              "g3+",
              "Kh1",
              "g2+",
              "Kh2",
              "g1=Q+",
              "Kh3",
              "Qg3#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxb2",
              "Nxb2",
              "Ne3",
              "Nd3",
              "Kf1",
              "Kf6",
              "Ke2",
              "Ne5",
              "Nf3",
              "Nxf3",
              "Kxf3",
              "g5",
              "Kg4",
              "Kg6",
              "Nd5",
              "h5+",
              "Kf3",
              "Kf5",
              "Ne3+",
              "Ke5",
              "g3",
              "Kf6",
              "Ke4",
              "Ke6",
              "Nd5",
              "h4",
              "g4",
              "Kf7",
              "Kf5",
              "Kg7",
              "Kxg5",
              "Kh7",
              "Kxh4",
              "Kg6",
              "g5",
              "Kh7",
              "Kh5",
              "Kg7",
              "g6",
              "Kh8",
              "Kh6",
              "Kg8",
              "g7",
              "Kf7",
              "Kh7",
              "Ke6",
              "g8=Q+",
              "Ke5",
              "Kg6",
              "Kd4",
              "Kf5",
              "Kc5",
              "Ke5",
              "Kc4",
              "Qc8+",
              "Kd3",
              "Qc3+",
              "Ke2",
              "Ke4",
              "Kf2",
              "Qf3+",
              "Kg1",
              "Qe2",
              "Kh1",
              "Kf3",
              "Kg1",
              "Qg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxb2",
              "Nxb2",
              "Ne3",
              "Nd3",
              "Kf1",
              "Kf6",
              "Ke2",
              "Ne5",
              "Nf3",
              "Nxf3",
              "Kxf3",
              "Kg5",
              "g3",
              "h5",
              "h4+",
              "Kh6",
              "Kf4",
              "Kg6",
              "Nf5",
              "Kf6",
              "Nd6",
              "Kg6",
              "Ke5",
              "Kh6",
              "Kf5",
              "Kh7",
              "Kg5",
              "g6",
              "Ne8",
              "Kg8",
              "Kxg6",
              "Kf8",
              "Nf6",
              "Ke7",
              "Nxh5",
              "Kf8",
              "Nf6",
              "Ke7",
              "h5",
              "Kf8",
              "h6",
              "Ke7",
              "h7",
              "Kf8",
              "h8=Q+",
              "Ke7",
              "Qe8+",
              "Kd6",
              "Qd7+",
              "Ke5",
              "Qd5#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 399,
            "completion_tokens": 481,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 399,
            "completion_tokens": 567,
            "total_tokens": 966,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 398,
            "completion_tokens": 504,
            "total_tokens": 902,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1196,
          "total_completion_tokens": 1552,
          "total_tokens": 2748
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 69,
            "turn_number": 35,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 399,
            "completion_tokens": 481,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 69,
            "turn_number": 35,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 399,
            "completion_tokens": 567,
            "total_tokens": 966,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 69,
            "turn_number": 35,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 398,
            "completion_tokens": 504,
            "total_tokens": 902,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "1R6/6pp/1n4k1/8/2PN4/8/1r4PP/5NK1 b - - 0 35"
    },
    {
      "turn": 72,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxb2",
          "aggressive_uci": "c4b2",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Kf1 Kf6 39. Ke2\nNe5 40. Nf3 Nxf3 41. Kxf3 Kg5 42. g3 h5 43. h4+ Kh6 44. Kf4 g6 45. Nd5 Kg7 46. Kg5\nKf7 47. Nf4 Kg7 48. Nxg6 Kh7 49. Kxh5 Kg7 50. Kg5 Kh7 51. h5 Kg7 52. h6+ Kh7\n53. Kh5 Kg8 54. g4 Kh7 55. g5 Kg8 56. Ne7+ Kh7 57. g6+ Kh8 58. g7+ Kh7 59. g8=Q# Kh8 60. Qg7# Kh7 61. Qg6+ Kh8 62. Qg8# Kh7 63. Qg7# Kh8 64. Qg8# Kh7 65. Qg7# Kh8 66. Qg8# Kh7 67. Qg7# Kh8 68. Qg8# Kh7 69. Qg7# Kh8 70. Qg8# Kh7 71. Qg7# Kh8 72. Qg8# Kh7 73. Qg7# Kh8 74. Qg8# Kh7 75. Qg7# Kh8 76. Qg8# Kh7 77.",
          "aggressive_tokens": {
            "prompt_tokens": 408,
            "completion_tokens": 640,
            "total_tokens": 1048,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ne3",
            "Nd3",
            "Kf1",
            "Kf6",
            "Ke2",
            "Ne5",
            "Nf3",
            "Nxf3",
            "Kxf3",
            "Kg5",
            "g3",
            "h5",
            "h4+",
            "Kh6",
            "Kf4",
            "g6",
            "Nd5",
            "Kg7",
            "Kg5",
            "Kf7",
            "Nf4",
            "Kg7",
            "Nxg6",
            "Kh7",
            "Kxh5",
            "Kg7",
            "Kg5",
            "Kh7",
            "h5",
            "Kg7",
            "h6+",
            "Kh7",
            "Kh5",
            "Kg8",
            "g4",
            "Kh7",
            "g5",
            "Kg8",
            "Ne7+",
            "Kh7",
            "g6+",
            "Kh8",
            "g7+",
            "Kh7",
            "g8=Q#",
            "Kh8",
            "Qg7#",
            "Kh7",
            "Qg6+",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7",
            "Qg7#",
            "Kh8",
            "Qg8#",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxb2",
          "positional_uci": "c4b2",
          "positional_response": "36... Nxb2 37. Ne3 Nd3 38. h3 Rb1+ 39. Kh2 Re1 40. Ndc2 Re2 41. Kg3 Ne1 42. Nxe1\nRxe1 43. Kf2 Ra1 44. Kf3 Ra3 45. Kf4 Kf6 46. Ng4+ Ke6 47. Ne3 Ra4+ 48. Kf3 Ke5\n49. Ng4+ Kf5 50. Ne3+ Kg5 51. g3 Ra3 52. h4+ Kh5 53. Kf4 Ra4+ 54. Kf3 g6 55.\nNg2 Ra3+ 56. Ne3 Rxe3+ 57. Kxe3 Kg4 58. Kf2 Kh3 59. Kf3 h5 60. Kf4 Kg2 61. g4\nKh3 62. gxh5 gxh5 63. Kg5 Kg3 64. Kxh5 Kf4 65. Kg6 Kg4 66. h5 Kf4 67. h6 Ke5\n68. h7 Ke6 69. h8=Q Kd5 70. Qe8 Kd4 71. Kf5 Kd5 72. Qd8+ Kc4 73. Ke4 Kc5 74.\nQd5+ Kb6 75. Qc4 Kb7 76. Kd5 Kb6 77. Qc6+ Ka5 78. Qb7 Ka4 79. Kc4 Ka3 80. Qb3#",
          "positional_tokens": {
            "prompt_tokens": 408,
            "completion_tokens": 367,
            "total_tokens": 775,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ne3",
            "Nd3",
            "h3",
            "Rb1+",
            "Kh2",
            "Re1",
            "Ndc2",
            "Re2",
            "Kg3",
            "Ne1",
            "Nxe1",
            "Rxe1",
            "Kf2",
            "Ra1",
            "Kf3",
            "Ra3",
            "Kf4",
            "Kf6",
            "Ng4+",
            "Ke6",
            "Ne3",
            "Ra4+",
            "Kf3",
            "Ke5",
            "Ng4+",
            "Kf5",
            "Ne3+",
            "Kg5",
            "g3",
            "Ra3",
            "h4+",
            "Kh5",
            "Kf4",
            "Ra4+",
            "Kf3",
            "g6",
            "Ng2",
            "Ra3+",
            "Ne3",
            "Rxe3+",
            "Kxe3",
            "Kg4",
            "Kf2",
            "Kh3",
            "Kf3",
            "h5",
            "Kf4",
            "Kg2",
            "g4",
            "Kh3",
            "gxh5",
            "gxh5",
            "Kg5",
            "Kg3",
            "Kxh5",
            "Kf4",
            "Kg6",
            "Kg4",
            "h5",
            "Kf4",
            "h6",
            "Ke5",
            "h7",
            "Ke6",
            "h8=Q",
            "Kd5",
            "Qe8",
            "Kd4",
            "Kf5",
            "Kd5",
            "Qd8+",
            "Kc4",
            "Ke4",
            "Kc5",
            "Qd5+",
            "Kb6",
            "Qc4",
            "Kb7",
            "Kd5",
            "Kb6",
            "Qc6+",
            "Ka5",
            "Qb7",
            "Ka4",
            "Kc4",
            "Ka3",
            "Qb3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxb2",
          "neutral_uci": "c4b2",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Kf1 Kf6 39. Ke2\nNe5 40. Nf3 Nxf3 41. Kxf3 Kg5 42. g3 h5 43. h4+ Kh6 44. Kf4 g6 45. Nd5 Kg7 46.\nKg5 Kf7 47. Nf4 Kg7 48. Nxg6 Kh7 49. Kxh5 Kg7 50. Kg5 Kh7 51. h5 Kg7 52. h6+\nKh7 53. Kh5 Kg8 54. g4 Kh7 55. g5 Kg8 56. Ne7+ Kh7 57. g6+ Kh8 58. g7+ Kh7 59.\ng8=Q#",
          "neutral_tokens": {
            "prompt_tokens": 407,
            "completion_tokens": 482,
            "total_tokens": 889,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ne3",
            "Nd3",
            "Kf1",
            "Kf6",
            "Ke2",
            "Ne5",
            "Nf3",
            "Nxf3",
            "Kxf3",
            "Kg5",
            "g3",
            "h5",
            "h4+",
            "Kh6",
            "Kf4",
            "g6",
            "Nd5",
            "Kg7",
            "Kg5",
            "Kf7",
            "Nf4",
            "Kg7",
            "Nxg6",
            "Kh7",
            "Kxh5",
            "Kg7",
            "Kg5",
            "Kh7",
            "h5",
            "Kg7",
            "h6+",
            "Kh7",
            "Kh5",
            "Kg8",
            "g4",
            "Kh7",
            "g5",
            "Kg8",
            "Ne7+",
            "Kh7",
            "g6+",
            "Kh8",
            "g7+",
            "Kh7",
            "g8=Q#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c4b2",
          "positional_uci": "c4b2",
          "neutral_uci": "c4b2",
          "consensus_move": "c4b2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ne3",
              "Nd3",
              "Kf1",
              "Kf6",
              "Ke2",
              "Ne5",
              "Nf3",
              "Nxf3",
              "Kxf3",
              "Kg5",
              "g3",
              "h5",
              "h4+",
              "Kh6",
              "Kf4",
              "g6",
              "Nd5",
              "Kg7",
              "Kg5",
              "Kf7",
              "Nf4",
              "Kg7",
              "Nxg6",
              "Kh7",
              "Kxh5",
              "Kg7",
              "Kg5",
              "Kh7",
              "h5",
              "Kg7",
              "h6+",
              "Kh7",
              "Kh5",
              "Kg8",
              "g4",
              "Kh7",
              "g5",
              "Kg8",
              "Ne7+",
              "Kh7",
              "g6+",
              "Kh8",
              "g7+",
              "Kh7",
              "g8=Q#",
              "Kh8",
              "Qg7#",
              "Kh7",
              "Qg6+",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7",
              "Qg7#",
              "Kh8",
              "Qg8#",
              "Kh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ne3",
              "Nd3",
              "h3",
              "Rb1+",
              "Kh2",
              "Re1",
              "Ndc2",
              "Re2",
              "Kg3",
              "Ne1",
              "Nxe1",
              "Rxe1",
              "Kf2",
              "Ra1",
              "Kf3",
              "Ra3",
              "Kf4",
              "Kf6",
              "Ng4+",
              "Ke6",
              "Ne3",
              "Ra4+",
              "Kf3",
              "Ke5",
              "Ng4+",
              "Kf5",
              "Ne3+",
              "Kg5",
              "g3",
              "Ra3",
              "h4+",
              "Kh5",
              "Kf4",
              "Ra4+",
              "Kf3",
              "g6",
              "Ng2",
              "Ra3+",
              "Ne3",
              "Rxe3+",
              "Kxe3",
              "Kg4",
              "Kf2",
              "Kh3",
              "Kf3",
              "h5",
              "Kf4",
              "Kg2",
              "g4",
              "Kh3",
              "gxh5",
              "gxh5",
              "Kg5",
              "Kg3",
              "Kxh5",
              "Kf4",
              "Kg6",
              "Kg4",
              "h5",
              "Kf4",
              "h6",
              "Ke5",
              "h7",
              "Ke6",
              "h8=Q",
              "Kd5",
              "Qe8",
              "Kd4",
              "Kf5",
              "Kd5",
              "Qd8+",
              "Kc4",
              "Ke4",
              "Kc5",
              "Qd5+",
              "Kb6",
              "Qc4",
              "Kb7",
              "Kd5",
              "Kb6",
              "Qc6+",
              "Ka5",
              "Qb7",
              "Ka4",
              "Kc4",
              "Ka3",
              "Qb3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ne3",
              "Nd3",
              "Kf1",
              "Kf6",
              "Ke2",
              "Ne5",
              "Nf3",
              "Nxf3",
              "Kxf3",
              "Kg5",
              "g3",
              "h5",
              "h4+",
              "Kh6",
              "Kf4",
              "g6",
              "Nd5",
              "Kg7",
              "Kg5",
              "Kf7",
              "Nf4",
              "Kg7",
              "Nxg6",
              "Kh7",
              "Kxh5",
              "Kg7",
              "Kg5",
              "Kh7",
              "h5",
              "Kg7",
              "h6+",
              "Kh7",
              "Kh5",
              "Kg8",
              "g4",
              "Kh7",
              "g5",
              "Kg8",
              "Ne7+",
              "Kh7",
              "g6+",
              "Kh8",
              "g7+",
              "Kh7",
              "g8=Q#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 408,
            "completion_tokens": 640,
            "total_tokens": 1048,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 408,
            "completion_tokens": 367,
            "total_tokens": 775,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 407,
            "completion_tokens": 482,
            "total_tokens": 889,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1223,
          "total_completion_tokens": 1489,
          "total_tokens": 2712
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 71,
            "turn_number": 36,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 408,
            "completion_tokens": 640,
            "total_tokens": 1048,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 71,
            "turn_number": 36,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 408,
            "completion_tokens": 367,
            "total_tokens": 775,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 71,
            "turn_number": 36,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 407,
            "completion_tokens": 482,
            "total_tokens": 889,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/6pp/6k1/8/2nN4/8/1R4PP/5NK1 b - - 0 36"
    },
    {
      "turn": 74,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nd3",
          "aggressive_uci": "b2d3",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Kf1 Kf6 39. Ke2 Ne5 40. Nf3 Nxf3 41. Kxf3 g5 42. Kg4 Kg6 43. Nd5 h5+ 44. Kf3 Kf5 45. Ne3+ Ke5 46. g3 Kf6 47. Ke4 Ke6 48. Nd5 h4 49. g4 Kf7 50. Kf5 Kg7 51. Kxg5 Kh7 52. Kxh4 Kg6 53. g5 Kg7 54. Kh5 Kh7 55. g6+ Kg7 56. Kg5 Kg8 57. Kh6 Kh8 58. g7+ Kg8 59. Nf6+ Kf7 60. g8=Q+ Kxf6 61. Qg5+ Ke6 62. Kg6 Kd6 63. Qf5 Kc6 64. Qe5 Kb6 65. Qd5 Kc7 66. Qe6 Kb7 67. Qd6 Ka7 68. Qc6 Kb8 69. Qd7 Ka8 70. Kf6 Kb8 71. Ke6 Ka8 72. Kd6 Kb8 73. Kc6 Ka8 74. Qb7# 1-0",
          "aggressive_tokens": {
            "prompt_tokens": 416,
            "completion_tokens": 612,
            "total_tokens": 1028,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf1",
            "Kf6",
            "Ke2",
            "Ne5",
            "Nf3",
            "Nxf3",
            "Kxf3",
            "g5",
            "Kg4",
            "Kg6",
            "Nd5",
            "h5+",
            "Kf3",
            "Kf5",
            "Ne3+",
            "Ke5",
            "g3",
            "Kf6",
            "Ke4",
            "Ke6",
            "Nd5",
            "h4",
            "g4",
            "Kf7",
            "Kf5",
            "Kg7",
            "Kxg5",
            "Kh7",
            "Kxh4",
            "Kg6",
            "g5",
            "Kg7",
            "Kh5",
            "Kh7",
            "g6+",
            "Kg7",
            "Kg5",
            "Kg8",
            "Kh6",
            "Kh8",
            "g7+",
            "Kg8",
            "Nf6+",
            "Kf7",
            "g8=Q+",
            "Kxf6",
            "Qg5+",
            "Ke6",
            "Kg6",
            "Kd6",
            "Qf5",
            "Kc6",
            "Qe5",
            "Kb6",
            "Qd5",
            "Kc7",
            "Qe6",
            "Kb7",
            "Qd6",
            "Ka7",
            "Qc6",
            "Kb8",
            "Qd7",
            "Ka8",
            "Kf6",
            "Kb8",
            "Ke6",
            "Ka8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nc4",
          "positional_uci": "b2c4",
          "positional_response": "37... Nc4 38. Nxc4 Kf6 39. Kf2 g5 40. Kf3 h5 41. Ke4 g4 42. Kf4 Kg6 43. Ne5+ Kf6 44. Nf5 Ke6 45. Ng7+ Kf6 46. Nxh5+ Ke6 47. Nxg4 Kf7 48. Kf5 Kg8 49. Kg6 Kh8 50. Ne5 Kg8 51. Nf6+ Kf8 52. Nfd7+ Kg8 53. h4 Kh8 54. h5 Kg8 55. h6 Kh8 56. Nf7+ Kg8 57. h7#",
          "positional_tokens": {
            "prompt_tokens": 416,
            "completion_tokens": 167,
            "total_tokens": 583,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxc4",
            "Kf6",
            "Kf2",
            "g5",
            "Kf3",
            "h5",
            "Ke4",
            "g4",
            "Kf4",
            "Kg6",
            "Ne5+",
            "Kf6",
            "Nf5",
            "Ke6",
            "Ng7+",
            "Kf6",
            "Nxh5+",
            "Ke6",
            "Nxg4",
            "Kf7",
            "Kf5",
            "Kg8",
            "Kg6",
            "Kh8",
            "Ne5",
            "Kg8",
            "Nf6+",
            "Kf8",
            "Nfd7+",
            "Kg8",
            "h4",
            "Kh8",
            "h5",
            "Kg8",
            "h6",
            "Kh8",
            "Nf7+",
            "Kg8",
            "h7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe3",
          "neutral_uci": null,
          "neutral_response": "37. Ne3 Nxe3 38. Nxe3 Kf6 39. Kf2 Ke5 40. Kf3 Kf6 41. Kf4 Ke6 42. Kg5 Kf7 43. Kf5 Ke7 44. Ng4 Kf7 45. Ne5+ Ke7 46. h4 Kd6 47. h5 Ke7 48. g4 Kd6 49. g5 Ke7 50. g6 hxg6+ 51. Kxg6 Kf8 52. Kh7 Ke7 53. Kxg7 Ke6 54. h6 Kxe5 55. h7 Kf5 56. h8=Q Ke5 57. Qh4 Kd5 58. Kf6 Kc5 59. Ke6 Kc6 60. Qc4+ Kb6 61. Kd6 Kb7 62. Qb5+ Ka7 63. Kc7 Ka8 64. Qa6# Kd8 65. Kd6 Ke8 66. Qb7 Kf8 67. Ke6 Kg8 68. Kf6 Kh8 69. Qg7# Kd8 70. Ke6 Kc8 71. Kd6 Kb8 72. Kc6 Ka8 73. Qb7# Kd8 74. Qd7# Kd8 75. Kd6# Kd8 76. Qe7# Kd8 77. Qf8# Kd8 78. Qe7# Kd8 79. Qd7# Kd8 80. Qc7# Kd8 81. Qb8# Kd8 82. Qc7# Kd8 83. Qd7# Kd8 84. Qe7# Kd8 85. Qf8# Kd8 86. Qe7# Kd8 87. Qd7# Kd8 88. Qc7# Kd8 89. Qb8# Kd8 90. Qc7# Kd8 91. Qd7# Kd8 92. Qe7# Kd8 93. Qf8# Kd8 94. Qe7# Kd8 95. Qd7# Kd8 96. Qc7# Kd8 97. Qb8# Kd8 98. Qc7# Kd8 99. Qd7# Kd8 100. Qe7# Kd8 101. Qf8# Kd8 102. Qe7# Kd8 103. Qd7# Kd8 104. Qc7# Kd8 105. Qb8# Kd8 106. Qc7# Kd8",
          "neutral_tokens": {
            "prompt_tokens": 415,
            "completion_tokens": 640,
            "total_tokens": 1055,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf6",
            "Kf2",
            "Ke5",
            "Kf3",
            "Kf6",
            "Kf4",
            "Ke6",
            "Kg5",
            "Kf7",
            "Kf5",
            "Ke7",
            "Ng4",
            "Kf7",
            "Ne5+",
            "Ke7",
            "h4",
            "Kd6",
            "h5",
            "Ke7",
            "g4",
            "Kd6",
            "g5",
            "Ke7",
            "g6",
            "hxg6+",
            "Kxg6",
            "Kf8",
            "Kh7",
            "Ke7",
            "Kxg7",
            "Ke6",
            "h6",
            "Kxe5",
            "h7",
            "Kf5",
            "h8=Q",
            "Ke5",
            "Qh4",
            "Kd5",
            "Kf6",
            "Kc5",
            "Ke6",
            "Kc6",
            "Qc4+",
            "Kb6",
            "Kd6",
            "Kb7",
            "Qb5+",
            "Ka7",
            "Kc7",
            "Ka8",
            "Qa6#",
            "Kd8",
            "Kd6",
            "Ke8",
            "Qb7",
            "Kf8",
            "Ke6",
            "Kg8",
            "Kf6",
            "Kh8",
            "Qg7#",
            "Kd8",
            "Ke6",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Kd6#",
            "Kd8",
            "Qe7#",
            "Kd8",
            "Qf8#",
            "Kd8",
            "Qe7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Qc7#",
            "Kd8",
            "Qb8#",
            "Kd8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Qe7#",
            "Kd8",
            "Qf8#",
            "Kd8",
            "Qe7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Qc7#",
            "Kd8",
            "Qb8#",
            "Kd8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Qe7#",
            "Kd8",
            "Qf8#",
            "Kd8",
            "Qe7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Qc7#",
            "Kd8",
            "Qb8#",
            "Kd8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Qe7#",
            "Kd8",
            "Qf8#",
            "Kd8",
            "Qe7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Qc7#",
            "Kd8",
            "Qb8#",
            "Kd8",
            "Qc7#",
            "Kd8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b2d3",
          "positional_uci": "b2c4",
          "neutral_uci": null,
          "consensus_move": "b2d3",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf1",
              "Kf6",
              "Ke2",
              "Ne5",
              "Nf3",
              "Nxf3",
              "Kxf3",
              "g5",
              "Kg4",
              "Kg6",
              "Nd5",
              "h5+",
              "Kf3",
              "Kf5",
              "Ne3+",
              "Ke5",
              "g3",
              "Kf6",
              "Ke4",
              "Ke6",
              "Nd5",
              "h4",
              "g4",
              "Kf7",
              "Kf5",
              "Kg7",
              "Kxg5",
              "Kh7",
              "Kxh4",
              "Kg6",
              "g5",
              "Kg7",
              "Kh5",
              "Kh7",
              "g6+",
              "Kg7",
              "Kg5",
              "Kg8",
              "Kh6",
              "Kh8",
              "g7+",
              "Kg8",
              "Nf6+",
              "Kf7",
              "g8=Q+",
              "Kxf6",
              "Qg5+",
              "Ke6",
              "Kg6",
              "Kd6",
              "Qf5",
              "Kc6",
              "Qe5",
              "Kb6",
              "Qd5",
              "Kc7",
              "Qe6",
              "Kb7",
              "Qd6",
              "Ka7",
              "Qc6",
              "Kb8",
              "Qd7",
              "Ka8",
              "Kf6",
              "Kb8",
              "Ke6",
              "Ka8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxc4",
              "Kf6",
              "Kf2",
              "g5",
              "Kf3",
              "h5",
              "Ke4",
              "g4",
              "Kf4",
              "Kg6",
              "Ne5+",
              "Kf6",
              "Nf5",
              "Ke6",
              "Ng7+",
              "Kf6",
              "Nxh5+",
              "Ke6",
              "Nxg4",
              "Kf7",
              "Kf5",
              "Kg8",
              "Kg6",
              "Kh8",
              "Ne5",
              "Kg8",
              "Nf6+",
              "Kf8",
              "Nfd7+",
              "Kg8",
              "h4",
              "Kh8",
              "h5",
              "Kg8",
              "h6",
              "Kh8",
              "Nf7+",
              "Kg8",
              "h7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf6",
              "Kf2",
              "Ke5",
              "Kf3",
              "Kf6",
              "Kf4",
              "Ke6",
              "Kg5",
              "Kf7",
              "Kf5",
              "Ke7",
              "Ng4",
              "Kf7",
              "Ne5+",
              "Ke7",
              "h4",
              "Kd6",
              "h5",
              "Ke7",
              "g4",
              "Kd6",
              "g5",
              "Ke7",
              "g6",
              "hxg6+",
              "Kxg6",
              "Kf8",
              "Kh7",
              "Ke7",
              "Kxg7",
              "Ke6",
              "h6",
              "Kxe5",
              "h7",
              "Kf5",
              "h8=Q",
              "Ke5",
              "Qh4",
              "Kd5",
              "Kf6",
              "Kc5",
              "Ke6",
              "Kc6",
              "Qc4+",
              "Kb6",
              "Kd6",
              "Kb7",
              "Qb5+",
              "Ka7",
              "Kc7",
              "Ka8",
              "Qa6#",
              "Kd8",
              "Kd6",
              "Ke8",
              "Qb7",
              "Kf8",
              "Ke6",
              "Kg8",
              "Kf6",
              "Kh8",
              "Qg7#",
              "Kd8",
              "Ke6",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Kd6#",
              "Kd8",
              "Qe7#",
              "Kd8",
              "Qf8#",
              "Kd8",
              "Qe7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Qc7#",
              "Kd8",
              "Qb8#",
              "Kd8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Qe7#",
              "Kd8",
              "Qf8#",
              "Kd8",
              "Qe7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Qc7#",
              "Kd8",
              "Qb8#",
              "Kd8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Qe7#",
              "Kd8",
              "Qf8#",
              "Kd8",
              "Qe7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Qc7#",
              "Kd8",
              "Qb8#",
              "Kd8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Qe7#",
              "Kd8",
              "Qf8#",
              "Kd8",
              "Qe7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Qc7#",
              "Kd8",
              "Qb8#",
              "Kd8",
              "Qc7#",
              "Kd8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 416,
            "completion_tokens": 612,
            "total_tokens": 1028,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 416,
            "completion_tokens": 167,
            "total_tokens": 583,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 415,
            "completion_tokens": 640,
            "total_tokens": 1055,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1247,
          "total_completion_tokens": 1419,
          "total_tokens": 2666
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 73,
            "turn_number": 37,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 416,
            "completion_tokens": 612,
            "total_tokens": 1028,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 73,
            "turn_number": 37,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 416,
            "completion_tokens": 167,
            "total_tokens": 583,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 73,
            "turn_number": 37,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 415,
            "completion_tokens": 640,
            "total_tokens": 1055,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/6pp/6k1/8/3N4/4N3/1n4PP/6K1 b - - 1 37"
    },
    {
      "turn": 76,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf4",
          "aggressive_uci": "d3f4",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Nf3 Nf4 39. g3 Ne6 40. Kf2 Kf6 41. Ng4+ Kf5 42. Ne3+ Kf6 43. Nd5+ Kf5 44. Ke3 g5 45. Nd4+ Nxd4 46. Kxd4 Kg4 47. Ke3 Kh3 48. Kf3 Kxh2 49. Kg4 h5+ 50. Kxh5 Kxg3 51. Kxg5 *",
          "aggressive_tokens": {
            "prompt_tokens": 424,
            "completion_tokens": 429,
            "total_tokens": 853,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g3",
            "Ne6",
            "Kf2",
            "Kf6",
            "Ng4+",
            "Kf5",
            "Ne3+",
            "Kf6",
            "Nd5+",
            "Kf5",
            "Ke3",
            "g5",
            "Nd4+",
            "Nxd4",
            "Kxd4",
            "Kg4",
            "Ke3",
            "Kh3",
            "Kf3",
            "Kxh2",
            "Kg4",
            "h5+",
            "Kxh5",
            "Kxg3",
            "Kxg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf4",
          "positional_uci": "d3f4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Nf3 Nf4 39. g3 Ne6 40. Kf2 Kf6 41. Nd5+ Kf7 42. Ke3 h6 43. Ke4 Nc5+ 44. Kf5 Nd3 45. Ne5+ Nxe5 46. Kxe5 Kg6 47. Nf4+ Kg5 48. h3 h5 49. Ne6+ Kg6 50. h4 Kh6 51. Kf5 Kh7 52. Kg5 g6 53. Nf4 Kg7 54. Nxg6 Kh7 55. Kxh5 Kg7 56. Kg5 Kh7 57. h5 Kg7 58. h6+ Kh7 59. Kh5 Kg8 60. g4 Kh7 61. g5 Kg8 62. Ne7+ Kh7 63. g6+ Kh8 64. g7+ Kh7 65. g8=Q# 1-0",
          "positional_tokens": {
            "prompt_tokens": 424,
            "completion_tokens": 534,
            "total_tokens": 958,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg7",
            "Nxg6",
            "Kh7",
            "Kxh5",
            "Kg7",
            "Kg5",
            "Kh7",
            "h5",
            "Kg7",
            "h6+",
            "Kh7",
            "Kh5",
            "Kg8",
            "g4",
            "Kh7",
            "g5",
            "Kg8",
            "Ne7+",
            "Kh7",
            "g6+",
            "Kh8",
            "g7+",
            "Kh7",
            "g8=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf4",
          "neutral_uci": "d3f4",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Nf3 Nf4 39. g3 Ne6 40. Kf2 Kf6 41. Nd5+ Kf7 42. Ke3 h6 43. Ne5+ Kg8 44. Ke4 Kh7 45. Kf5 Nd4+ 46. Ke4 Ne6 47. Nf4 Ng5+ 48. Kf5 Kg8 49. Kg6 Ne4 50. Ne6 Nd6 51. Nxg7 Ne4 52. Nf5 Nf2 53. Nxh6+ Kh8 54. Nef7#",
          "neutral_tokens": {
            "prompt_tokens": 423,
            "completion_tokens": 445,
            "total_tokens": 868,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ng5+",
            "Kf5",
            "Kg8",
            "Kg6",
            "Ne4",
            "Ne6",
            "Nd6",
            "Nxg7",
            "Ne4",
            "Nf5",
            "Nf2",
            "Nxh6+",
            "Kh8",
            "Nef7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3f4",
          "positional_uci": "d3f4",
          "neutral_uci": "d3f4",
          "consensus_move": "d3f4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "g3",
              "Ne6",
              "Kf2",
              "Kf6",
              "Ng4+",
              "Kf5",
              "Ne3+",
              "Kf6",
              "Nd5+",
              "Kf5",
              "Ke3",
              "g5",
              "Nd4+",
              "Nxd4",
              "Kxd4",
              "Kg4",
              "Ke3",
              "Kh3",
              "Kf3",
              "Kxh2",
              "Kg4",
              "h5+",
              "Kxh5",
              "Kxg3",
              "Kxg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg7",
              "Nxg6",
              "Kh7",
              "Kxh5",
              "Kg7",
              "Kg5",
              "Kh7",
              "h5",
              "Kg7",
              "h6+",
              "Kh7",
              "Kh5",
              "Kg8",
              "g4",
              "Kh7",
              "g5",
              "Kg8",
              "Ne7+",
              "Kh7",
              "g6+",
              "Kh8",
              "g7+",
              "Kh7",
              "g8=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ng5+",
              "Kf5",
              "Kg8",
              "Kg6",
              "Ne4",
              "Ne6",
              "Nd6",
              "Nxg7",
              "Ne4",
              "Nf5",
              "Nf2",
              "Nxh6+",
              "Kh8",
              "Nef7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 424,
            "completion_tokens": 429,
            "total_tokens": 853,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 424,
            "completion_tokens": 534,
            "total_tokens": 958,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 423,
            "completion_tokens": 445,
            "total_tokens": 868,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1271,
          "total_completion_tokens": 1408,
          "total_tokens": 2679
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 75,
            "turn_number": 38,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 424,
            "completion_tokens": 429,
            "total_tokens": 853,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 75,
            "turn_number": 38,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 424,
            "completion_tokens": 534,
            "total_tokens": 958,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 75,
            "turn_number": 38,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 423,
            "completion_tokens": 445,
            "total_tokens": 868,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/6pp/6k1/8/8/3nNN2/6PP/6K1 b - - 3 38"
    },
    {
      "turn": 78,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxf2",
          "aggressive_uci": null,
          "aggressive_response": "e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Nxe4 d4 b5 Bb3 d5 dxe5 Be6 c3 Bc5 Nbd2\nNxf2 Rxf2 Bxf2+ Kxf2 f6 exf6 Qxf6 Nf1 O-O Bxd5 Rad8 Bg5 Qf7 Bxe6 Qxe6 Bxd8 Rxd8 Qe2 Qf7 Kg1 Rf8 Ng5 Qf5 Qe6+ Qxe6 Nxe6 Rf7 Rd1 Re7 Nd8 Ne5 Nc6 Nxc6 bxc6 Rd8+ Kf7 Rb8 Kg6 c4 Nxc4 Nxc4 Re1+ Kf2 Ra1 Rb7 Rxa2+ Kf3 Ra3+ Nxa3 Kf5 Rxc7 g5 Rxc6 g4+ Kg3 h5 Rc5+ Kg6 Kh4 Kf6 Rxh5 Kg6 Kxg4 Kf6 Rg5 Ke6 h4 Kf6 h5 Ke6 h6 Kf6 h7 Ke6 h8=Q Kd6 Qh6+ Ke7 Rg7+ Kf8 Qh8#",
          "aggressive_tokens": {
            "prompt_tokens": 433,
            "completion_tokens": 273,
            "total_tokens": 706,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxf2",
            "Bxf2+",
            "Kxf2",
            "f6",
            "exf6",
            "Qxf6",
            "Nf1",
            "O-O",
            "Bxd5",
            "Rad8",
            "Bg5",
            "Qf7",
            "Bxe6",
            "Qxe6",
            "Bxd8",
            "Rxd8",
            "Qe2",
            "Qf7",
            "Kg1",
            "Rf8",
            "Ng5",
            "Qf5",
            "Qe6+",
            "Qxe6",
            "Nxe6",
            "Rf7",
            "Rd1",
            "Re7",
            "Nd8",
            "Ne5",
            "Nc6",
            "Nxc6",
            "bxc6",
            "Rd8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "c4",
            "Nxc4",
            "Nxc4",
            "Re1+",
            "Kf2",
            "Ra1",
            "Rb7",
            "Rxa2+",
            "Kf3",
            "Ra3+",
            "Nxa3",
            "Kf5",
            "Rxc7",
            "g5",
            "Rxc6",
            "g4+",
            "Kg3",
            "h5",
            "Rc5+",
            "Kg6",
            "Kh4",
            "Kf6",
            "Rxh5",
            "Kg6",
            "Kxg4",
            "Kf6",
            "Rg5",
            "Ke6",
            "h4",
            "Kf6",
            "h5",
            "Ke6",
            "h6",
            "Kf6",
            "h7",
            "Ke6",
            "h8=Q",
            "Kd6",
            "Qh6+",
            "Ke7",
            "Rg7+",
            "Kf8",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kf6",
          "positional_uci": "g6f6",
          "positional_response": "39... Kf6 40. Ng4+ Kg6 41. Nge5+ Kf6 42. Kf2 g5 43. Ng4+ Kg6 44. Nfe5+ Kf5 45. Kf3 h5 46. g3 hxg4+ 47. Nxg4 Nd5 48. Ne3+ Nxe3 49. Kxe3 Kg4 50. Kf2 Kh3 51. Kg1 g4 52. Kh1 *",
          "positional_tokens": {
            "prompt_tokens": 433,
            "completion_tokens": 113,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf2",
            "g5",
            "Ng4+",
            "Kg6",
            "Nfe5+",
            "Kf5",
            "Kf3",
            "h5",
            "g3",
            "hxg4+",
            "Nxg4",
            "Nd5",
            "Ne3+",
            "Nxe3",
            "Kxe3",
            "Kg4",
            "Kf2",
            "Kh3",
            "Kg1",
            "g4",
            "Kh1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": null,
          "neutral_response": "e4 Nxe5 f6 Qxf6 Qxf6 Nxf6 Kxf6 Kg8 f5 Kf7 f4 Kf6 g4 Kf7 h4 Kf6 g5+ Kf7 h5 Kf8 g6 hxg6 hxg6 Kg8 Kf2 Kf8 Ke3 Kg8 Kd4 Kf8 Kc5 Kg8 Kd6 Kf8 Kd7 Kg8 Ke7 Kh8 Kf7 *",
          "neutral_tokens": {
            "prompt_tokens": 432,
            "completion_tokens": 102,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nxe5",
            "f6",
            "Qxf6",
            "Qxf6",
            "Nxf6",
            "Kxf6",
            "Kg8",
            "f5",
            "Kf7",
            "f4",
            "Kf6",
            "g4",
            "Kf7",
            "h4",
            "Kf6",
            "g5+",
            "Kf7",
            "h5",
            "Kf8",
            "g6",
            "hxg6",
            "hxg6",
            "Kg8",
            "Kf2",
            "Kf8",
            "Ke3",
            "Kg8",
            "Kd4",
            "Kf8",
            "Kc5",
            "Kg8",
            "Kd6",
            "Kf8",
            "Kd7",
            "Kg8",
            "Ke7",
            "Kh8",
            "Kf7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g6f6",
          "neutral_uci": null,
          "consensus_move": "g6f6",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxf2",
              "Bxf2+",
              "Kxf2",
              "f6",
              "exf6",
              "Qxf6",
              "Nf1",
              "O-O",
              "Bxd5",
              "Rad8",
              "Bg5",
              "Qf7",
              "Bxe6",
              "Qxe6",
              "Bxd8",
              "Rxd8",
              "Qe2",
              "Qf7",
              "Kg1",
              "Rf8",
              "Ng5",
              "Qf5",
              "Qe6+",
              "Qxe6",
              "Nxe6",
              "Rf7",
              "Rd1",
              "Re7",
              "Nd8",
              "Ne5",
              "Nc6",
              "Nxc6",
              "bxc6",
              "Rd8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "c4",
              "Nxc4",
              "Nxc4",
              "Re1+",
              "Kf2",
              "Ra1",
              "Rb7",
              "Rxa2+",
              "Kf3",
              "Ra3+",
              "Nxa3",
              "Kf5",
              "Rxc7",
              "g5",
              "Rxc6",
              "g4+",
              "Kg3",
              "h5",
              "Rc5+",
              "Kg6",
              "Kh4",
              "Kf6",
              "Rxh5",
              "Kg6",
              "Kxg4",
              "Kf6",
              "Rg5",
              "Ke6",
              "h4",
              "Kf6",
              "h5",
              "Ke6",
              "h6",
              "Kf6",
              "h7",
              "Ke6",
              "h8=Q",
              "Kd6",
              "Qh6+",
              "Ke7",
              "Rg7+",
              "Kf8",
              "Qh8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf2",
              "g5",
              "Ng4+",
              "Kg6",
              "Nfe5+",
              "Kf5",
              "Kf3",
              "h5",
              "g3",
              "hxg4+",
              "Nxg4",
              "Nd5",
              "Ne3+",
              "Nxe3",
              "Kxe3",
              "Kg4",
              "Kf2",
              "Kh3",
              "Kg1",
              "g4",
              "Kh1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nxe5",
              "f6",
              "Qxf6",
              "Qxf6",
              "Nxf6",
              "Kxf6",
              "Kg8",
              "f5",
              "Kf7",
              "f4",
              "Kf6",
              "g4",
              "Kf7",
              "h4",
              "Kf6",
              "g5+",
              "Kf7",
              "h5",
              "Kf8",
              "g6",
              "hxg6",
              "hxg6",
              "Kg8",
              "Kf2",
              "Kf8",
              "Ke3",
              "Kg8",
              "Kd4",
              "Kf8",
              "Kc5",
              "Kg8",
              "Kd6",
              "Kf8",
              "Kd7",
              "Kg8",
              "Ke7",
              "Kh8",
              "Kf7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 433,
            "completion_tokens": 273,
            "total_tokens": 706,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 433,
            "completion_tokens": 113,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 432,
            "completion_tokens": 102,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1298,
          "total_completion_tokens": 488,
          "total_tokens": 1786
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 77,
            "turn_number": 39,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 433,
            "completion_tokens": 273,
            "total_tokens": 706,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 77,
            "turn_number": 39,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 433,
            "completion_tokens": 113,
            "total_tokens": 546,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 77,
            "turn_number": 39,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 432,
            "completion_tokens": 102,
            "total_tokens": 534,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/6pp/6k1/4N3/5n2/4N3/6PP/6K1 b - - 5 39"
    },
    {
      "turn": 80,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kg6",
          "aggressive_uci": "f6g6",
          "aggressive_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Nf3 Nf4 39.\nNe5+ Kf6 40. Nd7+ Kg6 41. g3 Ne6 42. Ne5+ Kf6 43. N3g4+ Kf5 44. Kf2 h5 45. Ne3+ Kxe5 46. Kf3 Nd4+ 47. Kf2 Ke4 48. Ng2 g5 49. h4 g4 50. Nf4 Nf5 51. Nxh5 Ke5 52. Nf4 Nxh4 53. Nd3+ Kd4 54. gxh4 Kxd3 55. Kg3 Ke4 56. Kxg4 Ke5 57. Kg5 Ke6 58. Kg6 Ke7 59. Kg7 Ke6 60. h5 Kf5 61. h6 Kg5 62. h7 Kf5 63. h8=Q Ke5 64. Qh4 Kd5 65. Qf4 Kc5 66. Qe4 Kd6 67. Kf6 Kc5 68. Ke6 Kb5 69. Qd4 Kc6 70. Qc4+ Kb6 71. Kd6 Kb7 72. Qb5+ Kc8 73. Qb4 Kd8 74. Qb8#",
          "aggressive_tokens": {
            "prompt_tokens": 442,
            "completion_tokens": 618,
            "total_tokens": 1060,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "Kg7",
            "Ke6",
            "h5",
            "Kf5",
            "h6",
            "Kg5",
            "h7",
            "Kf5",
            "h8=Q",
            "Ke5",
            "Qh4",
            "Kd5",
            "Qf4",
            "Kc5",
            "Qe4",
            "Kd6",
            "Kf6",
            "Kc5",
            "Ke6",
            "Kb5",
            "Qd4",
            "Kc6",
            "Qc4+",
            "Kb6",
            "Kd6",
            "Kb7",
            "Qb5+",
            "Kc8",
            "Qb4",
            "Kd8",
            "Qb8#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kg5",
          "positional_uci": "f6g5",
          "positional_response": "40... Kg5 41. Nf8 h6 42. Nh7+ Kh5",
          "positional_tokens": {
            "prompt_tokens": 442,
            "completion_tokens": 21,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf8",
            "h6",
            "Nh7+",
            "Kh5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kg6",
          "neutral_uci": "f6g6",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Nf3 Nf4 39.\nNe5+ Kf6 40. Nd7+ Kg6 41. g3 Ne6 42. Ne5+ Kf6 43. N3g4+ Kf5 44. Kf2 h5 45. Ne3+\nKxe5 46. Kf3 Nd4+ 47. Kg2 Ke4 48. Nc4 Nf5 49. Nd2+ Ke3 50. Nf3 Ke4 51. Ng5+ Ke5\n52. Kf3 Nd4+ 53. Ke3 Nf5+ 54. Kf3 Nd4+ 55. Ke3 Nf5+ 56. Kf3 Nd4+ 57. Ke3 Nf5+\n58. Kf3 Nd4+ 59. Ke3 Nf5+ 60. Kf3 Nd4+ 61. Ke3 Nf5+ 62. Kf3 Nd4+ 63. Ke3 Nf5+\n64. Kf3 Nd4+ 65. Ke3 Nf5+ 66. Kf3 Nd4+ 67. Ke3 Nf5+ 68. Kf3 Nd4+ 69. Ke3 Nf5+\n70. Kf3 Nd4+ 71. Ke3 Nf5+ 72. Kf3 Nd4+ 73. Ke3 Nf5+ 74. Kf3 Nd4+ 75. Ke3 Nf5",
          "neutral_tokens": {
            "prompt_tokens": 441,
            "completion_tokens": 640,
            "total_tokens": 1081,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "g3",
            "Ne6",
            "Ne5+",
            "Kf6",
            "N3g4+",
            "Kf5",
            "Kf2",
            "h5",
            "Ne3+",
            "Kxe5",
            "Kf3",
            "Nd4+",
            "Kg2",
            "Ke4",
            "Nc4",
            "Nf5",
            "Nd2+",
            "Ke3",
            "Nf3",
            "Ke4",
            "Ng5+",
            "Ke5",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5+",
            "Kf3",
            "Nd4+",
            "Ke3",
            "Nf5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f6g6",
          "positional_uci": "f6g5",
          "neutral_uci": "f6g6",
          "consensus_move": "f6g6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ke7",
              "Kg7",
              "Ke6",
              "h5",
              "Kf5",
              "h6",
              "Kg5",
              "h7",
              "Kf5",
              "h8=Q",
              "Ke5",
              "Qh4",
              "Kd5",
              "Qf4",
              "Kc5",
              "Qe4",
              "Kd6",
              "Kf6",
              "Kc5",
              "Ke6",
              "Kb5",
              "Qd4",
              "Kc6",
              "Qc4+",
              "Kb6",
              "Kd6",
              "Kb7",
              "Qb5+",
              "Kc8",
              "Qb4",
              "Kd8",
              "Qb8#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf8",
              "h6",
              "Nh7+",
              "Kh5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "g3",
              "Ne6",
              "Ne5+",
              "Kf6",
              "N3g4+",
              "Kf5",
              "Kf2",
              "h5",
              "Ne3+",
              "Kxe5",
              "Kf3",
              "Nd4+",
              "Kg2",
              "Ke4",
              "Nc4",
              "Nf5",
              "Nd2+",
              "Ke3",
              "Nf3",
              "Ke4",
              "Ng5+",
              "Ke5",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5+",
              "Kf3",
              "Nd4+",
              "Ke3",
              "Nf5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 442,
            "completion_tokens": 618,
            "total_tokens": 1060,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 442,
            "completion_tokens": 21,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 441,
            "completion_tokens": 640,
            "total_tokens": 1081,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1325,
          "total_completion_tokens": 1279,
          "total_tokens": 2604
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 79,
            "turn_number": 40,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 442,
            "completion_tokens": 618,
            "total_tokens": 1060,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 79,
            "turn_number": 40,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 442,
            "completion_tokens": 21,
            "total_tokens": 463,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 79,
            "turn_number": 40,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 441,
            "completion_tokens": 640,
            "total_tokens": 1081,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/3N2pp/5k2/8/5n2/4N3/6PP/6K1 b - - 7 40"
    },
    {
      "turn": 82,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf5 Nf3+ Kh8 Nf",
          "aggressive_tokens": {
            "prompt_tokens": 449,
            "completion_tokens": 640,
            "total_tokens": 1089,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8",
            "Nf5",
            "Nf3+",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ne6",
          "positional_uci": "f4e6",
          "positional_response": "41... Ne6 42. Ne5+ Kf6 43. N3g4+ Kf5 44. Kf2 h5 45. Ne3+ Kxe5 46. Kf3 Nd4+ 47. Kf2 Ke4 48. Ng2 g5 49. h4 g4 50. Nf4 Nf5 51. Nxh5 Ne3 52. Nf6+ Kd4 53. h5 Nd1+ 54. Ke2 Nc3+ 55. Kf1 Ke5 56. Nxg4+ Kf5 57. Ne3+ Kg5 58. g4 Ne4 59. Kg2 Nf6 60. Kf3 Nh7 61. Nd5 Nf8 62. Nf4 Nd7 63. Ne6+ Kh6 64. Kf4 Nf6 65. Kf5 Nd5 66. Nf4 Ne3+ 67. Kf6 Nxg4+ 68. Kf5 Ne3+ 69. Kf6 Ng4+ 70. Kf5 Ne3+ 71. Kf6 Ng4+ 72. Kf5 *",
          "positional_tokens": {
            "prompt_tokens": 449,
            "completion_tokens": 269,
            "total_tokens": 718,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kh6",
            "Kf4",
            "Nf6",
            "Kf5",
            "Nd5",
            "Nf4",
            "Ne3+",
            "Kf6",
            "Nxg4+",
            "Kf5",
            "Ne3+",
            "Kf6",
            "Ng4+",
            "Kf5",
            "Ne3+",
            "Kf6",
            "Ng4+",
            "Kf5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ne6",
          "neutral_uci": "f4e6",
          "neutral_response": "41... Ne6 42. Ne5+ Kf6 43. Nd3 Nd4 44. Kf2 g5 45. Ng4+ Kg6 46. Nge5+ Kf6 47. Nf3\nNf5 48. g4 Nd6 49. Ke3 h6 50. Kd4 Nf7 51. Nc5 Kg6 52. Ne5+ Nxe5 53. Kxe5 h5\n54. h3 hxg4 55. hxg4 Kh6 56. Kf6 Kh7 57. Kxg5 Kg7 58. Ne6+ Kf7 59. Kf5 Kg8 60.\nKg6 Kh8 61. Kf7 Kh7 62. g5 Kh8 63. Nf4 Kh7 64. g6+ Kh6 65. g7 Kg5 66. g8=Q+\nKxf4 67. Qg6 Ke5 68. Qf6+ Ke4 69. Ke6 Kd3 70. Qf4 Kc3 71. Qe4 Kb3 72. Qd4 Kc2\n73. Qe3 Kb2 74. Qd3 Ka2 75. Qc3 Kb1 76. Qd2 Ka1 77. Kd5 Kb1 78. Kc4 Ka1 79.\nKb3 Kb1 80. Qb2#",
          "neutral_tokens": {
            "prompt_tokens": 448,
            "completion_tokens": 327,
            "total_tokens": 775,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf7",
            "Kf5",
            "Kg8",
            "Kg6",
            "Kh8",
            "Kf7",
            "Kh7",
            "g5",
            "Kh8",
            "Nf4",
            "Kh7",
            "g6+",
            "Kh6",
            "g7",
            "Kg5",
            "g8=Q+",
            "Kxf4",
            "Qg6",
            "Ke5",
            "Qf6+",
            "Ke4",
            "Ke6",
            "Kd3",
            "Qf4",
            "Kc3",
            "Qe4",
            "Kb3",
            "Qd4",
            "Kc2",
            "Qe3",
            "Kb2",
            "Qd3",
            "Ka2",
            "Qc3",
            "Kb1",
            "Qd2",
            "Ka1",
            "Kd5",
            "Kb1",
            "Kc4",
            "Ka1",
            "Kb3",
            "Kb1",
            "Qb2#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "f4e6",
          "neutral_uci": "f4e6",
          "consensus_move": "f4e6",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8",
              "Nf5",
              "Nf3+",
              "Kh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kh6",
              "Kf4",
              "Nf6",
              "Kf5",
              "Nd5",
              "Nf4",
              "Ne3+",
              "Kf6",
              "Nxg4+",
              "Kf5",
              "Ne3+",
              "Kf6",
              "Ng4+",
              "Kf5",
              "Ne3+",
              "Kf6",
              "Ng4+",
              "Kf5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf7",
              "Kf5",
              "Kg8",
              "Kg6",
              "Kh8",
              "Kf7",
              "Kh7",
              "g5",
              "Kh8",
              "Nf4",
              "Kh7",
              "g6+",
              "Kh6",
              "g7",
              "Kg5",
              "g8=Q+",
              "Kxf4",
              "Qg6",
              "Ke5",
              "Qf6+",
              "Ke4",
              "Ke6",
              "Kd3",
              "Qf4",
              "Kc3",
              "Qe4",
              "Kb3",
              "Qd4",
              "Kc2",
              "Qe3",
              "Kb2",
              "Qd3",
              "Ka2",
              "Qc3",
              "Kb1",
              "Qd2",
              "Ka1",
              "Kd5",
              "Kb1",
              "Kc4",
              "Ka1",
              "Kb3",
              "Kb1",
              "Qb2#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 449,
            "completion_tokens": 640,
            "total_tokens": 1089,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 449,
            "completion_tokens": 269,
            "total_tokens": 718,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 448,
            "completion_tokens": 327,
            "total_tokens": 775,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1346,
          "total_completion_tokens": 1236,
          "total_tokens": 2582
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 81,
            "turn_number": 41,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 449,
            "completion_tokens": 640,
            "total_tokens": 1089,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 81,
            "turn_number": 41,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 449,
            "completion_tokens": 269,
            "total_tokens": 718,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 81,
            "turn_number": 41,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 448,
            "completion_tokens": 327,
            "total_tokens": 775,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/3N2pp/6k1/8/5n2/4N1P1/7P/6K1 b - - 0 41"
    },
    {
      "turn": 84,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kg7",
          "aggressive_uci": null,
          "aggressive_response": "e4 Nf6 Nxf6+ Kxf6 f6 Qxf6+ Qxf6 Nxf6\nKxf6 Kg6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6\nKg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7\nKf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7\nKf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7\nKf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7\nKf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6\nKg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7\nKf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7\nKf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6\nKg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7\nKf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7\nKf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6\nKg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7 Kf7 Kf6 Kg7",
          "aggressive_tokens": {
            "prompt_tokens": 457,
            "completion_tokens": 640,
            "total_tokens": 1097,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kg5",
          "positional_uci": "g6g5",
          "positional_response": "42...Kg5 43. h4+ Kh5 44. Kg2 g5 45. Kh3 gxh4 46. g4+ Kg5 47. Nf3+ Kf4 48. Nd5+ Kxf3 49. Kxh4 Ke4 50. Nf6+ Kf4 51. Nxh7 Ng7 52. Nf6 Ne6 53. Kh5 Ng7+ 54. Kg6 Ne6 55. Kf7 Ng5+ 56. Kg6 Ne6 57. Kh5 Ng7+ 58. Kh4 Ne6 59. Nh5+ Ke5 60. Ng3 Kf6 61. Ne4+ Kg6 62. g5 Nxg5 63. Nxg5 *",
          "positional_tokens": {
            "prompt_tokens": 457,
            "completion_tokens": 176,
            "total_tokens": 633,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf3+",
            "Kf4",
            "Nd5+",
            "Kxf3",
            "Kxh4",
            "Ke4",
            "Nf6+",
            "Kf4",
            "Nxh7",
            "Ng7",
            "Nf6",
            "Ne6",
            "Kh5",
            "Ng7+",
            "Kg6",
            "Ne6",
            "Kf7",
            "Ng5+",
            "Kg6",
            "Ne6",
            "Kh5",
            "Ng7+",
            "Kh4",
            "Ne6",
            "Nh5+",
            "Ke5",
            "Ng3",
            "Kf6",
            "Ne4+",
            "Kg6",
            "g5",
            "Nxg5",
            "Nxg5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kg3",
          "neutral_uci": null,
          "neutral_response": "e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 Nxe4\nb5 Bb3 d5 dxe5 Be6 c3 Bc5 Nbd2 Nxf2 Rxf2 Bxf2+ Kxf2 f6 exf6 Qxf6 Nf1 O-O\nBxd5 Rad8 Bg5 Qf7 Bxe6 Qxe6 Bxd8 Rxd8 Qe2 Qf7 Kg1 Rf8 Ng5 Qf5 Qe6+ Qxe6 Nxe6 Rf7 Rd1 Re7 Nf4 Ne5 Nb7 Nc4\nNxa6 Ra7 Nc5 Ra3 Nxb5 Rxb3 Nd4 Rb2 Nc6 Ne5 Nxe5 fxe5 Kf7 Ne3 Ke6 Nc4 Kd5\nNe3+ Ke4 Ng4 Kd3 Ne5+ Kxc3 Nxc6 Kxc6 Kf6 Kg6 Kf5 Kh5 Kf4 g5+ Kf3 h5\nKg3 h4+ Kf3 g4+ Kf4 h3 g3 Kg6 Kxg4 Kh6 Kxh3 Kg6 Kg4 Kh6 Kf5 Kh5 g4+ Kh6 g5+ Kh7 Kf6 Kh8 Kf7 Kh7 g6+ Kh8 g7+ Kh7 g8=Q+ Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5# Kh6 Qg6# Kh5 Qg5",
          "neutral_tokens": {
            "prompt_tokens": 456,
            "completion_tokens": 640,
            "total_tokens": 1096,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "h4+",
            "Kf3",
            "g4+",
            "Kf4",
            "h3",
            "g3",
            "Kg6",
            "Kxg4",
            "Kh6",
            "Kxh3",
            "Kg6",
            "Kg4",
            "Kh6",
            "Kf5",
            "Kh5",
            "g4+",
            "Kh6",
            "g5+",
            "Kh7",
            "Kf6",
            "Kh8",
            "Kf7",
            "Kh7",
            "g6+",
            "Kh8",
            "g7+",
            "Kh7",
            "g8=Q+",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5#",
            "Kh6",
            "Qg6#",
            "Kh5",
            "Qg5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g6g5",
          "neutral_uci": null,
          "consensus_move": "g6g5",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf3+",
              "Kf4",
              "Nd5+",
              "Kxf3",
              "Kxh4",
              "Ke4",
              "Nf6+",
              "Kf4",
              "Nxh7",
              "Ng7",
              "Nf6",
              "Ne6",
              "Kh5",
              "Ng7+",
              "Kg6",
              "Ne6",
              "Kf7",
              "Ng5+",
              "Kg6",
              "Ne6",
              "Kh5",
              "Ng7+",
              "Kh4",
              "Ne6",
              "Nh5+",
              "Ke5",
              "Ng3",
              "Kf6",
              "Ne4+",
              "Kg6",
              "g5",
              "Nxg5",
              "Nxg5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "h4+",
              "Kf3",
              "g4+",
              "Kf4",
              "h3",
              "g3",
              "Kg6",
              "Kxg4",
              "Kh6",
              "Kxh3",
              "Kg6",
              "Kg4",
              "Kh6",
              "Kf5",
              "Kh5",
              "g4+",
              "Kh6",
              "g5+",
              "Kh7",
              "Kf6",
              "Kh8",
              "Kf7",
              "Kh7",
              "g6+",
              "Kh8",
              "g7+",
              "Kh7",
              "g8=Q+",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5#",
              "Kh6",
              "Qg6#",
              "Kh5",
              "Qg5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 457,
            "completion_tokens": 640,
            "total_tokens": 1097,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 457,
            "completion_tokens": 176,
            "total_tokens": 633,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 456,
            "completion_tokens": 640,
            "total_tokens": 1096,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1370,
          "total_completion_tokens": 1456,
          "total_tokens": 2826
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 83,
            "turn_number": 42,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 457,
            "completion_tokens": 640,
            "total_tokens": 1097,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 83,
            "turn_number": 42,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 457,
            "completion_tokens": 176,
            "total_tokens": 633,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 83,
            "turn_number": 42,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 456,
            "completion_tokens": 640,
            "total_tokens": 1096,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/6pp/4n1k1/4N3/8/4N1P1/7P/6K1 b - - 2 42"
    },
    {
      "turn": 86,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nd6+",
          "aggressive_uci": null,
          "aggressive_response": "e4 Nf6+ Kg6 Nf4+ Kf6\nNxe5+ Kxe5 Nxg7 Kf6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7\nNd6+ Kg6 Nf4+ Kf7 Nd6+ Kg6 Nf8+ Kf7 Nd6+ Kg",
          "aggressive_tokens": {
            "prompt_tokens": 465,
            "completion_tokens": 640,
            "total_tokens": 1105,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kh5",
          "positional_uci": "g5h5",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Nf3 Nf4 39.\nNe5+ Kf6 40. Nd7+ Kg6 41. g3 Ne6 42. Ne5+ Kg5 43. h4+ Kh5 44. Kh2 g5 45. Kh3 gxh4\n46. g4+ Kg5 47. Nf3+ Kf4 48. Nxh4 Kxe3 49. Nf5+ Kf4 50. Kh4 Ng5 51. Kh5 Nf7\n52. Nh6 Ne5 53. g5 Nf3 54. Nf7 Kf5 55. Kh6 Nxg5 56. Nxg5 *",
          "positional_tokens": {
            "prompt_tokens": 465,
            "completion_tokens": 464,
            "total_tokens": 929,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf7",
            "Nh6",
            "Ne5",
            "g5",
            "Nf3",
            "Nf7",
            "Kf5",
            "Kh6",
            "Nxg5",
            "Nxg5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kh5",
          "neutral_uci": "g5h5",
          "neutral_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5. O-O Nxe4 6. d4 b5 7. Bb3 d5 8. dxe5\nBe6 9. c3 Bc5 10. Nbd2 Nxf2 11. Rxf2 Bxf2+ 12. Kxf2 f6 13. exf6 Qxf6 14. Nf1\nO-O 15. Bxd5 Rad8 16. Bg5 Qf7 17. Bxe6 Qxe6 18. Bxd8 Rxd8 19. Qe2 Qf7 20. Kg1\nRf8 21. Ng5 Qf5 22. Qe6+ Qxe6 23. Nxe6 Rf7 24. Rd1 Re7 25. Nd8 Ne5 26. Nb7 Nc4\n27. Rd8+ Kf7 28. b3 Nb6 29. Nc5 Re2 30. Nxa6 Rxa2 31. Nxc7 Ra3 32. Nxb5 Rxb3\n33. Nd4 Rb2 34. Rb8 Kg6 35. c4 Nxc4 36. Rxb2 Nxb2 37. Ne3 Nd3 38. Nf3 Nf4 39.\nNe5+ Kf6 40. Nd7+ Kg6 41. g3 Ne6 42. Ne5+ Kg5 43. h4+ Kh5 44. Kh2 g5 45. Kh3 gxh4\n46. g4+ Kg5 47. Nf3+ Kf4 48. Nxh4 Kxe3 49. Nf5+ Kf4 50. Kh4 Ng5 51. Kh5 Nf7\n52. Nh6 Nxh6 53. Kxh6 Kxg4 54. Kxh7 *",
          "neutral_tokens": {
            "prompt_tokens": 464,
            "completion_tokens": 452,
            "total_tokens": 916,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf7",
            "Nh6",
            "Nxh6",
            "Kxh6",
            "Kxg4",
            "Kxh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g5h5",
          "neutral_uci": "g5h5",
          "consensus_move": "g5h5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf7",
              "Nh6",
              "Ne5",
              "g5",
              "Nf3",
              "Nf7",
              "Kf5",
              "Kh6",
              "Nxg5",
              "Nxg5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf7",
              "Nh6",
              "Nxh6",
              "Kxh6",
              "Kxg4",
              "Kxh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 465,
            "completion_tokens": 640,
            "total_tokens": 1105,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 465,
            "completion_tokens": 464,
            "total_tokens": 929,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 464,
            "completion_tokens": 452,
            "total_tokens": 916,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1394,
          "total_completion_tokens": 1556,
          "total_tokens": 2950
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 85,
            "turn_number": 43,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 465,
            "completion_tokens": 640,
            "total_tokens": 1105,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 85,
            "turn_number": 43,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 465,
            "completion_tokens": 464,
            "total_tokens": 929,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 85,
            "turn_number": 43,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 464,
            "completion_tokens": 452,
            "total_tokens": 916,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/6pp/4n3/4N1k1/7P/4N1P1/8/6K1 b - - 0 43"
    },
    {
      "turn": 88,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe5",
          "aggressive_uci": null,
          "aggressive_response": "e4 e5 Nxe5\nNxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe5 Nxe",
          "aggressive_tokens": {
            "prompt_tokens": 473,
            "completion_tokens": 640,
            "total_tokens": 1113,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g5",
          "positional_uci": "g7g5",
          "positional_response": "44... g5 45. g4#",
          "positional_tokens": {
            "prompt_tokens": 473,
            "completion_tokens": 11,
            "total_tokens": 484,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxe6",
          "neutral_uci": null,
          "neutral_response": "e4 e5 Nf6\nNc6 Bc5 Nxe4 d5 Be6 Nc3 Nxc3 bxc3 f6 exf6 Qxf6 Nf1 O-O Bxd5 Rad8 Bg5 Qf7\nBxe6 Qxe6 Bxd8 Rxd8 Qe2 Qf7 Kg1 Rf8 Ng5 Qf5 Qe6+ Qxe6 Nxe6 Rf7 Rd1 h6 Rd8+ Kh7 Nf8+ Kg8 Ng6+ Kh7 Nf8+ Kg8 Ng6+ Kh7 Nf8+ Kg8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8+ Kh8 Ng6+ Kh7 Nf8+ Kg8 Nf8",
          "neutral_tokens": {
            "prompt_tokens": 472,
            "completion_tokens": 640,
            "total_tokens": 1112,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxe6",
            "Bxd8",
            "Rxd8",
            "Qe2",
            "Qf7",
            "Kg1",
            "Rf8",
            "Ng5",
            "Qf5",
            "Qe6+",
            "Qxe6",
            "Nxe6",
            "Rf7",
            "Rd1",
            "h6",
            "Rd8+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8+",
            "Kh8",
            "Ng6+",
            "Kh7",
            "Nf8+",
            "Kg8",
            "Nf8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g7g5",
          "neutral_uci": null,
          "consensus_move": "g7g5",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [],
            "execute": []
          },
          "positional": {
            "full": [
              "g4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxe6",
              "Bxd8",
              "Rxd8",
              "Qe2",
              "Qf7",
              "Kg1",
              "Rf8",
              "Ng5",
              "Qf5",
              "Qe6+",
              "Qxe6",
              "Nxe6",
              "Rf7",
              "Rd1",
              "h6",
              "Rd8+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8+",
              "Kh8",
              "Ng6+",
              "Kh7",
              "Nf8+",
              "Kg8",
              "Nf8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 473,
            "completion_tokens": 640,
            "total_tokens": 1113,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 473,
            "completion_tokens": 11,
            "total_tokens": 484,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 472,
            "completion_tokens": 640,
            "total_tokens": 1112,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1418,
          "total_completion_tokens": 1291,
          "total_tokens": 2709
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 87,
            "turn_number": 44,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 473,
            "completion_tokens": 640,
            "total_tokens": 1113,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 87,
            "turn_number": 44,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 473,
            "completion_tokens": 11,
            "total_tokens": 484,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 87,
            "turn_number": 44,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 472,
            "completion_tokens": 640,
            "total_tokens": 1112,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/6pp/4n3/4NN1k/7P/6P1/8/6K1 b - - 2 44"
    }
  ],
  "white_errors": [],
  "black_errors": [],
  "white_plan_log": [],
  "black_plan_log": [],
  "timestamp": "2025-11-30T01:20:31.129826",
  "game_id": "gpt-3.5-turbo-instruct_vs_gpt-3.5-turbo-instruct_SC_11",
  "configuration": "single"
}