{
  "result": "Stockfish wins by disqualification (gpt-3.5-turbo-instruct failed to produce a legal move)",
  "white_player": "gpt-3.5-turbo-instruct",
  "black_player": "Stockfish",
  "white_score": 0.0,
  "black_score": 1.0,
  "total_moves": 110,
  "moves": [
    "d2d4",
    "f7f5",
    "g1f3",
    "g8f6",
    "c1g5",
    "e7e6",
    "b1d2",
    "f8e7",
    "g5f6",
    "e7f6",
    "e2e4",
    "g7g6",
    "h2h4",
    "d7d6",
    "c2c3",
    "f6g7",
    "f1d3",
    "b8d7",
    "d1e2",
    "d8e7",
    "e1c1",
    "f5e4",
    "d2e4",
    "d7f6",
    "e4g5",
    "e8d8",
    "h1e1",
    "h8e8",
    "g5h7",
    "f6h7",
    "d3g6",
    "e8f8",
    "g6h7",
    "g7h6",
    "f3g5",
    "h6g5",
    "h4g5",
    "e7h7",
    "e1h1",
    "h7g8",
    "e2h5",
    "b7b6",
    "h5h4",
    "g8g6",
    "h4h6",
    "g6h6",
    "g5h6",
    "f8h8",
    "g2g4",
    "c8b7",
    "h1h5",
    "d8e8",
    "g4g5",
    "e8f7",
    "d1g1",
    "a8g8",
    "h5h4",
    "a7a6",
    "h4f4",
    "f7e8",
    "f4f6",
    "e8e7",
    "g1g3",
    "g8g5",
    "g3g5",
    "e7f6",
    "g5g7",
    "b7e4",
    "g7c7",
    "b6b5",
    "c7a7",
    "d6d5",
    "a7a6",
    "e4d3",
    "c1d2",
    "d3f1",
    "d2e3",
    "h8h7",
    "e3f4",
    "h7h6",
    "a2a4",
    "h6h2",
    "f4g3",
    "h2h3",
    "g3f4",
    "b5b4",
    "a6a8",
    "b4c3",
    "b2c3",
    "h3h4",
    "f4g3",
    "h4h3",
    "g3g4",
    "h3h1",
    "a8f8",
    "f6g7",
    "f8f3",
    "f1e2",
    "g4g3",
    "h1g1",
    "g3h2",
    "g1g6",
    "f3e3",
    "e2d1",
    "a4a5",
    "g7f6",
    "a5a6",
    "d1c2",
    "a6a7",
    "g6g8"
  ],
  "game_history": [
    {
      "move_number": 1,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2d4",
      "move_san": "d4",
      "fen_after": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1"
    },
    {
      "move_number": 2,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f7f5",
      "move_san": "f5",
      "fen_after": "rnbqkbnr/ppppp1pp/8/5p2/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "move_number": 3,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1f3",
      "move_san": "Nf3",
      "fen_after": "rnbqkbnr/ppppp1pp/8/5p2/3P4/5N2/PPP1PPPP/RNBQKB1R b KQkq - 1 2"
    },
    {
      "move_number": 4,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g8f6",
      "move_san": "Nf6",
      "fen_after": "rnbqkb1r/ppppp1pp/5n2/5p2/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "move_number": 5,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c1g5",
      "move_san": "Bg5",
      "fen_after": "rnbqkb1r/ppppp1pp/5n2/5pB1/3P4/5N2/PPP1PPPP/RN1QKB1R b KQkq - 3 3"
    },
    {
      "move_number": 6,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e7e6",
      "move_san": "e6",
      "fen_after": "rnbqkb1r/pppp2pp/4pn2/5pB1/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 4"
    },
    {
      "move_number": 7,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b1d2",
      "move_san": "Nbd2",
      "fen_after": "rnbqkb1r/pppp2pp/4pn2/5pB1/3P4/5N2/PPPNPPPP/R2QKB1R b KQkq - 1 4"
    },
    {
      "move_number": 8,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f8e7",
      "move_san": "Be7",
      "fen_after": "rnbqk2r/ppppb1pp/4pn2/5pB1/3P4/5N2/PPPNPPPP/R2QKB1R w KQkq - 2 5"
    },
    {
      "move_number": 9,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g5f6",
      "move_san": "Bxf6",
      "fen_after": "rnbqk2r/ppppb1pp/4pB2/5p2/3P4/5N2/PPPNPPPP/R2QKB1R b KQkq - 0 5"
    },
    {
      "move_number": 10,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e7f6",
      "move_san": "Bxf6",
      "fen_after": "rnbqk2r/pppp2pp/4pb2/5p2/3P4/5N2/PPPNPPPP/R2QKB1R w KQkq - 0 6"
    },
    {
      "move_number": 11,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2e4",
      "move_san": "e4",
      "fen_after": "rnbqk2r/pppp2pp/4pb2/5p2/3PP3/5N2/PPPN1PPP/R2QKB1R b KQkq - 0 6"
    },
    {
      "move_number": 12,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g7g6",
      "move_san": "g6",
      "fen_after": "rnbqk2r/pppp3p/4pbp1/5p2/3PP3/5N2/PPPN1PPP/R2QKB1R w KQkq - 0 7"
    },
    {
      "move_number": 13,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h2h4",
      "move_san": "h4",
      "fen_after": "rnbqk2r/pppp3p/4pbp1/5p2/3PP2P/5N2/PPPN1PP1/R2QKB1R b KQkq - 0 7"
    },
    {
      "move_number": 14,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d7d6",
      "move_san": "d6",
      "fen_after": "rnbqk2r/ppp4p/3ppbp1/5p2/3PP2P/5N2/PPPN1PP1/R2QKB1R w KQkq - 0 8"
    },
    {
      "move_number": 15,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c2c3",
      "move_san": "c3",
      "fen_after": "rnbqk2r/ppp4p/3ppbp1/5p2/3PP2P/2P2N2/PP1N1PP1/R2QKB1R b KQkq - 0 8"
    },
    {
      "move_number": 16,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f6g7",
      "move_san": "Bg7",
      "fen_after": "rnbqk2r/ppp3bp/3pp1p1/5p2/3PP2P/2P2N2/PP1N1PP1/R2QKB1R w KQkq - 1 9"
    },
    {
      "move_number": 17,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f1d3",
      "move_san": "Bd3",
      "fen_after": "rnbqk2r/ppp3bp/3pp1p1/5p2/3PP2P/2PB1N2/PP1N1PP1/R2QK2R b KQkq - 2 9"
    },
    {
      "move_number": 18,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b8d7",
      "move_san": "Nd7",
      "fen_after": "r1bqk2r/pppn2bp/3pp1p1/5p2/3PP2P/2PB1N2/PP1N1PP1/R2QK2R w KQkq - 3 10"
    },
    {
      "move_number": 19,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1e2",
      "move_san": "Qe2",
      "fen_after": "r1bqk2r/pppn2bp/3pp1p1/5p2/3PP2P/2PB1N2/PP1NQPP1/R3K2R b KQkq - 4 10"
    },
    {
      "move_number": 20,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d8e7",
      "move_san": "Qe7",
      "fen_after": "r1b1k2r/pppnq1bp/3pp1p1/5p2/3PP2P/2PB1N2/PP1NQPP1/R3K2R w KQkq - 5 11"
    },
    {
      "move_number": 21,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1c1",
      "move_san": "O-O-O",
      "fen_after": "r1b1k2r/pppnq1bp/3pp1p1/5p2/3PP2P/2PB1N2/PP1NQPP1/2KR3R b kq - 6 11"
    },
    {
      "move_number": 22,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f5e4",
      "move_san": "fxe4",
      "fen_after": "r1b1k2r/pppnq1bp/3pp1p1/8/3Pp2P/2PB1N2/PP1NQPP1/2KR3R w kq - 0 12"
    },
    {
      "move_number": 23,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2e4",
      "move_san": "Nxe4",
      "fen_after": "r1b1k2r/pppnq1bp/3pp1p1/8/3PN2P/2PB1N2/PP2QPP1/2KR3R b kq - 0 12"
    },
    {
      "move_number": 24,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d7f6",
      "move_san": "Nf6",
      "fen_after": "r1b1k2r/ppp1q1bp/3ppnp1/8/3PN2P/2PB1N2/PP2QPP1/2KR3R w kq - 1 13"
    },
    {
      "move_number": 25,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e4g5",
      "move_san": "Neg5",
      "fen_after": "r1b1k2r/ppp1q1bp/3ppnp1/6N1/3P3P/2PB1N2/PP2QPP1/2KR3R b kq - 2 13"
    },
    {
      "move_number": 26,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e8d8",
      "move_san": "Kd8",
      "fen_after": "r1bk3r/ppp1q1bp/3ppnp1/6N1/3P3P/2PB1N2/PP2QPP1/2KR3R w - - 3 14"
    },
    {
      "move_number": 27,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h1e1",
      "move_san": "Rhe1",
      "fen_after": "r1bk3r/ppp1q1bp/3ppnp1/6N1/3P3P/2PB1N2/PP2QPP1/2KRR3 b - - 4 14"
    },
    {
      "move_number": 28,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h8e8",
      "move_san": "Re8",
      "fen_after": "r1bkr3/ppp1q1bp/3ppnp1/6N1/3P3P/2PB1N2/PP2QPP1/2KRR3 w - - 5 15"
    },
    {
      "move_number": 29,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g5h7",
      "move_san": "Nxh7",
      "fen_after": "r1bkr3/ppp1q1bN/3ppnp1/8/3P3P/2PB1N2/PP2QPP1/2KRR3 b - - 0 15"
    },
    {
      "move_number": 30,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f6h7",
      "move_san": "Nxh7",
      "fen_after": "r1bkr3/ppp1q1bn/3pp1p1/8/3P3P/2PB1N2/PP2QPP1/2KRR3 w - - 0 16"
    },
    {
      "move_number": 31,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d3g6",
      "move_san": "Bxg6",
      "fen_after": "r1bkr3/ppp1q1bn/3pp1B1/8/3P3P/2P2N2/PP2QPP1/2KRR3 b - - 0 16"
    },
    {
      "move_number": 32,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e8f8",
      "move_san": "Rf8",
      "fen_after": "r1bk1r2/ppp1q1bn/3pp1B1/8/3P3P/2P2N2/PP2QPP1/2KRR3 w - - 1 17"
    },
    {
      "move_number": 33,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g6h7",
      "move_san": "Bxh7",
      "fen_after": "r1bk1r2/ppp1q1bB/3pp3/8/3P3P/2P2N2/PP2QPP1/2KRR3 b - - 0 17"
    },
    {
      "move_number": 34,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g7h6",
      "move_san": "Bh6+",
      "fen_after": "r1bk1r2/ppp1q2B/3pp2b/8/3P3P/2P2N2/PP2QPP1/2KRR3 w - - 1 18"
    },
    {
      "move_number": 35,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f3g5",
      "move_san": "Ng5",
      "fen_after": "r1bk1r2/ppp1q2B/3pp2b/6N1/3P3P/2P5/PP2QPP1/2KRR3 b - - 2 18"
    },
    {
      "move_number": 36,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h6g5",
      "move_san": "Bxg5+",
      "fen_after": "r1bk1r2/ppp1q2B/3pp3/6b1/3P3P/2P5/PP2QPP1/2KRR3 w - - 0 19"
    },
    {
      "move_number": 37,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h4g5",
      "move_san": "hxg5",
      "fen_after": "r1bk1r2/ppp1q2B/3pp3/6P1/3P4/2P5/PP2QPP1/2KRR3 b - - 0 19"
    },
    {
      "move_number": 38,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e7h7",
      "move_san": "Qxh7",
      "fen_after": "r1bk1r2/ppp4q/3pp3/6P1/3P4/2P5/PP2QPP1/2KRR3 w - - 0 20"
    },
    {
      "move_number": 39,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e1h1",
      "move_san": "Rh1",
      "fen_after": "r1bk1r2/ppp4q/3pp3/6P1/3P4/2P5/PP2QPP1/2KR3R b - - 1 20"
    },
    {
      "move_number": 40,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h7g8",
      "move_san": "Qg8",
      "fen_after": "r1bk1rq1/ppp5/3pp3/6P1/3P4/2P5/PP2QPP1/2KR3R w - - 2 21"
    },
    {
      "move_number": 41,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e2h5",
      "move_san": "Qh5",
      "fen_after": "r1bk1rq1/ppp5/3pp3/6PQ/3P4/2P5/PP3PP1/2KR3R b - - 3 21"
    },
    {
      "move_number": 42,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b7b6",
      "move_san": "b6",
      "fen_after": "r1bk1rq1/p1p5/1p1pp3/6PQ/3P4/2P5/PP3PP1/2KR3R w - - 0 22"
    },
    {
      "move_number": 43,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h5h4",
      "move_san": "Qh4",
      "fen_after": "r1bk1rq1/p1p5/1p1pp3/6P1/3P3Q/2P5/PP3PP1/2KR3R b - - 1 22"
    },
    {
      "move_number": 44,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g8g6",
      "move_san": "Qg6",
      "fen_after": "r1bk1r2/p1p5/1p1pp1q1/6P1/3P3Q/2P5/PP3PP1/2KR3R w - - 2 23"
    },
    {
      "move_number": 45,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h4h6",
      "move_san": "Qh6",
      "fen_after": "r1bk1r2/p1p5/1p1pp1qQ/6P1/3P4/2P5/PP3PP1/2KR3R b - - 3 23"
    },
    {
      "move_number": 46,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g6h6",
      "move_san": "Qxh6",
      "fen_after": "r1bk1r2/p1p5/1p1pp2q/6P1/3P4/2P5/PP3PP1/2KR3R w - - 0 24"
    },
    {
      "move_number": 47,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g5h6",
      "move_san": "gxh6",
      "fen_after": "r1bk1r2/p1p5/1p1pp2P/8/3P4/2P5/PP3PP1/2KR3R b - - 0 24"
    },
    {
      "move_number": 48,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f8h8",
      "move_san": "Rh8",
      "fen_after": "r1bk3r/p1p5/1p1pp2P/8/3P4/2P5/PP3PP1/2KR3R w - - 1 25"
    },
    {
      "move_number": 49,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g2g4",
      "move_san": "g4",
      "fen_after": "r1bk3r/p1p5/1p1pp2P/8/3P2P1/2P5/PP3P2/2KR3R b - - 0 25"
    },
    {
      "move_number": 50,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "c8b7",
      "move_san": "Bb7",
      "fen_after": "r2k3r/pbp5/1p1pp2P/8/3P2P1/2P5/PP3P2/2KR3R w - - 1 26"
    },
    {
      "move_number": 51,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h1h5",
      "move_san": "Rh5",
      "fen_after": "r2k3r/pbp5/1p1pp2P/7R/3P2P1/2P5/PP3P2/2KR4 b - - 2 26"
    },
    {
      "move_number": 52,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d8e8",
      "move_san": "Ke8",
      "fen_after": "r3k2r/pbp5/1p1pp2P/7R/3P2P1/2P5/PP3P2/2KR4 w - - 3 27"
    },
    {
      "move_number": 53,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g4g5",
      "move_san": "g5",
      "fen_after": "r3k2r/pbp5/1p1pp2P/6PR/3P4/2P5/PP3P2/2KR4 b - - 0 27"
    },
    {
      "move_number": 54,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e8f7",
      "move_san": "Kf7",
      "fen_after": "r6r/pbp2k2/1p1pp2P/6PR/3P4/2P5/PP3P2/2KR4 w - - 1 28"
    },
    {
      "move_number": 55,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d1g1",
      "move_san": "Rg1",
      "fen_after": "r6r/pbp2k2/1p1pp2P/6PR/3P4/2P5/PP3P2/2K3R1 b - - 2 28"
    },
    {
      "move_number": 56,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "a8g8",
      "move_san": "Rag8",
      "fen_after": "6rr/pbp2k2/1p1pp2P/6PR/3P4/2P5/PP3P2/2K3R1 w - - 3 29"
    },
    {
      "move_number": 57,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h5h4",
      "move_san": "Rh4",
      "fen_after": "6rr/pbp2k2/1p1pp2P/6P1/3P3R/2P5/PP3P2/2K3R1 b - - 4 29"
    },
    {
      "move_number": 58,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "a7a6",
      "move_san": "a6",
      "fen_after": "6rr/1bp2k2/pp1pp2P/6P1/3P3R/2P5/PP3P2/2K3R1 w - - 0 30"
    },
    {
      "move_number": 59,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "h4f4",
      "move_san": "Rf4+",
      "fen_after": "6rr/1bp2k2/pp1pp2P/6P1/3P1R2/2P5/PP3P2/2K3R1 b - - 1 30"
    },
    {
      "move_number": 60,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f7e8",
      "move_san": "Ke8",
      "fen_after": "4k1rr/1bp5/pp1pp2P/6P1/3P1R2/2P5/PP3P2/2K3R1 w - - 2 31"
    },
    {
      "move_number": 61,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f4f6",
      "move_san": "Rf6",
      "fen_after": "4k1rr/1bp5/pp1ppR1P/6P1/3P4/2P5/PP3P2/2K3R1 b - - 3 31"
    },
    {
      "move_number": 62,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e8e7",
      "move_san": "Ke7",
      "fen_after": "6rr/1bp1k3/pp1ppR1P/6P1/3P4/2P5/PP3P2/2K3R1 w - - 4 32"
    },
    {
      "move_number": 63,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g1g3",
      "move_san": "Rg3",
      "fen_after": "6rr/1bp1k3/pp1ppR1P/6P1/3P4/2P3R1/PP3P2/2K5 b - - 5 32"
    },
    {
      "move_number": 64,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g8g5",
      "move_san": "Rxg5",
      "fen_after": "7r/1bp1k3/pp1ppR1P/6r1/3P4/2P3R1/PP3P2/2K5 w - - 0 33"
    },
    {
      "move_number": 65,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g3g5",
      "move_san": "Rxg5",
      "fen_after": "7r/1bp1k3/pp1ppR1P/6R1/3P4/2P5/PP3P2/2K5 b - - 0 33"
    },
    {
      "move_number": 66,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e7f6",
      "move_san": "Kxf6",
      "fen_after": "7r/1bp5/pp1ppk1P/6R1/3P4/2P5/PP3P2/2K5 w - - 0 34"
    },
    {
      "move_number": 67,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g5g7",
      "move_san": "Rg7",
      "fen_after": "7r/1bp3R1/pp1ppk1P/8/3P4/2P5/PP3P2/2K5 b - - 1 34"
    },
    {
      "move_number": 68,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b7e4",
      "move_san": "Be4",
      "fen_after": "7r/2p3R1/pp1ppk1P/8/3Pb3/2P5/PP3P2/2K5 w - - 2 35"
    },
    {
      "move_number": 69,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g7c7",
      "move_san": "Rxc7",
      "fen_after": "7r/2R5/pp1ppk1P/8/3Pb3/2P5/PP3P2/2K5 b - - 0 35"
    },
    {
      "move_number": 70,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b6b5",
      "move_san": "b5",
      "fen_after": "7r/2R5/p2ppk1P/1p6/3Pb3/2P5/PP3P2/2K5 w - - 0 36"
    },
    {
      "move_number": 71,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c7a7",
      "move_san": "Ra7",
      "fen_after": "7r/R7/p2ppk1P/1p6/3Pb3/2P5/PP3P2/2K5 b - - 1 36"
    },
    {
      "move_number": 72,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d6d5",
      "move_san": "d5",
      "fen_after": "7r/R7/p3pk1P/1p1p4/3Pb3/2P5/PP3P2/2K5 w - - 0 37"
    },
    {
      "move_number": 73,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a7a6",
      "move_san": "Rxa6",
      "fen_after": "7r/8/R3pk1P/1p1p4/3Pb3/2P5/PP3P2/2K5 b - - 0 37"
    },
    {
      "move_number": 74,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e4d3",
      "move_san": "Bd3",
      "fen_after": "7r/8/R3pk1P/1p1p4/3P4/2Pb4/PP3P2/2K5 w - - 1 38"
    },
    {
      "move_number": 75,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "c1d2",
      "move_san": "Kd2",
      "fen_after": "7r/8/R3pk1P/1p1p4/3P4/2Pb4/PP1K1P2/8 b - - 2 38"
    },
    {
      "move_number": 76,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d3f1",
      "move_san": "Bf1",
      "fen_after": "7r/8/R3pk1P/1p1p4/3P4/2P5/PP1K1P2/5b2 w - - 3 39"
    },
    {
      "move_number": 77,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "d2e3",
      "move_san": "Ke3",
      "fen_after": "7r/8/R3pk1P/1p1p4/3P4/2P1K3/PP3P2/5b2 b - - 4 39"
    },
    {
      "move_number": 78,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h8h7",
      "move_san": "Rh7",
      "fen_after": "8/7r/R3pk1P/1p1p4/3P4/2P1K3/PP3P2/5b2 w - - 5 40"
    },
    {
      "move_number": 79,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "e3f4",
      "move_san": "Kf4",
      "fen_after": "8/7r/R3pk1P/1p1p4/3P1K2/2P5/PP3P2/5b2 b - - 6 40"
    },
    {
      "move_number": 80,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h7h6",
      "move_san": "Rxh6",
      "fen_after": "8/8/R3pk1r/1p1p4/3P1K2/2P5/PP3P2/5b2 w - - 0 41"
    },
    {
      "move_number": 81,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a2a4",
      "move_san": "a4",
      "fen_after": "8/8/R3pk1r/1p1p4/P2P1K2/2P5/1P3P2/5b2 b - - 0 41"
    },
    {
      "move_number": 82,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h6h2",
      "move_san": "Rh2",
      "fen_after": "8/8/R3pk2/1p1p4/P2P1K2/2P5/1P3P1r/5b2 w - - 1 42"
    },
    {
      "move_number": 83,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f4g3",
      "move_san": "Kg3",
      "fen_after": "8/8/R3pk2/1p1p4/P2P4/2P3K1/1P3P1r/5b2 b - - 2 42"
    },
    {
      "move_number": 84,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h2h3",
      "move_san": "Rh3+",
      "fen_after": "8/8/R3pk2/1p1p4/P2P4/2P3Kr/1P3P2/5b2 w - - 3 43"
    },
    {
      "move_number": 85,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g3f4",
      "move_san": "Kf4",
      "fen_after": "8/8/R3pk2/1p1p4/P2P1K2/2P4r/1P3P2/5b2 b - - 4 43"
    },
    {
      "move_number": 86,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b5b4",
      "move_san": "b4",
      "fen_after": "8/8/R3pk2/3p4/Pp1P1K2/2P4r/1P3P2/5b2 w - - 0 44"
    },
    {
      "move_number": 87,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a6a8",
      "move_san": "Ra8",
      "fen_after": "R7/8/4pk2/3p4/Pp1P1K2/2P4r/1P3P2/5b2 b - - 1 44"
    },
    {
      "move_number": 88,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "b4c3",
      "move_san": "bxc3",
      "fen_after": "R7/8/4pk2/3p4/P2P1K2/2p4r/1P3P2/5b2 w - - 0 45"
    },
    {
      "move_number": 89,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "b2c3",
      "move_san": "bxc3",
      "fen_after": "R7/8/4pk2/3p4/P2P1K2/2P4r/5P2/5b2 b - - 0 45"
    },
    {
      "move_number": 90,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h3h4",
      "move_san": "Rh4+",
      "fen_after": "R7/8/4pk2/3p4/P2P1K1r/2P5/5P2/5b2 w - - 1 46"
    },
    {
      "move_number": 91,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f4g3",
      "move_san": "Kg3",
      "fen_after": "R7/8/4pk2/3p4/P2P3r/2P3K1/5P2/5b2 b - - 2 46"
    },
    {
      "move_number": 92,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h4h3",
      "move_san": "Rh3+",
      "fen_after": "R7/8/4pk2/3p4/P2P4/2P3Kr/5P2/5b2 w - - 3 47"
    },
    {
      "move_number": 93,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g3g4",
      "move_san": "Kg4",
      "fen_after": "R7/8/4pk2/3p4/P2P2K1/2P4r/5P2/5b2 b - - 4 47"
    },
    {
      "move_number": 94,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h3h1",
      "move_san": "Rh1",
      "fen_after": "R7/8/4pk2/3p4/P2P2K1/2P5/5P2/5b1r w - - 5 48"
    },
    {
      "move_number": 95,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a8f8",
      "move_san": "Rf8+",
      "fen_after": "5R2/8/4pk2/3p4/P2P2K1/2P5/5P2/5b1r b - - 6 48"
    },
    {
      "move_number": 96,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f6g7",
      "move_san": "Kg7",
      "fen_after": "5R2/6k1/4p3/3p4/P2P2K1/2P5/5P2/5b1r w - - 7 49"
    },
    {
      "move_number": 97,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f8f3",
      "move_san": "Rf3",
      "fen_after": "8/6k1/4p3/3p4/P2P2K1/2P2R2/5P2/5b1r b - - 8 49"
    },
    {
      "move_number": 98,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "f1e2",
      "move_san": "Be2",
      "fen_after": "8/6k1/4p3/3p4/P2P2K1/2P2R2/4bP2/7r w - - 9 50"
    },
    {
      "move_number": 99,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g4g3",
      "move_san": "Kg3",
      "fen_after": "8/6k1/4p3/3p4/P2P4/2P2RK1/4bP2/7r b - - 10 50"
    },
    {
      "move_number": 100,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "h1g1",
      "move_san": "Rg1+",
      "fen_after": "8/6k1/4p3/3p4/P2P4/2P2RK1/4bP2/6r1 w - - 11 51"
    },
    {
      "move_number": 101,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "g3h2",
      "move_san": "Kh2",
      "fen_after": "8/6k1/4p3/3p4/P2P4/2P2R2/4bP1K/6r1 b - - 12 51"
    },
    {
      "move_number": 102,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g1g6",
      "move_san": "Rg6",
      "fen_after": "8/6k1/4p1r1/3p4/P2P4/2P2R2/4bP1K/8 w - - 13 52"
    },
    {
      "move_number": 103,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "f3e3",
      "move_san": "Re3",
      "fen_after": "8/6k1/4p1r1/3p4/P2P4/2P1R3/4bP1K/8 b - - 14 52"
    },
    {
      "move_number": 104,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "e2d1",
      "move_san": "Bd1",
      "fen_after": "8/6k1/4p1r1/3p4/P2P4/2P1R3/5P1K/3b4 w - - 15 53"
    },
    {
      "move_number": 105,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a4a5",
      "move_san": "a5",
      "fen_after": "8/6k1/4p1r1/P2p4/3P4/2P1R3/5P1K/3b4 b - - 0 53"
    },
    {
      "move_number": 106,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g7f6",
      "move_san": "Kf6",
      "fen_after": "8/8/4pkr1/P2p4/3P4/2P1R3/5P1K/3b4 w - - 1 54"
    },
    {
      "move_number": 107,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a5a6",
      "move_san": "a6",
      "fen_after": "8/8/P3pkr1/3p4/3P4/2P1R3/5P1K/3b4 b - - 0 54"
    },
    {
      "move_number": 108,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "d1c2",
      "move_san": "Bc2",
      "fen_after": "8/8/P3pkr1/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 55"
    },
    {
      "move_number": 109,
      "player": "gpt-3.5-turbo-instruct",
      "color": "white",
      "move_uci": "a6a7",
      "move_san": "a7",
      "fen_after": "8/P7/4pkr1/3p4/3P4/2P1R3/2b2P1K/8 b - - 0 55"
    },
    {
      "move_number": 110,
      "player": "Stockfish",
      "color": "black",
      "move_uci": "g6g8",
      "move_san": "Rg8",
      "fen_after": "6r1/P7/4pk2/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 56"
    }
  ],
  "final_fen": "6r1/P7/4pk2/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 56",
  "white_tokens": {
    "prompt_tokens": 55049,
    "completion_tokens": 75785,
    "total_tokens": 130834
  },
  "black_tokens": {
    "prompt_tokens": 0,
    "completion_tokens": 0,
    "total_tokens": 0
  },
  "white_token_log": [
    {
      "turn": 1,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 633,
          "total_tokens": 743,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 329,
        "total_completion_tokens": 1913,
        "total_tokens": 2242
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 110,
          "completion_tokens": 640,
          "total_tokens": 750,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 110,
          "completion_tokens": 633,
          "total_tokens": 743,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 109,
          "completion_tokens": 640,
          "total_tokens": 749,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 3,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 411,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 347,
        "total_completion_tokens": 1691,
        "total_tokens": 2038
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 116,
          "completion_tokens": 411,
          "total_tokens": 527,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 116,
          "completion_tokens": 640,
          "total_tokens": 756,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 115,
          "completion_tokens": 640,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 5,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 374,
        "total_completion_tokens": 1920,
        "total_tokens": 2294
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 125,
          "completion_tokens": 640,
          "total_tokens": 765,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 124,
          "completion_tokens": 640,
          "total_tokens": 764,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 7,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 316,
          "total_tokens": 449,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 398,
        "total_completion_tokens": 1596,
        "total_tokens": 1994
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 133,
          "completion_tokens": 316,
          "total_tokens": 449,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 133,
          "completion_tokens": 640,
          "total_tokens": 773,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 132,
          "completion_tokens": 640,
          "total_tokens": 772,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 9,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 441,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 505,
          "total_tokens": 646,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 172,
          "total_tokens": 312,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 422,
        "total_completion_tokens": 1118,
        "total_tokens": 1540
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 141,
          "completion_tokens": 441,
          "total_tokens": 582,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 141,
          "completion_tokens": 505,
          "total_tokens": 646,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 140,
          "completion_tokens": 172,
          "total_tokens": 312,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 11,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 640,
          "total_tokens": 789,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 449,
        "total_completion_tokens": 1920,
        "total_tokens": 2369
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 150,
          "completion_tokens": 640,
          "total_tokens": 790,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 149,
          "completion_tokens": 640,
          "total_tokens": 789,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 13,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 381,
          "total_tokens": 538,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 363,
          "total_tokens": 520,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 640,
          "total_tokens": 796,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 470,
        "total_completion_tokens": 1384,
        "total_tokens": 1854
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 157,
          "completion_tokens": 381,
          "total_tokens": 538,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 157,
          "completion_tokens": 363,
          "total_tokens": 520,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 156,
          "completion_tokens": 640,
          "total_tokens": 796,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 15,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 164,
          "completion_tokens": 640,
          "total_tokens": 804,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 164,
          "completion_tokens": 342,
          "total_tokens": 506,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 163,
          "completion_tokens": 427,
          "total_tokens": 590,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 491,
        "total_completion_tokens": 1409,
        "total_tokens": 1900
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 164,
          "completion_tokens": 640,
          "total_tokens": 804,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 164,
          "completion_tokens": 342,
          "total_tokens": 506,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 163,
          "completion_tokens": 427,
          "total_tokens": 590,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 17,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 172,
          "completion_tokens": 640,
          "total_tokens": 812,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 172,
          "completion_tokens": 640,
          "total_tokens": 812,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 515,
        "total_completion_tokens": 1920,
        "total_tokens": 2435
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 172,
          "completion_tokens": 640,
          "total_tokens": 812,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 172,
          "completion_tokens": 640,
          "total_tokens": 812,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 171,
          "completion_tokens": 640,
          "total_tokens": 811,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 19,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 536,
        "total_completion_tokens": 1920,
        "total_tokens": 2456
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 179,
          "completion_tokens": 640,
          "total_tokens": 819,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 178,
          "completion_tokens": 640,
          "total_tokens": 818,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 21,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 285,
          "total_tokens": 473,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 217,
          "total_tokens": 405,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 200,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 563,
        "total_completion_tokens": 702,
        "total_tokens": 1265
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 188,
          "completion_tokens": 285,
          "total_tokens": 473,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 188,
          "completion_tokens": 217,
          "total_tokens": 405,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 187,
          "completion_tokens": 200,
          "total_tokens": 387,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 23,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 640,
          "total_tokens": 837,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 512,
          "total_tokens": 709,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 393,
          "total_tokens": 589,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 590,
        "total_completion_tokens": 1545,
        "total_tokens": 2135
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 197,
          "completion_tokens": 640,
          "total_tokens": 837,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 197,
          "completion_tokens": 512,
          "total_tokens": 709,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 196,
          "completion_tokens": 393,
          "total_tokens": 589,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 25,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 124,
          "total_tokens": 330,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 365,
          "total_tokens": 570,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 617,
        "total_completion_tokens": 1129,
        "total_tokens": 1746
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 206,
          "completion_tokens": 640,
          "total_tokens": 846,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 206,
          "completion_tokens": 124,
          "total_tokens": 330,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 205,
          "completion_tokens": 365,
          "total_tokens": 570,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 27,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 214,
          "completion_tokens": 640,
          "total_tokens": 854,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 214,
          "completion_tokens": 365,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 213,
          "completion_tokens": 162,
          "total_tokens": 375,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 641,
        "total_completion_tokens": 1167,
        "total_tokens": 1808
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 214,
          "completion_tokens": 640,
          "total_tokens": 854,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 214,
          "completion_tokens": 365,
          "total_tokens": 579,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 213,
          "completion_tokens": 162,
          "total_tokens": 375,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 29,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 283,
          "total_tokens": 505,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 308,
          "total_tokens": 530,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 665,
        "total_completion_tokens": 1231,
        "total_tokens": 1896
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 222,
          "completion_tokens": 283,
          "total_tokens": 505,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 222,
          "completion_tokens": 308,
          "total_tokens": 530,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 221,
          "completion_tokens": 640,
          "total_tokens": 861,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 31,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 209,
          "total_tokens": 440,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 514,
          "total_tokens": 744,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 692,
        "total_completion_tokens": 1363,
        "total_tokens": 2055
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 231,
          "completion_tokens": 640,
          "total_tokens": 871,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 231,
          "completion_tokens": 209,
          "total_tokens": 440,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 230,
          "completion_tokens": 514,
          "total_tokens": 744,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 33,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 241,
          "completion_tokens": 640,
          "total_tokens": 881,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 241,
          "completion_tokens": 640,
          "total_tokens": 881,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 722,
        "total_completion_tokens": 1920,
        "total_tokens": 2642
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 241,
          "completion_tokens": 640,
          "total_tokens": 881,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 241,
          "completion_tokens": 640,
          "total_tokens": 881,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 240,
          "completion_tokens": 640,
          "total_tokens": 880,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 35,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 149,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 329,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 640,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 752,
        "total_completion_tokens": 1118,
        "total_tokens": 1870
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 251,
          "completion_tokens": 149,
          "total_tokens": 400,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 251,
          "completion_tokens": 329,
          "total_tokens": 580,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 250,
          "completion_tokens": 640,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 37,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 261,
          "completion_tokens": 640,
          "total_tokens": 901,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 261,
          "completion_tokens": 640,
          "total_tokens": 901,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 260,
          "completion_tokens": 353,
          "total_tokens": 613,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 782,
        "total_completion_tokens": 1633,
        "total_tokens": 2415
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 261,
          "completion_tokens": 640,
          "total_tokens": 901,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 261,
          "completion_tokens": 640,
          "total_tokens": 901,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 260,
          "completion_tokens": 353,
          "total_tokens": 613,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 39,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 271,
          "completion_tokens": 194,
          "total_tokens": 465,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 271,
          "completion_tokens": 640,
          "total_tokens": 911,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 270,
          "completion_tokens": 252,
          "total_tokens": 522,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 812,
        "total_completion_tokens": 1086,
        "total_tokens": 1898
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 271,
          "completion_tokens": 194,
          "total_tokens": 465,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 271,
          "completion_tokens": 640,
          "total_tokens": 911,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 270,
          "completion_tokens": 252,
          "total_tokens": 522,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 41,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 279,
          "completion_tokens": 452,
          "total_tokens": 731,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 279,
          "completion_tokens": 44,
          "total_tokens": 323,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 278,
          "completion_tokens": 8,
          "total_tokens": 286,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 836,
        "total_completion_tokens": 504,
        "total_tokens": 1340
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 279,
          "completion_tokens": 452,
          "total_tokens": 731,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 279,
          "completion_tokens": 44,
          "total_tokens": 323,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 278,
          "completion_tokens": 8,
          "total_tokens": 286,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 43,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 287,
          "completion_tokens": 640,
          "total_tokens": 927,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 287,
          "completion_tokens": 108,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 286,
          "completion_tokens": 500,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 860,
        "total_completion_tokens": 1248,
        "total_tokens": 2108
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 287,
          "completion_tokens": 640,
          "total_tokens": 927,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 287,
          "completion_tokens": 108,
          "total_tokens": 395,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 286,
          "completion_tokens": 500,
          "total_tokens": 786,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 45,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 296,
          "completion_tokens": 304,
          "total_tokens": 600,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 296,
          "completion_tokens": 640,
          "total_tokens": 936,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 295,
          "completion_tokens": 640,
          "total_tokens": 935,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 887,
        "total_completion_tokens": 1584,
        "total_tokens": 2471
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 296,
          "completion_tokens": 304,
          "total_tokens": 600,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 296,
          "completion_tokens": 640,
          "total_tokens": 936,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 295,
          "completion_tokens": 640,
          "total_tokens": 935,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 47,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 306,
          "completion_tokens": 629,
          "total_tokens": 935,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 306,
          "completion_tokens": 166,
          "total_tokens": 472,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 305,
          "completion_tokens": 640,
          "total_tokens": 945,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 917,
        "total_completion_tokens": 1435,
        "total_tokens": 2352
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 306,
          "completion_tokens": 629,
          "total_tokens": 935,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 306,
          "completion_tokens": 166,
          "total_tokens": 472,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 305,
          "completion_tokens": 640,
          "total_tokens": 945,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 49,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 314,
          "completion_tokens": 640,
          "total_tokens": 954,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 314,
          "completion_tokens": 23,
          "total_tokens": 337,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 313,
          "completion_tokens": 640,
          "total_tokens": 953,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 941,
        "total_completion_tokens": 1303,
        "total_tokens": 2244
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 314,
          "completion_tokens": 640,
          "total_tokens": 954,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 314,
          "completion_tokens": 23,
          "total_tokens": 337,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 313,
          "completion_tokens": 640,
          "total_tokens": 953,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 51,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 322,
          "completion_tokens": 386,
          "total_tokens": 708,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 322,
          "completion_tokens": 221,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 321,
          "completion_tokens": 640,
          "total_tokens": 961,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 965,
        "total_completion_tokens": 1247,
        "total_tokens": 2212
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 322,
          "completion_tokens": 386,
          "total_tokens": 708,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 322,
          "completion_tokens": 221,
          "total_tokens": 543,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 321,
          "completion_tokens": 640,
          "total_tokens": 961,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 53,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 330,
          "completion_tokens": 640,
          "total_tokens": 970,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 330,
          "completion_tokens": 23,
          "total_tokens": 353,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 329,
          "completion_tokens": 618,
          "total_tokens": 947,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 989,
        "total_completion_tokens": 1281,
        "total_tokens": 2270
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 330,
          "completion_tokens": 640,
          "total_tokens": 970,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 330,
          "completion_tokens": 23,
          "total_tokens": 353,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 329,
          "completion_tokens": 618,
          "total_tokens": 947,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 55,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 337,
          "completion_tokens": 640,
          "total_tokens": 977,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 337,
          "completion_tokens": 169,
          "total_tokens": 506,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 336,
          "completion_tokens": 640,
          "total_tokens": 976,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1010,
        "total_completion_tokens": 1449,
        "total_tokens": 2459
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 337,
          "completion_tokens": 640,
          "total_tokens": 977,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 337,
          "completion_tokens": 169,
          "total_tokens": 506,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 336,
          "completion_tokens": 640,
          "total_tokens": 976,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 57,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 345,
          "completion_tokens": 236,
          "total_tokens": 581,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 345,
          "completion_tokens": 358,
          "total_tokens": 703,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 344,
          "completion_tokens": 249,
          "total_tokens": 593,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1034,
        "total_completion_tokens": 843,
        "total_tokens": 1877
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 345,
          "completion_tokens": 236,
          "total_tokens": 581,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 345,
          "completion_tokens": 358,
          "total_tokens": 703,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 344,
          "completion_tokens": 249,
          "total_tokens": 593,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 59,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 352,
          "completion_tokens": 640,
          "total_tokens": 992,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 352,
          "completion_tokens": 640,
          "total_tokens": 992,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 351,
          "completion_tokens": 6,
          "total_tokens": 357,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1055,
        "total_completion_tokens": 1286,
        "total_tokens": 2341
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 352,
          "completion_tokens": 640,
          "total_tokens": 992,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 352,
          "completion_tokens": 640,
          "total_tokens": 992,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 351,
          "completion_tokens": 6,
          "total_tokens": 357,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 61,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 361,
          "completion_tokens": 8,
          "total_tokens": 369,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 361,
          "completion_tokens": 199,
          "total_tokens": 560,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 360,
          "completion_tokens": 8,
          "total_tokens": 368,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1082,
        "total_completion_tokens": 215,
        "total_tokens": 1297
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 361,
          "completion_tokens": 8,
          "total_tokens": 369,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 361,
          "completion_tokens": 199,
          "total_tokens": 560,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 360,
          "completion_tokens": 8,
          "total_tokens": 368,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 63,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 369,
          "completion_tokens": 640,
          "total_tokens": 1009,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 369,
          "completion_tokens": 640,
          "total_tokens": 1009,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 368,
          "completion_tokens": 387,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1106,
        "total_completion_tokens": 1667,
        "total_tokens": 2773
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 369,
          "completion_tokens": 640,
          "total_tokens": 1009,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 369,
          "completion_tokens": 640,
          "total_tokens": 1009,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 368,
          "completion_tokens": 387,
          "total_tokens": 755,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 65,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 378,
          "completion_tokens": 640,
          "total_tokens": 1018,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 378,
          "completion_tokens": 432,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 377,
          "completion_tokens": 640,
          "total_tokens": 1017,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1133,
        "total_completion_tokens": 1712,
        "total_tokens": 2845
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 378,
          "completion_tokens": 640,
          "total_tokens": 1018,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 378,
          "completion_tokens": 432,
          "total_tokens": 810,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 377,
          "completion_tokens": 640,
          "total_tokens": 1017,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 67,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 387,
          "completion_tokens": 338,
          "total_tokens": 725,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 387,
          "completion_tokens": 361,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 386,
          "completion_tokens": 170,
          "total_tokens": 556,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1160,
        "total_completion_tokens": 869,
        "total_tokens": 2029
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 387,
          "completion_tokens": 338,
          "total_tokens": 725,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 387,
          "completion_tokens": 361,
          "total_tokens": 748,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 386,
          "completion_tokens": 170,
          "total_tokens": 556,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 69,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 395,
          "completion_tokens": 229,
          "total_tokens": 624,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 395,
          "completion_tokens": 640,
          "total_tokens": 1035,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 394,
          "completion_tokens": 640,
          "total_tokens": 1034,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1184,
        "total_completion_tokens": 1509,
        "total_tokens": 2693
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 395,
          "completion_tokens": 229,
          "total_tokens": 624,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 395,
          "completion_tokens": 640,
          "total_tokens": 1035,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 394,
          "completion_tokens": 640,
          "total_tokens": 1034,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 71,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 403,
          "completion_tokens": 640,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 403,
          "completion_tokens": 640,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 402,
          "completion_tokens": 8,
          "total_tokens": 410,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1208,
        "total_completion_tokens": 1288,
        "total_tokens": 2496
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 403,
          "completion_tokens": 640,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 403,
          "completion_tokens": 640,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 402,
          "completion_tokens": 8,
          "total_tokens": 410,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 73,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 410,
          "completion_tokens": 640,
          "total_tokens": 1050,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 410,
          "completion_tokens": 640,
          "total_tokens": 1050,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 409,
          "completion_tokens": 8,
          "total_tokens": 417,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1229,
        "total_completion_tokens": 1288,
        "total_tokens": 2517
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 410,
          "completion_tokens": 640,
          "total_tokens": 1050,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 410,
          "completion_tokens": 640,
          "total_tokens": 1050,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 409,
          "completion_tokens": 8,
          "total_tokens": 417,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 75,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 418,
          "completion_tokens": 640,
          "total_tokens": 1058,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 418,
          "completion_tokens": 124,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 417,
          "completion_tokens": 640,
          "total_tokens": 1057,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1253,
        "total_completion_tokens": 1404,
        "total_tokens": 2657
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 418,
          "completion_tokens": 640,
          "total_tokens": 1058,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 418,
          "completion_tokens": 124,
          "total_tokens": 542,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 417,
          "completion_tokens": 640,
          "total_tokens": 1057,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 77,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 427,
          "completion_tokens": 640,
          "total_tokens": 1067,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 427,
          "completion_tokens": 640,
          "total_tokens": 1067,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 426,
          "completion_tokens": 640,
          "total_tokens": 1066,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1280,
        "total_completion_tokens": 1920,
        "total_tokens": 3200
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 427,
          "completion_tokens": 640,
          "total_tokens": 1067,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 427,
          "completion_tokens": 640,
          "total_tokens": 1067,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 426,
          "completion_tokens": 640,
          "total_tokens": 1066,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 79,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 434,
          "completion_tokens": 640,
          "total_tokens": 1074,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1304,
        "total_completion_tokens": 1920,
        "total_tokens": 3224
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 435,
          "completion_tokens": 640,
          "total_tokens": 1075,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 434,
          "completion_tokens": 640,
          "total_tokens": 1074,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 81,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 444,
          "completion_tokens": 640,
          "total_tokens": 1084,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 444,
          "completion_tokens": 8,
          "total_tokens": 452,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 443,
          "completion_tokens": 612,
          "total_tokens": 1055,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1331,
        "total_completion_tokens": 1260,
        "total_tokens": 2591
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 444,
          "completion_tokens": 640,
          "total_tokens": 1084,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 444,
          "completion_tokens": 8,
          "total_tokens": 452,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 443,
          "completion_tokens": 612,
          "total_tokens": 1055,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 83,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 451,
          "completion_tokens": 518,
          "total_tokens": 969,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 451,
          "completion_tokens": 564,
          "total_tokens": 1015,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 450,
          "completion_tokens": 606,
          "total_tokens": 1056,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1352,
        "total_completion_tokens": 1688,
        "total_tokens": 3040
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 451,
          "completion_tokens": 518,
          "total_tokens": 969,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 451,
          "completion_tokens": 564,
          "total_tokens": 1015,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 450,
          "completion_tokens": 606,
          "total_tokens": 1056,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 85,
      "attempt": 2,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 459,
          "completion_tokens": 640,
          "total_tokens": 1099,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 459,
          "completion_tokens": 8,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 458,
          "completion_tokens": 640,
          "total_tokens": 1098,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1376,
        "total_completion_tokens": 1288,
        "total_tokens": 2664
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 459,
          "completion_tokens": 640,
          "total_tokens": 1099,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 459,
          "completion_tokens": 8,
          "total_tokens": 467,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 458,
          "completion_tokens": 640,
          "total_tokens": 1098,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 87,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 467,
          "completion_tokens": 423,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 467,
          "completion_tokens": 640,
          "total_tokens": 1107,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 466,
          "completion_tokens": 640,
          "total_tokens": 1106,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1400,
        "total_completion_tokens": 1703,
        "total_tokens": 3103
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 467,
          "completion_tokens": 423,
          "total_tokens": 890,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 467,
          "completion_tokens": 640,
          "total_tokens": 1107,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 466,
          "completion_tokens": 640,
          "total_tokens": 1106,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 89,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 475,
          "completion_tokens": 7,
          "total_tokens": 482,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 475,
          "completion_tokens": 640,
          "total_tokens": 1115,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 474,
          "completion_tokens": 640,
          "total_tokens": 1114,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1424,
        "total_completion_tokens": 1287,
        "total_tokens": 2711
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 475,
          "completion_tokens": 7,
          "total_tokens": 482,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 475,
          "completion_tokens": 640,
          "total_tokens": 1115,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 474,
          "completion_tokens": 640,
          "total_tokens": 1114,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 91,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 483,
          "completion_tokens": 222,
          "total_tokens": 705,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1451,
        "total_completion_tokens": 1502,
        "total_tokens": 2953
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 484,
          "completion_tokens": 640,
          "total_tokens": 1124,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 483,
          "completion_tokens": 222,
          "total_tokens": 705,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 93,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 491,
          "completion_tokens": 640,
          "total_tokens": 1131,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 491,
          "completion_tokens": 8,
          "total_tokens": 499,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 490,
          "completion_tokens": 164,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1472,
        "total_completion_tokens": 812,
        "total_tokens": 2284
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 491,
          "completion_tokens": 640,
          "total_tokens": 1131,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 491,
          "completion_tokens": 8,
          "total_tokens": 499,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 490,
          "completion_tokens": 164,
          "total_tokens": 654,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 95,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 498,
          "completion_tokens": 640,
          "total_tokens": 1138,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 498,
          "completion_tokens": 201,
          "total_tokens": 699,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 497,
          "completion_tokens": 640,
          "total_tokens": 1137,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1493,
        "total_completion_tokens": 1481,
        "total_tokens": 2974
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 498,
          "completion_tokens": 640,
          "total_tokens": 1138,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 498,
          "completion_tokens": 201,
          "total_tokens": 699,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 497,
          "completion_tokens": 640,
          "total_tokens": 1137,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 97,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 507,
          "completion_tokens": 535,
          "total_tokens": 1042,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 507,
          "completion_tokens": 528,
          "total_tokens": 1035,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 506,
          "completion_tokens": 528,
          "total_tokens": 1034,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1520,
        "total_completion_tokens": 1591,
        "total_tokens": 3111
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 507,
          "completion_tokens": 535,
          "total_tokens": 1042,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 507,
          "completion_tokens": 528,
          "total_tokens": 1035,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 506,
          "completion_tokens": 528,
          "total_tokens": 1034,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 99,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 515,
          "completion_tokens": 528,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 515,
          "completion_tokens": 549,
          "total_tokens": 1064,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 514,
          "completion_tokens": 640,
          "total_tokens": 1154,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1544,
        "total_completion_tokens": 1717,
        "total_tokens": 3261
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 515,
          "completion_tokens": 528,
          "total_tokens": 1043,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 515,
          "completion_tokens": 549,
          "total_tokens": 1064,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 514,
          "completion_tokens": 640,
          "total_tokens": 1154,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 101,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 524,
          "completion_tokens": 205,
          "total_tokens": 729,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 524,
          "completion_tokens": 597,
          "total_tokens": 1121,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 523,
          "completion_tokens": 640,
          "total_tokens": 1163,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1571,
        "total_completion_tokens": 1442,
        "total_tokens": 3013
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 524,
          "completion_tokens": 205,
          "total_tokens": 729,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 524,
          "completion_tokens": 597,
          "total_tokens": 1121,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 523,
          "completion_tokens": 640,
          "total_tokens": 1163,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    },
    {
      "turn": 103,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 532,
          "completion_tokens": 25,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 532,
          "completion_tokens": 361,
          "total_tokens": 893,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 531,
          "completion_tokens": 22,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1595,
        "total_completion_tokens": 408,
        "total_tokens": 2003
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 532,
          "completion_tokens": 25,
          "total_tokens": 557,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 532,
          "completion_tokens": 361,
          "total_tokens": 893,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 531,
          "completion_tokens": 22,
          "total_tokens": 553,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 105,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 539,
          "completion_tokens": 640,
          "total_tokens": 1179,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 539,
          "completion_tokens": 281,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 538,
          "completion_tokens": 283,
          "total_tokens": 821,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1616,
        "total_completion_tokens": 1204,
        "total_tokens": 2820
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 539,
          "completion_tokens": 640,
          "total_tokens": 1179,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 539,
          "completion_tokens": 281,
          "total_tokens": 820,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 538,
          "completion_tokens": 283,
          "total_tokens": 821,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 107,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 547,
          "completion_tokens": 139,
          "total_tokens": 686,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 547,
          "completion_tokens": 332,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 546,
          "completion_tokens": 354,
          "total_tokens": 900,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "total_prompt_tokens": 1640,
        "total_completion_tokens": 825,
        "total_tokens": 2465
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 547,
          "completion_tokens": 139,
          "total_tokens": 686,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "positional": {
          "prompt_tokens": 547,
          "completion_tokens": 332,
          "total_tokens": 879,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        },
        "neutral": {
          "prompt_tokens": 546,
          "completion_tokens": 354,
          "total_tokens": 900,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "stop"
        }
      }
    },
    {
      "turn": 109,
      "attempt": 1,
      "tokens": {
        "aggressive": {
          "prompt_tokens": 555,
          "completion_tokens": 640,
          "total_tokens": 1195,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 555,
          "completion_tokens": 640,
          "total_tokens": 1195,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 554,
          "completion_tokens": 640,
          "total_tokens": 1194,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "total_prompt_tokens": 1664,
        "total_completion_tokens": 1920,
        "total_tokens": 3584
      },
      "individual_agent_tokens": {
        "aggressive": {
          "prompt_tokens": 555,
          "completion_tokens": 640,
          "total_tokens": 1195,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "positional": {
          "prompt_tokens": 555,
          "completion_tokens": 640,
          "total_tokens": 1195,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        },
        "neutral": {
          "prompt_tokens": 554,
          "completion_tokens": 640,
          "total_tokens": 1194,
          "model": "gpt-3.5-turbo-instruct",
          "finish_reason": "length"
        }
      }
    }
  ],
  "black_token_log": [],
  "white_responses": [
    {
      "turn": 1,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": "d2d4",
          "aggressive_response": "d4 d5\nd4 d5 Nf3 Nf6 Bf4 Bf5 e3 e6 c4 c6 Nc3 Nbd7 Qb3 Qb6 c5 Qxb3 axb3 Be7 b4 O-O b5 cxb5 Bxb5 a6 Ba4 b5 Bb3 Rfc8 O-O Bd3 Rfd1 Bc4 Bc2 b4 Na4 b3 Bd3 Bxd3 Rxd3 Ne4 Rxb3 g5 Bg3 g4 Ne5 Nxe5 Bxe5 f6 Bg3 h5 Nb6 Nxg3 hxg3 Rcb8 Rba3 Ra7 Rxa6 Rxa6 Rxa6 Kf7 Ra7 Ke8 Kf1 Bd8 Ke2 Bxb6 cxb6 Rxb6 Kd2 e5 Kc3 Rb8 b4 Rc8+ Kd3 Rc1 b5 Rb1 Ra5 Rb1+ Kc2 Rf1 b6 Rxf2+ Kc3 Rxg2 b7 Rxg3 b8=Q+ Kf7 Rb7+ Kg6 Qg8+ Kf5 Qh7+ Ke6 Qd7#\nd4 d5 Nf3 Nf6 Bf4 Bf5 e3 e6 c4 c6 Nc3 Nbd7 Qb3 Qb6 c5 Qxb3 axb3 Be7 b4 O-O b5 cxb5 Bxb5 a6 Ba4 b5 Bb3 Rfc8 O-O Bd3 Rfd1 Bc4 Bc2 b4 Na4 b3 Bd3 Bxd3 Rxd3 Ne4 Rxb3 g5 Bg3 g4 Ne5 Nxe5 Bxe5 f6 Bg3 h5 Nb6 Nxg3 hxg3 Rcb8 Rba3 Ra7 Rxa6 Rxa6 Rxa6 Kf7 Ra7 Ke8 Kf1 Bd8 Ke2 Bxb6 cxb6 Rxb6 Kd2 e5 Kc3 Rb8 b4 Rc8+ Kd3 Rc1 b5 Rb1 Ra5 Rb1+ Kc2 Rf1 b6 Rxf2+ Kc3 Rxg2 b7 Rxg3 b8=Q+ Kf7 Rb7+ Kg6 Qg8+ Kf5 Qh7+ Ke6 Qd7# e4 e5 Nf3 Nc6 Nc3 Nbd7 Qb3 Qb6 c5 Qxb3 axb3 Be7 b4 O-O b5 cxb5 Bxb5 a6 Ba4 b5 Bb3 Rfc8 O-O Bd8 Rfd1 Bc7 Bxc7 Rxc7 b6 Rb7 Ra5 Rb1+ Kc2 Rf1 b7 Rxf2+ Kc3 Rxg2 b8=Q+ Kf7 Rb7+ Kg6 Qh8",
          "aggressive_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nf6",
            "Bf4",
            "Bf5",
            "e3",
            "e6",
            "c4",
            "c6",
            "Nc3",
            "Nbd7",
            "Qb3",
            "Qb6",
            "c5",
            "Qxb3",
            "axb3",
            "Be7",
            "b4",
            "O-O",
            "b5",
            "cxb5",
            "Bxb5",
            "a6",
            "Ba4",
            "b5",
            "Bb3",
            "Rfc8",
            "O-O",
            "Bd3",
            "Rfd1",
            "Bc4",
            "Bc2",
            "b4",
            "Na4",
            "b3",
            "Bd3",
            "Bxd3",
            "Rxd3",
            "Ne4",
            "Rxb3",
            "g5",
            "Bg3",
            "g4",
            "Ne5",
            "Nxe5",
            "Bxe5",
            "f6",
            "Bg3",
            "h5",
            "Nb6",
            "Nxg3",
            "hxg3",
            "Rcb8",
            "Rba3",
            "Ra7",
            "Rxa6",
            "Rxa6",
            "Rxa6",
            "Kf7",
            "Ra7",
            "Ke8",
            "Kf1",
            "Bd8",
            "Ke2",
            "Bxb6",
            "cxb6",
            "Rxb6",
            "Kd2",
            "e5",
            "Kc3",
            "Rb8",
            "b4",
            "Rc8+",
            "Kd3",
            "Rc1",
            "b5",
            "Rb1",
            "Ra5",
            "Rb1+",
            "Kc2",
            "Rf1",
            "b6",
            "Rxf2+",
            "Kc3",
            "Rxg2",
            "b7",
            "Rxg3",
            "b8=Q+",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Qg8+",
            "Kf5",
            "Qh7+",
            "Ke6",
            "Qd7#",
            "e4",
            "e5",
            "Nf3",
            "Nc6",
            "Nc3",
            "Nbd7",
            "Qb3",
            "Qb6",
            "c5",
            "Qxb3",
            "axb3",
            "Be7",
            "b4",
            "O-O",
            "b5",
            "cxb5",
            "Bxb5",
            "a6",
            "Ba4",
            "b5",
            "Bb3",
            "Rfc8",
            "O-O",
            "Bd8",
            "Rfd1",
            "Bc7",
            "Bxc7",
            "Rxc7",
            "b6",
            "Rb7",
            "Ra5",
            "Rb1+",
            "Kc2",
            "Rf1",
            "b7",
            "Rxf2+",
            "Kc3",
            "Rxg2",
            "b8=Q+",
            "Kf7",
            "Rb7+",
            "Kg6",
            "Qh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. O-O Nge7 5. Nxe5 Nxe5 6. d4 Bxd4 7. Qxd4 N7c6 8. Bxc6 Nxc6 9. Qxg7 Rf8 10. Bh6 Qe7 11. Nc3 d6 12. Nd5 Qe5 13. Qxf8+ Kd7 14. Qxf7+ Kd8 15. Qxc7+ Ke8 16. Qxh7 Kd8 17. Qg8+ Kd7 18. Qf7+ Kd8 19. Bg5+ Qxg5 20. Qf8+ Kd7 21. Nf6+ Kc7 22. Ne8+ Kb6 23. Qxd6 Bh3 24. Qc7+ Ka6 25. Qg3 Qxg3 26. fxg3 Rxe8 27. gxh3 Rxe4 28. Rae1 Rb4 29. b3 Nd4 30. c3 Nc2 31. cxb4 Nxe1 32. Rxe1 Kb5 33. Re4 a5 34. bxa5 Kxa5 35. h4 b5 36. h5 b4 37. h6 Kb5 38. h7 Kc5 39. h8=Q Kd5 40. Qe5+ Kc6 41. Rc4+ Kb6 42. Qc5+ Ka6 43. Qxb4 Ka7 44. Rc5 Ka6 45. Ra5# 1-0 e4 e5 Nf3 Nc6 Bb5 Bc5 O-O Nge7 Nxe5 Nxe5 d4 Bxd4 Qxd4 N7c6 Bxc6 Nxc6 Qxg7 Rf8 Bh6 Qe7 Nc3 d6 Nd5 Qe5 Qxf8+ Kd7 Qxf7+ Kd8 Qxc7+ Ke8 Qxh7 Kd8 Qxh6 Kd7 Nf6+ Kc7 Ne8+ Kb6 Qxd6 Bh3 Qc7+ Ka6 Qg3 Qxg3 fxg3 Rxe8 gxh3 Rxe4 Rae1 Rb4 b3 Nd4 c3 Nc2 cxb4 Nxe1 Rxe1 Kb5 Re4 a5 bxa5 Kxa5 h4 b5 h5 b4 h6 Kb5 h7 Kc5 h8=Q Kd5 Qe5+ Kc6 Rc4+ Kb6 Qc7+ Ka6 Qc6+ Ka7 Qc7+ Ka6 Rc6+ Kb5 Qb6#",
          "positional_tokens": {
            "prompt_tokens": 110,
            "completion_tokens": 633,
            "total_tokens": 743,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bc5",
            "O-O",
            "Nge7",
            "Nxe5",
            "Nxe5",
            "d4",
            "Bxd4",
            "Qxd4",
            "N7c6",
            "Bxc6",
            "Nxc6",
            "Qxg7",
            "Rf8",
            "Bh6",
            "Qe7",
            "Nc3",
            "d6",
            "Nd5",
            "Qe5",
            "Qxf8+",
            "Kd7",
            "Qxf7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Qxh7",
            "Kd8",
            "Qxh6",
            "Kd7",
            "Nf6+",
            "Kc7",
            "Ne8+",
            "Kb6",
            "Qxd6",
            "Bh3",
            "Qc7+",
            "Ka6",
            "Qg3",
            "Qxg3",
            "fxg3",
            "Rxe8",
            "gxh3",
            "Rxe4",
            "Rae1",
            "Rb4",
            "b3",
            "Nd4",
            "c3",
            "Nc2",
            "cxb4",
            "Nxe1",
            "Rxe1",
            "Kb5",
            "Re4",
            "a5",
            "bxa5",
            "Kxa5",
            "h4",
            "b5",
            "h5",
            "b4",
            "h6",
            "Kb5",
            "h7",
            "Kc5",
            "h8=Q",
            "Kd5",
            "Qe5+",
            "Kc6",
            "Rc4+",
            "Kb6",
            "Qc7+",
            "Ka6",
            "Qc6+",
            "Ka7",
            "Qc7+",
            "Ka6",
            "Rc6+",
            "Kb5",
            "Qb6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "d4",
          "neutral_uci": "d2d4",
          "neutral_response": "d4 d5\nd4 d5 Nc3 Nf6 Bg5 e6 e4 Be7 e5 Nfd7 Bxe7 Qxe7 Nf3 O-O Bd3 c5 O-O cxd4 Nxd4 Nxe5 Re1 Nxd3 Qxd3 Nc6 Nxc6 bxc6 Nxd5 cxd5 Qxd5 exd5 Rxe7 Be6 Re1 Rfc8 c3 Kf8 Rb7 Rcb8 Rxb8+ Rxb8 b3 Rc8 Rc1 d4 c4 d3 Rd1 Bf5 f3 Rd8 g4 Bg6 h4 h6 h5 Bh7 Kf2 f5 Ke3 fxg4 fxg4 Re8+ Kd4 Re4+ Kc3 Rxg4 c5 Rg5 b4 Rxh5 c6 Ke7 c7 Kd7 Kb3 Kxc7 a4 Kb6 Kc4 Rg4+ Kc3 h5 a5+ Kb5 a6 Kxa6 b5+ Kxb5 Kd2 h4 Ke3 h3 Kf3 Rg6 Kf4 h2 Kf5 h1=Q Ke5 Qe4#\nd4 d5 Nc3 Nf6 Bg5 e6 e4 Be7 e5 Nfd7 Bxe7 Qxe7 Nf3 O-O Bd3 c5 O-O cxd4 Nxd4 Nxe5 Re1 Nxd3 Qxd3 Nc6 Nxc6 bxc6 Nxd5 cxd5 Qxd5 exd5 Rxe7 Be6 Re1 Rfc8 c3 Kf8 Rb7 Rcb8 Rxb8+ Rxb8 b3 Rc8 Rc1 d4 c4 d3 Rd1 Bf5 f3 Rd8 g4 Bg6 h4 h6 h5 Bh7 Kf2 f5 Ke3 fxg4 fxg4 Re8+ Kd4 Re4+ Kc3 Rxg4 c5 Rg5 b4 Rxh5 c6 Ke7 c7 Kd7 Kb3 Kxc7 a4 Kb6 Kc4 Rg4+ Kc3 h5 a5+ Kb5 a6 Kxa6 b5+ Kxb5 Kd2 h4 Ke3 h3 Kf3 Rg6 Kf4 h2 Kf5 h1=Q Ke5 Qe4# d4 d5 Nc3 Nf6 Bg5 e6 e4 Be7 e5 Nfd7 Bxe7 Qxe7 Nf3 O-O Bd3 c5 O-O cxd4 Nxd4 Nxe5 Re1 Nxd3 Qxd3 Nc6 Nxc6 bxc6 Nxd5 cxd5 Qxd5 exd5 Rxe7 Be6 Re1 Rfc8 c3 Kf8 Rb7 Rcb8 Rxb8+ Rxb8 b3 Rc8 Rc1 d4 c4 d",
          "neutral_tokens": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "c4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2d4",
          "positional_uci": "e2e4",
          "neutral_uci": "d2d4",
          "consensus_move": "d2d4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nf3",
              "Nf6",
              "Bf4",
              "Bf5",
              "e3",
              "e6",
              "c4",
              "c6",
              "Nc3",
              "Nbd7",
              "Qb3",
              "Qb6",
              "c5",
              "Qxb3",
              "axb3",
              "Be7",
              "b4",
              "O-O",
              "b5",
              "cxb5",
              "Bxb5",
              "a6",
              "Ba4",
              "b5",
              "Bb3",
              "Rfc8",
              "O-O",
              "Bd3",
              "Rfd1",
              "Bc4",
              "Bc2",
              "b4",
              "Na4",
              "b3",
              "Bd3",
              "Bxd3",
              "Rxd3",
              "Ne4",
              "Rxb3",
              "g5",
              "Bg3",
              "g4",
              "Ne5",
              "Nxe5",
              "Bxe5",
              "f6",
              "Bg3",
              "h5",
              "Nb6",
              "Nxg3",
              "hxg3",
              "Rcb8",
              "Rba3",
              "Ra7",
              "Rxa6",
              "Rxa6",
              "Rxa6",
              "Kf7",
              "Ra7",
              "Ke8",
              "Kf1",
              "Bd8",
              "Ke2",
              "Bxb6",
              "cxb6",
              "Rxb6",
              "Kd2",
              "e5",
              "Kc3",
              "Rb8",
              "b4",
              "Rc8+",
              "Kd3",
              "Rc1",
              "b5",
              "Rb1",
              "Ra5",
              "Rb1+",
              "Kc2",
              "Rf1",
              "b6",
              "Rxf2+",
              "Kc3",
              "Rxg2",
              "b7",
              "Rxg3",
              "b8=Q+",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Qg8+",
              "Kf5",
              "Qh7+",
              "Ke6",
              "Qd7#",
              "e4",
              "e5",
              "Nf3",
              "Nc6",
              "Nc3",
              "Nbd7",
              "Qb3",
              "Qb6",
              "c5",
              "Qxb3",
              "axb3",
              "Be7",
              "b4",
              "O-O",
              "b5",
              "cxb5",
              "Bxb5",
              "a6",
              "Ba4",
              "b5",
              "Bb3",
              "Rfc8",
              "O-O",
              "Bd8",
              "Rfd1",
              "Bc7",
              "Bxc7",
              "Rxc7",
              "b6",
              "Rb7",
              "Ra5",
              "Rb1+",
              "Kc2",
              "Rf1",
              "b7",
              "Rxf2+",
              "Kc3",
              "Rxg2",
              "b8=Q+",
              "Kf7",
              "Rb7+",
              "Kg6",
              "Qh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bc5",
              "O-O",
              "Nge7",
              "Nxe5",
              "Nxe5",
              "d4",
              "Bxd4",
              "Qxd4",
              "N7c6",
              "Bxc6",
              "Nxc6",
              "Qxg7",
              "Rf8",
              "Bh6",
              "Qe7",
              "Nc3",
              "d6",
              "Nd5",
              "Qe5",
              "Qxf8+",
              "Kd7",
              "Qxf7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Qxh7",
              "Kd8",
              "Qxh6",
              "Kd7",
              "Nf6+",
              "Kc7",
              "Ne8+",
              "Kb6",
              "Qxd6",
              "Bh3",
              "Qc7+",
              "Ka6",
              "Qg3",
              "Qxg3",
              "fxg3",
              "Rxe8",
              "gxh3",
              "Rxe4",
              "Rae1",
              "Rb4",
              "b3",
              "Nd4",
              "c3",
              "Nc2",
              "cxb4",
              "Nxe1",
              "Rxe1",
              "Kb5",
              "Re4",
              "a5",
              "bxa5",
              "Kxa5",
              "h4",
              "b5",
              "h5",
              "b4",
              "h6",
              "Kb5",
              "h7",
              "Kc5",
              "h8=Q",
              "Kd5",
              "Qe5+",
              "Kc6",
              "Rc4+",
              "Kb6",
              "Qc7+",
              "Ka6",
              "Qc6+",
              "Ka7",
              "Qc7+",
              "Ka6",
              "Rc6+",
              "Kb5",
              "Qb6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "c4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 110,
            "completion_tokens": 633,
            "total_tokens": 743,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 329,
          "total_completion_tokens": 1913,
          "total_tokens": 2242
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 110,
            "completion_tokens": 640,
            "total_tokens": 750,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 110,
            "completion_tokens": 633,
            "total_tokens": 743,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 0,
            "turn_number": 1,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 109,
            "completion_tokens": 640,
            "total_tokens": 749,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
    },
    {
      "turn": 3,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nf3",
          "aggressive_uci": "g1f3",
          "aggressive_response": "2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 O-O 7. Bd3 d6 8. c3 Nc6 9. Qc2 g6 10. O-O-O a6 11. h4 b5 12. h5 b4 13. hxg6 hxg6 14. exf5 exf5 15. g4 bxc3 16. bxc3 Ne7 17. gxf5 Bxf5 18. Rdg1 Bg7 19. Nh4 Bxd3 20. Qxd3 Rxf2 21. Nxg6 Nxg6 22. Qxg6 Qf6 23. Qh7+ Kf8 24. Rg6 Qf7 25. Rhg1 Qxa2 26. Qxg7+ Ke8 27. Re1+ Kd8 28. Qg8+ Qxg8 29. Rxg8+ Kd7 30. Rxa8 Kc6 31. Rxa6+ Kb5 32. Ra7 c5 33. dxc5 dxc5 34. Re5 Kb6 35. Rae7 Kb5 36. Rc7 Ka4 37. Rexc5 Rf4 38. Rb7 Rf1+ 39. Kc2 Rf2 40. Rc8 Rf5 41. Ra8+ Ra5 42. Rxa5+ Kxa5 43. c4 Ka6 44. Rb1 Ka5 45. c5 Ka4 46. c6 Ka3 47. c7 Ka2 48. c8=Q Ka3 49. Qa8# e4 Nc3 Nf6",
          "aggressive_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 411,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "O-O",
            "Bd3",
            "d6",
            "c3",
            "Nc6",
            "Qc2",
            "g6",
            "O-O-O",
            "a6",
            "h4",
            "b5",
            "h5",
            "b4",
            "hxg6",
            "hxg6",
            "exf5",
            "exf5",
            "g4",
            "bxc3",
            "bxc3",
            "Ne7",
            "gxf5",
            "Bxf5",
            "Rdg1",
            "Bg7",
            "Nh4",
            "Bxd3",
            "Qxd3",
            "Rxf2",
            "Nxg6",
            "Nxg6",
            "Qxg6",
            "Qf6",
            "Qh7+",
            "Kf8",
            "Rg6",
            "Qf7",
            "Rhg1",
            "Qxa2",
            "Qxg7+",
            "Ke8",
            "Re1+",
            "Kd8",
            "Qg8+",
            "Qxg8",
            "Rxg8+",
            "Kd7",
            "Rxa8",
            "Kc6",
            "Rxa6+",
            "Kb5",
            "Ra7",
            "c5",
            "dxc5",
            "dxc5",
            "Re5",
            "Kb6",
            "Rae7",
            "Kb5",
            "Rc7",
            "Ka4",
            "Rexc5",
            "Rf4",
            "Rb7",
            "Rf1+",
            "Kc2",
            "Rf2",
            "Rc8",
            "Rf5",
            "Ra8+",
            "Ra5",
            "Rxa5+",
            "Kxa5",
            "c4",
            "Ka6",
            "Rb1",
            "Ka5",
            "c5",
            "Ka4",
            "c6",
            "Ka3",
            "c7",
            "Ka2",
            "c8=Q",
            "Ka3",
            "Qa8#",
            "e4",
            "Nc3",
            "Nf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nf3",
          "positional_uci": "g1f3",
          "positional_response": "2. Nf3 Nf6 3. c4 e6 4. Nc3 Bb4 5. Qc2 O-O 6. g3 b6 7. Bg2 Bb7 8. O-O Bxc3 9. Qxc3 d6 10. b3 Nbd7 11. Bb2 Qe7 12. Rad1 Rae8 13. Rfe1 Ne4 14. Qc2 Ndf6 15. Nd2 Nxf2 16. Kxf2 Ng4+ 17. Kg1 Ne3 18. Qd3 Nxg2 19. Rf1 f4 20. d5 Ne3 21. Rxf4 Nxd1 22. Rh4 g6 23. Ba1 exd5 24. cxd5 Qxe2 25. Qd4 Qe1+ 26. Kg2 Ne3+ 27. Kh3 Bc8+ 28. g4 Rf3+ 29. Nxf3 Qf1+ 30. Kg3 Qg2+ 31. Kf4 Rf8+ 32. Kg5 Qxf3 33. Qg7# Nf3+ 34. Kh6 Qf4+ 35. g5 Qxh4# Nf5+ 37. Qxf5 Rxf5 38. Bf6 Rxf6 39. gxf6 Qxh4# Nf3+ 41. Kh6 Qxh4# Nf3+ 43. Kh6 Qxh4# Nf3+ 45. Kh6 Qxh4# Nf3+ 47. Kh6 Qxh4# Nf3+ 49. Kh6 Qxh4# Nf3+ 51. Kh6 Qxh4# Nf3+ 53. Kh6 Qxh4# Nf3+ 55. Kh6 Qxh4# Nf3+ 57. Kh6 Qxh4# Nf3+ 59. Kh6 Qxh4# Nf3+ 61. Kh6 Qxh4# Nf3+ 63. Kh6 Qxh4# Nf3+ 65. Kh6 Qxh4# Nf3+ 67. Kh6 Qxh4# Nf3+ 69. Kh6 Qxh4# Nf3+ 71. Kh6 Qxh4# Nf3+ 73. Kh6 Qxh4# Nf3+ 75. Kh6 Qxh4# Nf3+ 77. Kh6 Qxh4# Nf3+ 79. Kh6 Qxh4# Nf3+ 81. Kh6 Qxh4# Nf3+ 83. Kh6 Qxh4# Nf3+ 85. Kh6",
          "positional_tokens": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nf3",
          "neutral_uci": "g1f3",
          "neutral_response": "2. Nf3 Nf6 3. c4 e6 4. Nc3 Bb4 5. Qc2 O-O 6. g3 b6 7. Bg2 Bb7 8. O-O Bxc3 9. Qxc3 d6 10. b3 Nbd7 11. Bb2 Qe7 12. Rad1 Rae8 13. Rfe1 Ne4 14. Qc2 Ndf6 15. Nd2 Nxd2 16. Bxb7 Nde4 17. f3 Ng5 18. h4 Nf7 19. Bc6 Rd8 20. e4 fxe4 21. Bxe4 Nxe4 22. Qxe4 Rde8 23. Kg2 Qd7 24. Qg4 Nh6 25. Qh3 Qf7 26. g4 Qf4 27. Bc1 Qf6 28. Bg5 Qg6 29. Re2 Nf7 30. Bc1 e5 31. h5 Qf6 32. d5 Ng5 33. Bxg5 Qxg5 34. Qg3 Rf4 35. Rde1 Ref8 36. Re4 Rxf3 37. Qxf3 Rxf3 38. Kxf3 Qd2 39. R1e2 Qd3+ 40. R4e3 Qd1 41. Kg2 Qd4 42. Re4 Qd3 43. R4e3 Qd4 44. Re4 Qd3 45. R4e3 Qd4 46. Re4 Qd3 47. R4e3 Qd4 48. Re4 Qd3 49. R4e3 Qd4 50. Re4 Qd3 51. R4e3 Qd4 52. Re4 Qd3 53. R4e3 Qd4 54. Re4 Qd3 55. R4e3 Qd4 56. Re4 Qd3 57. R4e3 Qd4 58. Re4 Qd3 59. R4e3 Qd4 60. Re4 Qd3 61. R4e3 Qd4 62. Re4 Qd3 63. R4e3 Qd4 64. Re4 Qd3 65. R4e3 Qd4 66. Re4 Qd3 67. R4e3 Qd4 68. Re4 Qd3 69. R4e3 Qd4 70. Re4 Qd3 71. R4e3 Qd4 72. Re4 Qd3 73. R4e3 Qd4 74. Re4 Qd3 75. R4e3",
          "neutral_tokens": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "c4",
            "e6",
            "Nc3",
            "Bb4",
            "Qc2",
            "O-O",
            "g3",
            "b6",
            "Bg2",
            "Bb7",
            "O-O",
            "Bxc3",
            "Qxc3",
            "d6",
            "b3",
            "Nbd7",
            "Bb2",
            "Qe7",
            "Rad1",
            "Rae8",
            "Rfe1",
            "Ne4",
            "Qc2",
            "Ndf6",
            "Nd2",
            "Nxd2",
            "Bxb7",
            "Nde4",
            "f3",
            "Ng5",
            "h4",
            "Nf7",
            "Bc6",
            "Rd8",
            "e4",
            "fxe4",
            "Bxe4",
            "Nxe4",
            "Qxe4",
            "Rde8",
            "Kg2",
            "Qd7",
            "Qg4",
            "Nh6",
            "Qh3",
            "Qf7",
            "g4",
            "Qf4",
            "Bc1",
            "Qf6",
            "Bg5",
            "Qg6",
            "Re2",
            "Nf7",
            "Bc1",
            "e5",
            "h5",
            "Qf6",
            "d5",
            "Ng5",
            "Bxg5",
            "Qxg5",
            "Qg3",
            "Rf4",
            "Rde1",
            "Ref8",
            "Re4",
            "Rxf3",
            "Qxf3",
            "Rxf3",
            "Kxf3",
            "Qd2",
            "R1e2",
            "Qd3+",
            "R4e3",
            "Qd1",
            "Kg2",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3",
            "Qd4",
            "Re4",
            "Qd3",
            "R4e3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g1f3",
          "positional_uci": "g1f3",
          "neutral_uci": "g1f3",
          "consensus_move": "g1f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "O-O",
              "Bd3",
              "d6",
              "c3",
              "Nc6",
              "Qc2",
              "g6",
              "O-O-O",
              "a6",
              "h4",
              "b5",
              "h5",
              "b4",
              "hxg6",
              "hxg6",
              "exf5",
              "exf5",
              "g4",
              "bxc3",
              "bxc3",
              "Ne7",
              "gxf5",
              "Bxf5",
              "Rdg1",
              "Bg7",
              "Nh4",
              "Bxd3",
              "Qxd3",
              "Rxf2",
              "Nxg6",
              "Nxg6",
              "Qxg6",
              "Qf6",
              "Qh7+",
              "Kf8",
              "Rg6",
              "Qf7",
              "Rhg1",
              "Qxa2",
              "Qxg7+",
              "Ke8",
              "Re1+",
              "Kd8",
              "Qg8+",
              "Qxg8",
              "Rxg8+",
              "Kd7",
              "Rxa8",
              "Kc6",
              "Rxa6+",
              "Kb5",
              "Ra7",
              "c5",
              "dxc5",
              "dxc5",
              "Re5",
              "Kb6",
              "Rae7",
              "Kb5",
              "Rc7",
              "Ka4",
              "Rexc5",
              "Rf4",
              "Rb7",
              "Rf1+",
              "Kc2",
              "Rf2",
              "Rc8",
              "Rf5",
              "Ra8+",
              "Ra5",
              "Rxa5+",
              "Kxa5",
              "c4",
              "Ka6",
              "Rb1",
              "Ka5",
              "c5",
              "Ka4",
              "c6",
              "Ka3",
              "c7",
              "Ka2",
              "c8=Q",
              "Ka3",
              "Qa8#",
              "e4",
              "Nc3",
              "Nf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "c4",
              "e6",
              "Nc3",
              "Bb4",
              "Qc2",
              "O-O",
              "g3",
              "b6",
              "Bg2",
              "Bb7",
              "O-O",
              "Bxc3",
              "Qxc3",
              "d6",
              "b3",
              "Nbd7",
              "Bb2",
              "Qe7",
              "Rad1",
              "Rae8",
              "Rfe1",
              "Ne4",
              "Qc2",
              "Ndf6",
              "Nd2",
              "Nxd2",
              "Bxb7",
              "Nde4",
              "f3",
              "Ng5",
              "h4",
              "Nf7",
              "Bc6",
              "Rd8",
              "e4",
              "fxe4",
              "Bxe4",
              "Nxe4",
              "Qxe4",
              "Rde8",
              "Kg2",
              "Qd7",
              "Qg4",
              "Nh6",
              "Qh3",
              "Qf7",
              "g4",
              "Qf4",
              "Bc1",
              "Qf6",
              "Bg5",
              "Qg6",
              "Re2",
              "Nf7",
              "Bc1",
              "e5",
              "h5",
              "Qf6",
              "d5",
              "Ng5",
              "Bxg5",
              "Qxg5",
              "Qg3",
              "Rf4",
              "Rde1",
              "Ref8",
              "Re4",
              "Rxf3",
              "Qxf3",
              "Rxf3",
              "Kxf3",
              "Qd2",
              "R1e2",
              "Qd3+",
              "R4e3",
              "Qd1",
              "Kg2",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3",
              "Qd4",
              "Re4",
              "Qd3",
              "R4e3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 116,
            "completion_tokens": 411,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 347,
          "total_completion_tokens": 1691,
          "total_tokens": 2038
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 116,
            "completion_tokens": 411,
            "total_tokens": 527,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 116,
            "completion_tokens": 640,
            "total_tokens": 756,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 2,
            "turn_number": 2,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 115,
            "completion_tokens": 640,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkbnr/ppppp1pp/8/5p2/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2"
    },
    {
      "turn": 5,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bg5",
          "aggressive_uci": "c1g5",
          "aggressive_response": "3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. O-O Ne4 8. Bxe7 Qxe7 9. Ne5 Nd7 10. Nxd7 Bxd7 11. f3 Nxd2 12. Qxd2 c5 13. c3 c4 14. Bc2 b5 15. e4 fxe4 16. fxe4 Rxf1+ 17. Rxf1 Rf8 18. Rxf8+ Qxf8 19. exd5 exd5 20. Qg5 Qd6 21. Qd8+ Kf7 22. Bxh7 Qe6 23. Qg8+ Kf6 24. Qxe6+ Bxe6 25. Bc2 a5 26. Kf2 b4 27. Kf3 g5 28. g3 Bd7 29. h4 gxh4 30. gxh4 Be8 31. Kf4 Bh5 32. Bf5 Bd1 33. Bg4 Bc2 34. Bf3 Ke6 35. h5 bxc3 36. bxc3 a4 37. a3 Bd3 38. Kg5 Be4 39. Bg4+ Kf7 40. Bf5 Bf3 41. h6 Be4 42. Bxe4 dxe4 43. Kf4 Kg6 44. Kxe4 Kxh6 45. Kd5 Kg6 46. Kxc4 Kf6 47. Kb4 Ke6 48. Kxa4 Kd5 49. Kb5 Kd6 50. c4 Kc7 51. c5 Kb7 52. d5 Kc7 53. d6+ Kb7 54. c6+ Kc8 55. Kb6 Kb8 56. d7 Ka8 57. d8=Q# 1-0 1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. O-O Ne4 8. Bxe7 Qxe7 9. Ne5 Nd7 10. Nxd7 Bxd7 11. f3 Nxd2 12. Qxd2 c5 13. c3 c4 14. Bc2 b5 15. e4 fxe4 16. fxe4 Rxf1+ 17. Rxf1 Rf8 18. Rxf8+ Qxf8 19. exd5 exd5 20. Qg5 Qd6 21. Qd8+ Kf7 22. Bxh7 Q",
          "aggressive_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "Nbd2",
            "Be7",
            "e3",
            "O-O",
            "Bd3",
            "d5",
            "O-O",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Ne5",
            "Nd7",
            "Nxd7",
            "Bxd7",
            "f3",
            "Nxd2",
            "Qxd2",
            "c5",
            "c3",
            "c4",
            "Bc2",
            "b5",
            "e4",
            "fxe4",
            "fxe4",
            "Rxf1+",
            "Rxf1",
            "Rf8",
            "Rxf8+",
            "Qxf8",
            "exd5",
            "exd5",
            "Qg5",
            "Qd6",
            "Qd8+",
            "Kf7",
            "Bxh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bg5",
          "positional_uci": "c1g5",
          "positional_response": "3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. Ne5 Nbd7 8. Ndf3 Ne4 9. Bxe7 Qxe7 10. O-O Nxe5 11. Nxe5 Bd7 12. c4 c6 13. c5 Be8 14. f3 Ng5 15. b4 Nf7 16. Nxf7 Bxf7 17. f4 g5 18. g3 Kh8 19. a4 Rg8 20. Kh1 Rg7 21. b5 Rag8 22. bxc6 bxc6 23. Rb1 Qe8 24. Be2 h5 25. Rb7 h4 26. gxh4 gxh4 27. Bf3 Bg6 28. Rxg7 Rxg7 29. Rg1 Qb8 30. Qe1 Qd8 31. Rg5 Kg8 32. Qxh4 Qa5 33. Qg3 Kf7 34. Bh5 Bxh5 35. Rxg7+ Ke8 36. Rg8+ Kd7 37. Qg7+ Bf7 38. Qxf7# e4 Qe8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd7 Qf7+ Kd8 Qf8+ Kd",
          "positional_tokens": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "Nbd2",
            "Be7",
            "e3",
            "O-O",
            "Bd3",
            "d5",
            "Ne5",
            "Nbd7",
            "Ndf3",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "O-O",
            "Nxe5",
            "Nxe5",
            "Bd7",
            "c4",
            "c6",
            "c5",
            "Be8",
            "f3",
            "Ng5",
            "b4",
            "Nf7",
            "Nxf7",
            "Bxf7",
            "f4",
            "g5",
            "g3",
            "Kh8",
            "a4",
            "Rg8",
            "Kh1",
            "Rg7",
            "b5",
            "Rag8",
            "bxc6",
            "bxc6",
            "Rb1",
            "Qe8",
            "Be2",
            "h5",
            "Rb7",
            "h4",
            "gxh4",
            "gxh4",
            "Bf3",
            "Bg6",
            "Rxg7",
            "Rxg7",
            "Rg1",
            "Qb8",
            "Qe1",
            "Qd8",
            "Rg5",
            "Kg8",
            "Qxh4",
            "Qa5",
            "Qg3",
            "Kf7",
            "Bh5",
            "Bxh5",
            "Rxg7+",
            "Ke8",
            "Rg8+",
            "Kd7",
            "Qg7+",
            "Bf7",
            "Qxf7#",
            "e4",
            "Qe8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+",
            "Kd7",
            "Qf7+",
            "Kd8",
            "Qf8+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bg5",
          "neutral_uci": "c1g5",
          "neutral_response": "3. Bg5 e6 4. Nbd2 Be7 5. e3 O-O 6. Bd3 d5 7. O-O Ne4 8. Bxe7 Qxe7 9. Ne5 Nd7 10. Nxd7 Bxd7 11. f3 Nxd2 12. Qxd2 c5 13. c3 c4 14. Bc2 b5 15. e4 fxe4 16. fxe4 Rxf1+ 17. Rxf1 Rf8 18. Rxf8+ Qxf8 19. exd5 exd5 20. Qg5 Qd6 21. Qd8+ Kf7 22. Bxh7 Qe6 23. Qg8+ Kf6 24. Qxe6+ Bxe6 25. Bc2 a5 26. Kf2 b4 27. Ke3 g5 28. g3 Bg4 29. h4 gxh4 30. gxh4 Bh5 31. Kf4 Be2 32. Bf5 Bd1 33. Bg4 Bc2 34. Bf3 Ke6 35. Kg5 bxc3 36. bxc3 a4 37. a3 Be4 38. Bg4+ Kf7 39. Bf5 Bf3 40. h5 Kg7 41. h6+ Kh8 42. Kf6 Be4 43. Ke5 Bf3 44. Be6 Kh7 45. Bxd5 Be2 46. Bc6 Kxh6 47. Bxa4 Kg7 48. Bb5 Kf8 49. Kd5 Ke7 50. Bxc4 Bf3+ 51. Kc5 Kd7 52. Bd5 Be2 53. c4 Kc7 54. a4 Bd1 55. a5 Ba4 56. a6 Kb8 57. Kb6 Bc6 58. Bxc6 Kc8 59. a7 Kd8 60. a8=Q+ Ke7 61. Qe8+ Kf6 62. Qe5+ Kg6 63. Be4+ Kf7 64. Qf5+ Ke7 65. Qg6 Kd7 66. Bf5+ Ke7 67. Qe6+ Kf8 68. Qd7 Kg8 69. Bg6 Kh8 70. Qh7# e4 d3 d2 d1=Q dxe4 Qd5+ Kf7 Qd6+ Ke7 Qd5+ Kf7 Qd6+ Ke7 Qd5+ Kf7 Qd6+ Ke7 Qd5+ Kf7 Qd6+ Ke7 Qd5+ Kf",
          "neutral_tokens": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "e6",
            "Nbd2",
            "Be7",
            "e3",
            "O-O",
            "Bd3",
            "d5",
            "O-O",
            "Ne4",
            "Bxe7",
            "Qxe7",
            "Ne5",
            "Nd7",
            "Nxd7",
            "Bxd7",
            "f3",
            "Nxd2",
            "Qxd2",
            "c5",
            "c3",
            "c4",
            "Bc2",
            "b5",
            "e4",
            "fxe4",
            "fxe4",
            "Rxf1+",
            "Rxf1",
            "Rf8",
            "Rxf8+",
            "Qxf8",
            "exd5",
            "exd5",
            "Qg5",
            "Qd6",
            "Qd8+",
            "Kf7",
            "Bxh7",
            "Qe6",
            "Qg8+",
            "Kf6",
            "Qxe6+",
            "Bxe6",
            "Bc2",
            "a5",
            "Kf2",
            "b4",
            "Ke3",
            "g5",
            "g3",
            "Bg4",
            "h4",
            "gxh4",
            "gxh4",
            "Bh5",
            "Kf4",
            "Be2",
            "Bf5",
            "Bd1",
            "Bg4",
            "Bc2",
            "Bf3",
            "Ke6",
            "Kg5",
            "bxc3",
            "bxc3",
            "a4",
            "a3",
            "Be4",
            "Bg4+",
            "Kf7",
            "Bf5",
            "Bf3",
            "h5",
            "Kg7",
            "h6+",
            "Kh8",
            "Kf6",
            "Be4",
            "Ke5",
            "Bf3",
            "Be6",
            "Kh7",
            "Bxd5",
            "Be2",
            "Bc6",
            "Kxh6",
            "Bxa4",
            "Kg7",
            "Bb5",
            "Kf8",
            "Kd5",
            "Ke7",
            "Bxc4",
            "Bf3+",
            "Kc5",
            "Kd7",
            "Bd5",
            "Be2",
            "c4",
            "Kc7",
            "a4",
            "Bd1",
            "a5",
            "Ba4",
            "a6",
            "Kb8",
            "Kb6",
            "Bc6",
            "Bxc6",
            "Kc8",
            "a7",
            "Kd8",
            "a8=Q+",
            "Ke7",
            "Qe8+",
            "Kf6",
            "Qe5+",
            "Kg6",
            "Be4+",
            "Kf7",
            "Qf5+",
            "Ke7",
            "Qg6",
            "Kd7",
            "Bf5+",
            "Ke7",
            "Qe6+",
            "Kf8",
            "Qd7",
            "Kg8",
            "Bg6",
            "Kh8",
            "Qh7#",
            "e4",
            "d3",
            "d2",
            "d1=Q",
            "dxe4",
            "Qd5+",
            "Kf7",
            "Qd6+",
            "Ke7",
            "Qd5+",
            "Kf7",
            "Qd6+",
            "Ke7",
            "Qd5+",
            "Kf7",
            "Qd6+",
            "Ke7",
            "Qd5+",
            "Kf7",
            "Qd6+",
            "Ke7",
            "Qd5+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1g5",
          "positional_uci": "c1g5",
          "neutral_uci": "c1g5",
          "consensus_move": "c1g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e6",
              "Nbd2",
              "Be7",
              "e3",
              "O-O",
              "Bd3",
              "d5",
              "O-O",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Ne5",
              "Nd7",
              "Nxd7",
              "Bxd7",
              "f3",
              "Nxd2",
              "Qxd2",
              "c5",
              "c3",
              "c4",
              "Bc2",
              "b5",
              "e4",
              "fxe4",
              "fxe4",
              "Rxf1+",
              "Rxf1",
              "Rf8",
              "Rxf8+",
              "Qxf8",
              "exd5",
              "exd5",
              "Qg5",
              "Qd6",
              "Qd8+",
              "Kf7",
              "Bxh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e6",
              "Nbd2",
              "Be7",
              "e3",
              "O-O",
              "Bd3",
              "d5",
              "Ne5",
              "Nbd7",
              "Ndf3",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "O-O",
              "Nxe5",
              "Nxe5",
              "Bd7",
              "c4",
              "c6",
              "c5",
              "Be8",
              "f3",
              "Ng5",
              "b4",
              "Nf7",
              "Nxf7",
              "Bxf7",
              "f4",
              "g5",
              "g3",
              "Kh8",
              "a4",
              "Rg8",
              "Kh1",
              "Rg7",
              "b5",
              "Rag8",
              "bxc6",
              "bxc6",
              "Rb1",
              "Qe8",
              "Be2",
              "h5",
              "Rb7",
              "h4",
              "gxh4",
              "gxh4",
              "Bf3",
              "Bg6",
              "Rxg7",
              "Rxg7",
              "Rg1",
              "Qb8",
              "Qe1",
              "Qd8",
              "Rg5",
              "Kg8",
              "Qxh4",
              "Qa5",
              "Qg3",
              "Kf7",
              "Bh5",
              "Bxh5",
              "Rxg7+",
              "Ke8",
              "Rg8+",
              "Kd7",
              "Qg7+",
              "Bf7",
              "Qxf7#",
              "e4",
              "Qe8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+",
              "Kd7",
              "Qf7+",
              "Kd8",
              "Qf8+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e6",
              "Nbd2",
              "Be7",
              "e3",
              "O-O",
              "Bd3",
              "d5",
              "O-O",
              "Ne4",
              "Bxe7",
              "Qxe7",
              "Ne5",
              "Nd7",
              "Nxd7",
              "Bxd7",
              "f3",
              "Nxd2",
              "Qxd2",
              "c5",
              "c3",
              "c4",
              "Bc2",
              "b5",
              "e4",
              "fxe4",
              "fxe4",
              "Rxf1+",
              "Rxf1",
              "Rf8",
              "Rxf8+",
              "Qxf8",
              "exd5",
              "exd5",
              "Qg5",
              "Qd6",
              "Qd8+",
              "Kf7",
              "Bxh7",
              "Qe6",
              "Qg8+",
              "Kf6",
              "Qxe6+",
              "Bxe6",
              "Bc2",
              "a5",
              "Kf2",
              "b4",
              "Ke3",
              "g5",
              "g3",
              "Bg4",
              "h4",
              "gxh4",
              "gxh4",
              "Bh5",
              "Kf4",
              "Be2",
              "Bf5",
              "Bd1",
              "Bg4",
              "Bc2",
              "Bf3",
              "Ke6",
              "Kg5",
              "bxc3",
              "bxc3",
              "a4",
              "a3",
              "Be4",
              "Bg4+",
              "Kf7",
              "Bf5",
              "Bf3",
              "h5",
              "Kg7",
              "h6+",
              "Kh8",
              "Kf6",
              "Be4",
              "Ke5",
              "Bf3",
              "Be6",
              "Kh7",
              "Bxd5",
              "Be2",
              "Bc6",
              "Kxh6",
              "Bxa4",
              "Kg7",
              "Bb5",
              "Kf8",
              "Kd5",
              "Ke7",
              "Bxc4",
              "Bf3+",
              "Kc5",
              "Kd7",
              "Bd5",
              "Be2",
              "c4",
              "Kc7",
              "a4",
              "Bd1",
              "a5",
              "Ba4",
              "a6",
              "Kb8",
              "Kb6",
              "Bc6",
              "Bxc6",
              "Kc8",
              "a7",
              "Kd8",
              "a8=Q+",
              "Ke7",
              "Qe8+",
              "Kf6",
              "Qe5+",
              "Kg6",
              "Be4+",
              "Kf7",
              "Qf5+",
              "Ke7",
              "Qg6",
              "Kd7",
              "Bf5+",
              "Ke7",
              "Qe6+",
              "Kf8",
              "Qd7",
              "Kg8",
              "Bg6",
              "Kh8",
              "Qh7#",
              "e4",
              "d3",
              "d2",
              "d1=Q",
              "dxe4",
              "Qd5+",
              "Kf7",
              "Qd6+",
              "Ke7",
              "Qd5+",
              "Kf7",
              "Qd6+",
              "Ke7",
              "Qd5+",
              "Kf7",
              "Qd6+",
              "Ke7",
              "Qd5+",
              "Kf7",
              "Qd6+",
              "Ke7",
              "Qd5+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 374,
          "total_completion_tokens": 1920,
          "total_tokens": 2294
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 125,
            "completion_tokens": 640,
            "total_tokens": 765,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 4,
            "turn_number": 3,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 124,
            "completion_tokens": 640,
            "total_tokens": 764,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/ppppp1pp/5n2/5p2/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3"
    },
    {
      "turn": 7,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nbd2",
          "aggressive_uci": "b1d2",
          "aggressive_response": "4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O c5 11. c3 cxd4 12. cxd4 Nc6 13. Rc1 Bd7 14. Bb5 Rac8 15. Bxc6 Bxc6 16. Ne5 Bb5 17. Rxc8 Rxc8 18. Re1 Qf4 19. g3 Qf5 20. Qb3 Rc2 21. f4 Bc4 22. Qxb7 h6 23. Qc8+ Kh7 24. Nxc4 dxc4 25. Qxe6 Qxe6 26. Rxe6 Rxb2 27. Rc6 Rxa2 28. Rxc4 Kg6 29. Rc5 Kf6 30. g4 a5 31. Rc6+ Kf7 32. Ra6 a4 33. h4 a3 34. g5 hxg5 35. hxg5 g6 36. d5 Rd2 37. Rxa3 Rxd5 38. Kf2 Ke6 39. Kf3 Kf5 40. Re3 Rd4 41. Re5# e4+ Nxe4 Qxe4",
          "aggressive_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 316,
            "total_tokens": 449,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "c5",
            "c3",
            "cxd4",
            "cxd4",
            "Nc6",
            "Rc1",
            "Bd7",
            "Bb5",
            "Rac8",
            "Bxc6",
            "Bxc6",
            "Ne5",
            "Bb5",
            "Rxc8",
            "Rxc8",
            "Re1",
            "Qf4",
            "g3",
            "Qf5",
            "Qb3",
            "Rc2",
            "f4",
            "Bc4",
            "Qxb7",
            "h6",
            "Qc8+",
            "Kh7",
            "Nxc4",
            "dxc4",
            "Qxe6",
            "Qxe6",
            "Rxe6",
            "Rxb2",
            "Rc6",
            "Rxa2",
            "Rxc4",
            "Kg6",
            "Rc5",
            "Kf6",
            "g4",
            "a5",
            "Rc6+",
            "Kf7",
            "Ra6",
            "a4",
            "h4",
            "a3",
            "g5",
            "hxg5",
            "hxg5",
            "g6",
            "d5",
            "Rd2",
            "Rxa3",
            "Rxd5",
            "Kf2",
            "Ke6",
            "Kf3",
            "Kf5",
            "Re3",
            "Rd4",
            "Re5#",
            "e4+",
            "Nxe4",
            "Qxe4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nbd2",
          "positional_uci": "b1d2",
          "positional_response": "4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O c5 11. c3 cxd4 12. cxd4 Nc6 13. Rc1 Bd7 14. Re1 Rae8 15. Qd2 Kh8 16. Bb1 e5 17. dxe5 Nxe5 18. Nxe5 Rxe5 19. Rxe5 Qxe5 20. Re1 Qd6 21. Qd3 Bf5 22. Qxf5 Rxf5 23. Bxf5 g6 24. Bd3 Kg7 25. g3 Kf6 26. Re2 Qc5 27. Kg2 Qd4 28. Bc2 Qc4 29. Rd2 Qxa2 30. Bd1 Qa5 31. Rd3 Ke5 32. Bf3 b6 33. h4 d4 34. Ra3 Qb4 35. Rxa7 Qxb2 36. Rxh7 d3 37. Rd7 d2 38. Rd5+ Ke6 39. Rd3 b5 40. Bd1 b4 41. Kf1 Qc1 42. Ke2 Qc4 43. Kxd2 Qa2+ 44. Ke3 Qa7+ 45. Ke2 Qa2+ 46. Rd2 Qc4+ 47. Ke1 b3 48. Re2+ Kf6 49. Rb2 Qc3+ 50. Rd2 b2 51. Bc2 Qxc2 52. Rxc2 b1=Q+ 53. Kd2 Qb4+ 54. Ke2 Qe4+ 55. Kd2 Qd4+ 56. Ke2 Kf5 57. Rd2 Qc4+ 58. Ke3 Qe4# 0-1\nd4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 fxe4 Nxe4 O-O Bd3 d5 Nxf6+ Qxf6 O-O c5 c3 cxd4 cxd4 Nc6 Rc1 Bd7 Re1 Rae8 Qd2 Kh8 Bb1 e5 dxe5 Nxe5 Nxe5 Rxe5 Rxe5 Qxe5 Re1 Qd6 Qd3 Bf5 Qxf5 Rxf5 Bxf5 g6 Bd3 Kg7 g3 Kf6 Re2 Qc5 Kg2 Qd4 Rd2 Qc5 Be2 Qc1 Rd3 Qxb2 Rf3+ Ke5 Re3+ Kd6 a3 d4 Rd3 Kc5 B",
          "positional_tokens": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "c5",
            "c3",
            "cxd4",
            "cxd4",
            "Nc6",
            "Rc1",
            "Bd7",
            "Re1",
            "Rae8",
            "Qd2",
            "Kh8",
            "Bb1",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Rxe5",
            "Rxe5",
            "Qxe5",
            "Re1",
            "Qd6",
            "Qd3",
            "Bf5",
            "Qxf5",
            "Rxf5",
            "Bxf5",
            "g6",
            "Bd3",
            "Kg7",
            "g3",
            "Kf6",
            "Re2",
            "Qc5",
            "Kg2",
            "Qd4",
            "Rd2",
            "Qc5",
            "Be2",
            "Qc1",
            "Rd3",
            "Qxb2",
            "Rf3+",
            "Ke5",
            "Re3+",
            "Kd6",
            "a3",
            "d4",
            "Rd3",
            "Kc5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nbd2",
          "neutral_uci": "b1d2",
          "neutral_response": "4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qe2 Rae8 13. Rae1 Re7 14. Ne5 Nxe5 15. Qxe5 Qxe5 16. Rxe5 Rf6 17. Rfe1 Kf7 18. g3 g6 19. f4 b6 20. b4 c6 21. a4 Bc8 22. Ra1 Rc7 23. a5 b5 24. Rae1 Re7 25. Kg2 Bd7 26. h3 Kg7 27. Rf1 Ref7 28. Rf2 h6 29. h4 h5 30. Rfe2 Re7 31. Rg5 Kf7 32. Ree5 Be8 33. Kf3 Kg7 34. Ke3 Kh6 35. Kd2 Bf7 36. Be2 Be8 37. Ke3 Bf7 38. g4 hxg4 39. Bxg4 Be8 40. h5 gxh5 41. Bxh5 Bxh5 42. Rxh5+ Kg7 43. Reg5+ Rg6 44. Rxg6+ Kxg6 45. Rh8 Kf5 46. Rc8 Rh7 47. Rxc6 Rh3+ 48. Kd2 Kxf4 49. Rxe6 Rh2+ 50. Kd3 Rh3+ 51. Kc2 Rh2+ 52. Kb3 Rh5 53. Re7 a6 54. Re6 Rh1 55. Rxa6 Rb1+ 56. Kc2 Ra1 57. Rb6 Ke4 58. Rxb5 Ra2+ 59. Kb3 Ra1 60. Rb6 Kd3 61. Rc6 Rb1+ 62. Ka4 Ra1+ 63. Kb5 Ra3 64. a6 Ra1 65. Kb6 Ra3 66. a7 Ra1 67. Kb7 Ra3 68. a8=Q Rxa8 69. Kxa8 Ke4 70. b5 Kd3 71. b6 Ke4 72. b7 Kd3 73. b8=Q Ke4 74. Qe5+ Kd3 75. Qxd5 Kc2 76. Qf3 Kb3 77. c4+ Kb4 78. Rb6+ Kxc4 79. Qb3+ Kxd4 80. Rd6+ Ke5 81. Qd5+ Kf4 82.",
          "neutral_tokens": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qe2",
            "Rae8",
            "Rae1",
            "Re7",
            "Ne5",
            "Nxe5",
            "Qxe5",
            "Qxe5",
            "Rxe5",
            "Rf6",
            "Rfe1",
            "Kf7",
            "g3",
            "g6",
            "f4",
            "b6",
            "b4",
            "c6",
            "a4",
            "Bc8",
            "Ra1",
            "Rc7",
            "a5",
            "b5",
            "Rae1",
            "Re7",
            "Kg2",
            "Bd7",
            "h3",
            "Kg7",
            "Rf1",
            "Ref7",
            "Rf2",
            "h6",
            "h4",
            "h5",
            "Rfe2",
            "Re7",
            "Rg5",
            "Kf7",
            "Ree5",
            "Be8",
            "Kf3",
            "Kg7",
            "Ke3",
            "Kh6",
            "Kd2",
            "Bf7",
            "Be2",
            "Be8",
            "Ke3",
            "Bf7",
            "g4",
            "hxg4",
            "Bxg4",
            "Be8",
            "h5",
            "gxh5",
            "Bxh5",
            "Bxh5",
            "Rxh5+",
            "Kg7",
            "Reg5+",
            "Rg6",
            "Rxg6+",
            "Kxg6",
            "Rh8",
            "Kf5",
            "Rc8",
            "Rh7",
            "Rxc6",
            "Rh3+",
            "Kd2",
            "Kxf4",
            "Rxe6",
            "Rh2+",
            "Kd3",
            "Rh3+",
            "Kc2",
            "Rh2+",
            "Kb3",
            "Rh5",
            "Re7",
            "a6",
            "Re6",
            "Rh1",
            "Rxa6",
            "Rb1+",
            "Kc2",
            "Ra1",
            "Rb6",
            "Ke4",
            "Rxb5",
            "Ra2+",
            "Kb3",
            "Ra1",
            "Rb6",
            "Kd3",
            "Rc6",
            "Rb1+",
            "Ka4",
            "Ra1+",
            "Kb5",
            "Ra3",
            "a6",
            "Ra1",
            "Kb6",
            "Ra3",
            "a7",
            "Ra1",
            "Kb7",
            "Ra3",
            "a8=Q",
            "Rxa8",
            "Kxa8",
            "Ke4",
            "b5",
            "Kd3",
            "b6",
            "Ke4",
            "b7",
            "Kd3",
            "b8=Q",
            "Ke4",
            "Qe5+",
            "Kd3",
            "Qxd5",
            "Kc2",
            "Qf3",
            "Kb3",
            "c4+",
            "Kb4",
            "Rb6+",
            "Kxc4",
            "Qb3+",
            "Kxd4",
            "Rd6+",
            "Ke5",
            "Qd5+",
            "Kf4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "b1d2",
          "positional_uci": "b1d2",
          "neutral_uci": "b1d2",
          "consensus_move": "b1d2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "c5",
              "c3",
              "cxd4",
              "cxd4",
              "Nc6",
              "Rc1",
              "Bd7",
              "Bb5",
              "Rac8",
              "Bxc6",
              "Bxc6",
              "Ne5",
              "Bb5",
              "Rxc8",
              "Rxc8",
              "Re1",
              "Qf4",
              "g3",
              "Qf5",
              "Qb3",
              "Rc2",
              "f4",
              "Bc4",
              "Qxb7",
              "h6",
              "Qc8+",
              "Kh7",
              "Nxc4",
              "dxc4",
              "Qxe6",
              "Qxe6",
              "Rxe6",
              "Rxb2",
              "Rc6",
              "Rxa2",
              "Rxc4",
              "Kg6",
              "Rc5",
              "Kf6",
              "g4",
              "a5",
              "Rc6+",
              "Kf7",
              "Ra6",
              "a4",
              "h4",
              "a3",
              "g5",
              "hxg5",
              "hxg5",
              "g6",
              "d5",
              "Rd2",
              "Rxa3",
              "Rxd5",
              "Kf2",
              "Ke6",
              "Kf3",
              "Kf5",
              "Re3",
              "Rd4",
              "Re5#",
              "e4+",
              "Nxe4",
              "Qxe4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "c5",
              "c3",
              "cxd4",
              "cxd4",
              "Nc6",
              "Rc1",
              "Bd7",
              "Re1",
              "Rae8",
              "Qd2",
              "Kh8",
              "Bb1",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Rxe5",
              "Rxe5",
              "Qxe5",
              "Re1",
              "Qd6",
              "Qd3",
              "Bf5",
              "Qxf5",
              "Rxf5",
              "Bxf5",
              "g6",
              "Bd3",
              "Kg7",
              "g3",
              "Kf6",
              "Re2",
              "Qc5",
              "Kg2",
              "Qd4",
              "Rd2",
              "Qc5",
              "Be2",
              "Qc1",
              "Rd3",
              "Qxb2",
              "Rf3+",
              "Ke5",
              "Re3+",
              "Kd6",
              "a3",
              "d4",
              "Rd3",
              "Kc5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qe2",
              "Rae8",
              "Rae1",
              "Re7",
              "Ne5",
              "Nxe5",
              "Qxe5",
              "Qxe5",
              "Rxe5",
              "Rf6",
              "Rfe1",
              "Kf7",
              "g3",
              "g6",
              "f4",
              "b6",
              "b4",
              "c6",
              "a4",
              "Bc8",
              "Ra1",
              "Rc7",
              "a5",
              "b5",
              "Rae1",
              "Re7",
              "Kg2",
              "Bd7",
              "h3",
              "Kg7",
              "Rf1",
              "Ref7",
              "Rf2",
              "h6",
              "h4",
              "h5",
              "Rfe2",
              "Re7",
              "Rg5",
              "Kf7",
              "Ree5",
              "Be8",
              "Kf3",
              "Kg7",
              "Ke3",
              "Kh6",
              "Kd2",
              "Bf7",
              "Be2",
              "Be8",
              "Ke3",
              "Bf7",
              "g4",
              "hxg4",
              "Bxg4",
              "Be8",
              "h5",
              "gxh5",
              "Bxh5",
              "Bxh5",
              "Rxh5+",
              "Kg7",
              "Reg5+",
              "Rg6",
              "Rxg6+",
              "Kxg6",
              "Rh8",
              "Kf5",
              "Rc8",
              "Rh7",
              "Rxc6",
              "Rh3+",
              "Kd2",
              "Kxf4",
              "Rxe6",
              "Rh2+",
              "Kd3",
              "Rh3+",
              "Kc2",
              "Rh2+",
              "Kb3",
              "Rh5",
              "Re7",
              "a6",
              "Re6",
              "Rh1",
              "Rxa6",
              "Rb1+",
              "Kc2",
              "Ra1",
              "Rb6",
              "Ke4",
              "Rxb5",
              "Ra2+",
              "Kb3",
              "Ra1",
              "Rb6",
              "Kd3",
              "Rc6",
              "Rb1+",
              "Ka4",
              "Ra1+",
              "Kb5",
              "Ra3",
              "a6",
              "Ra1",
              "Kb6",
              "Ra3",
              "a7",
              "Ra1",
              "Kb7",
              "Ra3",
              "a8=Q",
              "Rxa8",
              "Kxa8",
              "Ke4",
              "b5",
              "Kd3",
              "b6",
              "Ke4",
              "b7",
              "Kd3",
              "b8=Q",
              "Ke4",
              "Qe5+",
              "Kd3",
              "Qxd5",
              "Kc2",
              "Qf3",
              "Kb3",
              "c4+",
              "Kb4",
              "Rb6+",
              "Kxc4",
              "Qb3+",
              "Kxd4",
              "Rd6+",
              "Ke5",
              "Qd5+",
              "Kf4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 133,
            "completion_tokens": 316,
            "total_tokens": 449,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 398,
          "total_completion_tokens": 1596,
          "total_tokens": 1994
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 133,
            "completion_tokens": 316,
            "total_tokens": 449,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 133,
            "completion_tokens": 640,
            "total_tokens": 773,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 6,
            "turn_number": 4,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 132,
            "completion_tokens": 640,
            "total_tokens": 772,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqkb1r/pppp2pp/4pn2/5pB1/3P4/5N2/PPP1PPPP/RN1QKB1R w KQkq - 0 4"
    },
    {
      "turn": 9,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxf6",
          "aggressive_uci": "g5f6",
          "aggressive_response": "5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qc2 h6 13. Rae1 Rae8 14. Ne5 Nxe5 15. Rxe5 c5 16. Qe2 cxd4 17. cxd4 Rc8 18. Bb1 Rc4 19. Qd3 Rfc8 20. f4 Bb5 21. Qh7+ Kf7 22. f5 Rc1 23. fxe6+ Ke7 24. Rf5 Rxf1+ 25. Rxf1 Qxd4+ 26. Kh1 Bxf1 27. Qg6 Rc1 28. Qf7+ Kd6 29. Qd7+ Ke5 30. Qxg7+ Kxe6 31. Qxd4 Bd3+ 32. Qg1 Rxg1+ 33. Kxg1 Bxb1 34. a3 Ke5 35. Kf2 Ke4 36. Ke2 d4 37. Kd2 d3 38. b4 Kd4 39. g4 Ba2 40. h4 Be6 41. g5 hxg5 42. hxg5 Bf5 43. a4 b6 44. a5 bxa5 45. bxa5 a6 46. Kd1 Ke3 47. Ke1 d2+ 48. Kd1 Bg4+ 49. Kc2 d1=Q+ 50. Kc3 Qd4+ 51. Kb3 Be6+ 52. Kc2 Qd3+ 53. Kb2 Qb3+ 54. Kc1 Kd3 55. g6 Qc2# e4 d5 g4",
          "aggressive_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 441,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qc2",
            "h6",
            "Rae1",
            "Rae8",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "c5",
            "Qe2",
            "cxd4",
            "cxd4",
            "Rc8",
            "Bb1",
            "Rc4",
            "Qd3",
            "Rfc8",
            "f4",
            "Bb5",
            "Qh7+",
            "Kf7",
            "f5",
            "Rc1",
            "fxe6+",
            "Ke7",
            "Rf5",
            "Rxf1+",
            "Rxf1",
            "Qxd4+",
            "Kh1",
            "Bxf1",
            "Qg6",
            "Rc1",
            "Qf7+",
            "Kd6",
            "Qd7+",
            "Ke5",
            "Qxg7+",
            "Kxe6",
            "Qxd4",
            "Bd3+",
            "Qg1",
            "Rxg1+",
            "Kxg1",
            "Bxb1",
            "a3",
            "Ke5",
            "Kf2",
            "Ke4",
            "Ke2",
            "d4",
            "Kd2",
            "d3",
            "b4",
            "Kd4",
            "g4",
            "Ba2",
            "h4",
            "Be6",
            "g5",
            "hxg5",
            "hxg5",
            "Bf5",
            "a4",
            "b6",
            "a5",
            "bxa5",
            "bxa5",
            "a6",
            "Kd1",
            "Ke3",
            "Ke1",
            "d2+",
            "Kd1",
            "Bg4+",
            "Kc2",
            "d1=Q+",
            "Kc3",
            "Qd4+",
            "Kb3",
            "Be6+",
            "Kc2",
            "Qd3+",
            "Kb2",
            "Qb3+",
            "Kc1",
            "Kd3",
            "g6",
            "Qc2#",
            "e4",
            "d5",
            "g4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxf6",
          "positional_uci": "g5f6",
          "positional_response": "5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O c5 11. c3 cxd4 12. cxd4 Nc6 13. Rc1 Bd7 14. Re1 Rae8 15. Qd2 Kh8 16. Bb1 Qf4 17. Qxf4 Rxf4 18. Rcd1 Ref8 19. Re3 g6 20. a3 Kg7 21. b4 a6 22. Ba2 h6 23. h3 g5 24. Rd2 R8f6 25. Bb3 Be8 26. Bd1 Bh5 27. g4 Bg6 28. Kg2 Be4 29. Kg3 Bxf3 30. Bxf3 Nxd4 31. Bd1 Nc6 32. Rc3 Rc4 33. Rxc4 dxc4 34. Rd7+ Rf7 35. Rd6 Kf6 36. Be2 Ke5 37. Rd1 b5 38. Bf3 Nd4 39. Re1+ Kd6 40. Be4 c3 41. Rd1 Ke5 42. Re1 Kd6 43. Rd1 e5 44. f3 Rc7 45. Kf2 c2 46. Rc1 Rc3 47. Ke1 Rxa3 48. Bxc2 Rc3 49. Kd2 Rxc2+ 50. Rxc2 Nxc2 51. Kxc2 Kd5 52. Kd3 e4+ 53. fxe4+ Ke5 54. Ke3 Ke6 55. Kd4 Kd6 56. e5+ Ke6 57. Ke4 Ke7 58. Kd5 Kd7 59. e6+ Ke7 60. Ke5 Ke8 61. Kd6 Kd8 62. e7+ Ke8 63. Ke6 a5 64. bxa5 b4 65. a6 b3 66. a7 b2 67. a8=Q# e4 d5 c4",
          "positional_tokens": {
            "prompt_tokens": 141,
            "completion_tokens": 505,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "c5",
            "c3",
            "cxd4",
            "cxd4",
            "Nc6",
            "Rc1",
            "Bd7",
            "Re1",
            "Rae8",
            "Qd2",
            "Kh8",
            "Bb1",
            "Qf4",
            "Qxf4",
            "Rxf4",
            "Rcd1",
            "Ref8",
            "Re3",
            "g6",
            "a3",
            "Kg7",
            "b4",
            "a6",
            "Ba2",
            "h6",
            "h3",
            "g5",
            "Rd2",
            "R8f6",
            "Bb3",
            "Be8",
            "Bd1",
            "Bh5",
            "g4",
            "Bg6",
            "Kg2",
            "Be4",
            "Kg3",
            "Bxf3",
            "Bxf3",
            "Nxd4",
            "Bd1",
            "Nc6",
            "Rc3",
            "Rc4",
            "Rxc4",
            "dxc4",
            "Rd7+",
            "Rf7",
            "Rd6",
            "Kf6",
            "Be2",
            "Ke5",
            "Rd1",
            "b5",
            "Bf3",
            "Nd4",
            "Re1+",
            "Kd6",
            "Be4",
            "c3",
            "Rd1",
            "Ke5",
            "Re1",
            "Kd6",
            "Rd1",
            "e5",
            "f3",
            "Rc7",
            "Kf2",
            "c2",
            "Rc1",
            "Rc3",
            "Ke1",
            "Rxa3",
            "Bxc2",
            "Rc3",
            "Kd2",
            "Rxc2+",
            "Rxc2",
            "Nxc2",
            "Kxc2",
            "Kd5",
            "Kd3",
            "e4+",
            "fxe4+",
            "Ke5",
            "Ke3",
            "Ke6",
            "Kd4",
            "Kd6",
            "e5+",
            "Ke6",
            "Ke4",
            "Ke7",
            "Kd5",
            "Kd7",
            "e6+",
            "Ke7",
            "Ke5",
            "Ke8",
            "Kd6",
            "Kd8",
            "e7+",
            "Ke8",
            "Ke6",
            "a5",
            "bxa5",
            "b4",
            "a6",
            "b3",
            "a7",
            "b2",
            "a8=Q#",
            "e4",
            "d5",
            "c4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxf6",
          "neutral_uci": "g5f6",
          "neutral_response": "5. Bxf6 Bxf6 6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qc2 h6 13. Rae1 Rae8 14. Ne5 Nxe5 15. Rxe5 c5 16. Qe2 cxd4 17. cxd4 Rc8 18. Bb1 Rc4 19. Qd3 Rfc8 20. Re3 Rc1 21. Rf3 Rxf1+ 22. Kxf1 Rc1+ 23. Ke2 Qg5 24. Qh7# e4 Nf6 Qh8#",
          "neutral_tokens": {
            "prompt_tokens": 140,
            "completion_tokens": 172,
            "total_tokens": 312,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "e4",
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qc2",
            "h6",
            "Rae1",
            "Rae8",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "c5",
            "Qe2",
            "cxd4",
            "cxd4",
            "Rc8",
            "Bb1",
            "Rc4",
            "Qd3",
            "Rfc8",
            "Re3",
            "Rc1",
            "Rf3",
            "Rxf1+",
            "Kxf1",
            "Rc1+",
            "Ke2",
            "Qg5",
            "Qh7#",
            "e4",
            "Nf6",
            "Qh8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5f6",
          "positional_uci": "g5f6",
          "neutral_uci": "g5f6",
          "consensus_move": "g5f6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qc2",
              "h6",
              "Rae1",
              "Rae8",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "c5",
              "Qe2",
              "cxd4",
              "cxd4",
              "Rc8",
              "Bb1",
              "Rc4",
              "Qd3",
              "Rfc8",
              "f4",
              "Bb5",
              "Qh7+",
              "Kf7",
              "f5",
              "Rc1",
              "fxe6+",
              "Ke7",
              "Rf5",
              "Rxf1+",
              "Rxf1",
              "Qxd4+",
              "Kh1",
              "Bxf1",
              "Qg6",
              "Rc1",
              "Qf7+",
              "Kd6",
              "Qd7+",
              "Ke5",
              "Qxg7+",
              "Kxe6",
              "Qxd4",
              "Bd3+",
              "Qg1",
              "Rxg1+",
              "Kxg1",
              "Bxb1",
              "a3",
              "Ke5",
              "Kf2",
              "Ke4",
              "Ke2",
              "d4",
              "Kd2",
              "d3",
              "b4",
              "Kd4",
              "g4",
              "Ba2",
              "h4",
              "Be6",
              "g5",
              "hxg5",
              "hxg5",
              "Bf5",
              "a4",
              "b6",
              "a5",
              "bxa5",
              "bxa5",
              "a6",
              "Kd1",
              "Ke3",
              "Ke1",
              "d2+",
              "Kd1",
              "Bg4+",
              "Kc2",
              "d1=Q+",
              "Kc3",
              "Qd4+",
              "Kb3",
              "Be6+",
              "Kc2",
              "Qd3+",
              "Kb2",
              "Qb3+",
              "Kc1",
              "Kd3",
              "g6",
              "Qc2#",
              "e4",
              "d5",
              "g4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "c5",
              "c3",
              "cxd4",
              "cxd4",
              "Nc6",
              "Rc1",
              "Bd7",
              "Re1",
              "Rae8",
              "Qd2",
              "Kh8",
              "Bb1",
              "Qf4",
              "Qxf4",
              "Rxf4",
              "Rcd1",
              "Ref8",
              "Re3",
              "g6",
              "a3",
              "Kg7",
              "b4",
              "a6",
              "Ba2",
              "h6",
              "h3",
              "g5",
              "Rd2",
              "R8f6",
              "Bb3",
              "Be8",
              "Bd1",
              "Bh5",
              "g4",
              "Bg6",
              "Kg2",
              "Be4",
              "Kg3",
              "Bxf3",
              "Bxf3",
              "Nxd4",
              "Bd1",
              "Nc6",
              "Rc3",
              "Rc4",
              "Rxc4",
              "dxc4",
              "Rd7+",
              "Rf7",
              "Rd6",
              "Kf6",
              "Be2",
              "Ke5",
              "Rd1",
              "b5",
              "Bf3",
              "Nd4",
              "Re1+",
              "Kd6",
              "Be4",
              "c3",
              "Rd1",
              "Ke5",
              "Re1",
              "Kd6",
              "Rd1",
              "e5",
              "f3",
              "Rc7",
              "Kf2",
              "c2",
              "Rc1",
              "Rc3",
              "Ke1",
              "Rxa3",
              "Bxc2",
              "Rc3",
              "Kd2",
              "Rxc2+",
              "Rxc2",
              "Nxc2",
              "Kxc2",
              "Kd5",
              "Kd3",
              "e4+",
              "fxe4+",
              "Ke5",
              "Ke3",
              "Ke6",
              "Kd4",
              "Kd6",
              "e5+",
              "Ke6",
              "Ke4",
              "Ke7",
              "Kd5",
              "Kd7",
              "e6+",
              "Ke7",
              "Ke5",
              "Ke8",
              "Kd6",
              "Kd8",
              "e7+",
              "Ke8",
              "Ke6",
              "a5",
              "bxa5",
              "b4",
              "a6",
              "b3",
              "a7",
              "b2",
              "a8=Q#",
              "e4",
              "d5",
              "c4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "e4",
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qc2",
              "h6",
              "Rae1",
              "Rae8",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "c5",
              "Qe2",
              "cxd4",
              "cxd4",
              "Rc8",
              "Bb1",
              "Rc4",
              "Qd3",
              "Rfc8",
              "Re3",
              "Rc1",
              "Rf3",
              "Rxf1+",
              "Kxf1",
              "Rc1+",
              "Ke2",
              "Qg5",
              "Qh7#",
              "e4",
              "Nf6",
              "Qh8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 141,
            "completion_tokens": 441,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 141,
            "completion_tokens": 505,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 140,
            "completion_tokens": 172,
            "total_tokens": 312,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 422,
          "total_completion_tokens": 1118,
          "total_tokens": 1540
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 141,
            "completion_tokens": 441,
            "total_tokens": 582,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 141,
            "completion_tokens": 505,
            "total_tokens": 646,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 8,
            "turn_number": 5,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 140,
            "completion_tokens": 172,
            "total_tokens": 312,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppppb1pp/4pn2/5pB1/3P4/5N2/PPPNPPPP/R2QKB1R w KQkq - 2 5"
    },
    {
      "turn": 11,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": "e2e4",
          "aggressive_response": "6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 e5 12. dxe5 Nxe5 13. Nxe5 Qxe5 14. Qc2 Bf5 15. Rae1 Bxd3 16. Qxd3 Qd6 17. Re3 Rae8 18. Rfe1 Rxe3 19. Rxe3 c6 20. Qe2 Qf6 21. Re7 Rf7 22. Re8+ Rf8 23. Re7 Rf7 24. Re8+ Rf8 25. Re7 Rf7 26. Re8+ Rf8 27. Re7 Rf7 28. Re8+ Rf8 29. Re7 Rf7 30. Re8+ Rf8 31. Re7 Rf7 32. Re8+ Rf8 33. Re7 Rf7 34. Re8+ Rf8 35. Re7 Rf7 36. Re8+ Rf8 37. Re7 Rf7 38. Re8+ Rf8 39. Re7 Rf7 40. Re8+ Rf8 41. Re7 Rf7 42. Re8+ Rf8 43. Re7 Rf7 44. Re8+ Rf8 45. Re7 Rf7 46. Re8+ Rf8 47. Re7 Rf7 48. Re8+ Rf8 49. Re7 Rf7 50. Re8+ Rf8 51. Re7 Rf7 52. Re8+ Rf8 53. Re7 Rf7 54. Re8+ Rf8 55. Re7 Rf7 56. Re8+ Rf8 57. Re7 Rf7 58. Re8+ Rf8 59. Re7 Rf7 60. Re8+ Rf8 61. Re7 Rf7 62. Re8+ Rf8 63. Re7 Rf7 64. Re8+ Rf8 65. Re7 Rf7 66. Re8+ Rf8 67. Re7 Rf7 68. Re8+ Rf8 69. Re7 Rf7 70. Re8+ Rf8 71. Re7 Rf7 72. Re8+ Rf8 73. Re7 Rf7 74. Re8+ Rf8 75. Re7 Rf7 76. Re8+ Rf8 77. Re7 Rf7 78. Re8+ Rf8 79. Re7 Rf7 80. Re8+ Rf8 81. Re7",
          "aggressive_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Qxe5",
            "Qc2",
            "Bf5",
            "Rae1",
            "Bxd3",
            "Qxd3",
            "Qd6",
            "Re3",
            "Rae8",
            "Rfe1",
            "Rxe3",
            "Rxe3",
            "c6",
            "Qe2",
            "Qf6",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7",
            "Rf7",
            "Re8+",
            "Rf8",
            "Re7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "e4",
          "positional_uci": "e2e4",
          "positional_response": "6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qc2 g6 13. Rae1 Rae8 14. Ne5 Nxe5 15. Rxe5 c5 16. Qe2 cxd4 17. cxd4 Rc8 18. g3 Rc6 19. f4 Rfc8 20. h4 Rc1 21. h5 Rxf1+ 22. Kxf1 Rc1+ 23. Kg2 Kg7 24. hxg6 hxg6 25. Rg5 Be8 26. Qe5 Qxe5 27. Rxe5 Kf6 28. g4 Rd1 29. g5+ Kf7 30. Re3 Rd2+ 31. Kf3 Rxb2 32. Re2 Rxe2 33. Kxe2 Ke7 34. Kd2 Kd6 35. Kc3 Kc6 36. Kb4 Kb6 37. a4 a5+ 38. Kb3 Kc7 39. Bb5 Bxb5 40. axb5 Kb6 41. Ka4 Ka7 42. Kxa5 b6+ 43. Kb4 Kb7 44. Kc3 Kc7 45. Kd3 Kd6 46. Ke3 Ke7 47. Kf3 Kf7 48. Kg4 Kg7 49. Kh4 Kh7 50. Kg4 Kg7 51. Kh4 Kh7 52. Kg4 Kg7 53. Kh4 Kh7 54. Kg4 Kg7 55. Kh4 Kh7 56. Kg4 Kg7 57. Kh4 Kh7 58. Kg4 Kg7 59. Kh4 Kh7 60. Kg4 Kg7 61. Kh4 Kh7 62. Kg4 Kg7 63. Kh4 Kh7 64. Kg4 Kg7 65. Kh4 Kh7 66. Kg4 Kg7 67. Kh4 Kh7 68. Kg4 Kg7 69. Kh4 Kh7 70. Kg4 Kg7 71. Kh4 Kh7 72. Kg4 Kg7 73. Kh4 Kh7 74. Kg4 Kg7 75. Kh4 Kh7 76. Kg4 Kg7 77. Kh4 Kh7 78. Kg4 Kg7 79. Kh4 Kh7 80. Kg4 Kg7 81. Kh4 Kh7 82. Kg4 Kg7 83. Kh4 Kh7 84. Kg4 Kg7 85. Kh4 Kh7 86. Kg4 Kg7 87. Kh4 Kh7 88. Kg4 Kg7 89. Kh4 Kh7 90. Kg",
          "positional_tokens": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qc2",
            "g6",
            "Rae1",
            "Rae8",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "c5",
            "Qe2",
            "cxd4",
            "cxd4",
            "Rc8",
            "g3",
            "Rc6",
            "f4",
            "Rfc8",
            "h4",
            "Rc1",
            "h5",
            "Rxf1+",
            "Kxf1",
            "Rc1+",
            "Kg2",
            "Kg7",
            "hxg6",
            "hxg6",
            "Rg5",
            "Be8",
            "Qe5",
            "Qxe5",
            "Rxe5",
            "Kf6",
            "g4",
            "Rd1",
            "g5+",
            "Kf7",
            "Re3",
            "Rd2+",
            "Kf3",
            "Rxb2",
            "Re2",
            "Rxe2",
            "Kxe2",
            "Ke7",
            "Kd2",
            "Kd6",
            "Kc3",
            "Kc6",
            "Kb4",
            "Kb6",
            "a4",
            "a5+",
            "Kb3",
            "Kc7",
            "Bb5",
            "Bxb5",
            "axb5",
            "Kb6",
            "Ka4",
            "Ka7",
            "Kxa5",
            "b6+",
            "Kb4",
            "Kb7",
            "Kc3",
            "Kc7",
            "Kd3",
            "Kd6",
            "Ke3",
            "Ke7",
            "Kf3",
            "Kf7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7",
            "Kg4",
            "Kg7",
            "Kh4",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "e4",
          "neutral_uci": "e2e4",
          "neutral_response": "6. e4 fxe4 7. Nxe4 O-O 8. Bd3 d5 9. Nxf6+ Qxf6 10. O-O Nc6 11. c3 Bd7 12. Qc2 h6 13. Rae1 Rae8 14. Ne5 Nxe5 15. Rxe5 c5 16. Qe2 cxd4 17. cxd4 Rc8 18. Bb5 Bxb5 19. Qxb5 Rc2 20. Re2 Rxe2 21. Qxe2 Qxd4 22. Qxe6+ Kh8 23. Qe2 Qc4 24. Qxc4 dxc4 25. Rc1 b5 26. Kf1 Rd8 27. Ke2 Kg8 28. Rc3 Kf7 29. Ra3 Rd7 30. Ra5 Rb7 31. Kd2 Ke6 32. Kc3 Kd5 33. Kb4 Kc6 34. Ra6+ Kd5 35. Ra5 Kc6 36. Ra6+ Kd5 37. Ra5 Kc6 38. Ra6+ Kd5 39. Ra5 Kc6 40. Ra6+ Kd5 41. Ra5 Kc6 42. Ra6+ Kd5 43. Ra5 Kc6 44. Ra6+ Kd5 45. Ra5 Kc6 46. Ra6+ Kd5 47. Ra5 Kc6 48. Ra6+ Kd5 49. Ra5 Kc6 50. Ra6+ Kd5 51. Ra5 Kc6 52. Ra6+ Kd5 53. Ra5 Kc6 54. Ra6+ Kd5 55. Ra5 Kc6 56. Ra6+ Kd5 57. Ra5 Kc6 58. Ra6+ Kd5 59. Ra5 Kc6 60. Ra6+ Kd5 61. Ra5 Kc6 62. Ra6+ Kd5 63. Ra5 Kc6 64. Ra6+ Kd5 65. Ra5 Kc6 66. Ra6+ Kd5 67. Ra5 Kc6 68. Ra6+ Kd5 69. Ra5 Kc6 70. Ra6+ Kd5 71. Ra5 Kc6 72. Ra6+ Kd5 73. Ra5 Kc6 74. Ra6+ Kd5 75. Ra5 Kc6 76. Ra6+ Kd5 77. Ra5 Kc6 78. Ra6+ Kd5 79. Ra5 Kc6 80. Ra6+ Kd5 81. Ra5 Kc6 82. Ra6",
          "neutral_tokens": {
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "fxe4",
            "Nxe4",
            "O-O",
            "Bd3",
            "d5",
            "Nxf6+",
            "Qxf6",
            "O-O",
            "Nc6",
            "c3",
            "Bd7",
            "Qc2",
            "h6",
            "Rae1",
            "Rae8",
            "Ne5",
            "Nxe5",
            "Rxe5",
            "c5",
            "Qe2",
            "cxd4",
            "cxd4",
            "Rc8",
            "Bb5",
            "Bxb5",
            "Qxb5",
            "Rc2",
            "Re2",
            "Rxe2",
            "Qxe2",
            "Qxd4",
            "Qxe6+",
            "Kh8",
            "Qe2",
            "Qc4",
            "Qxc4",
            "dxc4",
            "Rc1",
            "b5",
            "Kf1",
            "Rd8",
            "Ke2",
            "Kg8",
            "Rc3",
            "Kf7",
            "Ra3",
            "Rd7",
            "Ra5",
            "Rb7",
            "Kd2",
            "Ke6",
            "Kc3",
            "Kd5",
            "Kb4",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6+",
            "Kd5",
            "Ra5",
            "Kc6",
            "Ra6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2e4",
          "positional_uci": "e2e4",
          "neutral_uci": "e2e4",
          "consensus_move": "e2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Qxe5",
              "Qc2",
              "Bf5",
              "Rae1",
              "Bxd3",
              "Qxd3",
              "Qd6",
              "Re3",
              "Rae8",
              "Rfe1",
              "Rxe3",
              "Rxe3",
              "c6",
              "Qe2",
              "Qf6",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7",
              "Rf7",
              "Re8+",
              "Rf8",
              "Re7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qc2",
              "g6",
              "Rae1",
              "Rae8",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "c5",
              "Qe2",
              "cxd4",
              "cxd4",
              "Rc8",
              "g3",
              "Rc6",
              "f4",
              "Rfc8",
              "h4",
              "Rc1",
              "h5",
              "Rxf1+",
              "Kxf1",
              "Rc1+",
              "Kg2",
              "Kg7",
              "hxg6",
              "hxg6",
              "Rg5",
              "Be8",
              "Qe5",
              "Qxe5",
              "Rxe5",
              "Kf6",
              "g4",
              "Rd1",
              "g5+",
              "Kf7",
              "Re3",
              "Rd2+",
              "Kf3",
              "Rxb2",
              "Re2",
              "Rxe2",
              "Kxe2",
              "Ke7",
              "Kd2",
              "Kd6",
              "Kc3",
              "Kc6",
              "Kb4",
              "Kb6",
              "a4",
              "a5+",
              "Kb3",
              "Kc7",
              "Bb5",
              "Bxb5",
              "axb5",
              "Kb6",
              "Ka4",
              "Ka7",
              "Kxa5",
              "b6+",
              "Kb4",
              "Kb7",
              "Kc3",
              "Kc7",
              "Kd3",
              "Kd6",
              "Ke3",
              "Ke7",
              "Kf3",
              "Kf7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7",
              "Kg4",
              "Kg7",
              "Kh4",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "fxe4",
              "Nxe4",
              "O-O",
              "Bd3",
              "d5",
              "Nxf6+",
              "Qxf6",
              "O-O",
              "Nc6",
              "c3",
              "Bd7",
              "Qc2",
              "h6",
              "Rae1",
              "Rae8",
              "Ne5",
              "Nxe5",
              "Rxe5",
              "c5",
              "Qe2",
              "cxd4",
              "cxd4",
              "Rc8",
              "Bb5",
              "Bxb5",
              "Qxb5",
              "Rc2",
              "Re2",
              "Rxe2",
              "Qxe2",
              "Qxd4",
              "Qxe6+",
              "Kh8",
              "Qe2",
              "Qc4",
              "Qxc4",
              "dxc4",
              "Rc1",
              "b5",
              "Kf1",
              "Rd8",
              "Ke2",
              "Kg8",
              "Rc3",
              "Kf7",
              "Ra3",
              "Rd7",
              "Ra5",
              "Rb7",
              "Kd2",
              "Ke6",
              "Kc3",
              "Kd5",
              "Kb4",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6+",
              "Kd5",
              "Ra5",
              "Kc6",
              "Ra6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 449,
          "total_completion_tokens": 1920,
          "total_tokens": 2369
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 150,
            "completion_tokens": 640,
            "total_tokens": 790,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 10,
            "turn_number": 6,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 149,
            "completion_tokens": 640,
            "total_tokens": 789,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/pppp2pp/4pb2/5p2/3P4/5N2/PPPNPPPP/R2QKB1R w KQkq - 0 6"
    },
    {
      "turn": 13,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "exf5",
          "aggressive_uci": "e4f5",
          "aggressive_response": "7. exf5 exf5 8. Bc4 d5 9. Qe2+ Kf7 10. Ne5+ Kg7 11. Bb3 Re8 12. f4 c5 13. c3 Nc6 14. Ndf3 cxd4 15. cxd4 Qa5+ 16. Qd2 Qxd2+ 17. Kxd2 Be6 18. Rac1 Rac8 19. Rc5 Nxd4 20. Rxc8 Nxb3+ 21. axb3 Rxc8 22. Nd4 Bg8 23. Ra1 a6 24. Ra5 Bd8 25. Ra1 Bb6 26. Kd3 Kf6 27. Nd7+ Ke7 28. Nxb6 Rc7 29. Re1+ Kd6 30. Re8 Bf7 31. Rd8+ Kc5 32. Na4+ Kb4 33. Nc3 b5 34. Rd6 Ka5 35. Nc6+ Kb6 36. Ne5+ Kc5 37. Rxa6 Be8 38. b4+ Kxb4 39. Nxd5+ Kb3 40. Nxc7 Kxb2 41. Nxe8 b4 42. Rb6 b3 43. Nc4+ Ka2 44. Kc3 b2 45. Rxb2+ Ka1 46. Kb3 g5 47. Na3 gxf4 48. Nc2# 1-0 7. exf5 exf5 8. Bc4 d5 9. Qe2+ Kf7",
          "aggressive_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 381,
            "total_tokens": 538,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "d5",
            "Qe2+",
            "Kf7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "h4",
          "positional_uci": "h2h4",
          "positional_response": "7. h4 O-O 8. h5 g5 9. exf5 exf5 10. Bd3 d5 11. c3 Nc6 12. Qc2 Bg7 13. O-O-O h6 14. Rde1 Qd6 15. Re2 Bd7 16. Rhe1 a6 17. Ne5 Nxe5 18. dxe5 Qe6 19. Nb3 b6 20. Nd4 Qe8 21. e6 Bb5 22. Nxf5 Bxd3 23. Qxd3 Qxh5 24. Nxg7 Kxg7 25. Qxd5 Rae8 26. Qd7+ Kg8 27. e7 Rf4 28. Qxc7 Qf7 29. Qxb6 Rf6 30. Qb3 Qxb3 31. axb3 Kf7 32. f3 h5 33. Re5 g4 34. fxg4 hxg4 35. R1e4 Rf2 36. Rxg4 Rxe7 37. Rxe7+ Kxe7 38. b4 Kd6 39. Kb1 Kc6 40. Ka2 Kb5 41. Kb3 Rf5 42. c4+ Kb6 43. Rg6+ Kb7 44. Ka4 Rf2 45. b3 Ra2# 0-1\n46. b5 axb5+ 47. Kxb5 Rxb2+ 48. Kc5 Rc2 49. c4 Kc7",
          "positional_tokens": {
            "prompt_tokens": 157,
            "completion_tokens": 363,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "exf5",
            "exf5",
            "Bd3",
            "d5",
            "c3",
            "Nc6",
            "Qc2",
            "Bg7",
            "O-O-O",
            "h6",
            "Rde1",
            "Qd6",
            "Re2",
            "Bd7",
            "Rhe1",
            "a6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Qe6",
            "Nb3",
            "b6",
            "Nd4",
            "Qe8",
            "e6",
            "Bb5",
            "Nxf5",
            "Bxd3",
            "Qxd3",
            "Qxh5",
            "Nxg7",
            "Kxg7",
            "Qxd5",
            "Rae8",
            "Qd7+",
            "Kg8",
            "e7",
            "Rf4",
            "Qxc7",
            "Qf7",
            "Qxb6",
            "Rf6",
            "Qb3",
            "Qxb3",
            "axb3",
            "Kf7",
            "f3",
            "h5",
            "Re5",
            "g4",
            "fxg4",
            "hxg4",
            "R1e4",
            "Rf2",
            "Rxg4",
            "Rxe7",
            "Rxe7+",
            "Kxe7",
            "b4",
            "Kd6",
            "Kb1",
            "Kc6",
            "Ka2",
            "Kb5",
            "Kb3",
            "Rf5",
            "c4+",
            "Kb6",
            "Rg6+",
            "Kb7",
            "Ka4",
            "Rf2",
            "b3",
            "Ra2#",
            "b5",
            "axb5+",
            "Kxb5",
            "Rxb2+",
            "Kc5",
            "Rc2",
            "c4",
            "Kc7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "h4",
          "neutral_uci": "h2h4",
          "neutral_response": "7. h4 O-O 8. h5 g5 9. exf5 exf5 10. Bd3 d5 11. c3 Nc6 12. Qc2 Bg7 13. O-O-O h6 14. Rde1 Qd6 15. Re2 Bd7 16. Rhe1 a6 17. Ne5 Nxe5 18. dxe5 Qe6 19. Nb3 b6 20. Nd4 Qe8 21. e6 Bb5 22. Nxf5 Bxd3 23. Qxd3 Qxh5 24. Nxg7 Kxg7 25. Qxd5 Rae8 26. Qd7+ Kg8 27. e7 Rf4 28. Qxc7 Qf7 29. Qxb6 Rf6 30. Qb3 Qxb3 31. axb3 Kf7 32. f3 h5 33. Re5 g4 34. fxg4 hxg4 35. R1e4 Rf2 36. Rxg4 Rxe7 37. Rxe7+ Kxe7 38. b4 Kd6 39. Kb1 Kc6 40. Ka2 Kb5 41. Kb3 Rf5 42. c4+ Kb6 43. Rg6+ Kb7 44. Ka4 Rf2 45. b3 Ra2# 0-1 46. b5 axb5+ 47. Kxb5 Rxb2+ 48. Kc5 Rc2 49. c4 Kc7 50. Rg7+ Kd8 51. Kd5 Rd2+ 52. Kc6 Rc2 53. c5 Ke8 54. Kd6 Rd2+ 55. Kc7 Rc2 56. c6 Kf8 57. Rg5 Ke7 58. Kb7 Rb2+ 59. Kc8 Rc2 60. c7 Kd6 61. Rg6+ Ke7 62. Rg4 Kd6 63. Rd4+ Ke7 64. Kb7 Rb2+ 65. Kc6 Rc2+ 66. Kb6 Rb2+ 67. Kc5 Rc2+ 68. Rc4 Rxc4+ 69. Kxc4 Kd7 70. Kd5 Kxc7 71. Ke6 Kd8 72. Kf7 Kd7 73. g4 Kd6 74. g5 Ke5 75. g6 Kf5 76. g7 Ke5 77. g8=Q Kd5 78. Qg6 Ke5 79. Qe6+ Kd4 80. Qf5 Kc4 81. Qe5 Kd3 82.",
          "neutral_tokens": {
            "prompt_tokens": 156,
            "completion_tokens": 640,
            "total_tokens": 796,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "exf5",
            "exf5",
            "Bd3",
            "d5",
            "c3",
            "Nc6",
            "Qc2",
            "Bg7",
            "O-O-O",
            "h6",
            "Rde1",
            "Qd6",
            "Re2",
            "Bd7",
            "Rhe1",
            "a6",
            "Ne5",
            "Nxe5",
            "dxe5",
            "Qe6",
            "Nb3",
            "b6",
            "Nd4",
            "Qe8",
            "e6",
            "Bb5",
            "Nxf5",
            "Bxd3",
            "Qxd3",
            "Qxh5",
            "Nxg7",
            "Kxg7",
            "Qxd5",
            "Rae8",
            "Qd7+",
            "Kg8",
            "e7",
            "Rf4",
            "Qxc7",
            "Qf7",
            "Qxb6",
            "Rf6",
            "Qb3",
            "Qxb3",
            "axb3",
            "Kf7",
            "f3",
            "h5",
            "Re5",
            "g4",
            "fxg4",
            "hxg4",
            "R1e4",
            "Rf2",
            "Rxg4",
            "Rxe7",
            "Rxe7+",
            "Kxe7",
            "b4",
            "Kd6",
            "Kb1",
            "Kc6",
            "Ka2",
            "Kb5",
            "Kb3",
            "Rf5",
            "c4+",
            "Kb6",
            "Rg6+",
            "Kb7",
            "Ka4",
            "Rf2",
            "b3",
            "Ra2#",
            "b5",
            "axb5+",
            "Kxb5",
            "Rxb2+",
            "Kc5",
            "Rc2",
            "c4",
            "Kc7",
            "Rg7+",
            "Kd8",
            "Kd5",
            "Rd2+",
            "Kc6",
            "Rc2",
            "c5",
            "Ke8",
            "Kd6",
            "Rd2+",
            "Kc7",
            "Rc2",
            "c6",
            "Kf8",
            "Rg5",
            "Ke7",
            "Kb7",
            "Rb2+",
            "Kc8",
            "Rc2",
            "c7",
            "Kd6",
            "Rg6+",
            "Ke7",
            "Rg4",
            "Kd6",
            "Rd4+",
            "Ke7",
            "Kb7",
            "Rb2+",
            "Kc6",
            "Rc2+",
            "Kb6",
            "Rb2+",
            "Kc5",
            "Rc2+",
            "Rc4",
            "Rxc4+",
            "Kxc4",
            "Kd7",
            "Kd5",
            "Kxc7",
            "Ke6",
            "Kd8",
            "Kf7",
            "Kd7",
            "g4",
            "Kd6",
            "g5",
            "Ke5",
            "g6",
            "Kf5",
            "g7",
            "Ke5",
            "g8=Q",
            "Kd5",
            "Qg6",
            "Ke5",
            "Qe6+",
            "Kd4",
            "Qf5",
            "Kc4",
            "Qe5",
            "Kd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4f5",
          "positional_uci": "h2h4",
          "neutral_uci": "h2h4",
          "consensus_move": "h2h4",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bc4",
              "d5",
              "Qe2+",
              "Kf7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "exf5",
              "exf5",
              "Bd3",
              "d5",
              "c3",
              "Nc6",
              "Qc2",
              "Bg7",
              "O-O-O",
              "h6",
              "Rde1",
              "Qd6",
              "Re2",
              "Bd7",
              "Rhe1",
              "a6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Qe6",
              "Nb3",
              "b6",
              "Nd4",
              "Qe8",
              "e6",
              "Bb5",
              "Nxf5",
              "Bxd3",
              "Qxd3",
              "Qxh5",
              "Nxg7",
              "Kxg7",
              "Qxd5",
              "Rae8",
              "Qd7+",
              "Kg8",
              "e7",
              "Rf4",
              "Qxc7",
              "Qf7",
              "Qxb6",
              "Rf6",
              "Qb3",
              "Qxb3",
              "axb3",
              "Kf7",
              "f3",
              "h5",
              "Re5",
              "g4",
              "fxg4",
              "hxg4",
              "R1e4",
              "Rf2",
              "Rxg4",
              "Rxe7",
              "Rxe7+",
              "Kxe7",
              "b4",
              "Kd6",
              "Kb1",
              "Kc6",
              "Ka2",
              "Kb5",
              "Kb3",
              "Rf5",
              "c4+",
              "Kb6",
              "Rg6+",
              "Kb7",
              "Ka4",
              "Rf2",
              "b3",
              "Ra2#",
              "b5",
              "axb5+",
              "Kxb5",
              "Rxb2+",
              "Kc5",
              "Rc2",
              "c4",
              "Kc7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "exf5",
              "exf5",
              "Bd3",
              "d5",
              "c3",
              "Nc6",
              "Qc2",
              "Bg7",
              "O-O-O",
              "h6",
              "Rde1",
              "Qd6",
              "Re2",
              "Bd7",
              "Rhe1",
              "a6",
              "Ne5",
              "Nxe5",
              "dxe5",
              "Qe6",
              "Nb3",
              "b6",
              "Nd4",
              "Qe8",
              "e6",
              "Bb5",
              "Nxf5",
              "Bxd3",
              "Qxd3",
              "Qxh5",
              "Nxg7",
              "Kxg7",
              "Qxd5",
              "Rae8",
              "Qd7+",
              "Kg8",
              "e7",
              "Rf4",
              "Qxc7",
              "Qf7",
              "Qxb6",
              "Rf6",
              "Qb3",
              "Qxb3",
              "axb3",
              "Kf7",
              "f3",
              "h5",
              "Re5",
              "g4",
              "fxg4",
              "hxg4",
              "R1e4",
              "Rf2",
              "Rxg4",
              "Rxe7",
              "Rxe7+",
              "Kxe7",
              "b4",
              "Kd6",
              "Kb1",
              "Kc6",
              "Ka2",
              "Kb5",
              "Kb3",
              "Rf5",
              "c4+",
              "Kb6",
              "Rg6+",
              "Kb7",
              "Ka4",
              "Rf2",
              "b3",
              "Ra2#",
              "b5",
              "axb5+",
              "Kxb5",
              "Rxb2+",
              "Kc5",
              "Rc2",
              "c4",
              "Kc7",
              "Rg7+",
              "Kd8",
              "Kd5",
              "Rd2+",
              "Kc6",
              "Rc2",
              "c5",
              "Ke8",
              "Kd6",
              "Rd2+",
              "Kc7",
              "Rc2",
              "c6",
              "Kf8",
              "Rg5",
              "Ke7",
              "Kb7",
              "Rb2+",
              "Kc8",
              "Rc2",
              "c7",
              "Kd6",
              "Rg6+",
              "Ke7",
              "Rg4",
              "Kd6",
              "Rd4+",
              "Ke7",
              "Kb7",
              "Rb2+",
              "Kc6",
              "Rc2+",
              "Kb6",
              "Rb2+",
              "Kc5",
              "Rc2+",
              "Rc4",
              "Rxc4+",
              "Kxc4",
              "Kd7",
              "Kd5",
              "Kxc7",
              "Ke6",
              "Kd8",
              "Kf7",
              "Kd7",
              "g4",
              "Kd6",
              "g5",
              "Ke5",
              "g6",
              "Kf5",
              "g7",
              "Ke5",
              "g8=Q",
              "Kd5",
              "Qg6",
              "Ke5",
              "Qe6+",
              "Kd4",
              "Qf5",
              "Kc4",
              "Qe5",
              "Kd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 157,
            "completion_tokens": 381,
            "total_tokens": 538,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 157,
            "completion_tokens": 363,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 156,
            "completion_tokens": 640,
            "total_tokens": 796,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 470,
          "total_completion_tokens": 1384,
          "total_tokens": 1854
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 157,
            "completion_tokens": 381,
            "total_tokens": 538,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 157,
            "completion_tokens": 363,
            "total_tokens": 520,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 12,
            "turn_number": 7,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 156,
            "completion_tokens": 640,
            "total_tokens": 796,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/pppp3p/4pbp1/5p2/3PP3/5N2/PPPN1PPP/R2QKB1R w KQkq - 0 7"
    },
    {
      "turn": 15,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "c3",
          "aggressive_uci": "c2c3",
          "aggressive_response": "8. c3 O-O 9. Bd3 Nc6 10. Qe2 e5 11. dxe5 Nxe5 12. Nxe5 Bxe5 13. O-O-O fxe4 14. Nxe4 Be6 15. Kb1 Qe7 16. h5 g5 17. h6 Rae8 18. Rh5 Bf4 19. g3 Bf7 20. gxf4 Bxh5 21. Qxh5 Rxf4 22. Nxg5 Rxf2 23. Bxh7+ Kh8 24. Bg6 Ref8 25. Nf7+ R8xf7 26. Bxf7 Qxf7 27. Qxf7 Rxf7 28. Re1 Kh7 29. Re6 Rf1+ 30. Kc2 Rf2+ 31. Kb3 Rf7 32. Kc4 Rf4+ 33. Kd5 Rf5+ 34. Ke4 Rf7 35. b4 Rd7 36. Kf5 Rf7+ 37. Rf6 Re7 38. Kg5 Re5+ 39. Rf5 Re7 40. Kf6 Re3 41. Kf7 Rxc3 42. Rf6 Re3 43. Kf8 d5 44. Rf7+ Kxh6 45. Rxc7 d4 46. Rxb7 d3 47. Rd7 Kg6 48. a4 Kf6 49. b5 Re4 50. a5 Re5 51. b6 axb6 52. axb6 Rb5 53. b7 Ke6 54. Rxd3 Rxb7 55. Re3+ Kf6 56. Rf3+ Ke6 57. Re3+ Kf6 58. Rf3+ Ke6 59. Re3+ Kf6 60. Rf3+ Ke6 61. Re3+ Kf6 62. Rf3+ Ke6 63. Re3+ Kf6 64. Rf3+ Ke6 65. Re3+ Kf6 66. Rf3+ Ke6 67. Re3+ Kf6 68. Rf3+ Ke6 69. Re3+ Kf6 70. Rf3+ Ke6 71. Re3+ Kf6 72. Rf3+ Ke6 73. Re3+ Kf6 74. Rf3+ Ke6 75. Re3+ Kf6 76. Rf3+ Ke6 77. Re3+ Kf6 78. Rf3+ Ke6 79. Re3+ Kf6 80. Rf3+ Ke6 81. Re3+ Kf6",
          "aggressive_tokens": {
            "prompt_tokens": 164,
            "completion_tokens": 640,
            "total_tokens": 804,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Bd3",
            "Nc6",
            "Qe2",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Be6",
            "Kb1",
            "Qe7",
            "h5",
            "g5",
            "h6",
            "Rae8",
            "Rh5",
            "Bf4",
            "g3",
            "Bf7",
            "gxf4",
            "Bxh5",
            "Qxh5",
            "Rxf4",
            "Nxg5",
            "Rxf2",
            "Bxh7+",
            "Kh8",
            "Bg6",
            "Ref8",
            "Nf7+",
            "R8xf7",
            "Bxf7",
            "Qxf7",
            "Qxf7",
            "Rxf7",
            "Re1",
            "Kh7",
            "Re6",
            "Rf1+",
            "Kc2",
            "Rf2+",
            "Kb3",
            "Rf7",
            "Kc4",
            "Rf4+",
            "Kd5",
            "Rf5+",
            "Ke4",
            "Rf7",
            "b4",
            "Rd7",
            "Kf5",
            "Rf7+",
            "Rf6",
            "Re7",
            "Kg5",
            "Re5+",
            "Rf5",
            "Re7",
            "Kf6",
            "Re3",
            "Kf7",
            "Rxc3",
            "Rf6",
            "Re3",
            "Kf8",
            "d5",
            "Rf7+",
            "Kxh6",
            "Rxc7",
            "d4",
            "Rxb7",
            "d3",
            "Rd7",
            "Kg6",
            "a4",
            "Kf6",
            "b5",
            "Re4",
            "a5",
            "Re5",
            "b6",
            "axb6",
            "axb6",
            "Rb5",
            "b7",
            "Ke6",
            "Rxd3",
            "Rxb7",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6",
            "Rf3+",
            "Ke6",
            "Re3+",
            "Kf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "c3",
          "positional_uci": "c2c3",
          "positional_response": "8. c3 O-O 9. Bd3 Nc6 10. Qe2 e5 11. dxe5 Nxe5 12. Nxe5 Bxe5 13. O-O-O fxe4 14. Nxe4 Be6 15. Kb1 Qe7 16. h5 Rae8 17. hxg6 hxg6 18. Rh6 Qg7 19. Rdh1 Bf5 20. g4 Bxe4 21. Bxe4 Bf4 22. Qc4+ Rf7 23. Rxg6 Rxe4 24. Rxg7+ Kxg7 25. Qxe4 Be5 26. Rh7+ Kf8 27. Rxf7+ Kxf7 28. Qxb7 Ke6 29. Qxc7 Kd5 30. Qxa7 Ke4 31. Qe3+ Kd5 32. f4 Bf6 33. g5 Bd8 34. f5 Kc6 35. f6 Kd7 36. f7 Be7 37. g6 Bf8 38. Qe8+ Kc7 39. Qxf8 Kc6 40. Qxd6+ Kxd6 41. f8=Q+ Ke5 42. g7 Ke4 43. g8=Q Kd3 44. Qd5+ Ke2 45. Qff3+ Ke1 46. Qdd1# d4 e5 Qd6",
          "positional_tokens": {
            "prompt_tokens": 164,
            "completion_tokens": 342,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bd3",
            "Nc6",
            "Qe2",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Be6",
            "Kb1",
            "Qe7",
            "h5",
            "Rae8",
            "hxg6",
            "hxg6",
            "Rh6",
            "Qg7",
            "Rdh1",
            "Bf5",
            "g4",
            "Bxe4",
            "Bxe4",
            "Bf4",
            "Qc4+",
            "Rf7",
            "Rxg6",
            "Rxe4",
            "Rxg7+",
            "Kxg7",
            "Qxe4",
            "Be5",
            "Rh7+",
            "Kf8",
            "Rxf7+",
            "Kxf7",
            "Qxb7",
            "Ke6",
            "Qxc7",
            "Kd5",
            "Qxa7",
            "Ke4",
            "Qe3+",
            "Kd5",
            "f4",
            "Bf6",
            "g5",
            "Bd8",
            "f5",
            "Kc6",
            "f6",
            "Kd7",
            "f7",
            "Be7",
            "g6",
            "Bf8",
            "Qe8+",
            "Kc7",
            "Qxf8",
            "Kc6",
            "Qxd6+",
            "Kxd6",
            "f8=Q+",
            "Ke5",
            "g7",
            "Ke4",
            "g8=Q",
            "Kd3",
            "Qd5+",
            "Ke2",
            "Qff3+",
            "Ke1",
            "Qdd1#",
            "d4",
            "e5",
            "Qd6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "c3",
          "neutral_uci": "c2c3",
          "neutral_response": "8. c3 O-O 9. Bd3 Nc6 10. Qe2 e5 11. dxe5 Nxe5 12. Nxe5 Bxe5 13. O-O-O fxe4 14. Nxe4 Be6 15. Kb1 Qe8 16. h5 Qa4 17. b3 Qa5 18. hxg6 hxg6 19. Ng5 Rae8 20. Nxe6 Rxe6 21. Bc4 Rfe8 22. Qg4 Kf7 23. Rh7+ Bg7 24. Bxe6+ Rxe6 25. Rxg7+ Kxg7 26. Qxe6 Qxc3 27. Qe7+ Kh6 28. Rh1+ 1-0\n\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3 O-O 9. Bd3 Nc6 10. Qe2 e5 11. dxe5 Nxe5 12. Nxe5 Bxe5 13. O-O-O fxe4 14. Nxe4 Be6 15. Kb1 Qe8 16. h5 Qa4 17. b3 Qa5 18. hxg6 hxg6 19. Ng5 Rae8 20. Nxe6 Rxe6 21. Bc4 Rfe8 22. Qg4 Kf7 23. Rh7+ Bg7 24. Bxe6+ Rxe6 25. Rxg7+ Kxg7 26. Qxe6 Qxc3 27. Qe7+ Kh6 28. Rh1+ 1-0 e6 d4 d5",
          "neutral_tokens": {
            "prompt_tokens": 163,
            "completion_tokens": 427,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Bd3",
            "Nc6",
            "Qe2",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Be6",
            "Kb1",
            "Qe8",
            "h5",
            "Qa4",
            "b3",
            "Qa5",
            "hxg6",
            "hxg6",
            "Ng5",
            "Rae8",
            "Nxe6",
            "Rxe6",
            "Bc4",
            "Rfe8",
            "Qg4",
            "Kf7",
            "Rh7+",
            "Bg7",
            "Bxe6+",
            "Rxe6",
            "Rxg7+",
            "Kxg7",
            "Qxe6",
            "Qxc3",
            "Qe7+",
            "Kh6",
            "Rh1+",
            "e6",
            "d4",
            "d5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c2c3",
          "positional_uci": "c2c3",
          "neutral_uci": "c2c3",
          "consensus_move": "c2c3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Bd3",
              "Nc6",
              "Qe2",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Be6",
              "Kb1",
              "Qe7",
              "h5",
              "g5",
              "h6",
              "Rae8",
              "Rh5",
              "Bf4",
              "g3",
              "Bf7",
              "gxf4",
              "Bxh5",
              "Qxh5",
              "Rxf4",
              "Nxg5",
              "Rxf2",
              "Bxh7+",
              "Kh8",
              "Bg6",
              "Ref8",
              "Nf7+",
              "R8xf7",
              "Bxf7",
              "Qxf7",
              "Qxf7",
              "Rxf7",
              "Re1",
              "Kh7",
              "Re6",
              "Rf1+",
              "Kc2",
              "Rf2+",
              "Kb3",
              "Rf7",
              "Kc4",
              "Rf4+",
              "Kd5",
              "Rf5+",
              "Ke4",
              "Rf7",
              "b4",
              "Rd7",
              "Kf5",
              "Rf7+",
              "Rf6",
              "Re7",
              "Kg5",
              "Re5+",
              "Rf5",
              "Re7",
              "Kf6",
              "Re3",
              "Kf7",
              "Rxc3",
              "Rf6",
              "Re3",
              "Kf8",
              "d5",
              "Rf7+",
              "Kxh6",
              "Rxc7",
              "d4",
              "Rxb7",
              "d3",
              "Rd7",
              "Kg6",
              "a4",
              "Kf6",
              "b5",
              "Re4",
              "a5",
              "Re5",
              "b6",
              "axb6",
              "axb6",
              "Rb5",
              "b7",
              "Ke6",
              "Rxd3",
              "Rxb7",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6",
              "Rf3+",
              "Ke6",
              "Re3+",
              "Kf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Bd3",
              "Nc6",
              "Qe2",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Be6",
              "Kb1",
              "Qe7",
              "h5",
              "Rae8",
              "hxg6",
              "hxg6",
              "Rh6",
              "Qg7",
              "Rdh1",
              "Bf5",
              "g4",
              "Bxe4",
              "Bxe4",
              "Bf4",
              "Qc4+",
              "Rf7",
              "Rxg6",
              "Rxe4",
              "Rxg7+",
              "Kxg7",
              "Qxe4",
              "Be5",
              "Rh7+",
              "Kf8",
              "Rxf7+",
              "Kxf7",
              "Qxb7",
              "Ke6",
              "Qxc7",
              "Kd5",
              "Qxa7",
              "Ke4",
              "Qe3+",
              "Kd5",
              "f4",
              "Bf6",
              "g5",
              "Bd8",
              "f5",
              "Kc6",
              "f6",
              "Kd7",
              "f7",
              "Be7",
              "g6",
              "Bf8",
              "Qe8+",
              "Kc7",
              "Qxf8",
              "Kc6",
              "Qxd6+",
              "Kxd6",
              "f8=Q+",
              "Ke5",
              "g7",
              "Ke4",
              "g8=Q",
              "Kd3",
              "Qd5+",
              "Ke2",
              "Qff3+",
              "Ke1",
              "Qdd1#",
              "d4",
              "e5",
              "Qd6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "Bd3",
              "Nc6",
              "Qe2",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Be6",
              "Kb1",
              "Qe8",
              "h5",
              "Qa4",
              "b3",
              "Qa5",
              "hxg6",
              "hxg6",
              "Ng5",
              "Rae8",
              "Nxe6",
              "Rxe6",
              "Bc4",
              "Rfe8",
              "Qg4",
              "Kf7",
              "Rh7+",
              "Bg7",
              "Bxe6+",
              "Rxe6",
              "Rxg7+",
              "Kxg7",
              "Qxe6",
              "Qxc3",
              "Qe7+",
              "Kh6",
              "Rh1+",
              "e6",
              "d4",
              "d5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 164,
            "completion_tokens": 640,
            "total_tokens": 804,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 164,
            "completion_tokens": 342,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 163,
            "completion_tokens": 427,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 491,
          "total_completion_tokens": 1409,
          "total_tokens": 1900
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 164,
            "completion_tokens": 640,
            "total_tokens": 804,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 164,
            "completion_tokens": 342,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 14,
            "turn_number": 8,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 163,
            "completion_tokens": 427,
            "total_tokens": 590,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp4p/3ppbp1/5p2/3PP2P/5N2/PPPN1PP1/R2QKB1R w KQkq - 0 8"
    },
    {
      "turn": 17,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bd3",
          "aggressive_uci": "f1d3",
          "aggressive_response": "9. Bd3 O-O 10. Qe2 Nc6 11. O-O-O e5 12. dxe5 Nxe5 13. Nxe5 Bxe5 14. h5 Qf6 15. hxg6 hxg6 16. exf5 Bxf5 17. Bxf5 Qxf5 18. Qc4+ Qf7 19. Qh4 Qg7 20. Nf3 Bf6 21. Qc4+ Qf7 22. Qxf7+ Rxf7 23. Rde1 Kg7 24. Kc2 Rh8 25. Rxh8 Kxh8 26. Re8+ Kg7 27. Kd3 Re7 28. Rxe7+ Bxe7 29. Ke4 c6 30. Nd4 Kf6 31. f4 d5+ 32. Kf3 Bd6 33. g4 a6 34. g5+ Kf7 35. Kg4 c5 36. Ne2 b5 37. f5 gxf5+ 38. Kxf5 b4 39. cxb4 cxb4 40. b3 Bc5 41. Nf4 d4 42. g6+ Kg8 43. Nd3 Bf8 44. Kf6 Bg7+ 45. Ke6 a5 46. Kd5 Bf6 47. Kc5 Kg7 48. Kb5 Bd8 49. Ne5 Bc7 50. Nc6 d3 51. Nd4 d2 52. Ne6+ Kxg6 53. Nxc7 d1=Q 54. Kxa5 Qd8 55. Kxb4 Qxc7 56. a4 Kf6 57. Kb5 Ke6 58. b4 Kd6 59. a5 Qc6# 1-0 1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3 Bg7 9. Bd3 O-O 10. Qe2 Nc6 11. O-O-O e5 12. dxe5 Nxe5 13. Nxe5 Bxe5 14. h5 Qf6 15. hxg6 hxg6 16. exf5 Bxf5 17. Bxf5 Qxf5 18. Qc4+ Qf7 19. Qh4 Qg7 20. Nf3 Bf6 21. Qc4+ Qf7 22. Qxf7+ Rxf7 23. Rde1 Kg7 24. Kc2 Rh8 25",
          "aggressive_tokens": {
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Qe2",
            "Nc6",
            "O-O-O",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "h5",
            "Qf6",
            "hxg6",
            "hxg6",
            "exf5",
            "Bxf5",
            "Bxf5",
            "Qxf5",
            "Qc4+",
            "Qf7",
            "Qh4",
            "Qg7",
            "Nf3",
            "Bf6",
            "Qc4+",
            "Qf7",
            "Qxf7+",
            "Rxf7",
            "Rde1",
            "Kg7",
            "Kc2",
            "Rh8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bd3",
          "positional_uci": "f1d3",
          "positional_response": "9. Bd3 O-O 10. Qe2 Nc6 11. O-O-O e5 12. dxe5 Nxe5 13. Nxe5 Bxe5 14. exf5 Bxf5 15. Bxf5 Rxf5 16. g3 Qf8 17. f4 Bg7 18. Rhe1 Kh8 19. Nf3 Ra5 20. Kb1 Qf5+ 21. Qe4 Qb5 22. Nd4 Qa4 23. a3 c5 24. Ne6 Bxc3 25. Qxa4 Rxa4 26. bxc3 Rxa3 27. Kb2 Ra6 28. Nc7 Rb6+ 29. Kc2 Rc8 30. Re7 Rc6 31. Nd5 b5 32. Nf6 R6c7 33. Rde1 b4 34. Rxc7 Rxc7 35. Ne8 Rc6 36. Re6 bxc3 37. Rxd6 Rxd6 38. Nxd6 Kg7 39. Kxc3 Kf6 40. Kc4 Ke6 41. Kxc5 a5 42. Nc4 a4 43. Kb4 Kf5 44. Ne3+ Ke4 45. Ng4 Kf3 46. Nf6 h5 47. Kxa4 Kxg3 48. Nd5 Kxh4 49. Kb4 Kg4 50. Kc4 h4 51. Kd3 h3 52. Ke2 h2 53. Ne3+ Kxf4 54. Ng2+ Kg3 55. Ne3 h1=Q 56. Nf1+ Kf4 57. Nd2 Qg2+ 58. Kd3 Qxd2+ 59. Kxd2 Kf3 60. Ke1 Kg2 61. Ke2 g5 62. Ke3 g4 63. Kf4 g3 64. Kg4 Kf2 65. Kh3 g2 66. Kh2 g1=Q+ 67. Kh3 Qg3# 0-1 1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3 Bg7 9. Bd3 O-O 10. Qe2 Nc6 11. O-O-O e5 12. dxe5 Nxe5 13. Nxe5 Bxe5 14. exf5 Bxf5 15. Bxf5 Rxf5 16. g3 Qf8 17. f4 Bg7 18. Rhe1 Kh8",
          "positional_tokens": {
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "Qe2",
            "Nc6",
            "O-O-O",
            "e5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "exf5",
            "Bxf5",
            "Bxf5",
            "Rxf5",
            "g3",
            "Qf8",
            "f4",
            "Bg7",
            "Rhe1",
            "Kh8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qc2",
          "neutral_uci": "d1c2",
          "neutral_response": "9. Qc2 O-O 10. O-O-O Nc6 11. Bd3 Ne7 12. h5 d5 13. hxg6 hxg6 14. exf5 exf5 15. Rde1 Qd6 16. Ne5 c5 17. Ndf3 c4 18. Be2 b5 19. Qd2 a5 20. Qg5 Ra6 21. Qh4 Re8 22. Qh7+ Kf8 23. Ng5 Qf6 24. f4 b4 25. Qh4 Kg8 26. Qh7+ Kf8 27. Qh4 Kg8 28. Qh7+ Kf8 29. Qh4 Kg8 30. Qh7+ Kf8 31. Qh4 Kg8 32. Qh7+ Kf8 33. Qh4 Kg8 34. Qh7+ Kf8 35. Qh4 Kg8 36. Qh7+ Kf8 37. Qh4 Kg8 38. Qh7+ Kf8 39. Qh4 Kg8 40. Qh7+ Kf8 41. Qh4 Kg8 42. Qh7+ Kf8 43. Qh4 Kg8 44. Qh7+ Kf8 45. Qh4 Kg8 46. Qh7+ Kf8 47. Qh4 Kg8 48. Qh7+ Kf8 49. Qh4 Kg8 50. Qh7+ Kf8 51. Qh4 Kg8 52. Qh7+ Kf8 53. Qh4 Kg8 54. Qh7+ Kf8 55. Qh4 Kg8 56. Qh7+ Kf8 57. Qh4 Kg8 58. Qh7+ Kf8 59. Qh4 Kg8 60. Qh7+ Kf8 61. Qh4 Kg8 62. Qh7+ Kf8 63. Qh4 Kg8 64. Qh7+ Kf8 65. Qh4 Kg8 66. Qh7+ Kf8 67. Qh4 Kg8 68. Qh7+ Kf8 69. Qh4 Kg8 70. Qh7+ Kf8 71. Qh4 Kg8 72. Qh7+ Kf8 73. Qh4 Kg8 74. Qh7+ Kf8 75. Qh4 Kg8 76. Qh7+ Kf8 77. Qh4 Kg8 78. Qh7+ Kf8 79. Qh4 Kg8 80. Qh7+ Kf8 81. Qh4 Kg",
          "neutral_tokens": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O-O",
            "Nc6",
            "Bd3",
            "Ne7",
            "h5",
            "d5",
            "hxg6",
            "hxg6",
            "exf5",
            "exf5",
            "Rde1",
            "Qd6",
            "Ne5",
            "c5",
            "Ndf3",
            "c4",
            "Be2",
            "b5",
            "Qd2",
            "a5",
            "Qg5",
            "Ra6",
            "Qh4",
            "Re8",
            "Qh7+",
            "Kf8",
            "Ng5",
            "Qf6",
            "f4",
            "b4",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4",
            "Kg8",
            "Qh7+",
            "Kf8",
            "Qh4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f1d3",
          "positional_uci": "f1d3",
          "neutral_uci": "d1c2",
          "consensus_move": "f1d3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "Qe2",
              "Nc6",
              "O-O-O",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "h5",
              "Qf6",
              "hxg6",
              "hxg6",
              "exf5",
              "Bxf5",
              "Bxf5",
              "Qxf5",
              "Qc4+",
              "Qf7",
              "Qh4",
              "Qg7",
              "Nf3",
              "Bf6",
              "Qc4+",
              "Qf7",
              "Qxf7+",
              "Rxf7",
              "Rde1",
              "Kg7",
              "Kc2",
              "Rh8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Qe2",
              "Nc6",
              "O-O-O",
              "e5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "exf5",
              "Bxf5",
              "Bxf5",
              "Rxf5",
              "g3",
              "Qf8",
              "f4",
              "Bg7",
              "Rhe1",
              "Kh8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "O-O-O",
              "Nc6",
              "Bd3",
              "Ne7",
              "h5",
              "d5",
              "hxg6",
              "hxg6",
              "exf5",
              "exf5",
              "Rde1",
              "Qd6",
              "Ne5",
              "c5",
              "Ndf3",
              "c4",
              "Be2",
              "b5",
              "Qd2",
              "a5",
              "Qg5",
              "Ra6",
              "Qh4",
              "Re8",
              "Qh7+",
              "Kf8",
              "Ng5",
              "Qf6",
              "f4",
              "b4",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4",
              "Kg8",
              "Qh7+",
              "Kf8",
              "Qh4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 515,
          "total_completion_tokens": 1920,
          "total_tokens": 2435
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 172,
            "completion_tokens": 640,
            "total_tokens": 812,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 16,
            "turn_number": 9,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 171,
            "completion_tokens": 640,
            "total_tokens": 811,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "rnbqk2r/ppp3bp/3pp1p1/5p2/3PP2P/2P2N2/PP1N1PP1/R2QKB1R w KQkq - 1 9"
    },
    {
      "turn": 19,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qe2",
          "aggressive_uci": "d1e2",
          "aggressive_response": "10. Qe2 O-O 11. O-O-O Nf6 12. e5 Ng4 13. h5 dxe5 14. dxe5 Qe7 15. hxg6 hxg6 16. Nh4 Qf7 17. f4 Bd7 18. Ndf3 Bh6 19. g3 Bc6 20. Bc4 Rad8 21. Rxd8 Rxd8 22. Rd1 Rxd1+ 23. Kxd1 Qd7+ 24. Kc1 Kf7 25. Nd4 Bd5 26. Bxd5 Qxd5 27. Qf3 Qxf3 28. Nhxf3 c6 29. Kd2 Bf8 30. Ng5+ Ke7 31. Ngxe6 Bh6 32. Nc5 Nxe5 33. Nxb7 Nc4+ 34. Kc2 Ne3+ 35. Kd3 Nf1 36. Ne2 Nh2 37. Na5 Kd6 38. Nc4+ Kc5 39. b4+ Kb5 40. Nd6+ Ka4 41. Kc4 Bf8 42. Nc8 a5 43. Nb6+ Ka3 44. bxa5 Kxa2 45. a6 Kb2 46. a7 Kc2 47. a8=Q Kd2 48. Nd4 Ke3 49. Qxf8 Kf2 50. Qh6 Kxg3 51. Qxg6+ Kxf4 52. Qxf5+ Ke3 53. Qh3+ Kd2 54. Qxh2+ Kc1 55. Qc2# e5 56. Nb3# e4 57. Qxc1# e3 58. Qxe3# e2 59. Qxe2# e1=Q 60. Qxe1# e5 61. Qxe5# e4 62. Qxe4# e3 63. Qxe3# e2 64. Qxe2# e1=Q 65. Qxe1# e5 66. Qxe5# e4 67. Qxe4# e3 68. Qxe3# e2 69. Qxe2# e5 70. Qxe5# e4 71. Qxe4# e3 72. Qxe3# e2 73. Qxe2# e5 74. Qxe5# e4 75. Qxe4# e3 76. Qxe3# e2 77. Qxe2# e5 78. Qxe5# e4 79. Qxe4# e3 80. Qxe3# e2 81. Qxe2# e5 82. Qxe5",
          "aggressive_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O-O",
            "Nf6",
            "e5",
            "Ng4",
            "h5",
            "dxe5",
            "dxe5",
            "Qe7",
            "hxg6",
            "hxg6",
            "Nh4",
            "Qf7",
            "f4",
            "Bd7",
            "Ndf3",
            "Bh6",
            "g3",
            "Bc6",
            "Bc4",
            "Rad8",
            "Rxd8",
            "Rxd8",
            "Rd1",
            "Rxd1+",
            "Kxd1",
            "Qd7+",
            "Kc1",
            "Kf7",
            "Nd4",
            "Bd5",
            "Bxd5",
            "Qxd5",
            "Qf3",
            "Qxf3",
            "Nhxf3",
            "c6",
            "Kd2",
            "Bf8",
            "Ng5+",
            "Ke7",
            "Ngxe6",
            "Bh6",
            "Nc5",
            "Nxe5",
            "Nxb7",
            "Nc4+",
            "Kc2",
            "Ne3+",
            "Kd3",
            "Nf1",
            "Ne2",
            "Nh2",
            "Na5",
            "Kd6",
            "Nc4+",
            "Kc5",
            "b4+",
            "Kb5",
            "Nd6+",
            "Ka4",
            "Kc4",
            "Bf8",
            "Nc8",
            "a5",
            "Nb6+",
            "Ka3",
            "bxa5",
            "Kxa2",
            "a6",
            "Kb2",
            "a7",
            "Kc2",
            "a8=Q",
            "Kd2",
            "Nd4",
            "Ke3",
            "Qxf8",
            "Kf2",
            "Qh6",
            "Kxg3",
            "Qxg6+",
            "Kxf4",
            "Qxf5+",
            "Ke3",
            "Qh3+",
            "Kd2",
            "Qxh2+",
            "Kc1",
            "Qc2#",
            "e5",
            "Nb3#",
            "e4",
            "Qxc1#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e1=Q",
            "Qxe1#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e1=Q",
            "Qxe1#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e5",
            "Qxe5#",
            "e4",
            "Qxe4#",
            "e3",
            "Qxe3#",
            "e2",
            "Qxe2#",
            "e5",
            "Qxe5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Qe2",
          "positional_uci": "d1e2",
          "positional_response": "10. Qe2 O-O 11. O-O-O Nf6 12. e5 Nh5 13. g3 d5 14. Ng5 Qe7 15. Rdg1 c5 16. f4\ncxd4 17. cxd4 Bd7 18. Kb1 Rfc8 19. Qe3 Qb4 20. g4 fxg4 21. Rxg4 Rc6 22. Nxh7\nKxh7 23. Bxg6+ Kh8 24. Bxh5 Rac8 25. Nb3 a5 26. Rhg1 a4 27. Rxg7 axb3 28. f5\nbxa2+ 29. Ka1 Rc1+ 30. Rxc1 Rxc1+ 31. Qxc1 Kxg7 32. Qg5+ Kf8 33. Qf6+ Kg8 34.\nBf7+ Kf8 35. Bxe6+ Ke8 36. Qf7+ Kd8 37. Qxd7# Qe1+ 38. Kxa2 Qa5+ 39. Kb3 Qb6+\n40. Kc3 Qa5+ 41. Kd3 Qa6+ 42. Ke3 Qc6 43. Qxc6 bxc6 44. h5 Ke7 45. h6 Kf8 46.\nf6 c5 47. h7 cxd4+ 48. Kxd4 Ke8 49. h8=Q# Qd8 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd7 Qe7 Qd",
          "positional_tokens": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O-O",
            "Nf6",
            "e5",
            "Nh5",
            "g3",
            "d5",
            "Ng5",
            "Qe7",
            "Rdg1",
            "c5",
            "f4",
            "cxd4",
            "cxd4",
            "Bd7",
            "Kb1",
            "Rfc8",
            "Qe3",
            "Qb4",
            "g4",
            "fxg4",
            "Rxg4",
            "Rc6",
            "Nxh7",
            "Kxh7",
            "Bxg6+",
            "Kh8",
            "Bxh5",
            "Rac8",
            "Nb3",
            "a5",
            "Rhg1",
            "a4",
            "Rxg7",
            "axb3",
            "f5",
            "bxa2+",
            "Ka1",
            "Rc1+",
            "Rxc1",
            "Rxc1+",
            "Qxc1",
            "Kxg7",
            "Qg5+",
            "Kf8",
            "Qf6+",
            "Kg8",
            "Bf7+",
            "Kf8",
            "Bxe6+",
            "Ke8",
            "Qf7+",
            "Kd8",
            "Qxd7#",
            "Qe1+",
            "Kxa2",
            "Qa5+",
            "Kb3",
            "Qb6+",
            "Kc3",
            "Qa5+",
            "Kd3",
            "Qa6+",
            "Ke3",
            "Qc6",
            "Qxc6",
            "bxc6",
            "h5",
            "Ke7",
            "h6",
            "Kf8",
            "f6",
            "c5",
            "h7",
            "cxd4+",
            "Kxd4",
            "Ke8",
            "h8=Q#",
            "Qd8",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7",
            "Qd7",
            "Qe7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qe2",
          "neutral_uci": "d1e2",
          "neutral_response": "10. Qe2 O-O 11. O-O-O Nf6 12. e5 Ng4 13. h5 dxe5 14. dxe5 Nxe5 15. Nxe5 Bxe5 16. hxg6 hxg6 17. Nf3 Bf4+ 18. Kb1 Qf6 19. g3 Bd6 20. Rh6 Kg7 21. Rdh1 Rg8 22. Qe3 Bd7 23. Ng5 Kf8 24. Nh7+ Kf7 25. Nxf6 Kxf6 26. Rh7 Bc6 27. Re1 Rae8 28. Bc4 Be4+ 29. Ka1 g5 30. f3 Kg6 31. Reh1 Bf8 32. fxe4 f4 33. gxf4 g4 34. f5+ Kf6 35. Qd4+ Kg5 36. R1h5+ Kf4 37. e5+ Kf3 38. Qd3+ Kf4 39. Qd4+ Kf3 40. Rh3+ gxh3 41. Rxh3+ Kg2 42. Qh4 Bc5 43. Rh2+ Kf3 44. Be2+ Ke3 45. Qf2+ Ke4 46. Qxc5 Kxf5 47. Bd3+ Kg5 48. Qe3+ Kg4 49. Rg2+ Kh4 50. Qh6# O-O-O 51. Rxg8 Rxg8 52. Qh7 Rg1+ 53. Bb1 Kg3 54. Qg6+ Kf2 55. Qxe6 Ke3 56. Qd7 c5 57. e6 b5 58. e7 b4 59. e8=Q+ Kf2 60. Qdf7+ Kg2 61. Qeg8+ Kh1 62. Qfh7# c4 63. Qxg1+ Kxg1 64. Qxa7+ Kf1 65. cxb4 Ke2 66. Qd4 c3 67. bxc3 Kf3 68. c4 Ke2 69. c5 Kf3 70. c6 Ke2 71. c7 Kf3 72. c8=Q Ke2 73. Qe8+ Kf3 74. Qf6+ Kg4 75. Qg8+ Kh5 76. Qfh8# c5 77. Qg6+ Kh4 78. Qhh5# cxb4 79. Qgg4# c3 80. Qhh3# cxb2+ 81. Kxb2# c4 82. Qgg3# c3+",
          "neutral_tokens": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "O-O",
            "O-O-O",
            "Nf6",
            "e5",
            "Ng4",
            "h5",
            "dxe5",
            "dxe5",
            "Nxe5",
            "Nxe5",
            "Bxe5",
            "hxg6",
            "hxg6",
            "Nf3",
            "Bf4+",
            "Kb1",
            "Qf6",
            "g3",
            "Bd6",
            "Rh6",
            "Kg7",
            "Rdh1",
            "Rg8",
            "Qe3",
            "Bd7",
            "Ng5",
            "Kf8",
            "Nh7+",
            "Kf7",
            "Nxf6",
            "Kxf6",
            "Rh7",
            "Bc6",
            "Re1",
            "Rae8",
            "Bc4",
            "Be4+",
            "Ka1",
            "g5",
            "f3",
            "Kg6",
            "Reh1",
            "Bf8",
            "fxe4",
            "f4",
            "gxf4",
            "g4",
            "f5+",
            "Kf6",
            "Qd4+",
            "Kg5",
            "R1h5+",
            "Kf4",
            "e5+",
            "Kf3",
            "Qd3+",
            "Kf4",
            "Qd4+",
            "Kf3",
            "Rh3+",
            "gxh3",
            "Rxh3+",
            "Kg2",
            "Qh4",
            "Bc5",
            "Rh2+",
            "Kf3",
            "Be2+",
            "Ke3",
            "Qf2+",
            "Ke4",
            "Qxc5",
            "Kxf5",
            "Bd3+",
            "Kg5",
            "Qe3+",
            "Kg4",
            "Rg2+",
            "Kh4",
            "Qh6#",
            "O-O-O",
            "Rxg8",
            "Rxg8",
            "Qh7",
            "Rg1+",
            "Bb1",
            "Kg3",
            "Qg6+",
            "Kf2",
            "Qxe6",
            "Ke3",
            "Qd7",
            "c5",
            "e6",
            "b5",
            "e7",
            "b4",
            "e8=Q+",
            "Kf2",
            "Qdf7+",
            "Kg2",
            "Qeg8+",
            "Kh1",
            "Qfh7#",
            "c4",
            "Qxg1+",
            "Kxg1",
            "Qxa7+",
            "Kf1",
            "cxb4",
            "Ke2",
            "Qd4",
            "c3",
            "bxc3",
            "Kf3",
            "c4",
            "Ke2",
            "c5",
            "Kf3",
            "c6",
            "Ke2",
            "c7",
            "Kf3",
            "c8=Q",
            "Ke2",
            "Qe8+",
            "Kf3",
            "Qf6+",
            "Kg4",
            "Qg8+",
            "Kh5",
            "Qfh8#",
            "c5",
            "Qg6+",
            "Kh4",
            "Qhh5#",
            "cxb4",
            "Qgg4#",
            "c3",
            "Qhh3#",
            "cxb2+",
            "Kxb2#",
            "c4",
            "Qgg3#",
            "c3+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d1e2",
          "positional_uci": "d1e2",
          "neutral_uci": "d1e2",
          "consensus_move": "d1e2",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "O-O-O",
              "Nf6",
              "e5",
              "Ng4",
              "h5",
              "dxe5",
              "dxe5",
              "Qe7",
              "hxg6",
              "hxg6",
              "Nh4",
              "Qf7",
              "f4",
              "Bd7",
              "Ndf3",
              "Bh6",
              "g3",
              "Bc6",
              "Bc4",
              "Rad8",
              "Rxd8",
              "Rxd8",
              "Rd1",
              "Rxd1+",
              "Kxd1",
              "Qd7+",
              "Kc1",
              "Kf7",
              "Nd4",
              "Bd5",
              "Bxd5",
              "Qxd5",
              "Qf3",
              "Qxf3",
              "Nhxf3",
              "c6",
              "Kd2",
              "Bf8",
              "Ng5+",
              "Ke7",
              "Ngxe6",
              "Bh6",
              "Nc5",
              "Nxe5",
              "Nxb7",
              "Nc4+",
              "Kc2",
              "Ne3+",
              "Kd3",
              "Nf1",
              "Ne2",
              "Nh2",
              "Na5",
              "Kd6",
              "Nc4+",
              "Kc5",
              "b4+",
              "Kb5",
              "Nd6+",
              "Ka4",
              "Kc4",
              "Bf8",
              "Nc8",
              "a5",
              "Nb6+",
              "Ka3",
              "bxa5",
              "Kxa2",
              "a6",
              "Kb2",
              "a7",
              "Kc2",
              "a8=Q",
              "Kd2",
              "Nd4",
              "Ke3",
              "Qxf8",
              "Kf2",
              "Qh6",
              "Kxg3",
              "Qxg6+",
              "Kxf4",
              "Qxf5+",
              "Ke3",
              "Qh3+",
              "Kd2",
              "Qxh2+",
              "Kc1",
              "Qc2#",
              "e5",
              "Nb3#",
              "e4",
              "Qxc1#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e1=Q",
              "Qxe1#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e1=Q",
              "Qxe1#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e5",
              "Qxe5#",
              "e4",
              "Qxe4#",
              "e3",
              "Qxe3#",
              "e2",
              "Qxe2#",
              "e5",
              "Qxe5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "O-O-O",
              "Nf6",
              "e5",
              "Nh5",
              "g3",
              "d5",
              "Ng5",
              "Qe7",
              "Rdg1",
              "c5",
              "f4",
              "cxd4",
              "cxd4",
              "Bd7",
              "Kb1",
              "Rfc8",
              "Qe3",
              "Qb4",
              "g4",
              "fxg4",
              "Rxg4",
              "Rc6",
              "Nxh7",
              "Kxh7",
              "Bxg6+",
              "Kh8",
              "Bxh5",
              "Rac8",
              "Nb3",
              "a5",
              "Rhg1",
              "a4",
              "Rxg7",
              "axb3",
              "f5",
              "bxa2+",
              "Ka1",
              "Rc1+",
              "Rxc1",
              "Rxc1+",
              "Qxc1",
              "Kxg7",
              "Qg5+",
              "Kf8",
              "Qf6+",
              "Kg8",
              "Bf7+",
              "Kf8",
              "Bxe6+",
              "Ke8",
              "Qf7+",
              "Kd8",
              "Qxd7#",
              "Qe1+",
              "Kxa2",
              "Qa5+",
              "Kb3",
              "Qb6+",
              "Kc3",
              "Qa5+",
              "Kd3",
              "Qa6+",
              "Ke3",
              "Qc6",
              "Qxc6",
              "bxc6",
              "h5",
              "Ke7",
              "h6",
              "Kf8",
              "f6",
              "c5",
              "h7",
              "cxd4+",
              "Kxd4",
              "Ke8",
              "h8=Q#",
              "Qd8",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7",
              "Qd7",
              "Qe7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "O-O-O",
              "Nf6",
              "e5",
              "Ng4",
              "h5",
              "dxe5",
              "dxe5",
              "Nxe5",
              "Nxe5",
              "Bxe5",
              "hxg6",
              "hxg6",
              "Nf3",
              "Bf4+",
              "Kb1",
              "Qf6",
              "g3",
              "Bd6",
              "Rh6",
              "Kg7",
              "Rdh1",
              "Rg8",
              "Qe3",
              "Bd7",
              "Ng5",
              "Kf8",
              "Nh7+",
              "Kf7",
              "Nxf6",
              "Kxf6",
              "Rh7",
              "Bc6",
              "Re1",
              "Rae8",
              "Bc4",
              "Be4+",
              "Ka1",
              "g5",
              "f3",
              "Kg6",
              "Reh1",
              "Bf8",
              "fxe4",
              "f4",
              "gxf4",
              "g4",
              "f5+",
              "Kf6",
              "Qd4+",
              "Kg5",
              "R1h5+",
              "Kf4",
              "e5+",
              "Kf3",
              "Qd3+",
              "Kf4",
              "Qd4+",
              "Kf3",
              "Rh3+",
              "gxh3",
              "Rxh3+",
              "Kg2",
              "Qh4",
              "Bc5",
              "Rh2+",
              "Kf3",
              "Be2+",
              "Ke3",
              "Qf2+",
              "Ke4",
              "Qxc5",
              "Kxf5",
              "Bd3+",
              "Kg5",
              "Qe3+",
              "Kg4",
              "Rg2+",
              "Kh4",
              "Qh6#",
              "O-O-O",
              "Rxg8",
              "Rxg8",
              "Qh7",
              "Rg1+",
              "Bb1",
              "Kg3",
              "Qg6+",
              "Kf2",
              "Qxe6",
              "Ke3",
              "Qd7",
              "c5",
              "e6",
              "b5",
              "e7",
              "b4",
              "e8=Q+",
              "Kf2",
              "Qdf7+",
              "Kg2",
              "Qeg8+",
              "Kh1",
              "Qfh7#",
              "c4",
              "Qxg1+",
              "Kxg1",
              "Qxa7+",
              "Kf1",
              "cxb4",
              "Ke2",
              "Qd4",
              "c3",
              "bxc3",
              "Kf3",
              "c4",
              "Ke2",
              "c5",
              "Kf3",
              "c6",
              "Ke2",
              "c7",
              "Kf3",
              "c8=Q",
              "Ke2",
              "Qe8+",
              "Kf3",
              "Qf6+",
              "Kg4",
              "Qg8+",
              "Kh5",
              "Qfh8#",
              "c5",
              "Qg6+",
              "Kh4",
              "Qhh5#",
              "cxb4",
              "Qgg4#",
              "c3",
              "Qhh3#",
              "cxb2+",
              "Kxb2#",
              "c4",
              "Qgg3#",
              "c3+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 536,
          "total_completion_tokens": 1920,
          "total_tokens": 2456
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 179,
            "completion_tokens": 640,
            "total_tokens": 819,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 18,
            "turn_number": 10,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 178,
            "completion_tokens": 640,
            "total_tokens": 818,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bqk2r/pppn2bp/3pp1p1/5p2/3PP2P/2PB1N2/PP1N1PP1/R2QK2R w KQkq - 3 10"
    },
    {
      "turn": 21,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "O-O-O",
          "aggressive_uci": "e1c1",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O O-O 12. h5 g5 13. h6 Bf6 14. exf5 exf5 15.\nQxe7 Bxe7 16. Rde1 Bf6 17. Bxf5 Nb6 18. Bxc8 Raxc8 19. Ne4 g4 20. Nxf6+ Rxf6 21.\nNg5 Rxf2 22. Re7 Nd5 23. Rg7+ Kh8 24. Rxh7+ Kg8 25. Rg7+ Kh8 26. Nf7+ Rxf7 27.\nRxf7 Re8 28. Rhf1 Re2 29. Rg7 Re8 30. Rff7 Ne3 31. Rh7+ Kg8 32. Rfg7+ Kf8 33. Rh8#\n33. ... Ng8 34. Rf7#",
          "aggressive_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 285,
            "total_tokens": 473,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "h6",
            "Bf6",
            "exf5",
            "exf5",
            "Qxe7",
            "Bxe7",
            "Rde1",
            "Bf6",
            "Bxf5",
            "Nb6",
            "Bxc8",
            "Raxc8",
            "Ne4",
            "g4",
            "Nxf6+",
            "Rxf6",
            "Ng5",
            "Rxf2",
            "Re7",
            "Nd5",
            "Rg7+",
            "Kh8",
            "Rxh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Nf7+",
            "Rxf7",
            "Rxf7",
            "Re8",
            "Rhf1",
            "Re2",
            "Rg7",
            "Re8",
            "Rff7",
            "Ne3",
            "Rh7+",
            "Kg8",
            "Rfg7+",
            "Kf8",
            "Rh8#",
            "Ng8",
            "Rf7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "O-O-O",
          "positional_uci": "e1c1",
          "positional_response": "11. O-O-O O-O 12. h5 g5 13. h6 Bf6 14. exf5 exf5 15. Qxe7 Bxe7 16. Rde1 Bf6 17. Bxf5 Nb6 18. Bxc8 Raxc8 19. Ne4 g4 20. Nxf6+ Rxf6 21. Ng5 Rxf2 22. Re7 Nd5 23. Rg7+ Kh8 24. Rxh7+ Kg8 25. Rg7+ Kh8 26. Nf7+ Rxf7 27. Rxf7 Re8 28. Rhf1 Re2 29. Rg7 Re8 30. Rff7 Ne3 31. Rh7+ Kg8 32. Rfg7+ Kf8 33. Rh8# Rg8 34. Rhxg8# Rg8 35. Rxg8# Rg8",
          "positional_tokens": {
            "prompt_tokens": 188,
            "completion_tokens": 217,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "h6",
            "Bf6",
            "exf5",
            "exf5",
            "Qxe7",
            "Bxe7",
            "Rde1",
            "Bf6",
            "Bxf5",
            "Nb6",
            "Bxc8",
            "Raxc8",
            "Ne4",
            "g4",
            "Nxf6+",
            "Rxf6",
            "Ng5",
            "Rxf2",
            "Re7",
            "Nd5",
            "Rg7+",
            "Kh8",
            "Rxh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Nf7+",
            "Rxf7",
            "Rxf7",
            "Re8",
            "Rhf1",
            "Re2",
            "Rg7",
            "Re8",
            "Rff7",
            "Ne3",
            "Rh7+",
            "Kg8",
            "Rfg7+",
            "Kf8",
            "Rh8#",
            "Rg8",
            "Rhxg8#",
            "Rg8",
            "Rxg8#",
            "Rg8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "O-O-O",
          "neutral_uci": "e1c1",
          "neutral_response": "11. O-O-O O-O 12. h5 g5 13. h6 Bf6 14. exf5 exf5 15. Qxe7 Bxe7 16. Rde1 Bf6 17. Bxf5 Nb6 18. Bxc8 Raxc8 19. Ne4 g4 20. Nxf6+ Rxf6 21. Ng5 Rxf2 22. Re7 Nd5 23. Rg7+ Kh8 24. Rxh7+ Kg8 25. Rg7+ Kh8 26. Nf7+ Rxf7 27. Rxf7 Re8 28. Rhf1 Re2 29. Rg7 Re8 30. Rff7 Ne3 31. Rh7+ Kg8 32. Rfg7+ Kf8 33. Rh8# d4 e5 dxe5",
          "neutral_tokens": {
            "prompt_tokens": 187,
            "completion_tokens": 200,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "g5",
            "h6",
            "Bf6",
            "exf5",
            "exf5",
            "Qxe7",
            "Bxe7",
            "Rde1",
            "Bf6",
            "Bxf5",
            "Nb6",
            "Bxc8",
            "Raxc8",
            "Ne4",
            "g4",
            "Nxf6+",
            "Rxf6",
            "Ng5",
            "Rxf2",
            "Re7",
            "Nd5",
            "Rg7+",
            "Kh8",
            "Rxh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Nf7+",
            "Rxf7",
            "Rxf7",
            "Re8",
            "Rhf1",
            "Re2",
            "Rg7",
            "Re8",
            "Rff7",
            "Ne3",
            "Rh7+",
            "Kg8",
            "Rfg7+",
            "Kf8",
            "Rh8#",
            "d4",
            "e5",
            "dxe5"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1c1",
          "positional_uci": "e1c1",
          "neutral_uci": "e1c1",
          "consensus_move": "e1c1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "h6",
              "Bf6",
              "exf5",
              "exf5",
              "Qxe7",
              "Bxe7",
              "Rde1",
              "Bf6",
              "Bxf5",
              "Nb6",
              "Bxc8",
              "Raxc8",
              "Ne4",
              "g4",
              "Nxf6+",
              "Rxf6",
              "Ng5",
              "Rxf2",
              "Re7",
              "Nd5",
              "Rg7+",
              "Kh8",
              "Rxh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Nf7+",
              "Rxf7",
              "Rxf7",
              "Re8",
              "Rhf1",
              "Re2",
              "Rg7",
              "Re8",
              "Rff7",
              "Ne3",
              "Rh7+",
              "Kg8",
              "Rfg7+",
              "Kf8",
              "Rh8#",
              "Ng8",
              "Rf7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "h6",
              "Bf6",
              "exf5",
              "exf5",
              "Qxe7",
              "Bxe7",
              "Rde1",
              "Bf6",
              "Bxf5",
              "Nb6",
              "Bxc8",
              "Raxc8",
              "Ne4",
              "g4",
              "Nxf6+",
              "Rxf6",
              "Ng5",
              "Rxf2",
              "Re7",
              "Nd5",
              "Rg7+",
              "Kh8",
              "Rxh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Nf7+",
              "Rxf7",
              "Rxf7",
              "Re8",
              "Rhf1",
              "Re2",
              "Rg7",
              "Re8",
              "Rff7",
              "Ne3",
              "Rh7+",
              "Kg8",
              "Rfg7+",
              "Kf8",
              "Rh8#",
              "Rg8",
              "Rhxg8#",
              "Rg8",
              "Rxg8#",
              "Rg8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "h5",
              "g5",
              "h6",
              "Bf6",
              "exf5",
              "exf5",
              "Qxe7",
              "Bxe7",
              "Rde1",
              "Bf6",
              "Bxf5",
              "Nb6",
              "Bxc8",
              "Raxc8",
              "Ne4",
              "g4",
              "Nxf6+",
              "Rxf6",
              "Ng5",
              "Rxf2",
              "Re7",
              "Nd5",
              "Rg7+",
              "Kh8",
              "Rxh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Nf7+",
              "Rxf7",
              "Rxf7",
              "Re8",
              "Rhf1",
              "Re2",
              "Rg7",
              "Re8",
              "Rff7",
              "Ne3",
              "Rh7+",
              "Kg8",
              "Rfg7+",
              "Kf8",
              "Rh8#",
              "d4",
              "e5",
              "dxe5"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 188,
            "completion_tokens": 285,
            "total_tokens": 473,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 188,
            "completion_tokens": 217,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 187,
            "completion_tokens": 200,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 563,
          "total_completion_tokens": 702,
          "total_tokens": 1265
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 188,
            "completion_tokens": 285,
            "total_tokens": 473,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 188,
            "completion_tokens": 217,
            "total_tokens": 405,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 20,
            "turn_number": 11,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 187,
            "completion_tokens": 200,
            "total_tokens": 387,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/pppnq1bp/3pp1p1/5p2/3PP2P/2PB1N2/PP1NQPP1/R3K2R w KQkq - 5 11"
    },
    {
      "turn": 23,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxe4",
          "aggressive_uci": "d2e4",
          "aggressive_response": "12. Nxe4 Nf6 13. Neg5 Bd7 14. Rde1 O-O-O 15. Nxe6 Rde8 16. Nxg7 Qxg7 17. Qd2 Bc6 18. Rxe8+ Rxe8 19. Re1 Rxe1+ 20. Nxe1 Qe7 21. Qe2 Kd7 22. Qxe7+ Kxe7 23. Kd2 Ke6 24. Ke3 Ng4+ 25. Kf4 Nxf2 26. Bc2 Kf6 27. g4 h6 28. g5+ hxg5+ 29. hxg5+ Kg7 30. c4 Nh3+ 31. Kg4 Bd7+ 32. Kh4 Nf4 33. Be4 c6 34. Nd3 Ne2 35. d5 c5 36. Bf3 Nd4 37. Bg4 Bf5 38. Nf4 Kf7 39. Kg3 Bb1 40. a3 Nf5+ 41. Kf2 Nd4 42. Ke3 Bf5 43. Bd1 Ke7 44. b4 b6 45. bxc5 bxc5 46. Kd2 Kd7 47. Kc3 Kc7 48. Ba4 Kb6 49. Be8 Nf3 50. Bxg6 Bxg6 51. Nxg6 Nxg5 52. Ne7 Nf7 53. Nc8+ Kb7 54. Ne7 Kb6 55. Nc8+ Kb7 56. Ne7 Kb6 57. Nc8+ Kb7 58. Ne7 Kb6 59. Nc8+ Kb7 60. Ne7 Kb6 61. Nc8+ Kb7 62. Ne7 Kb6 63. Nc8+ Kb7 64. Ne7 Kb6 65. Nc8+ Kb7 66. Ne7 Kb6 67. Nc8+ Kb7 68. Ne7 Kb6 69. Nc8+ Kb7 70. Ne7 Kb6 71. Nc8+ Kb7 72. Ne7 Kb6 73. Nc8+ Kb7 74. Ne7 Kb6 75. Nc8+ Kb7 76. Ne7 Kb6 77. Nc8+ Kb7 78. Ne7 Kb6 79. Nc8+ Kb7 80. Ne7 Kb6 81. Nc8+ Kb7 82. Ne7 Kb6 83. Nc8+ Kb7 84. Ne7 Kb6 85. Nc8+ Kb7 86. Ne7 Kb6 87. Nc8+ Kb7 88. Ne7 Kb6 89. N",
          "aggressive_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 640,
            "total_tokens": 837,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Neg5",
            "Bd7",
            "Rde1",
            "O-O-O",
            "Nxe6",
            "Rde8",
            "Nxg7",
            "Qxg7",
            "Qd2",
            "Bc6",
            "Rxe8+",
            "Rxe8",
            "Re1",
            "Rxe1+",
            "Nxe1",
            "Qe7",
            "Qe2",
            "Kd7",
            "Qxe7+",
            "Kxe7",
            "Kd2",
            "Ke6",
            "Ke3",
            "Ng4+",
            "Kf4",
            "Nxf2",
            "Bc2",
            "Kf6",
            "g4",
            "h6",
            "g5+",
            "hxg5+",
            "hxg5+",
            "Kg7",
            "c4",
            "Nh3+",
            "Kg4",
            "Bd7+",
            "Kh4",
            "Nf4",
            "Be4",
            "c6",
            "Nd3",
            "Ne2",
            "d5",
            "c5",
            "Bf3",
            "Nd4",
            "Bg4",
            "Bf5",
            "Nf4",
            "Kf7",
            "Kg3",
            "Bb1",
            "a3",
            "Nf5+",
            "Kf2",
            "Nd4",
            "Ke3",
            "Bf5",
            "Bd1",
            "Ke7",
            "b4",
            "b6",
            "bxc5",
            "bxc5",
            "Kd2",
            "Kd7",
            "Kc3",
            "Kc7",
            "Ba4",
            "Kb6",
            "Be8",
            "Nf3",
            "Bxg6",
            "Bxg6",
            "Nxg6",
            "Nxg5",
            "Ne7",
            "Nf7",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6",
            "Nc8+",
            "Kb7",
            "Ne7",
            "Kb6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxe4",
          "positional_uci": "d2e4",
          "positional_response": "12. Nxe4 Nf6 13. Neg5 Bd7 14. Rde1 O-O-O 15. Nxe6 Rde8 16. Nxg7 Qxg7 17. Qd2 Bc6 18. Rxe8+ Rxe8 19. Re1 Rxe1+ 20. Nxe1 Qe7 21. Qe3 Qxe3+ 22. fxe3 Ng4 23. Kd2 Kd7 24. e4 Ke7 25. Nf3 Nf6 26. Ke3 Ng4+ 27. Kf4 Nf6 28. g4 h6 29. g5 hxg5+ 30. Nxg5 Nh5+ 31. Ke3 Bd7 32. e5 dxe5 33. dxe5 Be8 34. Be4 b6 35. Bd5 Ng7 36. Be4 Nh5 37. Kf3 Ng7 38. Kg4 Nh5 39. Bd3 Ng7 40. Bc4 Nh5 41. Ne6 Bd7 42. Kg5 Bxe6 43. Bxe6 Kxe6 44. Kxg6 Nf4+ 45. Kg5 Kxe5 46. h5 Nxh5 47. Kxh5 Ke4 48. Kg5 Kd3 49. Kf5 Kc2 50. Ke5 Kxb2 51. Kd5 Kxc3 52. Kc6 Kb2 53. Kxc7 Kxa2 54. Kb7 b5 55. Kxa7 b4 56. Kb6 b3 57. Kc5 b2 58. Kd4 b1=Q 59. Ke3 Qb4 60. Kd3 Kb3 61. Ke3 Qc4 62. Kf3 Qd4 63. Kg3 Qe4 64. Kf2 Qd3 65. Kg2 Qe3 66. Kh2 Qf3 67. Kg1 Qe2 68. Kh1 Kc3 69. Kg1 Kd3 70. Kh1 Ke3 71. Kg1 Kf3 72. Kh1 Qg2# e4 d5 Nc6",
          "positional_tokens": {
            "prompt_tokens": 197,
            "completion_tokens": 512,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Neg5",
            "Bd7",
            "Rde1",
            "O-O-O",
            "Nxe6",
            "Rde8",
            "Nxg7",
            "Qxg7",
            "Qd2",
            "Bc6",
            "Rxe8+",
            "Rxe8",
            "Re1",
            "Rxe1+",
            "Nxe1",
            "Qe7",
            "Qe3",
            "Qxe3+",
            "fxe3",
            "Ng4",
            "Kd2",
            "Kd7",
            "e4",
            "Ke7",
            "Nf3",
            "Nf6",
            "Ke3",
            "Ng4+",
            "Kf4",
            "Nf6",
            "g4",
            "h6",
            "g5",
            "hxg5+",
            "Nxg5",
            "Nh5+",
            "Ke3",
            "Bd7",
            "e5",
            "dxe5",
            "dxe5",
            "Be8",
            "Be4",
            "b6",
            "Bd5",
            "Ng7",
            "Be4",
            "Nh5",
            "Kf3",
            "Ng7",
            "Kg4",
            "Nh5",
            "Bd3",
            "Ng7",
            "Bc4",
            "Nh5",
            "Ne6",
            "Bd7",
            "Kg5",
            "Bxe6",
            "Bxe6",
            "Kxe6",
            "Kxg6",
            "Nf4+",
            "Kg5",
            "Kxe5",
            "h5",
            "Nxh5",
            "Kxh5",
            "Ke4",
            "Kg5",
            "Kd3",
            "Kf5",
            "Kc2",
            "Ke5",
            "Kxb2",
            "Kd5",
            "Kxc3",
            "Kc6",
            "Kb2",
            "Kxc7",
            "Kxa2",
            "Kb7",
            "b5",
            "Kxa7",
            "b4",
            "Kb6",
            "b3",
            "Kc5",
            "b2",
            "Kd4",
            "b1=Q",
            "Ke3",
            "Qb4",
            "Kd3",
            "Kb3",
            "Ke3",
            "Qc4",
            "Kf3",
            "Qd4",
            "Kg3",
            "Qe4",
            "Kf2",
            "Qd3",
            "Kg2",
            "Qe3",
            "Kh2",
            "Qf3",
            "Kg1",
            "Qe2",
            "Kh1",
            "Kc3",
            "Kg1",
            "Kd3",
            "Kh1",
            "Ke3",
            "Kg1",
            "Kf3",
            "Kh1",
            "Qg2#",
            "e4",
            "d5",
            "Nc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxe4",
          "neutral_uci": "d2e4",
          "neutral_response": "12. Nxe4 Nf6 13. Neg5 Bd7 14. Rde1 O-O-O 15. Nxe6 Rde8 16. Nxg7 Qxg7 17. Qd2\nh6 18. Rxe8+ Rxe8 19. Re1 Rxe1+ 20. Qxe1 g5 21. hxg5 hxg5 22. Qe3 g4 23. Nh4\nNd5 24. Qe4 Qg5+ 25. Kc2 Nf6 26. Qg6 Qxh4 27. g3 Qh8 28. Bf5 Bxf5+ 29. Qxf5+\nKb8 30. a4 Qg7 31. b4 a6 32. b5 axb5 33. axb5 Qe7 34. Kd3 d5 35. f3 gxf3 36.\nQxf3 Qe4+ 37. Qxe4 Nxe4 38. g4 Kc8 39. c4 c6 40. bxc6 bxc6 41. cxd5 cxd5 42.\nKe3 Kd7 43. Kf4 Ke6 44. g5 Nd6 45. Kg4 Nf5 46. Kh5 Nxd4 47. Kh6 Nf5+ 48. Kh7\nd4 49. g6 d3 50. g7 Nxg7 51. Kxg7 d2 52. Kg6 d1=Q 53. Kg5 Qf3 54. Kg6 Qg4+ 55.\nKh6 Kf7 56. Kh7 Qh5# d3 d2 d1=Q",
          "neutral_tokens": {
            "prompt_tokens": 196,
            "completion_tokens": 393,
            "total_tokens": 589,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "g4",
            "Kc8",
            "c4",
            "c6",
            "bxc6",
            "bxc6",
            "cxd5",
            "cxd5",
            "Ke3",
            "Kd7",
            "Kf4",
            "Ke6",
            "g5",
            "Nd6",
            "Kg4",
            "Nf5",
            "Kh5",
            "Nxd4",
            "Kh6",
            "Nf5+",
            "Kh7",
            "d4",
            "g6",
            "d3",
            "g7",
            "Nxg7",
            "Kxg7",
            "d2",
            "Kg6",
            "d1=Q",
            "Kg5",
            "Qf3",
            "Kg6",
            "Qg4+",
            "Kh6",
            "Kf7",
            "Kh7",
            "Qh5#",
            "d3",
            "d2",
            "d1=Q"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2e4",
          "positional_uci": "d2e4",
          "neutral_uci": "d2e4",
          "consensus_move": "d2e4",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Neg5",
              "Bd7",
              "Rde1",
              "O-O-O",
              "Nxe6",
              "Rde8",
              "Nxg7",
              "Qxg7",
              "Qd2",
              "Bc6",
              "Rxe8+",
              "Rxe8",
              "Re1",
              "Rxe1+",
              "Nxe1",
              "Qe7",
              "Qe2",
              "Kd7",
              "Qxe7+",
              "Kxe7",
              "Kd2",
              "Ke6",
              "Ke3",
              "Ng4+",
              "Kf4",
              "Nxf2",
              "Bc2",
              "Kf6",
              "g4",
              "h6",
              "g5+",
              "hxg5+",
              "hxg5+",
              "Kg7",
              "c4",
              "Nh3+",
              "Kg4",
              "Bd7+",
              "Kh4",
              "Nf4",
              "Be4",
              "c6",
              "Nd3",
              "Ne2",
              "d5",
              "c5",
              "Bf3",
              "Nd4",
              "Bg4",
              "Bf5",
              "Nf4",
              "Kf7",
              "Kg3",
              "Bb1",
              "a3",
              "Nf5+",
              "Kf2",
              "Nd4",
              "Ke3",
              "Bf5",
              "Bd1",
              "Ke7",
              "b4",
              "b6",
              "bxc5",
              "bxc5",
              "Kd2",
              "Kd7",
              "Kc3",
              "Kc7",
              "Ba4",
              "Kb6",
              "Be8",
              "Nf3",
              "Bxg6",
              "Bxg6",
              "Nxg6",
              "Nxg5",
              "Ne7",
              "Nf7",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6",
              "Nc8+",
              "Kb7",
              "Ne7",
              "Kb6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Neg5",
              "Bd7",
              "Rde1",
              "O-O-O",
              "Nxe6",
              "Rde8",
              "Nxg7",
              "Qxg7",
              "Qd2",
              "Bc6",
              "Rxe8+",
              "Rxe8",
              "Re1",
              "Rxe1+",
              "Nxe1",
              "Qe7",
              "Qe3",
              "Qxe3+",
              "fxe3",
              "Ng4",
              "Kd2",
              "Kd7",
              "e4",
              "Ke7",
              "Nf3",
              "Nf6",
              "Ke3",
              "Ng4+",
              "Kf4",
              "Nf6",
              "g4",
              "h6",
              "g5",
              "hxg5+",
              "Nxg5",
              "Nh5+",
              "Ke3",
              "Bd7",
              "e5",
              "dxe5",
              "dxe5",
              "Be8",
              "Be4",
              "b6",
              "Bd5",
              "Ng7",
              "Be4",
              "Nh5",
              "Kf3",
              "Ng7",
              "Kg4",
              "Nh5",
              "Bd3",
              "Ng7",
              "Bc4",
              "Nh5",
              "Ne6",
              "Bd7",
              "Kg5",
              "Bxe6",
              "Bxe6",
              "Kxe6",
              "Kxg6",
              "Nf4+",
              "Kg5",
              "Kxe5",
              "h5",
              "Nxh5",
              "Kxh5",
              "Ke4",
              "Kg5",
              "Kd3",
              "Kf5",
              "Kc2",
              "Ke5",
              "Kxb2",
              "Kd5",
              "Kxc3",
              "Kc6",
              "Kb2",
              "Kxc7",
              "Kxa2",
              "Kb7",
              "b5",
              "Kxa7",
              "b4",
              "Kb6",
              "b3",
              "Kc5",
              "b2",
              "Kd4",
              "b1=Q",
              "Ke3",
              "Qb4",
              "Kd3",
              "Kb3",
              "Ke3",
              "Qc4",
              "Kf3",
              "Qd4",
              "Kg3",
              "Qe4",
              "Kf2",
              "Qd3",
              "Kg2",
              "Qe3",
              "Kh2",
              "Qf3",
              "Kg1",
              "Qe2",
              "Kh1",
              "Kc3",
              "Kg1",
              "Kd3",
              "Kh1",
              "Ke3",
              "Kg1",
              "Kf3",
              "Kh1",
              "Qg2#",
              "e4",
              "d5",
              "Nc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "g4",
              "Kc8",
              "c4",
              "c6",
              "bxc6",
              "bxc6",
              "cxd5",
              "cxd5",
              "Ke3",
              "Kd7",
              "Kf4",
              "Ke6",
              "g5",
              "Nd6",
              "Kg4",
              "Nf5",
              "Kh5",
              "Nxd4",
              "Kh6",
              "Nf5+",
              "Kh7",
              "d4",
              "g6",
              "d3",
              "g7",
              "Nxg7",
              "Kxg7",
              "d2",
              "Kg6",
              "d1=Q",
              "Kg5",
              "Qf3",
              "Kg6",
              "Qg4+",
              "Kh6",
              "Kf7",
              "Kh7",
              "Qh5#",
              "d3",
              "d2",
              "d1=Q"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 197,
            "completion_tokens": 640,
            "total_tokens": 837,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 197,
            "completion_tokens": 512,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 196,
            "completion_tokens": 393,
            "total_tokens": 589,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 590,
          "total_completion_tokens": 1545,
          "total_tokens": 2135
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 197,
            "completion_tokens": 640,
            "total_tokens": 837,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 197,
            "completion_tokens": 512,
            "total_tokens": 709,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 22,
            "turn_number": 12,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 196,
            "completion_tokens": 393,
            "total_tokens": 589,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/pppnq1bp/3pp1p1/8/3Pp2P/2PB1N2/PP1NQPP1/2KR3R w kq - 0 12"
    },
    {
      "turn": 25,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxf6+",
          "aggressive_uci": "e4f6",
          "aggressive_response": "13. Nxf6+ Bxf6 14. h5\ng5 15. h6 O-O 16. Rh5 Kh8 17. Qe3 Rg8 18. Re1 Bd7 19. Nh2 Rae8 20. Ng4 e5 21.\nNxf6 Qxf6 22. dxe5 Rxe5 23. Qd2 Rxe1+ 24. Qxe1 Re8 25. Qd2 Re5 26. g3 Bg4 27.\nRh1 Bf3 28. Re1 Qxh6 29. Rxe5 dxe5 30. Qe3 Qf6 31. Qxa7 Qd8 32. Qe3 Qf6 33. Be4\nBxe4 34. Qxe4 c6 35. f3 Kg7 36. Kd2 Qd6+ 37. Ke2 Qe6 38. b3 h5 39. Kf2 Qd6 40.\nQe3 Kf6 41. Kg2 Qd1 42. Qf2 Qd3 43. c4 Kf5 44. Kh2 Qd4 45. Qc2+ e4 46. fxe4+\nQxe4 47. Qf2+ Kg4 48. Qd2 h4 49. Qd1+ Qf3 50. Qd4+ Kh5 51. gxh4 Qf4+ 52. Qxf4\ngxf4 53. Kh3 f3 54. Kg3 f2 55. Kxf2 Kxh4 56. Ke3 Kg5 57. Kd4 Kf6 58. Kc5 Ke7 59.\nKb6 Kd6 60. Kxb7 Kc5 61. a4 Kb4 62. Kxc6 Kxb3 63. Kb5 Kc3 64. c5 Kd4 65. c6\nKd5 66. c7 Kd6 67. c8=Q Ke7 68. Qc6 Kd8 69. Qb7 Ke8 70. Kc6 Kf8 71. Kd6 Kg8\n72. Ke6 Kh8 73. Kf6 Kg8 74. Qg7# Kd8 75. Qb7 Ke8 76. Qe7# Kd8 77. Ke6 Kc8 78.\nKd6 Kb8 79. Kc6 Ka8 80. Qb7# Kd8 81. Qd7# Kxd8 82. Kb7 Kd7 83. a5 Kd6 84.\na6 Kc5 85. a7 Kb5 86. a8=Q Kc5 87. Qd8 Kb5 88. Q",
          "aggressive_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxf6",
            "dxe5",
            "Rxe5",
            "Qd2",
            "Rxe1+",
            "Qxe1",
            "Re8",
            "Qd2",
            "Re5",
            "g3",
            "Bg4",
            "Rh1",
            "Bf3",
            "Re1",
            "Qxh6",
            "Rxe5",
            "dxe5",
            "Qe3",
            "Qf6",
            "Qxa7",
            "Qd8",
            "Qe3",
            "Qf6",
            "Be4",
            "Bxe4",
            "Qxe4",
            "c6",
            "f3",
            "Kg7",
            "Kd2",
            "Qd6+",
            "Ke2",
            "Qe6",
            "b3",
            "h5",
            "Kf2",
            "Qd6",
            "Qe3",
            "Kf6",
            "Kg2",
            "Qd1",
            "Qf2",
            "Qd3",
            "c4",
            "Kf5",
            "Kh2",
            "Qd4",
            "Qc2+",
            "e4",
            "fxe4+",
            "Qxe4",
            "Qf2+",
            "Kg4",
            "Qd2",
            "h4",
            "Qd1+",
            "Qf3",
            "Qd4+",
            "Kh5",
            "gxh4",
            "Qf4+",
            "Qxf4",
            "gxf4",
            "Kh3",
            "f3",
            "Kg3",
            "f2",
            "Kxf2",
            "Kxh4",
            "Ke3",
            "Kg5",
            "Kd4",
            "Kf6",
            "Kc5",
            "Ke7",
            "Kb6",
            "Kd6",
            "Kxb7",
            "Kc5",
            "a4",
            "Kb4",
            "Kxc6",
            "Kxb3",
            "Kb5",
            "Kc3",
            "c5",
            "Kd4",
            "c6",
            "Kd5",
            "c7",
            "Kd6",
            "c8=Q",
            "Ke7",
            "Qc6",
            "Kd8",
            "Qb7",
            "Ke8",
            "Kc6",
            "Kf8",
            "Kd6",
            "Kg8",
            "Ke6",
            "Kh8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "Kd8",
            "Qb7",
            "Ke8",
            "Qe7#",
            "Kd8",
            "Ke6",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kxd8",
            "Kb7",
            "Kd7",
            "a5",
            "Kd6",
            "a6",
            "Kc5",
            "a7",
            "Kb5",
            "a8=Q",
            "Kc5",
            "Qd8",
            "Kb5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Neg5",
          "positional_uci": "e4g5",
          "positional_response": "13. Neg5 O-O 14. Rde1 Re8 15. h5 Nxh5 16. Rxh5 gxh5 17. Bxh7+ Kh8 18. Bg6 Rf8 19. Rh1 Bh6 20. Rxh5 Kg7 21. Rxh6 Kxh6 22. Qe4 Kg7 23. Bh5 Rf5 24. Qg4 Kh6 25. Nf7+ Rxf7 26. Qg6# d4 e5 Qf6",
          "positional_tokens": {
            "prompt_tokens": 206,
            "completion_tokens": 124,
            "total_tokens": 330,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "Rde1",
            "Re8",
            "h5",
            "Nxh5",
            "Rxh5",
            "gxh5",
            "Bxh7+",
            "Kh8",
            "Bg6",
            "Rf8",
            "Rh1",
            "Bh6",
            "Rxh5",
            "Kg7",
            "Rxh6",
            "Kxh6",
            "Qe4",
            "Kg7",
            "Bh5",
            "Rf5",
            "Qg4",
            "Kh6",
            "Nf7+",
            "Rxf7",
            "Qg6#",
            "d4",
            "e5",
            "Qf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Neg5",
          "neutral_uci": "e4g5",
          "neutral_response": "13. Neg5 O-O 14. h5 Nxh5 15. Nxh7 Kxh7 16. Rxh5+ Kg8 17. Bxg6 Rf6 18. Bh7+ Kf8 19. Rdh1 Bd7 20. Be4 d5 21. Bd3 Be8 22. Rh8+ Bxh8 23. Rxh8+ Kg7 24. Rh7+ Kf8 25. Rxe7 Kxe7 26. Ne5 Kd6 27. g4 c5 28. g5 Rf8 29. g6 cxd4 30. cxd4 Rc8+ 31. Kd2 Rg8 32. Qg4 Rc7 33. Qg5 Rcg7 34. Qd8+ Bd7 35. Nf7+ Kc6 36. Ne5+ Kd6 37. Qa5 b6 38. Qxa7 Bc6 39. Qxb6 Rc7 40. Bb5 Rgc8 41. Bxc6 Rxc6 42. Nxc6 Rxc6 43. Qxc6+ Kxc6 44. g7 Kd6 45. g8=Q e5 46. Qg6+ Kd7 47. dxe5 Ke7 48. Qd6+ Kf7 49. Qf6+ Ke8 50. e6 d4 51. Qf7+ Kd8 52. Qd7# O-O-O Nf3 Kc7 Qc5+ Kb8 Qc7#",
          "neutral_tokens": {
            "prompt_tokens": 205,
            "completion_tokens": 365,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "O-O",
            "h5",
            "Nxh5",
            "Nxh7",
            "Kxh7",
            "Rxh5+",
            "Kg8",
            "Bxg6",
            "Rf6",
            "Bh7+",
            "Kf8",
            "Rdh1",
            "Bd7",
            "Be4",
            "d5",
            "Bd3",
            "Be8",
            "Rh8+",
            "Bxh8",
            "Rxh8+",
            "Kg7",
            "Rh7+",
            "Kf8",
            "Rxe7",
            "Kxe7",
            "Ne5",
            "Kd6",
            "g4",
            "c5",
            "g5",
            "Rf8",
            "g6",
            "cxd4",
            "cxd4",
            "Rc8+",
            "Kd2",
            "Rg8",
            "Qg4",
            "Rc7",
            "Qg5",
            "Rcg7",
            "Qd8+",
            "Bd7",
            "Nf7+",
            "Kc6",
            "Ne5+",
            "Kd6",
            "Qa5",
            "b6",
            "Qxa7",
            "Bc6",
            "Qxb6",
            "Rc7",
            "Bb5",
            "Rgc8",
            "Bxc6",
            "Rxc6",
            "Nxc6",
            "Rxc6",
            "Qxc6+",
            "Kxc6",
            "g7",
            "Kd6",
            "g8=Q",
            "e5",
            "Qg6+",
            "Kd7",
            "dxe5",
            "Ke7",
            "Qd6+",
            "Kf7",
            "Qf6+",
            "Ke8",
            "e6",
            "d4",
            "Qf7+",
            "Kd8",
            "Qd7#",
            "O-O-O",
            "Nf3",
            "Kc7",
            "Qc5+",
            "Kb8",
            "Qc7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e4f6",
          "positional_uci": "e4g5",
          "neutral_uci": "e4g5",
          "consensus_move": "e4g5",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxf6",
              "dxe5",
              "Rxe5",
              "Qd2",
              "Rxe1+",
              "Qxe1",
              "Re8",
              "Qd2",
              "Re5",
              "g3",
              "Bg4",
              "Rh1",
              "Bf3",
              "Re1",
              "Qxh6",
              "Rxe5",
              "dxe5",
              "Qe3",
              "Qf6",
              "Qxa7",
              "Qd8",
              "Qe3",
              "Qf6",
              "Be4",
              "Bxe4",
              "Qxe4",
              "c6",
              "f3",
              "Kg7",
              "Kd2",
              "Qd6+",
              "Ke2",
              "Qe6",
              "b3",
              "h5",
              "Kf2",
              "Qd6",
              "Qe3",
              "Kf6",
              "Kg2",
              "Qd1",
              "Qf2",
              "Qd3",
              "c4",
              "Kf5",
              "Kh2",
              "Qd4",
              "Qc2+",
              "e4",
              "fxe4+",
              "Qxe4",
              "Qf2+",
              "Kg4",
              "Qd2",
              "h4",
              "Qd1+",
              "Qf3",
              "Qd4+",
              "Kh5",
              "gxh4",
              "Qf4+",
              "Qxf4",
              "gxf4",
              "Kh3",
              "f3",
              "Kg3",
              "f2",
              "Kxf2",
              "Kxh4",
              "Ke3",
              "Kg5",
              "Kd4",
              "Kf6",
              "Kc5",
              "Ke7",
              "Kb6",
              "Kd6",
              "Kxb7",
              "Kc5",
              "a4",
              "Kb4",
              "Kxc6",
              "Kxb3",
              "Kb5",
              "Kc3",
              "c5",
              "Kd4",
              "c6",
              "Kd5",
              "c7",
              "Kd6",
              "c8=Q",
              "Ke7",
              "Qc6",
              "Kd8",
              "Qb7",
              "Ke8",
              "Kc6",
              "Kf8",
              "Kd6",
              "Kg8",
              "Ke6",
              "Kh8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "Kd8",
              "Qb7",
              "Ke8",
              "Qe7#",
              "Kd8",
              "Ke6",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kxd8",
              "Kb7",
              "Kd7",
              "a5",
              "Kd6",
              "a6",
              "Kc5",
              "a7",
              "Kb5",
              "a8=Q",
              "Kc5",
              "Qd8",
              "Kb5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "O-O",
              "Rde1",
              "Re8",
              "h5",
              "Nxh5",
              "Rxh5",
              "gxh5",
              "Bxh7+",
              "Kh8",
              "Bg6",
              "Rf8",
              "Rh1",
              "Bh6",
              "Rxh5",
              "Kg7",
              "Rxh6",
              "Kxh6",
              "Qe4",
              "Kg7",
              "Bh5",
              "Rf5",
              "Qg4",
              "Kh6",
              "Nf7+",
              "Rxf7",
              "Qg6#",
              "d4",
              "e5",
              "Qf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "O-O",
              "h5",
              "Nxh5",
              "Nxh7",
              "Kxh7",
              "Rxh5+",
              "Kg8",
              "Bxg6",
              "Rf6",
              "Bh7+",
              "Kf8",
              "Rdh1",
              "Bd7",
              "Be4",
              "d5",
              "Bd3",
              "Be8",
              "Rh8+",
              "Bxh8",
              "Rxh8+",
              "Kg7",
              "Rh7+",
              "Kf8",
              "Rxe7",
              "Kxe7",
              "Ne5",
              "Kd6",
              "g4",
              "c5",
              "g5",
              "Rf8",
              "g6",
              "cxd4",
              "cxd4",
              "Rc8+",
              "Kd2",
              "Rg8",
              "Qg4",
              "Rc7",
              "Qg5",
              "Rcg7",
              "Qd8+",
              "Bd7",
              "Nf7+",
              "Kc6",
              "Ne5+",
              "Kd6",
              "Qa5",
              "b6",
              "Qxa7",
              "Bc6",
              "Qxb6",
              "Rc7",
              "Bb5",
              "Rgc8",
              "Bxc6",
              "Rxc6",
              "Nxc6",
              "Rxc6",
              "Qxc6+",
              "Kxc6",
              "g7",
              "Kd6",
              "g8=Q",
              "e5",
              "Qg6+",
              "Kd7",
              "dxe5",
              "Ke7",
              "Qd6+",
              "Kf7",
              "Qf6+",
              "Ke8",
              "e6",
              "d4",
              "Qf7+",
              "Kd8",
              "Qd7#",
              "O-O-O",
              "Nf3",
              "Kc7",
              "Qc5+",
              "Kb8",
              "Qc7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 206,
            "completion_tokens": 124,
            "total_tokens": 330,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 205,
            "completion_tokens": 365,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 617,
          "total_completion_tokens": 1129,
          "total_tokens": 1746
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 206,
            "completion_tokens": 640,
            "total_tokens": 846,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 206,
            "completion_tokens": 124,
            "total_tokens": 330,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 24,
            "turn_number": 13,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 205,
            "completion_tokens": 365,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1b1k2r/ppp1q1bp/3ppnp1/8/3PN2P/2PB1N2/PP2QPP1/2KR3R w kq - 1 13"
    },
    {
      "turn": 27,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rhe1",
          "aggressive_uci": "h1e1",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1 Re8 15. Bc4 d5 16. Bd3 c6 17. Ne5 Kc7 18. f4 Bd7 19. g4 Rad8 20. h5 gxh5 21. gxh5 Bh6 22. Rg1 Rf8 23. Rdf1 Be8 24. Ng4 Nxg4 25. Qxg4 Bd7 26. Qg3 Qd6 27. Nh3 Rg8 28. Qh4 Rxg1 29. Rxg1 Rf8 30. Rf1 c5 31. dxc5 Qxc5 32. Kb1 Qe3 33. Bc2 e5 34. Ng5 Rxf4 35. Rxf4 Qxf4 36. Qxf4 exf4 37. Nf3 Bg4 38. Bd1 Bxh5 39. Kc2 Bg6+ 40. Kd2 Be4 41. Ke2 Kd6 42. Kf2 Bg7 43. Ng5 Bf6 44. Nf3 h5 45. Kg2 h4 46. Kh3 Bf5+ 47. Kg2 h3+ 48. Kh2 Be4 49. Kxh3 Bxf3 50. Bxf3 Ke5 51. Kg4 b5 52. Be2 a6 53. Kf3 d4 54. cxd4+ Kxd4 55. Kxf4 Be5+ 56. Kf3 Bd6 57. Kf2 Bc5 58. Ke1 Ke3 59. Kd1 Bd4 60. b3 Bc3 61. Bf1 Kd4 62. Kc2 Be1 63. a4 bxa4 64. bxa4 a5 65. Kb3 Bb4 66. Bb5 Kc5 67. Bc4 Kd4 68. Bb5 Kc5 69. Bc4 Kd4 70. Bb5 Kc5 71. Bc4 Kd4 72. Bb5 Kc5 73. Bc4 Kd4 74. Bb5 Kc5 75. Bc4 Kd4 76. Bb5 Kc5 77. Bc4 Kd",
          "aggressive_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re8",
            "Bc4",
            "d5",
            "Bd3",
            "c6",
            "Ne5",
            "Kc7",
            "f4",
            "Bd7",
            "g4",
            "Rad8",
            "h5",
            "gxh5",
            "gxh5",
            "Bh6",
            "Rg1",
            "Rf8",
            "Rdf1",
            "Be8",
            "Ng4",
            "Nxg4",
            "Qxg4",
            "Bd7",
            "Qg3",
            "Qd6",
            "Nh3",
            "Rg8",
            "Qh4",
            "Rxg1",
            "Rxg1",
            "Rf8",
            "Rf1",
            "c5",
            "dxc5",
            "Qxc5",
            "Kb1",
            "Qe3",
            "Bc2",
            "e5",
            "Ng5",
            "Rxf4",
            "Rxf4",
            "Qxf4",
            "Qxf4",
            "exf4",
            "Nf3",
            "Bg4",
            "Bd1",
            "Bxh5",
            "Kc2",
            "Bg6+",
            "Kd2",
            "Be4",
            "Ke2",
            "Kd6",
            "Kf2",
            "Bg7",
            "Ng5",
            "Bf6",
            "Nf3",
            "h5",
            "Kg2",
            "h4",
            "Kh3",
            "Bf5+",
            "Kg2",
            "h3+",
            "Kh2",
            "Be4",
            "Kxh3",
            "Bxf3",
            "Bxf3",
            "Ke5",
            "Kg4",
            "b5",
            "Be2",
            "a6",
            "Kf3",
            "d4",
            "cxd4+",
            "Kxd4",
            "Kxf4",
            "Be5+",
            "Kf3",
            "Bd6",
            "Kf2",
            "Bc5",
            "Ke1",
            "Ke3",
            "Kd1",
            "Bd4",
            "b3",
            "Bc3",
            "Bf1",
            "Kd4",
            "Kc2",
            "Be1",
            "a4",
            "bxa4",
            "bxa4",
            "a5",
            "Kb3",
            "Bb4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4",
            "Kd4",
            "Bb5",
            "Kc5",
            "Bc4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rhe1",
          "positional_uci": "h1e1",
          "positional_response": "14. Rhe1 Re8 15. Bc4 d5 16. Bd3 Bd7 17. Ne5 Kc8 18. Nxd7 Kxd7 19. Nxe6 Qxe6 20.\nQxe6+ Rxe6 21. Rxe6 Kxe6 22. Re1+ Kd6 23. f3 Re8 24. Rxe8 Nxe8 25. g4 Nf6 26.\nKd2 c5 27. dxc5+ Kxc5 28. b4+ Kd6 29. Ke3 Nd7 30. c4 dxc4 31. Bxc4 Ne5 32. Bg8\nh6 33. Ke4 Nc6 34. a3 Bb2 35. b5 Ne7 36. Bf7 Bxa3 37. f4 Bc1 38. f5 gxf5+ 39.\ngxf5 Bb2 40. h5 Bf6 41. Be6 Kc5 42. Bd7 a6 43. bxa6 bxa6 44. Kd3 a5 45. Kc2\nKb4 46. Kb1 a4 47. Ka2 a3 48. Be6 Nc6 49. Bd5 Nd4 50. Be4 Nb5 51. Bd3 Nc3+ 52.\nKa1 Kb3 53. Bc4+ Kxc4 54. 1/2-1/2\n\nKb3 a5 Ka4 a4 Kb5 a3 Ka6 a2 Kb7 a1=Q#",
          "positional_tokens": {
            "prompt_tokens": 214,
            "completion_tokens": 365,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Bc4",
            "d5",
            "Bd3",
            "Bd7",
            "Ne5",
            "Kc8",
            "Nxd7",
            "Kxd7",
            "Nxe6",
            "Qxe6",
            "Qxe6+",
            "Rxe6",
            "Rxe6",
            "Kxe6",
            "Re1+",
            "Kd6",
            "f3",
            "Re8",
            "Rxe8",
            "Nxe8",
            "g4",
            "Nf6",
            "Kd2",
            "c5",
            "dxc5+",
            "Kxc5",
            "b4+",
            "Kd6",
            "Ke3",
            "Nd7",
            "c4",
            "dxc4",
            "Bxc4",
            "Ne5",
            "Bg8",
            "h6",
            "Ke4",
            "Nc6",
            "a3",
            "Bb2",
            "b5",
            "Ne7",
            "Bf7",
            "Bxa3",
            "f4",
            "Bc1",
            "f5",
            "gxf5+",
            "gxf5",
            "Bb2",
            "h5",
            "Bf6",
            "Be6",
            "Kc5",
            "Bd7",
            "a6",
            "bxa6",
            "bxa6",
            "Kd3",
            "a5",
            "Kc2",
            "Kb4",
            "Kb1",
            "a4",
            "Ka2",
            "a3",
            "Be6",
            "Nc6",
            "Bd5",
            "Nd4",
            "Be4",
            "Nb5",
            "Bd3",
            "Nc3+",
            "Ka1",
            "Kb3",
            "Bc4+",
            "Kxc4",
            "Kb3",
            "a5",
            "Ka4",
            "a4",
            "Kb5",
            "a3",
            "Ka6",
            "a2",
            "Kb7",
            "a1=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rhe1",
          "neutral_uci": "h1e1",
          "neutral_response": "14. Rhe1 Re8 15. Bc4 d5 16. Bd3 Bd7 17. Ne5 Kc8 18. Nxd7 Kxd7 19. Nxe6 Qxe6 20. Qxe6+ Rxe6 21. Rxe6 Kxe6 22. Re1+ Kd7 23. f3 Re8 24. Rxe8 Nxe8 25. g4 Nd6 26. Kd2 Ke6 27. Ke3 b6 28. b3 c5 29. dxc5 bxc5 30. c4 d4+ 31. Kf4 Be5+ 32. Kg5 Nf7# d4 d5 d6",
          "neutral_tokens": {
            "prompt_tokens": 213,
            "completion_tokens": 162,
            "total_tokens": 375,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Re8",
            "Bc4",
            "d5",
            "Bd3",
            "Bd7",
            "Ne5",
            "Kc8",
            "Nxd7",
            "Kxd7",
            "Nxe6",
            "Qxe6",
            "Qxe6+",
            "Rxe6",
            "Rxe6",
            "Kxe6",
            "Re1+",
            "Kd7",
            "f3",
            "Re8",
            "Rxe8",
            "Nxe8",
            "g4",
            "Nd6",
            "Kd2",
            "Ke6",
            "Ke3",
            "b6",
            "b3",
            "c5",
            "dxc5",
            "bxc5",
            "c4",
            "d4+",
            "Kf4",
            "Be5+",
            "Kg5",
            "Nf7#",
            "d4",
            "d5",
            "d6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h1e1",
          "positional_uci": "h1e1",
          "neutral_uci": "h1e1",
          "consensus_move": "h1e1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Re8",
              "Bc4",
              "d5",
              "Bd3",
              "c6",
              "Ne5",
              "Kc7",
              "f4",
              "Bd7",
              "g4",
              "Rad8",
              "h5",
              "gxh5",
              "gxh5",
              "Bh6",
              "Rg1",
              "Rf8",
              "Rdf1",
              "Be8",
              "Ng4",
              "Nxg4",
              "Qxg4",
              "Bd7",
              "Qg3",
              "Qd6",
              "Nh3",
              "Rg8",
              "Qh4",
              "Rxg1",
              "Rxg1",
              "Rf8",
              "Rf1",
              "c5",
              "dxc5",
              "Qxc5",
              "Kb1",
              "Qe3",
              "Bc2",
              "e5",
              "Ng5",
              "Rxf4",
              "Rxf4",
              "Qxf4",
              "Qxf4",
              "exf4",
              "Nf3",
              "Bg4",
              "Bd1",
              "Bxh5",
              "Kc2",
              "Bg6+",
              "Kd2",
              "Be4",
              "Ke2",
              "Kd6",
              "Kf2",
              "Bg7",
              "Ng5",
              "Bf6",
              "Nf3",
              "h5",
              "Kg2",
              "h4",
              "Kh3",
              "Bf5+",
              "Kg2",
              "h3+",
              "Kh2",
              "Be4",
              "Kxh3",
              "Bxf3",
              "Bxf3",
              "Ke5",
              "Kg4",
              "b5",
              "Be2",
              "a6",
              "Kf3",
              "d4",
              "cxd4+",
              "Kxd4",
              "Kxf4",
              "Be5+",
              "Kf3",
              "Bd6",
              "Kf2",
              "Bc5",
              "Ke1",
              "Ke3",
              "Kd1",
              "Bd4",
              "b3",
              "Bc3",
              "Bf1",
              "Kd4",
              "Kc2",
              "Be1",
              "a4",
              "bxa4",
              "bxa4",
              "a5",
              "Kb3",
              "Bb4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4",
              "Kd4",
              "Bb5",
              "Kc5",
              "Bc4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Re8",
              "Bc4",
              "d5",
              "Bd3",
              "Bd7",
              "Ne5",
              "Kc8",
              "Nxd7",
              "Kxd7",
              "Nxe6",
              "Qxe6",
              "Qxe6+",
              "Rxe6",
              "Rxe6",
              "Kxe6",
              "Re1+",
              "Kd6",
              "f3",
              "Re8",
              "Rxe8",
              "Nxe8",
              "g4",
              "Nf6",
              "Kd2",
              "c5",
              "dxc5+",
              "Kxc5",
              "b4+",
              "Kd6",
              "Ke3",
              "Nd7",
              "c4",
              "dxc4",
              "Bxc4",
              "Ne5",
              "Bg8",
              "h6",
              "Ke4",
              "Nc6",
              "a3",
              "Bb2",
              "b5",
              "Ne7",
              "Bf7",
              "Bxa3",
              "f4",
              "Bc1",
              "f5",
              "gxf5+",
              "gxf5",
              "Bb2",
              "h5",
              "Bf6",
              "Be6",
              "Kc5",
              "Bd7",
              "a6",
              "bxa6",
              "bxa6",
              "Kd3",
              "a5",
              "Kc2",
              "Kb4",
              "Kb1",
              "a4",
              "Ka2",
              "a3",
              "Be6",
              "Nc6",
              "Bd5",
              "Nd4",
              "Be4",
              "Nb5",
              "Bd3",
              "Nc3+",
              "Ka1",
              "Kb3",
              "Bc4+",
              "Kxc4",
              "Kb3",
              "a5",
              "Ka4",
              "a4",
              "Kb5",
              "a3",
              "Ka6",
              "a2",
              "Kb7",
              "a1=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re8",
              "Bc4",
              "d5",
              "Bd3",
              "Bd7",
              "Ne5",
              "Kc8",
              "Nxd7",
              "Kxd7",
              "Nxe6",
              "Qxe6",
              "Qxe6+",
              "Rxe6",
              "Rxe6",
              "Kxe6",
              "Re1+",
              "Kd7",
              "f3",
              "Re8",
              "Rxe8",
              "Nxe8",
              "g4",
              "Nd6",
              "Kd2",
              "Ke6",
              "Ke3",
              "b6",
              "b3",
              "c5",
              "dxc5",
              "bxc5",
              "c4",
              "d4+",
              "Kf4",
              "Be5+",
              "Kg5",
              "Nf7#",
              "d4",
              "d5",
              "d6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 214,
            "completion_tokens": 365,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 213,
            "completion_tokens": 162,
            "total_tokens": 375,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 641,
          "total_completion_tokens": 1167,
          "total_tokens": 1808
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 214,
            "completion_tokens": 640,
            "total_tokens": 854,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 214,
            "completion_tokens": 365,
            "total_tokens": 579,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 26,
            "turn_number": 14,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 213,
            "completion_tokens": 162,
            "total_tokens": 375,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk3r/ppp1q1bp/3ppnp1/6N1/3P3P/2PB1N2/PP2QPP1/2KR3R w - - 3 14"
    },
    {
      "turn": 29,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Nxh7",
          "aggressive_uci": "g5h7",
          "aggressive_response": "15. Nxh7 Nxh7 16. Bxg6 Rh8 17. g4 Nf8 18. Bd3 Bd7 19. g5 Be8 20. Qe4 c6 21.\nQg4 Bh5 22. Qg3 Kc7 23. Rd2 Re8 24. Nh2 e5 25. f4 Qf7 26. f5 Qxa2 27. f6\nBxf6 28. gxf6 Nd7 29. dxe5 Nxe5 30. Bb1 Qf7 31. Rf2 Rhg8 32. Qf4 Nd3+ 33.\nBxd3 Rxe1+ 34. Kd2 Rd1+ 35. Kc2 Rgg1 36. Nf1 Qd5 37. f7 Rxd3 38. f8=Q Bd1+\n39. Kc1 Bb3 40. Qe7+ Kb6 41. Qd8+ Ka6 42. Rd2 Rxf1+ 43. Qxf1 Rxd2 44. Qxd3+\nQxd3 45. Qa5+ Kxa5 46. c4 Qc2# Qc2 Qd1#",
          "aggressive_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 283,
            "total_tokens": 505,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg6",
            "Rh8",
            "g4",
            "Nf8",
            "Bd3",
            "Bd7",
            "g5",
            "Be8",
            "Qe4",
            "c6",
            "Qg4",
            "Bh5",
            "Qg3",
            "Kc7",
            "Rd2",
            "Re8",
            "Nh2",
            "e5",
            "f4",
            "Qf7",
            "f5",
            "Qxa2",
            "f6",
            "Bxf6",
            "gxf6",
            "Nd7",
            "dxe5",
            "Nxe5",
            "Bb1",
            "Qf7",
            "Rf2",
            "Rhg8",
            "Qf4",
            "Nd3+",
            "Bxd3",
            "Rxe1+",
            "Kd2",
            "Rd1+",
            "Kc2",
            "Rgg1",
            "Nf1",
            "Qd5",
            "f7",
            "Rxd3",
            "f8=Q",
            "Bd1+",
            "Kc1",
            "Bb3",
            "Qe7+",
            "Kb6",
            "Qd8+",
            "Ka6",
            "Rd2",
            "Rxf1+",
            "Qxf1",
            "Rxd2",
            "Qxd3+",
            "Qxd3",
            "Qa5+",
            "Kxa5",
            "c4",
            "Qc2#",
            "Qc2",
            "Qd1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Nxh7",
          "positional_uci": "g5h7",
          "positional_response": "15. Nxh7 Nxh7 16. Bxg6 Nf6 17. Bxe8 Qxe8 18. Ng5 Bh6 19. f4 Bxg5 20. hxg5\nNd5 21. Qf3 Qf7 22. g3 Bd7 23. Rh1 c6 24. Rh8+ Be8 25. Rdh1 Kc7 26. R1h7\nQxh7 27. Rxh7+ Kb6 28. c4 Nb4 29. Qb3 a5 30. a3 c5 31. dxc5+ dxc5 32. axb4\naxb4 33. Qe3 Bc6 34. Qxe6 Ra1+ 35. Kd2 Rb1 36. Kc2 Rg1 37. Qe3 Rg2+ 38. Kb3\nKa5 39. Qxc5+ Ka6 40. Qxb4 Rxg3+ 41. Ka2 Rg1 42. c5 Bd5+ 43. b3 Rg2+ 44. Ka3\nBc6 45. Qb6# g4 46. Qb4 g3 47. Qb6# g2 48. Qb4 g1=Q 49. Qb6# g3",
          "positional_tokens": {
            "prompt_tokens": 222,
            "completion_tokens": 308,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg6",
            "Nf6",
            "Bxe8",
            "Qxe8",
            "Ng5",
            "Bh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qf7",
            "g3",
            "Bd7",
            "Rh1",
            "c6",
            "Rh8+",
            "Be8",
            "Rdh1",
            "Kc7",
            "R1h7",
            "Qxh7",
            "Rxh7+",
            "Kb6",
            "c4",
            "Nb4",
            "Qb3",
            "a5",
            "a3",
            "c5",
            "dxc5+",
            "dxc5",
            "axb4",
            "axb4",
            "Qe3",
            "Bc6",
            "Qxe6",
            "Ra1+",
            "Kd2",
            "Rb1",
            "Kc2",
            "Rg1",
            "Qe3",
            "Rg2+",
            "Kb3",
            "Ka5",
            "Qxc5+",
            "Ka6",
            "Qxb4",
            "Rxg3+",
            "Ka2",
            "Rg1",
            "c5",
            "Bd5+",
            "b3",
            "Rg2+",
            "Ka3",
            "Bc6",
            "Qb6#",
            "g4",
            "Qb4",
            "g3",
            "Qb6#",
            "g2",
            "Qb4",
            "g1=Q",
            "Qb6#",
            "g3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Nxh7",
          "neutral_uci": "g5h7",
          "neutral_response": "15. Nxh7 Nxh7 16. Bxg6 Rh8 17. g4 Nf8 18. Bc2 Bd7 19. g5 c6 20. Rh1 Kc7\n21. h5 Nh7 22. Rdg1 Raf8 23. h6 Bxh6 24. Rxh6 Rfg8 25. Qe3 Nf8 26. Rxh8 Rxh8\n27. g6 Qg7 28. Qg5 Rh6 29. Nh4 Be8 30. f4 Bxg6 31. f5 exf5 32. Nxf5 Qh7 33. Nxh6\nBxc2 34. Qg7+ Qxg7 35. Rxg7+ Nd7 36. Kxc2 b5 37. Nf5 d5 38. b4 a6 39. Kd3 Kc8\n40. Ne7+ Kc7 41. Ke3 Kd6 42. Nc8+ Kc7 43. Kf4 Kxc8 44. Kf5 Kd8 45. Ke6 Nb6\n46. Kd6 Nc4+ 47. Kxc6 Ne3 48. Ra7 Nd1 49. Kd6 Kc8 50. Rc7+ Kb8 51. Rc5 Kb7\n52. Kxd5 Kb6 53. Ke6 Ne3 54. d5 Nc4 55. d6 Nxd6 56. Kxd6 a5 57. a3 axb4\n58. axb4 Ka6 59. Kc6 Ka7 60. Rxb5 Ka6 61. Ra5# Kxa5 62. b5 Ka4 63. b6 Kb3\n64. b7 Kxc3 65. b8=Q Kd4 66. Qd6+ Ke4 67. Qd5+ Kf4 68. Kd6 Ke3 69. Ke5 Kf2\n70. Qd3 Kg2 71. Kf4 Kf2 72. Qd2+ Kg1 73. Kg3 Kf1 74. Qf2# Kd1 75. Kf3 Kc1\n76. Ke3 Kb1 77. Kd3 Ka1 78. Kc3 Kb1 79. Qb2# Kc1 80. Qc2# Kc1 81. Qc1#\nKxc1 82. Kd3 Kb1 83. Kc3 Ka1 84. Kb3 Kb1 85. Ka3 Ka1 86. Kb3 Kb1 87. Kc3 Ka1\n88. Kd3 Kb1 89. Ke3 Ka1 90. Kf3 Kb1 91. Kg3 Ka",
          "neutral_tokens": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxg6",
            "Rh8",
            "g4",
            "Nf8",
            "Bc2",
            "Bd7",
            "g5",
            "c6",
            "Rh1",
            "Kc7",
            "h5",
            "Nh7",
            "Rdg1",
            "Raf8",
            "h6",
            "Bxh6",
            "Rxh6",
            "Rfg8",
            "Qe3",
            "Nf8",
            "Rxh8",
            "Rxh8",
            "g6",
            "Qg7",
            "Qg5",
            "Rh6",
            "Nh4",
            "Be8",
            "f4",
            "Bxg6",
            "f5",
            "exf5",
            "Nxf5",
            "Qh7",
            "Nxh6",
            "Bxc2",
            "Qg7+",
            "Qxg7",
            "Rxg7+",
            "Nd7",
            "Kxc2",
            "b5",
            "Nf5",
            "d5",
            "b4",
            "a6",
            "Kd3",
            "Kc8",
            "Ne7+",
            "Kc7",
            "Ke3",
            "Kd6",
            "Nc8+",
            "Kc7",
            "Kf4",
            "Kxc8",
            "Kf5",
            "Kd8",
            "Ke6",
            "Nb6",
            "Kd6",
            "Nc4+",
            "Kxc6",
            "Ne3",
            "Ra7",
            "Nd1",
            "Kd6",
            "Kc8",
            "Rc7+",
            "Kb8",
            "Rc5",
            "Kb7",
            "Kxd5",
            "Kb6",
            "Ke6",
            "Ne3",
            "d5",
            "Nc4",
            "d6",
            "Nxd6",
            "Kxd6",
            "a5",
            "a3",
            "axb4",
            "axb4",
            "Ka6",
            "Kc6",
            "Ka7",
            "Rxb5",
            "Ka6",
            "Ra5#",
            "Kxa5",
            "b5",
            "Ka4",
            "b6",
            "Kb3",
            "b7",
            "Kxc3",
            "b8=Q",
            "Kd4",
            "Qd6+",
            "Ke4",
            "Qd5+",
            "Kf4",
            "Kd6",
            "Ke3",
            "Ke5",
            "Kf2",
            "Qd3",
            "Kg2",
            "Kf4",
            "Kf2",
            "Qd2+",
            "Kg1",
            "Kg3",
            "Kf1",
            "Qf2#",
            "Kd1",
            "Kf3",
            "Kc1",
            "Ke3",
            "Kb1",
            "Kd3",
            "Ka1",
            "Kc3",
            "Kb1",
            "Qb2#",
            "Kc1",
            "Qc2#",
            "Kc1",
            "Qc1#",
            "Kxc1",
            "Kd3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kb3",
            "Kb1",
            "Ka3",
            "Ka1",
            "Kb3",
            "Kb1",
            "Kc3",
            "Ka1",
            "Kd3",
            "Kb1",
            "Ke3",
            "Ka1",
            "Kf3",
            "Kb1",
            "Kg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5h7",
          "positional_uci": "g5h7",
          "neutral_uci": "g5h7",
          "consensus_move": "g5h7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxg6",
              "Rh8",
              "g4",
              "Nf8",
              "Bd3",
              "Bd7",
              "g5",
              "Be8",
              "Qe4",
              "c6",
              "Qg4",
              "Bh5",
              "Qg3",
              "Kc7",
              "Rd2",
              "Re8",
              "Nh2",
              "e5",
              "f4",
              "Qf7",
              "f5",
              "Qxa2",
              "f6",
              "Bxf6",
              "gxf6",
              "Nd7",
              "dxe5",
              "Nxe5",
              "Bb1",
              "Qf7",
              "Rf2",
              "Rhg8",
              "Qf4",
              "Nd3+",
              "Bxd3",
              "Rxe1+",
              "Kd2",
              "Rd1+",
              "Kc2",
              "Rgg1",
              "Nf1",
              "Qd5",
              "f7",
              "Rxd3",
              "f8=Q",
              "Bd1+",
              "Kc1",
              "Bb3",
              "Qe7+",
              "Kb6",
              "Qd8+",
              "Ka6",
              "Rd2",
              "Rxf1+",
              "Qxf1",
              "Rxd2",
              "Qxd3+",
              "Qxd3",
              "Qa5+",
              "Kxa5",
              "c4",
              "Qc2#",
              "Qc2",
              "Qd1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxg6",
              "Nf6",
              "Bxe8",
              "Qxe8",
              "Ng5",
              "Bh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qf7",
              "g3",
              "Bd7",
              "Rh1",
              "c6",
              "Rh8+",
              "Be8",
              "Rdh1",
              "Kc7",
              "R1h7",
              "Qxh7",
              "Rxh7+",
              "Kb6",
              "c4",
              "Nb4",
              "Qb3",
              "a5",
              "a3",
              "c5",
              "dxc5+",
              "dxc5",
              "axb4",
              "axb4",
              "Qe3",
              "Bc6",
              "Qxe6",
              "Ra1+",
              "Kd2",
              "Rb1",
              "Kc2",
              "Rg1",
              "Qe3",
              "Rg2+",
              "Kb3",
              "Ka5",
              "Qxc5+",
              "Ka6",
              "Qxb4",
              "Rxg3+",
              "Ka2",
              "Rg1",
              "c5",
              "Bd5+",
              "b3",
              "Rg2+",
              "Ka3",
              "Bc6",
              "Qb6#",
              "g4",
              "Qb4",
              "g3",
              "Qb6#",
              "g2",
              "Qb4",
              "g1=Q",
              "Qb6#",
              "g3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxg6",
              "Rh8",
              "g4",
              "Nf8",
              "Bc2",
              "Bd7",
              "g5",
              "c6",
              "Rh1",
              "Kc7",
              "h5",
              "Nh7",
              "Rdg1",
              "Raf8",
              "h6",
              "Bxh6",
              "Rxh6",
              "Rfg8",
              "Qe3",
              "Nf8",
              "Rxh8",
              "Rxh8",
              "g6",
              "Qg7",
              "Qg5",
              "Rh6",
              "Nh4",
              "Be8",
              "f4",
              "Bxg6",
              "f5",
              "exf5",
              "Nxf5",
              "Qh7",
              "Nxh6",
              "Bxc2",
              "Qg7+",
              "Qxg7",
              "Rxg7+",
              "Nd7",
              "Kxc2",
              "b5",
              "Nf5",
              "d5",
              "b4",
              "a6",
              "Kd3",
              "Kc8",
              "Ne7+",
              "Kc7",
              "Ke3",
              "Kd6",
              "Nc8+",
              "Kc7",
              "Kf4",
              "Kxc8",
              "Kf5",
              "Kd8",
              "Ke6",
              "Nb6",
              "Kd6",
              "Nc4+",
              "Kxc6",
              "Ne3",
              "Ra7",
              "Nd1",
              "Kd6",
              "Kc8",
              "Rc7+",
              "Kb8",
              "Rc5",
              "Kb7",
              "Kxd5",
              "Kb6",
              "Ke6",
              "Ne3",
              "d5",
              "Nc4",
              "d6",
              "Nxd6",
              "Kxd6",
              "a5",
              "a3",
              "axb4",
              "axb4",
              "Ka6",
              "Kc6",
              "Ka7",
              "Rxb5",
              "Ka6",
              "Ra5#",
              "Kxa5",
              "b5",
              "Ka4",
              "b6",
              "Kb3",
              "b7",
              "Kxc3",
              "b8=Q",
              "Kd4",
              "Qd6+",
              "Ke4",
              "Qd5+",
              "Kf4",
              "Kd6",
              "Ke3",
              "Ke5",
              "Kf2",
              "Qd3",
              "Kg2",
              "Kf4",
              "Kf2",
              "Qd2+",
              "Kg1",
              "Kg3",
              "Kf1",
              "Qf2#",
              "Kd1",
              "Kf3",
              "Kc1",
              "Ke3",
              "Kb1",
              "Kd3",
              "Ka1",
              "Kc3",
              "Kb1",
              "Qb2#",
              "Kc1",
              "Qc2#",
              "Kc1",
              "Qc1#",
              "Kxc1",
              "Kd3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kb3",
              "Kb1",
              "Ka3",
              "Ka1",
              "Kb3",
              "Kb1",
              "Kc3",
              "Ka1",
              "Kd3",
              "Kb1",
              "Ke3",
              "Ka1",
              "Kf3",
              "Kb1",
              "Kg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 222,
            "completion_tokens": 283,
            "total_tokens": 505,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 222,
            "completion_tokens": 308,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 665,
          "total_completion_tokens": 1231,
          "total_tokens": 1896
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 222,
            "completion_tokens": 283,
            "total_tokens": 505,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 222,
            "completion_tokens": 308,
            "total_tokens": 530,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 28,
            "turn_number": 15,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 221,
            "completion_tokens": 640,
            "total_tokens": 861,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bkr3/ppp1q1bp/3ppnp1/6N1/3P3P/2PB1N2/PP2QPP1/2KRR3 w - - 5 15"
    },
    {
      "turn": 31,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxg6",
          "aggressive_uci": "d3g6",
          "aggressive_response": "16. Bxg6 Nf6 17. Bxe8 Qxe8 18. Ng5 Bh6 19. f4 Bxg5 20. hxg5 Nd5 21. Qf3 Qf7\n22. g3 Bd7 23. Rh1 c6 24. Rh8+ Be8 25. Rdh1 Kc7 26. R1h7 Ne7 27. Rxf7 Bxf7\n28. Rxa8 Nc8 29. g4 Bg6 30. f5 exf5 31. gxf5 Bf7 32. g6 Bd5 33. Qxd5 cxd5\n34. Rxc8+ Kxc8 35. g7 Kd7 36. g8=Q Kc6 37. Qe6 b5 38. f6 a5 39. f7 b4\n40. f8=Q bxc3 41. Qfxd6+ Kb5 42. Qexd5+ Ka4 43. Qb3# Bb7 44. Qda3# Bc6\n45. Qxc3 Bb5 46. Qcb3# Bc6 47. Qxc6# Bb5 48. Qcxb5# Bc6 49. Q3a4# Bb5\n50. Qaxb5# Bc6 51. Q5xc6# Bb5 52. Qcxb5# Bc6 53. Q5xc6# Bb5 54. Qcxb5# Bc6\n55. Q5xc6# Bb5 56. Qcxb5# Bc6 57. Q5xc6# Bb5 58. Qcxb5# Bc6 59. Q5xc6# Bb5\n60. Qcxb5# Bc6 61. Q5xc6# Bb5 62. Qcxb5# Bc6 63. Q5xc6# Bb5 64. Qcxb5# Bc6\n65. Q5xc6# Bb5 66. Qcxb5# Bc6 67. Q5xc6# Bb5 68. Qcxb5# Bc6 69. Q5xc6# Bb5\n70. Qcxb5# Bc6 71. Q5xc6# Bb5 72. Qcxb5# Bc6 73. Q5xc6# Bb5 74. Qcxb5# Bc6\n75. Q5xc6# Bb5 76. Qcxb5# Bc6 77. Q5xc6# Bb5 78. Qcxb5# Bc6 79. Q5xc6# Bb5\n80. Qcxb5#",
          "aggressive_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Bxe8",
            "Qxe8",
            "Ng5",
            "Bh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qf7",
            "g3",
            "Bd7",
            "Rh1",
            "c6",
            "Rh8+",
            "Be8",
            "Rdh1",
            "Kc7",
            "R1h7",
            "Ne7",
            "Rxf7",
            "Bxf7",
            "Rxa8",
            "Nc8",
            "g4",
            "Bg6",
            "f5",
            "exf5",
            "gxf5",
            "Bf7",
            "g6",
            "Bd5",
            "Qxd5",
            "cxd5",
            "Rxc8+",
            "Kxc8",
            "g7",
            "Kd7",
            "g8=Q",
            "Kc6",
            "Qe6",
            "b5",
            "f6",
            "a5",
            "f7",
            "b4",
            "f8=Q",
            "bxc3",
            "Qfxd6+",
            "Kb5",
            "Qexd5+",
            "Ka4",
            "Qb3#",
            "Bb7",
            "Qda3#",
            "Bc6",
            "Qxc3",
            "Bb5",
            "Qcb3#",
            "Bc6",
            "Qxc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q3a4#",
            "Bb5",
            "Qaxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#",
            "Bc6",
            "Q5xc6#",
            "Bb5",
            "Qcxb5#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxg6",
          "positional_uci": "d3g6",
          "positional_response": "16. Bxg6 Nf6 17. Bxe8 Qxe8 18. Ng5 Bh6 19. f4 Bxg5 20. hxg5 Nd5 21. Qf3 Qf7\n22. g3 Bd7 23. Rh1 c6 24. Rh8+ Be8 25. Rdh1 Kc7 26. R1h7 Ne7 27. Rxf7 Bxf7 28.\nRxa8 Nc8 29. f5 exf5 30. Qxf5 Bd5 31. Rxc8+ Kb6 32. g6 Bxa2 33. g7 a5 34. g8=Q\nBxg8 35. Rxg8 a4 36. Ra8 d5 37. Rxa4 Kb5 38. Rb4+ Ka5 39. Qc8 b5 40. Qxc6 *",
          "positional_tokens": {
            "prompt_tokens": 231,
            "completion_tokens": 209,
            "total_tokens": 440,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bxe8",
            "Qxe8",
            "Ng5",
            "Bh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qf7",
            "g3",
            "Bd7",
            "Rh1",
            "c6",
            "Rh8+",
            "Be8",
            "Rdh1",
            "Kc7",
            "R1h7",
            "Ne7",
            "Rxf7",
            "Bxf7",
            "Rxa8",
            "Nc8",
            "f5",
            "exf5",
            "Qxf5",
            "Bd5",
            "Rxc8+",
            "Kb6",
            "g6",
            "Bxa2",
            "g7",
            "a5",
            "g8=Q",
            "Bxg8",
            "Rxg8",
            "a4",
            "Ra8",
            "d5",
            "Rxa4",
            "Kb5",
            "Rb4+",
            "Ka5",
            "Qc8",
            "b5",
            "Qxc6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxg6",
          "neutral_uci": "d3g6",
          "neutral_response": "16. Bxg6 Nf6 17. Bxe8 Qxe8 18. Ng5 Bh6 19. f4 Bxg5 20. hxg5 Nd5 21. Qf3 Qf7\n22. g3 Bd7 23. Rh1 c6 24. Rh8+ Be8 25. Rdh1 Ne7 26. R1h7 Qf5 27. g4 Qa5 28. f5\nexf5 29. gxf5 Qxa2 30. f6 Qa1+ 31. Kc2 Qa4+ 32. Kd2 Qb3 33. fxe7+ Kc7 34. Rxe8\nQxb2+ 35. Ke1 Rxe8 36. Qe3 Qb1+ 37. Kf2 Qxh7 38. Qe6 Rxe7 39. Qf6 Rf7 40. Kg3\nRxf6 41. gxf6 Qg6+ 42. Kf4 Qxf6+ 43. Ke4 d5+ 44. Kd3 Qf3+ 45. Kc2 Qe2+ 46. Kb3\nQc4+ 47. Kc2 a5 48. Kb2 a4 49. Kc2 a3 50. Kd2 a2 51. Ke3 a1=Q 52. Kf4 Qaxc3 53.\nKf5 Q3xd4 54. Ke6 Qe4+ 55. Kf7 Qf1+ 56. Kg7 Qeg2+ 57. Kh6 Qfh1# e4 g5 d3 Bg7 Bxg7 g6 d6 Bg7 Nd7 Qe7 O-O-O fxe4 Nxe4 Neg5 Kd8 Rhe1 Re8 Nxh7 Bxh6 f4 Bxg5 hxg5 Nd5 Qf3 Qa5 fxe7+ Kc7 R1e6 Qxa2 f6 Qa1+ Kc2 Qa4+ Kd2 Qb3 fxe8=Q Qxb2+ Ke1 Qc1+ Kf2 Qd2+ Kg3 Qd1 Qc7+ Kc8 Re8#",
          "neutral_tokens": {
            "prompt_tokens": 230,
            "completion_tokens": 514,
            "total_tokens": 744,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Nf6",
            "Bxe8",
            "Qxe8",
            "Ng5",
            "Bh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qf7",
            "g3",
            "Bd7",
            "Rh1",
            "c6",
            "Rh8+",
            "Be8",
            "Rdh1",
            "Ne7",
            "R1h7",
            "Qf5",
            "g4",
            "Qa5",
            "f5",
            "exf5",
            "gxf5",
            "Qxa2",
            "f6",
            "Qa1+",
            "Kc2",
            "Qa4+",
            "Kd2",
            "Qb3",
            "fxe7+",
            "Kc7",
            "Rxe8",
            "Qxb2+",
            "Ke1",
            "Rxe8",
            "Qe3",
            "Qb1+",
            "Kf2",
            "Qxh7",
            "Qe6",
            "Rxe7",
            "Qf6",
            "Rf7",
            "Kg3",
            "Rxf6",
            "gxf6",
            "Qg6+",
            "Kf4",
            "Qxf6+",
            "Ke4",
            "d5+",
            "Kd3",
            "Qf3+",
            "Kc2",
            "Qe2+",
            "Kb3",
            "Qc4+",
            "Kc2",
            "a5",
            "Kb2",
            "a4",
            "Kc2",
            "a3",
            "Kd2",
            "a2",
            "Ke3",
            "a1=Q",
            "Kf4",
            "Qaxc3",
            "Kf5",
            "Q3xd4",
            "Ke6",
            "Qe4+",
            "Kf7",
            "Qf1+",
            "Kg7",
            "Qeg2+",
            "Kh6",
            "Qfh1#",
            "e4",
            "g5",
            "d3",
            "Bg7",
            "Bxg7",
            "g6",
            "d6",
            "Bg7",
            "Nd7",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Bxh6",
            "f4",
            "Bxg5",
            "hxg5",
            "Nd5",
            "Qf3",
            "Qa5",
            "fxe7+",
            "Kc7",
            "R1e6",
            "Qxa2",
            "f6",
            "Qa1+",
            "Kc2",
            "Qa4+",
            "Kd2",
            "Qb3",
            "fxe8=Q",
            "Qxb2+",
            "Ke1",
            "Qc1+",
            "Kf2",
            "Qd2+",
            "Kg3",
            "Qd1",
            "Qc7+",
            "Kc8",
            "Re8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d3g6",
          "positional_uci": "d3g6",
          "neutral_uci": "d3g6",
          "consensus_move": "d3g6",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Nf6",
              "Bxe8",
              "Qxe8",
              "Ng5",
              "Bh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qf7",
              "g3",
              "Bd7",
              "Rh1",
              "c6",
              "Rh8+",
              "Be8",
              "Rdh1",
              "Kc7",
              "R1h7",
              "Ne7",
              "Rxf7",
              "Bxf7",
              "Rxa8",
              "Nc8",
              "g4",
              "Bg6",
              "f5",
              "exf5",
              "gxf5",
              "Bf7",
              "g6",
              "Bd5",
              "Qxd5",
              "cxd5",
              "Rxc8+",
              "Kxc8",
              "g7",
              "Kd7",
              "g8=Q",
              "Kc6",
              "Qe6",
              "b5",
              "f6",
              "a5",
              "f7",
              "b4",
              "f8=Q",
              "bxc3",
              "Qfxd6+",
              "Kb5",
              "Qexd5+",
              "Ka4",
              "Qb3#",
              "Bb7",
              "Qda3#",
              "Bc6",
              "Qxc3",
              "Bb5",
              "Qcb3#",
              "Bc6",
              "Qxc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q3a4#",
              "Bb5",
              "Qaxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#",
              "Bc6",
              "Q5xc6#",
              "Bb5",
              "Qcxb5#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Bxe8",
              "Qxe8",
              "Ng5",
              "Bh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qf7",
              "g3",
              "Bd7",
              "Rh1",
              "c6",
              "Rh8+",
              "Be8",
              "Rdh1",
              "Kc7",
              "R1h7",
              "Ne7",
              "Rxf7",
              "Bxf7",
              "Rxa8",
              "Nc8",
              "f5",
              "exf5",
              "Qxf5",
              "Bd5",
              "Rxc8+",
              "Kb6",
              "g6",
              "Bxa2",
              "g7",
              "a5",
              "g8=Q",
              "Bxg8",
              "Rxg8",
              "a4",
              "Ra8",
              "d5",
              "Rxa4",
              "Kb5",
              "Rb4+",
              "Ka5",
              "Qc8",
              "b5",
              "Qxc6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Nf6",
              "Bxe8",
              "Qxe8",
              "Ng5",
              "Bh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qf7",
              "g3",
              "Bd7",
              "Rh1",
              "c6",
              "Rh8+",
              "Be8",
              "Rdh1",
              "Ne7",
              "R1h7",
              "Qf5",
              "g4",
              "Qa5",
              "f5",
              "exf5",
              "gxf5",
              "Qxa2",
              "f6",
              "Qa1+",
              "Kc2",
              "Qa4+",
              "Kd2",
              "Qb3",
              "fxe7+",
              "Kc7",
              "Rxe8",
              "Qxb2+",
              "Ke1",
              "Rxe8",
              "Qe3",
              "Qb1+",
              "Kf2",
              "Qxh7",
              "Qe6",
              "Rxe7",
              "Qf6",
              "Rf7",
              "Kg3",
              "Rxf6",
              "gxf6",
              "Qg6+",
              "Kf4",
              "Qxf6+",
              "Ke4",
              "d5+",
              "Kd3",
              "Qf3+",
              "Kc2",
              "Qe2+",
              "Kb3",
              "Qc4+",
              "Kc2",
              "a5",
              "Kb2",
              "a4",
              "Kc2",
              "a3",
              "Kd2",
              "a2",
              "Ke3",
              "a1=Q",
              "Kf4",
              "Qaxc3",
              "Kf5",
              "Q3xd4",
              "Ke6",
              "Qe4+",
              "Kf7",
              "Qf1+",
              "Kg7",
              "Qeg2+",
              "Kh6",
              "Qfh1#",
              "e4",
              "g5",
              "d3",
              "Bg7",
              "Bxg7",
              "g6",
              "d6",
              "Bg7",
              "Nd7",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Bxh6",
              "f4",
              "Bxg5",
              "hxg5",
              "Nd5",
              "Qf3",
              "Qa5",
              "fxe7+",
              "Kc7",
              "R1e6",
              "Qxa2",
              "f6",
              "Qa1+",
              "Kc2",
              "Qa4+",
              "Kd2",
              "Qb3",
              "fxe8=Q",
              "Qxb2+",
              "Ke1",
              "Qc1+",
              "Kf2",
              "Qd2+",
              "Kg3",
              "Qd1",
              "Qc7+",
              "Kc8",
              "Re8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 231,
            "completion_tokens": 209,
            "total_tokens": 440,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 230,
            "completion_tokens": 514,
            "total_tokens": 744,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 692,
          "total_completion_tokens": 1363,
          "total_tokens": 2055
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 231,
            "completion_tokens": 640,
            "total_tokens": 871,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 231,
            "completion_tokens": 209,
            "total_tokens": 440,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 30,
            "turn_number": 16,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 230,
            "completion_tokens": 514,
            "total_tokens": 744,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bkr3/ppp1q1bn/3pp1p1/8/3P3P/2PB1N2/PP2QPP1/2KRR3 w - - 0 16"
    },
    {
      "turn": 33,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Bxh7",
          "aggressive_uci": "g6h7",
          "aggressive_response": "17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5\nQf7 23. Qh4+ Qf6 24. Qh1 c6 25. Rf1 Qe7 26. Rxf8+ Qxf8 27. Rf1 Qe7 28. Qh8+\nKc7 29. Qg8 Kb6 30. Rf7 Qh4 31. Qg2 Qe1+ 32. Kc2 d5 33. Bd3 e5 34. dxe5 Qxe5\n35. Qf2+ c5 36. b4 d4 37. bxc5+ Kxc5 38. cxd4+ Qxd4 39. Rc7+ Kd5 40. Bc4+ Ke5\n41. Re7+ Kd6 42. Qxd4+ Kxe7 43. Qe5+ Kd8 44. Qd6+ Bd7 45. Be6 Rc8+ 46. Kd2 Rc7\n47. Qf8+ Be8 48. Qf6+ Re7 49. Kc3 Bd7 50. Bxd7 Kxd7 51. Qd4+ Kc7 52. Qxa7 Re6\n53. Qc5+ Rc6 54. Kb4 Rxc5 55. Kxc5 b6+ 56. Kb5 Kb7 57. a4 Ka7 58. a5 bxa5\n59. Kxa5 1/2-1/2\n\nd4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxg5+\n20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5 Qf7 23. Qh4+ Qf6 24. Qh1 c6 25. Rf1 Qe7\n26. Rxf8+ Qxf8 27. Rf1 Qe7 28. Qh8+ Kc7 29. Qg8 Kb6",
          "aggressive_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qh5",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh1",
            "c6",
            "Rf1",
            "Qe7",
            "Rxf8+",
            "Qxf8",
            "Rf1",
            "Qe7",
            "Qh8+",
            "Kc7",
            "Qg8",
            "Kb6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Bxh7",
          "positional_uci": "g6h7",
          "positional_response": "Re8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7\n20. Rh1 Qg7 21. f4 Bd7 22. Rh6 c6 23. Rdh1 Kc7 24. Rh7 Qg6 25. R1h6 Qf5 26. Rf6\nQxh7 27. g6 Qh1+ 28. Kc2 e5 29. dxe5 dxe5 30. fxe5 Rad8 31. g7 Qh7+ 32. Kb3\nQxg7 33. Qe3 Kb8 34. Qf4 Be6+ 35. Ka3 Qe7+ 36. b4 a5 37. g4 axb4+ 38. cxb4 Rd3+\n39. Ka4 b5+ 40. Ka5 Qa7# Qe7 41. g5 Qa7# Qe7 42. g5 Qa7# Qe7 43. g6 Qa7# Qe7\n44. g7 Qa7# Qe7 45. g8=Q Qa7# Qe7 46. Qxe8+ Qxe8 47. Rf8 Qxf8 48. Qxf8+ Kc7\n49. Qe7+ Bd7 50. e6 Rd6 51. exd7 Rxd7 52. Qe5+ Kb6 53. a4 bxa4 54. Kxa4 Rd5 55.\nQe3+ Kc7 56. c4 Rd7 57. Qe5+ Kc8 58. b5 cxb5+ 59. cxb5 Rc7 60. b6 Rc6 61. Qe8+\nKb7 62. Kb5 Rxb6+ 63. Kc5 Rc6+ 64. Qxc6+ Ka7 65. Qb5 Ka8 66. Kc6 Ka7 67. Qb7#\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7\n20. Rh1 Qg7 21.",
          "positional_tokens": {
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Bxh7",
          "neutral_uci": "g6h7",
          "neutral_response": "Re8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7\n20. Rh1 Qg7 21. f4 Bd7 22. Rh6 c6 23. Rdh1 Kc7 24. Rh7 Qg6 25. R1h6 Qf5 26. Rf6\nQxh7 27. g6 Qh1+ 28. Kc2 Rg8 29. Qg4 Raf8 30. Rxf8 Rxf8 31. g7 Rg8 32. Qg6\nQh8 33. gxh8=Q Rxh8 34. g4 Rf8 35. Qg5 * Rf8 36. Qh6 Rg8 37. g5 Be8 38. Qxe6\nBd7 39. Qxg8 * Rf8 40. Qxf8 * Rxf8 41. g6 Rxf4 42. g7 Rf2+ 43. Kb3 * Rg2 44.\nQf7 * Rg3 45. g8=Q * Rg7 46. Qgxg7 * Kb6 47. Qxd7 * Ka5 48. Qxb7 * c5 49. Qxa7+ *\nKb5 50. Qhb7# Kf5 51. Qf7+ * Kg4 52. Qg2+ * Kh4 53. Qh7# Kf4 54. Qf2+ * Kg4 55.\nQg6+ * Kh3 56. Qfg3# Kxg3 57. Qf5 * Kh4 58. Qg6 * Kh3 59. Qg5 * Kh2 60. Qg4 *\nKh1 61. Kc2 * Kh2 62. Kd2 * Kh1 63. Ke2 * Kh2 64. Kf2 * Kh1 65. Qg2# Kh2 66.\nQg3+ * Kh1 67. Qg1# Kh2 68. Qg2# Kh1 69. Qg1# Kh2 70. Qg2# Kh1 71. Qg1# Kh2\n72. Qg2# Kh1 73. Qg1# Kh2 74. Qg2# Kh1 75. Qg1# Kh2 76. Qg2# Kh1 77. Qg1# Kh2\n78. Qg2# Kh1 79. Qg1# Kh2 80. Qg2# Kh1 81. Qg1# Kh2 82. Qg2# Kh1 83. Qg1# Kh2\n84. Qg2# Kh1 85. Qg1# Kh2",
          "neutral_tokens": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qg7",
            "f4",
            "Bd7",
            "Rh6",
            "c6",
            "Rdh1",
            "Kc7",
            "Rh7",
            "Qg6",
            "R1h6",
            "Qf5",
            "Rf6",
            "Qxh7",
            "g6",
            "Qh1+",
            "Kc2",
            "Rg8",
            "Qg4",
            "Raf8",
            "Rxf8",
            "Rxf8",
            "g7",
            "Rg8",
            "Qg6",
            "Qh8",
            "gxh8=Q",
            "Rxh8",
            "g4",
            "Rf8",
            "Qg5",
            "Rf8",
            "Qh6",
            "Rg8",
            "g5",
            "Be8",
            "Qxe6",
            "Bd7",
            "Qxg8",
            "Rf8",
            "Qxf8",
            "Rxf8",
            "g6",
            "Rxf4",
            "g7",
            "Rf2+",
            "Kb3",
            "Rg2",
            "Qf7",
            "Rg3",
            "g8=Q",
            "Rg7",
            "Qgxg7",
            "Kb6",
            "Qxd7",
            "Ka5",
            "Qxb7",
            "c5",
            "Qxa7+",
            "Kb5",
            "Qhb7#",
            "Kf5",
            "Qf7+",
            "Kg4",
            "Qg2+",
            "Kh4",
            "Qh7#",
            "Kf4",
            "Qf2+",
            "Kg4",
            "Qg6+",
            "Kh3",
            "Qfg3#",
            "Kxg3",
            "Qf5",
            "Kh4",
            "Qg6",
            "Kh3",
            "Qg5",
            "Kh2",
            "Qg4",
            "Kh1",
            "Kc2",
            "Kh2",
            "Kd2",
            "Kh1",
            "Ke2",
            "Kh2",
            "Kf2",
            "Kh1",
            "Qg2#",
            "Kh2",
            "Qg3+",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2",
            "Qg2#",
            "Kh1",
            "Qg1#",
            "Kh2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g6h7",
          "positional_uci": "g6h7",
          "neutral_uci": "g6h7",
          "consensus_move": "g6h7",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qh5",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh1",
              "c6",
              "Rf1",
              "Qe7",
              "Rxf8+",
              "Qxf8",
              "Rf1",
              "Qe7",
              "Qh8+",
              "Kc7",
              "Qg8",
              "Kb6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qg7",
              "f4",
              "Bd7",
              "Rh6",
              "c6",
              "Rdh1",
              "Kc7",
              "Rh7",
              "Qg6",
              "R1h6",
              "Qf5",
              "Rf6",
              "Qxh7",
              "g6",
              "Qh1+",
              "Kc2",
              "Rg8",
              "Qg4",
              "Raf8",
              "Rxf8",
              "Rxf8",
              "g7",
              "Rg8",
              "Qg6",
              "Qh8",
              "gxh8=Q",
              "Rxh8",
              "g4",
              "Rf8",
              "Qg5",
              "Rf8",
              "Qh6",
              "Rg8",
              "g5",
              "Be8",
              "Qxe6",
              "Bd7",
              "Qxg8",
              "Rf8",
              "Qxf8",
              "Rxf8",
              "g6",
              "Rxf4",
              "g7",
              "Rf2+",
              "Kb3",
              "Rg2",
              "Qf7",
              "Rg3",
              "g8=Q",
              "Rg7",
              "Qgxg7",
              "Kb6",
              "Qxd7",
              "Ka5",
              "Qxb7",
              "c5",
              "Qxa7+",
              "Kb5",
              "Qhb7#",
              "Kf5",
              "Qf7+",
              "Kg4",
              "Qg2+",
              "Kh4",
              "Qh7#",
              "Kf4",
              "Qf2+",
              "Kg4",
              "Qg6+",
              "Kh3",
              "Qfg3#",
              "Kxg3",
              "Qf5",
              "Kh4",
              "Qg6",
              "Kh3",
              "Qg5",
              "Kh2",
              "Qg4",
              "Kh1",
              "Kc2",
              "Kh2",
              "Kd2",
              "Kh1",
              "Ke2",
              "Kh2",
              "Kf2",
              "Kh1",
              "Qg2#",
              "Kh2",
              "Qg3+",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2",
              "Qg2#",
              "Kh1",
              "Qg1#",
              "Kh2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 722,
          "total_completion_tokens": 1920,
          "total_tokens": 2642
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 241,
            "completion_tokens": 640,
            "total_tokens": 881,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 32,
            "turn_number": 17,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 240,
            "completion_tokens": 640,
            "total_tokens": 880,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk1r2/ppp1q1bn/3pp1B1/8/3P3P/2P2N2/PP2QPP1/2KRR3 w - - 1 17"
    },
    {
      "turn": 35,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ng5",
          "aggressive_uci": "f3g5",
          "aggressive_response": "18. Ng5 Bxg5+ 19. hxg5 Qxh7 20. Rh1 Qf5 21. Qh5 Bd7 22. g4 Qf4+ 23. Kb1 Be8 24. g6 Rg8 25. Qh4+ Kd7 26. Qh7+ Kc6 27. Qxg8 Bxg6+ 28. Qxg6 Qxf2 29. Qxe6 Rf8 30. Qc4+ Kd7 31. Rh7+ Kd8 32. Qxc7+ Ke8 33. Qe7# Bg8",
          "aggressive_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 149,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qf5",
            "Qh5",
            "Bd7",
            "g4",
            "Qf4+",
            "Kb1",
            "Be8",
            "g6",
            "Rg8",
            "Qh4+",
            "Kd7",
            "Qh7+",
            "Kc6",
            "Qxg8",
            "Bxg6+",
            "Qxg6",
            "Qxf2",
            "Qxe6",
            "Rf8",
            "Qc4+",
            "Kd7",
            "Rh7+",
            "Kd8",
            "Qxc7+",
            "Ke8",
            "Qe7#",
            "Bg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ng5",
          "positional_uci": "f3g5",
          "positional_response": "18. Ng5 Bxg5+ 19. hxg5 Qxh7 20. Rh1 Qg6 21. Rh5 Bd7 22. Rdh1 c6 23. Rh6 Qxg5+ 24. Kb1 Kc7 25. Rh7 Qf5+ 26. Ka1 Rf7 27. R7h5 Qxf2 28. Qxf2 Rxf2 29. g4 Raf8 30. a3 Rf1+ 31. Rxf1 Rxf1+ 32. Ka2 Rg1 33. g5 e5 34. dxe5 Be6+ 35. b3 Rg2+ 36. Kb1 Bxb3 37. Rh7+ Kb6 38. exd6 Rxg5 39. d7 Rd5 40. Kb2 Bc4 41. a4 a5 42. Kc2 Kc7 43. d8=Q+ Kxd8 44. Rxb7 Rd7 45. Rb6 Kc7 46. Rb1 Bd3+ 47. Kb2 Bxb1 48. Kxb1 Rd2 49. Kc1 Rh2 50. Kb1 Kd6 51. Kc1 Kc5 52. Kb1 Kc4 53. Kc1 Kxc3 54. Kb1 c5 55. Ka1 Kb3 56. Kb1 Rh1#",
          "positional_tokens": {
            "prompt_tokens": 251,
            "completion_tokens": 329,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qg6",
            "Rh5",
            "Bd7",
            "Rdh1",
            "c6",
            "Rh6",
            "Qxg5+",
            "Kb1",
            "Kc7",
            "Rh7",
            "Qf5+",
            "Ka1",
            "Rf7",
            "R7h5",
            "Qxf2",
            "Qxf2",
            "Rxf2",
            "g4",
            "Raf8",
            "a3",
            "Rf1+",
            "Rxf1",
            "Rxf1+",
            "Ka2",
            "Rg1",
            "g5",
            "e5",
            "dxe5",
            "Be6+",
            "b3",
            "Rg2+",
            "Kb1",
            "Bxb3",
            "Rh7+",
            "Kb6",
            "exd6",
            "Rxg5",
            "d7",
            "Rd5",
            "Kb2",
            "Bc4",
            "a4",
            "a5",
            "Kc2",
            "Kc7",
            "d8=Q+",
            "Kxd8",
            "Rxb7",
            "Rd7",
            "Rb6",
            "Kc7",
            "Rb1",
            "Bd3+",
            "Kb2",
            "Bxb1",
            "Kxb1",
            "Rd2",
            "Kc1",
            "Rh2",
            "Kb1",
            "Kd6",
            "Kc1",
            "Kc5",
            "Kb1",
            "Kc4",
            "Kc1",
            "Kxc3",
            "Kb1",
            "c5",
            "Ka1",
            "Kb3",
            "Kb1",
            "Rh1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ng5",
          "neutral_uci": "f3g5",
          "neutral_response": "18. Ng5 Bxg5+ 19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5 Qf7 23. Qh4+ Qe7\n24. Qh6 c6 25. Rf1 Rxf1 26. Rxf1 Bd7 27. Rf8+ Be8 28. Bg6 Kd7 29. Bxe8+ Rxe8\n30. Rf6 Rg8 31. a3 Rg7 32. Rxe6 Qh7+ 33. Qxh7 Rxh7 34. Rg6 Re7 35. Kc2 Re6\n36. Rg7+ Re7 37. Rg6 Re6 38. Rg7+ Re7 39. Rg6 Re6 40. Rg7+ Re7 41. Rg6 Re6\n42. Rg7+ Re7 43. Rg6 Re6 44. Rg7+ Re7 45. Rg6 Re6 46. Rg7+ Re7 47. Rg6 Re6\n48. Rg7+ Re7 49. Rg6 Re6 50. Rg7+ Re7 51. Rg6 Re6 52. Rg7+ Re7 53. Rg6 Re6\n54. Rg7+ Re7 55. Rg6 Re6 56. Rg7+ Re7 57. Rg6 Re6 58. Rg7+ Re7 59. Rg6 Re6\n60. Rg7+ Re7 61. Rg6 Re6 62. Rg7+ Re7 63. Rg6 Re6 64. Rg7+ Re7 65. Rg6 Re6\n66. Rg7+ Re7 67. Rg6 Re6 68. Rg7+ Re7 69. Rg6 Re6 70. Rg7+ Re7 71. Rg6 Re6\n72. Rg7+ Re7 73. Rg6 Re6 74. Rg7+ Re7 75. Rg6 Re6 76. Rg7+ Re7 77. Rg6 Re6\n78. Rg7+ Re7 79. Rg6 Re6 80. Rg7+ Re7 81. Rg6 Re6 82. Rg7+ Re7 83. Rg6 Re6\n84. Rg7+ Re7 85. Rg6 Re6 86. Rg7+ Re7 87. Rg6 Re6 88. Rg7+ Re7 89. Rg6 Re6\n90. Rg7+ Re7 91. Rg6 Re6",
          "neutral_tokens": {
            "prompt_tokens": 250,
            "completion_tokens": 640,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxg5+",
            "hxg5",
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qh5",
            "Qf7",
            "Qh4+",
            "Qe7",
            "Qh6",
            "c6",
            "Rf1",
            "Rxf1",
            "Rxf1",
            "Bd7",
            "Rf8+",
            "Be8",
            "Bg6",
            "Kd7",
            "Bxe8+",
            "Rxe8",
            "Rf6",
            "Rg8",
            "a3",
            "Rg7",
            "Rxe6",
            "Qh7+",
            "Qxh7",
            "Rxh7",
            "Rg6",
            "Re7",
            "Kc2",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6",
            "Rg7+",
            "Re7",
            "Rg6",
            "Re6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3g5",
          "positional_uci": "f3g5",
          "neutral_uci": "f3g5",
          "consensus_move": "f3g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qf5",
              "Qh5",
              "Bd7",
              "g4",
              "Qf4+",
              "Kb1",
              "Be8",
              "g6",
              "Rg8",
              "Qh4+",
              "Kd7",
              "Qh7+",
              "Kc6",
              "Qxg8",
              "Bxg6+",
              "Qxg6",
              "Qxf2",
              "Qxe6",
              "Rf8",
              "Qc4+",
              "Kd7",
              "Rh7+",
              "Kd8",
              "Qxc7+",
              "Ke8",
              "Qe7#",
              "Bg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qg6",
              "Rh5",
              "Bd7",
              "Rdh1",
              "c6",
              "Rh6",
              "Qxg5+",
              "Kb1",
              "Kc7",
              "Rh7",
              "Qf5+",
              "Ka1",
              "Rf7",
              "R7h5",
              "Qxf2",
              "Qxf2",
              "Rxf2",
              "g4",
              "Raf8",
              "a3",
              "Rf1+",
              "Rxf1",
              "Rxf1+",
              "Ka2",
              "Rg1",
              "g5",
              "e5",
              "dxe5",
              "Be6+",
              "b3",
              "Rg2+",
              "Kb1",
              "Bxb3",
              "Rh7+",
              "Kb6",
              "exd6",
              "Rxg5",
              "d7",
              "Rd5",
              "Kb2",
              "Bc4",
              "a4",
              "a5",
              "Kc2",
              "Kc7",
              "d8=Q+",
              "Kxd8",
              "Rxb7",
              "Rd7",
              "Rb6",
              "Kc7",
              "Rb1",
              "Bd3+",
              "Kb2",
              "Bxb1",
              "Kxb1",
              "Rd2",
              "Kc1",
              "Rh2",
              "Kb1",
              "Kd6",
              "Kc1",
              "Kc5",
              "Kb1",
              "Kc4",
              "Kc1",
              "Kxc3",
              "Kb1",
              "c5",
              "Ka1",
              "Kb3",
              "Kb1",
              "Rh1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bxg5+",
              "hxg5",
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qh5",
              "Qf7",
              "Qh4+",
              "Qe7",
              "Qh6",
              "c6",
              "Rf1",
              "Rxf1",
              "Rxf1",
              "Bd7",
              "Rf8+",
              "Be8",
              "Bg6",
              "Kd7",
              "Bxe8+",
              "Rxe8",
              "Rf6",
              "Rg8",
              "a3",
              "Rg7",
              "Rxe6",
              "Qh7+",
              "Qxh7",
              "Rxh7",
              "Rg6",
              "Re7",
              "Kc2",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6",
              "Rg7+",
              "Re7",
              "Rg6",
              "Re6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 251,
            "completion_tokens": 149,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 251,
            "completion_tokens": 329,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 250,
            "completion_tokens": 640,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 752,
          "total_completion_tokens": 1118,
          "total_tokens": 1870
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 251,
            "completion_tokens": 149,
            "total_tokens": 400,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 251,
            "completion_tokens": 329,
            "total_tokens": 580,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 34,
            "turn_number": 18,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 250,
            "completion_tokens": 640,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk1r2/ppp1q2B/3pp2b/8/3P3P/2P2N2/PP2QPP1/2KRR3 w - - 1 18"
    },
    {
      "turn": 37,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "hxg5",
          "aggressive_uci": "h4g5",
          "aggressive_response": "19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qxf2 Rxf2 23. Rh1 d5 24. Rh8+ Ke7\n25. Bd3 b6 26. Rg1 Bb7 27. Rh7+ Rf7 28. Rgg7 Rf8 29. Bg6 Rxg7 30. Rxg7+ Kd6\n31. Kc2 Ba6 32. Kb3 Bc4+ 33. Ka3 a5 34. b3 Bb5 35. Bc2 Rf2 36. Bb1 Rf3 37. Kb2\nRf2+ 38. Ka3 Rf3 39. Kb2 Rf2+ 40. Ka3 Rf3 41. Kb2 Rf2+ 42. Ka3 Rf3 43. Kb2 Rf2+ 44. Ka3 Rf3 45. Kb2 Rf2+ 46. Ka3 Rf3 47. Kb2 Rf2+ 48. Ka3 Rf3 49. Kb2 Rf2+ 50. Ka3 Rf3 51. Kb2 Rf2+ 52. Ka3 Rf3 53. Kb2 Rf2+ 54. Ka3 Rf3 55. Kb2 Rf2+ 56. Ka3 Rf3 57. Kb2 Rf2+ 58. Ka3 Rf3 59. Kb2 Rf2+ 60. Ka3 Rf3 61. Kb2 Rf2+ 62. Ka3 Rf3 63. Kb2 Rf2+ 64. Ka3 Rf3 65. Kb2 Rf2+ 66. Ka3 Rf3 67. Kb2 Rf2+ 68. Ka3 Rf3 69. Kb2 Rf2+ 70. Ka3 Rf3 71. Kb2 Rf2+ 72. Ka3 Rf3 73. Kb2 Rf2+ 74. Ka3 Rf3 75. Kb2 Rf2+ 76. Ka3 Rf3 77. Kb2 Rf2+ 78. Ka3 Rf3 79. Kb2 Rf2+ 80. Ka3 Rf3 81. Kb2 Rf2+ 82. Ka3 Rf3 83. Kb2 Rf2+ 84. Ka3 Rf3 85. Kb2 Rf2+ 86. Ka3 Rf3 87. Kb2 Rf2+ 88. Ka3 Rf3 89. Kb2 Rf2+ 90. Ka3 Rf3 91. Kb2 Rf2+ 92. Ka3 Rf3 93. Kb2 Rf2",
          "aggressive_tokens": {
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qxf2",
            "Rxf2",
            "Rh1",
            "d5",
            "Rh8+",
            "Ke7",
            "Bd3",
            "b6",
            "Rg1",
            "Bb7",
            "Rh7+",
            "Rf7",
            "Rgg7",
            "Rf8",
            "Bg6",
            "Rxg7",
            "Rxg7+",
            "Kd6",
            "Kc2",
            "Ba6",
            "Kb3",
            "Bc4+",
            "Ka3",
            "a5",
            "b3",
            "Bb5",
            "Bc2",
            "Rf2",
            "Bb1",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2+",
            "Ka3",
            "Rf3",
            "Kb2",
            "Rf2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "hxg5",
          "positional_uci": "h4g5",
          "positional_response": "19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5 Qf7 23. Qh4+ Qf6 24. Qh7 Qf7 25. Qh4+ Qf6 26. Qh7 Qf7 27. Qh4+ Qf6 28. Qh7 Qf7 29. Qh4+ Qf6 30. Qh7 Qf7 31. Qh4+ Qf6 32. Qh7 Qf7 33. Qh4+ Qf6 34. Qh7 Qf7 35. Qh4+ Qf6 36. Qh7 Qf7 37. Qh4+ Qf6 38. Qh7 Qf7 39. Qh4+ Qf6 40. Qh7 Qf7 41. Qh4+ Qf6 42. Qh7 Qf7 43. Qh4+ Qf6 44. Qh7 Qf7 45. Qh4+ Qf6 46. Qh7 Qf7 47. Qh4+ Qf6 48. Qh7 Qf7 49. Qh4+ Qf6 50. Qh7 Qf7 51. Qh4+ Qf6 52. Qh7 Qf7 53. Qh4+ Qf6 54. Qh7 Qf7 55. Qh4+ Qf6 56. Qh7 Qf7 57. Qh4+ Qf6 58. Qh7 Qf7 59. Qh4+ Qf6 60. Qh7 Qf7 61. Qh4+ Qf6 62. Qh7 Qf7 63. Qh4+ Qf6 64. Qh7 Qf7 65. Qh4+ Qf6 66. Qh7 Qf7 67. Qh4+ Qf6 68. Qh7 Qf7 69. Qh4+ Qf6 70. Qh7 Qf7 71. Qh4+ Qf6 72. Qh7 Qf7 73. Qh4+ Qf6 74. Qh7 Qf7 75. Qh4+ Qf6 76. Qh7 Qf7 77. Qh4+ Qf6 78. Qh7 Qf7 79. Qh4+ Qf6 80. Qh7 Qf7 81. Qh4+ Qf6 82. Qh7 Qf7 83. Qh4+ Qf6 84. Qh7 Qf7 85. Qh4+ Qf6 86. Q",
          "positional_tokens": {
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qh5",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6",
            "Qh7",
            "Qf7",
            "Qh4+",
            "Qf6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "hxg5",
          "neutral_uci": "h4g5",
          "neutral_response": "19. hxg5 Qxg5+ 20. Kb1 Qxg2 21. Be4 Qxf2 22. Qh5 Qf7 23. Qh4+ Qe7 24. Qh6\nQf6 25. Qh1 Qh8 26. Qg2 Qg8 27. Qh2 Qh8 28. Qg3 Qg8 29. Qh4+ Kd7 30. Rg1\nQh8 31. Qg5 Qf6 32. Qh5 Qh8 33. Qg6 Qf6 34. Qh7+ Qf7 35. Rg7 Ke8 36. Rxf7\nRxf7 37. Bg6 Kd7 38. Qxf7+ Kc6 39. Qe8+ Kb6 40. Bd3 c6 41. Qd8# e5 42. Qxd6\nexd4 43. Qd8+ Kc5 44. b4# Kd5 45. Bf5+ Ke5 46. Bxc8 dxc3 47. Qd4# Kf5 48.\nRf1+ Kg5 49. Qg4+ Kh6 50. Rh1# Kg7 51. Qg5# Kf7 52. Rh7+ Kf8 53. Qg7+ Ke8\n54. Qe7# Kf8 55. Qf7# Kg8 56. Qg7# 1-0",
          "neutral_tokens": {
            "prompt_tokens": 260,
            "completion_tokens": 353,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxg5+",
            "Kb1",
            "Qxg2",
            "Be4",
            "Qxf2",
            "Qh5",
            "Qf7",
            "Qh4+",
            "Qe7",
            "Qh6",
            "Qf6",
            "Qh1",
            "Qh8",
            "Qg2",
            "Qg8",
            "Qh2",
            "Qh8",
            "Qg3",
            "Qg8",
            "Qh4+",
            "Kd7",
            "Rg1",
            "Qh8",
            "Qg5",
            "Qf6",
            "Qh5",
            "Qh8",
            "Qg6",
            "Qf6",
            "Qh7+",
            "Qf7",
            "Rg7",
            "Ke8",
            "Rxf7",
            "Rxf7",
            "Bg6",
            "Kd7",
            "Qxf7+",
            "Kc6",
            "Qe8+",
            "Kb6",
            "Bd3",
            "c6",
            "Qd8#",
            "e5",
            "Qxd6",
            "exd4",
            "Qd8+",
            "Kc5",
            "b4#",
            "Kd5",
            "Bf5+",
            "Ke5",
            "Bxc8",
            "dxc3",
            "Qd4#",
            "Kf5",
            "Rf1+",
            "Kg5",
            "Qg4+",
            "Kh6",
            "Rh1#",
            "Kg7",
            "Qg5#",
            "Kf7",
            "Rh7+",
            "Kf8",
            "Qg7+",
            "Ke8",
            "Qe7#",
            "Kf8",
            "Qf7#",
            "Kg8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4g5",
          "positional_uci": "h4g5",
          "neutral_uci": "h4g5",
          "consensus_move": "h4g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qxf2",
              "Rxf2",
              "Rh1",
              "d5",
              "Rh8+",
              "Ke7",
              "Bd3",
              "b6",
              "Rg1",
              "Bb7",
              "Rh7+",
              "Rf7",
              "Rgg7",
              "Rf8",
              "Bg6",
              "Rxg7",
              "Rxg7+",
              "Kd6",
              "Kc2",
              "Ba6",
              "Kb3",
              "Bc4+",
              "Ka3",
              "a5",
              "b3",
              "Bb5",
              "Bc2",
              "Rf2",
              "Bb1",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2+",
              "Ka3",
              "Rf3",
              "Kb2",
              "Rf2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qh5",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6",
              "Qh7",
              "Qf7",
              "Qh4+",
              "Qf6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxg5+",
              "Kb1",
              "Qxg2",
              "Be4",
              "Qxf2",
              "Qh5",
              "Qf7",
              "Qh4+",
              "Qe7",
              "Qh6",
              "Qf6",
              "Qh1",
              "Qh8",
              "Qg2",
              "Qg8",
              "Qh2",
              "Qh8",
              "Qg3",
              "Qg8",
              "Qh4+",
              "Kd7",
              "Rg1",
              "Qh8",
              "Qg5",
              "Qf6",
              "Qh5",
              "Qh8",
              "Qg6",
              "Qf6",
              "Qh7+",
              "Qf7",
              "Rg7",
              "Ke8",
              "Rxf7",
              "Rxf7",
              "Bg6",
              "Kd7",
              "Qxf7+",
              "Kc6",
              "Qe8+",
              "Kb6",
              "Bd3",
              "c6",
              "Qd8#",
              "e5",
              "Qxd6",
              "exd4",
              "Qd8+",
              "Kc5",
              "b4#",
              "Kd5",
              "Bf5+",
              "Ke5",
              "Bxc8",
              "dxc3",
              "Qd4#",
              "Kf5",
              "Rf1+",
              "Kg5",
              "Qg4+",
              "Kh6",
              "Rh1#",
              "Kg7",
              "Qg5#",
              "Kf7",
              "Rh7+",
              "Kf8",
              "Qg7+",
              "Ke8",
              "Qe7#",
              "Kf8",
              "Qf7#",
              "Kg8",
              "Qg7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 260,
            "completion_tokens": 353,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 782,
          "total_completion_tokens": 1633,
          "total_tokens": 2415
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 261,
            "completion_tokens": 640,
            "total_tokens": 901,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 36,
            "turn_number": 19,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 260,
            "completion_tokens": 353,
            "total_tokens": 613,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk1r2/ppp1q2B/3pp3/6b1/3P3P/2P5/PP2QPP1/2KRR3 w - - 0 19"
    },
    {
      "turn": 39,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rh1",
          "aggressive_uci": "e1h1",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20. Rh1 Qf5 21. Qh5 Bd7 22. g4 Qf4+ 23. Kb1 Be8",
          "aggressive_tokens": {
            "prompt_tokens": 271,
            "completion_tokens": 194,
            "total_tokens": 465,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf5",
            "Qh5",
            "Bd7",
            "g4",
            "Qf4+",
            "Kb1",
            "Be8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rh1",
          "positional_uci": "e1h1",
          "positional_response": "20. Rh1 Qf5 21. Qe3 Qxf2 22. Qxf2 Rxf2 23. Rh8+ Ke7 24. Rdh1 Kf7 25. R1h7+ Kg6 26. Rxc7 Kxg5 27. Rcxc8 Rxc8 28. Rxc8 Kf5 29. Rc7 Rxg2 30. Rxb7 Ke4 31. Rxa7 Kd3 32. b4 Kxc3 33. Rc7+ Kxb4 34. Rc6 Rxa2 35. Rxd6 Kc3 36. Kd1 Kd3 37. Ke1 Ke3 38. Rxe6+ Kxd4 39. Re2 Ra1+ 40. Kf2 Ra3 41. Rd2+ Ke4 42. Re2+ Kf4 43. Rd2 Rf3+ 44. Ke2 Re3+ 45. Kd1 Ra3 46. Kc2 Ra2+ 47. Kc3 Ra3+ 48. Kc2 Ra2+ 49. Kc3 Ra3+ 50. Kc2 Ra2+ 51. Kc3 Ra3+ 52. Kc2 Ra2+ 53. Kc3 Ra3+ 54. Kc2 Ra2+ 55. Kc3 Ra3+ 56. Kc2 Ra2+ 57. Kc3 Ra3+ 58. Kc2 Ra2+ 59. Kc3 Ra3+ 60. Kc2 Ra2+ 61. Kc3 Ra3+ 62. Kc2 Ra2+ 63. Kc3 Ra3+ 64. Kc2 Ra2+ 65. Kc3 Ra3+ 66. Kc2 Ra2+ 67. Kc3 Ra3+ 68. Kc2 Ra2+ 69. Kc3 Ra3+ 70. Kc2 Ra2+ 71. Kc3 Ra3+ 72. Kc2 Ra2+ 73. Kc3 Ra3+ 74. Kc2 Ra2+ 75. Kc3 Ra3+ 76. Kc2 Ra2+ 77. Kc3 Ra3+ 78. Kc2 Ra2+ 79. Kc3 Ra3+ 80. Kc2 Ra2+ 81. Kc3 Ra3+ 82. Kc2 Ra2+ 83. Kc3 Ra3+ 84. Kc2 Ra2+ 85. Kc3 Ra3+ 86. Kc2 Ra2+ 87. Kc3 Ra3+ 88. Kc2 Ra2+ 89. Kc3 Ra3+ 90. Kc2 Ra2+ 91. Kc3 Ra3+ 92",
          "positional_tokens": {
            "prompt_tokens": 271,
            "completion_tokens": 640,
            "total_tokens": 911,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qf5",
            "Qe3",
            "Qxf2",
            "Qxf2",
            "Rxf2",
            "Rh8+",
            "Ke7",
            "Rdh1",
            "Kf7",
            "R1h7+",
            "Kg6",
            "Rxc7",
            "Kxg5",
            "Rcxc8",
            "Rxc8",
            "Rxc8",
            "Kf5",
            "Rc7",
            "Rxg2",
            "Rxb7",
            "Ke4",
            "Rxa7",
            "Kd3",
            "b4",
            "Kxc3",
            "Rc7+",
            "Kxb4",
            "Rc6",
            "Rxa2",
            "Rxd6",
            "Kc3",
            "Kd1",
            "Kd3",
            "Ke1",
            "Ke3",
            "Rxe6+",
            "Kxd4",
            "Re2",
            "Ra1+",
            "Kf2",
            "Ra3",
            "Rd2+",
            "Ke4",
            "Re2+",
            "Kf4",
            "Rd2",
            "Rf3+",
            "Ke2",
            "Re3+",
            "Kd1",
            "Ra3",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+",
            "Kc2",
            "Ra2+",
            "Kc3",
            "Ra3+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rh1",
          "neutral_uci": "e1h1",
          "neutral_response": "20. Rh1 Qf5 21. Qh5 Bd7 22. g4 Qf4+ 23. Kb1 Be8 24. g6 Rg8 25. Qh4+ Kd7 26. Qh7+ Kc6 27. Qxg8 Bxg6+ 28. Qxg6 Qxf2 29. Qxe6 Qf3 30. d5+ Kb6 31. Rhf1 Qg3 32. Qe4 a5 33. Qd4+ Ka6 34. Qc4+ Kb6 35. Rf7 Rc8 36. a4 Qe3 37. Qb5+ Ka7 38. Qxa5+ Kb8 39. Qb4 Qe2 40. Rdf1 Qd3+ 41. Ka1 Qxd5 42. Rf8 Qe6 43. Rxc8+ Qxc8 44. g5 Qh3 45. Rf8+ Ka7 46. Qa5# Bf8 Qxf8+ Qb6 Qxb6#",
          "neutral_tokens": {
            "prompt_tokens": 270,
            "completion_tokens": 252,
            "total_tokens": 522,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf5",
            "Qh5",
            "Bd7",
            "g4",
            "Qf4+",
            "Kb1",
            "Be8",
            "g6",
            "Rg8",
            "Qh4+",
            "Kd7",
            "Qh7+",
            "Kc6",
            "Qxg8",
            "Bxg6+",
            "Qxg6",
            "Qxf2",
            "Qxe6",
            "Qf3",
            "d5+",
            "Kb6",
            "Rhf1",
            "Qg3",
            "Qe4",
            "a5",
            "Qd4+",
            "Ka6",
            "Qc4+",
            "Kb6",
            "Rf7",
            "Rc8",
            "a4",
            "Qe3",
            "Qb5+",
            "Ka7",
            "Qxa5+",
            "Kb8",
            "Qb4",
            "Qe2",
            "Rdf1",
            "Qd3+",
            "Ka1",
            "Qxd5",
            "Rf8",
            "Qe6",
            "Rxc8+",
            "Qxc8",
            "g5",
            "Qh3",
            "Rf8+",
            "Ka7",
            "Qa5#",
            "Bf8",
            "Qxf8+",
            "Qb6",
            "Qxb6#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e1h1",
          "positional_uci": "e1h1",
          "neutral_uci": "e1h1",
          "consensus_move": "e1h1",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qf5",
              "Qh5",
              "Bd7",
              "g4",
              "Qf4+",
              "Kb1",
              "Be8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qf5",
              "Qe3",
              "Qxf2",
              "Qxf2",
              "Rxf2",
              "Rh8+",
              "Ke7",
              "Rdh1",
              "Kf7",
              "R1h7+",
              "Kg6",
              "Rxc7",
              "Kxg5",
              "Rcxc8",
              "Rxc8",
              "Rxc8",
              "Kf5",
              "Rc7",
              "Rxg2",
              "Rxb7",
              "Ke4",
              "Rxa7",
              "Kd3",
              "b4",
              "Kxc3",
              "Rc7+",
              "Kxb4",
              "Rc6",
              "Rxa2",
              "Rxd6",
              "Kc3",
              "Kd1",
              "Kd3",
              "Ke1",
              "Ke3",
              "Rxe6+",
              "Kxd4",
              "Re2",
              "Ra1+",
              "Kf2",
              "Ra3",
              "Rd2+",
              "Ke4",
              "Re2+",
              "Kf4",
              "Rd2",
              "Rf3+",
              "Ke2",
              "Re3+",
              "Kd1",
              "Ra3",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+",
              "Kc2",
              "Ra2+",
              "Kc3",
              "Ra3+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qf5",
              "Qh5",
              "Bd7",
              "g4",
              "Qf4+",
              "Kb1",
              "Be8",
              "g6",
              "Rg8",
              "Qh4+",
              "Kd7",
              "Qh7+",
              "Kc6",
              "Qxg8",
              "Bxg6+",
              "Qxg6",
              "Qxf2",
              "Qxe6",
              "Qf3",
              "d5+",
              "Kb6",
              "Rhf1",
              "Qg3",
              "Qe4",
              "a5",
              "Qd4+",
              "Ka6",
              "Qc4+",
              "Kb6",
              "Rf7",
              "Rc8",
              "a4",
              "Qe3",
              "Qb5+",
              "Ka7",
              "Qxa5+",
              "Kb8",
              "Qb4",
              "Qe2",
              "Rdf1",
              "Qd3+",
              "Ka1",
              "Qxd5",
              "Rf8",
              "Qe6",
              "Rxc8+",
              "Qxc8",
              "g5",
              "Qh3",
              "Rf8+",
              "Ka7",
              "Qa5#",
              "Bf8",
              "Qxf8+",
              "Qb6",
              "Qxb6#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 271,
            "completion_tokens": 194,
            "total_tokens": 465,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 271,
            "completion_tokens": 640,
            "total_tokens": 911,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 270,
            "completion_tokens": 252,
            "total_tokens": 522,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 812,
          "total_completion_tokens": 1086,
          "total_tokens": 1898
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 271,
            "completion_tokens": 194,
            "total_tokens": 465,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 271,
            "completion_tokens": 640,
            "total_tokens": 911,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 38,
            "turn_number": 20,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 270,
            "completion_tokens": 252,
            "total_tokens": 522,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk1r2/ppp4q/3pp3/6P1/3P4/2P5/PP2QPP1/2KRR3 w - - 0 20"
    },
    {
      "turn": 41,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh5",
          "aggressive_uci": "e2h5",
          "aggressive_response": "21. Qh5 Bd7 22. g6 Be8 23. Qg5+ Kc8 24. Rh6 b6 25. Rdh1 Kb7 26. f4 Bc6 27. Rh7\nRf5 28. Qe7 Rc8 29. g7 Rf7 30. Qg5 Be4 31. Rh8 Qxg7 32. Qxg7 Rxg7 33. Rxc8\nKxc8 34. Rh2 Rxg2 35. Rxg2 Bxg2 36. Kd2 Kd7 37. Ke3 Ke7 38. Kf2 Be4 39. Ke3\nd5 40. c4 Kf6 41. b4 Kf5 42. c5 bxc5 43. bxc5 a5 44. a3 a4 45. c6 Bc2 46. Kd2\nBb3 47. Ke3 Bc4 48. Kf3 Bb5 49. Ke3 Bxc6 50. Kf3 Bb5 51. Ke3 Bc4 52. Kf3 c6\n53. Ke3 Kg4 54. Kd2 Kxf4 55. Kc3 Ke4 56. Kb4 Kxd4 57. Kxa4 Kc5 58. Ka5 d4\n59. a4 Bb3 60. Ka6 Bxa4 61. Kb7 d3 62. Kc7 d2 63. Kd7 d1=Q+ 64. Kxe6 Qd5+ 65.\nKe7 Qd6+ 66. Kf7 Kd5 67. Kg7 Ke5 68. Kf7 Qe6+ 69. Kg7 Kf5 70. Kh7 Qg6+ 71.\nKh8 Qg5 72. Kh7 Kf6 73. Kh8 Qg7# d3 d2 d1=Q",
          "aggressive_tokens": {
            "prompt_tokens": 279,
            "completion_tokens": 452,
            "total_tokens": 731,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd7",
            "g6",
            "Be8",
            "Qg5+",
            "Kc8",
            "Rh6",
            "b6",
            "Rdh1",
            "Kb7",
            "f4",
            "Bc6",
            "Rh7",
            "Rf5",
            "Qe7",
            "Rc8",
            "g7",
            "Rf7",
            "Qg5",
            "Be4",
            "Rh8",
            "Qxg7",
            "Qxg7",
            "Rxg7",
            "Rxc8",
            "Kxc8",
            "Rh2",
            "Rxg2",
            "Rxg2",
            "Bxg2",
            "Kd2",
            "Kd7",
            "Ke3",
            "Ke7",
            "Kf2",
            "Be4",
            "Ke3",
            "d5",
            "c4",
            "Kf6",
            "b4",
            "Kf5",
            "c5",
            "bxc5",
            "bxc5",
            "a5",
            "a3",
            "a4",
            "c6",
            "Bc2",
            "Kd2",
            "Bb3",
            "Ke3",
            "Bc4",
            "Kf3",
            "Bb5",
            "Ke3",
            "Bxc6",
            "Kf3",
            "Bb5",
            "Ke3",
            "Bc4",
            "Kf3",
            "c6",
            "Ke3",
            "Kg4",
            "Kd2",
            "Kxf4",
            "Kc3",
            "Ke4",
            "Kb4",
            "Kxd4",
            "Kxa4",
            "Kc5",
            "Ka5",
            "d4",
            "a4",
            "Bb3",
            "Ka6",
            "Bxa4",
            "Kb7",
            "d3",
            "Kc7",
            "d2",
            "Kd7",
            "d1=Q+",
            "Kxe6",
            "Qd5+",
            "Ke7",
            "Qd6+",
            "Kf7",
            "Kd5",
            "Kg7",
            "Ke5",
            "Kf7",
            "Qe6+",
            "Kg7",
            "Kf5",
            "Kh7",
            "Qg6+",
            "Kh8",
            "Qg5",
            "Kh7",
            "Kf6",
            "Kh8",
            "Qg7#",
            "d3",
            "d2",
            "d1=Q"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 22. Qh5 Bd7 23. g6 Ke7 24. Qg5+ Kf8 25. Qf6+ Qf7 26. Qxf7#",
          "positional_tokens": {
            "prompt_tokens": 279,
            "completion_tokens": 44,
            "total_tokens": 323,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qh5",
            "Bd7",
            "g6",
            "Ke7",
            "Qg5+",
            "Kf8",
            "Qf6+",
            "Qf7",
            "Qxf7#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Qf7 Qg6",
          "neutral_tokens": {
            "prompt_tokens": 278,
            "completion_tokens": 8,
            "total_tokens": 286,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qf7",
            "Qg6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e2h5",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "e2h5",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd7",
              "g6",
              "Be8",
              "Qg5+",
              "Kc8",
              "Rh6",
              "b6",
              "Rdh1",
              "Kb7",
              "f4",
              "Bc6",
              "Rh7",
              "Rf5",
              "Qe7",
              "Rc8",
              "g7",
              "Rf7",
              "Qg5",
              "Be4",
              "Rh8",
              "Qxg7",
              "Qxg7",
              "Rxg7",
              "Rxc8",
              "Kxc8",
              "Rh2",
              "Rxg2",
              "Rxg2",
              "Bxg2",
              "Kd2",
              "Kd7",
              "Ke3",
              "Ke7",
              "Kf2",
              "Be4",
              "Ke3",
              "d5",
              "c4",
              "Kf6",
              "b4",
              "Kf5",
              "c5",
              "bxc5",
              "bxc5",
              "a5",
              "a3",
              "a4",
              "c6",
              "Bc2",
              "Kd2",
              "Bb3",
              "Ke3",
              "Bc4",
              "Kf3",
              "Bb5",
              "Ke3",
              "Bxc6",
              "Kf3",
              "Bb5",
              "Ke3",
              "Bc4",
              "Kf3",
              "c6",
              "Ke3",
              "Kg4",
              "Kd2",
              "Kxf4",
              "Kc3",
              "Ke4",
              "Kb4",
              "Kxd4",
              "Kxa4",
              "Kc5",
              "Ka5",
              "d4",
              "a4",
              "Bb3",
              "Ka6",
              "Bxa4",
              "Kb7",
              "d3",
              "Kc7",
              "d2",
              "Kd7",
              "d1=Q+",
              "Kxe6",
              "Qd5+",
              "Ke7",
              "Qd6+",
              "Kf7",
              "Kd5",
              "Kg7",
              "Ke5",
              "Kf7",
              "Qe6+",
              "Kg7",
              "Kf5",
              "Kh7",
              "Qg6+",
              "Kh8",
              "Qg5",
              "Kh7",
              "Kf6",
              "Kh8",
              "Qg7#",
              "d3",
              "d2",
              "d1=Q"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Qh5",
              "Bd7",
              "g6",
              "Ke7",
              "Qg5+",
              "Kf8",
              "Qf6+",
              "Qf7",
              "Qxf7#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qf7",
              "Qg6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 279,
            "completion_tokens": 452,
            "total_tokens": 731,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 279,
            "completion_tokens": 44,
            "total_tokens": 323,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 278,
            "completion_tokens": 8,
            "total_tokens": 286,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 836,
          "total_completion_tokens": 504,
          "total_tokens": 1340
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 279,
            "completion_tokens": 452,
            "total_tokens": 731,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 279,
            "completion_tokens": 44,
            "total_tokens": 323,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 40,
            "turn_number": 21,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 278,
            "completion_tokens": 8,
            "total_tokens": 286,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk1rq1/ppp5/3pp3/6P1/3P4/2P5/PP2QPP1/2KR3R w - - 2 21"
    },
    {
      "turn": 43,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh4",
          "aggressive_uci": "h5h4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Kd7 23. Qe4 Rb8 24. Rh7+ Rf7 25. g6 Rxh7 26. gxh7 Qh8 27. Rh1 Bb7 28. Qg6 Rf8 29. Rh6 Bd5 30. b3 b5 31. f3 a5 32. Kd2 a4 33. bxa4 bxa4 34. a3 Bb3 35. Ke3 Bd5 36. Kd3 Bb3 37. c4 Re8 38. Qf7+ Re7 39. Qg8 Re8 40. Qf7+ Re7 41. Qg8 Re8 42. Qf7+ Re7 43. Qg8 Re8 44. Qf7+ Re7 45. Qg8 Re8 46. Qf7+ Re7 47. Qg8 Re8 48. Qf7+ Re7 49. Qg8 Re8 50. Qf7+ Re7 51. Qg8 Re8 52. Qf7+ Re7 53. Qg8 Re8 54. Qf7+ Re7 55. Qg8 Re8 56. Qf7+ Re7 57. Qg8 Re8 58. Qf7+ Re7 59. Qg8 Re8 60. Qf7+ Re7 61. Qg8 Re8 62. Qf7+ Re7 63. Qg8 Re8 64. Qf7+ Re7 65. Qg8 Re8 66. Qf7+ Re7 67. Qg8 Re8 68. Qf7+ Re7 69. Qg8 Re8 70. Qf7+ Re7 71. Qg8 Re8 72. Qf7+ Re7 73. Qg8 Re8 74. Qf7+ Re7 75. Qg8 Re8 76. Qf7+ Re7",
          "aggressive_tokens": {
            "prompt_tokens": 287,
            "completion_tokens": 640,
            "total_tokens": 927,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kd7",
            "Qe4",
            "Rb8",
            "Rh7+",
            "Rf7",
            "g6",
            "Rxh7",
            "gxh7",
            "Qh8",
            "Rh1",
            "Bb7",
            "Qg6",
            "Rf8",
            "Rh6",
            "Bd5",
            "b3",
            "b5",
            "f3",
            "a5",
            "Kd2",
            "a4",
            "bxa4",
            "bxa4",
            "a3",
            "Bb3",
            "Ke3",
            "Bd5",
            "Kd3",
            "Bb3",
            "c4",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7",
            "Qg8",
            "Re8",
            "Qf7+",
            "Re7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g6",
          "positional_uci": "g5g6",
          "positional_response": "22. g6 Bb7 23. Qg5+ Kd7 24. Rh7+ Kc8 25. Qe7 Qxh7 26. gxh7 Rh8 27. Qg7\nRxh7 28. Qxh7 Bxg2 29. Rg1 Bd5 30. Rg8+ Kb7 31. Rxa8 Kxa8 32. Qxc7 Bxa2 33.\nQc8#",
          "positional_tokens": {
            "prompt_tokens": 287,
            "completion_tokens": 108,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb7",
            "Qg5+",
            "Kd7",
            "Rh7+",
            "Kc8",
            "Qe7",
            "Qxh7",
            "gxh7",
            "Rh8",
            "Qg7",
            "Rxh7",
            "Qxh7",
            "Bxg2",
            "Rg1",
            "Bd5",
            "Rg8+",
            "Kb7",
            "Rxa8",
            "Kxa8",
            "Qxc7",
            "Bxa2",
            "Qc8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh4",
          "neutral_uci": "h5h4",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Kd7 23. Qe4 Rb8 24. Rh7+ Rf7 25. g6 Rxh7 26. gxh7 Qh8 27. Rh1 Bb7 28. Qg6 Re8 29. Rh6 Bd5 30. b3 b5 31. g4 Rf8 32. g5 Rxf2 33. Qg8 Rf8 34. Qxh8 Rxh8 35. g6 Be4 36. g7 Rxh7 37. Rxh7 Bxh7 38. Kd2 Ke7 39. Ke3 Kf7 40. Kf4 Kxg7 41. Kg5 Bb1 42. a3 Ba2 43. b4 Kf7 44. Kf4 Kf6 45. Ke4 Bb1+ 46. Kf4 e5+ 47. dxe5+ dxe5+ 48. Ke3 Kf5 49. Kf3 e4+ 50. Ke3 Ke5 51. Kd2 Kf4 52. Ke2 e3 53. Ke1 Kf3 54. Kf1 e2+ 55. Ke1 Ke3 56. c4 bxc4 57. b5 c3 58. b6 c2 59. bxc7 c1=Q# 0-1",
          "neutral_tokens": {
            "prompt_tokens": 286,
            "completion_tokens": 500,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kd7",
            "Qe4",
            "Rb8",
            "Rh7+",
            "Rf7",
            "g6",
            "Rxh7",
            "gxh7",
            "Qh8",
            "Rh1",
            "Bb7",
            "Qg6",
            "Re8",
            "Rh6",
            "Bd5",
            "b3",
            "b5",
            "g4",
            "Rf8",
            "g5",
            "Rxf2",
            "Qg8",
            "Rf8",
            "Qxh8",
            "Rxh8",
            "g6",
            "Be4",
            "g7",
            "Rxh7",
            "Rxh7",
            "Bxh7",
            "Kd2",
            "Ke7",
            "Ke3",
            "Kf7",
            "Kf4",
            "Kxg7",
            "Kg5",
            "Bb1",
            "a3",
            "Ba2",
            "b4",
            "Kf7",
            "Kf4",
            "Kf6",
            "Ke4",
            "Bb1+",
            "Kf4",
            "e5+",
            "dxe5+",
            "dxe5+",
            "Ke3",
            "Kf5",
            "Kf3",
            "e4+",
            "Ke3",
            "Ke5",
            "Kd2",
            "Kf4",
            "Ke2",
            "e3",
            "Ke1",
            "Kf3",
            "Kf1",
            "e2+",
            "Ke1",
            "Ke3",
            "c4",
            "bxc4",
            "b5",
            "c3",
            "b6",
            "c2",
            "bxc7",
            "c1=Q#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h5h4",
          "positional_uci": "g5g6",
          "neutral_uci": "h5h4",
          "consensus_move": "h5h4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kd7",
              "Qe4",
              "Rb8",
              "Rh7+",
              "Rf7",
              "g6",
              "Rxh7",
              "gxh7",
              "Qh8",
              "Rh1",
              "Bb7",
              "Qg6",
              "Rf8",
              "Rh6",
              "Bd5",
              "b3",
              "b5",
              "f3",
              "a5",
              "Kd2",
              "a4",
              "bxa4",
              "bxa4",
              "a3",
              "Bb3",
              "Ke3",
              "Bd5",
              "Kd3",
              "Bb3",
              "c4",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7",
              "Qg8",
              "Re8",
              "Qf7+",
              "Re7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "Qg5+",
              "Kd7",
              "Rh7+",
              "Kc8",
              "Qe7",
              "Qxh7",
              "gxh7",
              "Rh8",
              "Qg7",
              "Rxh7",
              "Qxh7",
              "Bxg2",
              "Rg1",
              "Bd5",
              "Rg8+",
              "Kb7",
              "Rxa8",
              "Kxa8",
              "Qxc7",
              "Bxa2",
              "Qc8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kd7",
              "Qe4",
              "Rb8",
              "Rh7+",
              "Rf7",
              "g6",
              "Rxh7",
              "gxh7",
              "Qh8",
              "Rh1",
              "Bb7",
              "Qg6",
              "Re8",
              "Rh6",
              "Bd5",
              "b3",
              "b5",
              "g4",
              "Rf8",
              "g5",
              "Rxf2",
              "Qg8",
              "Rf8",
              "Qxh8",
              "Rxh8",
              "g6",
              "Be4",
              "g7",
              "Rxh7",
              "Rxh7",
              "Bxh7",
              "Kd2",
              "Ke7",
              "Ke3",
              "Kf7",
              "Kf4",
              "Kxg7",
              "Kg5",
              "Bb1",
              "a3",
              "Ba2",
              "b4",
              "Kf7",
              "Kf4",
              "Kf6",
              "Ke4",
              "Bb1+",
              "Kf4",
              "e5+",
              "dxe5+",
              "dxe5+",
              "Ke3",
              "Kf5",
              "Kf3",
              "e4+",
              "Ke3",
              "Ke5",
              "Kd2",
              "Kf4",
              "Ke2",
              "e3",
              "Ke1",
              "Kf3",
              "Kf1",
              "e2+",
              "Ke1",
              "Ke3",
              "c4",
              "bxc4",
              "b5",
              "c3",
              "b6",
              "c2",
              "bxc7",
              "c1=Q#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 287,
            "completion_tokens": 640,
            "total_tokens": 927,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 287,
            "completion_tokens": 108,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 286,
            "completion_tokens": 500,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 860,
          "total_completion_tokens": 1248,
          "total_tokens": 2108
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 287,
            "completion_tokens": 640,
            "total_tokens": 927,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 287,
            "completion_tokens": 108,
            "total_tokens": 395,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 42,
            "turn_number": 22,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 286,
            "completion_tokens": 500,
            "total_tokens": 786,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r1bk1rq1/p1p5/1p1pp3/6PQ/3P4/2P5/PP3PP1/2KR3R w - - 0 22"
    },
    {
      "turn": 45,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh6",
          "aggressive_uci": "h4h6",
          "aggressive_response": "23. Qh6 Qxh6 24. Rxh6 Ke7 25. Rh7+ Rf7 26. Rdh1 Bb7 27. g6 Rxh7 28. Rxh7+ Kf6\n29. Rxc7 Bxg2 30. g7 a5 31. Kd2 Rg8 32. Rd7 d5 33. Rb7 Rxg7 34. Rxb6 Bf1 35.\nb3 Rg2 36. Ke3 Rh2 37. Rb8 Rh3+ 38. Kd2 Rd3+ 39. Kc2 Rf3 40. Ra8 Rxf2+ 41. Kb1\nBd3+ 42. Ka1 Rc2 43. Rxa5 Rxc3 44. Kb2 Rc2+ 45. Ka3 Kf5 46. Ra8 Ke4 47. Re8 Rc6\n48. Kb4 Kxd4 49. a4 e5 50. a5 e4 51. Ka4 e3 52. b4 e2 53. b5 Rc4+ 54. Kb3 Be4\n55. b6 e1=Q 56. b7 Qb4+ 57. Ka2 Rc2+ 58. Ka1 Qb2# e4 d5 d4",
          "aggressive_tokens": {
            "prompt_tokens": 296,
            "completion_tokens": 304,
            "total_tokens": 600,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh6",
            "Rxh6",
            "Ke7",
            "Rh7+",
            "Rf7",
            "Rdh1",
            "Bb7",
            "g6",
            "Rxh7",
            "Rxh7+",
            "Kf6",
            "Rxc7",
            "Bxg2",
            "g7",
            "a5",
            "Kd2",
            "Rg8",
            "Rd7",
            "d5",
            "Rb7",
            "Rxg7",
            "Rxb6",
            "Bf1",
            "b3",
            "Rg2",
            "Ke3",
            "Rh2",
            "Rb8",
            "Rh3+",
            "Kd2",
            "Rd3+",
            "Kc2",
            "Rf3",
            "Ra8",
            "Rxf2+",
            "Kb1",
            "Bd3+",
            "Ka1",
            "Rc2",
            "Rxa5",
            "Rxc3",
            "Kb2",
            "Rc2+",
            "Ka3",
            "Kf5",
            "Ra8",
            "Ke4",
            "Re8",
            "Rc6",
            "Kb4",
            "Kxd4",
            "a4",
            "e5",
            "a5",
            "e4",
            "Ka4",
            "e3",
            "b4",
            "e2",
            "b5",
            "Rc4+",
            "Kb3",
            "Be4",
            "b6",
            "e1=Q",
            "b7",
            "Qb4+",
            "Ka2",
            "Rc2+",
            "Ka1",
            "Qb2#",
            "e4",
            "d5",
            "d4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "f4",
          "positional_uci": "f2f4",
          "positional_response": "23. f4 Bb7 24. Rh2 Kd7 25. g4 Rh8 26. Qg3 Rxh2 27. Qxh2 Qg7 28. Qg3 Rh8 29.\nRf1 Rh1 30. Rxh1 Bxh1 31. f5 exf5 32. gxf5 Be4 33. f6 Qg6 34. Qg4+ Bf5 35. Qg3\nBe6 36. Qf4 Bf7 37. Qg4+ Kd8 38. Qg2 Qf5 39. Qa8+ Kd7 40. Qg2 Qf4+ 41. Kc2\nBg6+ 42. Kb3 Qe4 43. Qh3+ Qe6+ 44. Qxe6+ Kxe6 45. c4 Kf5 46. Kb4 Kxg5 47. Kb5\nBe8+ 48. Ka6 Kxf6 49. Kxa7 Ke7 50. Kb7 Kd7 51. b4 Bf7 52. c5 dxc5 53. dxc5 bxc5\n54. bxc5 Bxa2 55. c6+ Kd6 56. Ka6 Kxc6 57. Ka5 Kc5 58. Ka4 Kc4 59. Ka3 Kc3\n60. Kxa2 c5 61. Kb1 c4 62. Kc1 Kd3 63. Kd1 c3 64. Kc1 c2 65. Kb2 Kd2 66. Kb3\nc1=Q 67. Kb4 Qc6 68. Kb3 Qc5 69. Kb2 Qc4 70. Kb1 Qb3+ 71. Ka1 Qb4 72. Ka2 Kc2\n73. Ka1 Qb2# d4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh4 b6 Qh4 Qg6 f4 Bb7 Rh2 Kd7 g4 Rh8 Qg3 Rxh2 Qxh2 Qg7 Qg3 Rh8 Rf1 Rh1 Rxh1 Bxh1 f5 exf5 gxf5 Be4 f6 Qg6 Qg4+ Bf5 Qg3 Bb1 Qg2 Qf5 Qg7",
          "positional_tokens": {
            "prompt_tokens": 296,
            "completion_tokens": 640,
            "total_tokens": 936,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bb7",
            "Rh2",
            "Kd7",
            "g4",
            "Rh8",
            "Qg3",
            "Rxh2",
            "Qxh2",
            "Qg7",
            "Qg3",
            "Rh8",
            "Rf1",
            "Rh1",
            "Rxh1",
            "Bxh1",
            "f5",
            "exf5",
            "gxf5",
            "Be4",
            "f6",
            "Qg6",
            "Qg4+",
            "Bf5",
            "Qg3",
            "Bb1",
            "Qg2",
            "Qf5",
            "Qg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Qh6",
          "neutral_uci": "h4h6",
          "neutral_response": "Re1 Re8 24. Rxe8+ Kxe8 25. Qh8+ Kd7 26. Rh7+\nKc6 27. Qg7 Qxg7 28. Rxg7 Bd7 29. Kd2 Rf8 30. Ke3 e5 31. dxe5 dxe5 32. f3 Kd6\n33. g4 Bc6 34. Rg6+ Kd7 35. Rf6 Rxf6 36. gxf6 Ke6 37. g5 Kf5 38. f7 Kxg5 39.\nf8=Q * Bb7 Bc6 41. Qe7+ Kf5 42. Qxc7 Bd5 43. Qxa7 b5 44. Qc5 Bxa2 45. Qxb5\nBe6 46. f4 Kf6 47. Qxe5+ Kf7 48. f5 Bd7 49. f6 Be6 50. Kf4 Bb3 51. Kg5 Be6\n52. Qc7+ Kf8 53. Qe7+ Kg8 54. Qg7# Bf7 56. Kh6 *\n\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Bb7 25. f3 Ke7 26. Rh3\nRh8 27. Rdh1 Rag8 28. R1h2 Rg6 29. Kd2 e5 30. dxe5 dxe5 31. Ke3 Kf6 32. g4\nBc6 33. Rh5 Bd7 34. R2h4 Be6 35. b3 c5 36. c4 a6 37. Ke4 Rg5 38. Rxg5 Kxg5\n39. Rh5+ Kf6 40. g5+ Kg6 41. Rh2 Bf5+ 42. Kxe5 Kxg5 43. f4+",
          "neutral_tokens": {
            "prompt_tokens": 295,
            "completion_tokens": 640,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Qxh6",
            "gxh6",
            "Bb7",
            "f3",
            "Ke7",
            "Rh3",
            "Rh8",
            "Rdh1",
            "Rag8",
            "R1h2",
            "Rg6",
            "Kd2",
            "e5",
            "dxe5",
            "dxe5",
            "Ke3",
            "Kf6",
            "g4",
            "Bc6",
            "Rh5",
            "Bd7",
            "R2h4",
            "Be6",
            "b3",
            "c5",
            "c4",
            "a6",
            "Ke4",
            "Rg5",
            "Rxg5",
            "Kxg5",
            "Rh5+",
            "Kf6",
            "g5+",
            "Kg6",
            "Rh2",
            "Bf5+",
            "Kxe5",
            "Kxg5",
            "f4+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4h6",
          "positional_uci": "f2f4",
          "neutral_uci": "h4h6",
          "consensus_move": "h4h6",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxh6",
              "Rxh6",
              "Ke7",
              "Rh7+",
              "Rf7",
              "Rdh1",
              "Bb7",
              "g6",
              "Rxh7",
              "Rxh7+",
              "Kf6",
              "Rxc7",
              "Bxg2",
              "g7",
              "a5",
              "Kd2",
              "Rg8",
              "Rd7",
              "d5",
              "Rb7",
              "Rxg7",
              "Rxb6",
              "Bf1",
              "b3",
              "Rg2",
              "Ke3",
              "Rh2",
              "Rb8",
              "Rh3+",
              "Kd2",
              "Rd3+",
              "Kc2",
              "Rf3",
              "Ra8",
              "Rxf2+",
              "Kb1",
              "Bd3+",
              "Ka1",
              "Rc2",
              "Rxa5",
              "Rxc3",
              "Kb2",
              "Rc2+",
              "Ka3",
              "Kf5",
              "Ra8",
              "Ke4",
              "Re8",
              "Rc6",
              "Kb4",
              "Kxd4",
              "a4",
              "e5",
              "a5",
              "e4",
              "Ka4",
              "e3",
              "b4",
              "e2",
              "b5",
              "Rc4+",
              "Kb3",
              "Be4",
              "b6",
              "e1=Q",
              "b7",
              "Qb4+",
              "Ka2",
              "Rc2+",
              "Ka1",
              "Qb2#",
              "e4",
              "d5",
              "d4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bb7",
              "Rh2",
              "Kd7",
              "g4",
              "Rh8",
              "Qg3",
              "Rxh2",
              "Qxh2",
              "Qg7",
              "Qg3",
              "Rh8",
              "Rf1",
              "Rh1",
              "Rxh1",
              "Bxh1",
              "f5",
              "exf5",
              "gxf5",
              "Be4",
              "f6",
              "Qg6",
              "Qg4+",
              "Bf5",
              "Qg3",
              "Bb1",
              "Qg2",
              "Qf5",
              "Qg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Qxh6",
              "gxh6",
              "Bb7",
              "f3",
              "Ke7",
              "Rh3",
              "Rh8",
              "Rdh1",
              "Rag8",
              "R1h2",
              "Rg6",
              "Kd2",
              "e5",
              "dxe5",
              "dxe5",
              "Ke3",
              "Kf6",
              "g4",
              "Bc6",
              "Rh5",
              "Bd7",
              "R2h4",
              "Be6",
              "b3",
              "c5",
              "c4",
              "a6",
              "Ke4",
              "Rg5",
              "Rxg5",
              "Kxg5",
              "Rh5+",
              "Kf6",
              "g5+",
              "Kg6",
              "Rh2",
              "Bf5+",
              "Kxe5",
              "Kxg5",
              "f4+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 296,
            "completion_tokens": 304,
            "total_tokens": 600,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 296,
            "completion_tokens": 640,
            "total_tokens": 936,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 295,
            "completion_tokens": 640,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 887,
          "total_completion_tokens": 1584,
          "total_tokens": 2471
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 296,
            "completion_tokens": 304,
            "total_tokens": 600,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 296,
            "completion_tokens": 640,
            "total_tokens": 936,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 44,
            "turn_number": 23,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 295,
            "completion_tokens": 640,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk1r2/p1p5/1p1pp1q1/6P1/3P3Q/2P5/PP3PP1/2KR3R w - - 2 23"
    },
    {
      "turn": 47,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "gxh6",
          "aggressive_uci": "g5h6",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Bb7 25. Rh2 Ke7 26. g4\nRf4 27. g5 Be4 28. Re1 d5 29. Kd2 Rg8 30. Rg1 Bh7 31. Ke3 Rf5 32. f4 c5 33.\ndxc5 bxc5 34. b4 cxb4 35. cxb4 e5 36. fxe5 Rxe5+ 37. Kd4 Rexg5 38. Rxg5 Rxg5\n39. a4 Kd6 40. Rh4 Rg1 41. Kc3 Rg3+ 42. Kd2 Ra3 43. a5 Ke5 44. Rh5+ Kd4 45.\nRh4+ Be4 46. h7 Ra2+ 47. Kc1 Kc3 48. Rh3+ Bd3 49. Rxd3+ Kxd3 50. h8=Q Rc2+\n51. Kb1 Rc4 52. Qh3+ Kd4 53. Qg4+ Kc3 54. Qf3+ Kxb4 55. Qxd5 Rc5 56. Qd4+\nRc4 57. Qxa7 Kb5 58. Qb6+ Ka4 59. a6 Rb4+ 60. Qxb4+ Kxb4 61. a7 Kc5 62. a8=Q\nKd6 63. Qa5 Ke6 64. Kc2 Kd6 65. Kd3 Ke6 66. Ke4 Kd6 67. Qb6+ Kd7 68. Ke5 Ke7\n69. Qc7+ Kf8 70. Kf6 Kg8 71. Qg7# Qd8 72. Qg7# Qd8 73. Qg7#",
          "aggressive_tokens": {
            "prompt_tokens": 306,
            "completion_tokens": 629,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bb7",
            "Rh2",
            "Ke7",
            "g4",
            "Rf4",
            "g5",
            "Be4",
            "Re1",
            "d5",
            "Kd2",
            "Rg8",
            "Rg1",
            "Bh7",
            "Ke3",
            "Rf5",
            "f4",
            "c5",
            "dxc5",
            "bxc5",
            "b4",
            "cxb4",
            "cxb4",
            "e5",
            "fxe5",
            "Rxe5+",
            "Kd4",
            "Rexg5",
            "Rxg5",
            "Rxg5",
            "a4",
            "Kd6",
            "Rh4",
            "Rg1",
            "Kc3",
            "Rg3+",
            "Kd2",
            "Ra3",
            "a5",
            "Ke5",
            "Rh5+",
            "Kd4",
            "Rh4+",
            "Be4",
            "h7",
            "Ra2+",
            "Kc1",
            "Kc3",
            "Rh3+",
            "Bd3",
            "Rxd3+",
            "Kxd3",
            "h8=Q",
            "Rc2+",
            "Kb1",
            "Rc4",
            "Qh3+",
            "Kd4",
            "Qg4+",
            "Kc3",
            "Qf3+",
            "Kxb4",
            "Qxd5",
            "Rc5",
            "Qd4+",
            "Rc4",
            "Qxa7",
            "Kb5",
            "Qb6+",
            "Ka4",
            "a6",
            "Rb4+",
            "Qxb4+",
            "Kxb4",
            "a7",
            "Kc5",
            "a8=Q",
            "Kd6",
            "Qa5",
            "Ke6",
            "Kc2",
            "Kd6",
            "Kd3",
            "Ke6",
            "Ke4",
            "Kd6",
            "Qb6+",
            "Kd7",
            "Ke5",
            "Ke7",
            "Qc7+",
            "Kf8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "Qd8",
            "Qg7#",
            "Qd8",
            "Qg7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "gxh6",
          "positional_uci": "g5h6",
          "positional_response": "24. gxh6 Ke7 25. g4 Bb7 26. Rh2 Rf4 27. g5 Be4 28. Rg1 Bg6 29. Kd2 Raf8 30. Ke1\nRf3 31. Rg3 Rxg3 32. fxg3 Rf3 33. Rh3 Kf7 34. Ke2 Rf5 35. g4 Rxg5 36. Kf3 Kg8\n37. Kf4 Ra5 38. a3 Kh7 39. g5 Rf5+ 40. Kg4 Rf2 41. Re3 Bf5+ 42. Kh5 Rh2+ 43. Rh3\nRxh3#",
          "positional_tokens": {
            "prompt_tokens": 306,
            "completion_tokens": 166,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "g4",
            "Bb7",
            "Rh2",
            "Rf4",
            "g5",
            "Be4",
            "Rg1",
            "Bg6",
            "Kd2",
            "Raf8",
            "Ke1",
            "Rf3",
            "Rg3",
            "Rxg3",
            "fxg3",
            "Rf3",
            "Rh3",
            "Kf7",
            "Ke2",
            "Rf5",
            "g4",
            "Rxg5",
            "Kf3",
            "Kg8",
            "Kf4",
            "Ra5",
            "a3",
            "Kh7",
            "g5",
            "Rf5+",
            "Kg4",
            "Rf2",
            "Re3",
            "Bf5+",
            "Kh5",
            "Rh2+",
            "Rh3",
            "Rxh3#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxh6",
          "neutral_uci": "h1h6",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. Rxh6 Ke7 25. Rh7+ Rf7 26. Rdh1\nBb7 27. g6 Rxh7 28. Rxh7+ Kf6 29. Rxc7 Bxg2 30. g7 Rg8 31. Rxa7 Rxg7 32. Ra6\nRb7 33. Kd2 Kf5 34. Ke3 Bf1 35. Ra8 e5 36. Rf8+ Ke6 37. Re8+ Kd5 38. dxe5 dxe5\n39. Rd8+ Ke6 40. Re8+ Re7 41. Rb8 b5 42. Rb6+ Kf5 43. Rh6 Rd7 44. Rh5+ Kf6 45.\nRh6+ Kg5 46. Rh1 Bg2 47. Rg1 Kf5 48. Rxg2 Ra7 49. a3 Rd7 50. f3 Rd1 51. Rd2\nRe1+ 52. Kf2 Rb1 53. Ke3 Re1+ 54. Re2 Rd1 55. Rh2 Re1+ 56. Kd2 Rb1 57. Kc2\nRf1 58. Rh5+ Kf4 59. Rh4+ Kxf3 60. Rh5 Ke4 61. Rh4+ Kd5 62. Rh5 Rf2+ 63. Kb3\nRf3 64. Kb4 Rf2 65. b3 Rf4+ 66. Kxb5 Rf3 67. c4+ Kd4 68. Rh4+ e4 69. Kb4 Rf8\n70. c5 Rb8+ 71. Ka4 Kd3 72. b4 e3 73. Rh3 Kd2 74. Rxe3 Kxe3 75. c6 Kd4 76",
          "neutral_tokens": {
            "prompt_tokens": 305,
            "completion_tokens": 640,
            "total_tokens": 945,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke7",
            "Rh7+",
            "Rf7",
            "Rdh1",
            "Bb7",
            "g6",
            "Rxh7",
            "Rxh7+",
            "Kf6",
            "Rxc7",
            "Bxg2",
            "g7",
            "Rg8",
            "Rxa7",
            "Rxg7",
            "Ra6",
            "Rb7",
            "Kd2",
            "Kf5",
            "Ke3",
            "Bf1",
            "Ra8",
            "e5",
            "Rf8+",
            "Ke6",
            "Re8+",
            "Kd5",
            "dxe5",
            "dxe5",
            "Rd8+",
            "Ke6",
            "Re8+",
            "Re7",
            "Rb8",
            "b5",
            "Rb6+",
            "Kf5",
            "Rh6",
            "Rd7",
            "Rh5+",
            "Kf6",
            "Rh6+",
            "Kg5",
            "Rh1",
            "Bg2",
            "Rg1",
            "Kf5",
            "Rxg2",
            "Ra7",
            "a3",
            "Rd7",
            "f3",
            "Rd1",
            "Rd2",
            "Re1+",
            "Kf2",
            "Rb1",
            "Ke3",
            "Re1+",
            "Re2",
            "Rd1",
            "Rh2",
            "Re1+",
            "Kd2",
            "Rb1",
            "Kc2",
            "Rf1",
            "Rh5+",
            "Kf4",
            "Rh4+",
            "Kxf3",
            "Rh5",
            "Ke4",
            "Rh4+",
            "Kd5",
            "Rh5",
            "Rf2+",
            "Kb3",
            "Rf3",
            "Kb4",
            "Rf2",
            "b3",
            "Rf4+",
            "Kxb5",
            "Rf3",
            "c4+",
            "Kd4",
            "Rh4+",
            "e4",
            "Kb4",
            "Rf8",
            "c5",
            "Rb8+",
            "Ka4",
            "Kd3",
            "b4",
            "e3",
            "Rh3",
            "Kd2",
            "Rxe3",
            "Kxe3",
            "c6",
            "Kd4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5h6",
          "positional_uci": "g5h6",
          "neutral_uci": "h1h6",
          "consensus_move": "g5h6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bb7",
              "Rh2",
              "Ke7",
              "g4",
              "Rf4",
              "g5",
              "Be4",
              "Re1",
              "d5",
              "Kd2",
              "Rg8",
              "Rg1",
              "Bh7",
              "Ke3",
              "Rf5",
              "f4",
              "c5",
              "dxc5",
              "bxc5",
              "b4",
              "cxb4",
              "cxb4",
              "e5",
              "fxe5",
              "Rxe5+",
              "Kd4",
              "Rexg5",
              "Rxg5",
              "Rxg5",
              "a4",
              "Kd6",
              "Rh4",
              "Rg1",
              "Kc3",
              "Rg3+",
              "Kd2",
              "Ra3",
              "a5",
              "Ke5",
              "Rh5+",
              "Kd4",
              "Rh4+",
              "Be4",
              "h7",
              "Ra2+",
              "Kc1",
              "Kc3",
              "Rh3+",
              "Bd3",
              "Rxd3+",
              "Kxd3",
              "h8=Q",
              "Rc2+",
              "Kb1",
              "Rc4",
              "Qh3+",
              "Kd4",
              "Qg4+",
              "Kc3",
              "Qf3+",
              "Kxb4",
              "Qxd5",
              "Rc5",
              "Qd4+",
              "Rc4",
              "Qxa7",
              "Kb5",
              "Qb6+",
              "Ka4",
              "a6",
              "Rb4+",
              "Qxb4+",
              "Kxb4",
              "a7",
              "Kc5",
              "a8=Q",
              "Kd6",
              "Qa5",
              "Ke6",
              "Kc2",
              "Kd6",
              "Kd3",
              "Ke6",
              "Ke4",
              "Kd6",
              "Qb6+",
              "Kd7",
              "Ke5",
              "Ke7",
              "Qc7+",
              "Kf8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "Qd8",
              "Qg7#",
              "Qd8",
              "Qg7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke7",
              "g4",
              "Bb7",
              "Rh2",
              "Rf4",
              "g5",
              "Be4",
              "Rg1",
              "Bg6",
              "Kd2",
              "Raf8",
              "Ke1",
              "Rf3",
              "Rg3",
              "Rxg3",
              "fxg3",
              "Rf3",
              "Rh3",
              "Kf7",
              "Ke2",
              "Rf5",
              "g4",
              "Rxg5",
              "Kf3",
              "Kg8",
              "Kf4",
              "Ra5",
              "a3",
              "Kh7",
              "g5",
              "Rf5+",
              "Kg4",
              "Rf2",
              "Re3",
              "Bf5+",
              "Kh5",
              "Rh2+",
              "Rh3",
              "Rxh3#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ke7",
              "Rh7+",
              "Rf7",
              "Rdh1",
              "Bb7",
              "g6",
              "Rxh7",
              "Rxh7+",
              "Kf6",
              "Rxc7",
              "Bxg2",
              "g7",
              "Rg8",
              "Rxa7",
              "Rxg7",
              "Ra6",
              "Rb7",
              "Kd2",
              "Kf5",
              "Ke3",
              "Bf1",
              "Ra8",
              "e5",
              "Rf8+",
              "Ke6",
              "Re8+",
              "Kd5",
              "dxe5",
              "dxe5",
              "Rd8+",
              "Ke6",
              "Re8+",
              "Re7",
              "Rb8",
              "b5",
              "Rb6+",
              "Kf5",
              "Rh6",
              "Rd7",
              "Rh5+",
              "Kf6",
              "Rh6+",
              "Kg5",
              "Rh1",
              "Bg2",
              "Rg1",
              "Kf5",
              "Rxg2",
              "Ra7",
              "a3",
              "Rd7",
              "f3",
              "Rd1",
              "Rd2",
              "Re1+",
              "Kf2",
              "Rb1",
              "Ke3",
              "Re1+",
              "Re2",
              "Rd1",
              "Rh2",
              "Re1+",
              "Kd2",
              "Rb1",
              "Kc2",
              "Rf1",
              "Rh5+",
              "Kf4",
              "Rh4+",
              "Kxf3",
              "Rh5",
              "Ke4",
              "Rh4+",
              "Kd5",
              "Rh5",
              "Rf2+",
              "Kb3",
              "Rf3",
              "Kb4",
              "Rf2",
              "b3",
              "Rf4+",
              "Kxb5",
              "Rf3",
              "c4+",
              "Kd4",
              "Rh4+",
              "e4",
              "Kb4",
              "Rf8",
              "c5",
              "Rb8+",
              "Ka4",
              "Kd3",
              "b4",
              "e3",
              "Rh3",
              "Kd2",
              "Rxe3",
              "Kxe3",
              "c6",
              "Kd4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 306,
            "completion_tokens": 629,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 306,
            "completion_tokens": 166,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 305,
            "completion_tokens": 640,
            "total_tokens": 945,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 917,
          "total_completion_tokens": 1435,
          "total_tokens": 2352
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 306,
            "completion_tokens": 629,
            "total_tokens": 935,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 306,
            "completion_tokens": 166,
            "total_tokens": 472,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 46,
            "turn_number": 24,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 305,
            "completion_tokens": 640,
            "total_tokens": 945,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk1r2/p1p5/1p1pp2q/6P1/3P4/2P5/PP3PP1/2KR3R w - - 0 24"
    },
    {
      "turn": 49,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf6",
          "aggressive_uci": null,
          "aggressive_response": "Re1 Re7 Rxe7 Kxe7 Kd2\nKf6 Ke3 Kg5 f4+ Kxh6 Kf4 Kg7 g4 Kf7 g5 Kg7 Kg4 Kf7 f5 Kg7 f6+ Kf7 Kf5 Kg8 g6 Kf8 Ke6 Kg8 Ke7 Kh8 f7 Kg7 f8=Q+ Kxf8 Kf6 Kg8 g7 Kh7 Kf7 Kh6 g8=Q Kh5 Qg3 Kh6 Qg6# Kg5 Qg5# Kg6 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8 Qg6# Kg7 Qg5# Kg8",
          "aggressive_tokens": {
            "prompt_tokens": 314,
            "completion_tokens": 640,
            "total_tokens": 954,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg8",
            "g7",
            "Kh7",
            "Kf7",
            "Kh6",
            "g8=Q",
            "Kh5",
            "Qg3",
            "Kh6",
            "Qg6#",
            "Kg5",
            "Qg5#",
            "Kg6",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8",
            "Qg6#",
            "Kg7",
            "Qg5#",
            "Kg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g4",
          "positional_uci": "g2g4",
          "positional_response": "25. g4 Ke7 26. g5 Kf7 27. Rdg1 Kg6",
          "positional_tokens": {
            "prompt_tokens": 314,
            "completion_tokens": 23,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "g5",
            "Kf7",
            "Rdg1",
            "Kg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kf2",
          "neutral_uci": null,
          "neutral_response": "Re1 Re7 Rxe7 Kxe7 Kd2\nKf6 Ke3 Kg5 Kf3 Rxh6 Rxh6 Rxh6 g4+ Kg6 Kg3 Rh1 f4 Rb1 b3 Rxb2 f5+ Kf6 Kf4 Rxa2\ng5+ Kf7 Ke5 Re2+ Kf4 a5 g6+ Kf6 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2\nRe4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4\nKf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1 Kf2 Re4 Kf3 Re1\nKf2 Re4 Kf3 Re1 Kf2 Re4 K",
          "neutral_tokens": {
            "prompt_tokens": 313,
            "completion_tokens": 640,
            "total_tokens": 953,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Re4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g2g4",
          "neutral_uci": null,
          "consensus_move": "g2g4",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg8",
              "g7",
              "Kh7",
              "Kf7",
              "Kh6",
              "g8=Q",
              "Kh5",
              "Qg3",
              "Kh6",
              "Qg6#",
              "Kg5",
              "Qg5#",
              "Kg6",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8",
              "Qg6#",
              "Kg7",
              "Qg5#",
              "Kg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke7",
              "g5",
              "Kf7",
              "Rdg1",
              "Kg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Re4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 314,
            "completion_tokens": 640,
            "total_tokens": 954,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 314,
            "completion_tokens": 23,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 313,
            "completion_tokens": 640,
            "total_tokens": 953,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 941,
          "total_completion_tokens": 1303,
          "total_tokens": 2244
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 314,
            "completion_tokens": 640,
            "total_tokens": 954,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 314,
            "completion_tokens": 23,
            "total_tokens": 337,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 48,
            "turn_number": 25,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 313,
            "completion_tokens": 640,
            "total_tokens": 953,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r1bk3r/p1p5/1p1pp2P/8/3P4/2P5/PP3PP1/2KR3R w - - 1 25"
    },
    {
      "turn": 51,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rh5",
          "aggressive_uci": "h1h5",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke7 27. g5 Rag8 28. f4 Bf3 29. Rh4 Bxd1 30. Kxd1 Kf7 31. Ke2 Kg6 32. Kf3 Rf8 33. Kg4 Rf5 34. Rh2 e5 35. dxe5 dxe5 36. fxe5 Rxg5+ 37. Kf4 Rxh6 38. Rd2 Rh4+ 39. Kf3 Rxe5 40. Rd7 Rh7 41. Rd8 Rf7+ 42. Kg4 Rg5+ 43. Kh4 Rh7# 0-1\n25... Bb7 26. Rh5 Ke7 27. g4 Rfg8",
          "aggressive_tokens": {
            "prompt_tokens": 322,
            "completion_tokens": 386,
            "total_tokens": 708,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "g4",
            "Rfg8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rh4",
          "positional_uci": "h1h4",
          "positional_response": "26. Rh4 Ke7 27. g5 Rag8 28. f4 Be4 29. Re1 d5 30. Kd2 Kf7 31. Ke3 Kg6 32. Kf2\nRh7 33. Kg3 Rf8 34. Rh2 c5 35. dxc5 bxc5 36. Rd2 Rhf7 37. Rf2 e5 38. Ref1\nexf4+ 39. Rxf4 Rxf4 40. Rxf4 Rxf4 41. Kxf4 Bb1 42. a3 a5 43. b4 cxb4 44. cxb4\naxb4 45. axb4 d4 46. b5 d3 47. Ke3 Kxg5 48. h7 d2 49. Kxd2 Bxh7 50. b6 Be4\n51. b7 Bxb7 52. *\nd5 d4 d3",
          "positional_tokens": {
            "prompt_tokens": 322,
            "completion_tokens": 221,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "g5",
            "Rag8",
            "f4",
            "Be4",
            "Re1",
            "d5",
            "Kd2",
            "Kf7",
            "Ke3",
            "Kg6",
            "Kf2",
            "Rh7",
            "Kg3",
            "Rf8",
            "Rh2",
            "c5",
            "dxc5",
            "bxc5",
            "Rd2",
            "Rhf7",
            "Rf2",
            "e5",
            "Ref1",
            "exf4+",
            "Rxf4",
            "Rxf4",
            "Rxf4",
            "Rxf4",
            "Kxf4",
            "Bb1",
            "a3",
            "a5",
            "b4",
            "cxb4",
            "cxb4",
            "axb4",
            "axb4",
            "d4",
            "b5",
            "d3",
            "Ke3",
            "Kxg5",
            "h7",
            "d2",
            "Kxd2",
            "Bxh7",
            "b6",
            "Be4",
            "b7",
            "Bxb7",
            "d5",
            "d4",
            "d3"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rh5",
          "neutral_uci": "h1h5",
          "neutral_response": "Re8\n26. Rh5 Ke7 27. g5 Kf7 28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Bf5 32. Ke3\nRh7 33. Rgh1 Rfh8 34. R1h2 Kf7 35. Rg2 Bg6 36. Rgh2 Ke7 37. Rg2 Kd7 38. Rgh2\nKc6 39. Rg2 Kd5 40. Rgh2 c5 41. dxc5 bxc5 42. Rd2+ Kc6 43. Rdh2 d5 44. R4h3\nKd6 45. Rh4 a5 46. R4h3 a4 47. Rh4 Rb8 48. Rd2 a3 49. b3 Rf8 50. Rf2 e5 51.\nfxe5+ Kxe5 52. Rxf8 d4+ 53. cxd4+ cxd4+ 54. Rxd4 Re7 55. Rf6 Bb1 56. Rd2 Bxa2\n57. Rxa2 Kd5+ 58. Kd3 Kc5 59. Rxa3 Kb4 60. Ra4+ Kxb3 61. Re4 Rd7+ 62. Ke3 Kc3\n63. Rc6+ Kb3 64. g6 Ka3 65. g7 Kb3 66. g8=Q+ Ka3 67. Ra6+ Kb2 68. Qa2+ Kc3\n69. Rc4# Kd3 70. Qc2# Kd5 71. Qe4# Kd6 72. Rc6# Kd7 73. Qe6# Kd8 74. Rc8# Kxc8\n75. Qxd7+ Kxd7 76. h7 Ke7 77. h8=Q Kf7 78. Qh7+ Kf8 79. Rg8# Kxg8 80. Qe7\nKh8 81. Kf4 Kg8 82. Kg5 Kh8 83. Kg6 Kg8 84. Qg7# Kd8 85. Qb7 Ke8 86. Qc7 Kf8\n87. Qd7 Kg8 88. Qe7 Kh8 89. Qf8# Kxh7 90. Qf7+ Kh8 91. Qg7# Kg8 92. Qf7+ Kh8\n93. Qf8# Kxh7 94. Qf7+ Kh8 95. Qf8# Kxh7 96. Qf7+ Kh8 97. Qf8# Kxh7 98.",
          "neutral_tokens": {
            "prompt_tokens": 321,
            "completion_tokens": 640,
            "total_tokens": 961,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke7",
            "g5",
            "Kf7",
            "Rg1",
            "Kg6",
            "Rh4",
            "Raf8",
            "f4",
            "Be4",
            "Kd2",
            "Bf5",
            "Ke3",
            "Rh7",
            "Rgh1",
            "Rfh8",
            "R1h2",
            "Kf7",
            "Rg2",
            "Bg6",
            "Rgh2",
            "Ke7",
            "Rg2",
            "Kd7",
            "Rgh2",
            "Kc6",
            "Rg2",
            "Kd5",
            "Rgh2",
            "c5",
            "dxc5",
            "bxc5",
            "Rd2+",
            "Kc6",
            "Rdh2",
            "d5",
            "R4h3",
            "Kd6",
            "Rh4",
            "a5",
            "R4h3",
            "a4",
            "Rh4",
            "Rb8",
            "Rd2",
            "a3",
            "b3",
            "Rf8",
            "Rf2",
            "e5",
            "fxe5+",
            "Kxe5",
            "Rxf8",
            "d4+",
            "cxd4+",
            "cxd4+",
            "Rxd4",
            "Re7",
            "Rf6",
            "Bb1",
            "Rd2",
            "Bxa2",
            "Rxa2",
            "Kd5+",
            "Kd3",
            "Kc5",
            "Rxa3",
            "Kb4",
            "Ra4+",
            "Kxb3",
            "Re4",
            "Rd7+",
            "Ke3",
            "Kc3",
            "Rc6+",
            "Kb3",
            "g6",
            "Ka3",
            "g7",
            "Kb3",
            "g8=Q+",
            "Ka3",
            "Ra6+",
            "Kb2",
            "Qa2+",
            "Kc3",
            "Rc4#",
            "Kd3",
            "Qc2#",
            "Kd5",
            "Qe4#",
            "Kd6",
            "Rc6#",
            "Kd7",
            "Qe6#",
            "Kd8",
            "Rc8#",
            "Kxc8",
            "Qxd7+",
            "Kxd7",
            "h7",
            "Ke7",
            "h8=Q",
            "Kf7",
            "Qh7+",
            "Kf8",
            "Rg8#",
            "Kxg8",
            "Qe7",
            "Kh8",
            "Kf4",
            "Kg8",
            "Kg5",
            "Kh8",
            "Kg6",
            "Kg8",
            "Qg7#",
            "Kd8",
            "Qb7",
            "Ke8",
            "Qc7",
            "Kf8",
            "Qd7",
            "Kg8",
            "Qe7",
            "Kh8",
            "Qf8#",
            "Kxh7",
            "Qf7+",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kxh7",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kxh7",
            "Qf7+",
            "Kh8",
            "Qf8#",
            "Kxh7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h1h5",
          "positional_uci": "h1h4",
          "neutral_uci": "h1h5",
          "consensus_move": "h1h5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ke7",
              "g4",
              "Rfg8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke7",
              "g5",
              "Rag8",
              "f4",
              "Be4",
              "Re1",
              "d5",
              "Kd2",
              "Kf7",
              "Ke3",
              "Kg6",
              "Kf2",
              "Rh7",
              "Kg3",
              "Rf8",
              "Rh2",
              "c5",
              "dxc5",
              "bxc5",
              "Rd2",
              "Rhf7",
              "Rf2",
              "e5",
              "Ref1",
              "exf4+",
              "Rxf4",
              "Rxf4",
              "Rxf4",
              "Rxf4",
              "Kxf4",
              "Bb1",
              "a3",
              "a5",
              "b4",
              "cxb4",
              "cxb4",
              "axb4",
              "axb4",
              "d4",
              "b5",
              "d3",
              "Ke3",
              "Kxg5",
              "h7",
              "d2",
              "Kxd2",
              "Bxh7",
              "b6",
              "Be4",
              "b7",
              "Bxb7",
              "d5",
              "d4",
              "d3"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Ke7",
              "g5",
              "Kf7",
              "Rg1",
              "Kg6",
              "Rh4",
              "Raf8",
              "f4",
              "Be4",
              "Kd2",
              "Bf5",
              "Ke3",
              "Rh7",
              "Rgh1",
              "Rfh8",
              "R1h2",
              "Kf7",
              "Rg2",
              "Bg6",
              "Rgh2",
              "Ke7",
              "Rg2",
              "Kd7",
              "Rgh2",
              "Kc6",
              "Rg2",
              "Kd5",
              "Rgh2",
              "c5",
              "dxc5",
              "bxc5",
              "Rd2+",
              "Kc6",
              "Rdh2",
              "d5",
              "R4h3",
              "Kd6",
              "Rh4",
              "a5",
              "R4h3",
              "a4",
              "Rh4",
              "Rb8",
              "Rd2",
              "a3",
              "b3",
              "Rf8",
              "Rf2",
              "e5",
              "fxe5+",
              "Kxe5",
              "Rxf8",
              "d4+",
              "cxd4+",
              "cxd4+",
              "Rxd4",
              "Re7",
              "Rf6",
              "Bb1",
              "Rd2",
              "Bxa2",
              "Rxa2",
              "Kd5+",
              "Kd3",
              "Kc5",
              "Rxa3",
              "Kb4",
              "Ra4+",
              "Kxb3",
              "Re4",
              "Rd7+",
              "Ke3",
              "Kc3",
              "Rc6+",
              "Kb3",
              "g6",
              "Ka3",
              "g7",
              "Kb3",
              "g8=Q+",
              "Ka3",
              "Ra6+",
              "Kb2",
              "Qa2+",
              "Kc3",
              "Rc4#",
              "Kd3",
              "Qc2#",
              "Kd5",
              "Qe4#",
              "Kd6",
              "Rc6#",
              "Kd7",
              "Qe6#",
              "Kd8",
              "Rc8#",
              "Kxc8",
              "Qxd7+",
              "Kxd7",
              "h7",
              "Ke7",
              "h8=Q",
              "Kf7",
              "Qh7+",
              "Kf8",
              "Rg8#",
              "Kxg8",
              "Qe7",
              "Kh8",
              "Kf4",
              "Kg8",
              "Kg5",
              "Kh8",
              "Kg6",
              "Kg8",
              "Qg7#",
              "Kd8",
              "Qb7",
              "Ke8",
              "Qc7",
              "Kf8",
              "Qd7",
              "Kg8",
              "Qe7",
              "Kh8",
              "Qf8#",
              "Kxh7",
              "Qf7+",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kxh7",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kxh7",
              "Qf7+",
              "Kh8",
              "Qf8#",
              "Kxh7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 322,
            "completion_tokens": 386,
            "total_tokens": 708,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 322,
            "completion_tokens": 221,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 321,
            "completion_tokens": 640,
            "total_tokens": 961,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 965,
          "total_completion_tokens": 1247,
          "total_tokens": 2212
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 322,
            "completion_tokens": 386,
            "total_tokens": 708,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 322,
            "completion_tokens": 221,
            "total_tokens": 543,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 50,
            "turn_number": 26,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 321,
            "completion_tokens": 640,
            "total_tokens": 961,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r2k3r/pbp5/1p1pp2P/8/3P2P1/2P5/PP3P2/2KR3R w - - 1 26"
    },
    {
      "turn": 53,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "g5",
          "aggressive_uci": "g4g5",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8.\nc3 Bg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Rf7 32. Ke3 d5 33. c4\nc6 34. b4 a6 35. a4 b5 36. axb5 axb5 37. c5 Ra7 38. Rh2 Ra3+ 39. Kd2 Ra2+ 40.\nKc3 Rxh2 41. Ra1 Rc2+ 42. Kb3 Rc4 43. Ra6 Bc2+ 44. Kb2 Ba4 45. Rxc6 Rxb4+ 46.\nKc3 Rc4+ 47. Kd3 Bc2+ 48. Ke3 Bf5 49. Rb6 b4 50. c6 Rc3+ 51. Kd2 Rd3+ 52. Ke2\nRxd4 53. c7 Rc4 54. Rb7 Rc8 55. Ke3 R8xc7 56. Rb8 Rc3+ 57. Kd4 R7c4+ 58. Ke5\nRe3+ 59. Kd6 Rxf4 60. Rg8+ Kh5 61. Rg7 b3 62. h7 Bxh7 63. Rxh7+ Kxg5 64. Rg7+\nKf6 65. Rb7 Rc4 66. Rb8 Rc2 67. Rf8+ Kg7 68. Rb8 b2 69. Rb7+ Kf6 70. Rb8 Re1\n71. Rf8+ Kg7 72. Rb8 b1=Q 73. Rxb1 Rxb1 74. Kxe6 d4 75. Ke5 d3 76. Ke4 d",
          "aggressive_tokens": {
            "prompt_tokens": 330,
            "completion_tokens": 640,
            "total_tokens": 970,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf7",
            "Rg1",
            "Kg6",
            "Rh4",
            "Raf8",
            "f4",
            "Be4",
            "Kd2",
            "Rf7",
            "Ke3",
            "d5",
            "c4",
            "c6",
            "b4",
            "a6",
            "a4",
            "b5",
            "axb5",
            "axb5",
            "c5",
            "Ra7",
            "Rh2",
            "Ra3+",
            "Kd2",
            "Ra2+",
            "Kc3",
            "Rxh2",
            "Ra1",
            "Rc2+",
            "Kb3",
            "Rc4",
            "Ra6",
            "Bc2+",
            "Kb2",
            "Ba4",
            "Rxc6",
            "Rxb4+",
            "Kc3",
            "Rc4+",
            "Kd3",
            "Bc2+",
            "Ke3",
            "Bf5",
            "Rb6",
            "b4",
            "c6",
            "Rc3+",
            "Kd2",
            "Rd3+",
            "Ke2",
            "Rxd4",
            "c7",
            "Rc4",
            "Rb7",
            "Rc8",
            "Ke3",
            "R8xc7",
            "Rb8",
            "Rc3+",
            "Kd4",
            "R7c4+",
            "Ke5",
            "Re3+",
            "Kd6",
            "Rxf4",
            "Rg8+",
            "Kh5",
            "Rg7",
            "b3",
            "h7",
            "Bxh7",
            "Rxh7+",
            "Kxg5",
            "Rg7+",
            "Kf6",
            "Rb7",
            "Rc4",
            "Rb8",
            "Rc2",
            "Rf8+",
            "Kg7",
            "Rb8",
            "b2",
            "Rb7+",
            "Kf6",
            "Rb8",
            "Re1",
            "Rf8+",
            "Kg7",
            "Rb8",
            "b1=Q",
            "Rxb1",
            "Rxb1",
            "Kxe6",
            "d4",
            "Ke5",
            "d3",
            "Ke4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d5",
          "positional_uci": "d4d5",
          "positional_response": "27. d5 exd5 28. g5 Kf7 29. f4 Kg6",
          "positional_tokens": {
            "prompt_tokens": 330,
            "completion_tokens": 23,
            "total_tokens": 353,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "exd5",
            "g5",
            "Kf7",
            "f4",
            "Kg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "g5",
          "neutral_uci": "g4g5",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8.\nc3 Bg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Bf5 32. Ke3 Rh7 33. Rgh1\nRfh8 34. R1h2 c5 35. dxc5 bxc5 36. Rd2 d5 37. b4 cxb4 38. cxb4 Rc8 39. Rhh2 Rc3+\n40. Kd4 Rc4+ 41. Ke5 Re4+ 42. Kd6 Rxf4 43. Rdg2 Rxb4 44. Rh1 Rb6+ 45. Ke5 Rc6\n46. Rhh2 a5 47. Rg3 a4 48. Rh1 Rc4 49. Rh2 Re4+ 50. Kd6 Rg4 51. Rxg4 Bxg4 52.\nRg2 Kxg5 53. Ke5 Rxh6 54. Rg3 Rh3 55. Rg2 Re3+ 56. Kd4 Re4+ 57. Kd3 Kf4 58.\nRf2+ Bf3 59. Rh2 Kg3 60. Rh8 Kf2 61. Rh2+ Bg2 62. Rh8 Re3+ 63. Kd4 e5+ 64. Kc5\nd4 65. Rf8+ Bf3 66. Kb4 a3 67. Rf7 Ke2 68. Rg7 d3 69. Kxa3 d2+ 70. Kb2 d1=Q\n71. Rg2+ Bxg2 72. a4 Rb3+ 73. Ka2 Qb1#",
          "neutral_tokens": {
            "prompt_tokens": 329,
            "completion_tokens": 618,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf7",
            "Rg1",
            "Kg6",
            "Rh4",
            "Raf8",
            "f4",
            "Be4",
            "Kd2",
            "Bf5",
            "Ke3",
            "Rh7",
            "Rgh1",
            "Rfh8",
            "R1h2",
            "c5",
            "dxc5",
            "bxc5",
            "Rd2",
            "d5",
            "b4",
            "cxb4",
            "cxb4",
            "Rc8",
            "Rhh2",
            "Rc3+",
            "Kd4",
            "Rc4+",
            "Ke5",
            "Re4+",
            "Kd6",
            "Rxf4",
            "Rdg2",
            "Rxb4",
            "Rh1",
            "Rb6+",
            "Ke5",
            "Rc6",
            "Rhh2",
            "a5",
            "Rg3",
            "a4",
            "Rh1",
            "Rc4",
            "Rh2",
            "Re4+",
            "Kd6",
            "Rg4",
            "Rxg4",
            "Bxg4",
            "Rg2",
            "Kxg5",
            "Ke5",
            "Rxh6",
            "Rg3",
            "Rh3",
            "Rg2",
            "Re3+",
            "Kd4",
            "Re4+",
            "Kd3",
            "Kf4",
            "Rf2+",
            "Bf3",
            "Rh2",
            "Kg3",
            "Rh8",
            "Kf2",
            "Rh2+",
            "Bg2",
            "Rh8",
            "Re3+",
            "Kd4",
            "e5+",
            "Kc5",
            "d4",
            "Rf8+",
            "Bf3",
            "Kb4",
            "a3",
            "Rf7",
            "Ke2",
            "Rg7",
            "d3",
            "Kxa3",
            "d2+",
            "Kb2",
            "d1=Q",
            "Rg2+",
            "Bxg2",
            "a4",
            "Rb3+",
            "Ka2",
            "Qb1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4g5",
          "positional_uci": "d4d5",
          "neutral_uci": "g4g5",
          "consensus_move": "g4g5",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf7",
              "Rg1",
              "Kg6",
              "Rh4",
              "Raf8",
              "f4",
              "Be4",
              "Kd2",
              "Rf7",
              "Ke3",
              "d5",
              "c4",
              "c6",
              "b4",
              "a6",
              "a4",
              "b5",
              "axb5",
              "axb5",
              "c5",
              "Ra7",
              "Rh2",
              "Ra3+",
              "Kd2",
              "Ra2+",
              "Kc3",
              "Rxh2",
              "Ra1",
              "Rc2+",
              "Kb3",
              "Rc4",
              "Ra6",
              "Bc2+",
              "Kb2",
              "Ba4",
              "Rxc6",
              "Rxb4+",
              "Kc3",
              "Rc4+",
              "Kd3",
              "Bc2+",
              "Ke3",
              "Bf5",
              "Rb6",
              "b4",
              "c6",
              "Rc3+",
              "Kd2",
              "Rd3+",
              "Ke2",
              "Rxd4",
              "c7",
              "Rc4",
              "Rb7",
              "Rc8",
              "Ke3",
              "R8xc7",
              "Rb8",
              "Rc3+",
              "Kd4",
              "R7c4+",
              "Ke5",
              "Re3+",
              "Kd6",
              "Rxf4",
              "Rg8+",
              "Kh5",
              "Rg7",
              "b3",
              "h7",
              "Bxh7",
              "Rxh7+",
              "Kxg5",
              "Rg7+",
              "Kf6",
              "Rb7",
              "Rc4",
              "Rb8",
              "Rc2",
              "Rf8+",
              "Kg7",
              "Rb8",
              "b2",
              "Rb7+",
              "Kf6",
              "Rb8",
              "Re1",
              "Rf8+",
              "Kg7",
              "Rb8",
              "b1=Q",
              "Rxb1",
              "Rxb1",
              "Kxe6",
              "d4",
              "Ke5",
              "d3",
              "Ke4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "exd5",
              "g5",
              "Kf7",
              "f4",
              "Kg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf7",
              "Rg1",
              "Kg6",
              "Rh4",
              "Raf8",
              "f4",
              "Be4",
              "Kd2",
              "Bf5",
              "Ke3",
              "Rh7",
              "Rgh1",
              "Rfh8",
              "R1h2",
              "c5",
              "dxc5",
              "bxc5",
              "Rd2",
              "d5",
              "b4",
              "cxb4",
              "cxb4",
              "Rc8",
              "Rhh2",
              "Rc3+",
              "Kd4",
              "Rc4+",
              "Ke5",
              "Re4+",
              "Kd6",
              "Rxf4",
              "Rdg2",
              "Rxb4",
              "Rh1",
              "Rb6+",
              "Ke5",
              "Rc6",
              "Rhh2",
              "a5",
              "Rg3",
              "a4",
              "Rh1",
              "Rc4",
              "Rh2",
              "Re4+",
              "Kd6",
              "Rg4",
              "Rxg4",
              "Bxg4",
              "Rg2",
              "Kxg5",
              "Ke5",
              "Rxh6",
              "Rg3",
              "Rh3",
              "Rg2",
              "Re3+",
              "Kd4",
              "Re4+",
              "Kd3",
              "Kf4",
              "Rf2+",
              "Bf3",
              "Rh2",
              "Kg3",
              "Rh8",
              "Kf2",
              "Rh2+",
              "Bg2",
              "Rh8",
              "Re3+",
              "Kd4",
              "e5+",
              "Kc5",
              "d4",
              "Rf8+",
              "Bf3",
              "Kb4",
              "a3",
              "Rf7",
              "Ke2",
              "Rg7",
              "d3",
              "Kxa3",
              "d2+",
              "Kb2",
              "d1=Q",
              "Rg2+",
              "Bxg2",
              "a4",
              "Rb3+",
              "Ka2",
              "Qb1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 330,
            "completion_tokens": 640,
            "total_tokens": 970,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 330,
            "completion_tokens": 23,
            "total_tokens": 353,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 329,
            "completion_tokens": 618,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 989,
          "total_completion_tokens": 1281,
          "total_tokens": 2270
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 330,
            "completion_tokens": 640,
            "total_tokens": 970,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 330,
            "completion_tokens": 23,
            "total_tokens": 353,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 52,
            "turn_number": 27,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 329,
            "completion_tokens": 618,
            "total_tokens": 947,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "r3k2r/pbp5/1p1pp2P/7R/3P2P1/2P5/PP3P2/2KR4 w - - 3 27"
    },
    {
      "turn": 55,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "f4",
          "aggressive_uci": "f2f4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. f4 Kg6 29. Rh4 Raf8 30. Re1 Bc8 31. Kd2 Rf5 32. Ke3 e5 33. dxe5\ndxe5 34. Rd1 exf4+ 35. Rxf4 Re8+ 36. Re4 Rxe4+ 37. Kxe4 Rxg5 38. Rd8 Bf5+ 39.\nKf4 Rg4+ 40. Ke5 Re4+ 41. Kd5 Kxh6 42. Rf8 Bg6 43. Rf6 Re2 44. b4 Rxa2 45.\nKc6 Rc2 46. Kxc7 Rxc3+ 47. Kb7 Ra3 48. b5 Kg5 49. Rd6 Be4+ 50. Kb8 Kf5 51. Rd7\nRa5 52. Rxa7 Rxa7 53. Kxa7 Ke5 54. Kxb6 Kd6 55. Ka7 Kc7 56. b6+ Kc8 57. Ka6 Kb8\n58. Kb5 Kb7 59. Kc5 Bc6 60. Kd6 Kxb6 61. Ke5 Kc5 62. Kf4 Kd4 63. Kg3 Ke3 64.\nKh2 Kf2 65. Kh3 Bd7+ 66. Kh2 Be6 67. Kh1 Kg3 68. Kg1 Bc4 69. Kh1 Kf2 70. Kh2\nBe6 71. Kh1 Kg3 72. Kg1 Bc4 73. Kh1 Kf2 74. Kh2 Be6 75. Kh1 Kg3 76. Kg1 Bc4 77.\nKh1 Kf2 78. Kh",
          "aggressive_tokens": {
            "prompt_tokens": 337,
            "completion_tokens": 640,
            "total_tokens": 977,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg6",
            "Rh4",
            "Raf8",
            "Re1",
            "Bc8",
            "Kd2",
            "Rf5",
            "Ke3",
            "e5",
            "dxe5",
            "dxe5",
            "Rd1",
            "exf4+",
            "Rxf4",
            "Re8+",
            "Re4",
            "Rxe4+",
            "Kxe4",
            "Rxg5",
            "Rd8",
            "Bf5+",
            "Kf4",
            "Rg4+",
            "Ke5",
            "Re4+",
            "Kd5",
            "Kxh6",
            "Rf8",
            "Bg6",
            "Rf6",
            "Re2",
            "b4",
            "Rxa2",
            "Kc6",
            "Rc2",
            "Kxc7",
            "Rxc3+",
            "Kb7",
            "Ra3",
            "b5",
            "Kg5",
            "Rd6",
            "Be4+",
            "Kb8",
            "Kf5",
            "Rd7",
            "Ra5",
            "Rxa7",
            "Rxa7",
            "Kxa7",
            "Ke5",
            "Kxb6",
            "Kd6",
            "Ka7",
            "Kc7",
            "b6+",
            "Kc8",
            "Ka6",
            "Kb8",
            "Kb5",
            "Kb7",
            "Kc5",
            "Bc6",
            "Kd6",
            "Kxb6",
            "Ke5",
            "Kc5",
            "Kf4",
            "Kd4",
            "Kg3",
            "Ke3",
            "Kh2",
            "Kf2",
            "Kh3",
            "Bd7+",
            "Kh2",
            "Be6",
            "Kh1",
            "Kg3",
            "Kg1",
            "Bc4",
            "Kh1",
            "Kf2",
            "Kh2",
            "Be6",
            "Kh1",
            "Kg3",
            "Kg1",
            "Bc4",
            "Kh1",
            "Kf2",
            "Kh2",
            "Be6",
            "Kh1",
            "Kg3",
            "Kg1",
            "Bc4",
            "Kh1",
            "Kf2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rg1",
          "positional_uci": "d1g1",
          "positional_response": "28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Bf5 32. Ke3 c5 33. Rd1 c4 34. d5\ne5 35. fxe5 dxe5 36. Rxc4 Kxg5 37. Rc7 Rxh6 38. Rxa7 Rh3+ 39. Kd2 Rh2+ 40. Ke3\nRfh8 41. Rg1+ Kf6 42. Rg3 Rxb2 43. d6 Rhh2 44. d7 Rhe2+ 45. Kf3 Rf2+ 46. Ke3\nRbe2# d4 e5 dxe5",
          "positional_tokens": {
            "prompt_tokens": 337,
            "completion_tokens": 169,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf6",
            "Rg3",
            "Rxb2",
            "d6",
            "Rhh2",
            "d7",
            "Rhe2+",
            "Kf3",
            "Rf2+",
            "Ke3",
            "Rbe2#",
            "d4",
            "e5",
            "dxe5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rg1",
          "neutral_uci": "d1g1",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Kg6 29. Rh4 Raf8 30. f4 Be4 31. Kd2 Bf5 32. Ke3 c5 33. Rd1\nd5 34. Rd2 c4 35. b3 b5 36. b4 a5 37. a3 axb4 38. axb4 Ra8 39. Rhh2 Ra3 40. Ra2\nRxc3+ 41. Kd2 Rd3+ 42. Ke2 Rxd4 43. Ra7 Rh7 44. Ra8 Rxf4 45. Rg8+ Kf7 46. Rb8\nKg6 47. Rg8+ Kf7 48. Rb8 Re4+ 49. Kf3 Kg6 50. Rg8+ Kf7 51. Rb8 Kg6 52. Rg8+\nKf7 53. Rb8 Kg6 54. Rg8+ Kf7 55. Rb8 Kg6 56. Rg8+ Kf7 57. Rb8 Kg6 58. Rg8+\nKf7 59. Rb8 Kg6 60. Rg8+ Kf7 61. Rb8 Kg6 62. Rg8+ Kf7 63. Rb8 Kg6 64. Rg8+\nKf7 65. Rb8 Kg6 66. Rg8+ Kf7 67. Rb8 Kg6 68. Rg8+ Kf7 69. Rb8 Kg6 70. Rg8+\nKf7 71. Rb8 Kg6 72. Rg8+ Kf7 73. Rb8 Kg6 74. Rg8+ Kf7 75. Rb8",
          "neutral_tokens": {
            "prompt_tokens": 336,
            "completion_tokens": 640,
            "total_tokens": 976,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg6",
            "Rh4",
            "Raf8",
            "f4",
            "Be4",
            "Kd2",
            "Bf5",
            "Ke3",
            "c5",
            "Rd1",
            "d5",
            "Rd2",
            "c4",
            "b3",
            "b5",
            "b4",
            "a5",
            "a3",
            "axb4",
            "axb4",
            "Ra8",
            "Rhh2",
            "Ra3",
            "Ra2",
            "Rxc3+",
            "Kd2",
            "Rd3+",
            "Ke2",
            "Rxd4",
            "Ra7",
            "Rh7",
            "Ra8",
            "Rxf4",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Re4+",
            "Kf3",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8",
            "Kg6",
            "Rg8+",
            "Kf7",
            "Rb8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f2f4",
          "positional_uci": "d1g1",
          "neutral_uci": "d1g1",
          "consensus_move": "d1g1",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg6",
              "Rh4",
              "Raf8",
              "Re1",
              "Bc8",
              "Kd2",
              "Rf5",
              "Ke3",
              "e5",
              "dxe5",
              "dxe5",
              "Rd1",
              "exf4+",
              "Rxf4",
              "Re8+",
              "Re4",
              "Rxe4+",
              "Kxe4",
              "Rxg5",
              "Rd8",
              "Bf5+",
              "Kf4",
              "Rg4+",
              "Ke5",
              "Re4+",
              "Kd5",
              "Kxh6",
              "Rf8",
              "Bg6",
              "Rf6",
              "Re2",
              "b4",
              "Rxa2",
              "Kc6",
              "Rc2",
              "Kxc7",
              "Rxc3+",
              "Kb7",
              "Ra3",
              "b5",
              "Kg5",
              "Rd6",
              "Be4+",
              "Kb8",
              "Kf5",
              "Rd7",
              "Ra5",
              "Rxa7",
              "Rxa7",
              "Kxa7",
              "Ke5",
              "Kxb6",
              "Kd6",
              "Ka7",
              "Kc7",
              "b6+",
              "Kc8",
              "Ka6",
              "Kb8",
              "Kb5",
              "Kb7",
              "Kc5",
              "Bc6",
              "Kd6",
              "Kxb6",
              "Ke5",
              "Kc5",
              "Kf4",
              "Kd4",
              "Kg3",
              "Ke3",
              "Kh2",
              "Kf2",
              "Kh3",
              "Bd7+",
              "Kh2",
              "Be6",
              "Kh1",
              "Kg3",
              "Kg1",
              "Bc4",
              "Kh1",
              "Kf2",
              "Kh2",
              "Be6",
              "Kh1",
              "Kg3",
              "Kg1",
              "Bc4",
              "Kh1",
              "Kf2",
              "Kh2",
              "Be6",
              "Kh1",
              "Kg3",
              "Kg1",
              "Bc4",
              "Kh1",
              "Kf2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf6",
              "Rg3",
              "Rxb2",
              "d6",
              "Rhh2",
              "d7",
              "Rhe2+",
              "Kf3",
              "Rf2+",
              "Ke3",
              "Rbe2#",
              "d4",
              "e5",
              "dxe5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg6",
              "Rh4",
              "Raf8",
              "f4",
              "Be4",
              "Kd2",
              "Bf5",
              "Ke3",
              "c5",
              "Rd1",
              "d5",
              "Rd2",
              "c4",
              "b3",
              "b5",
              "b4",
              "a5",
              "a3",
              "axb4",
              "axb4",
              "Ra8",
              "Rhh2",
              "Ra3",
              "Ra2",
              "Rxc3+",
              "Kd2",
              "Rd3+",
              "Ke2",
              "Rxd4",
              "Ra7",
              "Rh7",
              "Ra8",
              "Rxf4",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Re4+",
              "Kf3",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8",
              "Kg6",
              "Rg8+",
              "Kf7",
              "Rb8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 337,
            "completion_tokens": 640,
            "total_tokens": 977,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 337,
            "completion_tokens": 169,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 336,
            "completion_tokens": 640,
            "total_tokens": 976,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1010,
          "total_completion_tokens": 1449,
          "total_tokens": 2459
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 337,
            "completion_tokens": 640,
            "total_tokens": 977,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 337,
            "completion_tokens": 169,
            "total_tokens": 506,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 54,
            "turn_number": 28,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 336,
            "completion_tokens": 640,
            "total_tokens": 976,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "r6r/pbp2k2/1p1pp2P/6PR/3P4/2P5/PP3P2/2KR4 w - - 1 28"
    },
    {
      "turn": 57,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rh4",
          "aggressive_uci": "h5h4",
          "aggressive_response": "29. Rh4 Kg6 30. Rf4 Rf8 31. Rxf8 Rxf8 32. Kd2 Rxf2+ 33. Ke3 Rf3+ 34. Ke2 Rf8 35. Ke3 Bd5 36. b3 b5 37. Rg3 a5 38. Kd3 a4 39. c4 bxc4+ 40. bxc4 Bc6 41. Kc3 Rf3+ 42. Rxf3 Bxf3 43. Kb4 Bd1 44. Kb5 e5 45. dxe5 dxe5 46. Kc6 e4 47. Kxc7 e3 48. c5 e2 49. c6 e1=Q 50. Kb8 Qb4+ 51. Kc8 Bg4+ 52. Kd8 Qd6+ 53. Ke8 Qxc6+ 54. Kf8 Qd7 55. Kg8 Qe8# e4 e5 e6",
          "aggressive_tokens": {
            "prompt_tokens": 345,
            "completion_tokens": 236,
            "total_tokens": 581,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg6",
            "Rf4",
            "Rf8",
            "Rxf8",
            "Rxf8",
            "Kd2",
            "Rxf2+",
            "Ke3",
            "Rf3+",
            "Ke2",
            "Rf8",
            "Ke3",
            "Bd5",
            "b3",
            "b5",
            "Rg3",
            "a5",
            "Kd3",
            "a4",
            "c4",
            "bxc4+",
            "bxc4",
            "Bc6",
            "Kc3",
            "Rf3+",
            "Rxf3",
            "Bxf3",
            "Kb4",
            "Bd1",
            "Kb5",
            "e5",
            "dxe5",
            "dxe5",
            "Kc6",
            "e4",
            "Kxc7",
            "e3",
            "c5",
            "e2",
            "c6",
            "e1=Q",
            "Kb8",
            "Qb4+",
            "Kc8",
            "Bg4+",
            "Kd8",
            "Qd6+",
            "Ke8",
            "Qxc6+",
            "Kf8",
            "Qd7",
            "Kg8",
            "Qe8#",
            "e4",
            "e5",
            "e6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "g6+",
          "positional_uci": "g5g6",
          "positional_response": "29. g6+ Rxg6 30. Rxg6 Kxg6 31. Rh3 Rxh6 32. Rg3+ Kf7 33. Kd2 Rf6 34. Ke3 e5 35. dxe5 dxe5 36. Rh3 Ke6 37. Rh7 Rf7 38. Rh6+ Kd5 39. b3 Kc5 40. Rh5 Rf3+ 41. Ke2 Rxc3 42. Rxe5+ Kd6 43. Rh5 Rc2+ 44. Ke3 Rxa2 45. f4 Ra3 46. Rh6+ Kc5 47. Rh5+ Kb4 48. f5 Rxb3+ 49. Kd4 c5+ 50. Ke5 Re3+ 51. Kd6 Rf3 52. Kc7 Be4 53. Kb8 a5 54. Ka7 b5 55. Kb6 a4 56. Rh4 Rxf5 57. Rxe4+ c4 58. Re1 a3 59. Rb1+ Ka4 60. Ra1 b4 61. Rc1 c3 62. Rh1 a2 63. Rh8 Kb3 64. Ra8 c2 65. Rc8 a1=Q 66. Rc7 Qa5+ 67. Kb7 Qxc7+ 68. Kxc7 c1=Q+ 69. Kb6 Qc5+ 70. Kb7 Rf7+ 71. Kb8 Qf8#",
          "positional_tokens": {
            "prompt_tokens": 345,
            "completion_tokens": 358,
            "total_tokens": 703,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxg6",
            "Rxg6",
            "Kxg6",
            "Rh3",
            "Rxh6",
            "Rg3+",
            "Kf7",
            "Kd2",
            "Rf6",
            "Ke3",
            "e5",
            "dxe5",
            "dxe5",
            "Rh3",
            "Ke6",
            "Rh7",
            "Rf7",
            "Rh6+",
            "Kd5",
            "b3",
            "Kc5",
            "Rh5",
            "Rf3+",
            "Ke2",
            "Rxc3",
            "Rxe5+",
            "Kd6",
            "Rh5",
            "Rc2+",
            "Ke3",
            "Rxa2",
            "f4",
            "Ra3",
            "Rh6+",
            "Kc5",
            "Rh5+",
            "Kb4",
            "f5",
            "Rxb3+",
            "Kd4",
            "c5+",
            "Ke5",
            "Re3+",
            "Kd6",
            "Rf3",
            "Kc7",
            "Be4",
            "Kb8",
            "a5",
            "Ka7",
            "b5",
            "Kb6",
            "a4",
            "Rh4",
            "Rxf5",
            "Rxe4+",
            "c4",
            "Re1",
            "a3",
            "Rb1+",
            "Ka4",
            "Ra1",
            "b4",
            "Rc1",
            "c3",
            "Rh1",
            "a2",
            "Rh8",
            "Kb3",
            "Ra8",
            "c2",
            "Rc8",
            "a1=Q",
            "Rc7",
            "Qa5+",
            "Kb7",
            "Qxc7+",
            "Kxc7",
            "c1=Q+",
            "Kb6",
            "Qc5+",
            "Kb7",
            "Rf7+",
            "Kb8",
            "Qf8#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rh4",
          "neutral_uci": "h5h4",
          "neutral_response": "29. Rh4 Kg6 30. Rf4 Rf8 31. Rxf8 Rxf8 32. Kd2 Rxf2+ 33. Ke3 Rf3+ 34. Ke2 Rf8 35. Ke3 Bd5 36. b3 b5 37. Rg3 a5 38. Kd3 a4 39. c4 bxc4+ 40. bxc4 Bc6 41. Kc3 Rf3+ 42. Rxf3 Bxf3 43. Kb4 Bc6 44. Ka5 e5 45. dxe5 dxe5 46. Kb4 e4 47. Kc3 Bd7 48. Kd4 Bf5 49. Ke3 c5 50. Kf4 a3 51. Ke3 Kxg5 52. h7 Bxh7 53. Kd2 Kf4 54. Kc3 e3 55. Kb3 e2 56. Kxa3 e1=Q 57. Kb3 Qb4# e4 e5 e6",
          "neutral_tokens": {
            "prompt_tokens": 344,
            "completion_tokens": 249,
            "total_tokens": 593,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg6",
            "Rf4",
            "Rf8",
            "Rxf8",
            "Rxf8",
            "Kd2",
            "Rxf2+",
            "Ke3",
            "Rf3+",
            "Ke2",
            "Rf8",
            "Ke3",
            "Bd5",
            "b3",
            "b5",
            "Rg3",
            "a5",
            "Kd3",
            "a4",
            "c4",
            "bxc4+",
            "bxc4",
            "Bc6",
            "Kc3",
            "Rf3+",
            "Rxf3",
            "Bxf3",
            "Kb4",
            "Bc6",
            "Ka5",
            "e5",
            "dxe5",
            "dxe5",
            "Kb4",
            "e4",
            "Kc3",
            "Bd7",
            "Kd4",
            "Bf5",
            "Ke3",
            "c5",
            "Kf4",
            "a3",
            "Ke3",
            "Kxg5",
            "h7",
            "Bxh7",
            "Kd2",
            "Kf4",
            "Kc3",
            "e3",
            "Kb3",
            "e2",
            "Kxa3",
            "e1=Q",
            "Kb3",
            "Qb4#",
            "e4",
            "e5",
            "e6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h5h4",
          "positional_uci": "g5g6",
          "neutral_uci": "h5h4",
          "consensus_move": "h5h4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kg6",
              "Rf4",
              "Rf8",
              "Rxf8",
              "Rxf8",
              "Kd2",
              "Rxf2+",
              "Ke3",
              "Rf3+",
              "Ke2",
              "Rf8",
              "Ke3",
              "Bd5",
              "b3",
              "b5",
              "Rg3",
              "a5",
              "Kd3",
              "a4",
              "c4",
              "bxc4+",
              "bxc4",
              "Bc6",
              "Kc3",
              "Rf3+",
              "Rxf3",
              "Bxf3",
              "Kb4",
              "Bd1",
              "Kb5",
              "e5",
              "dxe5",
              "dxe5",
              "Kc6",
              "e4",
              "Kxc7",
              "e3",
              "c5",
              "e2",
              "c6",
              "e1=Q",
              "Kb8",
              "Qb4+",
              "Kc8",
              "Bg4+",
              "Kd8",
              "Qd6+",
              "Ke8",
              "Qxc6+",
              "Kf8",
              "Qd7",
              "Kg8",
              "Qe8#",
              "e4",
              "e5",
              "e6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxg6",
              "Rxg6",
              "Kxg6",
              "Rh3",
              "Rxh6",
              "Rg3+",
              "Kf7",
              "Kd2",
              "Rf6",
              "Ke3",
              "e5",
              "dxe5",
              "dxe5",
              "Rh3",
              "Ke6",
              "Rh7",
              "Rf7",
              "Rh6+",
              "Kd5",
              "b3",
              "Kc5",
              "Rh5",
              "Rf3+",
              "Ke2",
              "Rxc3",
              "Rxe5+",
              "Kd6",
              "Rh5",
              "Rc2+",
              "Ke3",
              "Rxa2",
              "f4",
              "Ra3",
              "Rh6+",
              "Kc5",
              "Rh5+",
              "Kb4",
              "f5",
              "Rxb3+",
              "Kd4",
              "c5+",
              "Ke5",
              "Re3+",
              "Kd6",
              "Rf3",
              "Kc7",
              "Be4",
              "Kb8",
              "a5",
              "Ka7",
              "b5",
              "Kb6",
              "a4",
              "Rh4",
              "Rxf5",
              "Rxe4+",
              "c4",
              "Re1",
              "a3",
              "Rb1+",
              "Ka4",
              "Ra1",
              "b4",
              "Rc1",
              "c3",
              "Rh1",
              "a2",
              "Rh8",
              "Kb3",
              "Ra8",
              "c2",
              "Rc8",
              "a1=Q",
              "Rc7",
              "Qa5+",
              "Kb7",
              "Qxc7+",
              "Kxc7",
              "c1=Q+",
              "Kb6",
              "Qc5+",
              "Kb7",
              "Rf7+",
              "Kb8",
              "Qf8#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg6",
              "Rf4",
              "Rf8",
              "Rxf8",
              "Rxf8",
              "Kd2",
              "Rxf2+",
              "Ke3",
              "Rf3+",
              "Ke2",
              "Rf8",
              "Ke3",
              "Bd5",
              "b3",
              "b5",
              "Rg3",
              "a5",
              "Kd3",
              "a4",
              "c4",
              "bxc4+",
              "bxc4",
              "Bc6",
              "Kc3",
              "Rf3+",
              "Rxf3",
              "Bxf3",
              "Kb4",
              "Bc6",
              "Ka5",
              "e5",
              "dxe5",
              "dxe5",
              "Kb4",
              "e4",
              "Kc3",
              "Bd7",
              "Kd4",
              "Bf5",
              "Ke3",
              "c5",
              "Kf4",
              "a3",
              "Ke3",
              "Kxg5",
              "h7",
              "Bxh7",
              "Kd2",
              "Kf4",
              "Kc3",
              "e3",
              "Kb3",
              "e2",
              "Kxa3",
              "e1=Q",
              "Kb3",
              "Qb4#",
              "e4",
              "e5",
              "e6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 345,
            "completion_tokens": 236,
            "total_tokens": 581,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 345,
            "completion_tokens": 358,
            "total_tokens": 703,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 344,
            "completion_tokens": 249,
            "total_tokens": 593,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1034,
          "total_completion_tokens": 843,
          "total_tokens": 1877
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 345,
            "completion_tokens": 236,
            "total_tokens": 581,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 345,
            "completion_tokens": 358,
            "total_tokens": 703,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 56,
            "turn_number": 29,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 344,
            "completion_tokens": 249,
            "total_tokens": 593,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6rr/pbp2k2/1p1pp2P/6PR/3P4/2P5/PP3P2/2K3R1 w - - 3 29"
    },
    {
      "turn": 59,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rf4+",
          "aggressive_uci": "h4f4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Kg6 31. Rf6+ Kh5 32. f4 Be4 33. Rxe6 Bf5 34. Rf6 Rf8 35. Rxf8 Rxf8 36. Kd2 Bg6 37. Ke3 Re8+ 38. Kf3 Be4+ 39. Kg3 Kg6 40. Re1 d5 41. c4 c6 42. cxd5 cxd5 43. Rc1 Re6 44. Rc7 Bf5 45. Rg7+ Kh5 46. h7 Re8 47. Rg8 Re3+ 48. Kf2 Bxh7 49. Rh8 Re7 50. Kg3 Kg6 51. Kg4 Kg7 52. Rb8 Re6 53. f5 Re4+ 54. Kh5 Bxf5 55. Rb7+ Kf8 56. g6 Rxd4 57. g7+ Kg8 58. Kg5 Be6 59. Kf6 Re4 60. Rb8+ Kh7 61. Rh8# Bg8 62. Rh5# Bf7 63. Kxf7 Rf4+ 64. Ke6 Kg6 65. g8=Q+ Kxh5 66. h7 Re4+ 67. Kxd5 Rg4 68. h8=Q# Kg3 69. Qe5+ Kf3 70. Qf7+ Kg2 71. Qe2+ Kh3 72. Qh5+ Kg3 73. Qhxg4# Kg1 74. Qgxg2# Bxg2 75. Qxg2# Kxg",
          "aggressive_tokens": {
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ke6",
            "Kg6",
            "g8=Q+",
            "Kxh5",
            "h7",
            "Re4+",
            "Kxd5",
            "Rg4",
            "h8=Q#",
            "Kg3",
            "Qe5+",
            "Kf3",
            "Qf7+",
            "Kg2",
            "Qe2+",
            "Kh3",
            "Qh5+",
            "Kg3",
            "Qhxg4#",
            "Kg1",
            "Qgxg2#",
            "Bxg2",
            "Qxg2#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 31. Rf4+ Kg8 32. Rf6 Rh7 33. f4 Be4 34.\nKd2 Bf5 35. Ke3 Rf8 36. Rxf8+ Kxf8 37. Kf3 Kf7 38. Kg3 Kg6 39. Kh4 Re7 40. Re1\nc5 41. dxc5 bxc5 42. Rd1 d5 43. b4 cxb4 44. cxb4 Rc7 45. Rd4 Rc3 46. a4 Rh3#\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 * Re8 31. Rf4+ Kg8 32. Rf6 Rh7 33. f4 Be4 34.\nKd2 Bf5 35. Ke3 Rf8 36. Rxf8+ Kxf8 37. Kf3 Kf7 38. Kg3 Kg6 39. Kh4 Re7 40. Re1\nc5 41. dxc5 bxc5 42. Rd1 d5 43. b4 cxb4 44. cxb4 Rc7 45. Rd4 Rc3 46. a4 Rh3# 1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17",
          "positional_tokens": {
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": null,
          "neutral_response": "a6 b3 c4",
          "neutral_tokens": {
            "prompt_tokens": 351,
            "completion_tokens": 6,
            "total_tokens": 357,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "b3",
            "c4"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "h4f4",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "h4f4",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ke6",
              "Kg6",
              "g8=Q+",
              "Kxh5",
              "h7",
              "Re4+",
              "Kxd5",
              "Rg4",
              "h8=Q#",
              "Kg3",
              "Qe5+",
              "Kf3",
              "Qf7+",
              "Kg2",
              "Qe2+",
              "Kh3",
              "Qh5+",
              "Kg3",
              "Qhxg4#",
              "Kg1",
              "Qgxg2#",
              "Bxg2",
              "Qxg2#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "b3",
              "c4"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 351,
            "completion_tokens": 6,
            "total_tokens": 357,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1055,
          "total_completion_tokens": 1286,
          "total_tokens": 2341
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 352,
            "completion_tokens": 640,
            "total_tokens": 992,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 58,
            "turn_number": 30,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 351,
            "completion_tokens": 6,
            "total_tokens": 357,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6rr/1bp2k2/pp1pp2P/6P1/3P3R/2P5/PP3P2/2K3R1 w - - 0 30"
    },
    {
      "turn": 61,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re8",
          "aggressive_uci": null,
          "aggressive_response": "Re8 Rg6 Rg7",
          "aggressive_tokens": {
            "prompt_tokens": 361,
            "completion_tokens": 8,
            "total_tokens": 369,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg6",
            "Rg7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rf6",
          "positional_uci": "f4f6",
          "positional_response": "31. Rf6 Bd5 32. b3 b5 33. Kd2 Ke7 34. Ke3 a5 35. f4 a4 36. bxa4 bxa4 37. a3\nBb3 38. Kd3 Ba2 39. c4 Bb3 40. Kc3 Ba2 41. Re1 Kd7 42. Rexe6 Bb1 43. d5\nBh7 44. Rf7+ Kc8 45. Ree7 Bb1 46. Rxc7+ Kb8 47. Rb7+ Ka8 48. Rxb1 Rb8 49.\nRxb8+ Kxb8 50. h7 Kc8 51. g6 Kd8 52. g7 Ke8 53. Ra7 Rxh7 54. g8=Q#",
          "positional_tokens": {
            "prompt_tokens": 361,
            "completion_tokens": 199,
            "total_tokens": 560,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bd5",
            "b3",
            "b5",
            "Kd2",
            "Ke7",
            "Ke3",
            "a5",
            "f4",
            "a4",
            "bxa4",
            "bxa4",
            "a3",
            "Bb3",
            "Kd3",
            "Ba2",
            "c4",
            "Bb3",
            "Kc3",
            "Ba2",
            "Re1",
            "Kd7",
            "Rexe6",
            "Bb1",
            "d5",
            "Bh7",
            "Rf7+",
            "Kc8",
            "Ree7",
            "Bb1",
            "Rxc7+",
            "Kb8",
            "Rb7+",
            "Ka8",
            "Rxb1",
            "Rb8",
            "Rxb8+",
            "Kxb8",
            "h7",
            "Kc8",
            "g6",
            "Kd8",
            "g7",
            "Ke8",
            "Ra7",
            "Rxh7",
            "g8=Q#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg6 Rg7",
          "neutral_tokens": {
            "prompt_tokens": 360,
            "completion_tokens": 8,
            "total_tokens": 368,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg6",
            "Rg7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "f4f6",
          "neutral_uci": null,
          "consensus_move": "f4f6",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg6",
              "Rg7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd5",
              "b3",
              "b5",
              "Kd2",
              "Ke7",
              "Ke3",
              "a5",
              "f4",
              "a4",
              "bxa4",
              "bxa4",
              "a3",
              "Bb3",
              "Kd3",
              "Ba2",
              "c4",
              "Bb3",
              "Kc3",
              "Ba2",
              "Re1",
              "Kd7",
              "Rexe6",
              "Bb1",
              "d5",
              "Bh7",
              "Rf7+",
              "Kc8",
              "Ree7",
              "Bb1",
              "Rxc7+",
              "Kb8",
              "Rb7+",
              "Ka8",
              "Rxb1",
              "Rb8",
              "Rxb8+",
              "Kxb8",
              "h7",
              "Kc8",
              "g6",
              "Kd8",
              "g7",
              "Ke8",
              "Ra7",
              "Rxh7",
              "g8=Q#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg6",
              "Rg7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 361,
            "completion_tokens": 8,
            "total_tokens": 369,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 361,
            "completion_tokens": 199,
            "total_tokens": 560,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 360,
            "completion_tokens": 8,
            "total_tokens": 368,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1082,
          "total_completion_tokens": 215,
          "total_tokens": 1297
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 361,
            "completion_tokens": 8,
            "total_tokens": 369,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 361,
            "completion_tokens": 199,
            "total_tokens": 560,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 60,
            "turn_number": 31,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 360,
            "completion_tokens": 8,
            "total_tokens": 368,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "4k1rr/1bp5/pp1pp2P/6P1/3P1R2/2P5/PP3P2/2K3R1 w - - 2 31"
    },
    {
      "turn": 63,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 f4 e5 dxe5 dxe5 fxe5 Bxe5 Bxe5 Qxe5 Qxe5 Rxe5 Rxe5 Rxe5 Re8 Rxe8 Kxe8 Kd2 Kf7 Ke3 Kg6 Kf4 c5 dxc5 bxc5 b4 cxb4 cxb4 Kxh6 a4 Kg5 a5 Kf6 a6 Ke7 a7 Kd7 a8=Q Kc7 Qa6 Kd7 Qb6 Ke7 Qc6 Kf7 Qd6 Kg7 Qe6 Kh7 Qf6 Kg8 Qe7 Kh8 Kg6 Kg8 Qg7# 1-0\n\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 * e4 d5 f4 e5 dxe5 dxe5 fxe5 Bxe5 Bxe5 Qxe5 Qxe5 Rxe5 Rxe5 Rxe5 Re8 Rxe8 Kxe8 Kd2 Kf7 Ke3 Kg6 Kf4 c5 dxc5 bxc5 b4 cxb4 cxb4 Kxh6 a4 Kg5 a5 Kf6 a6 Ke7 a7 Kd7 Qa6 Kc7 Qb6+ Kd7 Qc6+ Ke7 Qd6+ Kf7 Qe6+ Kg7 Qf6+ Kh7 Qg6+ Kh8 Qg7# 1-0 e4 d5 f4 e5 dxe5 dxe5 fxe5 Bxe5 Bxe5 Qxe5 Qxe5 Rxe5 Re8 Rxe8 Kxe8 Kd2 Kf7 Ke3 Kg6 Kf4 c5 dxc5 bxc5 b4 cxb4 cxb4 Kxh6 a4 Kg5",
          "aggressive_tokens": {
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "f4",
            "e5",
            "dxe5",
            "dxe5",
            "fxe5",
            "Bxe5",
            "Bxe5",
            "Qxe5",
            "Qxe5",
            "Rxe5",
            "Re8",
            "Rxe8",
            "Kxe8",
            "Kd2",
            "Kf7",
            "Ke3",
            "Kg6",
            "Kf4",
            "c5",
            "dxc5",
            "bxc5",
            "b4",
            "cxb4",
            "cxb4",
            "Kxh6",
            "a4",
            "Kg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re1",
          "positional_uci": "g1e1",
          "positional_response": "32. Re1 Bd5 33. f4 Rf8 34. Rxf8 Kxf8 35. b3 b5 36. Kd2 Kf7 37. Ke3 Kg6 38. Kf2\nKf5 39. Kg3 Be4 40. Re2 d5 41. Rh2 Kg6 42. Kg4 Bf5+ 43. Kg3 Rh7 44. Re2 c6 45.\nRe1 a5 46. Re2 Ra7 47. Rh2 Kh7 48. Kh4 a4 49. b4 a3 50. Kh5 Bg6+ 51. Kg4 Rf7 52.\nRe2 Bf5+ 53. Kh5 Bg6+ 54. Kg4 Re7 55. Re5 Bf5+ 56. Kh5 Bg6+ 57. Kg4 Bf5+ 58.\nKh5 Bg6+ 59. Kg4 Bf5+ 60. Kh5 Bg6+ 61. Kg4 Bf5+ 62. Kh5 Bg6+ 63. Kg4 Bf5+ 64.\nKh5 Bg6+ 65. Kg4 Bf5+ 66. Kh5 Bg6+ 67. Kg4 Bf5+ 68. Kh5 Bg6+ 69. Kg4 Bf5+ 70.\nKh5 Bg6+ 71. Kg4 Bf5+ 72. Kh5 Bg6+ 73. Kg4 Bf5+ 74. Kh5 Bg6+ 75. Kg4 Bf5+ 76.\nKh5 Bg6+ 77. Kg4 Bf5+ 78. Kh5 Bg6+ 79. Kg4 Bf5+ 80. Kh5 Bg6+ 81. Kg4 Bf5+ 82.\nKh5 Bg6+ 83. Kg4 Bf5+ 84. Kh5 Bg6+ 85. Kg4 Bf5+ 86. Kh5 Bg6+ 87. Kg4 Bf5+ 88.\nKh5 Bg6+ 89. Kg4 Bf5+ 90. Kh5 Bg6+ 91. Kg4 Bf5+ 92. Kh5 Bg6+ 93. Kg4 Bf5+ 94.\nKh5 Bg6+ 95. Kg4 Bf5+ 96. Kh5 Bg6+ 97. Kg4 Bf5+ 98. Kh5 Bg6+ 99. Kg4 Bf5+ 100.\nKh5 Bg6+ 101. Kg4 Bf5+ 102. Kh5 Bg6+ 103. Kg4 Bf5+ 104. Kh5 Bg6+ 105. Kg4 Bf5+ 106.",
          "positional_tokens": {
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "a5",
            "Re2",
            "Ra7",
            "Rh2",
            "Kh7",
            "Kh4",
            "a4",
            "b4",
            "a3",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Rf7",
            "Re2",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Re7",
            "Re5",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+",
            "Kh5",
            "Bg6+",
            "Kg4",
            "Bf5+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rg3",
          "neutral_uci": "g1g3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Bc6 33. Kd2 Be8 34. Ke3 Bg6 35. f4 Bf5 36. Kf2 Rf8 37. Rxf8 Kxf8 38. Re3 Kf7 39. Kg3 Kg6 40. Kh4 Re8 41. Re1 c5 42. dxc5 bxc5 43. Rd1 d5 44. b4 cxb4 45. cxb4 Rc8 46. Rd4 Rc3 47. a4 Rh3#",
          "neutral_tokens": {
            "prompt_tokens": 368,
            "completion_tokens": 387,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc6",
            "Kd2",
            "Be8",
            "Ke3",
            "Bg6",
            "f4",
            "Bf5",
            "Kf2",
            "Rf8",
            "Rxf8",
            "Kxf8",
            "Re3",
            "Kf7",
            "Kg3",
            "Kg6",
            "Kh4",
            "Re8",
            "Re1",
            "c5",
            "dxc5",
            "bxc5",
            "Rd1",
            "d5",
            "b4",
            "cxb4",
            "cxb4",
            "Rc8",
            "Rd4",
            "Rc3",
            "a4",
            "Rh3#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g1e1",
          "neutral_uci": "g1g3",
          "consensus_move": "g1g3",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "f4",
              "e5",
              "dxe5",
              "dxe5",
              "fxe5",
              "Bxe5",
              "Bxe5",
              "Qxe5",
              "Qxe5",
              "Rxe5",
              "Re8",
              "Rxe8",
              "Kxe8",
              "Kd2",
              "Kf7",
              "Ke3",
              "Kg6",
              "Kf4",
              "c5",
              "dxc5",
              "bxc5",
              "b4",
              "cxb4",
              "cxb4",
              "Kxh6",
              "a4",
              "Kg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "a5",
              "Re2",
              "Ra7",
              "Rh2",
              "Kh7",
              "Kh4",
              "a4",
              "b4",
              "a3",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Rf7",
              "Re2",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Re7",
              "Re5",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+",
              "Kh5",
              "Bg6+",
              "Kg4",
              "Bf5+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bc6",
              "Kd2",
              "Be8",
              "Ke3",
              "Bg6",
              "f4",
              "Bf5",
              "Kf2",
              "Rf8",
              "Rxf8",
              "Kxf8",
              "Re3",
              "Kf7",
              "Kg3",
              "Kg6",
              "Kh4",
              "Re8",
              "Re1",
              "c5",
              "dxc5",
              "bxc5",
              "Rd1",
              "d5",
              "b4",
              "cxb4",
              "cxb4",
              "Rc8",
              "Rd4",
              "Rc3",
              "a4",
              "Rh3#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 368,
            "completion_tokens": 387,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1106,
          "total_completion_tokens": 1667,
          "total_tokens": 2773
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 369,
            "completion_tokens": 640,
            "total_tokens": 1009,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 62,
            "turn_number": 32,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 368,
            "completion_tokens": 387,
            "total_tokens": 755,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6rr/1bp1k3/pp1ppR1P/6P1/3P4/2P5/PP3P2/2K3R1 w - - 4 32"
    },
    {
      "turn": 65,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxg5",
          "aggressive_uci": "g3g5",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33. Rxg5 Kxf6 34. Rg7 Rxh6 35. Rxc7 Bd5 36. c4 Be4 37. Ra7 Rh2 38. Rxa6 Rxf2 39. Rxb6 Rc2+ 40. Kd1 Rxc4 41. Rxd6 Bd5 42. b3 Rxd4+ 43. Kc1 Ke5 44. Rd8 Rh4 45. Kb2 Kd4 46. a4 Rh2+ 47. Ka3 Rh3 48. Rb8 e5 49. a5 e4 50. a6 e3 51. a7 e2 52. Re8 Re3 53. Rd8 e1=Q 54. a8=Q Qa1+ 55. Kb4 Qxa8 56. Rxa8 Bxa8 57. Ka4 Kc5 58. b4+ Kc4 59. Ka5 Ra3+ 60. Kb6 Kxb4 61. Kc7 Kc5 62. Kd7 Ra6 63. Ke7 Kd5 64. Kf7 Ke5 65. Kg7 Kf5 66. Kh7 Kg5 67. Kg7 Ra7+ 68. Kf8 Kf6 69. Ke8 Bc6+ 70. Kd8 Ke6 71. Kc8 Kd6 72. Kb8 Ra8# 0-1\nd4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7",
          "aggressive_tokens": {
            "prompt_tokens": 378,
            "completion_tokens": 640,
            "total_tokens": 1018,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxf6",
            "Rg7",
            "Rxh6",
            "Rxc7",
            "Bd5",
            "c4",
            "Be4",
            "Ra7",
            "Rh2",
            "Rxa6",
            "Rxf2",
            "Rxb6",
            "Rc2+",
            "Kd1",
            "Rxc4",
            "Rxd6",
            "Bd5",
            "b3",
            "Rxd4+",
            "Kc1",
            "Ke5",
            "Rd8",
            "Rh4",
            "Kb2",
            "Kd4",
            "a4",
            "Rh2+",
            "Ka3",
            "Rh3",
            "Rb8",
            "e5",
            "a5",
            "e4",
            "a6",
            "e3",
            "a7",
            "e2",
            "Re8",
            "Re3",
            "Rd8",
            "e1=Q",
            "a8=Q",
            "Qa1+",
            "Kb4",
            "Qxa8",
            "Rxa8",
            "Bxa8",
            "Ka4",
            "Kc5",
            "b4+",
            "Kc4",
            "Ka5",
            "Ra3+",
            "Kb6",
            "Kxb4",
            "Kc7",
            "Kc5",
            "Kd7",
            "Ra6",
            "Ke7",
            "Kd5",
            "Kf7",
            "Ke5",
            "Kg7",
            "Kf5",
            "Kh7",
            "Kg5",
            "Kg7",
            "Ra7+",
            "Kf8",
            "Kf6",
            "Ke8",
            "Bc6+",
            "Kd8",
            "Ke6",
            "Kc8",
            "Kd6",
            "Kb8",
            "Ra8#",
            "d4",
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxg5",
          "positional_uci": "g3g5",
          "positional_response": "33. Rxg5 Kxf6 34. Rg7 Rc8 35. Rd7 Bc6 36. Rg7 Be4 37. Kd2 Bg6 38. Ke3 Kg5 39. h7\nKf6 40. Rd7 Bf7 41. Kf4 Kg7 42. Kg5 Rf8 43. Rxc7 Kxh7 44. Kf6 Kg8 45. Ke7 e5\n46. Kxd6 exd4 47. cxd4 Bxa2 48. Rc6 Rf6+ 49. Kc7 Rxc6+ 50. Kxc6 b5 51. Kb6 Bc4\n52. Kxa6 Kf7 53. Kb6 Ke6 54. Kc5 Kf5 55. d5 Ke5 56. d6 Ke6 57. Kc6 Bd5+ 58. Kc7\nBc6 59. Kxc6 b4 60. d7 b3 61. d8=Q Ke5 62. Qd3 Kf4 63. Qxb3 Ke4 64. Qe3+ Kf5\n65. Kd5 Kf6 66. Qe5+ Kf7 67. Qe6+ Kg7 68. Ke5 Kf8 69. Qd7 Kg8 70. Kf6 Kh8 71.\nQg7# Kd8 72. Ke6 Kc8 73. Kd6 Kb8 74. Kc6 Ka8 75. Qb7# Kd8 76. Qd7# Kxd7 77.\nKb7 Kd6 78. b4 Kd5 79. b5 Kc5 80. b6 Kb5 81. Kc7 Ka6 82. b7 Ka7 83. b8=Q+ Ka6",
          "positional_tokens": {
            "prompt_tokens": 378,
            "completion_tokens": 432,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kxf6",
            "Rg7",
            "Rc8",
            "Rd7",
            "Bc6",
            "Rg7",
            "Be4",
            "Kd2",
            "Bg6",
            "Ke3",
            "Kg5",
            "h7",
            "Kf6",
            "Rd7",
            "Bf7",
            "Kf4",
            "Kg7",
            "Kg5",
            "Rf8",
            "Rxc7",
            "Kxh7",
            "Kf6",
            "Kg8",
            "Ke7",
            "e5",
            "Kxd6",
            "exd4",
            "cxd4",
            "Bxa2",
            "Rc6",
            "Rf6+",
            "Kc7",
            "Rxc6+",
            "Kxc6",
            "b5",
            "Kb6",
            "Bc4",
            "Kxa6",
            "Kf7",
            "Kb6",
            "Ke6",
            "Kc5",
            "Kf5",
            "d5",
            "Ke5",
            "d6",
            "Ke6",
            "Kc6",
            "Bd5+",
            "Kc7",
            "Bc6",
            "Kxc6",
            "b4",
            "d7",
            "b3",
            "d8=Q",
            "Ke5",
            "Qd3",
            "Kf4",
            "Qxb3",
            "Ke4",
            "Qe3+",
            "Kf5",
            "Kd5",
            "Kf6",
            "Qe5+",
            "Kf7",
            "Qe6+",
            "Kg7",
            "Ke5",
            "Kf8",
            "Qd7",
            "Kg8",
            "Kf6",
            "Kh8",
            "Qg7#",
            "Kd8",
            "Ke6",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kxd7",
            "Kb7",
            "Kd6",
            "b4",
            "Kd5",
            "b5",
            "Kc5",
            "b6",
            "Kb5",
            "Kc7",
            "Ka6",
            "b7",
            "Ka7",
            "b8=Q+",
            "Ka6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxg5",
          "neutral_uci": "g3g5",
          "neutral_response": "33. Rxg5 Kxf6 34. Rg7 Rc8 35. Kd2 Be4 36. Ke3 Bf5 37. Kf4 e5+ 38. dxe5+ dxe5+ 39. Ke3 a5 40. f4 exf4+ 41. Kxf4 c6 42. Rb7 b5 43. Ra7 a4 44. b3 axb3 45. axb3 Bc2 46. c4 bxc4 47. bxc4 Kg6 48. h7 Rh8 49. Rc7 Ba4 50. Ke5 Rxh7 51. Rxh7 Kxh7 52. Kd6 Kg6 53. Kc5 Kf5 54. Kb4 Bd1 55. Kc5 Bf3 56. Kd4 Kf4 57. Kc5 Ke3 58. Kb4 Kd4 59. Kb3 Be2 60. Kb4 Bxc4 61. Ka3 Kc3 62. Ka4 c5 63. Ka3 Bb5 64. Ka2 c4 65. Kb1 Kd2 66. Kb2 c3+ 67. Kb3 c2 68. Kb4 c1=Q 69. Kxb5 Kd3 70. Kb4 Qc4+ 71. Ka5 Qb3 72. Ka6 Kc4 73. Ka7 Kc5 74. Ka8 Kc6 75. Ka7 Qb7# 1-0\nd4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 * 33. Rxg5 Kxf6 34. Rg7 Rc8",
          "neutral_tokens": {
            "prompt_tokens": 377,
            "completion_tokens": 640,
            "total_tokens": 1017,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kxf6",
            "Rg7",
            "Rc8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g3g5",
          "positional_uci": "g3g5",
          "neutral_uci": "g3g5",
          "consensus_move": "g3g5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kxf6",
              "Rg7",
              "Rxh6",
              "Rxc7",
              "Bd5",
              "c4",
              "Be4",
              "Ra7",
              "Rh2",
              "Rxa6",
              "Rxf2",
              "Rxb6",
              "Rc2+",
              "Kd1",
              "Rxc4",
              "Rxd6",
              "Bd5",
              "b3",
              "Rxd4+",
              "Kc1",
              "Ke5",
              "Rd8",
              "Rh4",
              "Kb2",
              "Kd4",
              "a4",
              "Rh2+",
              "Ka3",
              "Rh3",
              "Rb8",
              "e5",
              "a5",
              "e4",
              "a6",
              "e3",
              "a7",
              "e2",
              "Re8",
              "Re3",
              "Rd8",
              "e1=Q",
              "a8=Q",
              "Qa1+",
              "Kb4",
              "Qxa8",
              "Rxa8",
              "Bxa8",
              "Ka4",
              "Kc5",
              "b4+",
              "Kc4",
              "Ka5",
              "Ra3+",
              "Kb6",
              "Kxb4",
              "Kc7",
              "Kc5",
              "Kd7",
              "Ra6",
              "Ke7",
              "Kd5",
              "Kf7",
              "Ke5",
              "Kg7",
              "Kf5",
              "Kh7",
              "Kg5",
              "Kg7",
              "Ra7+",
              "Kf8",
              "Kf6",
              "Ke8",
              "Bc6+",
              "Kd8",
              "Ke6",
              "Kc8",
              "Kd6",
              "Kb8",
              "Ra8#",
              "d4",
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kxf6",
              "Rg7",
              "Rc8",
              "Rd7",
              "Bc6",
              "Rg7",
              "Be4",
              "Kd2",
              "Bg6",
              "Ke3",
              "Kg5",
              "h7",
              "Kf6",
              "Rd7",
              "Bf7",
              "Kf4",
              "Kg7",
              "Kg5",
              "Rf8",
              "Rxc7",
              "Kxh7",
              "Kf6",
              "Kg8",
              "Ke7",
              "e5",
              "Kxd6",
              "exd4",
              "cxd4",
              "Bxa2",
              "Rc6",
              "Rf6+",
              "Kc7",
              "Rxc6+",
              "Kxc6",
              "b5",
              "Kb6",
              "Bc4",
              "Kxa6",
              "Kf7",
              "Kb6",
              "Ke6",
              "Kc5",
              "Kf5",
              "d5",
              "Ke5",
              "d6",
              "Ke6",
              "Kc6",
              "Bd5+",
              "Kc7",
              "Bc6",
              "Kxc6",
              "b4",
              "d7",
              "b3",
              "d8=Q",
              "Ke5",
              "Qd3",
              "Kf4",
              "Qxb3",
              "Ke4",
              "Qe3+",
              "Kf5",
              "Kd5",
              "Kf6",
              "Qe5+",
              "Kf7",
              "Qe6+",
              "Kg7",
              "Ke5",
              "Kf8",
              "Qd7",
              "Kg8",
              "Kf6",
              "Kh8",
              "Qg7#",
              "Kd8",
              "Ke6",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kxd7",
              "Kb7",
              "Kd6",
              "b4",
              "Kd5",
              "b5",
              "Kc5",
              "b6",
              "Kb5",
              "Kc7",
              "Ka6",
              "b7",
              "Ka7",
              "b8=Q+",
              "Ka6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kxf6",
              "Rg7",
              "Rc8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 378,
            "completion_tokens": 640,
            "total_tokens": 1018,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 378,
            "completion_tokens": 432,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 377,
            "completion_tokens": 640,
            "total_tokens": 1017,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1133,
          "total_completion_tokens": 1712,
          "total_tokens": 2845
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 378,
            "completion_tokens": 640,
            "total_tokens": 1018,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 378,
            "completion_tokens": 432,
            "total_tokens": 810,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 64,
            "turn_number": 33,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 377,
            "completion_tokens": 640,
            "total_tokens": 1017,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "7r/1bp1k3/pp1ppR1P/6r1/3P4/2P3R1/PP3P2/2K5 w - - 0 33"
    },
    {
      "turn": 67,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rg7",
          "aggressive_uci": "g5g7",
          "aggressive_response": "34. Rg7 Rxh6 35. Rxc7 Be4 36. Ra7 Bd3 37. Kd2 Bf1 38. Rb7 Rh2 39. Ke1 Rh1 40.\nRxb6 Bc4+ 41. Kd2 Bxa2 42. Rxa6 Bc4 43. Rxd6 Rf1 44. Ke3 Re1+ 45. Kf3 Kf5 46.\nRd8 Bd5+ 47. Kg3 Rg1+ 48. Kh3 Kf4 49. Rf8+ Ke4 50. Kh2 Rb1 51. b4 Kd3 52. Rc8\nKe2 53. Kg3 Rg1+ 54. Kf4 Kxf2 55. c4 Bf3 56. Ke5 Re1+ 57. Kd6 Ke3 58. Kxe6 Kxd4+\n59. Kd6 Rb1 60. b5 Be2 61. Rc7 Bxc4 62. Kc6 Bxb5+ 63. Kd6 Bc4 64. Rc8 Rb6+ 65.\nKc7 Kc5 66. Rb8 Rh6 67. Rd8 Bd5 68. Rf8 Rh7+ 69. Kd8 Kd6 70. Rf6+ Be6 71. Rf8\nRa7 72. Ke8 Ra8# e4 d5 c4",
          "aggressive_tokens": {
            "prompt_tokens": 387,
            "completion_tokens": 338,
            "total_tokens": 725,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxh6",
            "Rxc7",
            "Be4",
            "Ra7",
            "Bd3",
            "Kd2",
            "Bf1",
            "Rb7",
            "Rh2",
            "Ke1",
            "Rh1",
            "Rxb6",
            "Bc4+",
            "Kd2",
            "Bxa2",
            "Rxa6",
            "Bc4",
            "Rxd6",
            "Rf1",
            "Ke3",
            "Re1+",
            "Kf3",
            "Kf5",
            "Rd8",
            "Bd5+",
            "Kg3",
            "Rg1+",
            "Kh3",
            "Kf4",
            "Rf8+",
            "Ke4",
            "Kh2",
            "Rb1",
            "b4",
            "Kd3",
            "Rc8",
            "Ke2",
            "Kg3",
            "Rg1+",
            "Kf4",
            "Kxf2",
            "c4",
            "Bf3",
            "Ke5",
            "Re1+",
            "Kd6",
            "Ke3",
            "Kxe6",
            "Kxd4+",
            "Kd6",
            "Rb1",
            "b5",
            "Be2",
            "Rc7",
            "Bxc4",
            "Kc6",
            "Bxb5+",
            "Kd6",
            "Bc4",
            "Rc8",
            "Rb6+",
            "Kc7",
            "Kc5",
            "Rb8",
            "Rh6",
            "Rd8",
            "Bd5",
            "Rf8",
            "Rh7+",
            "Kd8",
            "Kd6",
            "Rf6+",
            "Be6",
            "Rf8",
            "Ra7",
            "Ke8",
            "Ra8#",
            "e4",
            "d5",
            "c4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ra1#",
          "positional_uci": null,
          "positional_response": "Re8 35. Rg7 Re7 36. Rg8 Rh7 37. Rb8 Bf3 38. Rf8+ Rf7 39. Rh8 Kg6\n40. Kd2 Rh7 41. Rf8 Bd5 42. b3 Rxh6 43. c4 Bc6 44. Rc8 Rh7 45. Ke3 Kf5 46. Rf8+\nKg6 47. Rc8 Rf7 48. f4 Kf5 49. Rg8 Kf6 50. Rc8 Bb7 51. Rb8 c5 52. dxc5 dxc5\n53. Rd8 Ke7 54. Rb8 Kd6 55. Rd8+ Kc7 56. Re8 Bc8 57. Ke4 Bd7 58. Ra8 Kb7 59.\nRd8 b5 60. cxb5 axb5 61. Ke5 Kc7 62. Ra8 Rf5+ 63. Ke4 Bc6+ 64. Ke3 Bxa8 65.\na4 bxa4 66. bxa4 Kb6 67. Kd3 Rxf4 68. Kc3 Rxa4 69. Kb3 Kb5 70. Kc3 Ra3+ 71.\nKb2 Kb4 72. Kc2 Be4+ 73. Kb2 c4 74. Kc1 Kc3 75. Kd1 Bd3 76. Ke1 Ra2 77. Kd1\nRa1# 0-1",
          "positional_tokens": {
            "prompt_tokens": 387,
            "completion_tokens": 361,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rg7",
          "neutral_uci": "g5g7",
          "neutral_response": "34. Rg7 Rxh6 35. Rxc7 Be4 36. Ra7 Rh2 37. Rxa6 Rxf2 38. Rxb6 Rc2+ 39. Kd1\nd5 40. a4 Rh2 41. a5 Bd3 42. a6 Rh1+ 43. Kd2 Bc4 44. a7 Ra1 45. Rb7 Kf5 46.\nb3 Ra2+ 47. Kc1 Bd3 48. b4 Ke4 49. b5 Ke3 50. b6 Rc2+ 51. Kd1 Rb2 52. Kc1\nRb1# Kd2 Rb2+ Kc1 Rb1#",
          "neutral_tokens": {
            "prompt_tokens": 386,
            "completion_tokens": 170,
            "total_tokens": 556,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxh6",
            "Rxc7",
            "Be4",
            "Ra7",
            "Rh2",
            "Rxa6",
            "Rxf2",
            "Rxb6",
            "Rc2+",
            "Kd1",
            "d5",
            "a4",
            "Rh2",
            "a5",
            "Bd3",
            "a6",
            "Rh1+",
            "Kd2",
            "Bc4",
            "a7",
            "Ra1",
            "Rb7",
            "Kf5",
            "b3",
            "Ra2+",
            "Kc1",
            "Bd3",
            "b4",
            "Ke4",
            "b5",
            "Ke3",
            "b6",
            "Rc2+",
            "Kd1",
            "Rb2",
            "Kc1",
            "Rb1#",
            "Kd2",
            "Rb2+",
            "Kc1",
            "Rb1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g5g7",
          "positional_uci": null,
          "neutral_uci": "g5g7",
          "consensus_move": "g5g7",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxh6",
              "Rxc7",
              "Be4",
              "Ra7",
              "Bd3",
              "Kd2",
              "Bf1",
              "Rb7",
              "Rh2",
              "Ke1",
              "Rh1",
              "Rxb6",
              "Bc4+",
              "Kd2",
              "Bxa2",
              "Rxa6",
              "Bc4",
              "Rxd6",
              "Rf1",
              "Ke3",
              "Re1+",
              "Kf3",
              "Kf5",
              "Rd8",
              "Bd5+",
              "Kg3",
              "Rg1+",
              "Kh3",
              "Kf4",
              "Rf8+",
              "Ke4",
              "Kh2",
              "Rb1",
              "b4",
              "Kd3",
              "Rc8",
              "Ke2",
              "Kg3",
              "Rg1+",
              "Kf4",
              "Kxf2",
              "c4",
              "Bf3",
              "Ke5",
              "Re1+",
              "Kd6",
              "Ke3",
              "Kxe6",
              "Kxd4+",
              "Kd6",
              "Rb1",
              "b5",
              "Be2",
              "Rc7",
              "Bxc4",
              "Kc6",
              "Bxb5+",
              "Kd6",
              "Bc4",
              "Rc8",
              "Rb6+",
              "Kc7",
              "Kc5",
              "Rb8",
              "Rh6",
              "Rd8",
              "Bd5",
              "Rf8",
              "Rh7+",
              "Kd8",
              "Kd6",
              "Rf6+",
              "Be6",
              "Rf8",
              "Ra7",
              "Ke8",
              "Ra8#",
              "e4",
              "d5",
              "c4"
            ],
            "execute": []
          },
          "positional": {
            "full": [],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxh6",
              "Rxc7",
              "Be4",
              "Ra7",
              "Rh2",
              "Rxa6",
              "Rxf2",
              "Rxb6",
              "Rc2+",
              "Kd1",
              "d5",
              "a4",
              "Rh2",
              "a5",
              "Bd3",
              "a6",
              "Rh1+",
              "Kd2",
              "Bc4",
              "a7",
              "Ra1",
              "Rb7",
              "Kf5",
              "b3",
              "Ra2+",
              "Kc1",
              "Bd3",
              "b4",
              "Ke4",
              "b5",
              "Ke3",
              "b6",
              "Rc2+",
              "Kd1",
              "Rb2",
              "Kc1",
              "Rb1#",
              "Kd2",
              "Rb2+",
              "Kc1",
              "Rb1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 387,
            "completion_tokens": 338,
            "total_tokens": 725,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 387,
            "completion_tokens": 361,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 386,
            "completion_tokens": 170,
            "total_tokens": 556,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1160,
          "total_completion_tokens": 869,
          "total_tokens": 2029
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 387,
            "completion_tokens": 338,
            "total_tokens": 725,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 387,
            "completion_tokens": 361,
            "total_tokens": 748,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 66,
            "turn_number": 34,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 386,
            "completion_tokens": 170,
            "total_tokens": 556,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "7r/1bp5/pp1ppk1P/6R1/3P4/2P5/PP3P2/2K5 w - - 0 34"
    },
    {
      "turn": 69,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxc7",
          "aggressive_uci": "g7c7",
          "aggressive_response": "35. Rxc7 Rxh6 36. Ra7 Rh2 37. Rxa6 Rxf2 38. Rxb6 Rc2+ 39. Kd1 Ke7 40. a4 Kd7 41. a5 Kc7 42. Rb4 Rh2 43. a6 Rh8 44. Kd2 Ra8 45. Ra4 Kb6 46. Ke3 Bc6 47. Ra3 Rxa6 48. Rxa6+ Kxa6 49. c4 Ka5 50. Kd3 Kb4 51. c5 d5 52. Kc2 Kc4 53. b3+ Kxd4 54. b4 Kc4 55. b5 Bxb5 56. c6 Bxc6 57. Kd2 d4 58. Kc2 d3+ 59. Kd2 Kd4 60. Kd1 Ke3 61. Ke1 d2+ 62. Kd1 Ba4#",
          "aggressive_tokens": {
            "prompt_tokens": 395,
            "completion_tokens": 229,
            "total_tokens": 624,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxh6",
            "Ra7",
            "Rh2",
            "Rxa6",
            "Rxf2",
            "Rxb6",
            "Rc2+",
            "Kd1",
            "Ke7",
            "a4",
            "Kd7",
            "a5",
            "Kc7",
            "Rb4",
            "Rh2",
            "a6",
            "Rh8",
            "Kd2",
            "Ra8",
            "Ra4",
            "Kb6",
            "Ke3",
            "Bc6",
            "Ra3",
            "Rxa6",
            "Rxa6+",
            "Kxa6",
            "c4",
            "Ka5",
            "Kd3",
            "Kb4",
            "c5",
            "d5",
            "Kc2",
            "Kc4",
            "b3+",
            "Kxd4",
            "b4",
            "Kc4",
            "b5",
            "Bxb5",
            "c6",
            "Bxc6",
            "Kd2",
            "d4",
            "Kc2",
            "d3+",
            "Kd2",
            "Kd4",
            "Kd1",
            "Ke3",
            "Ke1",
            "d2+",
            "Kd1",
            "Ba4#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Nf6 Rg8 Rxg8 Kxf6 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg7 Bc8 Rg8 Bc8 Rg",
          "positional_tokens": {
            "prompt_tokens": 395,
            "completion_tokens": 640,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Nf6",
            "Rg8",
            "Rxg8",
            "Kxf6",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8",
            "Rg7",
            "Bc8",
            "Rg8",
            "Bc8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxc7",
          "neutral_uci": "g7c7",
          "neutral_response": "35. Rxc7 Rxh6 36. Ra7 Rh1+ 37. Kd2 Rb1 38. Ke3 d5 39.\nRxa6 Rxb2 40. a4 Rb3 41. Kd2 Kf5 42. a5 bxa5 43. Rxa5 Rb2+ 44. Ke3 Rc2 45. Rc5\nKg4 46. Rc6 Bf5 47. Rc8 Kh3 48. Kf3 Kh2 49. Rh8+ Kg1 50. Rg8+ Kf1 51. Ke3 Rxc3+\n52. Kd2 Rd3+ 53. Kc1 Rxd4 54. Rg3 Kxf2 55. Rc3 Rc4 56. Rxc4 dxc4 57. Kd2 e5\n58. Kc3 e4 59. Kxc4 e3 60. Kd4 e2 61. Ke5 e1=Q+ 62. Kxf5 Qe3 63. Kg4 Qf3+ 64.\nKg5 Ke3 65. Kg6 Ke4 66. Kg5 Qf4+ 67. Kg6 Ke5 68. Kg7 Qf6+ 69. Kg8 Qe7 70. Kh8\nKf6 71. Kg8 Qg7# 72. Kxg7 * 72... Kg5 73. Kf7 Kf5 74. Ke7 Ke5 75. Kd7 Kd5 76.\nKc7 Kc5 77. Kb7 Kb5 78. Ka7 Ka5 79. Kb7 Kb5 80. Ka7 Ka5 81. Kb7 Kb5 82. Ka7\nKc6 83. Kb8 Kb6 84. Ka8 Kc7 85. Ka7 Kc6 86. Ka6 Kc5 87. Ka5 Kc4 88. Ka4 Kc3 89.\nKa3 Kc2 90. Ka2 Kc1 91. Ka1 Kc2 92. Ka2 Kc3 93. Ka3 Kc4 94. Ka4 Kc5 95. Ka5\nKc6 96. Ka6 Kc7 97. Ka7 Kc8 98. Ka8 Kc7 99. Ka7 Kc6 100. Ka6 Kc5 101. Ka5 Kc4\n102. Ka4 Kc3 103. Ka3 Kc2 104. Ka2 Kc1 105. Ka1 Kc2 106. Ka2 Kc3 107. Ka3 Kc4\n108. Ka4 Kc5 109. Ka5 Kc6 110. Ka6 Kc7 111. Ka7 Kc8 112. Ka8 K",
          "neutral_tokens": {
            "prompt_tokens": 394,
            "completion_tokens": 640,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Ra7",
            "Rh1+",
            "Kd2",
            "Rb1",
            "Ke3",
            "d5",
            "Rxa6",
            "Rxb2",
            "a4",
            "Rb3",
            "Kd2",
            "Kf5",
            "a5",
            "bxa5",
            "Rxa5",
            "Rb2+",
            "Ke3",
            "Rc2",
            "Rc5",
            "Kg4",
            "Rc6",
            "Bf5",
            "Rc8",
            "Kh3",
            "Kf3",
            "Kh2",
            "Rh8+",
            "Kg1",
            "Rg8+",
            "Kf1",
            "Ke3",
            "Rxc3+",
            "Kd2",
            "Rd3+",
            "Kc1",
            "Rxd4",
            "Rg3",
            "Kxf2",
            "Rc3",
            "Rc4",
            "Rxc4",
            "dxc4",
            "Kd2",
            "e5",
            "Kc3",
            "e4",
            "Kxc4",
            "e3",
            "Kd4",
            "e2",
            "Ke5",
            "e1=Q+",
            "Kxf5",
            "Qe3",
            "Kg4",
            "Qf3+",
            "Kg5",
            "Ke3",
            "Kg6",
            "Ke4",
            "Kg5",
            "Qf4+",
            "Kg6",
            "Ke5",
            "Kg7",
            "Qf6+",
            "Kg8",
            "Qe7",
            "Kh8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "Kxg7",
            "Kg5",
            "Kf7",
            "Kf5",
            "Ke7",
            "Ke5",
            "Kd7",
            "Kd5",
            "Kc7",
            "Kc5",
            "Kb7",
            "Kb5",
            "Ka7",
            "Ka5",
            "Kb7",
            "Kb5",
            "Ka7",
            "Ka5",
            "Kb7",
            "Kb5",
            "Ka7",
            "Kc6",
            "Kb8",
            "Kb6",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc6",
            "Ka6",
            "Kc5",
            "Ka5",
            "Kc4",
            "Ka4",
            "Kc3",
            "Ka3",
            "Kc2",
            "Ka2",
            "Kc1",
            "Ka1",
            "Kc2",
            "Ka2",
            "Kc3",
            "Ka3",
            "Kc4",
            "Ka4",
            "Kc5",
            "Ka5",
            "Kc6",
            "Ka6",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8",
            "Kc7",
            "Ka7",
            "Kc6",
            "Ka6",
            "Kc5",
            "Ka5",
            "Kc4",
            "Ka4",
            "Kc3",
            "Ka3",
            "Kc2",
            "Ka2",
            "Kc1",
            "Ka1",
            "Kc2",
            "Ka2",
            "Kc3",
            "Ka3",
            "Kc4",
            "Ka4",
            "Kc5",
            "Ka5",
            "Kc6",
            "Ka6",
            "Kc7",
            "Ka7",
            "Kc8",
            "Ka8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g7c7",
          "positional_uci": null,
          "neutral_uci": "g7c7",
          "consensus_move": "g7c7",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxh6",
              "Ra7",
              "Rh2",
              "Rxa6",
              "Rxf2",
              "Rxb6",
              "Rc2+",
              "Kd1",
              "Ke7",
              "a4",
              "Kd7",
              "a5",
              "Kc7",
              "Rb4",
              "Rh2",
              "a6",
              "Rh8",
              "Kd2",
              "Ra8",
              "Ra4",
              "Kb6",
              "Ke3",
              "Bc6",
              "Ra3",
              "Rxa6",
              "Rxa6+",
              "Kxa6",
              "c4",
              "Ka5",
              "Kd3",
              "Kb4",
              "c5",
              "d5",
              "Kc2",
              "Kc4",
              "b3+",
              "Kxd4",
              "b4",
              "Kc4",
              "b5",
              "Bxb5",
              "c6",
              "Bxc6",
              "Kd2",
              "d4",
              "Kc2",
              "d3+",
              "Kd2",
              "Kd4",
              "Kd1",
              "Ke3",
              "Ke1",
              "d2+",
              "Kd1",
              "Ba4#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Nf6",
              "Rg8",
              "Rxg8",
              "Kxf6",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8",
              "Rg7",
              "Bc8",
              "Rg8",
              "Bc8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxh6",
              "Ra7",
              "Rh1+",
              "Kd2",
              "Rb1",
              "Ke3",
              "d5",
              "Rxa6",
              "Rxb2",
              "a4",
              "Rb3",
              "Kd2",
              "Kf5",
              "a5",
              "bxa5",
              "Rxa5",
              "Rb2+",
              "Ke3",
              "Rc2",
              "Rc5",
              "Kg4",
              "Rc6",
              "Bf5",
              "Rc8",
              "Kh3",
              "Kf3",
              "Kh2",
              "Rh8+",
              "Kg1",
              "Rg8+",
              "Kf1",
              "Ke3",
              "Rxc3+",
              "Kd2",
              "Rd3+",
              "Kc1",
              "Rxd4",
              "Rg3",
              "Kxf2",
              "Rc3",
              "Rc4",
              "Rxc4",
              "dxc4",
              "Kd2",
              "e5",
              "Kc3",
              "e4",
              "Kxc4",
              "e3",
              "Kd4",
              "e2",
              "Ke5",
              "e1=Q+",
              "Kxf5",
              "Qe3",
              "Kg4",
              "Qf3+",
              "Kg5",
              "Ke3",
              "Kg6",
              "Ke4",
              "Kg5",
              "Qf4+",
              "Kg6",
              "Ke5",
              "Kg7",
              "Qf6+",
              "Kg8",
              "Qe7",
              "Kh8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "Kxg7",
              "Kg5",
              "Kf7",
              "Kf5",
              "Ke7",
              "Ke5",
              "Kd7",
              "Kd5",
              "Kc7",
              "Kc5",
              "Kb7",
              "Kb5",
              "Ka7",
              "Ka5",
              "Kb7",
              "Kb5",
              "Ka7",
              "Ka5",
              "Kb7",
              "Kb5",
              "Ka7",
              "Kc6",
              "Kb8",
              "Kb6",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc6",
              "Ka6",
              "Kc5",
              "Ka5",
              "Kc4",
              "Ka4",
              "Kc3",
              "Ka3",
              "Kc2",
              "Ka2",
              "Kc1",
              "Ka1",
              "Kc2",
              "Ka2",
              "Kc3",
              "Ka3",
              "Kc4",
              "Ka4",
              "Kc5",
              "Ka5",
              "Kc6",
              "Ka6",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8",
              "Kc7",
              "Ka7",
              "Kc6",
              "Ka6",
              "Kc5",
              "Ka5",
              "Kc4",
              "Ka4",
              "Kc3",
              "Ka3",
              "Kc2",
              "Ka2",
              "Kc1",
              "Ka1",
              "Kc2",
              "Ka2",
              "Kc3",
              "Ka3",
              "Kc4",
              "Ka4",
              "Kc5",
              "Ka5",
              "Kc6",
              "Ka6",
              "Kc7",
              "Ka7",
              "Kc8",
              "Ka8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 395,
            "completion_tokens": 229,
            "total_tokens": 624,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 395,
            "completion_tokens": 640,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 394,
            "completion_tokens": 640,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1184,
          "total_completion_tokens": 1509,
          "total_tokens": 2693
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 395,
            "completion_tokens": 229,
            "total_tokens": 624,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 395,
            "completion_tokens": 640,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 68,
            "turn_number": 35,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 394,
            "completion_tokens": 640,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "7r/2p3R1/pp1ppk1P/8/3Pb3/2P5/PP3P2/2K5 w - - 2 35"
    },
    {
      "turn": 71,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ra7",
          "aggressive_uci": "c7a7",
          "aggressive_response": "36. Ra7 Rxh6 37. Rxa6 Rh1+ 38. Kd2 Rb1 39.\nb3 Rb2+ 40. Ke3 Bb1 41. Rxd6 Bxa2 42. d5 Bxb3 43. Rxe6+ Kf5 44. Rd6 Bc4 45.\nRd8 Re2+ 46. Kd4 Rd2+ 47. Kc5 Ke5 48. Re8+ Kf6 49. d6 Rd5+ 50. Kc6 Rd3 51. d7\nRxc3 52. d8=Q+ Kf5 53. Rf8+ Ke4 54. Qh4+ Kd3 55. Rf3+ Kc2 56. Qe4+ Kb3 57.\nRxc3+ Kxc3 58. Kc5 Kb3 59. Qb1+ Kc3 60. Qb4+ Kd3 61. Qe1 Kc2 62. Kb4 Kd3 63.\nQe3+ Kc2 64. Qc3+ Kd1 65. Qb2 Ke1 66. f4 Kd1 67. Kc3 Ke1 68. Qg2 Kd1 69. Qd2#\n1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 * 36. Ra7 Rxh6 37. Rxa6 Rh1+ 38. Kd2 Rb1 39.\nb3 Rb2+ 40. Ke3 Bb1",
          "aggressive_tokens": {
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Rxa6",
            "Rh1+",
            "Kd2",
            "Rb1",
            "b3",
            "Rb2+",
            "Ke3",
            "Bb1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ra7",
          "positional_uci": "c7a7",
          "positional_response": "36. Ra7 Rxh6 37. Rxa6 Rh1+ 38. Kd2 Rb1 39. b3 Rb2+ 40. Ke3 Bb1 41. Rxd6 Bxa2 42. d5 Bxb3 43. Rxe6+ Kf5 44. Rd6 Bc4 45. Rd8 Re2+ 46. Kd4 Rd2+ 47. Kc5 Ke5 48. Re8+ Kf6 49. d6 Rd5+ 50. Kc6 Rd3 51. d7 Bd5+ 52. Kxb5 Bf7 53. d8=Q+ Rxd8 54. Rxd8 Ke7 55. Rd4 Be8+ 56. Kb6 Ke6 57. c4 Ke5 58. Rd8 Bf7 59. c5 Bd5 60. c6 Bxc6 61. Kxc6 Ke4 62. Kc5 Kf3 63. Re8 Kxf2 64. Kd4 Kf3 65. Re7 Kf4 66. Rf7+ Kg5 67. Ke4 Kg6 68. Rf1 Kg5 69. Rf2 Kg6 70. Ke5 Kg7 71. Ke6 Kg8 72. Ke7 Kg7 73. Rg2+ Kh6 74. Kf7 Kh5 75. Kf6 Kh4 76. Kf5 Kh3 77. Rg8 Kh4 78. Rg7 Kh3 79. Kf4 Kh2 80. Kf3 Kh1 81. Kf2 Kh2 82. Rh7# Bg4 83. Rh8# Bf5 84. Rh5# Bg4 85. Rh4# Bf5 86. Rh5# Bg4 87. Rh4# Bf5 88. Rh5# Bg4 89. Rh4# Bf5 90. Rh5# Bg4 91. Rh4# Bf5 92. Rh5# Bg4 93. Rh4# Bf5 94. Rh5# Bg4 95. Rh4# Bf5 96. Rh5# Bg4 97. Rh4# Bf5 98. Rh5# Bg4 99. Rh4# Bf5 100. Rh5# Bg4 101. Rh4# Bf5 102. Rh5# Bg4 103. Rh4# Bf5 104. Rh5# Bg4 105. Rh4# Bf5 106. Rh5# Bg4 107. Rh4# Bf5 108. Rh5# Bg4 109. Rh4# Bf5 110. Rh5# Bg4 111",
          "positional_tokens": {
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Rxa6",
            "Rh1+",
            "Kd2",
            "Rb1",
            "b3",
            "Rb2+",
            "Ke3",
            "Bb1",
            "Rxd6",
            "Bxa2",
            "d5",
            "Bxb3",
            "Rxe6+",
            "Kf5",
            "Rd6",
            "Bc4",
            "Rd8",
            "Re2+",
            "Kd4",
            "Rd2+",
            "Kc5",
            "Ke5",
            "Re8+",
            "Kf6",
            "d6",
            "Rd5+",
            "Kc6",
            "Rd3",
            "d7",
            "Bd5+",
            "Kxb5",
            "Bf7",
            "d8=Q+",
            "Rxd8",
            "Rxd8",
            "Ke7",
            "Rd4",
            "Be8+",
            "Kb6",
            "Ke6",
            "c4",
            "Ke5",
            "Rd8",
            "Bf7",
            "c5",
            "Bd5",
            "c6",
            "Bxc6",
            "Kxc6",
            "Ke4",
            "Kc5",
            "Kf3",
            "Re8",
            "Kxf2",
            "Kd4",
            "Kf3",
            "Re7",
            "Kf4",
            "Rf7+",
            "Kg5",
            "Ke4",
            "Kg6",
            "Rf1",
            "Kg5",
            "Rf2",
            "Kg6",
            "Ke5",
            "Kg7",
            "Ke6",
            "Kg8",
            "Ke7",
            "Kg7",
            "Rg2+",
            "Kh6",
            "Kf7",
            "Kh5",
            "Kf6",
            "Kh4",
            "Kf5",
            "Kh3",
            "Rg8",
            "Kh4",
            "Rg7",
            "Kh3",
            "Kf4",
            "Kh2",
            "Kf3",
            "Kh1",
            "Kf2",
            "Kh2",
            "Rh7#",
            "Bg4",
            "Rh8#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4",
            "Rh4#",
            "Bf5",
            "Rh5#",
            "Bg4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 d5 Nf6",
          "neutral_tokens": {
            "prompt_tokens": 402,
            "completion_tokens": 8,
            "total_tokens": 410,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Nf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c7a7",
          "positional_uci": "c7a7",
          "neutral_uci": null,
          "consensus_move": "c7a7",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxh6",
              "Rxa6",
              "Rh1+",
              "Kd2",
              "Rb1",
              "b3",
              "Rb2+",
              "Ke3",
              "Bb1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxh6",
              "Rxa6",
              "Rh1+",
              "Kd2",
              "Rb1",
              "b3",
              "Rb2+",
              "Ke3",
              "Bb1",
              "Rxd6",
              "Bxa2",
              "d5",
              "Bxb3",
              "Rxe6+",
              "Kf5",
              "Rd6",
              "Bc4",
              "Rd8",
              "Re2+",
              "Kd4",
              "Rd2+",
              "Kc5",
              "Ke5",
              "Re8+",
              "Kf6",
              "d6",
              "Rd5+",
              "Kc6",
              "Rd3",
              "d7",
              "Bd5+",
              "Kxb5",
              "Bf7",
              "d8=Q+",
              "Rxd8",
              "Rxd8",
              "Ke7",
              "Rd4",
              "Be8+",
              "Kb6",
              "Ke6",
              "c4",
              "Ke5",
              "Rd8",
              "Bf7",
              "c5",
              "Bd5",
              "c6",
              "Bxc6",
              "Kxc6",
              "Ke4",
              "Kc5",
              "Kf3",
              "Re8",
              "Kxf2",
              "Kd4",
              "Kf3",
              "Re7",
              "Kf4",
              "Rf7+",
              "Kg5",
              "Ke4",
              "Kg6",
              "Rf1",
              "Kg5",
              "Rf2",
              "Kg6",
              "Ke5",
              "Kg7",
              "Ke6",
              "Kg8",
              "Ke7",
              "Kg7",
              "Rg2+",
              "Kh6",
              "Kf7",
              "Kh5",
              "Kf6",
              "Kh4",
              "Kf5",
              "Kh3",
              "Rg8",
              "Kh4",
              "Rg7",
              "Kh3",
              "Kf4",
              "Kh2",
              "Kf3",
              "Kh1",
              "Kf2",
              "Kh2",
              "Rh7#",
              "Bg4",
              "Rh8#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4",
              "Rh4#",
              "Bf5",
              "Rh5#",
              "Bg4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d5",
              "Nf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 402,
            "completion_tokens": 8,
            "total_tokens": 410,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1208,
          "total_completion_tokens": 1288,
          "total_tokens": 2496
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 403,
            "completion_tokens": 640,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 70,
            "turn_number": 36,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 402,
            "completion_tokens": 8,
            "total_tokens": 410,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "7r/2R5/p2ppk1P/1p6/3Pb3/2P5/PP3P2/2K5 w - - 0 36"
    },
    {
      "turn": 73,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rxa6",
          "aggressive_uci": "a7a6",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Rxh6 38. Rb6 Rh1+ 39. Kd2 Rf1 40. Rxb5 Rxf2+ 41. Ke3 Rf3+ 42. Kd2 Rf2+ 43. Ke3 Rf3+ 44. Kd2 Rf2+ 45. Ke3 Rf3+ 46. Kd2 Rf2+ 47. Ke3 Rf3+ 48. Kd2 Rf2+ 49. Ke3 Rf3+ 50. Kd2 Rf2+ 51. Ke3 Rf3+ 52. Kd2 Rf2+ 53. Ke3 Rf3+ 54. Kd2 Rf2+ 55. Ke3 Rf3+ 56. Kd2 Rf2+ 57. Ke3 Rf3+ 58. Kd2 Rf2+ 59. Ke3 Rf3+ 60. Kd2 Rf2+ 61. Ke3 Rf3+ 62. Kd2 Rf2+ 63. Ke3 Rf3+ 64. Kd2 Rf2+ 65. Ke3 Rf3+ 66. Kd2 Rf2+ 67. Ke3 Rf3+ 68. Kd2 Rf2+ 69. Ke3 Rf3+ 70. Kd2 Rf2+ 71. Ke3 Rf3+ 72. Kd2 Rf",
          "aggressive_tokens": {
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Rb6",
            "Rh1+",
            "Kd2",
            "Rf1",
            "Rxb5",
            "Rxf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2",
            "Rf2+",
            "Ke3",
            "Rf3+",
            "Kd2"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rxa6",
          "positional_uci": "a7a6",
          "positional_response": "37. Rxa6 Rxh6 38. Rb6 Rh1+ 39. Kd2 Rf1 40. Ke2 Rb1 41. Rxb5 Bc2 42. Kd2 Ba4 43. Rb4 Be8 44. a4 Ra1 45. b3 Ra2+ 46. Ke3 Rc2 47. c4 dxc4 48. bxc4 Ra2 49. c5 Bxa4 50. Rb6 Ra3+ 51. Kf4 Rd3 52. Ke4 Bc2 53. Rd6 Rh3+ 54. Kf4 Rh4+ 55. Ke3 Re4+ 56. Kd2 Bb3 57. Kc3 Bd5 58. c6 Ke7 59. c7 Bb7 60. Rd8 Rf4 61. c8=Q Bxc8 62. Rxc8 Rxf2 63. Rc7+ Kd6 64. Rc5 Rf3+ 65. Kc4 Rf4 66. Re5 Rf1 67. Kd3 Rd1+ 68. Kc3 Rc1+ 69. Kd3 Rd1+ 70. Kc3 Rc1+ 71. Kd3 Rd1+ 72. Kc3 Rc1+ 73. Kd3 Rd1+ 74. Kc3 Rc1+ 75. Kd3 Rd1+ 76. Kc3 Rc1+ 77. Kd3 Rd1+ 78. Kc3 Rc1+ 79. Kd3 Rd1+ 80. Kc3 Rc1+ 81. Kd3 Rd1+ 82. Kc3 Rc1+ 83. Kd3 Rd1+ 84. Kc3 Rc1+ 85. Kd3 Rd1+ 86. Kc3 Rc1+ 87. Kd3 Rd1+ 88. Kc3 Rc1+ 89. Kd3 Rd1+ 90. Kc3 Rc1+ 91. Kd3 Rd1+ 92. Kc3 Rc1+ 93. Kd3 Rd1+ 94. Kc3 Rc1+ 95. Kd3 Rd1+ 96. Kc3 Rc1+ 97. Kd3 Rd1+ 98. Kc3 Rc1+ 99. Kd3 Rd1+ 100. Kc3 Rc1+ 101. Kd3 Rd1+ 102. Kc3 Rc1+ 103. Kd3 Rd1+ 104. Kc3 Rc1+ 105. Kd3 Rd1+ 106. Kc3 Rc1+ 107. Kd3 Rd1+ 108. Kc3 Rc1+ 109. Kd3 Rd1+ 110.",
          "positional_tokens": {
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "Rb6",
            "Rh1+",
            "Kd2",
            "Rf1",
            "Ke2",
            "Rb1",
            "Rxb5",
            "Bc2",
            "Kd2",
            "Ba4",
            "Rb4",
            "Be8",
            "a4",
            "Ra1",
            "b3",
            "Ra2+",
            "Ke3",
            "Rc2",
            "c4",
            "dxc4",
            "bxc4",
            "Ra2",
            "c5",
            "Bxa4",
            "Rb6",
            "Ra3+",
            "Kf4",
            "Rd3",
            "Ke4",
            "Bc2",
            "Rd6",
            "Rh3+",
            "Kf4",
            "Rh4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Bb3",
            "Kc3",
            "Bd5",
            "c6",
            "Ke7",
            "c7",
            "Bb7",
            "Rd8",
            "Rf4",
            "c8=Q",
            "Bxc8",
            "Rxc8",
            "Rxf2",
            "Rc7+",
            "Kd6",
            "Rc5",
            "Rf3+",
            "Kc4",
            "Rf4",
            "Re5",
            "Rf1",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+",
            "Kc3",
            "Rc1+",
            "Kd3",
            "Rd1+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg8 Rg3",
          "neutral_tokens": {
            "prompt_tokens": 409,
            "completion_tokens": 8,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a7a6",
          "positional_uci": "a7a6",
          "neutral_uci": null,
          "consensus_move": "a7a6",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxh6",
              "Rb6",
              "Rh1+",
              "Kd2",
              "Rf1",
              "Rxb5",
              "Rxf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2",
              "Rf2+",
              "Ke3",
              "Rf3+",
              "Kd2"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxh6",
              "Rb6",
              "Rh1+",
              "Kd2",
              "Rf1",
              "Ke2",
              "Rb1",
              "Rxb5",
              "Bc2",
              "Kd2",
              "Ba4",
              "Rb4",
              "Be8",
              "a4",
              "Ra1",
              "b3",
              "Ra2+",
              "Ke3",
              "Rc2",
              "c4",
              "dxc4",
              "bxc4",
              "Ra2",
              "c5",
              "Bxa4",
              "Rb6",
              "Ra3+",
              "Kf4",
              "Rd3",
              "Ke4",
              "Bc2",
              "Rd6",
              "Rh3+",
              "Kf4",
              "Rh4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Bb3",
              "Kc3",
              "Bd5",
              "c6",
              "Ke7",
              "c7",
              "Bb7",
              "Rd8",
              "Rf4",
              "c8=Q",
              "Bxc8",
              "Rxc8",
              "Rxf2",
              "Rc7+",
              "Kd6",
              "Rc5",
              "Rf3+",
              "Kc4",
              "Rf4",
              "Re5",
              "Rf1",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+",
              "Kc3",
              "Rc1+",
              "Kd3",
              "Rd1+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg8",
              "Rg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 409,
            "completion_tokens": 8,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1229,
          "total_completion_tokens": 1288,
          "total_tokens": 2517
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 410,
            "completion_tokens": 640,
            "total_tokens": 1050,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 72,
            "turn_number": 37,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 409,
            "completion_tokens": 8,
            "total_tokens": 417,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "7r/R7/p3pk1P/1p1p4/3Pb3/2P5/PP3P2/2K5 w - - 0 37"
    },
    {
      "turn": 75,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kd2",
          "aggressive_uci": "c1d2",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf5 39. Rb6 Rxh6 40. Rxb5 Rh2 41. Ke3 Rh3+ 42. Kd2 Rd3+ 43. Ke2 Rh3 44. Kd2 Rh2 45. Ke3 Rh3+ 46. Kd2 Rd3+ 47. Ke2 Rh3 48. Kd2 Rd3+ 49. Ke2 Rh3 50. Kd2 Rd3+ 51. Ke2 Rh3 52. Kd2 Rd3+ 53. Ke2 Rh3 54. Kd2 Rd3+ 55. Ke2 Rh3 56. Kd2 Rd3+ 57. Ke2 Rh3 58. Kd2 Rd3+ 59. Ke2 Rh3 60. Kd2 Rd3+ 61. Ke2 Rh3 62. Kd2 Rd3+ 63. Ke2 Rh3 64. Kd2 Rd3+ 65. Ke2 Rh3 66. Kd2 Rd3+ 67. Ke2 Rh3 68. Kd2 Rd3+ 69. Ke2 Rh3 70. Kd2 Rd3+ 71. Ke2 Rh3 72. Kd2 Rd3+ 73. Ke2 Rh3 74. Kd2 Rd3+ 75. Ke2 Rh3 76. Kd2 Rd3+ 77. Ke2 Rh3 78. Kd2 Rd3+",
          "aggressive_tokens": {
            "prompt_tokens": 418,
            "completion_tokens": 640,
            "total_tokens": 1058,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rd3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kd2",
          "positional_uci": "c1d2",
          "positional_response": "38. Kd2 Bf5 39. Rb6 Rxh6 40. Rxb5 Rh2 41. Ke3 Rh3+ 42. Kd2 Rd3+ 43. Ke2 Rh3 44.\nKd2 Kg5 45. a4 Kf4 46. a5 Rh2 47. Ke1 Kf3 48. a6 Rxf2 49. a7 Ke3 50. a8=Q Bd3\n51. Qf8 Rxf8 52. Rxd5 Rf1#",
          "positional_tokens": {
            "prompt_tokens": 418,
            "completion_tokens": 124,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kg5",
            "a4",
            "Kf4",
            "a5",
            "Rh2",
            "Ke1",
            "Kf3",
            "a6",
            "Rxf2",
            "a7",
            "Ke3",
            "a8=Q",
            "Bd3",
            "Qf8",
            "Rxf8",
            "Rxd5",
            "Rf1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rxa6",
          "neutral_uci": null,
          "neutral_response": "Re8 Bc4 Bb5\nRxa6 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 Kf4 Kf5 Kf6 K",
          "neutral_tokens": {
            "prompt_tokens": 417,
            "completion_tokens": 640,
            "total_tokens": 1057,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6",
            "Kf4",
            "Kf5",
            "Kf6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "c1d2",
          "positional_uci": "c1d2",
          "neutral_uci": null,
          "consensus_move": "c1d2",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rd3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kg5",
              "a4",
              "Kf4",
              "a5",
              "Rh2",
              "Ke1",
              "Kf3",
              "a6",
              "Rxf2",
              "a7",
              "Ke3",
              "a8=Q",
              "Bd3",
              "Qf8",
              "Rxf8",
              "Rxd5",
              "Rf1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6",
              "Kf4",
              "Kf5",
              "Kf6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 418,
            "completion_tokens": 640,
            "total_tokens": 1058,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 418,
            "completion_tokens": 124,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 417,
            "completion_tokens": 640,
            "total_tokens": 1057,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1253,
          "total_completion_tokens": 1404,
          "total_tokens": 2657
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 418,
            "completion_tokens": 640,
            "total_tokens": 1058,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 418,
            "completion_tokens": 124,
            "total_tokens": 542,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 74,
            "turn_number": 38,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 417,
            "completion_tokens": 640,
            "total_tokens": 1057,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "7r/8/R3pk1P/1p1p4/3P4/2Pb4/PP3P2/2K5 w - - 1 38"
    },
    {
      "turn": 77,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ke3",
          "aggressive_uci": "d2e3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRxh6 40. a4 bxa4 41. Rxa4 Rh3+ 42. Kd2 Rf3 43. Ke1 Bc4 44. Ra8 Ke7 45. Ra7+ Kd6\n46. Ra8 Kc6 47. Ra7 Kb6 48. Ra8 Kb7 49. Ra4 Rh3 50. Rb4+ Kc6 51. Ra4 Rh1+ 52.\nKd2 Rf1 53. Ke3 Re1+ 54. Kf3 Rb1 55. Rb4 Bb5 56. Ke3 Kb6 57. Kd2 Ka5 58. Kc2\nRf1 59. Kb3 Rxf2 60. Ka3 Bc4 61. Ra4+ Kb5 62. Rb4+ Kc6 63. Ra4 Kd6 64. Ra8\nRf1 65. Rd8+ Ke7 66. Rh8 Ra1+ 67. Kb4 Ra2 68. b3 Rb2 69. Rh7+ Kd6 70. Rh8 Rxb3+\n71. Ka4 Rxc3 72. Rd8+ Ke7 73. Rh8 Rd3 74. Rh7+ Kd6 75. Rh8 Rxd4 76. Rd8+ Ke5\n77. Rh8 Rd1 78",
          "aggressive_tokens": {
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kb6",
            "Kd2",
            "Ka5",
            "Kc2",
            "Rf1",
            "Kb3",
            "Rxf2",
            "Ka3",
            "Bc4",
            "Ra4+",
            "Kb5",
            "Rb4+",
            "Kc6",
            "Ra4",
            "Kd6",
            "Ra8",
            "Rf1",
            "Rd8+",
            "Ke7",
            "Rh8",
            "Ra1+",
            "Kb4",
            "Ra2",
            "b3",
            "Rb2",
            "Rh7+",
            "Kd6",
            "Rh8",
            "Rxb3+",
            "Ka4",
            "Rxc3",
            "Rd8+",
            "Ke7",
            "Rh8",
            "Rd3",
            "Rh7+",
            "Kd6",
            "Rh8",
            "Rxd4",
            "Rd8+",
            "Ke5",
            "Rh8",
            "Rd1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ke1",
          "positional_uci": "d2e1",
          "positional_response": "39. Ke1 Bd3 40. Kd2 Bf1 41. Ke1 Bd3 42. Kd2 Bf1 43. Ke1 Bd3 44. Kd2 Bf1 45. Ke1 Bd3 46. Kd2 Bf1 47. Ke1 Bd3 48. Kd2 Bf1 49. Ke1 Bd3 50. Kd2 Bf1 51. Ke1 Bd3 52. Kd2 Bf1 53. Ke1 Bd3 54. Kd2 Bf1 55. Ke1 Bd3 56. Kd2 Bf1 57. Ke1 Bd3 58. Kd2 Bf1 59. Ke1 Bd3 60. Kd2 Bf1 61. Ke1 Bd3 62. Kd2 Bf1 63. Ke1 Bd3 64. Kd2 Bf1 65. Ke1 Bd3 66. Kd2 Bf1 67. Ke1 Bd3 68. Kd2 Bf1 69. Ke1 Bd3 70. Kd2 Bf1 71. Ke1 Bd3 72. Kd2 Bf1 73. Ke1 Bd3 74. Kd2 Bf1 75. Ke1 Bd3 76. Kd2 Bf1 77. Ke1 Bd3 78. Kd2 Bf1 79. Ke1 Bd3 80. Kd2 Bf1 81. Ke1 Bd3 82. Kd2 Bf1 83. Ke1 Bd3 84. Kd2 Bf1 85. Ke1 Bd3 86. Kd2 Bf1 87. Ke1 Bd3 88. Kd2 Bf1 89. Ke1 Bd3 90. Kd2 Bf1 91. Ke1 Bd3 92. Kd2 Bf1 93. Ke1 Bd3 94. Kd2 Bf1 95. Ke1 Bd3 96. Kd2 Bf1 97. Ke1 Bd3 98. Kd2 Bf1 99. Ke1 Bd3 100. Kd2 Bf1 101. Ke1 Bd3 102. Kd2 Bf1 103. Ke1 Bd3 104. Kd2 Bf1 105. Ke1 Bd3 106. Kd2 Bf1 107. Ke1 Bd3 108. Kd2 Bf1 109. Ke1 Bd3 110. Kd2 Bf1 111. Ke1 Bd3 112. Kd2 Bf1 113. Ke1 Bd3 114. Kd2 Bf1 115. Ke1 Bd3 116. Kd2 Bf1 117. Ke1 Bd3 118. Kd2 Bf1",
          "positional_tokens": {
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd3",
            "Kd2",
            "Bf1"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ke3",
          "neutral_uci": "d2e3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRxh6 40. a4 bxa4 41. Rxa4 Rh3+ 42. Kd2 Rf3 43. Ke1 Bc4 44. Ra8 Ke7 45. Ra7+ Kd6\n46. Ra8 Kc6 47. Ra7 Kb6 48. Ra8 Kb5 49. Ra7 Rh3 50. Kd2 Rh2 51. Ke3 Rh1 52. Kd2\nRb1 53. Kc2 Rf1 54. Kd2 Rxf2+ 55. Kc1 Bb3 56. Ra8 Rc2+ 57. Kb1 Rd2 58. Kc1 Rd1#\nd5 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxh7 Qh5 b6 Qg6 Qxh6 Qg8 b5 Qg6 Qxh6 gxh6 Rh1 b4 Rxh6 bxc3 bxc3 Kc7 Kc2 Kd6 Rg3",
          "neutral_tokens": {
            "prompt_tokens": 426,
            "completion_tokens": 640,
            "total_tokens": 1066,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rh1",
            "Kd2",
            "Rb1",
            "Kc2",
            "Rf1",
            "Kd2",
            "Rxf2+",
            "Kc1",
            "Bb3",
            "Ra8",
            "Rc2+",
            "Kb1",
            "Rd2",
            "Kc1",
            "Rd1#",
            "d5",
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Qh5",
            "b6",
            "Qg6",
            "Qxh6",
            "Qg8",
            "b5",
            "Qg6",
            "Qxh6",
            "gxh6",
            "Rh1",
            "b4",
            "Rxh6",
            "bxc3",
            "bxc3",
            "Kc7",
            "Kc2",
            "Kd6",
            "Rg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "d2e3",
          "positional_uci": "d2e1",
          "neutral_uci": "d2e3",
          "consensus_move": "d2e3",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kb6",
              "Kd2",
              "Ka5",
              "Kc2",
              "Rf1",
              "Kb3",
              "Rxf2",
              "Ka3",
              "Bc4",
              "Ra4+",
              "Kb5",
              "Rb4+",
              "Kc6",
              "Ra4",
              "Kd6",
              "Ra8",
              "Rf1",
              "Rd8+",
              "Ke7",
              "Rh8",
              "Ra1+",
              "Kb4",
              "Ra2",
              "b3",
              "Rb2",
              "Rh7+",
              "Kd6",
              "Rh8",
              "Rxb3+",
              "Ka4",
              "Rxc3",
              "Rd8+",
              "Ke7",
              "Rh8",
              "Rd3",
              "Rh7+",
              "Kd6",
              "Rh8",
              "Rxd4",
              "Rd8+",
              "Ke5",
              "Rh8",
              "Rd1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bd3",
              "Kd2",
              "Bf1"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rh1",
              "Kd2",
              "Rb1",
              "Kc2",
              "Rf1",
              "Kd2",
              "Rxf2+",
              "Kc1",
              "Bb3",
              "Ra8",
              "Rc2+",
              "Kb1",
              "Rd2",
              "Kc1",
              "Rd1#",
              "d5",
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Qh5",
              "b6",
              "Qg6",
              "Qxh6",
              "Qg8",
              "b5",
              "Qg6",
              "Qxh6",
              "gxh6",
              "Rh1",
              "b4",
              "Rxh6",
              "bxc3",
              "bxc3",
              "Kc7",
              "Kc2",
              "Kd6",
              "Rg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 426,
            "completion_tokens": 640,
            "total_tokens": 1066,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1280,
          "total_completion_tokens": 1920,
          "total_tokens": 3200
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 427,
            "completion_tokens": 640,
            "total_tokens": 1067,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 76,
            "turn_number": 39,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 426,
            "completion_tokens": 640,
            "total_tokens": 1066,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "7r/8/R3pk1P/1p1p4/3P4/2P5/PP1K1P2/5b2 w - - 3 39"
    },
    {
      "turn": 79,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf4",
          "aggressive_uci": "e3f4",
          "aggressive_response": "40. Kf4 Bd3 41. Ke3 Bf1 42. Kf4 Bd3 43. Ke3 Bf1 44. Kf4 Bd3 45. Ke3 Bf1 46. Kf4 Bd3 47. Ke3 Bf1 48. Kf4 Bd3 49. Ke3 Bf1 50. Kf4 Bd3 51. Ke3 Bf1 52. Kf4 Bd3 53. Ke3 Bf1 54. Kf4 Bd3 55. Ke3 Bf1 56. Kf4 Bd3 57. Ke3 Bf1 58. Kf4 Bd3 59. Ke3 Bf1 60. Kf4 Bd3 61. Ke3 Bf1 62. Kf4 Bd3 63. Ke3 Bf1 64. Kf4 Bd3 65. Ke3 Bf1 66. Kf4 Bd3 67. Ke3 Bf1 68. Kf4 Bd3 69. Ke3 Bf1 70. Kf4 Bd3 71. Ke3 Bf1 72. Kf4 Bd3 73. Ke3 Bf1 74. Kf4 Bd3 75. Ke3 Bf1 76. Kf4 Bd3 77. Ke3 Bf1 78. Kf4 Bd3 79. Ke3 Bf1 80. Kf4 Bd3 81. Ke3 Bf1 82. Kf4 Bd3 83. Ke3 Bf1 84. Kf4 Bd3 85. Ke3 Bf1 86. Kf4 Bd3 87. Ke3 Bf1 88. Kf4 Bd3 89. Ke3 Bf1 90. Kf4 Bd3 91. Ke3 Bf1 92. Kf4 Bd3 93. Ke3 Bf1 94. Kf4 Bd3 95. Ke3 Bf1 96. Kf4 Bd3 97. Ke3 Bf1 98. Kf4 Bd3 99. Ke3 Bf1 100. Kf4 Bd3 101. Ke3 Bf1 102. Kf4 Bd3 103. Ke3 Bf1 104. Kf4 Bd3 105. Ke3 Bf1 106. Kf4 Bd3 107. Ke3 Bf1 108. Kf4 Bd3 109. Ke3 Bf1 110. Kf4 Bd3 111. Ke3 Bf1 112. Kf4 Bd3 113. Ke3 Bf1 114. Kf4 Bd3 115. Ke3 Bf1 116. Kf4 Bd3 117. Ke3 Bf1 118. Kf4 Bd3 119. Ke3 Bf1",
          "aggressive_tokens": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bd3",
            "Ke3",
            "Bf1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "b3",
          "positional_uci": "b2b3",
          "positional_response": "40. b3 Rxh6 41. a4 bxa4 42. Rxa4 Rh3+ 43. Kd2 Rd3+ 44. Kc2 Rf3 45. c4 Rxf2+ 46. Kc3 Rf3+ 47. Kb4 dxc4 48. bxc4 Rf4 49. Kc5 Kf5 50. d5 exd5 51. Kxd5 Bg2+ 52. Kd6 Rd4+ 53. Kc5 Ke5 54. Ra7 Bf1 55. Re7+ Kf6 56. Kxd4 Kxe7 57. c5 Kd7 58. Kd5 Bg2+ 59. Kd4 Kc6 60. Kc4 Bd5+ 61. Kd4 Bf7 62. Ke5 Kxc5 63. Kf6 Bc4 64. Ke5 Bd3 65. Kf6 Kd6 66. Kg5 Ke5 67. Kg4 Be4 68. Kg5 Bf5 69. Kh6 Kf6 70. Kh5 Be6 71. Kh6 Bg8 72. Kh5 Kf5 73. Kh6 Kf6 74. Kh5 Be6 75. Kh6 Bf5 76. Kh5 Be4 77. Kh6 Bf3 78. Kh7 Be4+ 79. Kh6 Bf5 80. Kh5 Be6 81. Kh6 Bf7 82. Kh7 Bg6+ 83. Kh6 Bf7 84. Kh7 Be6 85. Kh6 Bf5 86. Kh5 Be4 87. Kh6 Bf3 88. Kh7 Be4+ 89. Kh6 Bf5 90. Kh5 Be6 91. Kh6 Bf7 92. Kh7 Bg6+ 93. Kh6 Bf7 94. Kh7 Be6 95. Kh6 Bf5 96. Kh5 Be4 97. Kh6 Bf3 98. Kh7 Be4+ 99. Kh6 Bf5 100. Kh5 Be6 101. Kh6 Bf7 102. Kh7 Bg6+ 103. Kh6 Bf7 104. Kh7 Be6 105. Kh6 Bf5 106. Kh5 Be4 107. Kh6 Bf3 108. Kh7 Be4+ 109. Kh6 Bf5 110. Kh5 Be6 111. Kh6 Bf7 112. Kh7 Bg6+ 113. Kh6 Bf7 114. Kh7 Be6 115. Kh6 Bf5 116. Kh5 Be4 117. Kh6 Bf3 118. Kh7 Be4+ 119",
          "positional_tokens": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxh6",
            "a4",
            "bxa4",
            "Rxa4",
            "Rh3+",
            "Kd2",
            "Rd3+",
            "Kc2",
            "Rf3",
            "c4",
            "Rxf2+",
            "Kc3",
            "Rf3+",
            "Kb4",
            "dxc4",
            "bxc4",
            "Rf4",
            "Kc5",
            "Kf5",
            "d5",
            "exd5",
            "Kxd5",
            "Bg2+",
            "Kd6",
            "Rd4+",
            "Kc5",
            "Ke5",
            "Ra7",
            "Bf1",
            "Re7+",
            "Kf6",
            "Kxd4",
            "Kxe7",
            "c5",
            "Kd7",
            "Kd5",
            "Bg2+",
            "Kd4",
            "Kc6",
            "Kc4",
            "Bd5+",
            "Kd4",
            "Bf7",
            "Ke5",
            "Kxc5",
            "Kf6",
            "Bc4",
            "Ke5",
            "Bd3",
            "Kf6",
            "Kd6",
            "Kg5",
            "Ke5",
            "Kg4",
            "Be4",
            "Kg5",
            "Bf5",
            "Kh6",
            "Kf6",
            "Kh5",
            "Be6",
            "Kh6",
            "Bg8",
            "Kh5",
            "Kf5",
            "Kh6",
            "Kf6",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf7",
            "Kh7",
            "Bg6+",
            "Kh6",
            "Bf7",
            "Kh7",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf7",
            "Kh7",
            "Bg6+",
            "Kh6",
            "Bf7",
            "Kh7",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf7",
            "Kh7",
            "Bg6+",
            "Kh6",
            "Bf7",
            "Kh7",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be6",
            "Kh6",
            "Bf7",
            "Kh7",
            "Bg6+",
            "Kh6",
            "Bf7",
            "Kh7",
            "Be6",
            "Kh6",
            "Bf5",
            "Kh5",
            "Be4",
            "Kh6",
            "Bf3",
            "Kh7",
            "Be4+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kf4",
          "neutral_uci": "e3f4",
          "neutral_response": "40. Kf4 Rxh6 41. Ra8 Rh4+ 42. Kg3 Rh3+ 43. Kg4 Rd3 44. Rf8+ Ke7 45. Rb8 Rd2\n46. b3 Rxa2 47. f4 Rc2 48. Rc8 b4 49. Rc7+ Kd6 50. Rb7 bxc3 51. Rb6+ Kd7 52.\nRb7+ Kc6 53. Re7 Re2 54. f5 c2 55. f6 c1=Q 56. f7 Rg2+ 57. Kh5 Qg5# Bg7+ 59. Kh4\nBf6+ 60. Kh3 Qg4# Bxg4+ 62. Kxg4 Bxe7 63. Kf4 Rf2+ 64. Ke5 Kd7 65. f8=N+ Bxf8\n66. b4 Bg7# Bxg7+ 68. Kxg7 Ke7 69. b5 Rg2+ 70. Kh6 Kf6 71. Kh5 Kf5 72. Kh4\nRg8 73. b6 Kf4 74. Kh5 Rb8 75. Kg6 Rxb6 76. Kf6 Ke4 77. Ke7 Kxd4 78. Kd7 e5\n79. Kc7 Rh6 80. Kd7 e4 81. Ke7 e3 82. Kf7 e2 83. Kg7 Ra6 84. Kf7 e1=Q 85. Kg7\nQe7+ 86. Kg8 Ra8# e4 e3 e2 e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q\ne1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q\ne1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q\ne1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q\ne1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=Q e1=",
          "neutral_tokens": {
            "prompt_tokens": 434,
            "completion_tokens": 640,
            "total_tokens": 1074,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kh5",
            "Rb8",
            "Kg6",
            "Rxb6",
            "Kf6",
            "Ke4",
            "Ke7",
            "Kxd4",
            "Kd7",
            "e5",
            "Kc7",
            "Rh6",
            "Kd7",
            "e4",
            "Ke7",
            "e3",
            "Kf7",
            "e2",
            "Kg7",
            "Ra6",
            "Kf7",
            "e1=Q",
            "Kg7",
            "Qe7+",
            "Kg8",
            "Ra8#",
            "e4",
            "e3",
            "e2",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1=Q",
            "e1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "e3f4",
          "positional_uci": "b2b3",
          "neutral_uci": "e3f4",
          "consensus_move": "e3f4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bd3",
              "Ke3",
              "Bf1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxh6",
              "a4",
              "bxa4",
              "Rxa4",
              "Rh3+",
              "Kd2",
              "Rd3+",
              "Kc2",
              "Rf3",
              "c4",
              "Rxf2+",
              "Kc3",
              "Rf3+",
              "Kb4",
              "dxc4",
              "bxc4",
              "Rf4",
              "Kc5",
              "Kf5",
              "d5",
              "exd5",
              "Kxd5",
              "Bg2+",
              "Kd6",
              "Rd4+",
              "Kc5",
              "Ke5",
              "Ra7",
              "Bf1",
              "Re7+",
              "Kf6",
              "Kxd4",
              "Kxe7",
              "c5",
              "Kd7",
              "Kd5",
              "Bg2+",
              "Kd4",
              "Kc6",
              "Kc4",
              "Bd5+",
              "Kd4",
              "Bf7",
              "Ke5",
              "Kxc5",
              "Kf6",
              "Bc4",
              "Ke5",
              "Bd3",
              "Kf6",
              "Kd6",
              "Kg5",
              "Ke5",
              "Kg4",
              "Be4",
              "Kg5",
              "Bf5",
              "Kh6",
              "Kf6",
              "Kh5",
              "Be6",
              "Kh6",
              "Bg8",
              "Kh5",
              "Kf5",
              "Kh6",
              "Kf6",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf7",
              "Kh7",
              "Bg6+",
              "Kh6",
              "Bf7",
              "Kh7",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf7",
              "Kh7",
              "Bg6+",
              "Kh6",
              "Bf7",
              "Kh7",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf7",
              "Kh7",
              "Bg6+",
              "Kh6",
              "Bf7",
              "Kh7",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be6",
              "Kh6",
              "Bf7",
              "Kh7",
              "Bg6+",
              "Kh6",
              "Bf7",
              "Kh7",
              "Be6",
              "Kh6",
              "Bf5",
              "Kh5",
              "Be4",
              "Kh6",
              "Bf3",
              "Kh7",
              "Be4+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kh5",
              "Rb8",
              "Kg6",
              "Rxb6",
              "Kf6",
              "Ke4",
              "Ke7",
              "Kxd4",
              "Kd7",
              "e5",
              "Kc7",
              "Rh6",
              "Kd7",
              "e4",
              "Ke7",
              "e3",
              "Kf7",
              "e2",
              "Kg7",
              "Ra6",
              "Kf7",
              "e1=Q",
              "Kg7",
              "Qe7+",
              "Kg8",
              "Ra8#",
              "e4",
              "e3",
              "e2",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1=Q",
              "e1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 434,
            "completion_tokens": 640,
            "total_tokens": 1074,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1304,
          "total_completion_tokens": 1920,
          "total_tokens": 3224
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 435,
            "completion_tokens": 640,
            "total_tokens": 1075,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 78,
            "turn_number": 40,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 434,
            "completion_tokens": 640,
            "total_tokens": 1074,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/7r/R3pk1P/1p1p4/3P4/2P1K3/PP3P2/5b2 w - - 5 40"
    },
    {
      "turn": 81,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": null,
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3 Bg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1 Re8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20. Rh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8 27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33. Rxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3 Rh7 40. Kf4 Rxh6",
          "aggressive_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 333,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4",
            "Qg6",
            "Qh6",
            "Qxh6",
            "gxh6",
            "Rh8",
            "g4",
            "Bb7",
            "Rh5",
            "Ke8",
            "g5",
            "Kf7",
            "Rg1",
            "Rag8",
            "Rh4",
            "a6",
            "Rf4+",
            "Ke8",
            "Rf6",
            "Ke7",
            "Rg3",
            "Rxg5",
            "Rxg5",
            "Kxf6",
            "Rg7",
            "Be4",
            "Rxc7",
            "b5",
            "Ra7",
            "d5",
            "Rxa6",
            "Bd3",
            "Kd2",
            "Bf1",
            "Ke3",
            "Rh7",
            "Kf4",
            "Rxh6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8 Rg7",
          "positional_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg8 Rg3",
          "neutral_tokens": {
            "prompt_tokens": 443,
            "completion_tokens": 8,
            "total_tokens": 451,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4",
              "Qg6",
              "Qh6",
              "Qxh6",
              "gxh6",
              "Rh8",
              "g4",
              "Bb7",
              "Rh5",
              "Ke8",
              "g5",
              "Kf7",
              "Rg1",
              "Rag8",
              "Rh4",
              "a6",
              "Rf4+",
              "Ke8",
              "Rf6",
              "Ke7",
              "Rg3",
              "Rxg5",
              "Rxg5",
              "Kxf6",
              "Rg7",
              "Be4",
              "Rxc7",
              "b5",
              "Ra7",
              "d5",
              "Rxa6",
              "Bd3",
              "Kd2",
              "Bf1",
              "Ke3",
              "Rh7",
              "Kf4",
              "Rxh6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg8",
              "Rg3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 444,
            "completion_tokens": 333,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 443,
            "completion_tokens": 8,
            "total_tokens": 451,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1331,
          "total_completion_tokens": 349,
          "total_tokens": 1680
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 444,
            "completion_tokens": 333,
            "total_tokens": 777,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 443,
            "completion_tokens": 8,
            "total_tokens": 451,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/8/R3pk1r/1p1p4/3P1K2/2P5/PP3P2/5b2 w - - 0 41"
    },
    {
      "turn": 81,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "a4",
          "aggressive_uci": "a2a4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 bxa4 42. Rxa4 Rh4+ 43. Kg3 Rh3+ 44. Kg4 Rd3 45. Ra1 Be2+ 46. Kh4 Kf5 47. Re1 Bg4 48. Re5+ Kf4 49. Re3 Rxe3 50. fxe3+ Kf5 51. b4 Be2 52. Kg3 Ke4 53. Kf2 Bb5 54. Ke1 Kxe3 55. Kd1 Kd3 56. Kc1 Kxc3 57. Kd1 Kxd4 58. Kd2 Kc4 59. Ke3 Kxb4 60. Kd4 Bc4 61. Ke5 Kc3 62. Kxe6 d4+ 63. Ke5 d3 64. Ke4 d2 65. Ke3 d1=Q 66. Kf4 Qe2 67. Kf5 Qe3 68. Kf6 Qe4 69. Kg5 Qf3 70. Kg6 Qf4 71. Kg7 Qf5 72. Kh6 Qg4 73. Kh7 Qg5 74. Kh8 Qg8# 0-1\nd5 e6 c4 d6 Nc3 Nf6 Bg5",
          "aggressive_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 640,
            "total_tokens": 1084,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "bxa4",
            "Rxa4",
            "Rh4+",
            "Kg3",
            "Rh3+",
            "Kg4",
            "Rd3",
            "Ra1",
            "Be2+",
            "Kh4",
            "Kf5",
            "Re1",
            "Bg4",
            "Re5+",
            "Kf4",
            "Re3",
            "Rxe3",
            "fxe3+",
            "Kf5",
            "b4",
            "Be2",
            "Kg3",
            "Ke4",
            "Kf2",
            "Bb5",
            "Ke1",
            "Kxe3",
            "Kd1",
            "Kd3",
            "Kc1",
            "Kxc3",
            "Kd1",
            "Kxd4",
            "Kd2",
            "Kc4",
            "Ke3",
            "Kxb4",
            "Kd4",
            "Bc4",
            "Ke5",
            "Kc3",
            "Kxe6",
            "d4+",
            "Ke5",
            "d3",
            "Ke4",
            "d2",
            "Ke3",
            "d1=Q",
            "Kf4",
            "Qe2",
            "Kf5",
            "Qe3",
            "Kf6",
            "Qe4",
            "Kg5",
            "Qf3",
            "Kg6",
            "Qf4",
            "Kg7",
            "Qf5",
            "Kh6",
            "Qg4",
            "Kh7",
            "Qg5",
            "Kh8",
            "Qg8#",
            "d5",
            "e6",
            "c4",
            "d6",
            "Nc3",
            "Nf6",
            "Bg5"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8 Rg7",
          "positional_tokens": {
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a4",
          "neutral_uci": "a2a4",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 bxa4 42. Rxa4 Rh4+ 43. Kg3 Rh3+ 44. Kg4 Rd3 45. Ra1 Be2+ 46. Kh4 Kf5 47. Re1 Bg4 48. Re5+ Kf4 49. Re3 Rxe3 50. fxe3+ Kf5 51. b4 Be2 52. Kg3 Ke4 53. Kf2 Bb5 54. Ke1 Kxe3 55. Kd1 Kd3 56. Kc1 Kxc3 57. Kd1 Kxd4 58. Kd2 Kc4 59. Ke3 Kxb4 60. Kd4 Bc4 61. Ke5 Kc3 62. Kxe6 d4+ 63. Ke5 d3 64. Ke4 d2 65. Ke3 d1=Q 66. Ke4 Qd5+ 67. Ke3 Qd4+ 68. Kf3 Bd5+ 69. Ke2 Qd3+ 70. Kf2 Qf3+ 71. Ke1 Qg2 72. Kd1 Qd2# d5 d4 d3",
          "neutral_tokens": {
            "prompt_tokens": 443,
            "completion_tokens": 612,
            "total_tokens": 1055,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "bxa4",
            "Rxa4",
            "Rh4+",
            "Kg3",
            "Rh3+",
            "Kg4",
            "Rd3",
            "Ra1",
            "Be2+",
            "Kh4",
            "Kf5",
            "Re1",
            "Bg4",
            "Re5+",
            "Kf4",
            "Re3",
            "Rxe3",
            "fxe3+",
            "Kf5",
            "b4",
            "Be2",
            "Kg3",
            "Ke4",
            "Kf2",
            "Bb5",
            "Ke1",
            "Kxe3",
            "Kd1",
            "Kd3",
            "Kc1",
            "Kxc3",
            "Kd1",
            "Kxd4",
            "Kd2",
            "Kc4",
            "Ke3",
            "Kxb4",
            "Kd4",
            "Bc4",
            "Ke5",
            "Kc3",
            "Kxe6",
            "d4+",
            "Ke5",
            "d3",
            "Ke4",
            "d2",
            "Ke3",
            "d1=Q",
            "Ke4",
            "Qd5+",
            "Ke3",
            "Qd4+",
            "Kf3",
            "Bd5+",
            "Ke2",
            "Qd3+",
            "Kf2",
            "Qf3+",
            "Ke1",
            "Qg2",
            "Kd1",
            "Qd2#",
            "d5",
            "d4",
            "d3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a2a4",
          "positional_uci": null,
          "neutral_uci": "a2a4",
          "consensus_move": "a2a4",
          "source_agents": [
            "aggressive",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "bxa4",
              "Rxa4",
              "Rh4+",
              "Kg3",
              "Rh3+",
              "Kg4",
              "Rd3",
              "Ra1",
              "Be2+",
              "Kh4",
              "Kf5",
              "Re1",
              "Bg4",
              "Re5+",
              "Kf4",
              "Re3",
              "Rxe3",
              "fxe3+",
              "Kf5",
              "b4",
              "Be2",
              "Kg3",
              "Ke4",
              "Kf2",
              "Bb5",
              "Ke1",
              "Kxe3",
              "Kd1",
              "Kd3",
              "Kc1",
              "Kxc3",
              "Kd1",
              "Kxd4",
              "Kd2",
              "Kc4",
              "Ke3",
              "Kxb4",
              "Kd4",
              "Bc4",
              "Ke5",
              "Kc3",
              "Kxe6",
              "d4+",
              "Ke5",
              "d3",
              "Ke4",
              "d2",
              "Ke3",
              "d1=Q",
              "Kf4",
              "Qe2",
              "Kf5",
              "Qe3",
              "Kf6",
              "Qe4",
              "Kg5",
              "Qf3",
              "Kg6",
              "Qf4",
              "Kg7",
              "Qf5",
              "Kh6",
              "Qg4",
              "Kh7",
              "Qg5",
              "Kh8",
              "Qg8#",
              "d5",
              "e6",
              "c4",
              "d6",
              "Nc3",
              "Nf6",
              "Bg5"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rg7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "bxa4",
              "Rxa4",
              "Rh4+",
              "Kg3",
              "Rh3+",
              "Kg4",
              "Rd3",
              "Ra1",
              "Be2+",
              "Kh4",
              "Kf5",
              "Re1",
              "Bg4",
              "Re5+",
              "Kf4",
              "Re3",
              "Rxe3",
              "fxe3+",
              "Kf5",
              "b4",
              "Be2",
              "Kg3",
              "Ke4",
              "Kf2",
              "Bb5",
              "Ke1",
              "Kxe3",
              "Kd1",
              "Kd3",
              "Kc1",
              "Kxc3",
              "Kd1",
              "Kxd4",
              "Kd2",
              "Kc4",
              "Ke3",
              "Kxb4",
              "Kd4",
              "Bc4",
              "Ke5",
              "Kc3",
              "Kxe6",
              "d4+",
              "Ke5",
              "d3",
              "Ke4",
              "d2",
              "Ke3",
              "d1=Q",
              "Ke4",
              "Qd5+",
              "Ke3",
              "Qd4+",
              "Kf3",
              "Bd5+",
              "Ke2",
              "Qd3+",
              "Kf2",
              "Qf3+",
              "Ke1",
              "Qg2",
              "Kd1",
              "Qd2#",
              "d5",
              "d4",
              "d3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 444,
            "completion_tokens": 640,
            "total_tokens": 1084,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 443,
            "completion_tokens": 612,
            "total_tokens": 1055,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1331,
          "total_completion_tokens": 1260,
          "total_tokens": 2591
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 444,
            "completion_tokens": 640,
            "total_tokens": 1084,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 444,
            "completion_tokens": 8,
            "total_tokens": 452,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 80,
            "turn_number": 41,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 443,
            "completion_tokens": 612,
            "total_tokens": 1055,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/8/R3pk1r/1p1p4/3P1K2/2P5/PP3P2/5b2 w - - 0 41"
    },
    {
      "turn": 83,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kg3",
          "aggressive_uci": "f4g3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6\nBxf6 6. e4 g6 7. h4 d6 8. c3 Bg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4\nNf6 13. Neg5 Kd8 14. Rhe1 Re8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5\nBxg5+ 19. hxg5 Qxh7 20. Rh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8\n25. g4 Bb7 26. Rh5 Ke8 27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6\nKe7 32. Rg3 Rxg5 33. Rxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3\n38. Kd2 Bf1 39. Ke3 Rh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rg2+ 43. Kf3 bxa4 44.\nRxa4 Rg7 45. Ra1 Bd3 46. Ke3 Bc4 47. Ra3 Rb7 48. b4 Rh7 49. Ra8 Rh3+ 50. Kd2\nRd3+ 51. Kc2 Rf3 52. Rf8+ * 42. Kg3 Rg2+ 43. Kf3 bxa4 44. Rxa4 Rg7 45. Ra1 Bd3\n46. Ke3 Bc4 47. Ra3 Rb7 48. b4 Rh7 49. Ra8 Rh3+ 50. Kd2 Rf3 51. Rf8+",
          "aggressive_tokens": {
            "prompt_tokens": 451,
            "completion_tokens": 518,
            "total_tokens": 969,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg2+",
            "Kf3",
            "bxa4",
            "Rxa4",
            "Rg7",
            "Ra1",
            "Bd3",
            "Ke3",
            "Bc4",
            "Ra3",
            "Rb7",
            "b4",
            "Rh7",
            "Ra8",
            "Rh3+",
            "Kd2",
            "Rf3",
            "Rf8+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kg3",
          "positional_uci": "f4g3",
          "positional_response": "42. Kg3 Rg2+ 43. Kf3 bxa4 44. Rxa4 Rg8 45. Ra1 Bd3 46. Ke3 Bc4 47. Ra3 Rb8 48.\nb4 Rh8 49. Ra7 Rh3+ 50. Kd2 Rd3+ 51. Kc2 Rf3 52. Ra8 Rxf2+ 53. Kc1 Kf5 54. Rf8+\nKe4 55. Rxf2 Kd3 56. Rf3+ Ke2 57. Rh3 Kf2 58. Kd2 Kg2 59. Re3 Kf2 60. Rxe6 Kf3\n61. Re5 Kf4 62. Kc2 Kf3 63. Kb2 Kf4 64. Ka3 Kf3 65. Ka4 Kf4 66. b5 Kf3 67. b6\nKf4 68. b7 Kf3 69. b8=Q Kf4 70. Qf8+ Kg4 71. Re7 Kg5 72. Rg7+ Kh6 73. Qh8# Kf5\n74. Qe8 Kf4 75. Rf7+ Kg5 76. Qg8+ Kh6 77. Rh7# Kxh7 78. Qf7+ Kh6 79. Qf6+ Kh7\n80. Qf5+ Kh6 81. Qf4+ Kh7 82. Qf3 Kh6 83. Qf2 Kh7 84. Qf1 Kh6 85. Qg1 Kh7 86.\nQg2 Kh6 87. Qg3 Kh7 88. Qg4 Kh6 89. Qg5+ Kh7 90. Qg6+ Kh8 91. Qg7+ Kxg7 92.\nKb4 Kf6 93. Kc5 Kf5 94. Kd6 Ke4 95. Kc5 Kd3 96. Kb4 Kc2 97. Kc5 Kxc3 98. Kd6\nKxd4 99. Ke6 Ke4 100. Kf6 d4 101. Kg5 d3 102. Kg4 d2 103. Kg3 d1=Q 104. Kf2 Qf3+\n105. Kg1 Qe2 106. Kh1 Kf3 107. Kg1 Qg2#",
          "positional_tokens": {
            "prompt_tokens": 451,
            "completion_tokens": 564,
            "total_tokens": 1015,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d1=Q",
            "Kf2",
            "Qf3+",
            "Kg1",
            "Qe2",
            "Kh1",
            "Kf3",
            "Kg1",
            "Qg2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kg3",
          "neutral_uci": "f4g3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kg4 bxa4 44. Rxa4 Rh2 45. Kg3 Rh8\n46. Ra1 Bd3 47. Kf4 Rh4+ 48. Ke3 Bc4 49. Ra3 Rh3+ 50. Kf4 Rd3 51. b4 Bb5 52.\nRa5 Bc4 53. Ra3 Ke7 54. Ke5 Kd7 55. Ra7+ Kc6 56. Kxe6 Rxc3 57. f4 Re3+ 58. Kf6\nRe4 59. f5 Rxd4 60. Ke5 Re4+ 61. Kf6 d4 62. Ra8 d3 63. Rd8 Bd5 64. b5+ Kc5 65.\nb6 d2 66. b7 d1=Q 67. b8=Q Qd4+ 68. Kg6 Rg4+ 69. Kh5 Rh4+ 70. Kg6 Qg4+ 71. Kf6\nRh6+ 72. Ke7 Qg7+ 73. Ke8 Rh8#",
          "neutral_tokens": {
            "prompt_tokens": 450,
            "completion_tokens": 606,
            "total_tokens": 1056,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rh8",
            "Ra1",
            "Bd3",
            "Kf4",
            "Rh4+",
            "Ke3",
            "Bc4",
            "Ra3",
            "Rh3+",
            "Kf4",
            "Rd3",
            "b4",
            "Bb5",
            "Ra5",
            "Bc4",
            "Ra3",
            "Ke7",
            "Ke5",
            "Kd7",
            "Ra7+",
            "Kc6",
            "Kxe6",
            "Rxc3",
            "f4",
            "Re3+",
            "Kf6",
            "Re4",
            "f5",
            "Rxd4",
            "Ke5",
            "Re4+",
            "Kf6",
            "d4",
            "Ra8",
            "d3",
            "Rd8",
            "Bd5",
            "b5+",
            "Kc5",
            "b6",
            "d2",
            "b7",
            "d1=Q",
            "b8=Q",
            "Qd4+",
            "Kg6",
            "Rg4+",
            "Kh5",
            "Rh4+",
            "Kg6",
            "Qg4+",
            "Kf6",
            "Rh6+",
            "Ke7",
            "Qg7+",
            "Ke8",
            "Rh8#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f4g3",
          "positional_uci": "f4g3",
          "neutral_uci": "f4g3",
          "consensus_move": "f4g3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg2+",
              "Kf3",
              "bxa4",
              "Rxa4",
              "Rg7",
              "Ra1",
              "Bd3",
              "Ke3",
              "Bc4",
              "Ra3",
              "Rb7",
              "b4",
              "Rh7",
              "Ra8",
              "Rh3+",
              "Kd2",
              "Rf3",
              "Rf8+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "d1=Q",
              "Kf2",
              "Qf3+",
              "Kg1",
              "Qe2",
              "Kh1",
              "Kf3",
              "Kg1",
              "Qg2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rh8",
              "Ra1",
              "Bd3",
              "Kf4",
              "Rh4+",
              "Ke3",
              "Bc4",
              "Ra3",
              "Rh3+",
              "Kf4",
              "Rd3",
              "b4",
              "Bb5",
              "Ra5",
              "Bc4",
              "Ra3",
              "Ke7",
              "Ke5",
              "Kd7",
              "Ra7+",
              "Kc6",
              "Kxe6",
              "Rxc3",
              "f4",
              "Re3+",
              "Kf6",
              "Re4",
              "f5",
              "Rxd4",
              "Ke5",
              "Re4+",
              "Kf6",
              "d4",
              "Ra8",
              "d3",
              "Rd8",
              "Bd5",
              "b5+",
              "Kc5",
              "b6",
              "d2",
              "b7",
              "d1=Q",
              "b8=Q",
              "Qd4+",
              "Kg6",
              "Rg4+",
              "Kh5",
              "Rh4+",
              "Kg6",
              "Qg4+",
              "Kf6",
              "Rh6+",
              "Ke7",
              "Qg7+",
              "Ke8",
              "Rh8#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 451,
            "completion_tokens": 518,
            "total_tokens": 969,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 451,
            "completion_tokens": 564,
            "total_tokens": 1015,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 450,
            "completion_tokens": 606,
            "total_tokens": 1056,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1352,
          "total_completion_tokens": 1688,
          "total_tokens": 3040
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 451,
            "completion_tokens": 518,
            "total_tokens": 969,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 451,
            "completion_tokens": 564,
            "total_tokens": 1015,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 82,
            "turn_number": 42,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 450,
            "completion_tokens": 606,
            "total_tokens": 1056,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/8/R3pk2/1p1p4/P2P1K2/2P5/1P3P1r/5b2 w - - 1 42"
    },
    {
      "turn": 85,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re8",
          "aggressive_uci": null,
          "aggressive_response": "Re8 Rg8+ Kh7",
          "aggressive_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8+ Kh7",
          "positional_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg8+ Kh7 Rg7+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh8 Rh6+ Rh7 Rg6+ Kh",
          "neutral_tokens": {
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rg8+",
            "Kh7",
            "Rg7+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+",
            "Kh8",
            "Rh6+",
            "Rh7",
            "Rg6+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg8+",
              "Kh7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg8+",
              "Kh7",
              "Rg7+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+",
              "Kh8",
              "Rh6+",
              "Rh7",
              "Rg6+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1376,
          "total_completion_tokens": 656,
          "total_tokens": 2032
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/8/R3pk2/1p1p4/P2P4/2P3Kr/1P3P2/5b2 w - - 3 43"
    },
    {
      "turn": 85,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf4",
          "aggressive_uci": "g3f4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Rc6 bxc3 45. bxc3 Rh4+ 46. Kg3 Rh3+ 47. Kf4 Rh2 48. Kg3 Rh3+ 49. Kf4 Rh2 50. Kg3 Rh3+ 51. Kf4 Rh2 52. Kg3 Rh3+ 53. Kf4 Rh2 54. Kg3 Rh3+ 55. Kf4 Rh2 56. Kg3 Rh3+ 57. Kf4 Rh2 58. Kg3 Rh3+ 59. Kf4 Rh2 60. Kg3 Rh3+ 61. Kf4 Rh2 62. Kg3 Rh3+ 63. Kf4 Rh2 64. Kg3 Rh3+ 65. Kf4 Rh2 66. Kg3 Rh3+ 67. Kf4 Rh2 68. Kg3 Rh3+ 69. Kf4 Rh2 70. Kg3 Rh3+ 71. Kf4 Rh2 72. Kg3 Rh3+ 73. Kf4 Rh2 74. Kg3 Rh3+ 75. Kf4 Rh2 76. Kg3 Rh3+ 77. Kf4 Rh2 78. Kg3 Rh3+",
          "aggressive_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 640,
            "total_tokens": 1099,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rh2",
            "Kg3",
            "Rh3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8+ Kh7",
          "positional_tokens": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rg8+ Kh7 Rf7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg8 Rg7+ Kh8 Rh7+ Kg",
          "neutral_tokens": {
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rg8+",
            "Kh7",
            "Rf7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+",
            "Kg8",
            "Rg7+",
            "Kh8",
            "Rh7+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g3f4",
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": "g3f4",
          "source_agents": [
            "aggressive"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rh2",
              "Kg3",
              "Rh3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg8+",
              "Kh7",
              "Rf7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+",
              "Kg8",
              "Rg7+",
              "Kh8",
              "Rh7+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 459,
            "completion_tokens": 640,
            "total_tokens": 1099,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1376,
          "total_completion_tokens": 1288,
          "total_tokens": 2664
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 459,
            "completion_tokens": 640,
            "total_tokens": 1099,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 459,
            "completion_tokens": 8,
            "total_tokens": 467,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 84,
            "turn_number": 43,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 458,
            "completion_tokens": 640,
            "total_tokens": 1098,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/8/R3pk2/1p1p4/P2P4/2P3Kr/1P3P2/5b2 w - - 3 43"
    },
    {
      "turn": 87,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Ra8",
          "aggressive_uci": "a6a8",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rxc3 46. a5 Rc4 47. Ke3 Rc3+ 48. Kd2 Rd3+ 49. Ke1 Bg2 50. a6 Bf3 51. a7 Rd1#",
          "aggressive_tokens": {
            "prompt_tokens": 467,
            "completion_tokens": 423,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "bxc3",
            "bxc3",
            "Rxc3",
            "a5",
            "Rc4",
            "Ke3",
            "Rc3+",
            "Kd2",
            "Rd3+",
            "Ke1",
            "Bg2",
            "a6",
            "Bf3",
            "a7",
            "Rd1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Ra8",
          "positional_uci": "a6a8",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rxc3\n46. a5 Ra3 47. Rf8+ Ke7 48. Ra8 Kd6 49. Rd8+ Kc7 50. Ra8 Kb7 51. Re8 Bh3 52.\nRh8 Bf5 53. Ke5 Rxa5 54. Rh1 Ra2 55. f4 Kc6 56. Rc1+ Rc2 57. Ra1 Re2+ 58. Kf6\nRe4 59. Ra6+ Kb5 60. Ra8 Rxf4 61. Ke5 Re4+ 62. Kd6 Rxd4 63. Rb8+ Kc4 64. Rc8+\nKd3 65. Ke5 Re4+ 66. Kf6 d4 67. Rc1 Kd2 68. Ra1 d3 69. Ra2+ Ke3 70. Ra3 Ke2\n71. Ra2+ d2 72. Rb2 Ke1 73. Rxd2 Kxd2 74. Kg5 Ke3 75. Kf6 Kf4 76. Ke7 Rd4 77.\nKf6 e5 78. Ke7 e4",
          "positional_tokens": {
            "prompt_tokens": 467,
            "completion_tokens": 640,
            "total_tokens": 1107,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxf4",
            "Ke5",
            "Re4+",
            "Kd6",
            "Rxd4",
            "Rb8+",
            "Kc4",
            "Rc8+",
            "Kd3",
            "Ke5",
            "Re4+",
            "Kf6",
            "d4",
            "Rc1",
            "Kd2",
            "Ra1",
            "d3",
            "Ra2+",
            "Ke3",
            "Ra3",
            "Ke2",
            "Ra2+",
            "d2",
            "Rb2",
            "Ke1",
            "Rxd2",
            "Kxd2",
            "Kg5",
            "Ke3",
            "Kf6",
            "Kf4",
            "Ke7",
            "Rd4",
            "Kf6",
            "e5",
            "Ke7",
            "e4"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Ra8",
          "neutral_uci": "a6a8",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rxc3\n46. a5 Ra3 47. Rf8+ Ke7 48. Ra8 Kd6 49. Rd8+ Kc7 50. Ra8 Kb7 51. Re8 Bh3 52.\nRh8 Bf5 53. Ke5 Rxa5 54. Rh1 Ra2 55. f4 Kc6 56. Rc1+ Rc2 57. Ra1 Re2+ 58. Kf6\nRe4 59. Ra6+ Kb5 60. Ra8 Rxf4 61. Ke5 Re4+ 62. Kd6 Rxd4 63. Rb8+ Kc4 64. Rc8+\nKd3 65. Ke5 Rc4 66. Ra8 d4 67. Ra3+ Rc3 68. Ra4 Rc5+ 69. Kf4 Kc3 70. Ra3+ Kb4\n71. Ra1 d3 72. Ke3 Rc2 73. Rb1+ Kc3 74. Rb8 Re2+ 75. Kf3 Be4+ 76. Kf4 d2 77.\nRc8+ Kd3 78.",
          "neutral_tokens": {
            "prompt_tokens": 466,
            "completion_tokens": 640,
            "total_tokens": 1106,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d4",
            "Ra3+",
            "Rc3",
            "Ra4",
            "Rc5+",
            "Kf4",
            "Kc3",
            "Ra3+",
            "Kb4",
            "Ra1",
            "d3",
            "Ke3",
            "Rc2",
            "Rb1+",
            "Kc3",
            "Rb8",
            "Re2+",
            "Kf3",
            "Be4+",
            "Kf4",
            "d2",
            "Rc8+",
            "Kd3"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a6a8",
          "positional_uci": "a6a8",
          "neutral_uci": "a6a8",
          "consensus_move": "a6a8",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "bxc3",
              "bxc3",
              "Rxc3",
              "a5",
              "Rc4",
              "Ke3",
              "Rc3+",
              "Kd2",
              "Rd3+",
              "Ke1",
              "Bg2",
              "a6",
              "Bf3",
              "a7",
              "Rd1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxf4",
              "Ke5",
              "Re4+",
              "Kd6",
              "Rxd4",
              "Rb8+",
              "Kc4",
              "Rc8+",
              "Kd3",
              "Ke5",
              "Re4+",
              "Kf6",
              "d4",
              "Rc1",
              "Kd2",
              "Ra1",
              "d3",
              "Ra2+",
              "Ke3",
              "Ra3",
              "Ke2",
              "Ra2+",
              "d2",
              "Rb2",
              "Ke1",
              "Rxd2",
              "Kxd2",
              "Kg5",
              "Ke3",
              "Kf6",
              "Kf4",
              "Ke7",
              "Rd4",
              "Kf6",
              "e5",
              "Ke7",
              "e4"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "d4",
              "Ra3+",
              "Rc3",
              "Ra4",
              "Rc5+",
              "Kf4",
              "Kc3",
              "Ra3+",
              "Kb4",
              "Ra1",
              "d3",
              "Ke3",
              "Rc2",
              "Rb1+",
              "Kc3",
              "Rb8",
              "Re2+",
              "Kf3",
              "Be4+",
              "Kf4",
              "d2",
              "Rc8+",
              "Kd3"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 467,
            "completion_tokens": 423,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 467,
            "completion_tokens": 640,
            "total_tokens": 1107,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 466,
            "completion_tokens": 640,
            "total_tokens": 1106,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1400,
          "total_completion_tokens": 1703,
          "total_tokens": 3103
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 467,
            "completion_tokens": 423,
            "total_tokens": 890,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 467,
            "completion_tokens": 640,
            "total_tokens": 1107,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 86,
            "turn_number": 44,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 466,
            "completion_tokens": 640,
            "total_tokens": 1106,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/8/R3pk2/3p4/Pp1P1K2/2P4r/1P3P2/5b2 w - - 0 44"
    },
    {
      "turn": 89,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 dxe4",
          "aggressive_tokens": {
            "prompt_tokens": 475,
            "completion_tokens": 7,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "dxe4"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "bxc3",
          "positional_uci": "b2c3",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rxc3 46. a5 Rc4 47. Ke3 Rc3+ 48. Kd2 Rd3+ 49. Ke1 Bg2 50. a6 Rxd4 51. a7 Re4+ 52. Kd2 Rd4+ 53. Ke3 Re4+ 54. Kd2 Rd4+ 55. Ke3 Re4+ 56. Kd2 Rd4+ 57. Ke3 Re4+ 58. Kd2 Rd4+ 59. Ke3 Re4+ 60. Kd2 Rd4+ 61. Ke3 Re4+ 62. Kd2 Rd4+ 63. Ke3 Re4+ 64. Kd2 Rd4+ 65. Ke3 Re4+ 66. Kd2 Rd4+ 67. Ke3 Re4+ 68. Kd2 Rd4+ 69. Ke3 Re4+ 70. Kd2 Rd4+ 71. Ke3 Re4+ 72. Kd2 Rd4+ 73. Ke3 Re4+ 74. Kd2 Rd4+ 75. Ke3 Re4+ 76. Kd2 Rd4+ 77. Ke",
          "positional_tokens": {
            "prompt_tokens": 475,
            "completion_tokens": 640,
            "total_tokens": 1115,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxc3",
            "a5",
            "Rc4",
            "Ke3",
            "Rc3+",
            "Kd2",
            "Rd3+",
            "Ke1",
            "Bg2",
            "a6",
            "Rxd4",
            "a7",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+",
            "Ke3",
            "Re4+",
            "Kd2",
            "Rd4+"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "bxc3",
          "neutral_uci": "b2c3",
          "neutral_response": "Re8+ Bxe8\n45. bxc3 Rxc3 46. a5 Ra3 47. a6 Bb5 48. a7 Bc6 49. Rf8+ Ke7 50. Rh8 Rxa7 51.\nRh7+ Kd6 52. Rxa7 Bb5 53. Kg5 Bd3 54. f4 Bf5 55. Kf6 Kc6 56. Ra6+ Kb5 57. Rxe6\nBxe6 58. Kxe6 Kc4 59. Ke5 Kd3 60. f5 Ke3 61. f6 Kf3 62. f7 Ke3 63. f8=Q Kd3 64.\nKxd5 Kc3 65. Qf3+ Kb4 66. Qd3 Ka5 67. Kc5 Ka4 68. Qh3 Ka5 69. Qa3# Kf3 Kd2\n70. Ke4 Ke2 71. Qb2+ Kf1 72. Kf3 Ke1 73. Qe2# Kd1 74. Qb2 Ke1 75. Qe2# Kd1\n76. Qb2 Ke1 77. Qe2# Kd1 78. Qb2 Ke1 79. Qe2# Kd1 80. Qb2 Ke1 81. Qe2# Kd1\n82. Qb2 Ke1 83. Qe2# Kd1 84. Qb2 Ke1 85. Qe2# Kd1 86. Qb2 Ke1 87. Qe2# Kd1\n88. Qb2 Ke1 89. Qe2# Kd1 90. Qb2 Ke1 91. Qe2# Kd1 92. Qb2 Ke1 93. Qe2# Kd1\n94. Qb2 Ke1 95. Qe2# Kd1 96. Qb2 Ke1 97. Qe2# Kd1 98. Qb2 Ke1 99. Qe2# Kd1\n100. Qb2 Ke1 101. Qe2# Kd1 102. Qb2 Ke1 103. Qe2# Kd1 104. Qb2 Ke1 105. Qe2# Kd1 106. Qb2 Ke1 107. Qe2# Kd1 108. Qb2 Ke1 109. Qe2# Kd1 110. Qb2 Ke1 111. Qe2# Kd1 112. Qb2 Ke1 113. Qe2# Kd1 114. Qb2 Ke1 115. Qe2# Kd1 116. Qb2 Ke1",
          "neutral_tokens": {
            "prompt_tokens": 474,
            "completion_tokens": 640,
            "total_tokens": 1114,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rxc3",
            "a5",
            "Ra3",
            "a6",
            "Bb5",
            "a7",
            "Bc6",
            "Rf8+",
            "Ke7",
            "Rh8",
            "Rxa7",
            "Rh7+",
            "Kd6",
            "Rxa7",
            "Bb5",
            "Kg5",
            "Bd3",
            "f4",
            "Bf5",
            "Kf6",
            "Kc6",
            "Ra6+",
            "Kb5",
            "Rxe6",
            "Bxe6",
            "Kxe6",
            "Kc4",
            "Ke5",
            "Kd3",
            "f5",
            "Ke3",
            "f6",
            "Kf3",
            "f7",
            "Ke3",
            "f8=Q",
            "Kd3",
            "Kxd5",
            "Kc3",
            "Qf3+",
            "Kb4",
            "Qd3",
            "Ka5",
            "Kc5",
            "Ka4",
            "Qh3",
            "Ka5",
            "Qa3#",
            "Kf3",
            "Kd2",
            "Ke4",
            "Ke2",
            "Qb2+",
            "Kf1",
            "Kf3",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1",
            "Qe2#",
            "Kd1",
            "Qb2",
            "Ke1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "b2c3",
          "neutral_uci": "b2c3",
          "consensus_move": "b2c3",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "dxe4"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rxc3",
              "a5",
              "Rc4",
              "Ke3",
              "Rc3+",
              "Kd2",
              "Rd3+",
              "Ke1",
              "Bg2",
              "a6",
              "Rxd4",
              "a7",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+",
              "Ke3",
              "Re4+",
              "Kd2",
              "Rd4+"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxc3",
              "a5",
              "Ra3",
              "a6",
              "Bb5",
              "a7",
              "Bc6",
              "Rf8+",
              "Ke7",
              "Rh8",
              "Rxa7",
              "Rh7+",
              "Kd6",
              "Rxa7",
              "Bb5",
              "Kg5",
              "Bd3",
              "f4",
              "Bf5",
              "Kf6",
              "Kc6",
              "Ra6+",
              "Kb5",
              "Rxe6",
              "Bxe6",
              "Kxe6",
              "Kc4",
              "Ke5",
              "Kd3",
              "f5",
              "Ke3",
              "f6",
              "Kf3",
              "f7",
              "Ke3",
              "f8=Q",
              "Kd3",
              "Kxd5",
              "Kc3",
              "Qf3+",
              "Kb4",
              "Qd3",
              "Ka5",
              "Kc5",
              "Ka4",
              "Qh3",
              "Ka5",
              "Qa3#",
              "Kf3",
              "Kd2",
              "Ke4",
              "Ke2",
              "Qb2+",
              "Kf1",
              "Kf3",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1",
              "Qe2#",
              "Kd1",
              "Qb2",
              "Ke1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 475,
            "completion_tokens": 7,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 475,
            "completion_tokens": 640,
            "total_tokens": 1115,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 474,
            "completion_tokens": 640,
            "total_tokens": 1114,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1424,
          "total_completion_tokens": 1287,
          "total_tokens": 2711
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 475,
            "completion_tokens": 7,
            "total_tokens": 482,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 475,
            "completion_tokens": 640,
            "total_tokens": 1115,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 88,
            "turn_number": 45,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 474,
            "completion_tokens": 640,
            "total_tokens": 1114,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "R7/8/4pk2/3p4/P2P1K2/2p4r/1P3P2/5b2 w - - 0 45"
    },
    {
      "turn": 91,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "d4",
          "aggressive_uci": null,
          "aggressive_response": "d4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh5 b6 Qh4 Qg6 Qh6 Qxh6 gxh6 Rh8 g4 Bb7 Rh7 Rg1 Rxg5 Rxg5 Kxf6 Rg7 Be4 Rxc7 b5 Ra7 d5 Ra6 Bd3 Kd2 Bf1 Ke3 Rh7 Kf4 Rxh6 a4 Rh2 Kg3 Rh3+ Kf4 b4 Ra8 bxc3 bxc3 Rh4+ Kg3 Rh3+ Kf4 bxc3 Ra7 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+ Kf4 Rh2 Kg3 Rh3+",
          "aggressive_tokens": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4",
            "Qg6",
            "Qh6",
            "Qxh6",
            "gxh6",
            "Rh8",
            "g4",
            "Bb7",
            "Rh7",
            "Rg1",
            "Rxg5",
            "Rxg5",
            "Kxf6",
            "Rg7",
            "Be4",
            "Rxc7",
            "b5",
            "Ra7",
            "d5",
            "Ra6",
            "Bd3",
            "Kd2",
            "Bf1",
            "Ke3",
            "Rh7",
            "Kf4",
            "Rxh6",
            "a4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "b4",
            "Ra8",
            "bxc3",
            "bxc3",
            "Rh4+",
            "Kg3",
            "Rh3+",
            "Kf4",
            "bxc3",
            "Ra7",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "Rh2",
            "Kg3",
            "Rh3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "d4",
          "positional_uci": null,
          "positional_response": "d4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh5 b6 Qh4 Qg6 Qh6 Qxh6 gxh6 Rh8 Bb7 Rh7 Ke8 g4 a6 Rf6 Ke7 Rg6 Rxg5 Rxg5 Kxf6 Rg7 Be4 Rxc7 b5 a4 bxc3 bxc3 Rh4 Kg3 Rh6 f4 Rh1 a5 Rg1+ Kf2 Rh1 a6 Rg1 a7 Rg2+ Ke3 Rg3+ Kd2 Rg2+ Kc1 Rg1+ Kb2 Rg2+ Kb3 Rg3 a8=Q Rg1 Qf8+ Kg2 Qf7+ Kh3 Qf3+ Kh4 Qf4+ Kh5 Qf5+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf6+ Kh7 Qf7+ Kh6 Qf",
          "positional_tokens": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "f5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "Bxf6",
            "e4",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Neg5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4",
            "Qg6",
            "Qh6",
            "Qxh6",
            "gxh6",
            "Rh8",
            "Bb7",
            "Rh7",
            "Ke8",
            "g4",
            "a6",
            "Rf6",
            "Ke7",
            "Rg6",
            "Rxg5",
            "Rxg5",
            "Kxf6",
            "Rg7",
            "Be4",
            "Rxc7",
            "b5",
            "a4",
            "bxc3",
            "bxc3",
            "Rh4",
            "Kg3",
            "Rh6",
            "f4",
            "Rh1",
            "a5",
            "Rg1+",
            "Kf2",
            "Rh1",
            "a6",
            "Rg1",
            "a7",
            "Rg2+",
            "Ke3",
            "Rg3+",
            "Kd2",
            "Rg2+",
            "Kc1",
            "Rg1+",
            "Kb2",
            "Rg2+",
            "Kb3",
            "Rg3",
            "a8=Q",
            "Rg1",
            "Qf8+",
            "Kg2",
            "Qf7+",
            "Kh3",
            "Qf3+",
            "Kh4",
            "Qf4+",
            "Kh5",
            "Qf5+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6",
            "Qf6+",
            "Kh7",
            "Qf7+",
            "Kh6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kg3",
          "neutral_uci": "f4g3",
          "neutral_response": "46. Kg3 Rh3+ 47. Kf4 Rxc3 48. a5 Ra3 49. Ra7 Ra4 50. Ke3 Ra3+ 51. Kf4 Be2 52.\nRa8 Rf3+ 53. Kg4 Rxf2+ 54. Kg3 Rf3+ 55. Kg2 Ra3 56. Kf2 Bc4 57. Ke1 Kf5 58.\nKd2 Ke4 59. Re8 Kxd4 60. Rxe6 Ra2+ 61. Kc1 Kc3 62. Kb1 Rxa5 63. Re3+ Bd3+ 64.\nRxd3+ Kxd3 65. Kb2 Rb5+ 66. Ka3 Kc4 67. Ka4 d4 68. Ka3 d3 69. Ka2 d2 70. Ka3\nd1=Q 71. Ka2 Qa4# d4 d3 d2",
          "neutral_tokens": {
            "prompt_tokens": 483,
            "completion_tokens": 222,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rf3+",
            "Kg2",
            "Ra3",
            "Kf2",
            "Bc4",
            "Ke1",
            "Kf5",
            "Kd2",
            "Ke4",
            "Re8",
            "Kxd4",
            "Rxe6",
            "Ra2+",
            "Kc1",
            "Kc3",
            "Kb1",
            "Rxa5",
            "Re3+",
            "Bd3+",
            "Rxd3+",
            "Kxd3",
            "Kb2",
            "Rb5+",
            "Ka3",
            "Kc4",
            "Ka4",
            "d4",
            "Ka3",
            "d3",
            "Ka2",
            "d2",
            "Ka3",
            "d1=Q",
            "Ka2",
            "Qa4#",
            "d4",
            "d3",
            "d2"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": "f4g3",
          "consensus_move": "f4g3",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4",
              "Qg6",
              "Qh6",
              "Qxh6",
              "gxh6",
              "Rh8",
              "g4",
              "Bb7",
              "Rh7",
              "Rg1",
              "Rxg5",
              "Rxg5",
              "Kxf6",
              "Rg7",
              "Be4",
              "Rxc7",
              "b5",
              "Ra7",
              "d5",
              "Ra6",
              "Bd3",
              "Kd2",
              "Bf1",
              "Ke3",
              "Rh7",
              "Kf4",
              "Rxh6",
              "a4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "b4",
              "Ra8",
              "bxc3",
              "bxc3",
              "Rh4+",
              "Kg3",
              "Rh3+",
              "Kf4",
              "bxc3",
              "Ra7",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "Rh2",
              "Kg3",
              "Rh3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "f5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "Bxf6",
              "e4",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Neg5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4",
              "Qg6",
              "Qh6",
              "Qxh6",
              "gxh6",
              "Rh8",
              "Bb7",
              "Rh7",
              "Ke8",
              "g4",
              "a6",
              "Rf6",
              "Ke7",
              "Rg6",
              "Rxg5",
              "Rxg5",
              "Kxf6",
              "Rg7",
              "Be4",
              "Rxc7",
              "b5",
              "a4",
              "bxc3",
              "bxc3",
              "Rh4",
              "Kg3",
              "Rh6",
              "f4",
              "Rh1",
              "a5",
              "Rg1+",
              "Kf2",
              "Rh1",
              "a6",
              "Rg1",
              "a7",
              "Rg2+",
              "Ke3",
              "Rg3+",
              "Kd2",
              "Rg2+",
              "Kc1",
              "Rg1+",
              "Kb2",
              "Rg2+",
              "Kb3",
              "Rg3",
              "a8=Q",
              "Rg1",
              "Qf8+",
              "Kg2",
              "Qf7+",
              "Kh3",
              "Qf3+",
              "Kh4",
              "Qf4+",
              "Kh5",
              "Qf5+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6",
              "Qf6+",
              "Kh7",
              "Qf7+",
              "Kh6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rf3+",
              "Kg2",
              "Ra3",
              "Kf2",
              "Bc4",
              "Ke1",
              "Kf5",
              "Kd2",
              "Ke4",
              "Re8",
              "Kxd4",
              "Rxe6",
              "Ra2+",
              "Kc1",
              "Kc3",
              "Kb1",
              "Rxa5",
              "Re3+",
              "Bd3+",
              "Rxd3+",
              "Kxd3",
              "Kb2",
              "Rb5+",
              "Ka3",
              "Kc4",
              "Ka4",
              "d4",
              "Ka3",
              "d3",
              "Ka2",
              "d2",
              "Ka3",
              "d1=Q",
              "Ka2",
              "Qa4#",
              "d4",
              "d3",
              "d2"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 483,
            "completion_tokens": 222,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1451,
          "total_completion_tokens": 1502,
          "total_tokens": 2953
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 484,
            "completion_tokens": 640,
            "total_tokens": 1124,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 90,
            "turn_number": 46,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 483,
            "completion_tokens": 222,
            "total_tokens": 705,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "R7/8/4pk2/3p4/P2P1K1r/2P5/5P2/5b2 w - - 1 46"
    },
    {
      "turn": 93,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kf4",
          "aggressive_uci": "g3f4",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kf4 Rxc3 48. a5 Rc4 49. Ke3 Rc3+ 50. Kf4 Ra3 51. Ra7 Ra4 52.\nKe3 Ra3+ 53. Kf4 Ra4 54. Ke3 Ra3+ 55. Kf4 Ra4 56. Ke3 Ra3+ 57. Kf4 Ra4 58. Ke3 Ra3+ 59. Kf4 Ra4 60. Ke3 Ra3+ 61. Kf4 Ra4 62. Ke3 Ra3+ 63. Kf4 Ra4 64. Ke3 Ra3+ 65. Kf4 Ra4 66. Ke3 Ra3+ 67. Kf4 Ra4 68. Ke3 Ra3+ 69. Kf4 Ra4 70. Ke3 Ra3+ 71. Kf4 Ra4 72. Ke3 Ra3+ 73. Kf4 Ra4 74. Ke3 Ra3+ 75. Kf4 Ra4 76. Ke3 Ra3+ 77. Kf4 Ra4 78. Ke3 Ra3+ 79.",
          "aggressive_tokens": {
            "prompt_tokens": 491,
            "completion_tokens": 640,
            "total_tokens": 1131,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Ra4",
            "Ke3",
            "Ra3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8+ Kh7",
          "positional_tokens": {
            "prompt_tokens": 491,
            "completion_tokens": 8,
            "total_tokens": 499,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8+",
            "Kh7"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kg4",
          "neutral_uci": "g3g4",
          "neutral_response": "47. Kg4 Rxc3 48. a5 Be2+ 49. Kh4 Kf5 50. Rf8+ Ke4 51. Re8 Kxd4 52. Rxe6 Bf1 53. a6 Ra3 54. f4 Rxa6 55. Rxa6 Bxa6 56. f5 Ke5 57. Kg5 d4 58. f6 Bc4 59. Kg6 d3 60. f7 Bxf7+ 61. Kxf7 d2 62. Ke7 d1=Q 63. Kf7 Qd7+ 64. Kg6 Qe7 65. Kh6 Kf5 66. Kh5 Qh7#",
          "neutral_tokens": {
            "prompt_tokens": 490,
            "completion_tokens": 164,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxc3",
            "a5",
            "Be2+",
            "Kh4",
            "Kf5",
            "Rf8+",
            "Ke4",
            "Re8",
            "Kxd4",
            "Rxe6",
            "Bf1",
            "a6",
            "Ra3",
            "f4",
            "Rxa6",
            "Rxa6",
            "Bxa6",
            "f5",
            "Ke5",
            "Kg5",
            "d4",
            "f6",
            "Bc4",
            "Kg6",
            "d3",
            "f7",
            "Bxf7+",
            "Kxf7",
            "d2",
            "Ke7",
            "d1=Q",
            "Kf7",
            "Qd7+",
            "Kg6",
            "Qe7",
            "Kh6",
            "Kf5",
            "Kh5",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g3f4",
          "positional_uci": null,
          "neutral_uci": "g3g4",
          "consensus_move": "g3g4",
          "source_agents": [
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Ra4",
              "Ke3",
              "Ra3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8+",
              "Kh7"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxc3",
              "a5",
              "Be2+",
              "Kh4",
              "Kf5",
              "Rf8+",
              "Ke4",
              "Re8",
              "Kxd4",
              "Rxe6",
              "Bf1",
              "a6",
              "Ra3",
              "f4",
              "Rxa6",
              "Rxa6",
              "Bxa6",
              "f5",
              "Ke5",
              "Kg5",
              "d4",
              "f6",
              "Bc4",
              "Kg6",
              "d3",
              "f7",
              "Bxf7+",
              "Kxf7",
              "d2",
              "Ke7",
              "d1=Q",
              "Kf7",
              "Qd7+",
              "Kg6",
              "Qe7",
              "Kh6",
              "Kf5",
              "Kh5",
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 491,
            "completion_tokens": 640,
            "total_tokens": 1131,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 491,
            "completion_tokens": 8,
            "total_tokens": 499,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 490,
            "completion_tokens": 164,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1472,
          "total_completion_tokens": 812,
          "total_tokens": 2284
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 92,
            "turn_number": 47,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 491,
            "completion_tokens": 640,
            "total_tokens": 1131,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 92,
            "turn_number": 47,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 491,
            "completion_tokens": 8,
            "total_tokens": 499,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 92,
            "turn_number": 47,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 490,
            "completion_tokens": 164,
            "total_tokens": 654,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "R7/8/4pk2/3p4/P2P4/2P3Kr/5P2/5b2 w - - 3 47"
    },
    {
      "turn": 95,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rf8+",
          "aggressive_uci": "a8f8",
          "aggressive_response": "48. Rf8+ Ke7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1\n52. Ke3 Rxa4 53. Kd3 Kd6 54. f4 Ra1 55. Ke3 Rd1 56. Ke2 Rc1 57. Kd2 Rf1 58.\nKe3 Kc6 59. Ke2 Rxf4 60. Ke3 Rf1 61. Ke2 Rc1 62. Kd2 Rf1 63. Ke2 Rf8 64. Ke3\nKb5 65. Kd3 Rf3+ 66. Kd2 Kc4 67. Ke2 Rxc3 68. Kd2 Kxd4 69. Ke2 Rd3 70. Kf2\nRe3 71. Kg2 Ke4 72. Kf2 d4 73. Kg2 d3 74. Kf2 d2 75. Kg2 d1=Q 76. Kf2 Qd2+ 77.\nKf1 Re1# d4 f5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 Bxf6 e4 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Ng5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh5 b6 Qh4+ Kd7 Qh6 Bb7 Qh7+ Qxh7 Rxh7+ Kc6 Be4+ d5 Bf3 Rf6 Re1 Re8 Nxh7 Rf5 Bg4 Rf4 Rxe6+ Rxe6 Bxe6 Kd6 Bg4 Bc6 f4 Bd7 Bxd7 Kxd7 g4 Ke6 Ke3 Kf6 Kf3 Kg6 Kg3 Kxh7 Kh4 Kg6 f5+ Kf6 Kh5 c5 Kh6 cxd4 cxd4 b5 g5+ Kxf5 g6 d3 g7 d2 g8=Q d1=Q Qf8+ Ke5 Qe8+ Kd4 Qh8+ Kc4 Qxa1 Qd5 Qxa7+ Kc3 Qa3+ b4 Qa4+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc2 Qa2+ Kc3 Qa3+ Kc",
          "aggressive_tokens": {
            "prompt_tokens": 498,
            "completion_tokens": 640,
            "total_tokens": 1138,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4+",
            "Kd7",
            "Qh6",
            "Bb7",
            "Qh7+",
            "Qxh7",
            "Rxh7+",
            "Kc6",
            "Be4+",
            "d5",
            "Bf3",
            "Rf6",
            "Re1",
            "Re8",
            "Nxh7",
            "Rf5",
            "Bg4",
            "Rf4",
            "Rxe6+",
            "Rxe6",
            "Bxe6",
            "Kd6",
            "Bg4",
            "Bc6",
            "f4",
            "Bd7",
            "Bxd7",
            "Kxd7",
            "g4",
            "Ke6",
            "Ke3",
            "Kf6",
            "Kf3",
            "Kg6",
            "Kg3",
            "Kxh7",
            "Kh4",
            "Kg6",
            "f5+",
            "Kf6",
            "Kh5",
            "c5",
            "Kh6",
            "cxd4",
            "cxd4",
            "b5",
            "g5+",
            "Kxf5",
            "g6",
            "d3",
            "g7",
            "d2",
            "g8=Q",
            "d1=Q",
            "Qf8+",
            "Ke5",
            "Qe8+",
            "Kd4",
            "Qh8+",
            "Kc4",
            "Qxa1",
            "Qd5",
            "Qxa7+",
            "Kc3",
            "Qa3+",
            "b4",
            "Qa4+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+",
            "Kc2",
            "Qa2+",
            "Kc3",
            "Qa3+"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rf8+",
          "positional_uci": "a8f8",
          "positional_response": "48. Rf8+ Ke7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52. Ke3 Rxa4 53. Kd3 Kd6 54. f4\nRa3 55. Kc2 Kc6 56. Kb2 Ra8 57. Kb3 Kb5 58. Kc2 Kc4 59. Kd2 Ra2+ 60. Ke3 Kxc3\n61. Kf3 Kxd4 62. Kg4 Ke4 63. Kg5 Rg2+ 64. Kf6 Kxf4 65. Kxe6 d4 66. Kd5 d3\n67. Kc4 d2 68. Kc3 d1=Q 69. Kc4 Rc2+ 70. Kb3 Qb1+ 71. Ka3 Ra2#",
          "positional_tokens": {
            "prompt_tokens": 498,
            "completion_tokens": 201,
            "total_tokens": 699,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Ke7",
            "Rf3",
            "Be2",
            "Kg3",
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kd6",
            "f4",
            "Ra3",
            "Kc2",
            "Kc6",
            "Kb2",
            "Ra8",
            "Kb3",
            "Kb5",
            "Kc2",
            "Kc4",
            "Kd2",
            "Ra2+",
            "Ke3",
            "Kxc3",
            "Kf3",
            "Kxd4",
            "Kg4",
            "Ke4",
            "Kg5",
            "Rg2+",
            "Kf6",
            "Kxf4",
            "Kxe6",
            "d4",
            "Kd5",
            "d3",
            "Kc4",
            "d2",
            "Kc3",
            "d1=Q",
            "Kc4",
            "Rc2+",
            "Kb3",
            "Qb1+",
            "Ka3",
            "Ra2#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a5",
          "neutral_uci": "a4a5",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. a5 Be2+ 49. Kg3 Ra1 50. Kf4 Ra3 51. Rf8+ Ke7 52.\nRa8 Rxc3 53. a6 Ra3 54. a7 Kf7 55. Ke5 Ra6 56. f4 Bd3 57. f5 Bxf5 58. Kf4\nKg7 59. Ke5 Bg4 60. Kf4 Bh5 61. Ke5 Bf7 62. Kf4 Kf6 63. Ke3 Ra3+ 64. Kf4 Bg6\n65. Rf8+ Ke7 66. a8=Q Rxa8 67. Rxa8 Kd6 68. Ra6+ Kd7 69. Ke5 Bf5 70. Ra7+ Kc6\n71. Ra6+ Kb5 72. Rxe6 Bxe6 73. Kxe6 Kc4 74. Ke5 Kb5 75. Kxd5 Kb6 76. Kd6 Kb7\n77. Kd7 Kb6 78.",
          "neutral_tokens": {
            "prompt_tokens": 497,
            "completion_tokens": 640,
            "total_tokens": 1137,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Be2+",
            "Kg3",
            "Ra1",
            "Kf4",
            "Ra3",
            "Rf8+",
            "Ke7",
            "Ra8",
            "Rxc3",
            "a6",
            "Ra3",
            "a7",
            "Kf7",
            "Ke5",
            "Ra6",
            "f4",
            "Bd3",
            "f5",
            "Bxf5",
            "Kf4",
            "Kg7",
            "Ke5",
            "Bg4",
            "Kf4",
            "Bh5",
            "Ke5",
            "Bf7",
            "Kf4",
            "Kf6",
            "Ke3",
            "Ra3+",
            "Kf4",
            "Bg6",
            "Rf8+",
            "Ke7",
            "a8=Q",
            "Rxa8",
            "Rxa8",
            "Kd6",
            "Ra6+",
            "Kd7",
            "Ke5",
            "Bf5",
            "Ra7+",
            "Kc6",
            "Ra6+",
            "Kb5",
            "Rxe6",
            "Bxe6",
            "Kxe6",
            "Kc4",
            "Ke5",
            "Kb5",
            "Kxd5",
            "Kb6",
            "Kd6",
            "Kb7",
            "Kd7",
            "Kb6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a8f8",
          "positional_uci": "a8f8",
          "neutral_uci": "a4a5",
          "consensus_move": "a8f8",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4+",
              "Kd7",
              "Qh6",
              "Bb7",
              "Qh7+",
              "Qxh7",
              "Rxh7+",
              "Kc6",
              "Be4+",
              "d5",
              "Bf3",
              "Rf6",
              "Re1",
              "Re8",
              "Nxh7",
              "Rf5",
              "Bg4",
              "Rf4",
              "Rxe6+",
              "Rxe6",
              "Bxe6",
              "Kd6",
              "Bg4",
              "Bc6",
              "f4",
              "Bd7",
              "Bxd7",
              "Kxd7",
              "g4",
              "Ke6",
              "Ke3",
              "Kf6",
              "Kf3",
              "Kg6",
              "Kg3",
              "Kxh7",
              "Kh4",
              "Kg6",
              "f5+",
              "Kf6",
              "Kh5",
              "c5",
              "Kh6",
              "cxd4",
              "cxd4",
              "b5",
              "g5+",
              "Kxf5",
              "g6",
              "d3",
              "g7",
              "d2",
              "g8=Q",
              "d1=Q",
              "Qf8+",
              "Ke5",
              "Qe8+",
              "Kd4",
              "Qh8+",
              "Kc4",
              "Qxa1",
              "Qd5",
              "Qxa7+",
              "Kc3",
              "Qa3+",
              "b4",
              "Qa4+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+",
              "Kc2",
              "Qa2+",
              "Kc3",
              "Qa3+"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Ke7",
              "Rf3",
              "Be2",
              "Kg3",
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kd6",
              "f4",
              "Ra3",
              "Kc2",
              "Kc6",
              "Kb2",
              "Ra8",
              "Kb3",
              "Kb5",
              "Kc2",
              "Kc4",
              "Kd2",
              "Ra2+",
              "Ke3",
              "Kxc3",
              "Kf3",
              "Kxd4",
              "Kg4",
              "Ke4",
              "Kg5",
              "Rg2+",
              "Kf6",
              "Kxf4",
              "Kxe6",
              "d4",
              "Kd5",
              "d3",
              "Kc4",
              "d2",
              "Kc3",
              "d1=Q",
              "Kc4",
              "Rc2+",
              "Kb3",
              "Qb1+",
              "Ka3",
              "Ra2#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be2+",
              "Kg3",
              "Ra1",
              "Kf4",
              "Ra3",
              "Rf8+",
              "Ke7",
              "Ra8",
              "Rxc3",
              "a6",
              "Ra3",
              "a7",
              "Kf7",
              "Ke5",
              "Ra6",
              "f4",
              "Bd3",
              "f5",
              "Bxf5",
              "Kf4",
              "Kg7",
              "Ke5",
              "Bg4",
              "Kf4",
              "Bh5",
              "Ke5",
              "Bf7",
              "Kf4",
              "Kf6",
              "Ke3",
              "Ra3+",
              "Kf4",
              "Bg6",
              "Rf8+",
              "Ke7",
              "a8=Q",
              "Rxa8",
              "Rxa8",
              "Kd6",
              "Ra6+",
              "Kd7",
              "Ke5",
              "Bf5",
              "Ra7+",
              "Kc6",
              "Ra6+",
              "Kb5",
              "Rxe6",
              "Bxe6",
              "Kxe6",
              "Kc4",
              "Ke5",
              "Kb5",
              "Kxd5",
              "Kb6",
              "Kd6",
              "Kb7",
              "Kd7",
              "Kb6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 498,
            "completion_tokens": 640,
            "total_tokens": 1138,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 498,
            "completion_tokens": 201,
            "total_tokens": 699,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 497,
            "completion_tokens": 640,
            "total_tokens": 1137,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1493,
          "total_completion_tokens": 1481,
          "total_tokens": 2974
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 94,
            "turn_number": 48,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 498,
            "completion_tokens": 640,
            "total_tokens": 1138,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 94,
            "turn_number": 48,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 498,
            "completion_tokens": 201,
            "total_tokens": 699,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 94,
            "turn_number": 48,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 497,
            "completion_tokens": 640,
            "total_tokens": 1137,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "R7/8/4pk2/3p4/P2P2K1/2P5/5P2/5b1r w - - 5 48"
    },
    {
      "turn": 97,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rf3",
          "aggressive_uci": "f8f3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Kf5 55. f3 Kf4 56. Kc2 Kxf3 57. Kb3 Rc4 58. Kb2\nKe3 59. Kc2 Ke2 60. Kb3 Kd3 61. Kb2 Rxc3 62. Kb1 Kxd4 63. Kb2 Kc4 64. Kb1 Kb3 65.\nKa1 Rc1#",
          "aggressive_tokens": {
            "prompt_tokens": 507,
            "completion_tokens": 535,
            "total_tokens": 1042,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Kg3",
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kf5",
            "f3",
            "Kf4",
            "Kc2",
            "Kxf3",
            "Kb3",
            "Rc4",
            "Kb2",
            "Ke3",
            "Kc2",
            "Ke2",
            "Kb3",
            "Kd3",
            "Kb2",
            "Rxc3",
            "Kb1",
            "Kxd4",
            "Kb2",
            "Kc4",
            "Kb1",
            "Kb3",
            "Ka1",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Rf3",
          "positional_uci": "f8f3",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Kf5 55. f3 Kf4 56. Kc2 Kxf3 57. Kb3 Rc4 58. Kc2\nKe3 59. Kb3 Kd3 60. Kb2 Rxc3 61. Kb1 Kxd4 62. Kb2 Kc4 63. Kb1 Kb3 64. Ka1 Rc1#",
          "positional_tokens": {
            "prompt_tokens": 507,
            "completion_tokens": 528,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Kg3",
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kf5",
            "f3",
            "Kf4",
            "Kc2",
            "Kxf3",
            "Kb3",
            "Rc4",
            "Kc2",
            "Ke3",
            "Kb3",
            "Kd3",
            "Kb2",
            "Rxc3",
            "Kb1",
            "Kxd4",
            "Kb2",
            "Kc4",
            "Kb1",
            "Kb3",
            "Ka1",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Rf3",
          "neutral_uci": "f8f3",
          "neutral_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Kf5 55. f3 Kf4 56. Kc2 Kxf3 57. Kb3 Rc4 58. Kc2\nKe3 59. Kb3 Kd3 60. Kb2 Rxc3 61. Kb1 Kxd4 62. Kb2 Kc4 63. Kb1 Kb3 64. Ka1 Rc1#",
          "neutral_tokens": {
            "prompt_tokens": 506,
            "completion_tokens": 528,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Be2",
            "Kg3",
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kf5",
            "f3",
            "Kf4",
            "Kc2",
            "Kxf3",
            "Kb3",
            "Rc4",
            "Kc2",
            "Ke3",
            "Kb3",
            "Kd3",
            "Kb2",
            "Rxc3",
            "Kb1",
            "Kxd4",
            "Kb2",
            "Kc4",
            "Kb1",
            "Kb3",
            "Ka1",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f8f3",
          "positional_uci": "f8f3",
          "neutral_uci": "f8f3",
          "consensus_move": "f8f3",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Be2",
              "Kg3",
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kf5",
              "f3",
              "Kf4",
              "Kc2",
              "Kxf3",
              "Kb3",
              "Rc4",
              "Kb2",
              "Ke3",
              "Kc2",
              "Ke2",
              "Kb3",
              "Kd3",
              "Kb2",
              "Rxc3",
              "Kb1",
              "Kxd4",
              "Kb2",
              "Kc4",
              "Kb1",
              "Kb3",
              "Ka1",
              "Rc1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Be2",
              "Kg3",
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kf5",
              "f3",
              "Kf4",
              "Kc2",
              "Kxf3",
              "Kb3",
              "Rc4",
              "Kc2",
              "Ke3",
              "Kb3",
              "Kd3",
              "Kb2",
              "Rxc3",
              "Kb1",
              "Kxd4",
              "Kb2",
              "Kc4",
              "Kb1",
              "Kb3",
              "Ka1",
              "Rc1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Be2",
              "Kg3",
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kf5",
              "f3",
              "Kf4",
              "Kc2",
              "Kxf3",
              "Kb3",
              "Rc4",
              "Kc2",
              "Ke3",
              "Kb3",
              "Kd3",
              "Kb2",
              "Rxc3",
              "Kb1",
              "Kxd4",
              "Kb2",
              "Kc4",
              "Kb1",
              "Kb3",
              "Ka1",
              "Rc1#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 507,
            "completion_tokens": 535,
            "total_tokens": 1042,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 507,
            "completion_tokens": 528,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 506,
            "completion_tokens": 528,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1520,
          "total_completion_tokens": 1591,
          "total_tokens": 3111
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 96,
            "turn_number": 49,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 507,
            "completion_tokens": 535,
            "total_tokens": 1042,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 96,
            "turn_number": 49,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 507,
            "completion_tokens": 528,
            "total_tokens": 1035,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 96,
            "turn_number": 49,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 506,
            "completion_tokens": 528,
            "total_tokens": 1034,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "5R2/6k1/4p3/3p4/P2P2K1/2P5/5P2/5b1r w - - 7 49"
    },
    {
      "turn": 99,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Kg3",
          "aggressive_uci": "g4g3",
          "aggressive_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Kf5 55. f3 Kf4 56. Kc2 Kxf3 57. Kb3 Rc4 58. Kc2\nKe3 59. Kb3 Kd3 60. Kb2 Rxc3 61. Kb1 Kxd4 62. Kb2 Kc4 63. Kb1 Kb3 64. Ka1 Rc1#",
          "aggressive_tokens": {
            "prompt_tokens": 515,
            "completion_tokens": 528,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Kf5",
            "f3",
            "Kf4",
            "Kc2",
            "Kxf3",
            "Kb3",
            "Rc4",
            "Kc2",
            "Ke3",
            "Kb3",
            "Kd3",
            "Kb2",
            "Rxc3",
            "Kb1",
            "Kxd4",
            "Kb2",
            "Kc4",
            "Kb1",
            "Kb3",
            "Ka1",
            "Rc1#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kg3",
          "positional_uci": "g4g3",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Bxf3 51. Kxf3 Ra1 52.\nKf4 Kf6 53. Ke3 Rxa4 54. Kd3 Ra2 55. f3 Kf5 56. c4 Ra3+ 57. Ke2 dxc4 58. Kd2\nRxf3 59. Ke2 Ke4 60. Kd2 Kxd4 61. Ke2 Rf4 62. Kd2 Rf2+ 63. Ke1 Ke3 64. Kd1 Kd3\n65. Ke1 Rf3 66. Kd1 Rf1#",
          "positional_tokens": {
            "prompt_tokens": 515,
            "completion_tokens": 549,
            "total_tokens": 1064,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf3",
            "Kxf3",
            "Ra1",
            "Kf4",
            "Kf6",
            "Ke3",
            "Rxa4",
            "Kd3",
            "Ra2",
            "f3",
            "Kf5",
            "c4",
            "Ra3+",
            "Ke2",
            "dxc4",
            "Kd2",
            "Rxf3",
            "Ke2",
            "Ke4",
            "Kd2",
            "Kxd4",
            "Ke2",
            "Rf4",
            "Kd2",
            "Rf2+",
            "Ke1",
            "Ke3",
            "Kd1",
            "Kd3",
            "Ke1",
            "Rf3",
            "Kd1",
            "Rf1#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8+",
          "neutral_uci": null,
          "neutral_response": "Re8+ Kf7 Rf8+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+ Kg8 Rf6+ Kg7 Rf7+",
          "neutral_tokens": {
            "prompt_tokens": 514,
            "completion_tokens": 640,
            "total_tokens": 1154,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf7",
            "Rf8+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+",
            "Kg8",
            "Rf6+",
            "Kg7",
            "Rf7+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "g4g3",
          "positional_uci": "g4g3",
          "neutral_uci": null,
          "consensus_move": "g4g3",
          "source_agents": [
            "aggressive",
            "positional"
          ],
          "selected_agent": "aggressive"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Kf5",
              "f3",
              "Kf4",
              "Kc2",
              "Kxf3",
              "Kb3",
              "Rc4",
              "Kc2",
              "Ke3",
              "Kb3",
              "Kd3",
              "Kb2",
              "Rxc3",
              "Kb1",
              "Kxd4",
              "Kb2",
              "Kc4",
              "Kb1",
              "Kb3",
              "Ka1",
              "Rc1#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf3",
              "Kxf3",
              "Ra1",
              "Kf4",
              "Kf6",
              "Ke3",
              "Rxa4",
              "Kd3",
              "Ra2",
              "f3",
              "Kf5",
              "c4",
              "Ra3+",
              "Ke2",
              "dxc4",
              "Kd2",
              "Rxf3",
              "Ke2",
              "Ke4",
              "Kd2",
              "Kxd4",
              "Ke2",
              "Rf4",
              "Kd2",
              "Rf2+",
              "Ke1",
              "Ke3",
              "Kd1",
              "Kd3",
              "Ke1",
              "Rf3",
              "Kd1",
              "Rf1#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf7",
              "Rf8+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+",
              "Kg8",
              "Rf6+",
              "Kg7",
              "Rf7+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 515,
            "completion_tokens": 528,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 515,
            "completion_tokens": 549,
            "total_tokens": 1064,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 514,
            "completion_tokens": 640,
            "total_tokens": 1154,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1544,
          "total_completion_tokens": 1717,
          "total_tokens": 3261
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 98,
            "turn_number": 50,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 515,
            "completion_tokens": 528,
            "total_tokens": 1043,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 98,
            "turn_number": 50,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 515,
            "completion_tokens": 549,
            "total_tokens": 1064,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 98,
            "turn_number": 50,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 514,
            "completion_tokens": 640,
            "total_tokens": 1154,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/6k1/4p3/3p4/P2P2K1/2P2R2/4bP2/7r w - - 9 50"
    },
    {
      "turn": 101,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 Nf3 Nc6 Bb5 Bf5 Bxf6 gxf6 e5 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Ne5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxh7 Rh8 Qh6 Qxh6 gxh6 Bb7 Rh5 d5 Bd3 Ke8 Rg3 Rxg5 Rxg5 Kxf6 Rg7 Be4 Rxc7 b5 Ra7 d5 Ra6 Bd3 Kd2 Bf1 Ke3 Rh7 Kf4 Rxh6 a4 Rh2 Kg3 Rh3+ Kf4 b4 Ra8 bxc3 bxc3 Rh4+ Kg3 Rh3+ Kg4 Rh1 Rf8+ Kg7 Rf3 Bf1 *",
          "aggressive_tokens": {
            "prompt_tokens": 524,
            "completion_tokens": 205,
            "total_tokens": 729,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nc6",
            "Bb5",
            "Bf5",
            "Bxf6",
            "gxf6",
            "e5",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Ne5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxh7",
            "Rh8",
            "Qh6",
            "Qxh6",
            "gxh6",
            "Bb7",
            "Rh5",
            "d5",
            "Bd3",
            "Ke8",
            "Rg3",
            "Rxg5",
            "Rxg5",
            "Kxf6",
            "Rg7",
            "Be4",
            "Rxc7",
            "b5",
            "Ra7",
            "d5",
            "Ra6",
            "Bd3",
            "Kd2",
            "Bf1",
            "Ke3",
            "Rh7",
            "Kf4",
            "Rxh6",
            "a4",
            "Rh2",
            "Kg3",
            "Rh3+",
            "Kf4",
            "b4",
            "Ra8",
            "bxc3",
            "bxc3",
            "Rh4+",
            "Kg3",
            "Rh3+",
            "Kg4",
            "Rh1",
            "Rf8+",
            "Kg7",
            "Rf3",
            "Bf1"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Kh2",
          "positional_uci": "g3h2",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Rg1+ 51. Kh2 Bxf3 52. Kxg1 Be2 53. Kg2 Kf6 54. Kg3 Kf5 55. f3 Bd3 56. a5 Bc4 57. Kf2 Kf4 58. Kg2 Ke3 59. Kg3 Kd3 60. Kf4 Kxc3 61. Ke5 Kd3 62. Kxe6 Kxd4 63. f4 Ke4 64. f5 d4+ 65. Kd6 d3 66. f6 d2 67. Kc5 d1=Q 68. Kxc4 Qd5+ 69. Kb4 Kd4 70. a6 Qc5+ 71. Ka4 Kc4 72. f7 Qb4#",
          "positional_tokens": {
            "prompt_tokens": 524,
            "completion_tokens": 597,
            "total_tokens": 1121,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bxf3",
            "Kxg1",
            "Be2",
            "Kg2",
            "Kf6",
            "Kg3",
            "Kf5",
            "f3",
            "Bd3",
            "a5",
            "Bc4",
            "Kf2",
            "Kf4",
            "Kg2",
            "Ke3",
            "Kg3",
            "Kd3",
            "Kf4",
            "Kxc3",
            "Ke5",
            "Kd3",
            "Kxe6",
            "Kxd4",
            "f4",
            "Ke4",
            "f5",
            "d4+",
            "Kd6",
            "d3",
            "f6",
            "d2",
            "Kc5",
            "d1=Q",
            "Kxc4",
            "Qd5+",
            "Kb4",
            "Kd4",
            "a6",
            "Qc5+",
            "Ka4",
            "Kc4",
            "f7",
            "Qb4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8+",
          "neutral_uci": null,
          "neutral_response": "Re8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg7 Rg8+ Kh7 Rf8+ Kg",
          "neutral_tokens": {
            "prompt_tokens": 523,
            "completion_tokens": 640,
            "total_tokens": 1163,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+",
            "Kg7",
            "Rg8+",
            "Kh7",
            "Rf8+"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "g3h2",
          "neutral_uci": null,
          "consensus_move": "g3h2",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nf3",
              "Nc6",
              "Bb5",
              "Bf5",
              "Bxf6",
              "gxf6",
              "e5",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Ne5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxh7",
              "Rh8",
              "Qh6",
              "Qxh6",
              "gxh6",
              "Bb7",
              "Rh5",
              "d5",
              "Bd3",
              "Ke8",
              "Rg3",
              "Rxg5",
              "Rxg5",
              "Kxf6",
              "Rg7",
              "Be4",
              "Rxc7",
              "b5",
              "Ra7",
              "d5",
              "Ra6",
              "Bd3",
              "Kd2",
              "Bf1",
              "Ke3",
              "Rh7",
              "Kf4",
              "Rxh6",
              "a4",
              "Rh2",
              "Kg3",
              "Rh3+",
              "Kf4",
              "b4",
              "Ra8",
              "bxc3",
              "bxc3",
              "Rh4+",
              "Kg3",
              "Rh3+",
              "Kg4",
              "Rh1",
              "Rf8+",
              "Kg7",
              "Rf3",
              "Bf1"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bxf3",
              "Kxg1",
              "Be2",
              "Kg2",
              "Kf6",
              "Kg3",
              "Kf5",
              "f3",
              "Bd3",
              "a5",
              "Bc4",
              "Kf2",
              "Kf4",
              "Kg2",
              "Ke3",
              "Kg3",
              "Kd3",
              "Kf4",
              "Kxc3",
              "Ke5",
              "Kd3",
              "Kxe6",
              "Kxd4",
              "f4",
              "Ke4",
              "f5",
              "d4+",
              "Kd6",
              "d3",
              "f6",
              "d2",
              "Kc5",
              "d1=Q",
              "Kxc4",
              "Qd5+",
              "Kb4",
              "Kd4",
              "a6",
              "Qc5+",
              "Ka4",
              "Kc4",
              "f7",
              "Qb4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+",
              "Kg7",
              "Rg8+",
              "Kh7",
              "Rf8+"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 524,
            "completion_tokens": 205,
            "total_tokens": 729,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 524,
            "completion_tokens": 597,
            "total_tokens": 1121,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 523,
            "completion_tokens": 640,
            "total_tokens": 1163,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1571,
          "total_completion_tokens": 1442,
          "total_tokens": 3013
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 100,
            "turn_number": 51,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 524,
            "completion_tokens": 205,
            "total_tokens": 729,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 100,
            "turn_number": 51,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 524,
            "completion_tokens": 597,
            "total_tokens": 1121,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 100,
            "turn_number": 51,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 523,
            "completion_tokens": 640,
            "total_tokens": 1163,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/6k1/4p3/3p4/P2P4/2P2RK1/4bP2/6r1 w - - 11 51"
    },
    {
      "turn": 103,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rg3",
          "aggressive_uci": "f3g3",
          "aggressive_response": "51... Rg6 52. Rg3 Rxg3 53. Kxg3 Kf6",
          "aggressive_tokens": {
            "prompt_tokens": 532,
            "completion_tokens": 25,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxg3",
            "Kxg3",
            "Kf6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re3",
          "positional_uci": "f3e3",
          "positional_response": "52. Re3 Bc4 53. a5 Kf6 54. Rf3+ Ke7 55. Rg3 Rf6 56. Kg2 Kd6 57. Rg8 Kc6 58.\nRb8 Rf7 59. Rb6+ Kd7 60. Rb7+ Ke8 61. Rb8+ Ke7 62. Rb7+ Kf6 63. Rb6 Ra7 64.\na6 Rxa6 65. Rxa6 Bxa6 66. Kf3 Kf5 67. Ke3 Bc4 68. Kf3 Bb3 69. Ke3 Bd1 70. Kd2\nBf3 71. Ke3 Kg4 72. Kd2 Kf4 73. Kd3 Bg4 74. c4 Bf5+ 75. Kc3 Kf3 76. cxd5 exd5\n77. Kb4 Kxf2 78. Kc5 Be4 79. Kb4 Ke3 80. Kc3 Bf5 81. Kb2 Kxd4 82. Kc1 Kc3 83.\nKd1 d4 84. Kc1 d3 85. Kd1 Bg4+ 86. Ke1 d2+ 87. Kf2 d1=Q 88. Kg3 Qf3+ 89. Kh4\nBf5 90. Kg5 Be4 91. Kh4 Qg2 92. Kh5 Bf5 93. Kh6 Qg6#",
          "positional_tokens": {
            "prompt_tokens": 532,
            "completion_tokens": 361,
            "total_tokens": 893,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "a5",
            "Kf6",
            "Rf3+",
            "Ke7",
            "Rg3",
            "Rf6",
            "Kg2",
            "Kd6",
            "Rg8",
            "Kc6",
            "Rb8",
            "Rf7",
            "Rb6+",
            "Kd7",
            "Rb7+",
            "Ke8",
            "Rb8+",
            "Ke7",
            "Rb7+",
            "Kf6",
            "Rb6",
            "Ra7",
            "a6",
            "Rxa6",
            "Rxa6",
            "Bxa6",
            "Kf3",
            "Kf5",
            "Ke3",
            "Bc4",
            "Kf3",
            "Bb3",
            "Ke3",
            "Bd1",
            "Kd2",
            "Bf3",
            "Ke3",
            "Kg4",
            "Kd2",
            "Kf4",
            "Kd3",
            "Bg4",
            "c4",
            "Bf5+",
            "Kc3",
            "Kf3",
            "cxd5",
            "exd5",
            "Kb4",
            "Kxf2",
            "Kc5",
            "Be4",
            "Kb4",
            "Ke3",
            "Kc3",
            "Bf5",
            "Kb2",
            "Kxd4",
            "Kc1",
            "Kc3",
            "Kd1",
            "d4",
            "Kc1",
            "d3",
            "Kd1",
            "Bg4+",
            "Ke1",
            "d2+",
            "Kf2",
            "d1=Q",
            "Kg3",
            "Qf3+",
            "Kh4",
            "Bf5",
            "Kg5",
            "Be4",
            "Kh4",
            "Qg2",
            "Kh5",
            "Bf5",
            "Kh6",
            "Qg6#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re3",
          "neutral_uci": "f3e3",
          "neutral_response": "51... Rg6 52. Re3 Bc4 53. a5 Kf7",
          "neutral_tokens": {
            "prompt_tokens": 531,
            "completion_tokens": 22,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Bc4",
            "a5",
            "Kf7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "f3g3",
          "positional_uci": "f3e3",
          "neutral_uci": "f3e3",
          "consensus_move": "f3e3",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rxg3",
              "Kxg3",
              "Kf6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Bc4",
              "a5",
              "Kf6",
              "Rf3+",
              "Ke7",
              "Rg3",
              "Rf6",
              "Kg2",
              "Kd6",
              "Rg8",
              "Kc6",
              "Rb8",
              "Rf7",
              "Rb6+",
              "Kd7",
              "Rb7+",
              "Ke8",
              "Rb8+",
              "Ke7",
              "Rb7+",
              "Kf6",
              "Rb6",
              "Ra7",
              "a6",
              "Rxa6",
              "Rxa6",
              "Bxa6",
              "Kf3",
              "Kf5",
              "Ke3",
              "Bc4",
              "Kf3",
              "Bb3",
              "Ke3",
              "Bd1",
              "Kd2",
              "Bf3",
              "Ke3",
              "Kg4",
              "Kd2",
              "Kf4",
              "Kd3",
              "Bg4",
              "c4",
              "Bf5+",
              "Kc3",
              "Kf3",
              "cxd5",
              "exd5",
              "Kb4",
              "Kxf2",
              "Kc5",
              "Be4",
              "Kb4",
              "Ke3",
              "Kc3",
              "Bf5",
              "Kb2",
              "Kxd4",
              "Kc1",
              "Kc3",
              "Kd1",
              "d4",
              "Kc1",
              "d3",
              "Kd1",
              "Bg4+",
              "Ke1",
              "d2+",
              "Kf2",
              "d1=Q",
              "Kg3",
              "Qf3+",
              "Kh4",
              "Bf5",
              "Kg5",
              "Be4",
              "Kh4",
              "Qg2",
              "Kh5",
              "Bf5",
              "Kh6",
              "Qg6#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Bc4",
              "a5",
              "Kf7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 532,
            "completion_tokens": 25,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 532,
            "completion_tokens": 361,
            "total_tokens": 893,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 531,
            "completion_tokens": 22,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1595,
          "total_completion_tokens": 408,
          "total_tokens": 2003
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 532,
            "completion_tokens": 25,
            "total_tokens": 557,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 532,
            "completion_tokens": 361,
            "total_tokens": 893,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 102,
            "turn_number": 52,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 531,
            "completion_tokens": 22,
            "total_tokens": 553,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/6k1/4p1r1/3p4/P2P4/2P2R2/4bP1K/8 w - - 13 52"
    },
    {
      "turn": 105,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "a5",
          "aggressive_uci": "a4a5",
          "aggressive_response": "53. a5 Kf6 54. Re1 Bf3 55. Rg1 Rh6+ 56. Kg3 Rg6+ 57. Kh2 Rxg1 58. Kxg1\nBe2 59. Kg2 Kf5 60. Kg3 Ke4 61. f4 Kd3 62. a6 Kxc3 63. a7 Kxd4 64. a8=Q Ke3 65.\nQa7+ Kd2 66. Qd4+ Bd3 67. Kf2 Kc2 68. Ke3 Bf5 69. Qd2+ Kb3 70. Kd4 Ka4 71. Qb2\nKa5 72. Kc5 Ka6 73. Qb6# Kd7 74. Qb7+ Ke8 75. Kd6 Kf8 76. Ke5 Kg8 77. Kf6 Kh8\n78. Qg7# Kd8 79. Qe7+ Kc8 80. Ke5 Kb8 81. Kd6 Ka8 82. Kc6 Kb8 83. Qb7# Kc8\n84. Qc7# Kd8 85. Kd6 Ke8 86. Qe7# Kf8 87. Ke5 Kg8 88. Kf6 Kh8 89. Qg7# Kg8\n90. Qg5+ Kf8 91. Qg7+ Ke8 92. Qe7# Kd8 93. Ke5 Kc8 94. Kd6 Kb8 95. Kc6 Ka8\n96. Qb7# Kd8 97. Qd7# Kc8 98. Qc7# Kd8 99. Qd7# Kc8 100. Qc7# Kd8 101. Qd7# Kc8 102. Qc7# Kd8 103. Qd7# Kc8 104. Qc7# Kd8 105. Qd7# Kc8 106. Qc7# Kd8 107. Qd7# Kc8 108. Qc7# Kd8 109. Qd7# Kc8 110. Qc7# Kd8 111. Qd7# Kc8 112. Qc7# Kd8 113. Qd7# Kc8 114. Qc7# Kd8 115. Qd7# Kc8 116. Qc7# Kd8 117. Qd7# Kc8 118. Qc7# Kd8 119. Qd7# Kc8 120. Qc7# Kd8 121. Qd7# Kc8 122. Qc7# Kd",
          "aggressive_tokens": {
            "prompt_tokens": 539,
            "completion_tokens": 640,
            "total_tokens": 1179,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kf6",
            "Re1",
            "Bf3",
            "Rg1",
            "Rh6+",
            "Kg3",
            "Rg6+",
            "Kh2",
            "Rxg1",
            "Kxg1",
            "Be2",
            "Kg2",
            "Kf5",
            "Kg3",
            "Ke4",
            "f4",
            "Kd3",
            "a6",
            "Kxc3",
            "a7",
            "Kxd4",
            "a8=Q",
            "Ke3",
            "Qa7+",
            "Kd2",
            "Qd4+",
            "Bd3",
            "Kf2",
            "Kc2",
            "Ke3",
            "Bf5",
            "Qd2+",
            "Kb3",
            "Kd4",
            "Ka4",
            "Qb2",
            "Ka5",
            "Kc5",
            "Ka6",
            "Qb6#",
            "Kd7",
            "Qb7+",
            "Ke8",
            "Kd6",
            "Kf8",
            "Ke5",
            "Kg8",
            "Kf6",
            "Kh8",
            "Qg7#",
            "Kd8",
            "Qe7+",
            "Kc8",
            "Ke5",
            "Kb8",
            "Kd6",
            "Ka8",
            "Kc6",
            "Kb8",
            "Qb7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Kd6",
            "Ke8",
            "Qe7#",
            "Kf8",
            "Ke5",
            "Kg8",
            "Kf6",
            "Kh8",
            "Qg7#",
            "Kg8",
            "Qg5+",
            "Kf8",
            "Qg7+",
            "Ke8",
            "Qe7#",
            "Kd8",
            "Ke5",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#",
            "Kd8",
            "Qd7#",
            "Kc8",
            "Qc7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a5",
          "positional_uci": "a4a5",
          "positional_response": "53. a5 Kf6 54. Re1 Bf3 55. Re3 Be4 56. f3 Bf5 57. Re1 Rg7 58. Ra1 Bd3 59. Ra2\nKf5 60. Rg2 Rxg2+ 61. Kxg2 Kf4 62. Kf2 Bc4 63. Kg2 Ke3 64. Kg3 Kd3 65. Kf4\nKxc3 66. Ke5 Kd3 67. Kxe6 Kxd4 68. f4 Ke4 69. f5 d4+ 70. Kf6 d3 71. Kg6 d2 72.\nf6 d1=Q 73. f7 Qg4+ 74. Kf6 Qf5+ 75. Ke7 Qxf7+ 76. Kd6 Qd5+ 77. Kc7 Qxa5+ 78.\nKd6 Qd5+ 79. Kc7 Qe6 80. Kb7 Qd6 81. Ka7 Qc6 82. Kb8 Qd7 83. Ka8 Bd5+ 84. Kb8\nQb7# d4 e5 dxe5",
          "positional_tokens": {
            "prompt_tokens": 539,
            "completion_tokens": 281,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf6",
            "Re1",
            "Bf3",
            "Re3",
            "Be4",
            "f3",
            "Bf5",
            "Re1",
            "Rg7",
            "Ra1",
            "Bd3",
            "Ra2",
            "Kf5",
            "Rg2",
            "Rxg2+",
            "Kxg2",
            "Kf4",
            "Kf2",
            "Bc4",
            "Kg2",
            "Ke3",
            "Kg3",
            "Kd3",
            "Kf4",
            "Kxc3",
            "Ke5",
            "Kd3",
            "Kxe6",
            "Kxd4",
            "f4",
            "Ke4",
            "f5",
            "d4+",
            "Kf6",
            "d3",
            "Kg6",
            "d2",
            "f6",
            "d1=Q",
            "f7",
            "Qg4+",
            "Kf6",
            "Qf5+",
            "Ke7",
            "Qxf7+",
            "Kd6",
            "Qd5+",
            "Kc7",
            "Qxa5+",
            "Kd6",
            "Qd5+",
            "Kc7",
            "Qe6",
            "Kb7",
            "Qd6",
            "Ka7",
            "Qc6",
            "Kb8",
            "Qd7",
            "Ka8",
            "Bd5+",
            "Kb8",
            "Qb7#",
            "d4",
            "e5",
            "dxe5"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a5",
          "neutral_uci": "a4a5",
          "neutral_response": "53. a5 Kf6 54. Re1 Bf3 55. Rg1 Rh6+ 56. Kg3 Rg6+ 57. Kh2 Rxg1 58. Kxg1\nBe2 59. Kg2 Kf5 60. Kg3 Ke4 61. f4 Kd3 62. a6 Kxc3 63. a7 Kxd4 64. a8=Q Ke3 65.\nQa7+ Kd2 66. Qd4+ Bd3 67. Kf2 Kc2 68. Ke3 Bf5 69. Qd2+ Kb3 70. Kd4 Ka4 71. Qb2\nKa5 72. Kc5 Ka6 73. Qb6# Kd7 74. Qd6+ Ke8 75. Qc7 Kf8 76. Kd6 Kg8 77. Ke5 Kf8\n78. Kf6 Kg8 79. Qg7# Kd8 80. Ke5 Kc8 81. Kd6 Kb8 82. Kc6 Ka8 83. Qb7# Kd8\n84. Qd7# Kd8 85. Kd6 *",
          "neutral_tokens": {
            "prompt_tokens": 538,
            "completion_tokens": 283,
            "total_tokens": 821,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Kf6",
            "Re1",
            "Bf3",
            "Rg1",
            "Rh6+",
            "Kg3",
            "Rg6+",
            "Kh2",
            "Rxg1",
            "Kxg1",
            "Be2",
            "Kg2",
            "Kf5",
            "Kg3",
            "Ke4",
            "f4",
            "Kd3",
            "a6",
            "Kxc3",
            "a7",
            "Kxd4",
            "a8=Q",
            "Ke3",
            "Qa7+",
            "Kd2",
            "Qd4+",
            "Bd3",
            "Kf2",
            "Kc2",
            "Ke3",
            "Bf5",
            "Qd2+",
            "Kb3",
            "Kd4",
            "Ka4",
            "Qb2",
            "Ka5",
            "Kc5",
            "Ka6",
            "Qb6#",
            "Kd7",
            "Qd6+",
            "Ke8",
            "Qc7",
            "Kf8",
            "Kd6",
            "Kg8",
            "Ke5",
            "Kf8",
            "Kf6",
            "Kg8",
            "Qg7#",
            "Kd8",
            "Ke5",
            "Kc8",
            "Kd6",
            "Kb8",
            "Kc6",
            "Ka8",
            "Qb7#",
            "Kd8",
            "Qd7#",
            "Kd8",
            "Kd6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": "a4a5",
          "positional_uci": "a4a5",
          "neutral_uci": "a4a5",
          "consensus_move": "a4a5",
          "source_agents": [
            "aggressive",
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Kf6",
              "Re1",
              "Bf3",
              "Rg1",
              "Rh6+",
              "Kg3",
              "Rg6+",
              "Kh2",
              "Rxg1",
              "Kxg1",
              "Be2",
              "Kg2",
              "Kf5",
              "Kg3",
              "Ke4",
              "f4",
              "Kd3",
              "a6",
              "Kxc3",
              "a7",
              "Kxd4",
              "a8=Q",
              "Ke3",
              "Qa7+",
              "Kd2",
              "Qd4+",
              "Bd3",
              "Kf2",
              "Kc2",
              "Ke3",
              "Bf5",
              "Qd2+",
              "Kb3",
              "Kd4",
              "Ka4",
              "Qb2",
              "Ka5",
              "Kc5",
              "Ka6",
              "Qb6#",
              "Kd7",
              "Qb7+",
              "Ke8",
              "Kd6",
              "Kf8",
              "Ke5",
              "Kg8",
              "Kf6",
              "Kh8",
              "Qg7#",
              "Kd8",
              "Qe7+",
              "Kc8",
              "Ke5",
              "Kb8",
              "Kd6",
              "Ka8",
              "Kc6",
              "Kb8",
              "Qb7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Kd6",
              "Ke8",
              "Qe7#",
              "Kf8",
              "Ke5",
              "Kg8",
              "Kf6",
              "Kh8",
              "Qg7#",
              "Kg8",
              "Qg5+",
              "Kf8",
              "Qg7+",
              "Ke8",
              "Qe7#",
              "Kd8",
              "Ke5",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#",
              "Kd8",
              "Qd7#",
              "Kc8",
              "Qc7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Kf6",
              "Re1",
              "Bf3",
              "Re3",
              "Be4",
              "f3",
              "Bf5",
              "Re1",
              "Rg7",
              "Ra1",
              "Bd3",
              "Ra2",
              "Kf5",
              "Rg2",
              "Rxg2+",
              "Kxg2",
              "Kf4",
              "Kf2",
              "Bc4",
              "Kg2",
              "Ke3",
              "Kg3",
              "Kd3",
              "Kf4",
              "Kxc3",
              "Ke5",
              "Kd3",
              "Kxe6",
              "Kxd4",
              "f4",
              "Ke4",
              "f5",
              "d4+",
              "Kf6",
              "d3",
              "Kg6",
              "d2",
              "f6",
              "d1=Q",
              "f7",
              "Qg4+",
              "Kf6",
              "Qf5+",
              "Ke7",
              "Qxf7+",
              "Kd6",
              "Qd5+",
              "Kc7",
              "Qxa5+",
              "Kd6",
              "Qd5+",
              "Kc7",
              "Qe6",
              "Kb7",
              "Qd6",
              "Ka7",
              "Qc6",
              "Kb8",
              "Qd7",
              "Ka8",
              "Bd5+",
              "Kb8",
              "Qb7#",
              "d4",
              "e5",
              "dxe5"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kf6",
              "Re1",
              "Bf3",
              "Rg1",
              "Rh6+",
              "Kg3",
              "Rg6+",
              "Kh2",
              "Rxg1",
              "Kxg1",
              "Be2",
              "Kg2",
              "Kf5",
              "Kg3",
              "Ke4",
              "f4",
              "Kd3",
              "a6",
              "Kxc3",
              "a7",
              "Kxd4",
              "a8=Q",
              "Ke3",
              "Qa7+",
              "Kd2",
              "Qd4+",
              "Bd3",
              "Kf2",
              "Kc2",
              "Ke3",
              "Bf5",
              "Qd2+",
              "Kb3",
              "Kd4",
              "Ka4",
              "Qb2",
              "Ka5",
              "Kc5",
              "Ka6",
              "Qb6#",
              "Kd7",
              "Qd6+",
              "Ke8",
              "Qc7",
              "Kf8",
              "Kd6",
              "Kg8",
              "Ke5",
              "Kf8",
              "Kf6",
              "Kg8",
              "Qg7#",
              "Kd8",
              "Ke5",
              "Kc8",
              "Kd6",
              "Kb8",
              "Kc6",
              "Ka8",
              "Qb7#",
              "Kd8",
              "Qd7#",
              "Kd8",
              "Kd6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 539,
            "completion_tokens": 640,
            "total_tokens": 1179,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 539,
            "completion_tokens": 281,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 538,
            "completion_tokens": 283,
            "total_tokens": 821,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1616,
          "total_completion_tokens": 1204,
          "total_tokens": 2820
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 104,
            "turn_number": 53,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 539,
            "completion_tokens": 640,
            "total_tokens": 1179,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 104,
            "turn_number": 53,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 539,
            "completion_tokens": 281,
            "total_tokens": 820,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 104,
            "turn_number": 53,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 538,
            "completion_tokens": 283,
            "total_tokens": 821,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/6k1/4p1r1/3p4/P2P4/2P1R3/5P1K/3b4 w - - 15 53"
    },
    {
      "turn": 107,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Qh6",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 Nc3 Nf6 Bg5 e6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4\nNxe4 Nf6 Neg5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxh7 Bh6+ Ng5 Bxg5 hxg5 Qxh7 Rh8\nQh6 Qxh6 gxh6 Rxh6 Bg7 Bh6 Bh7 Bxg7 Bh6+ Kg8 b6 d5 b7 d4 b8=Q+ Kg7 Qb7+ Kg8 Qf7#",
          "aggressive_tokens": {
            "prompt_tokens": 547,
            "completion_tokens": 139,
            "total_tokens": 686,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Qxh6",
            "gxh6",
            "Rxh6",
            "Bg7",
            "Bh6",
            "Bh7",
            "Bxg7",
            "Bh6+",
            "Kg8",
            "b6",
            "d5",
            "b7",
            "d4",
            "b8=Q+",
            "Kg7",
            "Qb7+",
            "Kg8",
            "Qf7#"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a6",
          "positional_uci": "a5a6",
          "positional_response": "54. a6 Rg7 55. Re1 Bf3 56. Ra1 Ra7 57. Kg3 Be2 58. Kf4 Rxa6 59. Rxa6 Bxa6 60. Kg4\nBe2+ 61. Kf4 Bd1 62. Ke3 Kf5 63. Kd2 Bb3 64. Ke3 Bc4 65. Kf3 Bd3 66. Ke3 Bc2 67.\nKf3 Bd1+ 68. Ke3 Kg4 69. Kd2 Bb3 70. Ke3 Bc4 71. f3+ Kg3 72. f4 Kg4 73. f5 exf5\n74. Kf2 f4 75. Kg2 f3+ 76. Kf2 Kf4 77. Ke1 Ke3 78. Kd1 f2 79. Kc2 f1=Q 80. Kb2\nQe2+ 81. Ka3 Qa2+ 82. Kb4 Qb3+ 83. Kc5 Qb5+ 84. Kd6 Qb6+ 85. Ke5 Qc7+ 86. Kf5\nQf7+ 87. Kg5 Qg7+ 88. Kf5 Qf7+ 89. Kg5 Ke4 90. Kg4 Qg6+ 91. Kh3 Kf3 92. Kh4 Qg4#",
          "positional_tokens": {
            "prompt_tokens": 547,
            "completion_tokens": 332,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg7",
            "Re1",
            "Bf3",
            "Ra1",
            "Ra7",
            "Kg3",
            "Be2",
            "Kf4",
            "Rxa6",
            "Rxa6",
            "Bxa6",
            "Kg4",
            "Be2+",
            "Kf4",
            "Bd1",
            "Ke3",
            "Kf5",
            "Kd2",
            "Bb3",
            "Ke3",
            "Bc4",
            "Kf3",
            "Bd3",
            "Ke3",
            "Bc2",
            "Kf3",
            "Bd1+",
            "Ke3",
            "Kg4",
            "Kd2",
            "Bb3",
            "Ke3",
            "Bc4",
            "f3+",
            "Kg3",
            "f4",
            "Kg4",
            "f5",
            "exf5",
            "Kf2",
            "f4",
            "Kg2",
            "f3+",
            "Kf2",
            "Kf4",
            "Ke1",
            "Ke3",
            "Kd1",
            "f2",
            "Kc2",
            "f1=Q",
            "Kb2",
            "Qe2+",
            "Ka3",
            "Qa2+",
            "Kb4",
            "Qb3+",
            "Kc5",
            "Qb5+",
            "Kd6",
            "Qb6+",
            "Ke5",
            "Qc7+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Qg7+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Ke4",
            "Kg4",
            "Qg6+",
            "Kh3",
            "Kf3",
            "Kh4",
            "Qg4#"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "a6",
          "neutral_uci": "a5a6",
          "neutral_response": "54. a6 Rg7 55. Re1 Bf3 56. Ra1 Ra7 57. Kg3 Be2 58. Kf4 Rxa6 59. Rxa6 Bxa6 60. Ke3 Kf5 61. Kf3 Bc4 62. Ke3 Kg4 63. f3+ Kg3 64. f4 Kg4 65. f5 exf5 66. Kf2 f4 67. Kg2 f3+ 68. Kf2 Kf4 69. Ke1 Ke3 70. Kd1 f2 71. Kc2 f1=Q 72. Kb2 Qe2+ 73. Ka3 Qa2+ 74. Kb4 Qb3+ 75. Kc5 Qb5+ 76. Kd6 Qb6+ 77. Ke5 Qc7+ 78. Kf5 Qf7+ 79. Kg5 Qg7+ 80. Kf5 Bd3+ 81. Ke6 Qg6+ 82. Kxd5 Qf5+ 83. Kc6 Qe6+ 84. Kc5 Qc4+ 85. Kd6 Qxc3 86. d5 Qd4 87. Kc6 Be4 88. Kd6 Qxd5+ 89. Ke7 Qc6 90. Kf7 Qd6 91. Kg7 Qe6 92. Kf8 Qd7 93. Kg8 Qe7 94. Kh8 Qh7#",
          "neutral_tokens": {
            "prompt_tokens": 546,
            "completion_tokens": 354,
            "total_tokens": 900,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg7",
            "Re1",
            "Bf3",
            "Ra1",
            "Ra7",
            "Kg3",
            "Be2",
            "Kf4",
            "Rxa6",
            "Rxa6",
            "Bxa6",
            "Ke3",
            "Kf5",
            "Kf3",
            "Bc4",
            "Ke3",
            "Kg4",
            "f3+",
            "Kg3",
            "f4",
            "Kg4",
            "f5",
            "exf5",
            "Kf2",
            "f4",
            "Kg2",
            "f3+",
            "Kf2",
            "Kf4",
            "Ke1",
            "Ke3",
            "Kd1",
            "f2",
            "Kc2",
            "f1=Q",
            "Kb2",
            "Qe2+",
            "Ka3",
            "Qa2+",
            "Kb4",
            "Qb3+",
            "Kc5",
            "Qb5+",
            "Kd6",
            "Qb6+",
            "Ke5",
            "Qc7+",
            "Kf5",
            "Qf7+",
            "Kg5",
            "Qg7+",
            "Kf5",
            "Bd3+",
            "Ke6",
            "Qg6+",
            "Kxd5",
            "Qf5+",
            "Kc6",
            "Qe6+",
            "Kc5",
            "Qc4+",
            "Kd6",
            "Qxc3",
            "d5",
            "Qd4",
            "Kc6",
            "Be4",
            "Kd6",
            "Qxd5+",
            "Ke7",
            "Qc6",
            "Kf7",
            "Qd6",
            "Kg7",
            "Qe6",
            "Kf8",
            "Qd7",
            "Kg8",
            "Qe7",
            "Kh8",
            "Qh7#"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "a5a6",
          "neutral_uci": "a5a6",
          "consensus_move": "a5a6",
          "source_agents": [
            "positional",
            "neutral"
          ],
          "selected_agent": "neutral"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Qxh6",
              "gxh6",
              "Rxh6",
              "Bg7",
              "Bh6",
              "Bh7",
              "Bxg7",
              "Bh6+",
              "Kg8",
              "b6",
              "d5",
              "b7",
              "d4",
              "b8=Q+",
              "Kg7",
              "Qb7+",
              "Kg8",
              "Qf7#"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg7",
              "Re1",
              "Bf3",
              "Ra1",
              "Ra7",
              "Kg3",
              "Be2",
              "Kf4",
              "Rxa6",
              "Rxa6",
              "Bxa6",
              "Kg4",
              "Be2+",
              "Kf4",
              "Bd1",
              "Ke3",
              "Kf5",
              "Kd2",
              "Bb3",
              "Ke3",
              "Bc4",
              "Kf3",
              "Bd3",
              "Ke3",
              "Bc2",
              "Kf3",
              "Bd1+",
              "Ke3",
              "Kg4",
              "Kd2",
              "Bb3",
              "Ke3",
              "Bc4",
              "f3+",
              "Kg3",
              "f4",
              "Kg4",
              "f5",
              "exf5",
              "Kf2",
              "f4",
              "Kg2",
              "f3+",
              "Kf2",
              "Kf4",
              "Ke1",
              "Ke3",
              "Kd1",
              "f2",
              "Kc2",
              "f1=Q",
              "Kb2",
              "Qe2+",
              "Ka3",
              "Qa2+",
              "Kb4",
              "Qb3+",
              "Kc5",
              "Qb5+",
              "Kd6",
              "Qb6+",
              "Ke5",
              "Qc7+",
              "Kf5",
              "Qf7+",
              "Kg5",
              "Qg7+",
              "Kf5",
              "Qf7+",
              "Kg5",
              "Ke4",
              "Kg4",
              "Qg6+",
              "Kh3",
              "Kf3",
              "Kh4",
              "Qg4#"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rg7",
              "Re1",
              "Bf3",
              "Ra1",
              "Ra7",
              "Kg3",
              "Be2",
              "Kf4",
              "Rxa6",
              "Rxa6",
              "Bxa6",
              "Ke3",
              "Kf5",
              "Kf3",
              "Bc4",
              "Ke3",
              "Kg4",
              "f3+",
              "Kg3",
              "f4",
              "Kg4",
              "f5",
              "exf5",
              "Kf2",
              "f4",
              "Kg2",
              "f3+",
              "Kf2",
              "Kf4",
              "Ke1",
              "Ke3",
              "Kd1",
              "f2",
              "Kc2",
              "f1=Q",
              "Kb2",
              "Qe2+",
              "Ka3",
              "Qa2+",
              "Kb4",
              "Qb3+",
              "Kc5",
              "Qb5+",
              "Kd6",
              "Qb6+",
              "Ke5",
              "Qc7+",
              "Kf5",
              "Qf7+",
              "Kg5",
              "Qg7+",
              "Kf5",
              "Bd3+",
              "Ke6",
              "Qg6+",
              "Kxd5",
              "Qf5+",
              "Kc6",
              "Qe6+",
              "Kc5",
              "Qc4+",
              "Kd6",
              "Qxc3",
              "d5",
              "Qd4",
              "Kc6",
              "Be4",
              "Kd6",
              "Qxd5+",
              "Ke7",
              "Qc6",
              "Kf7",
              "Qd6",
              "Kg7",
              "Qe6",
              "Kf8",
              "Qd7",
              "Kg8",
              "Qe7",
              "Kh8",
              "Qh7#"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 547,
            "completion_tokens": 139,
            "total_tokens": 686,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 547,
            "completion_tokens": 332,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 546,
            "completion_tokens": 354,
            "total_tokens": 900,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1640,
          "total_completion_tokens": 825,
          "total_tokens": 2465
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 106,
            "turn_number": 54,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 547,
            "completion_tokens": 139,
            "total_tokens": 686,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 106,
            "turn_number": 54,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 547,
            "completion_tokens": 332,
            "total_tokens": 879,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 106,
            "turn_number": 54,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 546,
            "completion_tokens": 354,
            "total_tokens": 900,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "8/8/4pkr1/P2p4/3P4/2P1R3/5P1K/3b4 w - - 1 54"
    },
    {
      "turn": 109,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Rh1",
          "aggressive_uci": null,
          "aggressive_response": "Re8+ Kg7 Bf1 a6 a7 Rh8 Rg3+ Kf7 Rg8 Rh2+ Kg3\nRh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3 Rh1 Rg8 Rh2+ Kg3",
          "aggressive_tokens": {
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rg8",
            "Rh2+",
            "Kg3"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "a7",
          "positional_uci": "a6a7",
          "positional_response": "1. d4 f5 2. Nf3 Nf6 3. Bg5 e6 4. Nbd2 Be7 5. Bxf6 Bxf6 6. e4 g6 7. h4 d6 8. c3\nBg7 9. Bd3 Nd7 10. Qe2 Qe7 11. O-O-O fxe4 12. Nxe4 Nf6 13. Neg5 Kd8 14. Rhe1\nRe8 15. Nxh7 Nxh7 16. Bxg6 Rf8 17. Bxh7 Bh6+ 18. Ng5 Bxg5+ 19. hxg5 Qxh7 20.\nRh1 Qg8 21. Qh5 b6 22. Qh4 Qg6 23. Qh6 Qxh6 24. gxh6 Rh8 25. g4 Bb7 26. Rh5 Ke8\n27. g5 Kf7 28. Rg1 Rag8 29. Rh4 a6 30. Rf4+ Ke8 31. Rf6 Ke7 32. Rg3 Rxg5 33.\nRxg5 Kxf6 34. Rg7 Be4 35. Rxc7 b5 36. Ra7 d5 37. Rxa6 Bd3 38. Kd2 Bf1 39. Ke3\nRh7 40. Kf4 Rxh6 41. a4 Rh2 42. Kg3 Rh3+ 43. Kf4 b4 44. Ra8 bxc3 45. bxc3 Rh4+\n46. Kg3 Rh3+ 47. Kg4 Rh1 48. Rf8+ Kg7 49. Rf3 Be2 50. Kg3 Rg1+ 51. Kh2 Rg6 52.\nRe3 Bd1 53. a5 Kf6 54. a6 Bc2 55. a7 Rg8 56. Rf3+ Bf5 57. Rg3 Ra8 58. Rg1\nRxa7 59. Rc1 Ra2 60. Kg3 Rc2 61. Rxc2 Bxc2 62. Kf4 Bb3 63. Kg4 Bc4 64. Kf4 Bb5\n65. Kg4 Be8 66. Kf4 Bh5 67. Kg3 Kf5 68. f3 Bg6 69. Kf2 Kf4 70. Ke2 Bh5 71. Kd3\nBxf3 72. c4 dxc4+ 73. Kxc4 Bd5+ 74. Kd3 Kf3 75. Kd2 Ke4 76. Kc3 Ke3 77. Kc2\nKxd",
          "positional_tokens": {
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Rg8",
            "Rf3+",
            "Bf5",
            "Rg3",
            "Ra8",
            "Rg1",
            "Rxa7",
            "Rc1",
            "Ra2",
            "Kg3",
            "Rc2",
            "Rxc2",
            "Bxc2",
            "Kf4",
            "Bb3",
            "Kg4",
            "Bc4",
            "Kf4",
            "Bb5",
            "Kg4",
            "Be8",
            "Kf4",
            "Bh5",
            "Kg3",
            "Kf5",
            "f3",
            "Bg6",
            "Kf2",
            "Kf4",
            "Ke2",
            "Bh5",
            "Kd3",
            "Bxf3",
            "c4",
            "dxc4+",
            "Kxc4",
            "Bd5+",
            "Kd3",
            "Kf3",
            "Kd2",
            "Ke4",
            "Kc3",
            "Ke3",
            "Kc2"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8+",
          "neutral_uci": null,
          "neutral_response": "Re8+ Kg7 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6 a7 Rh1 Rf3+ Kg7 Rf4 Bf1 a6",
          "neutral_tokens": {
            "prompt_tokens": 554,
            "completion_tokens": 640,
            "total_tokens": 1194,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kg7",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6",
            "a7",
            "Rh1",
            "Rf3+",
            "Kg7",
            "Rf4",
            "Bf1",
            "a6"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": "a6a7",
          "neutral_uci": null,
          "consensus_move": "a6a7",
          "source_agents": [
            "positional"
          ],
          "selected_agent": "positional"
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg8",
              "Rh2+",
              "Kg3"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rf3+",
              "Bf5",
              "Rg3",
              "Ra8",
              "Rg1",
              "Rxa7",
              "Rc1",
              "Ra2",
              "Kg3",
              "Rc2",
              "Rxc2",
              "Bxc2",
              "Kf4",
              "Bb3",
              "Kg4",
              "Bc4",
              "Kf4",
              "Bb5",
              "Kg4",
              "Be8",
              "Kf4",
              "Bh5",
              "Kg3",
              "Kf5",
              "f3",
              "Bg6",
              "Kf2",
              "Kf4",
              "Ke2",
              "Bh5",
              "Kd3",
              "Bxf3",
              "c4",
              "dxc4+",
              "Kxc4",
              "Bd5+",
              "Kd3",
              "Kf3",
              "Kd2",
              "Ke4",
              "Kc3",
              "Ke3",
              "Kc2"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kg7",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6",
              "a7",
              "Rh1",
              "Rf3+",
              "Kg7",
              "Rf4",
              "Bf1",
              "a6"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "neutral": {
            "prompt_tokens": 554,
            "completion_tokens": 640,
            "total_tokens": 1194,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1664,
          "total_completion_tokens": 1920,
          "total_tokens": 3584
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 108,
            "turn_number": 55,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 108,
            "turn_number": 55,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 555,
            "completion_tokens": 640,
            "total_tokens": 1195,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 108,
            "turn_number": 55,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 554,
            "completion_tokens": 640,
            "total_tokens": 1194,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "8/8/P3pkr1/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 55"
    },
    {
      "turn": 111,
      "attempt": 1,
      "debate_history": {
        "query1": {
          "aggressive_move": "Re8",
          "aggressive_uci": null,
          "aggressive_response": "Re8 Rg8 Rf8",
          "aggressive_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rf8"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8 Rg6",
          "positional_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rg6"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kd6",
          "neutral_uci": null,
          "neutral_response": "Re8 Rxe8 Kf8 Rxe8 Kxe8 Kd7 Kd6 Kc7 Kc5\nKb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7\nKd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7 Kc5 Kb7 Kd6 Kc7",
          "neutral_tokens": {
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kc7"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "Rg8",
              "Rf8"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rg6"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kc7"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "positional": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1688,
          "total_completion_tokens": 656,
          "total_tokens": 2344
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "6r1/P7/4pk2/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 56"
    },
    {
      "turn": 111,
      "attempt": 2,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 d5 Nf3 Nc6 Bg5 e6 Nbd2 Be7 Bxf6 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Ng5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxg6 Rf8 Bxh7 Bh6+ Ng5 Bxg5 hxg5 Qxg5 Rh1 b6 Qh4 Qxh4 gxh4 Rh8 h6 d5 Rf6 Ke7 Rg3 Rxh6 Rg7+ Kf6 Rxc7 b5 Ra7 d5 Rxa6 Bd3 Kd2 Bf1 Ke3 Rh7 Kf4 Rxh6 a4 bxa4 Rxa4 Rh4+ Kg3 Rh1 Ra8 Rg1+ Kh2 Rg6 Re8 Kf7 Rg8 Rh6+ Kg3 Rg6+ Kf4 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 Rf6+ Kc5 Rf5 Rf6+ Ke5 Rf5+ Kd6 R",
          "aggressive_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "d5",
            "Nf3",
            "Nc6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Ng5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxg6",
            "Rf8",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5",
            "hxg5",
            "Qxg5",
            "Rh1",
            "b6",
            "Qh4",
            "Qxh4",
            "gxh4",
            "Rh8",
            "h6",
            "d5",
            "Rf6",
            "Ke7",
            "Rg3",
            "Rxh6",
            "Rg7+",
            "Kf6",
            "Rxc7",
            "b5",
            "Ra7",
            "d5",
            "Rxa6",
            "Bd3",
            "Kd2",
            "Bf1",
            "Ke3",
            "Rh7",
            "Kf4",
            "Rxh6",
            "a4",
            "bxa4",
            "Rxa4",
            "Rh4+",
            "Kg3",
            "Rh1",
            "Ra8",
            "Rg1+",
            "Kh2",
            "Rg6",
            "Re8",
            "Kf7",
            "Rg8",
            "Rh6+",
            "Kg3",
            "Rg6+",
            "Kf4",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6",
            "Rf6+",
            "Kc5",
            "Rf5",
            "Rf6+",
            "Ke5",
            "Rf5+",
            "Kd6"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg6 Rg8",
          "positional_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg6",
            "Rg8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Kb1",
          "neutral_uci": null,
          "neutral_response": "Re8 Rxe8 Kf3 Kf5 Ke2 Ke4 Kd2 Kd3 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2\nKb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc2 Kb1 Kb2 Kc1 Kc",
          "neutral_tokens": {
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "Kb2",
            "Kc1"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "d5",
              "Nf3",
              "Nc6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Ng5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxg6",
              "Rf8",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5",
              "hxg5",
              "Qxg5",
              "Rh1",
              "b6",
              "Qh4",
              "Qxh4",
              "gxh4",
              "Rh8",
              "h6",
              "d5",
              "Rf6",
              "Ke7",
              "Rg3",
              "Rxh6",
              "Rg7+",
              "Kf6",
              "Rxc7",
              "b5",
              "Ra7",
              "d5",
              "Rxa6",
              "Bd3",
              "Kd2",
              "Bf1",
              "Ke3",
              "Rh7",
              "Kf4",
              "Rxh6",
              "a4",
              "bxa4",
              "Rxa4",
              "Rh4+",
              "Kg3",
              "Rh1",
              "Ra8",
              "Rg1+",
              "Kh2",
              "Rg6",
              "Re8",
              "Kf7",
              "Rg8",
              "Rh6+",
              "Kg3",
              "Rg6+",
              "Kf4",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6",
              "Rf6+",
              "Kc5",
              "Rf5",
              "Rf6+",
              "Ke5",
              "Rf5+",
              "Kd6"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg6",
              "Rg8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Kb2",
              "Kc1"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "total_prompt_tokens": 1688,
          "total_completion_tokens": 1288,
          "total_tokens": 2976
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 562,
            "completion_tokens": 640,
            "total_tokens": 1202,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          }
        ]
      },
      "board_fen": "6r1/P7/4pk2/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 56"
    },
    {
      "turn": 111,
      "attempt": 3,
      "debate_history": {
        "query1": {
          "aggressive_move": "e4",
          "aggressive_uci": null,
          "aggressive_response": "e4 g5 Nf3 Nf6 Bg5 e6 Nbd2 Be7 Bxf6 gxf6 e5 g6 h4 d6 c3 Bg7 Bd3 Nd7 Qe2 Qe7 O-O-O fxe4 Nxe4 Nf6 Ng5 Kd8 Rhe1 Re8 Nxh7 Nxh7 Bxh7 Bh6+ Ng5 Bxg5+ hxg5 Qxg5 Rh1 Qg8 Qh5 b6 Qh4+ Kc8 Qh6 Kb7 Qh7 Qxh7 Rxh7 Bb7 Rxc7+ Kb8 Rg7 Bc8 Rh1 Ra7 Rxa7 Kxa7 Rh8 Kb8 Rxe8 Kc7 Rxc8+ Kxc8 g4 Kd8 g5 Ke8 g6 Kf8 Kc2 Kg7 Kd3 Kxg6 Ke4 Kf6 f4 Ke7 f5 Kf6 fxe6 Kxe6 d5+ Kd6 Kd4 Kc7 Ke5 Kd7 d6 Kd8 Ke6 Ke8 d7+ Kd8 Kd6 b5 axb5 a4 bxa4 c5 a3 c6 a2 c7# Kd8 Ke7 Kc8 Ke8 Kd8 Kd7 Kc8 Kc7 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kd7 Kc8 Kd8 Kc7 Kd8 Kc8 Kd7 Kc8 Kd7 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7 Kc7 Kd8 Kc8 Kd7",
          "aggressive_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "plan_full": [
            "g5",
            "Nf3",
            "Nf6",
            "Bg5",
            "e6",
            "Nbd2",
            "Be7",
            "Bxf6",
            "gxf6",
            "e5",
            "g6",
            "h4",
            "d6",
            "c3",
            "Bg7",
            "Bd3",
            "Nd7",
            "Qe2",
            "Qe7",
            "O-O-O",
            "fxe4",
            "Nxe4",
            "Nf6",
            "Ng5",
            "Kd8",
            "Rhe1",
            "Re8",
            "Nxh7",
            "Nxh7",
            "Bxh7",
            "Bh6+",
            "Ng5",
            "Bxg5+",
            "hxg5",
            "Qxg5",
            "Rh1",
            "Qg8",
            "Qh5",
            "b6",
            "Qh4+",
            "Kc8",
            "Qh6",
            "Kb7",
            "Qh7",
            "Qxh7",
            "Rxh7",
            "Bb7",
            "Rxc7+",
            "Kb8",
            "Rg7",
            "Bc8",
            "Rh1",
            "Ra7",
            "Rxa7",
            "Kxa7",
            "Rh8",
            "Kb8",
            "Rxe8",
            "Kc7",
            "Rxc8+",
            "Kxc8",
            "g4",
            "Kd8",
            "g5",
            "Ke8",
            "g6",
            "Kf8",
            "Kc2",
            "Kg7",
            "Kd3",
            "Kxg6",
            "Ke4",
            "Kf6",
            "f4",
            "Ke7",
            "f5",
            "Kf6",
            "fxe6",
            "Kxe6",
            "d5+",
            "Kd6",
            "Kd4",
            "Kc7",
            "Ke5",
            "Kd7",
            "d6",
            "Kd8",
            "Ke6",
            "Ke8",
            "d7+",
            "Kd8",
            "Kd6",
            "b5",
            "axb5",
            "a4",
            "bxa4",
            "c5",
            "a3",
            "c6",
            "a2",
            "c7#",
            "Kd8",
            "Ke7",
            "Kc8",
            "Ke8",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kd7",
            "Kc8",
            "Kd8",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc8",
            "Kd7",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7",
            "Kc7",
            "Kd8",
            "Kc8",
            "Kd7"
          ],
          "plan_execute": []
        },
        "query2": {
          "positional_move": "Re8",
          "positional_uci": null,
          "positional_response": "Re8 Rg8 Rf8",
          "positional_tokens": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rg8",
            "Rf8"
          ],
          "plan_execute": []
        },
        "query3": {
          "neutral_move": "Re8",
          "neutral_uci": null,
          "neutral_response": "Re8 Rxe8 Kf8",
          "neutral_tokens": {
            "prompt_tokens": 562,
            "completion_tokens": 8,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "plan_full": [
            "Rxe8",
            "Kf8"
          ],
          "plan_execute": []
        },
        "final_moves": {
          "aggressive_uci": null,
          "positional_uci": null,
          "neutral_uci": null,
          "consensus_move": null,
          "source_agents": [],
          "selected_agent": null
        },
        "plans": {
          "aggressive": {
            "full": [
              "g5",
              "Nf3",
              "Nf6",
              "Bg5",
              "e6",
              "Nbd2",
              "Be7",
              "Bxf6",
              "gxf6",
              "e5",
              "g6",
              "h4",
              "d6",
              "c3",
              "Bg7",
              "Bd3",
              "Nd7",
              "Qe2",
              "Qe7",
              "O-O-O",
              "fxe4",
              "Nxe4",
              "Nf6",
              "Ng5",
              "Kd8",
              "Rhe1",
              "Re8",
              "Nxh7",
              "Nxh7",
              "Bxh7",
              "Bh6+",
              "Ng5",
              "Bxg5+",
              "hxg5",
              "Qxg5",
              "Rh1",
              "Qg8",
              "Qh5",
              "b6",
              "Qh4+",
              "Kc8",
              "Qh6",
              "Kb7",
              "Qh7",
              "Qxh7",
              "Rxh7",
              "Bb7",
              "Rxc7+",
              "Kb8",
              "Rg7",
              "Bc8",
              "Rh1",
              "Ra7",
              "Rxa7",
              "Kxa7",
              "Rh8",
              "Kb8",
              "Rxe8",
              "Kc7",
              "Rxc8+",
              "Kxc8",
              "g4",
              "Kd8",
              "g5",
              "Ke8",
              "g6",
              "Kf8",
              "Kc2",
              "Kg7",
              "Kd3",
              "Kxg6",
              "Ke4",
              "Kf6",
              "f4",
              "Ke7",
              "f5",
              "Kf6",
              "fxe6",
              "Kxe6",
              "d5+",
              "Kd6",
              "Kd4",
              "Kc7",
              "Ke5",
              "Kd7",
              "d6",
              "Kd8",
              "Ke6",
              "Ke8",
              "d7+",
              "Kd8",
              "Kd6",
              "b5",
              "axb5",
              "a4",
              "bxa4",
              "c5",
              "a3",
              "c6",
              "a2",
              "c7#",
              "Kd8",
              "Ke7",
              "Kc8",
              "Ke8",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kd7",
              "Kc8",
              "Kd8",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc8",
              "Kd7",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7",
              "Kc7",
              "Kd8",
              "Kc8",
              "Kd7"
            ],
            "execute": []
          },
          "positional": {
            "full": [
              "Rg8",
              "Rf8"
            ],
            "execute": []
          },
          "neutral": {
            "full": [
              "Rxe8",
              "Kf8"
            ],
            "execute": []
          }
        },
        "final_plan": {
          "moves_for_execution": [],
          "full_moves": [],
          "source_agent": null
        },
        "total_tokens": {
          "aggressive": {
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          "positional": {
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "neutral": {
            "prompt_tokens": 562,
            "completion_tokens": 8,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          "total_prompt_tokens": 1688,
          "total_completion_tokens": 656,
          "total_tokens": 2344
        },
        "token_events": [
          {
            "paradigm": "self_consistency",
            "agent": "aggressive",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "aggressive_gm",
            "prompt_tokens": 563,
            "completion_tokens": 640,
            "total_tokens": 1203,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "length"
          },
          {
            "paradigm": "self_consistency",
            "agent": "positional",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "positional_gm",
            "prompt_tokens": 563,
            "completion_tokens": 8,
            "total_tokens": 571,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          },
          {
            "paradigm": "self_consistency",
            "agent": "neutral",
            "ply_index": 110,
            "turn_number": 56,
            "round": 1,
            "response_source": "neutral_gm",
            "prompt_tokens": 562,
            "completion_tokens": 8,
            "total_tokens": 570,
            "model": "gpt-3.5-turbo-instruct",
            "finish_reason": "stop"
          }
        ]
      },
      "board_fen": "6r1/P7/4pk2/3p4/3P4/2P1R3/2b2P1K/8 w - - 1 56"
    }
  ],
  "black_responses": [],
  "white_errors": [],
  "black_errors": [],
  "white_plan_log": [],
  "black_plan_log": [],
  "timestamp": "2025-11-29T22:50:32.341958",
  "game_id": "gpt-3.5-turbo-instruct_vs_Stockfish_SC_1",
  "configuration": "SC"
}